[
  {
    "title": "Sampling-based time-optimal path parameterization with jerk constraints for robotic manipulation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104530",
    "abstract": "In this paper, a sampling-based time-optimal path parameterization (S-TOPP) method is proposed to address time-optimal trajectory planning problems with bounded jerks. The key insight of S-TOPP is that a tree of feasible nodes connected by edges is established to find a time-optimal trajectory on the temporal dimension. The tree establishment process includes two major phases at each stage, namely sampling and one-step backtracking. In the sampling phase, a new sampling strategy integrating historical information is proposed to obtain superior samples whereby fewer samples can be controlled automatically, reducing the calculation loss. In one-step backtracking phase, a “lazy” strategy is used to lazily skip constraint-checking when evaluating local connections, enabling S-TOPP to avoid checking the vast majority of nodes that have no chance of being in an optimal trajectory. Simulations and real-world experiments validate the feasibility and practicability of S-TOPP. Results show that S-TOPP is an effective solution to jerk-bounded time-optimal trajectory planning, with features that are more in line with the needs of the practical tasks compared with other methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001690",
    "keywords": [
      "Acceleration",
      "Algorithm",
      "Artificial intelligence",
      "Astronomy",
      "Backtracking",
      "Classical mechanics",
      "Computer science",
      "Computer vision",
      "Filter (signal processing)",
      "Jerk",
      "Look-ahead",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Motion planning",
      "Path (computing)",
      "Physics",
      "Programming language",
      "Robot",
      "Sampling (signal processing)",
      "Trajectory",
      "Tree (set theory)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Huanhuan"
      },
      {
        "surname": "Liu",
        "given_name": "Houde"
      },
      {
        "surname": "Xia",
        "given_name": "Chongkun"
      },
      {
        "surname": "Mei",
        "given_name": "Hongwei"
      },
      {
        "surname": "Gao",
        "given_name": "Xuehai"
      },
      {
        "surname": "Liang",
        "given_name": "Bin"
      }
    ]
  },
  {
    "title": "Simultaneous search and monitoring by multiple aerial robots",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104544",
    "abstract": "This paper studies simultaneous search and monitoring (SSM) between multiple unmanned aerial vehicles (UAVs) and multiple moving ground targets. Searching for unknown targets and monitoring known ones are two intrinsically related problems, but they have mostly been addressed in isolation. We combine the two tasks and exploit their interconnection as a synergy rather than a trade-off. We construct the single-robot SSM as a partially observable Markov decision process (POMDP) and the multi-robot SSM as a semi-decentralised POMDP (semi-Dec-POMDP). A novel heuristic reactive policy planning is proposed to solve the POMDP. It is then extended for semi-Dec-POMDP with game-theoretical methods. In simulations and experiments, the searchers will successfully locate unknown targets without losing known ones and cooperate by partitioning their tasks. With theoretical proofs, simulations, and experiments, we demonstrate that our method can perform better than conventional approaches and the state-of-the-art.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001835",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer security",
      "Exploit",
      "Heuristic",
      "Isolation (microbiology)",
      "Machine learning",
      "Markov chain",
      "Markov decision process",
      "Markov model",
      "Markov process",
      "Mathematics",
      "Microbiology",
      "Operating system",
      "Partially observable Markov decision process",
      "Process (computing)",
      "Robot",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Haoyu"
      },
      {
        "surname": "Veres",
        "given_name": "Sandor"
      },
      {
        "surname": "Kolling",
        "given_name": "Andreas"
      }
    ]
  },
  {
    "title": "A novel robust adaptive neuro-sliding mode steering controller for autonomous ground vehicles",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104557",
    "abstract": "This paper intends to harness recent advances in intelligent commands to develop a novel steering control strategy for autonomous ground vehicles (AGVs) maneuvering problems. In this research, the vehicle is embodied by a single track-model (ST) taking into consideration its lateral dynamics. Besides, it is subject to unknown disturbances and uncertainties, associated with the tire/road adhesion coefficient, which are upper bounded by a positive limit. An on-line Radial Basis-function Neural-Networks (RBNN) adaptive mechanism is designed to estimate this upper limit in the sense of Lyapunov. On this basis, a novel robust adaptive neuro-sliding mode steering angle controller (AN-SMC) is introduced. Whilst the effectiveness of the controller is impacted by its parameters, a new neural-network optimization algorithm (NNA) is employed to provide optimal values for these settings. The proposed approach is evaluated through a single lane-change-maneuver planned out by a new methodology. The steering controller revealed a powerful path-tracking via the comparisons carried out in support of the developed strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001963",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Automotive engineering",
      "Biology",
      "Bounded function",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Engineering",
      "Limit (mathematics)",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Mode (computer interface)",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Quantum mechanics",
      "Radial basis function",
      "Sliding mode control",
      "Vehicle dynamics"
    ],
    "authors": [
      {
        "surname": "El Hajjami",
        "given_name": "Lhoussain"
      },
      {
        "surname": "Mellouli",
        "given_name": "El Mehdi"
      },
      {
        "surname": "Žuraulis",
        "given_name": "Vidas"
      },
      {
        "surname": "Berrada",
        "given_name": "Mohammed"
      }
    ]
  },
  {
    "title": "Design and modeling of a planar-to-spatial tendon-driven continuum manipulator subjected to uncertain forces",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104551",
    "abstract": "Continuum Manipulators (CMs) have gained popularity as a promising solution for exploring unstructured environments due to their dexterity, compliance, and redundancy. Studies on CMs have focused individually on planar and spatial configurations, ranging from single to multi-section constructions. Planar CMs are easier to design, have simpler kinematics equations and possesses less number of tendons with reduced dexterity, redundancy, and reach. Whereas spatial CMs, offer a larger workspace with improved dexterity and redundancy while computationally expensive. This paper introduces a novel two-section tendon-driven continuum manipulator (TDCM) design that uses two planar sections to manipulate the distal end of the manipulator in three-dimensional space to handle external interaction from the environment. The proposed solution offers improved performance in terms of handling payloads and tip deflection under external interactions. This design is intended for agricultural applications such as vegetable harvesting and requires larger workspace and fewer actuators. We demonstrate the effectiveness of our design through kinematic and static analysis. The kineto-static model estimates the profile of the proposed TDCM under external interaction acting at the manipulator's distal end. Finally, the proposed design is experimentally validated by an in-housed prototype of an two-section TDCM, actuated by two tendons/section.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001902",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Classical mechanics",
      "Computer graphics (images)",
      "Computer science",
      "Deflection (physics)",
      "Kinematics",
      "Operating system",
      "Optics",
      "Physics",
      "Planar",
      "Redundancy (engineering)",
      "Robot",
      "Simulation",
      "Workspace"
    ],
    "authors": [
      {
        "surname": "Pachouri",
        "given_name": "Vipin"
      },
      {
        "surname": "Pathak",
        "given_name": "Pushparaj Mani"
      }
    ]
  },
  {
    "title": "Modeling and analysing Cyber–Physical Systems in HOL-CSP",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104549",
    "abstract": "Modelling and Analysing Cyber–Physical Systems (CPS) is a challenge for Formal Methods and therefore a field of active research. It is characteristic of CPSs that models comprise aspects of Newtonian Physics appearing in system environments, the difficulties of their discretization, the problems of communication and interaction between actors in this environment as well as calculations respecting time-bounds. We present a novel framework to address these problems developed with industrial partners involved in the Autonomous Car domain. Based on HOL-CSP, we model time, physical evolution, “scenes” (global states) and “scenarios” (traces) as well as the interaction of “actors” (vehicles, pedestrians, traffic lights) inside this framework. In particular, discrete samplings are modelled by infinite internal choices. For several instances of the modelling framework, we give formal proofs of a particular safety property for Autonomous Cars: if each car follows the same driving strategy defined by the so-called Responsibility-Sensitive Safety (RSS), no collision will occur. The proofs give rise to a number of variants of RSS and optimizations as well as a test-case partitioning of abstract test cases and a test-strategy for integration tests.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001884",
    "keywords": [
      "Computer science",
      "Cyber-physical system",
      "Discretization",
      "Distributed computing",
      "Domain (mathematical analysis)",
      "Epistemology",
      "Field (mathematics)",
      "Geometry",
      "HOL",
      "Mathematical analysis",
      "Mathematical proof",
      "Mathematics",
      "Operating system",
      "Philosophy",
      "Programming language",
      "Property (philosophy)",
      "Pure mathematics",
      "RSS",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Crisafulli",
        "given_name": "Paolo"
      },
      {
        "surname": "Taha",
        "given_name": "Safouan"
      },
      {
        "surname": "Wolff",
        "given_name": "Burkhart"
      }
    ]
  },
  {
    "title": "Reinforcement learning in robotic motion planning by combined experience-based planning and self-imitation learning",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104545",
    "abstract": "High-quality and representative data is essential for both Imitation Learning (IL)- and Reinforcement Learning (RL)-based motion planning tasks. For real robots, it is challenging to collect enough qualified data either as demonstrations for IL or experiences for RL due to safety consideration in environments with obstacles. We target this challenge by proposing the self-imitation learning by planning plus (SILP+) algorithm, which efficiently embeds experience-based planning into the learning architecture to mitigate the data-collection problem. The planner generates demonstrations based on successfully visited states from the current RL policy, and the policy improves by learning from these demonstrations. In this way, we relieve the demand for human expert operators to collect demonstrations required by IL and improve the RL performance as well. Various experimental results shows that SILP+ achieves better training efficiency, higher and more stable success rate in complex motion planning tasks compared to several other methods. Extensive tests on physical robots illustrate the effectiveness of SILP+ in a physical setting, retaining a success rate of 90% where the next-best contender drops from 87% to 75% in the Sim2Real transition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001847",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Human–computer interaction",
      "Imitation",
      "Machine learning",
      "Motion (physics)",
      "Motion planning",
      "Planner",
      "Psychology",
      "Reinforcement learning",
      "Robot",
      "Social psychology"
    ],
    "authors": [
      {
        "surname": "Luo",
        "given_name": "Sha"
      },
      {
        "surname": "Schomaker",
        "given_name": "Lambert"
      }
    ]
  },
  {
    "title": "Collision-free and smooth motion planning of dual-arm Cartesian robot based on B-spline representation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104534",
    "abstract": "This paper discusses a new approach to motion planning of dual-arm gantry kinematic that solves the self-collision problem while ensuring G2-continuity and low curvatures. Starting from collision-free start and target points, the proposed method defines the geometric path of the end-effectors with classical five-segment planar trajectories, described by fifth-degree B-splines. The rototranslation of the loaded parts is evaluated in frames to define sampled overlapping curves, used to compute splines that act as deviation curves being added on the previously defined geometric paths in order to prevent collisions. Here, a quadratic programming minimization is employed to reduce the curvature of these spline and preserve the kinematics properties of the initial path. The kinematic constraints of the axes are ensured by iso-parametric trajectory planning, which results in an optimized motion profile to reduce the task execution time. Finally, the proposed approach is applied to a sorting system for laser machine (LST) having a dual-arm 7-d.o.f. gantry kinematic. The results of a case study of a typical sorting operation are presented and discussed to illustrate and clarify the method. The approach presented in this work can be applied to other robotic systems with similar kinematic structures, providing a useful tool for motion planning in pick-and-place applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001732",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Astronomy",
      "Cartesian coordinate system",
      "Classical mechanics",
      "Computer science",
      "Geometry",
      "Kinematics",
      "Mathematics",
      "Motion planning",
      "Parametric equation",
      "Path (computing)",
      "Physics",
      "Programming language",
      "Robot",
      "Robot end effector",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Riboli",
        "given_name": "Marco"
      },
      {
        "surname": "Jaccard",
        "given_name": "Matthieu"
      },
      {
        "surname": "Silvestri",
        "given_name": "Marco"
      },
      {
        "surname": "Aimi",
        "given_name": "Alessandra"
      },
      {
        "surname": "Malara",
        "given_name": "Cesare"
      }
    ]
  },
  {
    "title": "Stable skill improvement of quadruped robot based on privileged information and curriculum guidance",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104550",
    "abstract": "Quadruped robots have attracted many researchers due to their unique advantages. In the field of control, deep reinforcement learning (DRL) saves the complex and tedious design of traditional control algorithms and motivates the robot to learn the motion patterns by itself, which is a promising alternative approach. However, due to the lack of prior information that is difficult to obtain in the physical world, policy usually exhibits a single motion state when faced with multiple scenarios. In this paper, we adopt a teacher–student policy architecture that uses the student policy to implicitly identify the teacher policy containing a privileged information, enabling the robot to adjust its motion depending on the environment it is in. We propose the synthetic terrain-command curriculum that assigns different levels of command curriculum depending on the difficulty of the terrain, which is useful for improving policy adaptation and stability. Policy is often trapped in local optima due to the nonlinearity of the robot system and unreasonable parameters. We propose a self-correction mechanism to jump out of this state in time, so that the policy can be steadily improved. We demonstrate our policy on the real quadruped platform named SDUQuad-48, and the results show that the learned policy exhibits state-of-the-art performance in both high-speed locomotion and complex terrain adaptation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001896",
    "keywords": [
      "Adaptation (eye)",
      "Algorithm",
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Control (management)",
      "Curriculum",
      "Ecology",
      "Field (mathematics)",
      "Human–computer interaction",
      "Law",
      "Machine learning",
      "Mathematics",
      "Motion (physics)",
      "Optics",
      "Physics",
      "Political science",
      "Pure mathematics",
      "Reinforcement learning",
      "Robot",
      "Robotics",
      "Simulation",
      "Stability (learning theory)",
      "State (computer science)",
      "Terrain",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Han"
      },
      {
        "surname": "Chen",
        "given_name": "Teng"
      },
      {
        "surname": "Cao",
        "given_name": "Jingxuan"
      },
      {
        "surname": "Bi",
        "given_name": "Jian"
      },
      {
        "surname": "Lu",
        "given_name": "Guanglin"
      },
      {
        "surname": "Zhang",
        "given_name": "Guoteng"
      },
      {
        "surname": "Rong",
        "given_name": "Xuewen"
      },
      {
        "surname": "Li",
        "given_name": "Yibin"
      }
    ]
  },
  {
    "title": "A numerically-stable trajectory generation and optimization algorithm for autonomous quadrotor UAVs",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104532",
    "abstract": "This paper introduces a novel trajectory generation and optimization algorithm (TGO) that enables agile and aggressive flight of quadrotor UAVs while considering various constraints associated with robot dynamics, actuator inputs, and flight environment. The TGO algorithm employs time-parametrized polynomial trajectories based on a predetermined sequence of waypoints to produce dynamically feasible and collision-free trajectories. This approach extends previous work that utilized differential flatness property and polynomial based trajectories by eliminating the need for iterative searching and computationally intensive sampling. One of the significant advantages of the TGO algorithm is its numerical stability for large number of waypoints and high-order polynomials. To address the ill-conditioned problem of Quadratic Programming (QP) based methods, the TGO algorithm reformulates the trajectory generation and optimization problem into an unconstrained quadratic programming (UCP) using the numerically stable null-space factorization method. The TGO algorithm produces minimum derivative trajectories and minimum waypoints arrival times, generating a wide range of aggressive trajectories that can leverage the full maneuvering capabilities of quadrotor robots. The proposed algorithm’s numerical stability and computational advantages are demonstrated through various scenarios and comparisons. An animated simulation of the TGO algorithm is available at: https://youtu.be/MvvhBG14iIg.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001719",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Geometry",
      "Leverage (statistics)",
      "Mathematical optimization",
      "Mathematics",
      "Optimal control",
      "Physics",
      "Quadratic equation",
      "Quadratic programming",
      "Trajectory",
      "Trajectory optimization"
    ],
    "authors": [
      {
        "surname": "Alqudsi",
        "given_name": "Yunes"
      },
      {
        "surname": "Makaraci",
        "given_name": "Murat"
      },
      {
        "surname": "Kassem",
        "given_name": "Ayman"
      },
      {
        "surname": "El-Bayoumi",
        "given_name": "Gamal"
      }
    ]
  },
  {
    "title": "A method for understanding and digitizing manipulation activities using programming by demonstration in robotic applications",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104556",
    "abstract": "Robots are flexible machines, where the flexibility is achieved, mainly, by the re-programming of the robotic system. To fully exploit the potential of robotic systems, an easy, fast, and intuitive programming methodology is desired. By applying such methodology, robots will be open to a wider audience of potential users (i.e. SMEs, etc.) since the need for a robotic expert in charge of programming the robot will not be needed anymore. This paper presents a Programming by Demonstration approach dealing with high-level tasks taking advantage of the ROS standard. The system identifies the different processes associated to a single-arm human manipulation activity and generates an action plan for future interpretation by the robot. The system is composed of five modules, all of them containerized and interconnected by ROS. Three of these modules are in charge of processing the manipulation data gathered by the sensors system, and converting it from the lowest level to the highest manipulation processes. In order to do this transformation, a module is used to train the system. This module generates, for each operation, an Optimized Multiorder Multivariate Markov Model, that later will be used for the operations recognition and process segmentation. Finally, the fifth module is used to interface and calibrate the system. The system was implemented and tested using a dataglove and a hand position tracker to capture the operator’s data during the manipulation. Four users and five different object types were used to train and test the system both for operations recognition and process segmentation and classification, including also the detection of the locations where the operations are performed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001951",
    "keywords": [
      "Artificial intelligence",
      "Bubble",
      "Computer science",
      "Flexibility (engineering)",
      "Human–computer interaction",
      "Interface (matter)",
      "Mathematics",
      "Maximum bubble pressure method",
      "Operating system",
      "Process (computing)",
      "Programming by demonstration",
      "Programming language",
      "Robot",
      "Robotic arm",
      "Segmentation",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Malvido Fresnillo",
        "given_name": "Pablo"
      },
      {
        "surname": "Vasudevan",
        "given_name": "Saigopal"
      },
      {
        "surname": "Mohammed",
        "given_name": "Wael M."
      },
      {
        "surname": "Martinez Lastra",
        "given_name": "Jose L."
      },
      {
        "surname": "Pérez García",
        "given_name": "José A."
      }
    ]
  },
  {
    "title": "Task parse tree: Learning task policy from videos with task-irrelevant components",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104552",
    "abstract": "A good task policy should explicitly interpret the preconditions of actions and the composition structure of task. We aim to automatically learn such a task policy from videos which remains challenging at present. This issue can be further aggravated when task-irrelevant components are involved in videos, such as unoperated objects and small actions. Task-irrelevant objects may introduce disruptive visual relations, and task-irrelevant actions would lead to misleading and even failed task planning. Solving both issues simultaneously is beyond the scope of existing methods. To this end, we propose Task Parse Tree (TPT) as a novel task policy representation, distinguishing task-relevant actions with definite preconditions and clear execution order. The automatic generation of TPT relies on two core designs, where spatio-temporal graph (STG) seizes the vital changes in visual relations of objects and their attributes both spatially and temporally, and conjugate action graph (CAG) models the execution logic of actions in a graph. We collect a dataset of a real-world task, Make Tea, and experiment results on the dataset show that TPT realizes both accurate and interpretable task planning in two different scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001914",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Economics",
      "Graph",
      "Human–computer interaction",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Natural language processing",
      "Parsing",
      "Task (project management)",
      "Theoretical computer science",
      "Tree (set theory)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Weihao"
      },
      {
        "surname": "You",
        "given_name": "Mingyu"
      },
      {
        "surname": "Zhou",
        "given_name": "Hongjun"
      },
      {
        "surname": "He",
        "given_name": "Bin"
      }
    ]
  },
  {
    "title": "A review of UAV autonomous navigation in GPS-denied environments",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104533",
    "abstract": "Unmanned aerial vehicles (UAVs) have drawn increased research interest in recent years, leading to a vast number of applications, such as, terrain exploration, disaster assistance and industrial inspection. Unlike UAV navigation in outdoor environments that rely on GPS (Global Positioning System) for localization, indoor navigation cannot rely on GPS due to the poor quality or lack of signal. Although some reviewing papers particularly summarized indoor navigation strategies (e.g., Visual-based Navigation) or their specific sub-components (e.g., localization and path planning) in detail, there still lacks a comprehensive survey for the complete navigation strategies that cover different technologies. This paper proposes a taxonomy which firstly classifies the navigation strategies into Mapless and Map-based ones based on map usage and then, respectively categorizes the Mapless navigation into Integrated, Direct and Indirect approaches via common characteristics. The Map-based navigation is then split into Known Map/Spaces and Map-building via prior knowledge. In order to analyze these navigation strategies, this paper uses three evaluation metrics (Path Length, Deviation Rate and Exploration Efficiency) according to the common purposes of navigation to show how well they can perform. Furthermore, three representative strategies were selected and 120 flying experiments conducted in two reality-like simulated indoor environments to show their performances against the evaluation metrics proposed in this paper, i.e., the ratio of Successful Flight, the Mean time of Successful Flight, the Mean Length of Successful Flight, the Mean time of Flight, and the Mean Length of Flight. In comparison to the CNN-based Supervised Learning (directly maps visual observations to UAV controls) and the Frontier-based navigation (necessitates continuous global map generation), the experiments show that the CNN-based Distance Estimation for navigation trades off the ratio of Successful Flight and the required time and path length. Moreover, this paper identifies the current challenges and opportunities which will drive UAV navigation research in GPS-denied environments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001720",
    "keywords": [
      "Artificial intelligence",
      "Cartography",
      "Computer science",
      "Computer vision",
      "Geography",
      "Global Positioning System",
      "Mobile robot",
      "Mobile robot navigation",
      "Navigation system",
      "Real-time computing",
      "Robot",
      "Robot control",
      "Telecommunications",
      "Terrain"
    ],
    "authors": [
      {
        "surname": "Chang",
        "given_name": "Yingxiu"
      },
      {
        "surname": "Cheng",
        "given_name": "Yongqiang"
      },
      {
        "surname": "Manzoor",
        "given_name": "Umar"
      },
      {
        "surname": "Murray",
        "given_name": "John"
      }
    ]
  },
  {
    "title": "Pyramidal 3D feature fusion on polar grids for fast and robust traversability analysis on CPU",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104524",
    "abstract": "Self-driving vehicles and autonomous ground robots require a reliable and accurate method to analyze the traversability of the surrounding environment for safe navigation. This paper proposes and evaluates a real-time machine learning-based traversability analysis method that combines geometric features with a pyramid-polar space representation based on SVM classifiers. In particular, we show that by fusing geometric features with information stemming from coarser pyramid levels that account for a broader space portion, as well as integrating important implementation details, allows for a noticeable boost in performance and reliability. The main goal of this work is to demonstrate that traversability analysis is possible with effective results and in real-time even on cheaper hardware than expensive GPUs, e.g. CPU-only PCs. The proposed approach has been compared with state-of-the-art deep learning approaches on publicly available datasets of outdoor driving scenarios, running such algorithms both on GPU and CPU to compare runtimes. Our method can be fully executed on CPU and achieves results close to the best-in-class methods, runs faster, and requires fewer and less expensive hardware resources, consuming less than 30% electrical power with respect to deep learning models on embedded processing units. We release with this paper the open-source implementation of our method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902300163X",
    "keywords": [
      "Artificial intelligence",
      "Central processing unit",
      "Computer hardware",
      "Computer science",
      "Deep learning",
      "Feature (linguistics)",
      "Law",
      "Linguistics",
      "Optics",
      "Philosophy",
      "Physics",
      "Political science",
      "Politics",
      "Power (physics)",
      "Pyramid (geometry)",
      "Quantum mechanics",
      "Real-time computing",
      "Reliability (semiconductor)",
      "Representation (politics)",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Fusaro",
        "given_name": "Daniel"
      },
      {
        "surname": "Olivastri",
        "given_name": "Emilio"
      },
      {
        "surname": "Donadi",
        "given_name": "Ivano"
      },
      {
        "surname": "Evangelista",
        "given_name": "Daniele"
      },
      {
        "surname": "Menegatti",
        "given_name": "Emanuele"
      },
      {
        "surname": "Pretto",
        "given_name": "Alberto"
      }
    ]
  },
  {
    "title": "A novel indoor localization algorithm based on a modified EKF using virtual dynamic point landmarks for 2D grid maps",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104546",
    "abstract": "Localization is a self-position estimation problem and is one of the most critical research areas in autonomous mobile robots. This study presents novel solutions to two significant practical challenges in localization. The initial challenge pertains to the lack of distinct features within the environment, while the second involves the imperfectness of the map. Many studies are based on Extended Kalman Filter (EKF) and they need specific features from the environment for localization. The edges and corners are the popular natural feature types to be used in grid maps. The proposed study promises accurate and fast position tracking in the grid maps which have very few corners and edges. To achieve high performance in such a challenging map, we propose the virtual dynamic point landmark (VDPL) approach in this paper. VDPL does not need specific features such as edges and corners, and any part of the map can be used as a landmark. Since the real-world applications are based on imperfect maps, mostly generated by SLAM (Simultaneous Localization and Mapping) algorithm, the probabilistic distribution of the measurement model and measurement predictions are incorrect. In this study, the position errors that occur as a result of this incorrectness are alleviated by modifying the EKF algorithm. The modified equations of EKF for taking into account the map errors are clearly shown in the paper. The efficiency of the proposed solution is demonstrated in multiple simulations which are performed in randomly generated maps. Moreover, the benefits and real-time performance of the proposed approach are provided by real-world tests using an autonomous wheelchair platform. We believe that the methods developed in this study will improve the localization performance of autonomous robots that operate in challenging environments in terms of feature structure.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001859",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Economics",
      "Extended Kalman filter",
      "Feature (linguistics)",
      "Finance",
      "Geometry",
      "Grid",
      "Grid reference",
      "Kalman filter",
      "Landmark",
      "Linguistics",
      "Mathematics",
      "Mobile robot",
      "Monte Carlo localization",
      "Philosophy",
      "Position (finance)",
      "Probabilistic logic",
      "Robot",
      "Simultaneous localization and mapping"
    ],
    "authors": [
      {
        "surname": "Altınpınar",
        "given_name": "Ozan Vahit"
      },
      {
        "surname": "Sezer",
        "given_name": "Volkan"
      }
    ]
  },
  {
    "title": "On demand ride sharing: Scheduling of an autonomous bus fleet for last mile travel",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104559",
    "abstract": "Autonomous buses are expected to expand the mobility-on-demand options in cities in the next 10 years. An essential aspect of ensuring optimal usage of fleets of autonomous buses is the task of scheduling. This paper presents a scheduling approach based on the construction of all possible trips used to formulate an optimization problem. While in the past most research is focused on the scheduling of taxi trips, there is an increasing interest in the research for the scheduling of last-mile travel options. A street network has been generated based on open street map data as a basis for the scheduling. All possible combinations of buses and requests are calculated, and for each of those trips, a close to optimal order of requests is created. These are used to formulate the optimization problem, calculating a close to optimal assignment of requests on the buses. The approach has considered constraints such as maximum waiting time, travel delay, and targets to exploit shared trips for higher efficiency. Experiments have been carried out in a simulated environment of a university campus area with fleets of up to 10 vehicles. By performing various trials with changing parameters, the influence of the constraints on waiting time and travel delay to the scheduling is determined. Depending on the setup, service rates above 90%, while trails with strict constraints show that the approach can handle short-term requests. Based on the results, a use case-specific composition of the autonomous bus fleet can be done.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001987",
    "keywords": [
      "Computer science",
      "Computer security",
      "Engineering",
      "Exploit",
      "Mathematical optimization",
      "Mathematics",
      "Operations research",
      "Parallel computing",
      "Scheduling (production processes)",
      "TRIPS architecture"
    ],
    "authors": [
      {
        "surname": "Husemann",
        "given_name": "Jörg"
      },
      {
        "surname": "Kunz",
        "given_name": "Simon"
      },
      {
        "surname": "Berns",
        "given_name": "Karsten"
      }
    ]
  },
  {
    "title": "A general skeleton-based action and gesture recognition framework for human–robot collaboration",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104523",
    "abstract": "Recognizing human actions is crucial for an effective and safe collaboration between humans and robots. For example, in a collaborative assembly task, human workers can use gestures to communicate with the robot, and the robot can use the recognized actions to anticipate the next steps in the assembly process, leading to improved safety and productivity. In this work, we propose a general framework for human action recognition based on 3D pose estimation and ensemble techniques, which allows to recognize both body actions and hand gestures. The framework relies on OpenPose and 2D to 3D lifting methods to estimate 3D joints for the human body and the hands, feeding then these joints into a set of graph convolutional networks based on the Shift-GCN architecture. The output scores of all networks are combined using an ensemble approach to predict the final human action. The proposed framework was evaluated on a custom dataset designed for human–robot collaboration tasks, named IAS-Lab Collaborative HAR dataset. The results showed that using an ensemble of action recognition models improves the accuracy and robustness of the overall system; moreover, the proposed framework can be easily specialized on different scenarios and achieve state-of-the-art results on the HRI30 dataset when coupled with an object detector or classifier.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001628",
    "keywords": [
      "Action recognition",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Class (philosophy)",
      "Classifier (UML)",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Gene",
      "Gesture",
      "Gesture recognition",
      "Graph",
      "Human–computer interaction",
      "Human–robot interaction",
      "Machine learning",
      "Pose",
      "Robot",
      "Robustness (evolution)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Terreran",
        "given_name": "Matteo"
      },
      {
        "surname": "Barcellona",
        "given_name": "Leonardo"
      },
      {
        "surname": "Ghidoni",
        "given_name": "Stefano"
      }
    ]
  },
  {
    "title": "Measurement of mobile manipulator chassis pose change caused by suspension deformation and end-effector accuracy improvement based on multi-sensor fusion",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104553",
    "abstract": "In order to expand the application of mobile manipulators in high-precision scenarios, researchers have focused on improving their accuracy. However, it is challenging to eliminate the impact of reference movement on manipulator accuracy during operation. Therefore, real-time measurement of manipulator reference and compensation of end pose are necessary. To address the inflexibility of global measurement schemes, this study proposes a method for obtaining the pose change of the chassis by fusing an inertial measurement unit (IMU) array and suspension displacement sensors. The IMU array is used to remove acceleration interference from the accelerometer and obtain the attitude of the chassis, while the kinematic analysis of the suspension is used to obtain the 6-degree-of-freedom (DoF) pose of the chassis. These two measurements are fused to improve attitude accuracy. The pose change of the chassis is filtered and used to generate a compensated manipulator pose through pose transformation. Finally, the inverse kinematics of the manipulator is used to compensate each joint. An experiment was conducted on a mobile manipulator, and the end position error was found to be less than 0.5 mm after chassis disturbance, demonstrating promising results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001926",
    "keywords": [
      "Acceleration",
      "Accelerometer",
      "Artificial intelligence",
      "Chassis",
      "Classical mechanics",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Homotopy",
      "Inertial measurement unit",
      "Kinematics",
      "Mathematics",
      "Operating system",
      "Physics",
      "Pure mathematics",
      "Simulation",
      "Structural engineering",
      "Suspension (topology)"
    ],
    "authors": [
      {
        "surname": "Feng",
        "given_name": "Yixiao"
      },
      {
        "surname": "Tian",
        "given_name": "Xiangyu"
      },
      {
        "surname": "Li",
        "given_name": "Tiemin"
      },
      {
        "surname": "Jiang",
        "given_name": "Yao"
      }
    ]
  },
  {
    "title": "Model-based variable impedance learning control for robotic manipulation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104531",
    "abstract": "The capability to adapt compliance by varying muscle stiffness is crucial for dexterous manipulation skills in humans. Incorporating compliance in robot motor control is crucial for enabling real-world force interaction tasks with human-like dexterity. In this study, we introduce a novel approach, we call “deep Model Predictive Variable Impedance Controller (MPVIC)” for compliant robotic manipulation, which combines Variable Impedance Control with Model Predictive Control (MPC). The method involves learning a generalized Cartesian impedance model of a robot manipulator through an exploration strategy to maximize information gain. Within the MPC framework, this learned model is utilized to adapt the impedance parameters of a low-level variable impedance controller, thereby achieving the desired compliance behavior for various manipulation tasks without requiring retraining or finetuning. We assess the efficacy of the proposed deep MPVIC approach using a Franka Emika Panda robotic manipulator in simulations and real-world experiments involving diverse manipulation tasks. Comparative evaluations against model-free and model-based reinforcement learning approaches in variable impedance control are conducted, considering aspects such as transferability between tasks and performance. The results demonstrate the effectiveness and potential of the presented approach for advancing robotic manipulation capabilities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001707",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Electrical engineering",
      "Electrical impedance",
      "Engineering",
      "Impedance control",
      "Mathematical analysis",
      "Mathematics",
      "Model predictive control",
      "Reinforcement learning",
      "Robot",
      "Robotics",
      "Variable (mathematics)"
    ],
    "authors": [
      {
        "surname": "Anand",
        "given_name": "Akhil S."
      },
      {
        "surname": "Gravdahl",
        "given_name": "Jan Tommy"
      },
      {
        "surname": "Abu-Dakka",
        "given_name": "Fares J."
      }
    ]
  },
  {
    "title": "Learning stable robotic skills on Riemannian manifolds",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104510",
    "abstract": "In this paper, we propose an approach to learn stable dynamical systems that evolve on Riemannian manifolds. Our approach leverages a data-efficient procedure to learn a diffeomorphic transformation, enabling the mapping of simple stable dynamical systems onto complex robotic skills. By harnessing mathematical techniques derived from differential geometry, our method guarantees that the learned skills fulfill the geometric constraints imposed by the underlying manifolds, such as unit quaternions (UQ) for orientation and symmetric positive definite (SPD) matrices for impedance. Additionally, the method preserves convergence towards a given target. Initially, the proposed methodology is evaluated through simulation on a widely recognized benchmark, which involves projecting Cartesian data onto UQ and SPD manifolds. The performance of our proposed approach is then compared with existing methodologies. Apart from that, a series of experiments were performed to evaluate the proposed approach in real-world scenarios. These experiments involved a physical robot tasked with bottle stacking under various conditions and a drilling task performed in collaboration with a human operator. The evaluation results demonstrate encouraging outcomes in terms of learning accuracy and the ability to adapt to different situations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001495",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biochemistry",
      "Cartesian coordinate system",
      "Chemistry",
      "Computer science",
      "Gene",
      "Geodesy",
      "Geography",
      "Geometry",
      "Mathematics",
      "Operator (biology)",
      "Repressor",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Saveriano",
        "given_name": "Matteo"
      },
      {
        "surname": "Abu-Dakka",
        "given_name": "Fares J."
      },
      {
        "surname": "Kyrki",
        "given_name": "Ville"
      }
    ]
  },
  {
    "title": "Online trajectory optimization for safe autonomous overtaking with active obstacle avoidance",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104528",
    "abstract": "Autonomous driving with active obstacle avoidance in dynamic urban environment has attracted significant attention to improve road safety and traffic efficiency. In this paper, an online optimization-based trajectory planning method for autonomous overtaking is developed to prevent collision and realize safe efficient driving. Unlike traditional methods which solve the overtaking problem with segmented reference path in multi-stages with integer variables, this paper proposes a novel dual-variable trajectory planning framework to get the optimal trajectory for active collision avoidance. First, the nonlinear non-differentiable collision-free constraint between vehicles is reformulated using dual problem optimization. Then, the optimal trajectory for longitudinal and lateral movement is obtained jointly in a receding horizon optimization framework based on the optimized dual variable considering the safety and dynamic performance. The key novelty lies in the reformulation of the nonlinear optimal trajectory planning problem and the formulated whole optimization framework can be solved using efficient open-source solvers for online computation. Simulation studies in different dynamic cases are provided to show the efficiency and robustness for safe driving. The method reaches safe overtaking performance with much less calculation time. Real-world experiment with a static obstacle demonstrates its capability for the safe efficient trajectory planning and online implementation in autonomous driving.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001677",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Astronomy",
      "Civil engineering",
      "Collision",
      "Collision avoidance",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Law",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Mobile robot",
      "Motion planning",
      "Obstacle",
      "Obstacle avoidance",
      "Optimal control",
      "Optimization problem",
      "Overtaking",
      "Physics",
      "Political science",
      "Robot",
      "Trajectory",
      "Trajectory optimization",
      "Variable (mathematics)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Guoqiang"
      },
      {
        "surname": "Guo",
        "given_name": "Hongliang"
      },
      {
        "surname": "Wang",
        "given_name": "Zhenpo"
      },
      {
        "surname": "Wang",
        "given_name": "Meng"
      }
    ]
  },
  {
    "title": "Autonomous agent-based simulation modelling—A case study on a flexible GPU-card final assembly line",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104511",
    "abstract": "Market demands for high-tech products constantly evolve by product specification. To be competitive, a production system must be flexible and reconfigurable when facing mass customization. Flexible assembly line (FAL) enables mixed production with high efficiency. One example is graphic processing unit (GPU) cards. FAL requires comprehensive system design and scheduling to fully utilize the resources. This study adopts agent-based simulation (ABS) modelling for a FAL because of the abilities of ABS in flexibility and scalability. The proposed framework consists of three parts: real environment, virtual environment, and evaluation and analysis. This study uses agent-based simulation modelling to elaborate on sequencing and scheduling performances in the GPU-card assembly line. The Pareto frontier analysis is conducted to resolve conflicts between part tardiness and throughput.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001501",
    "keywords": [
      "Bottleneck",
      "Computer science",
      "Distributed computing",
      "Economics",
      "Embedded system",
      "Engineering",
      "Flexibility (engineering)",
      "Job shop scheduling",
      "Mass customization",
      "Mathematics",
      "Mechanical engineering",
      "Operating system",
      "Operations management",
      "Personalization",
      "Production line",
      "Routing (electronic design automation)",
      "Scalability",
      "Scheduling (production processes)",
      "Statistics",
      "Tardiness",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Kung-Jeng"
      },
      {
        "surname": "Eunike",
        "given_name": "Agustina"
      },
      {
        "surname": "Kurniawan",
        "given_name": "Ivan"
      },
      {
        "surname": "Ardi",
        "given_name": "Romadhani"
      },
      {
        "surname": "Chiu",
        "given_name": "Jing-Ming"
      }
    ]
  },
  {
    "title": "Visual-RRT: Integrating IBVS as a steering method in an RRT planner",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104525",
    "abstract": "In this paper, we present a new approach to robot motion planning that anticipates the use of vision-based feedback control during task execution. We accomplish this by incorporating an image-based visual servo (IBVS) controller directly into the steering function used by a Rapidly Exploring Random Tree (RRT) planner. Our approach requires a number of extensions to traditional RRT-style planning. First, we derive a new sampling strategy that augments the usual state information by including image features that will be used by the IBVS control law. These augmented samples are then used by our new IBVS steering function, which simulates an IBVS control law to generate local trajectories that extend the current tree. These trajectories must be validated to ensure that they are collision-free and that all image features remain unoccluded and within the camera field of view throughout the local trajectory. We also provide a formal proof showing that the proposed approach is probabilistically complete. We have applied our approach to the problem of planning trajectories for three different systems: a robotic arm, an unmanned aerial vehicle (UAV) and a car-like robot, which are equipped with an IBVS control law. We explore performance trade-offs in the control design via simulation studies and demonstrate real-world effectiveness via experiments in which a small-scale car-like robot uses IBVS to navigate a track that includes a number of obstacles and potential occlusions. By exploring performance trade-offs, we mean that several elements, such as the metric used to identify nearest neighbors in the RRT and the steering method used to generate nodes, are tested and compared.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001641",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Astronomy",
      "Biology",
      "Computer science",
      "Computer vision",
      "Controller (irrigation)",
      "Economics",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Motion planning",
      "Physics",
      "Planner",
      "Robot",
      "Task (project management)",
      "Trajectory",
      "Tree (set theory)",
      "Visual servoing"
    ],
    "authors": [
      {
        "surname": "Reyes",
        "given_name": "Ramses"
      },
      {
        "surname": "Becerra",
        "given_name": "Israel"
      },
      {
        "surname": "Murrieta-Cid",
        "given_name": "Rafael"
      },
      {
        "surname": "Hutchinson",
        "given_name": "Seth"
      }
    ]
  },
  {
    "title": "A novel collaborative path planning algorithm for 3-wheel omnidirectional Autonomous Mobile Robot",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104527",
    "abstract": "Collaboration of multiple mobile robots becomes important in situations where collaborative tasks are required. For this purpose, a method including obstacle detection based on collaborative path planning of multiple Autonomous Mobile Robots (AMRs) has been developed. This study ensures the usability of collaborative omnidirectional AMRs technologies in various fields. In the study, novel path planning and obstacle avoidance algorithms are developed for collaborative mobile robots with omnidirectional mobility. Essentially, these algorithms include motion planning performed by obstacle avoidance with two identical 3-wheel omnidirectional mobile robots (TWOMR). Numerical calculations of the collaborative algorithm have been performed after the kinematic calculations, and tested algorithms developed for the proposed model. As a result, it has been observed that the path planning and obstacle avoidance algorithms developed for collaborative omnidirectional AMRs successfully follow the Master robot in the most efficient trajectory without collision and it has been observed that the developed method works with high accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001665",
    "keywords": [
      "Algorithm",
      "Antenna (radio)",
      "Artificial intelligence",
      "Classical mechanics",
      "Collision",
      "Collision avoidance",
      "Computer network",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Kinematics",
      "Law",
      "Mobile robot",
      "Motion planning",
      "Obstacle",
      "Obstacle avoidance",
      "Omnidirectional antenna",
      "Omnidirectional camera",
      "Path (computing)",
      "Physics",
      "Political science",
      "Robot",
      "Simulation",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Eyuboglu",
        "given_name": "Meltem"
      },
      {
        "surname": "Atali",
        "given_name": "Gokhan"
      }
    ]
  },
  {
    "title": "Perception-aware online trajectory generation for a prescribed manoeuvre of unmanned surface vehicle in cluttered unstructured environment",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104508",
    "abstract": "This paper proposes a perception-aware online trajectory generation system that facilitates prescribed manoeuvres of an unmanned surface vehicle (USV) in a dynamic unstructured environment. The proposed system is developed based on the principles of the inverse dynamics in the virtual domain (IDVD) method and an event-triggered receding horizon control (ETRHC) mechanism. This approach transforms the underlying nonconvex constrained optimization problem into a virtual space with a differentially flat dynamics and uses relatively few decision variables to prototype feasible quasi-optimal trajectories. The closed-loop configuration is provided by a computationally efficient ETRHC mechanism that uses situational awareness of operating environment to trigger trajectory replanning if/when required. This addresses the challenge of continuously updating a closed-loop trajectory which imposes unnecessary computational burden on a system with the limited onboard resources. To investigate the performance of the proposed trajectory generating system, a dynamic unstructured environment including variable and uncertain no-fly zone areas as well as variable current vector fields are modeled. Further, different operating conditions incorporating the uncertainties of environment and sudden failure on the USV propulsion system are introduced to examine the effectiveness, agility, and robustness of the proposed trajectory generating system. A comparative study with benchmark solutions generated by the hp-adaptive Radau pseudo-spectral method is conducted to provide a detailed statistical analysis of the proposed approach robustness, computational complexity, and effectiveness. The simulation results confirm the effectiveness of the proposed trajectory generator and ability to produce a solution for online realization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001471",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Gene",
      "Inverted pendulum",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Robustness (evolution)",
      "Trajectory",
      "Trajectory optimization"
    ],
    "authors": [
      {
        "surname": "Yazdani",
        "given_name": "Amirmehdi"
      },
      {
        "surname": "MahmoudZadeh",
        "given_name": "Somaiyeh"
      },
      {
        "surname": "Yakimenko",
        "given_name": "Oleg"
      },
      {
        "surname": "Wang",
        "given_name": "Hai"
      }
    ]
  },
  {
    "title": "Towards autonomous mapping in agriculture: A review of supportive technologies for ground robotics",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104514",
    "abstract": "This paper surveys the supportive technologies currently available for ground mobile robots used for autonomous mapping in agriculture. Unlike previous reviews, we describe state-of-the-art approaches and technologies aimed at extracting information from agricultural environments, not only for navigation purposes but especially for mapping and monitoring. The state-of-the-art platforms and sensors, the modern localization techniques, the navigation and path planning approaches, as well as the potentialities of artificial intelligence towards autonomous mapping in agriculture are analyzed. According to the findings of this review, many examples of recent mobile robots provide full navigation and autonomous mapping capability. Significant resources are currently devoted to this research area, in order to further improve mobile robot capabilities in this complex and challenging field.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001537",
    "keywords": [
      "Agriculture",
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Data science",
      "Ecology",
      "Engineering",
      "Field (mathematics)",
      "Human–computer interaction",
      "Mathematics",
      "Mobile robot",
      "Motion planning",
      "Precision agriculture",
      "Pure mathematics",
      "Robot",
      "Robotics",
      "State (computer science)",
      "Systems engineering"
    ],
    "authors": [
      {
        "surname": "Tiozzo Fasiolo",
        "given_name": "Diego"
      },
      {
        "surname": "Scalera",
        "given_name": "Lorenzo"
      },
      {
        "surname": "Maset",
        "given_name": "Eleonora"
      },
      {
        "surname": "Gasparetto",
        "given_name": "Alessandro"
      }
    ]
  },
  {
    "title": "Towards autonomous mapping in agriculture: A review of supportive technologies for ground robotics",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104514",
    "abstract": "This paper surveys the supportive technologies currently available for ground mobile robots used for autonomous mapping in agriculture. Unlike previous reviews, we describe state-of-the-art approaches and technologies aimed at extracting information from agricultural environments, not only for navigation purposes but especially for mapping and monitoring. The state-of-the-art platforms and sensors, the modern localization techniques, the navigation and path planning approaches, as well as the potentialities of artificial intelligence towards autonomous mapping in agriculture are analyzed. According to the findings of this review, many examples of recent mobile robots provide full navigation and autonomous mapping capability. Significant resources are currently devoted to this research area, in order to further improve mobile robot capabilities in this complex and challenging field.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001537",
    "keywords": [
      "Agriculture",
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Data science",
      "Ecology",
      "Engineering",
      "Field (mathematics)",
      "Human–computer interaction",
      "Mathematics",
      "Mobile robot",
      "Motion planning",
      "Precision agriculture",
      "Pure mathematics",
      "Robot",
      "Robotics",
      "State (computer science)",
      "Systems engineering"
    ],
    "authors": [
      {
        "surname": "Tiozzo Fasiolo",
        "given_name": "Diego"
      },
      {
        "surname": "Scalera",
        "given_name": "Lorenzo"
      },
      {
        "surname": "Maset",
        "given_name": "Eleonora"
      },
      {
        "surname": "Gasparetto",
        "given_name": "Alessandro"
      }
    ]
  },
  {
    "title": "A study of robotic search strategy for multi-radiation sources in unknown environments",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104529",
    "abstract": "This paper focuses on the multiple radiation source search problems, where the mobile robot identifies the number and parameters of sources online while exploring an unknown environment. The radiation superposition and the limited observations improve the difficulty of estimation, and the exploration trajectory is also associated with estimation. A novel search strategy based on receding horizon planning is proposed, which includes the observation, estimation, and exploration modules. The observation module filters and records the radiation intensity for estimation. In the estimation module, an adaptive differential evolution algorithm is integrated into the peak suppression particle filter to avoid the local optimum. The multi-source radiation gain model is conceived to determine the observation position in the exploration module. The strategy trades off exploration of unknown areas and exploitation of known radiation fields. The results of simulations and experiments demonstrate that the proposed strategy can identify the parameters and quantities of all sources in multi-modal radiation fields. Furthermore, our strategy exhibits superior performance in searching for multi-radiation sources in unknown environments compared with the boustrophedon path and the Next-Best-View planner.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001689",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Economics",
      "Finance",
      "Optics",
      "Physics",
      "Position (finance)",
      "Quantum mechanics",
      "Radiation",
      "Superposition principle",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Bai",
        "given_name": "Hua"
      },
      {
        "surname": "Gao",
        "given_name": "Wenrui"
      },
      {
        "surname": "Ma",
        "given_name": "Haofei"
      },
      {
        "surname": "Ding",
        "given_name": "Pengchao"
      },
      {
        "surname": "Wang",
        "given_name": "Gongcheng"
      },
      {
        "surname": "Xu",
        "given_name": "Wenda"
      },
      {
        "surname": "Wang",
        "given_name": "Weidong"
      },
      {
        "surname": "Du",
        "given_name": "Zhijiang"
      }
    ]
  },
  {
    "title": "Driving line-based two-stage path planning in the AGV sorting system",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104505",
    "abstract": "The path planning problem is the core issue in the automatic guided vehicle (AGV) sorting system. The current AGV sorting system has the following characteristics: (1) a great number of AGVs; (2) dynamic sorting of tasks; and (3) two-stage tasks involving transporting express packages and then leaving the sorting area. Therefore, existing path planning methods face challenges in terms of achieving timeliness and optimality. In this paper, the path planning problem of the AGV sorting system in a mesh topology area is modeled. A Driving Line-based Two-Stage (DLTS) path planning algorithm is proposed. First, to avoid conflicts among AGVs with different driving directions, time–space resources are divided according to the driving line mechanism, which specifies the driving direction, possible planned locations and specific driving rules. Second, we propose an incremental search method to plan continuous paths for two-stage tasks while simultaneously avoiding conflicts among AGVs moving in the same direction. Finally, we verify the effectiveness of our method in terms of real-time and optimal performance through simulation experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001446",
    "keywords": [
      "Algorithm",
      "Archaeology",
      "Artificial intelligence",
      "Automated guided vehicle",
      "Computer science",
      "Geometry",
      "History",
      "Line (geometry)",
      "Mathematics",
      "Motion planning",
      "Path (computing)",
      "Plan (archaeology)",
      "Programming language",
      "Real-time computing",
      "Robot",
      "Simulation",
      "Sorting"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Ke"
      },
      {
        "surname": "Liang",
        "given_name": "Wei"
      },
      {
        "surname": "Shi",
        "given_name": "Huaguang"
      },
      {
        "surname": "Zhang",
        "given_name": "Jialin"
      },
      {
        "surname": "Wang",
        "given_name": "Qi"
      }
    ]
  },
  {
    "title": "Real-time terrain anomaly perception for safe robot locomotion using a digital double framework",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104512",
    "abstract": "Digital twinning systems are effective tools to test and develop new robotic capabilities before applying them in the real world. This work presents a real-time digital double framework that improves and facilitates robot perception of the environment. Soft or non-rigid terrains can cause locomotion failures, while visual perception alone is often insufficient to assess the physical properties of such surfaces. To tackle this problem we employ the proposed framework to estimate ground collapsibility through physical interactions while the robot is dynamically walking on challenging terrains. We extract discrepancy information between the two systems, a simulated digital double that is synchronized with a real robot, both using exactly the same physical model and locomotion controller. The discrepancy in sensor measurements between the real robot and its digital double serves as a critical indicator of anomalies between expected and actual motion and is utilized as input to a learning-based model for terrain collapsibility analysis. The performance of the collapsibility estimation was evaluated in a variety of real-world scenarios involving flat, inclined, elevated, and outdoor terrains. Our results demonstrate the generality and efficacy of our real-time digital double architecture for estimating terrain collapsibility.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001513",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Controller (irrigation)",
      "Ecology",
      "Generality",
      "Neuroscience",
      "Perception",
      "Psychology",
      "Psychotherapist",
      "Real-time computing",
      "Robot",
      "Simulation",
      "Terrain"
    ],
    "authors": [
      {
        "surname": "Haddeler",
        "given_name": "Garen"
      },
      {
        "surname": "Palanivelu",
        "given_name": "Hari P."
      },
      {
        "surname": "Colonnier",
        "given_name": "Fabien"
      },
      {
        "surname": "Ng",
        "given_name": "Yung Chuen"
      },
      {
        "surname": "Adiwahono",
        "given_name": "Albertus H."
      },
      {
        "surname": "Li",
        "given_name": "Zhibin"
      },
      {
        "surname": "Chew",
        "given_name": "Chee-Meng"
      },
      {
        "surname": "Chuah",
        "given_name": "Meng Yee Michael"
      }
    ]
  },
  {
    "title": "Flattening and folding towels with a single-arm robot based on reinforcement learning",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104506",
    "abstract": "Robots can learn how to complete a variety of tasks without explicit instructions thanks to reinforcement learning. In this work, a piece of cloth is placed on a table and manipulated using a single-arm robot. We consider 2 forms of manipulation: flattening a crumpled towel and folding a flat one. To learn a policy that will allow the robot to select the optimum course of action based on observations of the environment, we construct a simulation environment using a gripper and a piece of cloth. After that, the policy is applied to a real robot and put to the test. Additionally, we present our method for identifying the corners of a garment using computer vision, which includes a comparison between a traditional computer vision approach with a deep learning one. We use an ABB robot and a 2D camera for the experiments and PyBullet software for the simulation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001458",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Construct (python library)",
      "Data mining",
      "Engineering",
      "Flattening",
      "Folding (DSP implementation)",
      "Mechanical engineering",
      "Mobile robot",
      "Programming language",
      "Reinforcement learning",
      "Robot",
      "Robot learning",
      "Software",
      "Structural engineering",
      "Table (database)",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Shehawy",
        "given_name": "Hassan"
      },
      {
        "surname": "Pareyson",
        "given_name": "Daniele"
      },
      {
        "surname": "Caruso",
        "given_name": "Virginia"
      },
      {
        "surname": "De Bernardi",
        "given_name": "Stefano"
      },
      {
        "surname": "Zanchettin",
        "given_name": "Andrea Maria"
      },
      {
        "surname": "Rocco",
        "given_name": "Paolo"
      }
    ]
  },
  {
    "title": "Performance analysis of buck converter with fractional PID controller using hybrid technique",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104515",
    "abstract": "In this paper, a hybrid technique is proposed for analyzing the performance of buck converters with fractional-order proportional integral derivative (FOPID) controllers. The hybrid approach is a combination of Capuchin Search Algorithm (CapSA) and Golden Jackal Optimization (GJO). The update behavior of Golden Jackal Optimization2 is enhanced with Capuchin Search Algorithm (CapSA) therefore it is called the improved GJO (IGJO) technique. The power converters are hard to manage based on their nonlinear nature and therefore the search for smart and effectual controllers is ongoing and continual. In current years, fractional order controllers have shown greater efficiency in power electronic systems. The IGJO technique is used to establish the optimum design of a fractional-order proportional integral derivative (PID) controller for the buck converter. The FOPID controller parameters are considered to diminish several performance metrics, with a particular focus on the Integral Squared Error (ISE). The proposed method is performed in the MATLAB, and its execution is analyzed by using the existing methods. From the simulation result, the proposed method reduces the error more effectively than existing methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001549",
    "keywords": [
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Biology",
      "Buck converter",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Converters",
      "Engineering",
      "Fractional calculus",
      "MATLAB",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "PID controller",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Temperature control"
    ],
    "authors": [
      {
        "surname": "Sangeetha",
        "given_name": "S."
      },
      {
        "surname": "Revathi",
        "given_name": "B. Sri"
      },
      {
        "surname": "Balamurugan",
        "given_name": "K."
      },
      {
        "surname": "G.",
        "given_name": "Suresh"
      }
    ]
  },
  {
    "title": "A framework to integrate mobile manipulators as cyber–physical systems into existing production systems in the context of industry 4.0",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104526",
    "abstract": "With the emergence of the Cyber–Physical Systems (CPSs) along with the fourth industrial revolution, the discussion of distributed architecture and coordination and extensive communication between all components of a system was raised. On the other hand, Modern industrial manufacturing relies heavily on flexible production. Autonomous mobile manipulators (MMs) have the potential to improve the flexibility of existing manufacturing environments. With the advantages associated with this technology, there is an upsurge in the demand for MMs. Thus, adding a new MM as a new CPS into a system following industry 4.0 requires a framework to help taking all the advantages from it. In this article, we proposed a framework to integrating MMs as CPSs into an existing production system. This integration requires comprehensive knowledge of the existing production process and control, which is a view to improve the performance of the existing production systems via new functionalities due to MMs. The next step of the framework is to make new MM operations compatible with the existing production control system. For this purpose, we define different parametric blocks to perform new operations and thus contribute to making the production line more autonomous. Considering all of these issues simultaneously is necessary for an efficient integration in smart production context. For a successful integration, we presented four principal dimensions of integration: Physical integration, communicational integration, functional and operational integration, and digital integration. Furthermore, the framework has been applied to a research production line called Platform 4.0 at Arts et Métiers. An MM from OMRON Company (called MoMa) has been integrated into the existing production system. Results from this real-world demonstration show that MoMa is capable of successfully increasing flexibility, autonomy, and efficiency of a production system using command signals from Manufacturing Execution System (MES).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001653",
    "keywords": [
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Cyber-physical system",
      "Economics",
      "Embedded system",
      "Engineering",
      "Flexibility (engineering)",
      "Industry 4.0",
      "Macroeconomics",
      "Manufacturing engineering",
      "Mathematics",
      "Mechanical engineering",
      "Operating system",
      "Paleontology",
      "Production (economics)",
      "Production line",
      "Statistics",
      "System integration",
      "Systems engineering"
    ],
    "authors": [
      {
        "surname": "Ghodsian",
        "given_name": "Nooshin"
      },
      {
        "surname": "Benfriha",
        "given_name": "Khaled"
      },
      {
        "surname": "Olabi",
        "given_name": "Adel"
      },
      {
        "surname": "Gopinath",
        "given_name": "Varun"
      },
      {
        "surname": "Talhi",
        "given_name": "Esma"
      },
      {
        "surname": "Hof",
        "given_name": "Lucas A."
      },
      {
        "surname": "Arnou",
        "given_name": "Aurélien"
      }
    ]
  },
  {
    "title": "Humanoid motion generation in a world of stairs",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104495",
    "abstract": "Consider the problem of generating humanoid motions in an environment consisting of horizontal patches located at different heights (world of stairs). To this end, the paper proposes an integrated scheme which combines footstep planning and gait generation. In particular, footsteps are produced by a randomized algorithm that guarantees both feasibility and quality of the plan according to a chosen criterion; whereas for 3D gait generation we devise an ad hoc extension of the Intrinsically Stable MPC scheme. In its basic form, the proposed scheme addresses the off-line case (known environments), but a sensor-based adaptation is developed for the on-line case (unknown environments) based on an anytime version of the footstep planner. In order to validate the proposed approach, we present simulations in CoppeliaSim for the HRP-4 humanoid robot navigating scenarios of different complexity, both in the on-line and off-line case.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001343",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Biology",
      "Civil engineering",
      "Computer science",
      "Computer vision",
      "Engineering",
      "Gait",
      "Geometry",
      "Humanoid robot",
      "Line (geometry)",
      "Mathematical analysis",
      "Mathematics",
      "Optics",
      "Physics",
      "Physiology",
      "Real-time computing",
      "Robot",
      "Scheme (mathematics)",
      "Simulation",
      "Stairs"
    ],
    "authors": [
      {
        "surname": "Cipriano",
        "given_name": "Michele"
      },
      {
        "surname": "Ferrari",
        "given_name": "Paolo"
      },
      {
        "surname": "Scianca",
        "given_name": "Nicola"
      },
      {
        "surname": "Lanari",
        "given_name": "Leonardo"
      },
      {
        "surname": "Oriolo",
        "given_name": "Giuseppe"
      }
    ]
  },
  {
    "title": "YOLOPose V2: Understanding and improving transformer-based 6D pose estimation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104490",
    "abstract": "6D object pose estimation is a crucial prerequisite for autonomous robot manipulation applications. The state-of-the-art models for pose estimation are convolutional neural network (CNN)-based. Lately, Transformers, an architecture originally proposed for natural language processing, is achieving state-of-the-art results in many computer vision tasks as well. Equipped with the multi-head self-attention mechanism, Transformers enable simple single-stage end-to-end architectures for learning object detection and 6D object pose estimation jointly. In this work, we propose YOLOPose (short form for You Only Look Once Pose estimation), a Transformer-based multi-object 6D pose estimation method based on keypoint regression and an improved variant of the YOLOPose model. In contrast to the standard heatmaps for predicting keypoints in an image, we directly regress the keypoints. Additionally, we employ a learnable orientation estimation module to predict the orientation from the keypoints. Along with a separate translation estimation module, our model is end-to-end differentiable. Our method is suitable for real-time applications and achieves results comparable to state-of-the-art methods. We analyze the role of object queries in our architecture and reveal that the object queries specialize in detecting objects in specific image regions. Furthermore, we quantify the accuracy trade-off of using datasets of smaller sizes to train our model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902300129X",
    "keywords": [
      "3D pose estimation",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Geometry",
      "Machine learning",
      "Mathematics",
      "Object detection",
      "Orientation (vector space)",
      "Pattern recognition (psychology)",
      "Physics",
      "Pose",
      "Preprocessor",
      "Quantum mechanics",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Periyasamy",
        "given_name": "Arul Selvam"
      },
      {
        "surname": "Amini",
        "given_name": "Arash"
      },
      {
        "surname": "Tsaturyan",
        "given_name": "Vladimir"
      },
      {
        "surname": "Behnke",
        "given_name": "Sven"
      }
    ]
  },
  {
    "title": "A multi-locomotion clustered tensegrity mobile robot with fewer actuators",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104504",
    "abstract": "Mobile robots with multi locomotion modes have excellent terrain adaptability. However, traditional multi-locomotion mobile robots are usually actuated by a large number of motors, making their structures heavy and bulky. As a result, the controls become complex, the load-to-mass ratio is low, and the energy consumption is high. Inspired by the bio-mechanism of worms, a novel tensegrity-based multi-locomotion mobile robot, named TJUBot, has been designed. It is actuated by only two motors, yet it has the potential to realize three locomotion modes: earthworm-like, inchworm-like, and tumbling locomotion. The design of these three locomotion modes has been implemented based on kinematic and dynamic models, and the driving law of the two motors under each locomotion mode has been established. Notably, the robot’s locomotion has been analyzed under five different terrains. A laboratory prototype of TJUBot has been developed, and experiments demonstrate that the robot can adjust to five types of terrains using the three locomotion modes. For instance, on flat ground, it achieves a maximum velocity of 2.34 BL/min, and it can pass through confined spaces with a minimum height of 1.26 BH. Moreover, the robot can climb slopes with a maximum angle of 7°, overcome obstacles with a maximum height of 0.52 BH, and traverse gaps with a maximum width as 0.35 BL. Herein, BL and BH represent the body length and body height of the robot, respectively. In addition, TJUBot exhibits outstanding performance in terms of its load-to-mass ratio, which is measured at 5.56, and its low energy consumption of 0.69J/m, as observed in experiments. The promising results obtained from these experiments indicate that TJUBot holds significant potential for applications in multi-terrain environments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001434",
    "keywords": [
      "Actuator",
      "Aerospace engineering",
      "Anatomy",
      "Artificial intelligence",
      "Biology",
      "Classical mechanics",
      "Climb",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Crawling",
      "Ecology",
      "Engineering",
      "Geodesy",
      "Geography",
      "Kinematics",
      "Mechanism (biology)",
      "Medicine",
      "Mobile robot",
      "Physics",
      "Quantum mechanics",
      "Robot",
      "Robot control",
      "Robot locomotion",
      "Simulation",
      "Structural engineering",
      "Tensegrity",
      "Terrain",
      "Traverse"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Qi"
      },
      {
        "surname": "Liu",
        "given_name": "Xinyu"
      },
      {
        "surname": "Wang",
        "given_name": "Panfeng"
      },
      {
        "surname": "Song",
        "given_name": "Yimin"
      },
      {
        "surname": "Sun",
        "given_name": "Tao"
      }
    ]
  },
  {
    "title": "LSVL: Large-scale season-invariant visual localization for UAVs",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104497",
    "abstract": "Localization of autonomous unmanned aerial vehicles (UAVs) relies heavily on Global Navigation Satellite Systems (GNSS), which are susceptible to interference. Especially in security applications, robust localization algorithms independent of GNSS are needed to provide dependable operations of autonomous UAVs also in interfered conditions. Typical non-GNSS visual localization approaches rely on known starting pose, work only on a small-sized map, or require known flight paths before a mission starts. We consider the problem of localization with no information on initial pose or planned flight path. We propose a solution for global visual localization on large maps, based on matching orthoprojected UAV images to satellite imagery using learned season-invariant descriptors, and test with environment sizes up to 100 km 2 . We show that the method is able to determine heading, latitude and longitude of the UAV at 12.6–18.7 m lateral translation error in as few as 23.2–44.4 updates from an uninformed initialization, also in situations of significant seasonal appearance difference (winter–summer) between the UAV image and the map. We evaluate the characteristics of multiple neural network architectures for generating the descriptors, and likelihood estimation methods that are able to provide fast convergence and low localization error. We also evaluate the operation of the algorithm using real UAV data and evaluate running time on a real-time embedded platform. We believe this is the first work that is able to recover the pose of an UAV at this scale and rate of convergence, while allowing significant seasonal difference between camera observations and map.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001367",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "GNSS applications",
      "Global Positioning System",
      "Initialization",
      "Programming language",
      "Real-time computing",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Kinnari",
        "given_name": "Jouko"
      },
      {
        "surname": "Renzulli",
        "given_name": "Riccardo"
      },
      {
        "surname": "Verdoja",
        "given_name": "Francesco"
      },
      {
        "surname": "Kyrki",
        "given_name": "Ville"
      }
    ]
  },
  {
    "title": "Feedback control of millimeter scale pivot walkers using magnetic actuation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104496",
    "abstract": "An external magnetic field can be used to remotely control small-scaled robots, making them promising candidates for diverse biomedical and engineering applications. In a previous study, we showed that our magnetically actuated millirobot is highly agile and can perform a variety of locomotive tasks such as pivot walking, tumbling, and tapping in a horizontal plane. In this study, we focus on controlling the locomotion outcomes of this millirobot in the pivot walking mode. A mathematical model of the system is developed and the kinematic model is derived. The role of the sweep and tilt angles in the robot’s motion is also investigated. We study two controllers to regulate the gait of the pivot walker. The first one is a proportional-geometric-based controller, which determines the correct pivot point that the millirobot should use. Then, it regulates the angular velocity proportionally based on the error between the center of the millirobot and the reference trajectory. The second controller is based on a gradient descent optimization technique, which expresses the control action as an optimization problem. These control algorithms enable the millirobot to generate a stable gait while tracking the desired trajectory. A low-cost high-performance magnetic actuator is built to validate the proposed controllers. We conduct a set of different experiments and simulation runs to establish the effectiveness of proposed controllers for different sweep and tilt angles in terms of tracking error. The two controllers exhibit an appropriate performance, but it is observed that the gradient descent-based controller yields faster convergence time, smaller tracking error, and fewer number of steps. Finally, we perform an extensive experimentally parametric analysis of the effect of sweep and tilt angles and step time on the tracking error. As we expect, the optimization-based controller outperforms the geometric-based one.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001355",
    "keywords": [
      "Actuator",
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Biology",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Gradient descent",
      "Kinematics",
      "Physics",
      "Robot",
      "Simulation",
      "Tracking error",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Al Khatib",
        "given_name": "Ehab"
      },
      {
        "surname": "Razzaghi",
        "given_name": "Pouria"
      },
      {
        "surname": "Hurmuzlu",
        "given_name": "Yildirim"
      }
    ]
  },
  {
    "title": "From the desks of ROS maintainers: A survey of modern & capable mobile robotics algorithms in the robot operating system 2",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104493",
    "abstract": "The Robot Operating System 2 (ROS 2) is rapidly impacting the intelligent machines sector — on space missions, large agriculture equipment, multi-robot fleets, and more. Its success derives from its focused design and improved capabilities targeting product-grade and modern robotic systems. Following ROS 2’s example, the mobile robotics ecosystem has been fully redesigned based on the transformed needs of modern robots and is experiencing active development not seen since its inception. This paper comes from the desks of the key ROS Navigation maintainers to review and analyze the state of the art of robotics navigation in ROS 2. This includes new systems without parallel in ROS 1 or other similar mobile robotics frameworks. We discuss current research products and historically robust methods that provide differing behaviors and support for most every robot type. This survey consists of overviews, comparisons, and expert insights organized by the fundamental problems in the field. Some of these implementations have yet to be described in literature and many have not been benchmarked relative to others. We end by providing a glimpse into the future of the ROS 2 mobile robotics ecosystem.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902300132X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Human–computer interaction",
      "Mobile robot",
      "Robot",
      "Robotics",
      "Simulation"
    ],
    "authors": [
      {
        "surname": "Macenski",
        "given_name": "Steve"
      },
      {
        "surname": "Moore",
        "given_name": "Tom"
      },
      {
        "surname": "Lu",
        "given_name": "David V."
      },
      {
        "surname": "Merzlyakov",
        "given_name": "Alexey"
      },
      {
        "surname": "Ferguson",
        "given_name": "Michael"
      }
    ]
  },
  {
    "title": "Optimization techniques for Multi-Robot Task Allocation problems: Review on the state-of-the-art",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104492",
    "abstract": "In the last years, Multi-Robot Systems (MRS) have experienced considerable recognition due to various possible real-world applications. Multi-Robot Task Allocation (MRTA) is among the most interesting MRS problems. This problem concerns the situation when a set of given tasks must be performed by a team of mobile robots with the intention of optimizing an objective function (e.g., minimizing the mission time). This paper aims to present MRTA applications and categorizes methods into market-based, behavior-based, and optimization-based approaches. The paper focus on the latter and review several works in order to point out their advantages and limitations and to identify possible future research opportunities. Furthermore, a statistical analysis is provided to identify the most used methods and the evolution of the topic over the years.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001318",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Economics",
      "Engineering",
      "Evolutionary biology",
      "Focus (optics)",
      "Function (biology)",
      "Geometry",
      "Human–computer interaction",
      "Management science",
      "Mathematics",
      "Mobile robot",
      "Operations research",
      "Optics",
      "Physics",
      "Point (geometry)",
      "Programming language",
      "Robot",
      "Set (abstract data type)",
      "State (computer science)",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Chakraa",
        "given_name": "Hamza"
      },
      {
        "surname": "Guérin",
        "given_name": "François"
      },
      {
        "surname": "Leclercq",
        "given_name": "Edouard"
      },
      {
        "surname": "Lefebvre",
        "given_name": "Dimitri"
      }
    ]
  },
  {
    "title": "Probabilistic motion planning for non-Euclidean and multi-vehicle problems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104487",
    "abstract": "Trajectory planning tasks for non-holonomic or collaborative systems are naturally modeled by state spaces with non-Euclidean metrics. However, existing proofs of convergence for sample-based motion planners only consider the setting of Euclidean state spaces. We resolve this issue by formulating a flexible framework and set of assumptions for which the widely-used PRM*, RRT, and RRT* algorithms remain asymptotically optimal in the non-Euclidean setting. The framework is compatible with collaborative trajectory planning: given a fleet of robotic systems that individually satisfy our assumptions, we show that the corresponding collaborative system again satisfies the assumptions and therefore has guaranteed convergence for the trajectory-finding methods. Our joint state space construction builds in a coupling parameter 1 ≤ p ≤ ∞ , which interpolates between a preference for minimizing total energy at one extreme and a preference for minimizing the travel time at the opposite extreme. We illustrate our theory with trajectory planning for simple coupled systems, fleets of Reeds–Shepp vehicles, and a highly non-Euclidean fractal space.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001264",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Euclidean distance",
      "Euclidean geometry",
      "Euclidean space",
      "Geometry",
      "Holonomic",
      "Mathematical optimization",
      "Mathematical proof",
      "Mathematics",
      "Motion planning",
      "Physics",
      "Probabilistic logic",
      "Pure mathematics",
      "Robot",
      "State space",
      "Statistics",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Lukyanenko",
        "given_name": "Anton"
      },
      {
        "surname": "Soudbakhsh",
        "given_name": "Damoon"
      }
    ]
  },
  {
    "title": "RGB-D-based categorical object pose and shape estimation: Methods, datasets, and evaluation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104507",
    "abstract": "Recently, various methods for 6D pose and shape estimation of objects at a per-category level have been proposed. This work provides an overview of the field in terms of methods, datasets, and evaluation protocols. First, an overview of existing works and their commonalities and differences is provided. Second, we take a critical look at the predominant evaluation protocol, including metrics and datasets. Based on the findings, we propose a new set of metrics, contribute new annotations for the Redwood dataset, and evaluate state-of-the-art methods in a fair comparison. The results indicate that existing methods do not generalize well to unconstrained orientations and are actually heavily biased towards objects being upright. We provide an easy-to-use evaluation toolbox with well-defined metrics, methods, and dataset interfaces, which allows evaluation and comparison with various state-of-the-art approaches (https://github.com/roym899/pose_and_shape_evaluation).",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902300146X",
    "keywords": [
      "Alternative medicine",
      "Artificial intelligence",
      "Categorical variable",
      "Computer science",
      "Data mining",
      "Field (mathematics)",
      "Machine learning",
      "Mathematics",
      "Medicine",
      "Object (grammar)",
      "Pathology",
      "Pose",
      "Programming language",
      "Protocol (science)",
      "Pure mathematics",
      "Set (abstract data type)",
      "Toolbox"
    ],
    "authors": [
      {
        "surname": "Bruns",
        "given_name": "Leonard"
      },
      {
        "surname": "Jensfelt",
        "given_name": "Patric"
      }
    ]
  },
  {
    "title": "Traversability analysis for off-road environments using locomotion experiments and earth observation data",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104494",
    "abstract": "In recent years, the navigation capabilities of mobile robots in off-road environments have increased significantly, opening up new potential applications in a variety of settings. By accurately identifying different types of terrain in unstructured environments, safe automated navigation can be supported. However, to enable safe path planning and execution, the traversability costs of the terrain types need to be accurately estimated. Such estimations are often performed manually by experts who possess information about the environment and are familiar with the capabilities of the robotic system or using simplified experiments. In this paper, we present an automated pipeline for generating traversability costs that use recorded locomotion data from a realistic experiment and descriptive information on the terrain obtained from earth observation data. The main contribution is that the cost estimation for different terrain types is based on locomotion data obtained in realistic standardized experiments. Moreover, by repeating the experiments with different robot systems we are easily able to reflect the actual capabilities of the systems. Experiments were conducted in an alpine off-road environment to record locomotion data of four different robot systems and to investigate the performance and validity of the proposed pipeline. The recorded locomotion data for the different robots are publicly available at https://robonav.ist.tugraz.at/data/",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001331",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Ecology",
      "Mobile robot",
      "Motion planning",
      "Pipeline (software)",
      "Programming language",
      "Real-time computing",
      "Robot",
      "Simulation",
      "Terrain",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Eder",
        "given_name": "Matthias"
      },
      {
        "surname": "Prinz",
        "given_name": "Raphael"
      },
      {
        "surname": "Schöggl",
        "given_name": "Florian"
      },
      {
        "surname": "Steinbauer-Wagner",
        "given_name": "Gerald"
      }
    ]
  },
  {
    "title": "A fast and accurate compound collision detector for RRT motion planning",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104484",
    "abstract": "The application of artificial intelligence tools has led to newly developed collision detectors which have better computational efficiency than the kinematics-and-geometry based collision detectors (KCD) to improve robot motion planning strategies. However, new detectors are not very accurate in some cases. To improve the accuracy, a trade-off between efficiency and accuracy is required. We propose a novel compound collision detector (CCD) for collision queries that modifies the planners of rapidly-exploring random tree (RRT) to improve the classical probabilistic collision detector (PCD). It is composed of an exact collision detector (ECD), an inference collision detector (ICD) and a strategy to determine ECD or ICD based on some conditions. In our CCD, we use a sphere-ellipsoidal pseudo distance (SEPD) in the determination strategy to alleviate the problem of highly-frequent outputs of false-positive in narrow passages of PCD, and a node based bounding method (NBB) to increase the speed of data storage and loading for the sub-algorithm ICD. Experiments on a Kinova Jaco assistive robotic arm are taken to evaluate the performance of our CCD, which show an improved accuracy with a small reduction of speed in comparison with PCD. So, it is a promising tool in robot motion planning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001239",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Bounding overwatch",
      "Classical mechanics",
      "Collision",
      "Collision avoidance",
      "Collision detection",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Detector",
      "Geometry",
      "Kinematics",
      "Mathematics",
      "Motion (physics)",
      "Node (physics)",
      "Physics",
      "Quantum mechanics",
      "Reduction (mathematics)",
      "Robot",
      "Simulation",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Shangliang"
      },
      {
        "surname": "Liu",
        "given_name": "Guangyu"
      },
      {
        "surname": "Zhang",
        "given_name": "Yanxin"
      },
      {
        "surname": "Xue",
        "given_name": "Anke"
      }
    ]
  },
  {
    "title": "A deep multi-agent reinforcement learning framework for autonomous aerial navigation to grasping points on loads",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104489",
    "abstract": "Deep reinforcement learning, by taking advantage of neural networks, has made great strides in the continuous control of robots. However, in scenarios where multiple robots are required to collaborate with each other to accomplish a task, it is still challenging to build an efficient and scalable multi-agent control system due to increasing complexity. In this paper, we regard each unmanned aerial vehicle (UAV) with its manipulator as one agent, and leverage the power of multi-agent deep deterministic policy gradient (MADDPG) for the cooperative navigation and manipulation of a load. We propose solutions for addressing navigation to grasping point problem in targeted and flexible scenarios, and mainly focus on how to develop model-free policies for the UAVs without relying on a trajectory planner. To overcome the challenges of learning in scenarios with an increasing number of grasping points, we incorporate the demonstrations from an Optimal Reciprocal Collision Avoidance (ORCA) algorithm into our framework to guide the policy training and adapt two novel techniques into the architecture of MADDPG. Furthermore, curriculum learning with the attention mechanism is utilized by reusing knowledge from fewer grasping points to facilitate the training of a load with more points. Our experiments were validated by a load with three, four and six grasping points respectively in Coppeliasim simulator and then transferred into the real world with Crazyflie quadrotors. Our results show that the average tracking deviations from the desirable grasping point to the final position of the UAV can be less than 10 cm in some real-world experiments. Compared with state-of-the-art model-free reinforcement learning and swarm optimization algorithms, results show that our proposed methods outperform other baselines with a reasonable success rate especially in the scenarios with more grasping points. Furthermore, the learned optimal policies enable UAVs to reach and hover over all the grasping points before manipulation without any collision. We conducted a comprehensive analysis of both targeted and flexible navigation, highlighting their respective advantages and disadvantages.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001288",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Database",
      "Deep learning",
      "Geometry",
      "Leverage (statistics)",
      "Mathematics",
      "Physics",
      "Planner",
      "Point (geometry)",
      "Reinforcement learning",
      "Robot",
      "Scalability",
      "Simulation",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Jingyu"
      },
      {
        "surname": "Ma",
        "given_name": "Ruidong"
      },
      {
        "surname": "Oyekan",
        "given_name": "John"
      }
    ]
  },
  {
    "title": "Adaptive legged manipulation: Versatile disturbance predictive control for quadruped robots with robotic arms",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104468",
    "abstract": "Equipping a legged robot with a manipulator enables versatile mobile manipulation, significantly improving its performance in various tasks. However, developing a unified framework for diverse robotic arms and legged robots presents a challenge. This study proposes a disturbance predictive control framework where a high-level estimator cooperates with a disturbance-based low-level controller. Further, a transportable latent dynamic adapter is introduced to enable the model to migrate rapidly to different robotic arms. Our method can adapt well to other manipulators with a few samples. Further, the effectiveness of our method was demonstrated via simulation and real experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001070",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Disturbance (geology)",
      "Engineering",
      "Estimator",
      "Mathematics",
      "Mobile robot",
      "Model predictive control",
      "Paleontology",
      "Robot",
      "Simulation",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Yao",
        "given_name": "Qingfeng"
      },
      {
        "surname": "Wang",
        "given_name": "Cong"
      },
      {
        "surname": "Wang",
        "given_name": "Jilong"
      },
      {
        "surname": "Meng",
        "given_name": "Linghan"
      },
      {
        "surname": "Yang",
        "given_name": "Shuyu"
      },
      {
        "surname": "Zhang",
        "given_name": "Qifeng"
      },
      {
        "surname": "Wang",
        "given_name": "Donglin"
      }
    ]
  },
  {
    "title": "Bimanual dynamic grabbing and tossing of objects onto a moving target",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104481",
    "abstract": "Bimanual grabbing and tossing of packages onto trays or conveyor belts remains a human activity in the industry. For robots, such a dynamic task requires coordination between two arms and fast adaptation abilities when the tossing target is moving and subject to perturbations. Thus, this paper proposes a control framework that enables a bimanual robotic system to grab and toss objects onto a moving target. We develop a mixed learning-optimization method that computes the tossing parameters necessary to achieve accurate tossing tasks. Hence, we learn an inverse throwing map (a closed-form solution of the inverse non-linear throwing problem) that provides minimum release velocities of the object for given relative release positions. This map is embedded into a kinematics-based bi-level optimization that determines the associated feasible release states (positions and velocities) of the dual-arm robot. Additionally, we propose a closed-form modeling approach of the robot’s tossable workspace (set of all positions reachable by an object if tossed by the robot) and use the model to predict intercept or landing locations that yield high probabilities of task success. Furthermore, we employ dynamical systems to generate the coordinated motion of the dual-arm system and design an adaptation strategy to ensure robustness of the interception in the face of target’s perturbations in speed or location. Finally, we validate experimentally the framework on two 7-DoF robotic arms. We demonstrate the accuracy and robustness of the proposed approach. We also show its speed and energy advantages when compared to the traditional pick-and-place strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001203",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Classical mechanics",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Gene",
      "Inverse kinematics",
      "Kinematics",
      "Physics",
      "Robot",
      "Robotic arm",
      "Robustness (evolution)",
      "Simulation",
      "Workspace"
    ],
    "authors": [
      {
        "surname": "Bombile",
        "given_name": "Michael"
      },
      {
        "surname": "Billard",
        "given_name": "Aude"
      }
    ]
  },
  {
    "title": "Multi-agent planning and coordination for automated aircraft ground handling",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104480",
    "abstract": "Inspired by the vision of fully autonomous airside operations at Schiphol airport, this study aims to contribute to the short-term goal of automated aircraft ground handling. In this research, we design and evaluate a multi-agent system for planning of automated ground handling. There are two main components in the system: task allocation optimization and multi-agent path planning. To allocate tasks to ground support equipment (GSE) vehicles, an auction mechanism inspired by temporal sequential single item (TeSSI) auction is proposed. Ground handling tasks scheduling for GSE vehicles is modeled as several single-vehicle pickup and delivery optimization problems (SPDP), and the values of the objective functions are used to generate bids for GSE vehicle agents in the auction. Prioritized safe interval path planning for large agents (LA-SIPP) is used to plan collision-free paths for GSE vehicle agents in the model to execute tasks. The aim is to increase the success rates of allocating tasks and finding collision free paths without causing flight delays, given the limited resources such as a small number of available GSE vehicles, time windows constraints and conflicting interests of different agents. Due to the results, even for the instances with frequent flights and the most limited resources, the success rates of allocation and path planning were higher than 81% and 98%, respectively. Furthermore, periodic task allocation and path planning of the ground handling tasks for flights in three aircraft stands during a planning time window of the day, as well as replanning in case of disruptions were performed in a short CPU time. There is a lack of research dealing with the complete process of ground handling, since existing studies concerning the automation of ground handling operations involve fleet assignment or task scheduling models without an integration of detailed path planning. Our main contribution is to present a framework that combines task allocation and path planning for automation of ground handling operations and provides solutions using a multi-agent perspective.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001197",
    "keywords": [
      "Artificial intelligence",
      "Collision",
      "Collision avoidance",
      "Computer science",
      "Computer security",
      "Engineering",
      "Motion planning",
      "Operations management",
      "Operations research",
      "Real-time computing",
      "Robot",
      "Scheduling (production processes)",
      "Simulation",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Szu-Tung"
      },
      {
        "surname": "Ermiş",
        "given_name": "Gülçin"
      },
      {
        "surname": "Sharpanskykh",
        "given_name": "Alexei"
      }
    ]
  },
  {
    "title": "A fuzzy logic-based stabilization system for a flying robot, with an embedded energy harvester and a visual decision-making system",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104471",
    "abstract": "“Smart cities” is a popular concept in modern urban development that demands innovative solutions to enhance various aspects of our lives. This paper introduces a novel application that aims to improve public road maintenance by utilizing a flying robot to repaint partially erased sections of the sidewalks’ edges that are typically marked with black and white colors. The first contribution of this paper is the development of a fuzzy-logic-based stabilization system for an octocopter, which can serve as a liquids transporter and be equipped with a robot arm. The second contribution is the design of an embedded energy harvester for the flying robot, which optimizes the management of available power sources. Additionally, this project includes a complementary heuristic study that clarifies fundamental concepts related to a computer vision-based decision-making system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001100",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Energy (signal processing)",
      "Fuzzy logic",
      "Heuristic",
      "Human–computer interaction",
      "Mathematics",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Robot",
      "Simulation",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Baba",
        "given_name": "Abdullatif"
      },
      {
        "surname": "Alothman",
        "given_name": "Basil"
      }
    ]
  },
  {
    "title": "Modeling variability in self-adapting robotic systems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104470",
    "abstract": "Autonomous robots operating in everyday environments, such as hospitals, private houses, and public roads, are context-aware self-adaptive systems, i.e. they exploit knowledge about their resources and the environment to trigger runtime adaptation, so that they exhibit a behavior adequate to the current context. For these systems, context-aware self-adaptation requires to design the robot control application as a dynamically reconfigurable software architecture and to specify the adaptation logic for reconfiguring its variable aspects (e.g. the modules that implement various obstacle detection algorithms or control different distance sensors) according to specific criteria (e.g. enhancing robustness against variable illumination conditions). Despite self-adaptation is an intrinsic capability of autonomous robots, ad-hoc approaches are used in practice to design reconfigurable robot architectures. In order to enhance system maintainability, the control logic and the adaptation logic should be loosely coupled. For this purpose, the adaptation logic should be defined against an explicit representation of software variability in the robot control architecture. In this paper we propose a modeling approach, which consists in explicitly representing robot software variability with the MARTE::ARM-Variability metamodel, which has been designed as an extension of the UML MARTE profile. We evaluate the applicability of the proposed approach by exemplifying the software architecture design of a robot navigation framework and by analyzing the support provided by the ROS infrastructure for runtime reconfiguration of its variable aspects.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001094",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Computer science",
      "Control reconfiguration",
      "Distributed computing",
      "Embedded system",
      "Human–computer interaction",
      "Maintainability",
      "Optics",
      "Physics",
      "Robot",
      "Software engineering"
    ],
    "authors": [
      {
        "surname": "Brugali",
        "given_name": "Davide"
      }
    ]
  },
  {
    "title": "Near-optimal 3D trajectory design in presence of obstacles: A convolutional neural network approach",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104483",
    "abstract": "This paper proposes an approach based on neural networks for designing near-optimal 3D trajectories connecting two points separated by obstacles. A reference path is first built with a novel Theta* algorithm implementation, upgraded to reduce the number of waypoints and the angular variations. Starting from the path, a trajectory based on piecewise Bézier curves is designed with an algorithm relying on two design parameters. The optimal value of these parameters is estimated with a Convolutional Neural Network (CNN) architecture receiving as inputs an image of the path and its properties. The CNN training is performed on a synthetic dataset of optimal parameters built with Differential Evolution optimization for a variety of randomly generated paths. The parameters from CNN are refined with an algorithm capable of providing with high success rate near-optimal trajectories within minimum computation time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001227",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Computation",
      "Computer science",
      "Convolutional neural network",
      "Differential evolution",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Path (computing)",
      "Physics",
      "Piecewise",
      "Programming language",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Sartori",
        "given_name": "Daniele"
      },
      {
        "surname": "Zou",
        "given_name": "Danping"
      },
      {
        "surname": "Pei",
        "given_name": "Ling"
      },
      {
        "surname": "Yu",
        "given_name": "Wenxian"
      }
    ]
  },
  {
    "title": "Towards One Shot & Pick All: 3D-OAS, an end-to-end framework for vision guided top-down parcel bin-picking using 3D-overlapping-aware instance segmentation and GNN",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104491",
    "abstract": "Robotic Grasping and sorting is acknowledged as the most fundamental and significant manipulation task in industry. An ultimate goal of a Vision guided Robotic grasping system is to precisely and efficiently sort maximum objects with minimum inference time of vision system. So far, applicable end-to-end perception and autonomously picking of hierarchically stacked objects has not been intensively reported in previous works. Especially, in the scenario of top-down parcel bin-picking where robots are required to perceive and pick up parcels from random stacks. In this work, we focus on this challenging task by putting forward a novel end-to-end parcel bin-picking model termed 3D-OAS. Our proposal combines a 3D overlapping-aware instance segmentation and directed graph to describe the hierarchical structure of stacked objects from a top-down angle and a graph-neural-network is introduced to solve the optimal sorting orders. The experiment was conducted via a set of Vision guided Delta-Parallel robotic grasping system with a top-down RGB-D camera. Experimental Results proved the feasibility of our proposal, it could hierarchically segment stacked objects and solve sorting sequence with minimum one shot.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001306",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Bin",
      "Computer science",
      "Computer vision",
      "Economics",
      "End-to-end principle",
      "Focus (optics)",
      "Graph",
      "Information retrieval",
      "Machine vision",
      "Management",
      "Optics",
      "Physics",
      "Robot",
      "SMT placement equipment",
      "Segmentation",
      "Task (project management)",
      "Theoretical computer science",
      "sort"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Yi"
      },
      {
        "surname": "Yang",
        "given_name": "Jiacheng"
      },
      {
        "surname": "Wang",
        "given_name": "Shaocong"
      },
      {
        "surname": "Li",
        "given_name": "Xiaohui"
      }
    ]
  },
  {
    "title": "Autonomous cooperative wall building by a team of Unmanned Aerial Vehicles in the MBZIRC 2020 competition",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104482",
    "abstract": "This paper presents a system for autonomous cooperative wall building with a team of Unmanned Aerial Vehicles (UAVs). The system was developed for Challenge 2 of the Mohamed Bin Zayed International Robotics Challenge (MBZIRC) 2020. The wall-building scenario of Challenge 2 featured an initial stack of bricks and wall structure where the individual bricks had to be placed by a team of three UAVs. The objective of the task was to maximize collected points for placing the bricks within the restricted construction time while following the prescribed wall pattern. The proposed approach uses initial scanning to find a priori unknown locations of the bricks and the wall structure. Each UAV is then assigned to individual bricks and wall placing locations and further performs grasping and placement using onboard resources only. The developed system consists of methods for scanning a given area, RGB-D detection of bricks and wall placement locations, precise grasping and placing of bricks, and coordination of multiple UAVs. The paper describes the overall system, individual components, experimental verification in demanding outdoor conditions, the achieved results in the competition, and lessons learned. The presented CTU-UPenn-NYU approach achieved the overall best performance among all participants to win the MBZIRC competition by collecting the highest number of points by correct placement of a high number of bricks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001215",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Competition (biology)",
      "Computer science",
      "Computer vision",
      "Ecology",
      "Engineering",
      "Robot",
      "Robotics",
      "Simulation",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Baca",
        "given_name": "Tomas"
      },
      {
        "surname": "Penicka",
        "given_name": "Robert"
      },
      {
        "surname": "Stepan",
        "given_name": "Petr"
      },
      {
        "surname": "Petrlik",
        "given_name": "Matej"
      },
      {
        "surname": "Spurny",
        "given_name": "Vojtech"
      },
      {
        "surname": "Hert",
        "given_name": "Daniel"
      },
      {
        "surname": "Saska",
        "given_name": "Martin"
      }
    ]
  },
  {
    "title": "Distributed safe formation maneuver control of Euler–Lagrange multi-agent systems in a partially unknown environment by safe reinforcement learning",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104486",
    "abstract": "This paper describes a multi-layer approach to the problem of safe formation control. The agents’ and the leader’s dynamics are considered unknown Euler–Lagrange (E-L) systems. In addition, the environment is partially unknown. We propose a novel layered approach to reach the predefined target while preserving a designed, safe, optimal formation pattern along a planned optimal path. By satisfying the safety constraints, safe reinforcement learning (RL) is introduced to ensure the leader reaches the desired destination without collision. Maintaining a constant formation pattern is unsafe for followers since they are not familiar with the surroundings. Thus, we define the formation maneuver control problem, which can adjust formation geomatical patterns dynamically depending on the environment. A proposed algorithm based on the leader’s designed path is defined to solve the problem. Using off-policy RL, the model-free distributed control law is presented to generate a designed formation pattern in a determined optimal path. Finally, we demonstrate that the proposed approach can be applied to the safe formation maneuver problem in an environment with convex obstacles. This paper presents a safe formation control strategy that addresses practical issues, such as model uncertainty, without requiring sensor measurements in an unknown, static environment without uncertainty. Simulation demonstrates the effectiveness of the suggested approaches for a group of Uncrewed Surface Vehicles (USVs).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001252",
    "keywords": [
      "Artificial intelligence",
      "Collision",
      "Collision avoidance",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Control theory (sociology)",
      "Mathematical optimization",
      "Mathematics",
      "Path (computing)",
      "Programming language",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Golmisheh",
        "given_name": "Fatemeh Mahdavi"
      },
      {
        "surname": "Shamaghdari",
        "given_name": "Saeed"
      }
    ]
  },
  {
    "title": "Map point selection for visual SLAM",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104485",
    "abstract": "Simultaneous localisation and mapping (SLAM) play a vital role in autonomous robotics. Robotic platforms are often resource-constrained, and this limitation motivates resource-efficient SLAM implementations. While sparse visual SLAM algorithms offer good accuracy for modest hardware requirements, even these more scalable sparse approaches face limitations when applied to large-scale and long-term scenarios. A contributing factor is that the point clouds resulting from SLAM are inefficient to use and contain significant redundancy. This paper proposes the use of subset selection algorithms to reduce the map produced by sparse visual SLAM algorithms. Information-theoretic techniques have been applied to simpler related problems before, but they do not scale if applied to the full visual SLAM problem. This paper proposes a number of novel information-theoretic utility functions for map point selection and optimises these functions using greedy algorithms. The reduced maps are evaluated using practical data alongside an existing visual SLAM implementation (ORB-SLAM 2). Approximate selection techniques proposed in this paper achieve trajectory accuracy comparable to an offline baseline while being suitable for online use. These techniques enable the practical reduction of maps for visual SLAM with competitive trajectory accuracy. Results also demonstrate that SLAM front-end performance can significantly impact the performance of map point selection. This shows the importance of testing map point selection with a front-end implementation. To exploit this, this paper proposes an approach that includes a model of the front-end in the utility function when additional information is available. This approach outperforms alternatives on applicable datasets and highlights future research directions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001240",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Computer vision",
      "Database",
      "Machine learning",
      "Mobile robot",
      "Operating system",
      "Physics",
      "Redundancy (engineering)",
      "Robot",
      "Robotics",
      "Scalability",
      "Selection (genetic algorithm)",
      "Simultaneous localization and mapping",
      "Trajectory",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Müller",
        "given_name": "Christiaan J."
      },
      {
        "surname": "van Daalen",
        "given_name": "Corné E."
      }
    ]
  },
  {
    "title": "Online learning of MPC for autonomous racing",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104469",
    "abstract": "A Learning-based Model Predictive Control (LMPC) algorithm is proposed for a Formula Student (FS) autonomous vehicle. The online learning algorithm has two distinct roles: to improve the dynamic model accuracy of the vehicle used in the MPC, while performing online tuning of the model predictive controller parameters. The developed controller is shown to reduce the total lap time through an iterative learning process as the vehicle progresses on track. To capture the full complexity of the nonlinear higher order dynamics, an Artificial Neural Network (ANN) complements the vehicle’s nominal model. The ANN is trained using an online supervised learning scheme based on past model prediction errors. Additionally, a Genetic Algorithm (GA) is used to iteratively find the optimal set of controller parameters that maximizes a reward function. Several simulation tests performed on real examples of competition tracks demonstrate the effectiveness of the approach. Moreover, it is shown that the combination of both online learning methods is able to significantly improve tracking performance of the FS vehicle, eventually reducing the total lap time by over 16%.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001082",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Evolutionary biology",
      "Function (biology)",
      "Genetic algorithm",
      "Machine learning",
      "Mathematics",
      "Model predictive control",
      "Nonlinear system",
      "Online learning",
      "Online model",
      "Operating system",
      "Physics",
      "Process (computing)",
      "Programming language",
      "Quantum mechanics",
      "Set (abstract data type)",
      "Statistics",
      "Supervised learning",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Costa",
        "given_name": "Gabriel"
      },
      {
        "surname": "Pinho",
        "given_name": "João"
      },
      {
        "surname": "Botto",
        "given_name": "Miguel Ayala"
      },
      {
        "surname": "Lima",
        "given_name": "Pedro U."
      }
    ]
  },
  {
    "title": "Toward best practices in embedded ethics: Suggestions for interdisciplinary technology development",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104467",
    "abstract": "With current developments in robotics and artificial intelligence (AI) comes an increased focus on the ethical production and use of such novel technologies. Accordingly, a trend toward “embedded ethics” is seen in recent research, reflecting an increase in efforts to integrate social and ethical considerations in computer science education and early in the development phases of AI and robotics. What remains to be established, however, is a more concrete understanding of the best working modalities for such interdisciplinary collaborations. In this brief discussion paper, we provide reflections derived from our interdisciplinary Responsible Robotics project which integrates ethicists and social scientists at early stages of development. We put forward several suggestions on how to integrate ethics and social science within technological development. We believe these suggestions can serve as a working taxonomy of best practices for embedded ethics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001069",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Engineering",
      "Engineering ethics",
      "Modalities",
      "Robot",
      "Robotics",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Tigard",
        "given_name": "Daniel W."
      },
      {
        "surname": "Braun",
        "given_name": "Maximilian"
      },
      {
        "surname": "Breuer",
        "given_name": "Svenja"
      },
      {
        "surname": "Ritt",
        "given_name": "Konstantin"
      },
      {
        "surname": "Fiske",
        "given_name": "Amelia"
      },
      {
        "surname": "McLennan",
        "given_name": "Stuart"
      },
      {
        "surname": "Buyx",
        "given_name": "Alena"
      }
    ]
  },
  {
    "title": "Model checking embedded adaptive cruise controllers",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104488",
    "abstract": "While checking functional correctness for automated driving is often achieved through vast amounts of automated and manual field testing, automating specification verification is essential for developing and releasing fully self-driving vehicles. This paper presents an automatic bounded model checking approach for functional specifications over longitudinal vehicle controller implementations. The proposed method checks the actual embedded program, rather than an extracted abstract model. The specification is converted into a monitor that is interleaved with the execution of the program over a finite time horizon in closed-loop simulation. A decomposition is proposed to tackle the verification complexity. This allows verifying the program for whole parameter sets using a software model checker as opposed to testing only individual samples. The approach is capable of identifying functional flaws in several exemplary longitudinal controllers with variable complexity.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001276",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Control (management)",
      "Controller (irrigation)",
      "Correctness",
      "Cruise control",
      "Embedded system",
      "Formal verification",
      "Model checking",
      "Programming language"
    ],
    "authors": [
      {
        "surname": "Nenchev",
        "given_name": "Vladislav"
      }
    ]
  },
  {
    "title": "Design of 9-DOF humanoid arms inspired by the human’s inner shoulder to enhance versatility and workspace",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104447",
    "abstract": "Many humanoid arms have six degrees-of-freedom (DOFs), similar to the human joint configuration. Moreover, humanoid arms with 7-DOF or 8-DOF have been designed to enhance the range of motion or structural versatility. Notably, these arms exhibit structural limitations and thus cannot effectively implement versatile and complex motions such as valve closing motion. To address this problem, this paper proposes a novel 9-DOF humanoid arm, named RoK-Arm9, inspired by the human inner shoulder. Two additional joints are introduced inside the shoulder to increase the versatility and workspace. To demonstrate the superiority of RoK-Arm9 over the existing robots for complex dual-arm manipulation, we analyzed the corresponding manipulability measure, bimanual task areas, and dual-arm manipulability measure. Finally, we confirmed that the actual RoK-Arm9 can conduct the same motion as the simulation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000866",
    "keywords": [
      "ARM9",
      "Artificial intelligence",
      "Computer science",
      "Database",
      "Degrees of freedom (physics and chemistry)",
      "Embedded system",
      "Engineering",
      "Humanoid robot",
      "Measure (data warehouse)",
      "Motion (physics)",
      "Physics",
      "Quantum mechanics",
      "Robot",
      "Simulation",
      "Systems engineering",
      "Task (project management)",
      "Workspace"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Jaesoon"
      },
      {
        "surname": "Cho",
        "given_name": "Baek-Kyu"
      }
    ]
  },
  {
    "title": "Multi-contact planning and control for humanoid robots: Design and validation of a complete framework",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104448",
    "abstract": "In this paper, we consider the problem of generating appropriate motions for a torque-controlled humanoid robot that is assigned a multi-contact loco-manipulation task, i.e., a task that requires the robot to move within the environment by repeatedly establishing and breaking multiple, non-coplanar contacts. To this end, we present a complete multi-contact planning and control framework for multi-limbed robotic systems, such as humanoids. The planning layer works offline and consists of two sequential modules: first, a stance planner computes a sequence of feasible contact combinations; then, a whole-body planner finds the sequence of collision-free humanoid motions that realize them while respecting the physical limitations of the robot. For the challenging problem posed by the first stage, we propose a novel randomized approach that does not require the specification of pre-designed potential contacts or any kind of pre-computation. The control layer produces online torque commands that enable the humanoid to execute the planned motions while guaranteeing closed-loop balance. It relies on two modules, i.e., the stance switching and reactive balancing module; their combined action allows it to withstand possible execution inaccuracies, external disturbances, and modeling uncertainties. Numerical and experimental results obtained on COMAN+, a torque-controlled humanoid robot designed at Istituto Italiano di Tecnologia, validate our framework for loco-manipulation tasks of different complexity.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000878",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computation",
      "Computer science",
      "Control engineering",
      "Engineering",
      "Humanoid robot",
      "Human–computer interaction",
      "Physics",
      "Robot",
      "Simulation",
      "Systems engineering",
      "Task (project management)",
      "Thermodynamics",
      "Torque"
    ],
    "authors": [
      {
        "surname": "Ferrari",
        "given_name": "Paolo"
      },
      {
        "surname": "Rossini",
        "given_name": "Luca"
      },
      {
        "surname": "Ruscelli",
        "given_name": "Francesco"
      },
      {
        "surname": "Laurenzi",
        "given_name": "Arturo"
      },
      {
        "surname": "Oriolo",
        "given_name": "Giuseppe"
      },
      {
        "surname": "Tsagarakis",
        "given_name": "Nikos G."
      },
      {
        "surname": "Mingo Hoffman",
        "given_name": "Enrico"
      }
    ]
  },
  {
    "title": "Ultrasound-guide prostate biopsy robot and calibration based on dynamic kinematic error model with POE formula",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104465",
    "abstract": "In the transrectal ultrasound-guided transperineal prostate biopsy, the application of robots can effectively reduce the interference of low-quality ultrasound images on the physician to determine the biopsy route and improve the positive detection rate. In this paper, an 8-degree-of-freedom (DOF) prostate biopsy robot for clinical is developed to realize the operation of ultrasonic probe scanning, the inserting point and target lesion point positioning, and the needle insertion. Considering the dynamic errors caused by different motions of robot joints, a dynamic product-of-exponentials (POE) based kinematic model that can reflect non-geometric errors is proposed by integrating the errors into each joint. Moreover, the parameters in the model are identified by linearizing the dynamic POE-based kinematic model. Finally, the experiment shows the maximum errors can be limited to 0.60 and 1.16 mm for inserting point and needle endpoint after compensation, and the maximum inserting angle error is limited to 1.381°. It proves the feasibility of the kinematic model proposed in this paper and indicates that the robot system can meet the requirements of clinical biopsy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001045",
    "keywords": [
      "Artificial intelligence",
      "Cancer",
      "Classical mechanics",
      "Compensation (psychology)",
      "Computer science",
      "Computer vision",
      "Internal medicine",
      "Kinematics",
      "Medicine",
      "Physics",
      "Prostate",
      "Prostate biopsy",
      "Psychoanalysis",
      "Psychology",
      "Robot",
      "Simulation"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Weirong"
      },
      {
        "surname": "Pan",
        "given_name": "Bo"
      },
      {
        "surname": "Ai",
        "given_name": "Yue"
      },
      {
        "surname": "Fu",
        "given_name": "Yili"
      },
      {
        "surname": "Li",
        "given_name": "Gonghui"
      },
      {
        "surname": "Liu",
        "given_name": "Yanjie"
      }
    ]
  },
  {
    "title": "Learning 6-DoF grasping with dual-agent deep reinforcement learning",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104451",
    "abstract": "Self-supervised grasp learning (SGL) is one of the most promising approaches to challenging robotic grasping. However, most existing SGL-based methods are restricted to in 4-DoF planar grasps due to limited grasp representations and inadequate learning rewards. This paper proposes 6-DoF grasp learning (6DGL). It represents a 6-DoF grasp by exploiting both planar and spherical grasp affordance in the image space. Its underlying network is called Q Mixing Network with Planar and Spherical Affordances (QMIX-PSA). In QMIX-PSA, two agent networks, i.e., a planar affordance network (PA-Net) and a spherical affordance network (SA-Net), are used to predict grasp position and orientation. Then, the two networks’ joint action value is estimated by a QMIX to reconstruct their connection. Again, an augmented reward is presented to evaluate the quality of a 6-DoF grasp by measuring the incurred disturbance to the surroundings with scene images. Finally, extensive experiments are conducted on grasping metal workpieces and daily items. The results show that 6DGL outperforms its peers regarding grasp success rate and quality, especially in clutter where existing SGL methods are incompetent.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000908",
    "keywords": [
      "Affordance",
      "Art",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Dual (grammatical number)",
      "GRASP",
      "Human–computer interaction",
      "Literature",
      "Programming language",
      "Reinforcement learning",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Hou",
        "given_name": "Yanxu"
      },
      {
        "surname": "Li",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Informed expansion for informative path planning via online distribution learning",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104449",
    "abstract": "Mobile robots are essential tools for gathering knowledge of the environment and monitoring areas of interest as well as industrial assets. Informative Path Planning methodologies have been successfully applied making robots able to autonomously acquire information and explore unknown surroundings. Rapidly-exploring Information Gathering approaches have been validated in real-world applications, proving they are the way to go when aiming for Information Gathering tasks. In fact, RIG can plan paths for robots with several degrees of freedom and rapidly explore complex workspaces by using the state-of-the-art Voronoi-biased expansion. Nevertheless, it is an efficient solution when most of the area is unknown but its effectiveness decreases as the exploration/gathering evolves. This paper introduces an innovative informed expansion for IG tasks that combines the Kernel Density Estimation technique and a rejection sampling algorithm. By learning online the distribution of the acquired information (i.e., the discovered map), the proposed methodology generates samples in the unexplored regions of the workspace, and thus steers the tree toward the most promising areas. Realistic simulations and an experimental campaign, conducted in the underwater robotics domain, provide a proof-of-concept validation for the developed informed expansion methodology and demonstrate that it enhances the performance of the RIG algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902300088X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Domain (mathematical analysis)",
      "Human–computer interaction",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Motion planning",
      "Path (computing)",
      "Programming language",
      "Robot",
      "Robotics",
      "Workspace"
    ],
    "authors": [
      {
        "surname": "Zacchini",
        "given_name": "Leonardo"
      },
      {
        "surname": "Ridolfi",
        "given_name": "Alessandro"
      },
      {
        "surname": "Allotta",
        "given_name": "Benedetto"
      }
    ]
  },
  {
    "title": "Robot learning from human demonstrations with inconsistent contexts",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104466",
    "abstract": "Visual imitation learning is a promising approach that promotes robots to learn skills from visual demonstrations. However, current visual imitation learning approaches introduce unreasonable assumptions that the contexts of the visual demonstrations and the robot observations are consistent, which affects the flexibility and scalability of the approaches. It is a key challenge for robots to learn from visual demonstrations with inconsistent contexts. Inconsistent contexts may cause a serious difference in the pixel distribution of the operator and the environment, which makes vision-based control policies hardly effective. In this paper, we propose a novel imitation learning framework to enable robots to reproduce behavior by watching human demonstrations with inconsistent contexts, such as different viewpoints, operators, backgrounds, object appearances and positions. Specifically, our framework consists of three networks: flow-based viewpoint transformation network (FVTrans), robot2human alignment network (RANet) and inverse dynamics network (IDNet). First, FVTrans transforms various third-person demonstrations into the fixed robot execution view. With a meta learning strategy, FVTrans can quickly adapt to novel contexts with few samples. Then, RANet aligns the human and the robot at the feature level. Therefore, the demonstration feature can be used as a subgoal of the current moment. Finally, IDNet predicts the joint angles of the robot. We collect a multi-context dataset on the real robot (UR5) for three tasks, including grasping cups, sweeping garbage and placing objects. We empirically demonstrate that our framework can perform three tasks with a high success rate and be effectively generalized to different contexts.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001057",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Context (archaeology)",
      "Feature (linguistics)",
      "Flexibility (engineering)",
      "Human–computer interaction",
      "Imitation",
      "Linguistics",
      "Mathematics",
      "Paleontology",
      "Philosophy",
      "Psychology",
      "Robot",
      "Social psychology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Qian",
        "given_name": "Zhifeng"
      },
      {
        "surname": "You",
        "given_name": "Mingyu"
      },
      {
        "surname": "Zhou",
        "given_name": "Hongjun"
      },
      {
        "surname": "Xu",
        "given_name": "Xuanhui"
      },
      {
        "surname": "He",
        "given_name": "Bin"
      }
    ]
  },
  {
    "title": "SAR optimization and Convolutional Neural Network based fault estimations and for auto-landing control model",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104409",
    "abstract": "During auto landing, the aircraft flies at a significantly low altitude and low speed. So the consequent accidents and flight crashes are highly possible. Several constrained space and foremost external interruption while landing is considered as one of the most complex phases of the aircraft. Therefore it is necessary to recover the aircraft from various major disturbances and to estimate the rate of fault during aircraft landing. In addition to this, for the effective design of an aircraft, it is essential in determining the fault that affects the aircraft. To overcome the issues, this article aim to propose a novel CNNLSTM-SAR-based fault estimation approach to estimate the fault rate from various state trajectories of the aircraft. Here we employed a Convolution Neural Network (CNN) and Long Short-Term Memory (LSTM) model integrated with the Search and Rescue (SAR) optimization algorithm to react instantaneously to the broad range of failures such as actuator failure and failure due to the wind. Then the performances of the proposed CNNLSTM-SAR based fault estimation approach are compared and the results demonstrated that the proposed approach provide a smooth landing with minimum fault and error.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000489",
    "keywords": [
      "Actuator",
      "Aerospace engineering",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Engineering",
      "Fault (geology)",
      "Geology",
      "Range (aeronautics)",
      "Real-time computing",
      "Seismology"
    ],
    "authors": [
      {
        "surname": "Ayyasamy",
        "given_name": "T."
      },
      {
        "surname": "Nirmala",
        "given_name": "S."
      },
      {
        "surname": "Saravanakumar",
        "given_name": "A."
      }
    ]
  },
  {
    "title": "Motion planning in dynamic environments using context-aware human trajectory prediction",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104450",
    "abstract": "Over the years, the separate fields of motion planning, mapping, and human trajectory prediction have advanced considerably. However, the literature is still sparse in providing practical frameworks that enable mobile manipulators to perform whole-body movements and account for the predicted motion of moving obstacles. Previous optimisation-based motion planning approaches that use distance fields have suffered from the high computational cost required to update the environment representation. We demonstrate that GPU-accelerated predicted composite distance fields significantly reduce the computation time compared to calculating distance fields from scratch. We integrate this technique with a complete motion planning and perception framework that accounts for the predicted motion of humans in dynamic environments, enabling reactive and pre-emptive motion planning that incorporates predicted motions. To achieve this, we propose and implement a novel human trajectory prediction method that combines intention recognition with trajectory optimisation-based motion planning. We validate our resultant framework on a real-world Toyota Human Support Robot (HSR) using live RGB-D sensor data from the onboard camera. In addition to providing analysis on a publicly available dataset, we release the Oxford Indoor Human Motion (Oxford-IHM) dataset and demonstrate state-of-the-art performance in human trajectory prediction. The Oxford-IHM dataset is a human trajectory prediction dataset in which people walk between regions of interest in an indoor environment. Both static and robot-mounted RGB-D cameras observe the people while tracked with a motion-capture system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000891",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Biology",
      "Computer science",
      "Computer vision",
      "Context (archaeology)",
      "Law",
      "Motion (physics)",
      "Motion capture",
      "Motion planning",
      "Paleontology",
      "Physics",
      "Political science",
      "Politics",
      "RGB color model",
      "Representation (politics)",
      "Robot",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Finean",
        "given_name": "Mark Nicholas"
      },
      {
        "surname": "Petrović",
        "given_name": "Luka"
      },
      {
        "surname": "Merkt",
        "given_name": "Wolfgang"
      },
      {
        "surname": "Marković",
        "given_name": "Ivan"
      },
      {
        "surname": "Havoutis",
        "given_name": "Ioannis"
      }
    ]
  },
  {
    "title": "Symbolic representation of what robots are taught in one demonstration",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104452",
    "abstract": "To facilitate the use of robots in small and medium-sized enterprises (SMEs), they have to be easily and quickly deployed by non-expert users. Programming by Demonstration (PbD) is considered a fast and intuitive approach to handle this requirement. However, one of the major drawbacks of pure PbD is that it may suffer from poor generalisation capabilities, as it is mainly capable of motion-level representations. This work proposes a method to semantically represent a demonstrated skill, so as to identify the elements of the workspace that are relevant for the characterisation of the skill itself, as well as its preconditions and effects. This way, the robot can automatically abstract from the demonstration and memorise the skill in a more general way. An experimental case study consisting in a manipulation task is reported to validate the approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902300091X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Economics",
      "Human–computer interaction",
      "Law",
      "Management",
      "Motion (physics)",
      "Political science",
      "Politics",
      "Programming by demonstration",
      "Representation (politics)",
      "Robot",
      "Task (project management)",
      "Workspace"
    ],
    "authors": [
      {
        "surname": "Zanchettin",
        "given_name": "Andrea Maria"
      }
    ]
  },
  {
    "title": "A survey on control of humanoid fall over",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104443",
    "abstract": "Humanoid robot operation requires balancing to prevent failures, such as fall over. This is a crucial task in legged robots and thus several researchers are working on this topic. Fall prediction, controlled fall, and fall recovery become important topics in understanding robot control and allow legged robots to function in challenging real-world environments. This paper aims at setting up methodically the problem definition of humanoid falling and further identifying and surveying working techniques in the literature. The focus is to categorize all methods that were used in the community, identify the solved and open questions, as well as propose directions of research in the field. The paper is based on experimental research that has been done on a full-size humanoid robot.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000829",
    "keywords": [
      "Artificial intelligence",
      "Categorization",
      "Computer science",
      "Control (management)",
      "Engineering",
      "Environmental health",
      "Falling (accident)",
      "Field (mathematics)",
      "Focus (optics)",
      "Humanoid robot",
      "Human–computer interaction",
      "Mathematics",
      "Medicine",
      "Optics",
      "Physics",
      "Pure mathematics",
      "Robot",
      "Simulation",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Subburaman",
        "given_name": "Rajesh"
      },
      {
        "surname": "Kanoulas",
        "given_name": "Dimitrios"
      },
      {
        "surname": "Tsagarakis",
        "given_name": "Nikos"
      },
      {
        "surname": "Lee",
        "given_name": "Jinoh"
      }
    ]
  },
  {
    "title": "TMG: A topology-based motion generalization method with spatial relationship preservation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104445",
    "abstract": "As an important requirement, human-friendly motion in human–robot interaction (HRI) is increasingly attracting attention. In many scenarios, the ability to generalize a similar motion from demonstration is essential for a robot, and the similarity is generally captured by the spatial relationship between the different joints of the robot. Though a lot of investigation for motion generalization has been conducted and good progress achieved, they share limitations in leaving the relationship out of consideration and being difficult to apply the generalization between different robots. In this paper, we propose a novel topology-based motion generalization (TMG) method that abstracts the motion generalization problem to a mesh deformation optimization, and the spatial relationship between different parts of the robot is captured with a topology-based representation. Instead of only taking into account a single joint position, the relationship semantic with Laplacian coordinates is modeled, and the motion generalization from demonstration to reproduction is realized by preserving the semantic as a Laplacian deformation, and even the robot or target position is changed. Furthermore, motion generalization between single or multiple different robots can be achieved with spatial relationship preservation and transfer. Our experimental results show that the reproduction based on topology-based representation outperforms the mapping methods by training with end-effector pose or joint angles, and ensures robust motion with spatial relationship preservation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000842",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Computer vision",
      "Economics",
      "Finance",
      "Generalization",
      "Mathematical analysis",
      "Mathematics",
      "Motion (physics)",
      "Position (finance)",
      "Robot",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Yihui"
      },
      {
        "surname": "Wu",
        "given_name": "Jiajun"
      },
      {
        "surname": "Chen",
        "given_name": "Xiaohan"
      },
      {
        "surname": "Guan",
        "given_name": "Yisheng"
      },
      {
        "surname": "Zhu",
        "given_name": "Haifei"
      }
    ]
  },
  {
    "title": "A telerobotic system enabling online switching among various architectures and controllers",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104402",
    "abstract": "With the increasing complexity of teleoperation tasks, various teleoperation architectures, including the Single-Leader/Single-Follower (SLSF), Multiple-Leader/Multiple-Follower (MLMF), Single-Leader/Multiple-Follower (SLMF), and Multiple-Leader/Single-Follower (MLSF) systems, are emerging. Although numerous works have focused on the control strategies or a specific architecture, the study on online switching among different architectures is not equally prolific. However, the online switching among different architectures/controllers is required in a wide spectrum of robotic applications to perform complex tasks. This feature can also promote the development of shared autonomy robotic systems, including the seamless adaption of the autonomy level, the better co-adaption between human and robot, and so on. Here a generic, flexible, and expandable telerobotic system is developed. Instead of focusing on the control strategy of a specific architecture, the physical topology, the software design, and the switching strategy during transitions are all considered to enable the online switching among various architectures and/or controllers. The experimental results of several scenarios validate the main features of the proposed system and demonstrate the benefits of these features.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000416",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Computer science",
      "Control engineering",
      "Distributed computing",
      "Embedded system",
      "Engineering",
      "Human–computer interaction",
      "Programming language",
      "Robot",
      "Software",
      "Teleoperation",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Gaofeng"
      },
      {
        "surname": "Caponetto",
        "given_name": "Fernando"
      },
      {
        "surname": "Katsageorgiou",
        "given_name": "Vasiliki"
      },
      {
        "surname": "Tsagarakis",
        "given_name": "Nikos G."
      },
      {
        "surname": "Sagakoglou",
        "given_name": "Ioannis"
      }
    ]
  },
  {
    "title": "LWDNet-A lightweight water-obstacles detection network for unmanned surface vehicles",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104453",
    "abstract": "Water-obstacles detection based on semantic segmentation is an essential part of autonomous navigation of unmanned surface vehicles (USV). However, it is difficult for existing methods to ensure the real-time of water-obstacles recognition and high detection accuracy. To address this issue, we proposed novel network architecture, a lightweight water-obstacles detection network (LWDNet). In LWDNet, we adopt a novel backbone, bottleneck structure with attention block, the former decrease the model size, the latter obtain more semantic information, and then the dilated convolution has been used in depthwise separable (DW) convolution to enforce the extraction of feature information. Additionally, by using improved focal loss (weight the main and auxiliary focal loss), the water-obstacles detection accuracy increased. In order to test the real-time performance and detection accuracy of LWDNet, we use the most challenging dataset, Multi-modal Marine Obstacle Detection Dataset 2 (MODD2) dataset, for experimental validation. The experimental results show that, compared with the state-of-the-art detection methods, such as WasR and ShorelineNet, the LWDNet maintains a much faster speed of images inference (62 frames-per-second on an NVIDIA RTX 2080Ti), and at the same time, the obstacles detection performance is equally high (87.5% F-measure, 77.8% IOU). Therefore, the LWDNet is an efficient network in water-obstacles detection, making the autonomous navigation of USV more reliable.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000921",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Block (permutation group theory)",
      "Bottleneck",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Convolution (computer science)",
      "Embedded system",
      "Feature extraction",
      "Geometry",
      "Inference",
      "Law",
      "Mathematics",
      "Network architecture",
      "Object detection",
      "Obstacle",
      "Pattern recognition (psychology)",
      "Political science",
      "Real-time computing",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Cai",
        "given_name": "Qilie"
      },
      {
        "surname": "Wang",
        "given_name": "Qiang"
      },
      {
        "surname": "Zhang",
        "given_name": "Yulong"
      },
      {
        "surname": "He",
        "given_name": "Zhibo"
      },
      {
        "surname": "Zhang",
        "given_name": "Yuhong"
      }
    ]
  },
  {
    "title": "Online active and dynamic object shape exploration with a multi-fingered robotic hand",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104461",
    "abstract": "The sense of touch can provide a robot with a wealth of information about the contact region when interacting with an unknown environment. Nevertheless, utilizing touch information to plan exploration paths and adjust robot posture to improve task efficiency remains challenging. This paper presents a novel approach for the online tactile surface exploration of unknown objects with a multi-degree of freedom robotic hand. We propose an exploration strategy that actively maximizes the entropy of the acquired data while dynamically balancing the exploration’s global knowledge and local complexity. We demonstrate that our method can efficiently control a multi-fingered robotic hand to explore objects of arbitrary shapes (e.g., with a handle, hole, or sharp edges). To facilitate efficient multi-contact exploration with a robotic hand, we offer an optimization-based planning algorithm that adapts the hand pose to the local surface geometry online and increases the kinematic configuration of each finger during exploration. Ultimately, we compared our approach to state of the art in a simulated environment. Experimental results indicate that our proposed methods can guide a multi-finger robotic hand to explore efficiently and smoothly, thereby reconstructing the unknown geometry of a variety of everyday objects, with significant improvements in data efficiency and finger compliance when compared to state-of-the-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001008",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Human–computer interaction",
      "Object (grammar)",
      "Robot",
      "Robotic hand"
    ],
    "authors": [
      {
        "surname": "Khadivar",
        "given_name": "Farshad"
      },
      {
        "surname": "Yao",
        "given_name": "Kunpeng"
      },
      {
        "surname": "Gao",
        "given_name": "Xiao"
      },
      {
        "surname": "Billard",
        "given_name": "Aude"
      }
    ]
  },
  {
    "title": "Scalable modular synthetic data generation for advancing aerial autonomy",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104464",
    "abstract": "One major barrier to advancing aerial autonomy has been collecting large-scale aerial datasets for training machine learning models. Due to costly and time-consuming real-world data collection through deploying drones, there has been an increasing shift towards using synthetic data for training models in drone applications. However, to increase widespread generalization and transferring models to real-world, increasing the diversity of simulation environments to train a model over all the varieties and augmenting the training data, has been proved to be essential. Current synthetic aerial data generation tools either lack data augmentation or rely heavily on manual workload or real samples for configuring and generating diverse realistic simulation scenes for data collection. These dependencies limit scalability of the data generation workflow. Accordingly, there is a major challenge in balancing generalizability and scalability in synthetic data generation. To address these gaps, we introduce a scalable Aerial Synthetic Data Augmentation (ASDA) framework tailored to aerial autonomy applications. ASDA extends a central data collection engine with two scriptable pipelines that automatically perform scene and data augmentations to generate diverse aerial datasets for different training tasks. ASDA improves data generation workflow efficiency by providing a unified prompt-based interface over integrated pipelines for flexible control. The procedural generative approach of our data augmentation is performant and adaptable to different simulation environments, training tasks and data collection needs. We demonstrate the effectiveness of our method in automatically generating diverse datasets and show its potential for downstream performance optimization. Our work contributes to generating enhanced benchmark datasets for training models that can generalize better to real-world situations. Video: youtube.com/watch?v=eKpOh-K-NfQ",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023001033",
    "keywords": [
      "Artificial intelligence",
      "Autonomy",
      "Computer architecture",
      "Computer science",
      "Database",
      "Human–computer interaction",
      "Law",
      "Modular design",
      "Political science",
      "Programming language",
      "Scalability"
    ],
    "authors": [
      {
        "surname": "Sabet",
        "given_name": "Mehrnaz"
      },
      {
        "surname": "Palanisamy",
        "given_name": "Praveen"
      },
      {
        "surname": "Mishra",
        "given_name": "Sakshi"
      }
    ]
  },
  {
    "title": "An agent-based modeling framework for the multi-UAV rendezvous recharging problem",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104442",
    "abstract": "In this work, we aim to model the multi-UAV rendezvous recharging problem, which consists of energy-limited aerial vehicles that rendezvous with a mobile or fixed charging station. The motivation for such a problem is to tackle persistent surveillance missions, where the modeling of related problems often rely on heavy mathematical formulations, such as mixed integer linear programming (MILP). The major drawback of such approaches is great difficulty in capturing constraints and adjusting the model for changes. Additionally, MILP solvers are not guaranteed to yield a feasible solution in a timely manner. As a result, we chose to create an agent-based model (ABM). To the best of our knowledge, the presented problem has not been modeled before using ABM. Additionally, we sought to use a custom framework incorporating Behavior Trees (BTs) and Hierarchical Finite State Machines (HFSMs), two commonly used tools in the video game and robotics industry. We verify the model’s correctness through numerical simulations and show that it is highly modular and extensible.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000817",
    "keywords": [
      "Aerospace engineering",
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Correctness",
      "Distributed computing",
      "Engineering",
      "Integer (computer science)",
      "Integer programming",
      "Mathematical optimization",
      "Mathematics",
      "Modular design",
      "Modular programming",
      "Programming language",
      "Rendezvous",
      "Robot",
      "Robotics",
      "Spacecraft"
    ],
    "authors": [
      {
        "surname": "Chour",
        "given_name": "Kenny"
      },
      {
        "surname": "Reddinger",
        "given_name": "Jean-Paul"
      },
      {
        "surname": "Dotterweich",
        "given_name": "James"
      },
      {
        "surname": "Childers",
        "given_name": "Marshal"
      },
      {
        "surname": "Humann",
        "given_name": "James"
      },
      {
        "surname": "Rathinam",
        "given_name": "Sivakumar"
      },
      {
        "surname": "Darbha",
        "given_name": "Swaroop"
      }
    ]
  },
  {
    "title": "Super Intendo: Semantic Robot Programming from Multiple Demonstrations for taskable robots",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104397",
    "abstract": "When an end-user instructs a taskable robot on a new task, it is important for the robot to learn the user’s intention for the task. Knowing the user’s intention, represented as desired goal conditions, allows the robot to generalize across variations of the learned task seen at execution time. However, it has proven challenging to learn goal conditions due to the large, noisy, and complex space of goal conditions expressed by human users. This paper introduces Semantic Robot Programming with Multiple Demonstrations ( SRP-MD ) to learn a generative model of latent end-user task goal conditions from multiple end-user demonstrations in a shared workspace. By learning a generative model of the goal conditions, SRP-MD generalizes to task instances even when the quantity of objects to be arranged is not in the training set or novel object instances are included. At test time, a new goal is pulled from the learned generative model given the objects present in the initial scene. The efficacy of SRP-MD as a step toward taskable robots is shown on a Fetch robot learning and executing bin packing tasks in a simulated environment with grocery items.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000362",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Economics",
      "Generative grammar",
      "Generative model",
      "Human–computer interaction",
      "Management",
      "Object (grammar)",
      "Programming by demonstration",
      "Programming language",
      "Robot",
      "Set (abstract data type)",
      "Task (project management)",
      "Workspace"
    ],
    "authors": [
      {
        "surname": "French",
        "given_name": "Kevin David"
      },
      {
        "surname": "Kim",
        "given_name": "Ji Hwang"
      },
      {
        "surname": "Du",
        "given_name": "Yidong"
      },
      {
        "surname": "Goeddel",
        "given_name": "Elizabeth Mamantov"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhen"
      },
      {
        "surname": "Jenkins",
        "given_name": "Odest Chadwicke"
      }
    ]
  },
  {
    "title": "DROPO: Sim-to-real transfer with offline domain randomization",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104432",
    "abstract": "In recent years, domain randomization over dynamics parameters has gained a lot of traction as a method for sim-to-real transfer of reinforcement learning policies in robotic manipulation; however, finding optimal randomization distributions can be difficult. In this paper, we introduce DROPO, a novel method for estimating domain randomization distributions for safe sim-to-real transfer. Unlike prior work, DROPO only requires a limited, precollected offline dataset of trajectories, and explicitly models parameter uncertainty to match real data using a likelihood-based approach. We demonstrate that DROPO is capable of recovering dynamic parameter distributions in simulation and finding a distribution capable of compensating for an unmodeled phenomenon. We also evaluate the method in two zero-shot sim-to-real transfer scenarios, showing successful domain transfer and improved performance over prior methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000714",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Domain (mathematical analysis)",
      "Electrical engineering",
      "Engineering",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Medicine",
      "Parallel computing",
      "Randomization",
      "Randomized controlled trial",
      "Reinforcement learning",
      "Surgery",
      "Transfer (computing)",
      "Transfer function",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Tiboni",
        "given_name": "Gabriele"
      },
      {
        "surname": "Arndt",
        "given_name": "Karol"
      },
      {
        "surname": "Kyrki",
        "given_name": "Ville"
      }
    ]
  },
  {
    "title": "A multimodal loop closure fusion for autonomous vehicles SLAM",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104446",
    "abstract": "Place recognition and loop closure detection are critical steps in the process of Simultaneous Localization and Mapping (SLAM). Indeed, the ability to determine whether an Autonomous Ground Vehicle (AGV) has returned to a previously visited place is highly important in the context of building a reliable SLAM system. In order to build a consistent global map and to localize the AGV with high confidence in an unknown environment, it is crucial to reduce the cumulative error generated by pose estimation. Although multiple approaches using various data sources have been proposed in order to provide an accurate pose estimation, fewer studies have focused on the integration of a multimodal process to detect loop closure. In this work, we present a novel approach to leverage multiple modalities for a robust and reliable loop closure detection. Our method is based on Similarity-Guided Particle Filtering (SGPF) for the search and validation of Loop Closure Candidates (LCCs). We validate the proposed Multimodal Loop Closure (MMLC) by using two perception modalities based on Bag-of-Words and Scan Context techniques for camera-based and LiDAR-based place recognition, respectively. The efficiency of our method has been evaluated on both KITTI and a self-collected dataset. Compared to the classical loop closure used in ORB-SLAM2, the suggested approach reduces the Absolute Trajectory Error (ATE) by up to 54% and the cumulative error during run-time by up to 62.63%. Finally, 100% of the loops are accurately detected and the ground truth distance between the current pose and the LC is less than 3 m in 98% of the cases.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000854",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Biology",
      "Closure (psychology)",
      "Computer science",
      "Computer vision",
      "Context (archaeology)",
      "Economics",
      "Ground truth",
      "Leverage (statistics)",
      "Market economy",
      "Mobile robot",
      "Operating system",
      "Paleontology",
      "Physics",
      "Pose",
      "Process (computing)",
      "Robot",
      "Simultaneous localization and mapping",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Chghaf",
        "given_name": "Mohammed"
      },
      {
        "surname": "Flórez",
        "given_name": "Sergio Rodríguez"
      },
      {
        "surname": "Ouardi",
        "given_name": "Abdelhafid El"
      }
    ]
  },
  {
    "title": "Automatic extension of a symbolic mobile manipulation skill set",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104428",
    "abstract": "Symbolic planning can provide an intuitive interface for non-expert users to operate autonomous robots by abstracting away much of the low-level programming. However, symbolic planners assume that the initially provided abstract domain and problem descriptions are closed and complete. This means that they are fundamentally unable to adapt to changes in the environment or tasks that are not captured by the initial description. We propose a method that allows an agent to automatically extend the abstract description of its skill set upon encountering such a situation. We introduce strategies for generalizing from previous experience, completing sequences of key actions and discovering preconditions to ensure computational efficiency. The resulting system is evaluated on a symbolic planning benchmark task and on object rearrangement tasks in simulation. Compared to a Monte Carlo Tree Search baseline, our strategies for efficient search have on average a 25% higher success rate at a 67% faster runtime. Code is available at https://github.com/ethz-asl/high_level_planning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000672",
    "keywords": [
      "Artificial intelligence",
      "Baseline (sea)",
      "Benchmark (surveying)",
      "Bubble",
      "Code (set theory)",
      "Computer science",
      "Computer security",
      "Domain (mathematical analysis)",
      "Economics",
      "Extension (predicate logic)",
      "Geodesy",
      "Geography",
      "Geology",
      "Human–computer interaction",
      "Interface (matter)",
      "Key (lock)",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Maximum bubble pressure method",
      "Object (grammar)",
      "Oceanography",
      "Parallel computing",
      "Programming language",
      "Robot",
      "Set (abstract data type)",
      "Software",
      "Symbolic execution",
      "Task (project management)",
      "Theoretical computer science",
      "Tree (set theory)"
    ],
    "authors": [
      {
        "surname": "Förster",
        "given_name": "Julian"
      },
      {
        "surname": "Ott",
        "given_name": "Lionel"
      },
      {
        "surname": "Nieto",
        "given_name": "Juan"
      },
      {
        "surname": "Lawrance",
        "given_name": "Nicholas"
      },
      {
        "surname": "Siegwart",
        "given_name": "Roland"
      },
      {
        "surname": "Chung",
        "given_name": "Jen Jen"
      }
    ]
  },
  {
    "title": "Quasi-static balancing for biped robot to perform extreme postures using ducted-fan propulsion system",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104429",
    "abstract": "Quasi-static balancing is important for enabling humanoid robots to move through extremely rugged terrain, e.g., stepping over a ditch whose width exceeds the robot’s leg length. In this study, to overcome such challenges, an innovative solution was developed, in which external thrust is utilized to maintain the robot’s balance. Initially, a model of the robot’s balance was established for analyzing the factors affecting the balance and the means to maintain it. Subsequently, a new controller combining a thrust controller and a center-of-mass controller was developed to compensate for errors in the thrust output and mass distribution. Finally, a new motion-planning method based on line search regression (LSR) and grid search optimization (GSO) was developed. A series of experiments were conducted using a prototype robot (Jet-HR3), including an error compensation test, an external force disturbance test, a comprehensive motion test, and an active sliding steering test. The results indicated the effectiveness and efficiency of the proposed method. The robot successfully crossed a ditch 695 mm wide, i.e., 147% of the robot’s leg length.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000684",
    "keywords": [
      "Aerospace engineering",
      "Artificial intelligence",
      "Computer science",
      "Engineering",
      "Propulsion",
      "Robot",
      "Simulation"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Zhifeng"
      },
      {
        "surname": "Wang",
        "given_name": "Zijun"
      },
      {
        "surname": "Zhou",
        "given_name": "Jinglun"
      },
      {
        "surname": "Wu",
        "given_name": "Kairong"
      },
      {
        "surname": "Zhu",
        "given_name": "Shunjie"
      },
      {
        "surname": "Nie",
        "given_name": "Lei"
      },
      {
        "surname": "Liang",
        "given_name": "Yuwei"
      },
      {
        "surname": "Yang",
        "given_name": "Liang"
      },
      {
        "surname": "Zhang",
        "given_name": "Yun"
      }
    ]
  },
  {
    "title": "An exploratory study of software engineering in heavy-duty mobile machine automation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104424",
    "abstract": "As the amount and complexity of software for automating heavy-duty mobile machinery is increasing, software engineering in this domain is becoming more important. To characterize the industry’s current state of software engineering and its issues to guide future research, we performed an empirical exploratory study. We interviewed 16 software engineering professionals from 13 different companies conducting business in heavy-duty mobile machines and their automation. The interviews were analyzed qualitatively, and quantification of the analysis results is presented. We first create an overview of software engineering in the heavy-duty mobile machinery industry. We then identify problem areas affecting software development and discuss some of the possible solutions found in literature. Our findings indicate that the major problem areas faced in the industry that require more research are its digital transformation, autonomous machine functional safety, low availability of workforce for developing software for robotic mobile machines and the lack of established software standards.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000635",
    "keywords": [
      "Computer science",
      "Domain (mathematical analysis)",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Social software engineering",
      "Software",
      "Software construction",
      "Software development",
      "Software engineering",
      "Software requirements"
    ],
    "authors": [
      {
        "surname": "Ahonen",
        "given_name": "Andrei"
      },
      {
        "surname": "de Koning",
        "given_name": "Marea"
      },
      {
        "surname": "Machado",
        "given_name": "Tyrone"
      },
      {
        "surname": "Ghabcheloo",
        "given_name": "Reza"
      },
      {
        "surname": "Sievi-Korte",
        "given_name": "Outi"
      }
    ]
  },
  {
    "title": "Model predictive impedance control with Gaussian processes for human and environment interaction",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104431",
    "abstract": "Robotic tasks which involve uncertainty – due to variation in goal, environment configuration, or confidence in task model – may require human input to instruct or adapt the robot. In tasks with physical contact, several existing methods for adapting robot trajectory or impedance according to individual uncertainties have been proposed, e.g., realizing intention detection or uncertainty-aware learning from demonstration. However, isolated methods cannot address the wide range of uncertainties jointly present in many tasks. To improve generality, this paper proposes a model predictive control (MPC) framework which plans both trajectory and impedance online, can consider discrete and continuous uncertainties, includes safety constraints, and can be efficiently applied to a new task. This framework can consider uncertainty from: contact constraint variation, uncertainty in human goals, or task disturbances. An uncertainty-aware task model is learned from a few ( ≤ 3 ) demonstrations using Gaussian Processes. This task model is used in a nonlinear MPC problem to optimize robot trajectory and impedance according to belief in discrete human goals, human kinematics, safety constraints, contact stability, and frequency-domain disturbance rejection. This MPC formulation is introduced, analyzed with respect to convexity, and validated in co-manipulation with multiple goals, a collaborative polishing task, and a collaborative assembly task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000702",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Classical mechanics",
      "Composite material",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Economics",
      "Impedance control",
      "Kinematics",
      "Machine learning",
      "Management",
      "Materials science",
      "Model predictive control",
      "Physics",
      "Range (aeronautics)",
      "Robot",
      "Stability (learning theory)",
      "Task (project management)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Haninger",
        "given_name": "Kevin"
      },
      {
        "surname": "Hegeler",
        "given_name": "Christian"
      },
      {
        "surname": "Peternel",
        "given_name": "Luka"
      }
    ]
  },
  {
    "title": "Smooth collision avoidance for the formation control of first order multi-agent systems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104433",
    "abstract": "This work addresses collision avoidance in the formation control of a group of mobile robots with first-order dynamics perturbed by lateral and longitudinal slipping parameters. A Generalized Proportional–Integral Observer (GPIO) is designed to estimate these perturbations. Then, an Active Disturbance Rejection Control (ADRC) is proposed to solve the well-known formation control avoiding collisions among the agents. The control strategy only depends on the agents’ position measurements. On the other hand, Continuous Repulsive Vector Fields (C-RVFs) are developed to avoid collisions among the agents. For this purpose, a parameter depending on the inter-robot distance is developed to scale the RVFs properly. By proposing C-RVFs, the chattering is eliminated when using Discontinuous RVFs (D-RVFs). Numerical simulations and real-time experiments illustrate the agents’ performance when they are at risk of collision.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000726",
    "keywords": [
      "Artificial intelligence",
      "Collision",
      "Collision avoidance",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Distributed computing",
      "Economics",
      "Finance",
      "Order (exchange)"
    ],
    "authors": [
      {
        "surname": "González-Sierra",
        "given_name": "Jaime"
      },
      {
        "surname": "Hernandez-Martinez",
        "given_name": "E.G."
      },
      {
        "surname": "Ramírez-Neria",
        "given_name": "Mario"
      },
      {
        "surname": "Fernandez-Anaya",
        "given_name": "Guillermo"
      }
    ]
  },
  {
    "title": "Continual learning from demonstration of robotics skills",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104427",
    "abstract": "Methods for teaching motion skills to robots focus on training for a single skill at a time. Robots capable of learning from demonstration can considerably benefit from the added ability to learn new movement skills without forgetting what was learned in the past. To this end, we propose an approach for continual learning from demonstration using hypernetworks and neural ordinary differential equation solvers. We empirically demonstrate the effectiveness of this approach in remembering long sequences of trajectory learning tasks without the need to store any data from past demonstrations. Our results show that hypernetworks outperform other state-of-the-art continual learning approaches for learning from demonstration. In our experiments, we use the popular LASA benchmark, and two new datasets of kinesthetic demonstrations collected with a real robot that we introduce in this paper called the HelloWorld and RoboTasks datasets. We evaluate our approach on a physical robot and demonstrate its effectiveness in learning real-world robotic tasks involving changing positions as well as orientations. We report both trajectory error metrics and continual learning metrics, and we propose two new continual learning metrics. Our code, along with the newly collected datasets, is available at https://github.com/sayantanauddy/clfd.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000660",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Benchmark (surveying)",
      "Code (set theory)",
      "Computer science",
      "Developmental psychology",
      "Focus (optics)",
      "Forgetting",
      "Geodesy",
      "Geography",
      "Kinesthetic learning",
      "Linguistics",
      "Machine learning",
      "Mobile robot",
      "Motion (physics)",
      "Optics",
      "Philosophy",
      "Physics",
      "Programming language",
      "Psychology",
      "Robot",
      "Robot learning",
      "Robotics",
      "Set (abstract data type)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Auddy",
        "given_name": "Sayantan"
      },
      {
        "surname": "Hollenstein",
        "given_name": "Jakob"
      },
      {
        "surname": "Saveriano",
        "given_name": "Matteo"
      },
      {
        "surname": "Rodríguez-Sánchez",
        "given_name": "Antonio"
      },
      {
        "surname": "Piater",
        "given_name": "Justus"
      }
    ]
  },
  {
    "title": "Direction constraints adaptive extended bidirectional A* algorithm based on random two-dimensional map environments",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104430",
    "abstract": "This paper focuses on the mobile robot path planning problem of optimizing the performance metrics of bidirectional A* algorithm in randomized two-dimensional map environments. An algorithm called direction constraints adaptive extended bidirectional A* (DCAE-BA*), which is an improvement of the traditional target dynamic bidirectional A* algorithm (TTD-BA*), is proposed to improve the performance metrics of the algorithm. Regarding the improvement, we propose the adaptive extension method and the direction-constrained optimal node extension method (DCONE). Simulation experiments were conducted for DCAE-BA*, TTD-BA* and traditional A* algorithm (A*) in a large number of random two-dimensional map environments. The simulation experimental scenarios consider four types of start and end point relative directions and three obstacle proportions to objectively and comprehensively evaluate the performance of the proposed algorithms. The results show that different scenarios have a significant impact on the algorithm performance metrics. Finally, the overall performance of the proposed algorithm is evaluated with a large number of experiments in “random” scenarios, and the results show that DCAE-BA* obtains significantly better search time for all three obstacle proportions, and better path length and number of expanded nodes for 10% and 25% obstacle proportions. The effectiveness of the proposed DCAE-BA* algorithm is demonstrated, which provides an essential reference for the path planning of mobile robots in a random 2D map environment.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000696",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Engineering",
      "Geometry",
      "Law",
      "Mathematics",
      "Mobile robot",
      "Motion planning",
      "Node (physics)",
      "Obstacle",
      "Obstacle avoidance",
      "Path (computing)",
      "Point (geometry)",
      "Political science",
      "Programming language",
      "Robot",
      "Structural engineering"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Jiqing"
      },
      {
        "surname": "Li",
        "given_name": "Mingyu"
      },
      {
        "surname": "Su",
        "given_name": "Yousheng"
      },
      {
        "surname": "Li",
        "given_name": "Wenqu"
      },
      {
        "surname": "Lin",
        "given_name": "Yizhong"
      }
    ]
  },
  {
    "title": "Implementation relations and testing for cyclic systems: Adding probabilities",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104426",
    "abstract": "This paper concerns the systematic testing of robotic control software based on state-based models. We focus on cyclic systems that typically receive inputs (values from sensors), perform computations, produce outputs (sent to actuators) and possibly change state. We provide a testing theory for such cyclic systems where time can be represented and probabilities are used to quantify non-deterministic choices, making it possible to model probabilistic algorithms. In addition, refusals, the inability of a system to perform a set of actions, are taken into account. We consider several possible testing scenarios. For example, a tester might only be able to passively observe a sequence of events and so cannot check probabilities, while in another scenario a tester might be able to repeatedly apply a test case and so estimate the probabilities of sequences of events. These different testing scenarios lead to a range of implementation relations (notions of correctness). As a consequence, this paper provides formal definitions of implementation relations that can form the basis of sound automated testing in a range of testing scenarios. We also validate the implementation relations by showing how observers can be used to provide an alternative but equivalent characterisation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000659",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Composite material",
      "Computation",
      "Computer science",
      "Correctness",
      "Focus (optics)",
      "Genetics",
      "Materials science",
      "Optics",
      "Physics",
      "Probabilistic logic",
      "Programming language",
      "Range (aeronautics)",
      "Sequence (biology)",
      "Set (abstract data type)",
      "State (computer science)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Núñez",
        "given_name": "Manuel"
      },
      {
        "surname": "Hierons",
        "given_name": "Robert M."
      },
      {
        "surname": "Lefticaru",
        "given_name": "Raluca"
      }
    ]
  },
  {
    "title": "A lumen-adapted navigation scheme with spatial awareness from monocular vision for autonomous robotic endoscopy",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104444",
    "abstract": "Lumen is a common anatomical condition in endoscopic therapy or diagnostics. The navigation of autonomous robotic endoscopy usually involves vision techniques such as detection of lumen center or anatomically specific contour features. However, these methods may fail to achieve smooth interventions and result in large conveying force without spatial awareness of the tissue state. In this paper, a novel navigation pipeline based on a spatial-aware monocular vision is proposed. The spatial awareness pipeline starts with a data-driven depth estimation technique for reconstructing real-time approximate tissue surface. The spatial shape of the lumen described by the skeleton is then extracted using digital topology. We modify the skeleton to get a smooth pathway, and design an adaptive autonomous control strategy using geometric information from the pathway. We conduct experiments on a colon phantom and ex vivo pig intestines. We test turning performance of several bending segments with different angles in phantom, as well as the overall performance of a long-range intervention task in the phantom and pig intestines. The results show our navigation scheme achieve smoother intervention with lower conveying force. The proposed navigation method with spatial awareness can effectively improve the fluency of autonomous robotic endoscopy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000830",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Imaging phantom",
      "Medicine",
      "Mobile robot",
      "Monocular",
      "Monocular vision",
      "Obstacle avoidance",
      "Pipeline (software)",
      "Programming language",
      "Radiology",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Tao"
      },
      {
        "surname": "Yang",
        "given_name": "Yongming"
      },
      {
        "surname": "Wang",
        "given_name": "Peng"
      },
      {
        "surname": "Cao",
        "given_name": "Yang"
      },
      {
        "surname": "Yang",
        "given_name": "Zhuo"
      },
      {
        "surname": "Liu",
        "given_name": "Hao"
      }
    ]
  },
  {
    "title": "Cyclic policy distillation: Sample-efficient sim-to-real reinforcement learning with domain randomization",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104425",
    "abstract": "Deep reinforcement learning with domain randomization learns a control policy in various simulations with randomized physical and sensor model parameters to become transferable to the real world in a zero-shot setting. However, a huge number of samples are often required to learn an effective policy when the range of randomized parameters is extensive due to the instability of policy updates. To alleviate this problem, we propose a sample-efficient method named cyclic policy distillation (CPD). CPD divides the range of randomized parameters into several small sub-domains and assigns a local policy to each one. Then local policies are learned while cyclically transitioning to sub-domains. CPD accelerates learning through knowledge transfer based on expected performance improvements. Finally, all of the learned local policies are distilled into a global policy for sim-to-real transfers. CPD’s effectiveness and sample efficiency are demonstrated through simulations with four tasks (Pendulum from OpenAIGym and Pusher, Swimmer, and HalfCheetah from Mujoco), and a real-robot, ball-dispersal task. We published code and videos from our experiments at https://github.com/yuki-kadokawa/cyclic-policy-distillation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000647",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Distillation",
      "Domain (mathematical analysis)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Medicine",
      "Randomization",
      "Randomized controlled trial",
      "Reinforcement learning",
      "Sample (material)",
      "Sample complexity",
      "Surgery"
    ],
    "authors": [
      {
        "surname": "Kadokawa",
        "given_name": "Yuki"
      },
      {
        "surname": "Zhu",
        "given_name": "Lingwei"
      },
      {
        "surname": "Tsurumine",
        "given_name": "Yoshihisa"
      },
      {
        "surname": "Matsubara",
        "given_name": "Takamitsu"
      }
    ]
  },
  {
    "title": "Lifelong mapping in the wild: Novel strategies for ensuring map stability and accuracy over time evaluated on thousands of robots",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104403",
    "abstract": "Lifelong mapping presents unique challenges to household robots which operate in the same environment over long durations. One is the growth of redundant information in the map as it evolves over time, which can easily overwhelm the limited computation resources of a household robot. Another is the possibility of mapping errors. An error in robot pose estimate, which if not corrected fast enough, will result in incorrect occupancy and semantic representation, rendering the map unusable. Finally, for a lifelong mapping system where the map is updated continuously, avoiding these errors altogether is infeasible. In this paper, we present a comprehensive overview of novel strategies for eliminating redundant information from the map and preventing and correcting mapping errors. We also present a detailed evaluation of these novel strategies on 10,000 robots running in indoor environments across different geographic locations of the world to demonstrate map stability and accuracy over time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000428",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computation",
      "Computer science",
      "Data mining",
      "Global Map",
      "Law",
      "Political science",
      "Politics",
      "Real-time computing",
      "Rendering (computer graphics)",
      "Representation (politics)",
      "Robot",
      "Semantic mapping"
    ],
    "authors": [
      {
        "surname": "Banerjee",
        "given_name": "Nandan"
      },
      {
        "surname": "Lisin",
        "given_name": "Dimitri"
      },
      {
        "surname": "Lenser",
        "given_name": "Scott R."
      },
      {
        "surname": "Briggs",
        "given_name": "Jimmy"
      },
      {
        "surname": "Baravalle",
        "given_name": "Rodrigo"
      },
      {
        "surname": "Albanese",
        "given_name": "Victoria"
      },
      {
        "surname": "Chen",
        "given_name": "Yao"
      },
      {
        "surname": "Karimian",
        "given_name": "Arman"
      },
      {
        "surname": "Ramaswamy",
        "given_name": "Tyagaraja"
      },
      {
        "surname": "Pilotti",
        "given_name": "Pablo"
      },
      {
        "surname": "Alonso",
        "given_name": "Martin Llofriu"
      },
      {
        "surname": "Nardelli",
        "given_name": "Lucio"
      },
      {
        "surname": "Lane",
        "given_name": "Veronica"
      },
      {
        "surname": "Moser",
        "given_name": "Renaud"
      },
      {
        "surname": "Huttlin",
        "given_name": "Andrea Okerholm"
      },
      {
        "surname": "Shriver",
        "given_name": "Justin"
      },
      {
        "surname": "Fong",
        "given_name": "Phil"
      }
    ]
  },
  {
    "title": "Whole body motion generation with centroidal dynamics of legged robots using sequential bounds tightening of McCormick envelopes",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104401",
    "abstract": "In this paper we introduce a Sequential Convex Programming (SCP) algorithm for the motion generation with the centroidal dynamics of legged robots using a sequential bounds tightening of McCormick envelopes strategy to cope with the nonconvexity of the problem (related to bilinear terms). Therefore, the proposed SCP algorithm is initialized with relaxed McCormick envelopes and then their bounds are sequentially tightened around the current estimate of the solution enforcing this way convergence to a feasible point. The SCP algorithm solves a quadratic program at each iteration by an interior point method. Additionally, the proposed SCP algorithm is alternated with an inverse kinematics algorithm to achieve the whole body motion generation. Finally, extensive numerical experiments show the effectiveness of the proposed algorithm in generating highly agile motions such as trotting, bounding, stotting and running for humanoid and quadruped robots.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000404",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Bilinear interpolation",
      "Bounding overwatch",
      "Computer science",
      "Computer vision",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Geometry",
      "Humanoid robot",
      "Inverse kinematics",
      "Mathematical optimization",
      "Mathematics",
      "Point (geometry)",
      "Quadratic equation",
      "Quadratic programming",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Rojas-Rodriguez",
        "given_name": "Jose C."
      },
      {
        "surname": "Aguilar-Bustos",
        "given_name": "Ana Y."
      },
      {
        "surname": "Bugarin",
        "given_name": "Eusebio"
      }
    ]
  },
  {
    "title": "A robust and compliant framework for legged mobile manipulators using virtual model control and whole-body control",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104411",
    "abstract": "Quadruped robots can mimic animal locomotion mode and have great potential usage in unstructured environments. However, as mobile platforms, quadruped robots often lack manipulation capabilities. In this project, we equipped the quadruped robot SDU-ADog with a torque-controlled 6-DOF arm. A novel control framework which combines virtual model control (VMC) and prioritized whole-body control (WBC) for the whole system is proposed in this paper. VMC finds optimal target ground reaction forces while compensating the arm’s inertia, and then makes the robot compliant to external disturbance. Prioritized WBC deals with multiple tasks in an optimal fashion and achieves efficiency and robustness of robot’s locomotion and manipulation. The effectiveness of our framework has been evaluated through a set of robot dynamic simulations conducted in Webots. The robot can finish balance maintaining with moving arm, fixed point tracking while trotting, and locomotion over different obstacles with an end-point task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000507",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Gene",
      "Inertia",
      "Mobile robot",
      "Physics",
      "Robot",
      "Robot control",
      "Robustness (evolution)",
      "Simulation",
      "Thermodynamics",
      "Torque"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Aizhen"
      },
      {
        "surname": "Chen",
        "given_name": "Teng"
      },
      {
        "surname": "Rong",
        "given_name": "Xuewen"
      },
      {
        "surname": "Zhang",
        "given_name": "Guoteng"
      },
      {
        "surname": "Li",
        "given_name": "Yibin"
      },
      {
        "surname": "Fan",
        "given_name": "Yong"
      }
    ]
  },
  {
    "title": "Correct and efficient UAV missions based on temporal planning and in-flight hybrid simulations",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104404",
    "abstract": "Controller synthesis has been successfully applied in UAV applications, to construct a mission plan that is guaranteed to be correct with respect to a user-provided specification. Albeit being correct, these plans may not be optimal in the vehicle’s trajectory, battery consumption, or other criteria which the user may consider relevant. A possibility would be to apply a quantitative synthesis approach where the target is to compute efficient plans before the mission, at a higher cost of complexity and potential limitations in the optimization goals to achieve. As an alternative, in this paper we propose doing the plan optimization in-flight. For this, we use available tools that synthesize controllers with multiple controllable choices and later select among these choices in-flight using hybrid simulations ranking them according to the optimization objective. We present the advantages of our approach and validate them using software-in-the-loop simulation with typical UAV mission scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902300043X",
    "keywords": [
      "Agronomy",
      "Archaeology",
      "Artificial intelligence",
      "Astronomy",
      "Biology",
      "Computer science",
      "Controller (irrigation)",
      "Flight plan",
      "History",
      "Physics",
      "Plan (archaeology)",
      "Programming language",
      "Ranking (information retrieval)",
      "Real-time computing",
      "Software",
      "Trajectory",
      "Trajectory optimization"
    ],
    "authors": [
      {
        "surname": "Pecker-Marcosig",
        "given_name": "Ezequiel"
      },
      {
        "surname": "Zudaire",
        "given_name": "Sebastián"
      },
      {
        "surname": "Castro",
        "given_name": "Rodrigo"
      },
      {
        "surname": "Uchitel",
        "given_name": "Sebastián"
      }
    ]
  },
  {
    "title": "Fuzzy dynamical system for robot learning motion skills from human demonstration",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104406",
    "abstract": "Learning from demonstration (LfD) is an intuitive strategy for transferring human motion skills to robots in an agile and adaptable manner. The major goal of LfD is to identify significant movement primitives (MPs) from human demonstrations and then recompose those intrinsic primitives to adapt to a variety of new situations. However, maintaining the simplicity of MPs representation while guaranteeing their adaptability is not an easy undertaking. To achieve these two goals, two approaches are possible: (1) learning models that can capture and utilize the inherent patterns and main characteristics of the human demonstrations, and (2) dynamical systems that can respond to perturbations online without requiring to re-plan the entire trajectory. In this paper, we present a novel and efficient model that combines these two benefits to formulate MPs using a fuzzy dynamical system (Fuzzy-DS), which enables robots to adaptively alter the learned motion skills to meet various additional constraints in the process of performing tasks. Due to the joint use of a fuzzy inference system and a dynamic system, Fuzzy-DS is well-suited to human inputs and intuitive fuzzy rules, resulting in a computationally efficient model. To verify the effectiveness of the proposed method, experiments have been designed where the robot learned a plant pruning task and a pick-and-place task, subsequently, it can replicate and generalize these tasks to novel situations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000453",
    "keywords": [
      "Adaptability",
      "Agronomy",
      "Artificial intelligence",
      "Astronomy",
      "Biology",
      "Computer science",
      "Ecology",
      "Economics",
      "Fuzzy logic",
      "Human–computer interaction",
      "Law",
      "Machine learning",
      "Management",
      "Operating system",
      "Physics",
      "Political science",
      "Politics",
      "Process (computing)",
      "Pruning",
      "Representation (politics)",
      "Robot",
      "Task (project management)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Teng",
        "given_name": "Tao"
      },
      {
        "surname": "Gatti",
        "given_name": "Matteo"
      },
      {
        "surname": "Poni",
        "given_name": "Stefano"
      },
      {
        "surname": "Caldwell",
        "given_name": "Darwin"
      },
      {
        "surname": "Chen",
        "given_name": "Fei"
      }
    ]
  },
  {
    "title": "Teleoperation by seamless transitions in real and virtual world environments",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104405",
    "abstract": "This study investigates operability and acceptability issues in the teleoperation of robots. Prior studies have proposed efficient approaches to increase human perceptual ability and robot autonomy but with reduced operability and acceptance. We propose a novel teleoperation method that overcomes the weaknesses of existing approaches while inheriting their strengths. The key feature of our method is switching the teleoperated robot world from real to virtual. The user study results showed that the proposed method offered an improved user experience compared to the conventional methods, while task efficiency was equivalent in all methods. The contributions of this paper include the proposal of the teleoperation method by seamless switching between real and virtual space, the proposal of an image transformation method and visual effect to achieve seamless switching, and verification of the practicality of the proposed system through experiments on actual mobile robots.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000441",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Engineering",
      "Human–computer interaction",
      "Key (lock)",
      "Operability",
      "Real-time computing",
      "Robot",
      "Simulation",
      "Software engineering",
      "Systems engineering",
      "Task (project management)",
      "Teleoperation",
      "Virtual reality"
    ],
    "authors": [
      {
        "surname": "Aoki",
        "given_name": "Junki"
      },
      {
        "surname": "Sasaki",
        "given_name": "Fumihiro"
      },
      {
        "surname": "Yamashina",
        "given_name": "Ryota"
      },
      {
        "surname": "Kurazume",
        "given_name": "Ryo"
      }
    ]
  },
  {
    "title": "A vision-based virtual fixture with robot learning for teleoperation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104414",
    "abstract": "Teleoperation plays a key role for semi-automated tasks with high complexity in remote working environment. By integrating the interaction information and control strategy, the control performance can be guaranteed by the skilled operator manipulation in terms of stability and precision. However, due to a lack of prolonged specialized training, the manipulation characteristics, such as operation habits and tremor for green hands, the control performance of teleoperation cannot be guaranteed, especially for complicated and refined tasks. To this end, a vision-based virtual fixture with robot learning approach is proposed for teleoperation. In the proposed method, a dynamic movement primitives method is utilized to learn the human tutor or skilled operator manipulation skill and then generates the expert trajectories for training of green hands. Additionally, considering the instantaneity of manipulation, a vision-based virtual fixture is utilized to generate a force selector based on position error and provides a force guidance to the green hands in order to enhance the precision of control with expert level and reduce the operation pressure. Comparative experimental results demonstrated the performance of the developed approach for teleoperation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000532",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Engineering",
      "Fixture",
      "Gene",
      "Human–computer interaction",
      "Machine learning",
      "Mechanical engineering",
      "Operator (biology)",
      "Repressor",
      "Robot",
      "Simulation",
      "Stability (learning theory)",
      "Teleoperation",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Luo",
        "given_name": "Jing"
      },
      {
        "surname": "Liu",
        "given_name": "Weibin"
      },
      {
        "surname": "Qi",
        "given_name": "Wen"
      },
      {
        "surname": "Hu",
        "given_name": "Jianwen"
      },
      {
        "surname": "Chen",
        "given_name": "Junming"
      },
      {
        "surname": "Yang",
        "given_name": "Chenguang"
      }
    ]
  },
  {
    "title": "A memory system of a robot cognitive architecture and its implementation in ArmarX",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104415",
    "abstract": "Cognitive agents such as humans and robots perceive their environment through an abundance of sensors producing streams of data that need to be processed to generate intelligent behavior. A key question of cognition-enabled and AI-driven robotics is how to organize and manage such data and knowledge efficiently in a cognitive robot control architecture. We argue, that memory is a central active component of such architectures that mediates between semantic and sensorimotor representations, orchestrates the flow of data streams and events between different processes and provides the components of a cognitive architecture with data-driven services for learning semantics from sensorimotor data, the parametrization of symbolic plans for execution and prediction of action effects. Based on related work, and the experience gained in developing our ARMAR humanoid robot systems, we identified conceptual and technical requirements of a memory system as central component of cognitive robot control architecture that facilitate the realization of high-level cognitive abilities such as explaining, reasoning, prospection, simulation and augmentation. Conceptually, a memory should be active, support multi-modal data representations, associate knowledge, be introspective, and have an inherently episodic structure. Technically, the memory should support a distributed design, be access-efficient and capable of long-term data storage. We introduce the memory system for our cognitive robot control architecture and its implementation in the robot software framework ArmarX. We evaluate the efficiency of the memory system with respect to transfer speeds, compression, reproduction and prediction capabilities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000544",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Biology",
      "Cognition",
      "Cognitive architecture",
      "Cognitive science",
      "Computer architecture",
      "Computer science",
      "Human–computer interaction",
      "Neuroscience",
      "Psychology",
      "Robot",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Peller-Konrad",
        "given_name": "Fabian"
      },
      {
        "surname": "Kartmann",
        "given_name": "Rainer"
      },
      {
        "surname": "Dreher",
        "given_name": "Christian R.G."
      },
      {
        "surname": "Meixner",
        "given_name": "Andre"
      },
      {
        "surname": "Reister",
        "given_name": "Fabian"
      },
      {
        "surname": "Grotz",
        "given_name": "Markus"
      },
      {
        "surname": "Asfour",
        "given_name": "Tamim"
      }
    ]
  },
  {
    "title": "Design and analysis of an E-Puck2 robot plug-in for the ARGoS simulator",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104412",
    "abstract": "In this article we present a new plug-in for the ARGoS swarm robotic simulator to implement the E-Puck2 robot model, including its graphical representation, sensors and actuators. We have based our development on the former E-Puck robot model (version 1) by upgrading the existing sensors (proximity, light, ground, camera, and battery) and adding new ones (time of flight and simulated encoders) implemented from scratch. We have adapted the values produced by the proximity, light and ground sensors, including the E-Puck2’s onboard camera according to its resolution, and proposed four new discharge models for the battery. We have evaluated this new plug-in in terms of accuracy and efficiency through comparisons with real robots and extensive simulations. In all our experiments the proposed plug-in has worked well showing high levels of accuracy. The observed increment of execution times when using the studied sensors varies according to the number of robots and types of sensors included in the simulation, ranging from a negligible impact to 53% longer simulations in the most demanding cases.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000519",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Battery (electricity)",
      "Computer science",
      "Encoder",
      "Operating system",
      "Physics",
      "Plug-in",
      "Power (physics)",
      "Quantum mechanics",
      "Ranging",
      "Real-time computing",
      "Robot",
      "Simulation",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Stolfi",
        "given_name": "Daniel H."
      },
      {
        "surname": "Danoy",
        "given_name": "Grégoire"
      }
    ]
  },
  {
    "title": "A geometric optimal control approach for imitation and generalization of manipulation skills",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104413",
    "abstract": "Daily manipulation tasks are characterized by regular features associated with the task structure, which can be described by multiple geometric primitives related to actions and object shapes. Only using Cartesian coordinate systems cannot fully represent such geometric descriptors. In this article, we consider other candidate coordinate systems and propose a learning approach to extract the optimal representation of an observed movement/behavior from these coordinates. This is achieved by using an extension of Gaussian distributions on Riemannian manifolds, which is used to analyze a small set of user demonstrations statistically represented in different coordinate systems. We formulate the skill generalization as a general optimal control problem based on the (iterative) linear quadratic regulator ((i)LQR), where the Gaussian distribution in the proper coordinate systems is used to define the cost function. We apply our approach to object grasping and box-opening tasks in simulation and on a 7-axis Franka Emika robot using open-loop and feedback control, where precision matrices result in the automatic determination of feedback gains for the controller from very few demonstrations represented in multiple coordinate systems. The results show that the robot can exploit several geometries to execute the manipulation task and generalize it to new situations. The results show high variation along the do-not-matter direction, while maintaining the invariant characteristics of the task in the coordinate system(s) of interest. We then tested the approach in a human–robot shared control task. Results show that the robot can modify its grasping strategy based on the geometry of the object that the user decides to grasp.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000520",
    "keywords": [
      "Artificial intelligence",
      "Cartesian coordinate system",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Coordinate system",
      "Generalization",
      "Geometry",
      "Invariant (physics)",
      "Linear-quadratic regulator",
      "Mathematical analysis",
      "Mathematical physics",
      "Mathematics",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Ti",
        "given_name": "Boyang"
      },
      {
        "surname": "Razmjoo",
        "given_name": "Amirreza"
      },
      {
        "surname": "Gao",
        "given_name": "Yongsheng"
      },
      {
        "surname": "Zhao",
        "given_name": "Jie"
      },
      {
        "surname": "Calinon",
        "given_name": "Sylvain"
      }
    ]
  },
  {
    "title": "Pose accuracy improvement in robotic machining by visually-guided method and experimental investigation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104416",
    "abstract": "Industrial robots have been widely used in the industries of automotive, machining, electrical and electronic, rubber and plastics, aerospace, food, etc., owing to their high efficiency and flexibility in contrast to large scaled machining centers. However, the poor accuracy resulted from the serial configuration of industrial robots has restricted their applications to high-precision machining for several decades. In this paper, an error compensation technique is proposed using the visual guidance to effectively improve the pose accuracy of industrial robots. Firstly, the effect of the establishment method of tracking coordinate system for a visual sensor on the pose measurement error is analyzed and the establishment method is optimized. Next, a fuzzy PID controller is designed and integrated with a KUKA robot controller KRC via the KUKA robot sensor interface to guide the robot to the desired pose in real-time. Finally, experimental tests are implemented to validate the effectiveness of the proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000556",
    "keywords": [
      "Aerospace",
      "Aerospace engineering",
      "Agronomy",
      "Artificial intelligence",
      "Automotive industry",
      "Biology",
      "Bubble",
      "Compensation (psychology)",
      "Computer science",
      "Computer vision",
      "Control engineering",
      "Controller (irrigation)",
      "Engineering",
      "Flexibility (engineering)",
      "Industrial robot",
      "Interface (matter)",
      "Machining",
      "Mathematics",
      "Maximum bubble pressure method",
      "Mechanical engineering",
      "PID controller",
      "Parallel computing",
      "Psychoanalysis",
      "Psychology",
      "Robot",
      "Statistics",
      "Temperature control"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Bo"
      },
      {
        "surname": "Li",
        "given_name": "Yufei"
      },
      {
        "surname": "Tian",
        "given_name": "Wei"
      },
      {
        "surname": "Liao",
        "given_name": "Wenhe"
      }
    ]
  },
  {
    "title": "TRUSTS: A novel treadmill-based multifunctional testing system for performance evaluation of wheeled planetary exploration rover",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104408",
    "abstract": "This paper presents a novel treadmill-based multifunctional testing system (TRUSTS) to execute ground testing for wheeled planetary exploration rover (WPER) in both regular and extreme physical conditions before launching. The TRUSTS with specially-made components featuring compact structure and multifunctional testing items comprises a traction loading subsystem (TLS) and a treadmill-based resistance torque loading subsystem (TRTLS). The former offers the working modes including traction loading, position holding, and range limiting. The latter offers working modes including resistance torque loading and leader–follower tracking. By appropriately allocating the working modes of two subsystems, the TRUSTS is capable of conducting diverse testing items. The customized controllers for the TLS and the TRTLS are proposed to guarantee the operation performance of the TRUSTS in all testing items. Extensive experimental results on a Mars rover prototype in both regular and extreme physical conditions demonstrate that the devised TRUSTS could effectively executing trafficability and maneuverability as well as adaptability tests with reliable scenarios and satisfactory precisions of motion tracking and traction/torque loading, which makes the TRUSTS a favorable choice for comprehensive performance assessment of rover in simulant extraterrestrial environment.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000477",
    "keywords": [
      "Adaptability",
      "Biology",
      "Computer science",
      "Ecology",
      "Engineering",
      "Limiting",
      "Mechanical engineering",
      "Physics",
      "Simulation",
      "Thermodynamics",
      "Torque",
      "Traction (geology)"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Haitao"
      },
      {
        "surname": "Chen",
        "given_name": "Jian"
      },
      {
        "surname": "Pan",
        "given_name": "Dong"
      },
      {
        "surname": "Gao",
        "given_name": "Haibo"
      }
    ]
  },
  {
    "title": "Self-reconfiguration of PARTS: A parallel reconfiguration algorithm based on surface flow",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104417",
    "abstract": "In this paper, we present a parallel reconfiguration algorithm for shape-shifting modular robots with a triangular structure. The reconfiguration planning is based on partitioning the robot’s surface into source and sink sections for modules, using the largest common topology as a reference. Reconfiguration is realized by a synchronous surface flow of modules guided by the prior determination of module sources and sinks. Individual reconfiguration steps are carried out by a multi-step optimization framework, ensuring that intermediate configurations required for topology changes are valid and collision-free. With a configuration containing n modules, the algorithm completes the reconfiguration in O ( n ) reconfiguration steps and allows for a distributed and asynchronous hardware implementation. We demonstrate the performance of the proposed algorithm on multiple example configurations and compare the results to other reconfiguration approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000568",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Asynchronous communication",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Control reconfiguration",
      "Distributed computing",
      "Embedded system",
      "Mathematics",
      "Mobile robot",
      "Modular design",
      "Operating system",
      "Parallel computing",
      "Robot",
      "Robot control",
      "Self-reconfiguring modular robot",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Gerbl",
        "given_name": "Michael"
      },
      {
        "surname": "Gerstmayr",
        "given_name": "Johannes"
      }
    ]
  },
  {
    "title": "Force control of lightweight series elastic systems using enhanced disturbance observers",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104407",
    "abstract": "This paper analyzes the control challenges associated to lightweight series elastic systems in force control applications, showing that a low end-point inertia can lead to high sensitivity to environment uncertainties. Where mainstream force control methods fail, this paper proposes a control methodology to enhance the performance robustness of existing disturbance observers (DOBs). The approach is validated experimentally and successfully compared to basic control solutions and state of the art DOB approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000465",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Disturbance (geology)",
      "Engineering",
      "Gene",
      "Inertia",
      "Paleontology",
      "Physics",
      "Robustness (evolution)",
      "Series (stratigraphy)"
    ],
    "authors": [
      {
        "surname": "Calanca",
        "given_name": "Andrea"
      },
      {
        "surname": "Sartori",
        "given_name": "Enrico"
      },
      {
        "surname": "Maris",
        "given_name": "Bogdan"
      }
    ]
  },
  {
    "title": "Efficient reinforcement learning with least-squares soft Bellman residual for robotic grasping",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104385",
    "abstract": "Grasping control of intelligent robots has to deal with the difficulties of model uncertainties and nonlinearities. In this paper, we propose the Kernel-based Least-Squares Soft Bellman residual Actor–Critic (KLSAC) algorithm for robotic grasping. In the proposed approach, a novel linear temporal-difference learning algorithm using the least-squares soft Bellman residual (LS 2 BR) method is designed for policy evaluation. In addition, KLSAC adopts a sparse-kernel feature representation method based on approximate linear dependency (ALD) analysis to construct features for continuous state–action space. Compared with typical deep reinforcement learning algorithms, KLSAC has two main advantages: firstly, the critic module has the capacity for rapid convergence by computing the fixed point of the linear soft Bellman equation via the least-squares optimization method. Secondly, the kernel-based features construction approach only requires predefining the basic kernel function and can improve the generalization ability of KLSAC. The simulation studies on robotic grasping control were conducted in the V-REP simulator. The results demonstrate that compared with other typical RL algorithms (e.g., SAC and BMPO), the proposed KLSAC algorithm can achieve better performance in terms of sample efficiency and asymptotic convergence property. Furthermore, experimental results on a real UR5 robot validated that KLSAC performed well in the real world.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000246",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Estimator",
      "Generalization",
      "Kernel (algebra)",
      "Least-squares function approximation",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Reinforcement learning",
      "Residual",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Lan",
        "given_name": "Yixing"
      },
      {
        "surname": "Ren",
        "given_name": "Junkai"
      },
      {
        "surname": "Tang",
        "given_name": "Tao"
      },
      {
        "surname": "Xu",
        "given_name": "Xin"
      },
      {
        "surname": "Shi",
        "given_name": "Yifei"
      },
      {
        "surname": "Tang",
        "given_name": "Zixin"
      }
    ]
  },
  {
    "title": "Roboception and adaptation in a cognitive robot",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104400",
    "abstract": "In robotics, perception is usually oriented at understanding what is happening in the external world, while few works pay attention to what is occurring in the robot’s body. In this work, we propose an artificial somatosensory system, embedded in a cognitive architecture, that enables a robot to perceive the sensations from its embodiment while executing a task. We called these perceptions roboceptions, and they let the robot act according to its own physical needs in addition to the task demands. Physical information is processed by the robot to behave in a balanced way, determining the most appropriate trade-off between the achievement of the task and its well being. The experiments show the integration of information from the somatosensory system and the choices that lead to the accomplishment of the task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000398",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Cognition",
      "Cognitive science",
      "Computer science",
      "Human–computer interaction",
      "Neuroscience",
      "Psychology",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Augello",
        "given_name": "Agnese"
      },
      {
        "surname": "Gaglio",
        "given_name": "Salvatore"
      },
      {
        "surname": "Infantino",
        "given_name": "Ignazio"
      },
      {
        "surname": "Maniscalco",
        "given_name": "Umberto"
      },
      {
        "surname": "Pilato",
        "given_name": "Giovanni"
      },
      {
        "surname": "Vella",
        "given_name": "Filippo"
      }
    ]
  },
  {
    "title": "Cooperative Artificial Intelligence for underwater robotic swarm",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104410",
    "abstract": "Underwater Robots such as Autonomous Underwater Vehicles (AUVs) and Remotely Operated Vehicles (ROVs) has played an important role in many tasks, such as marine environmental monitoring, underwater resource exploration, oil and gas industries, hydrographic surveys, military missions, etc. Underwater robotic swarm is a team of cooperative underwater robots which focuses on controlling multiple underwater robots to work in an organic group. In contrast to a single underwater robot, underwater robotic swarm represents higher operation efficiency and better stability while executing complex tasks. However, it needs higher intelligence to realize complementary cooperation than a single robot. It is beneficial to researchers to present a comprehensive survey of the state of the art of cooperative research for underwater robotic swarm. We observe that the research of Artificial Intelligence (AI) for multiple underwater robots is still in an early stage. In this paper, we study different collaborative operation mode in detail, such as formation control, task allocation, path planning, obstacle avoidance, flocking control etc. We propose different classification frameworks for these research topics and it also can be used to compare different methods and help engineers choose suitable methods for various applications. To achieve better cooperative performance of underwater robots, there are several key factors, including multi-source heterogeneous sensing, cooperative communication and navigation, information fusion and decision. Moreover, cooperative AI for underwater robotic swarm has different kinds of interesting and helpful applications. Finally, several possible applied AI methods including meta-heuristic algorithms, deep learning method and distributed learning method are accomplishing to cooperation of underwater robotic swarm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000490",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Geology",
      "Machine learning",
      "Oceanography",
      "Particle swarm optimization",
      "Robot",
      "Swarm behaviour",
      "Swarm intelligence",
      "Swarm robotics",
      "Underwater"
    ],
    "authors": [
      {
        "surname": "Cai",
        "given_name": "Wenyu"
      },
      {
        "surname": "Liu",
        "given_name": "Ziqiang"
      },
      {
        "surname": "Zhang",
        "given_name": "Meiyan"
      },
      {
        "surname": "Wang",
        "given_name": "Chengcai"
      }
    ]
  },
  {
    "title": "Practical whole-body elasto-geometric calibration of a humanoid robot: Application to the TALOS robot",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104365",
    "abstract": "The whole-body elasto-geometrical calibration of humanoid robots is critical particularly for their control and accurate simulation. However, it is often not considered probably since it is a nontrivial task due to the mechanical complexity and inherent constraints of anthropomorphic structures. Also, humanoid robots have to sustain great efforts on their support legs, leading to link and joint being deformed, and are prone to auto-collision. Thus, elastic parameters have to be factored in addition to the geometric ones and to improve the precision of the pose of all robot segments. This is much more cumbersome and time consuming than the classical calibration of serial manipulators that deals solely with the estimation of the pose of the end-effector. Finally, due to the complexity of the task, a manual intervention in several steps of the calibration is no longer possible and a thorough automation of the approach is needed. Therefore, we propose to use a stereophotogrammetric system along with embedded joint torque sensors to calibrate the pose of all robot links with a fully automatic procedure. The generation of the minimal set of optimal calibration postures is based on a new iterative optimization process that leads to a stable maximum of an observability index. Then full set of geometrical parameters but also joint and base elastic parameters were calibrated using a single least-square optimization program. The proposed method was validated on a TALOS humanoid robot allowing to obtain an accurate whole-body calibration in less than 10 min. The proposed approach was cross-validated experimentally and showed an average RMS error of the tracked markers of 2.2 mm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000040",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Calibration",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Humanoid robot",
      "Mathematics",
      "Mobile robot",
      "Observability",
      "Programming language",
      "Robot",
      "Robot calibration",
      "Robot kinematics",
      "Set (abstract data type)",
      "Simulation",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Bonnet",
        "given_name": "Vincent"
      },
      {
        "surname": "Mirabel",
        "given_name": "Joseph"
      },
      {
        "surname": "Daney",
        "given_name": "David"
      },
      {
        "surname": "Lamiraux",
        "given_name": "Florent"
      },
      {
        "surname": "Gautier",
        "given_name": "Maxime"
      },
      {
        "surname": "Stasse",
        "given_name": "Olivier"
      }
    ]
  },
  {
    "title": "Robotic assembly strategy via reinforcement learning based on force and visual information",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104399",
    "abstract": "Since assembly tasks are frequently performed in a wide range of industries, there have been many efforts to develop robotic assembly strategies. However, robotic assembly is only applicable in structured environments wherein a target object is placed in a fixed position, because the occurrence of a large error substantially degrades performance. Thus, there is still a need for a generalized assembly strategy that can cope with a large position/orientation error regardless of the shape. To this end, this study presents an assembly strategy based on both the force and visual information. Specifically, the trajectory of the robot is obtained by combining the output of two neural-network-based trajectory generators that receive the force and image information, respectively, and then a deep reinforcement learning algorithm is applied to obtain the optimal strategy. In this process, imitation learning is applied to train the force-based network using the demonstration data collected with the suggested hand-guiding method, and the probability distribution of the feature is introduced in the image-based network to enable a robot to quickly adapt to assembly parts with different shapes. The performance of the proposed assembly strategy is experimentally verified using various peg-in-hole tasks, and the results confirm that the robot can successfully accomplish an assembly task regardless of the shapes of the assembly parts, even when the initial position/orientation error is large.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000386",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Computer science",
      "Computer vision",
      "Economics",
      "Feature (linguistics)",
      "Finance",
      "Geometry",
      "Linguistics",
      "Management",
      "Mathematics",
      "Operating system",
      "Orientation (vector space)",
      "Philosophy",
      "Physics",
      "Position (finance)",
      "Process (computing)",
      "Reinforcement learning",
      "Robot",
      "Task (project management)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Ahn",
        "given_name": "Kuk-Hyun"
      },
      {
        "surname": "Na",
        "given_name": "Minwoo"
      },
      {
        "surname": "Song",
        "given_name": "Jae-Bok"
      }
    ]
  },
  {
    "title": "Special Issue on the 10th European Conference on Mobile Robots (ECMR 2021)",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104380",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000192",
    "keywords": [
      "Adaptability",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Ecology",
      "Engineering",
      "Limiting",
      "Mechanical engineering",
      "Physics",
      "Robot",
      "Simulation",
      "Thermodynamics",
      "Torque",
      "Traction (geology)"
    ],
    "authors": [
      {
        "surname": "McCool",
        "given_name": "Chris"
      },
      {
        "surname": "Menegatti",
        "given_name": "Emanuele"
      },
      {
        "surname": "Behnke",
        "given_name": "Sven"
      }
    ]
  },
  {
    "title": "The XBot2 real-time middleware for robotics",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104379",
    "abstract": "This paper introduces XBot2, a novel real-time middleware for robotic applications with a strong focus on modularity and reusability of components, and seamless support for multi-threaded, mixed real-time (RT) and non-RT architectures. Compared to previous works, XBot2 focuses on providing a dynamic, ready-to-use hardware abstraction layer that allows users to make run-time queries about the robot topology, and act consequently, by leveraging an easy-to-use API that is fully RT-compatible. We provide an extensive description about implementation challenges and design decisions, and finally validate our architecture with multiple use-cases. These range from the integration of three popular simulation tools (i.e. Gazebo, PyBullet, and MuJoCo), to real-world tests involving complex, hybrid robotic platforms such as IIT’s CENTAURO and MoCA robots.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000180",
    "keywords": [
      "Abstraction",
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Biology",
      "Composite material",
      "Computer science",
      "Distributed computing",
      "Embedded system",
      "Epistemology",
      "Focus (optics)",
      "Genetics",
      "Materials science",
      "Middleware (distributed applications)",
      "Modularity (biology)",
      "Operating system",
      "Optics",
      "Philosophy",
      "Physics",
      "Range (aeronautics)",
      "Reusability",
      "Robot",
      "Robotics",
      "Software",
      "Software engineering",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Laurenzi",
        "given_name": "Arturo"
      },
      {
        "surname": "Antonucci",
        "given_name": "Davide"
      },
      {
        "surname": "Tsagarakis",
        "given_name": "Nikos G."
      },
      {
        "surname": "Muratore",
        "given_name": "Luca"
      }
    ]
  },
  {
    "title": "ArTuga: A novel multimodal fiducial marker for aerial robotics",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104398",
    "abstract": "For Vertical Take-Off and Landing Unmanned Aerial Vehicles (VTOL UAVs) to operate autonomously and effectively, it is mandatory to endow them with precise landing abilities. The UAV has to be able to detect the landing target and to perform the landing maneuver without compromising its own safety and the integrity of its surroundings. However, current UAVs do not present the required robustness and reliability for precise landing in highly demanding scenarios, particularly due to their inadequacy to perform accordingly under challenging lighting and weather conditions, including in day and night operations. This work proposes a multimodal fiducial marker, named ArTuga (Augmented Reality Tag for Unmanned vision-Guided Aircraft), capable of being detected by an heterogeneous perception system for accurate and precise landing in challenging environments and daylight conditions. This research combines photometric and radiometric information by proposing a real-time multimodal fusion technique that ensures a robust and reliable detection of the landing target in severe environments. Experimental results using a real multicopter UAV show that the system was able to detect the proposed marker in adverse conditions (such as at different heights, with intense sunlight and in dark environments). The obtained average accuracy for position estimation at 1 m height was of 0.0060 m with a standard deviation of 0.0003 m. Precise landing tests obtained an average deviation of 0.027 m from the proposed marker, with a standard deviation of 0.026 m. These results demonstrate the relevance of the proposed system for the precise landing in adverse conditions, such as in day and night operations with harsh weather conditions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000374",
    "keywords": [
      "Adverse weather",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Daylight",
      "Fiducial marker",
      "Gene",
      "Mathematics",
      "Meteorology",
      "Optics",
      "Physics",
      "Real-time computing",
      "Robot",
      "Robotics",
      "Robustness (evolution)",
      "Simulation",
      "Standard deviation",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Claro",
        "given_name": "Rafael Marques"
      },
      {
        "surname": "Silva",
        "given_name": "Diogo Brandão"
      },
      {
        "surname": "Pinto",
        "given_name": "Andry Maykol"
      }
    ]
  },
  {
    "title": "Model predictive optimization for imitation learning from demonstrations",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104381",
    "abstract": "“Motion generation by imitating” enables a robot to generate its trajectory in a new environment. Research works on dynamic movement primitives (DMP) has reported promising results, with good imitation effect and convergence to the target. However, DMP still has issues such as learning from multiple demonstrations for different initial conditions and achieving obstacle avoidance considering the distribution and motion of obstacles. One of the effective solutions is combining DMP and model predictive control (MPC). The imitation process was transformed into a receding horizon planning procedure, letting the robot to learn more from nearer demonstrations. It is solved as an optimization problem with obstacles modeled as constraints. However, its drawback includes the heavy computation burden, which can be even aggravated in a multi-obstacle scenario where complicated constraints occur. Thus, in this paper, we propose an enhanced MPDMP+ method that combines the advantages of MPC with potential function for both multi-demonstration imitation and multi-obstacle avoidance effect. A proximal augmented Lagrangian method is proposed to solve the optimization problem. This proposed method has a faster convergence rate and small errors. We conducted the simulation and robot experiments for imitation learning for obstacle avoidance scenarios. Our results illustrate the superior performance of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000209",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Benchmark (surveying)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Geodesy",
      "Geography",
      "Imitation",
      "Law",
      "Mathematical optimization",
      "Mathematics",
      "Mobile robot",
      "Motion planning",
      "Obstacle",
      "Obstacle avoidance",
      "Operating system",
      "Optimal control",
      "Physics",
      "Political science",
      "Process (computing)",
      "Psychology",
      "Robot",
      "Social psychology",
      "Trajectory",
      "Trajectory optimization"
    ],
    "authors": [
      {
        "surname": "Hu",
        "given_name": "Yingbai"
      },
      {
        "surname": "Cui",
        "given_name": "Mingyang"
      },
      {
        "surname": "Duan",
        "given_name": "Jianghua"
      },
      {
        "surname": "Liu",
        "given_name": "Wenjun"
      },
      {
        "surname": "Huang",
        "given_name": "Dianye"
      },
      {
        "surname": "Knoll",
        "given_name": "Alois"
      },
      {
        "surname": "Chen",
        "given_name": "Guang"
      }
    ]
  },
  {
    "title": "Safe deep learning-based global path planning using a fast collision-free path generator",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104384",
    "abstract": "In this research, a global path planning method based on recurrent neural networks by means of a new Loss function is presented, which regardless of the complexity of the configuration space, generates the path in a relatively constant time. The new Loss function is defined in such a way that in addition to learning the input data of the network, it creates an adjustable safety margin around the obstacles and ultimately creates a safe path. Moreover, a new global path planning method is also introduced, which is used to create the dataset required to train the proposed neural network. The convergence of this method is mathematically proven and it is shown that this method can also produce a suboptimal path in a much shorter time than the common methods of global path planning reported in the literature. In short, the main purpose of this research consists in providing a method which can create a suboptimal, fast and safe path for a mobile robot from any random starting point to any random destination in a known environment. First, the proposed methods will be implemented for different two-dimensional environments consisting of convex and non-convex obstacles, considering the robot as a point-mass, and then it will be implemented in a simulation environment, AI2THOR. Compared to classical global path planning algorithms, such as RRT and A*, the proposed approach demonstrates better performance in complex and challenging environments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000234",
    "keywords": [
      "Any-angle path planning",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer network",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Fast path",
      "Function (biology)",
      "Generator (circuit theory)",
      "Machine learning",
      "Margin (machine learning)",
      "Mathematical optimization",
      "Mathematics",
      "Motion planning",
      "Path (computing)",
      "Path length",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Real-time computing",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Chehelgami",
        "given_name": "Shirin"
      },
      {
        "surname": "Ashtari",
        "given_name": "Erfan"
      },
      {
        "surname": "Basiri",
        "given_name": "Mohammad Amin"
      },
      {
        "surname": "Tale Masouleh",
        "given_name": "Mehdi"
      },
      {
        "surname": "Kalhor",
        "given_name": "Ahmad"
      }
    ]
  },
  {
    "title": "Using model checking to formally verify rendezvous algorithms for robots with lights in Euclidean space",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104378",
    "abstract": "The paper details the first successful attempt at using model checking techniques to verify the correctness of distributed algorithms for robots evolving in a continuous environment. The study focuses on the problem of rendezvous of two robots with lights. There exist many different rendezvous algorithms that aim at finding the minimal number of colors needed to solve rendezvous in various synchrony models (e.g., FSYNC, SSYNC, ASYNC). While these rendezvous algorithms are typically very simple, their analysis and proof of correctness tend to be extremely complex, tedious, and error-prone as impossibility results are based on subtle interactions between the activation schedules of the robots. The paper presents a generic verification model that can be concretely expressed in available software model-checkers. In particular, we explain the subtle design decisions that allow to keep the search space finite and tractable, as well as prove several important theorems that support them. As a sanity check, we use the model to verify several known rendezvous algorithms in six different models of synchrony. In each case, we find that the results obtained from the model checker are consistent with the results known in the literature. The model checker outputs a counter-example execution in every case that is known to fail. In the course of developing and proving the validity of the model, we identified several fundamental theorems, including the ability for a well chosen algorithm and ASYNC scheduler to produce an emerging property of memory in a system of oblivious mobile robots, and why it is not a problem when robots executing the gathering algorithms are equipped with lights.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000179",
    "keywords": [
      "Aerospace engineering",
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Correctness",
      "Engineering",
      "Epistemology",
      "Impossibility",
      "Law",
      "Model checking",
      "Philosophy",
      "Political science",
      "Rendezvous",
      "Robot",
      "Simple (philosophy)",
      "Spacecraft",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Défago",
        "given_name": "Xavier"
      },
      {
        "surname": "Heriban",
        "given_name": "Adam"
      },
      {
        "surname": "Tixeuil",
        "given_name": "Sébastien"
      },
      {
        "surname": "Wada",
        "given_name": "Koichi"
      }
    ]
  },
  {
    "title": "Heel-strike and toe-off walking of humanoid robot using quadratic programming considering the foot contact states",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104396",
    "abstract": "Heel-strike and toe-off (heel-toe) walking has been studied to increase step length, reduce the torque of the leg joints, or make robots walk similarly to humans. To realize heel-toe walking, it is necessary to determine the foot angle and ensure contact between the ground and the heel and toe. The foot angle for heel-toe walking can be analytically calculated considering the position of the center of mass (CoM) before the foot lands or rises. Therefore, the trajectory of the CoM of one cycle of walking must be known in advance. However, this method cannot be easily incorporated with model predictive control (MPC) to generate the trajectory of CoM in real time. This paper proposes a heel-toe walking method that can be used with the CoM trajectory generated using the MPC scheme. The CoM trajectory generation method that reduced the velocity fluctuation using MPC, which was proposed in a previous study, was used. The stability of the MPC scheme is proved in this paper. The quadratic programming is used to generate the heel-toe walking by considering the foot contact states as the constraints. The increase in step length and the decrease in singularity occurrence due to heel-toe walking were compared and analyzed in the simulation. The experiment verified the proposed heel-toe method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000350",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Economics",
      "Engineering",
      "Finance",
      "Gait",
      "Ground reaction force",
      "Heel",
      "Humanoid robot",
      "Kinematics",
      "Mathematical optimization",
      "Mathematics",
      "Medicine",
      "Physical medicine and rehabilitation",
      "Physics",
      "Position (finance)",
      "Quadratic programming",
      "Robot",
      "Sequential quadratic programming",
      "Simulation",
      "Structural engineering",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Park",
        "given_name": "Beomyeong"
      },
      {
        "surname": "Park",
        "given_name": "Jaeheung"
      }
    ]
  },
  {
    "title": "Iterative reward shaping for non-overshooting altitude control of a wing-in-ground craft based on deep reinforcement learning",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104383",
    "abstract": "When a wing-in-ground craft (WIG) adjusts its flying altitude, overshooting behavior may occur, which weakens the safety and stealth ability. In previous studies on path following, cross-track error was used in company with other indicators to indirectly suppress overshoot. This paper proposes a method for direct and gradual suppression of the overshoot via deep reinforcement learning (DRL), which iterates the reward function by introducing a partial one based on the current overshoot magnitude. Each time the overshoot is obtained by DRL, a function about this overshoot is added to the reward function for retraining. The function is defined as a type of cross-track error within a range of the current overshoot magnitude to the target altitude, and it counts the partial reward before the WIG gets the worse overshoot during training. The methodological feasibility is proved by mathematical reasoning, and an example of a virtual WIG changing the altitude is taken to validate the method. Assuming that the added partial function is in a basic 1-order fractional form of cross-track error and multiplied by a factor, the implementation of iterative reward shaping decreases overshoot to a minimal level, with the overshoot down to over 99.8% when compared to the initial one. Moreover, when introducing the partial reward function in the first iteration, influence of the factor on overshoot is analyzed. For a WIG’s adjustment of altitude, the method can monotonically reduce overshoot within tolerance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000222",
    "keywords": [
      "Aerospace engineering",
      "Altitude (triangle)",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Geometry",
      "Mathematics",
      "Overshoot (microwave communication)",
      "Range (aeronautics)",
      "Reinforcement learning",
      "Simulation",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Hu",
        "given_name": "Huan"
      },
      {
        "surname": "Zhang",
        "given_name": "Guiyong"
      },
      {
        "surname": "Ding",
        "given_name": "Lichao"
      },
      {
        "surname": "Jiao",
        "given_name": "Kuikui"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhifan"
      },
      {
        "surname": "Zhang",
        "given_name": "Ji"
      }
    ]
  },
  {
    "title": "Mission specification and decomposition for multi-robot systems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104386",
    "abstract": "Service robots are increasingly being used to perform missions comprising dangerous or tedious tasks previously executed by humans. However, their users—who know the environment and requirements for these missions—have limited or no robotics experience. As such, they often find the process of allocating concrete tasks to each robot within a multi-robot system (MRS) very challenging. Our paper introduces a framework for Multi-Robot mission Specification and decomposition (MutRoSe) that simplifies and automates key activities of this process. To that end, MutRoSe allows an MRS mission designer to define all relevant aspects of a mission and its environment in a high-level specification language that accounts for the variability of real-world scenarios, the dependencies between task instances, and the reusability of task libraries. Additionally, MutRoSe automates the decomposition of MRS missions defined in this language into task instances, which can then be allocated to specific robots for execution—with all task dependencies appropriately taken into account. We illustrate the application of MutRoSe and show its effectiveness for four missions taken from a recently published repository of MRS applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000258",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Decomposition",
      "Ecology",
      "Economics",
      "Economy",
      "Engineering",
      "Human–computer interaction",
      "Key (lock)",
      "Operating system",
      "Process (computing)",
      "Programming language",
      "Reusability",
      "Robot",
      "Robotics",
      "Service (business)",
      "Software",
      "Software engineering",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Gil",
        "given_name": "Eric Bernd"
      },
      {
        "surname": "Rodrigues",
        "given_name": "Genaína Nunes"
      },
      {
        "surname": "Pelliccione",
        "given_name": "Patrizio"
      },
      {
        "surname": "Calinescu",
        "given_name": "Radu"
      }
    ]
  },
  {
    "title": "Specification, stochastic modeling and analysis of interactive service robotic applications",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104387",
    "abstract": "Assistive robotic systems are quickly becoming a core technology for the service sector as they are understood capable of supporting people in need of assistance in a wide variety of tasks. This step poses a number of ethical and technological questions. The research community is wondering how service robotics can be a step forward in human care and aid, and how robotics applications can be realized in order to put the human role at the forefront. Therefore, there is a growing demand for frameworks supporting robotic application designers in a “human-aware” development process. This paper presents a model-driven framework for analyzing and developing human–robot interactive scenarios in non-industrial settings with significant sources of uncertainty. The framework’s core is a formal model of the agents at play – the humans and the robot – and the robot’s mission, which is then put through verification to estimate the probability of completing the mission. The model captures non-trivial features related to human behavior, specifically the unpredictability of human choices and physiological aspects tied to their state of health. To foster the framework’s accessibility, we present a verification tool-agnostic Domain-Specific Language that allows designers lacking expertise in formal modeling to configure the interactive scenarios in a user-friendly manner. We compare the formal analysis outputs with results obtained by deploying benchmark scenarios in the physical environment with a real mobile robot to assess whether the formal model adheres to reality and whether the verification results are accurate. The entire development pipeline is then tested on several scenarios from the healthcare setting to assess its flexibility and effectiveness in the application design process.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902300026X",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Economics",
      "Economy",
      "Geodesy",
      "Geography",
      "Human–computer interaction",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pipeline (software)",
      "Process (computing)",
      "Programming language",
      "Robot",
      "Robotic paradigms",
      "Robotics",
      "Service (business)",
      "Service robot",
      "Software engineering",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Lestingi",
        "given_name": "Livia"
      },
      {
        "surname": "Zerla",
        "given_name": "Davide"
      },
      {
        "surname": "Bersani",
        "given_name": "Marcello M."
      },
      {
        "surname": "Rossi",
        "given_name": "Matteo"
      }
    ]
  },
  {
    "title": "Parallel multi-speed Pursuit-Evasion Game algorithms",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104382",
    "abstract": "Pursuit-Evasion Game (PEG) consists of a team of pursuers trying to capture one or more evaders. PEG is important due to its application in surveillance, search and rescue, disaster robotics, boundary defense and so on. In general, PEG requires exponential time to compute the minimum number of pursuers to capture an evader. To mitigate this, we have designed a parallel optimal algorithm to minimize the capture time in PEG. Given a discrete topology, this algorithm also outputs the minimum number of pursuers to capture an evader. We also extended parallel algorithm to consider other versions as: heterogeneous/multi-speed players; the pac-dot technique to increase evader lifetime in a game; and a pruning strategy for pac-dot technique to increase the scalability. The parallel algorithm performance was evaluated by speedup metric and this algorithm and its extensions were simulated and evaluated on many different topologies to validate the viability of our algorithms by discussing and evaluating a set of simulation results. The parallel algorithm enables us to scale up to 8.13 times with 8 cores compared to state-of-the-art. Considering the complexity of the state space growing up, pruning technique to pac-dot algorithm minimizes the state space and generated transition, and can handle a large number of states ( ≈ 830 M ) and transitions ( ≈ 11 G ) generated. In general, our algorithms increase the scalability and make it feasible to compute the PEG optimal strategy for more realistic cases.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000210",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Biology",
      "Computer science",
      "Database",
      "Parallel computing",
      "Pruning",
      "Scalability",
      "Speedup"
    ],
    "authors": [
      {
        "surname": "dos Santos",
        "given_name": "Renato F."
      },
      {
        "surname": "Ramachandran",
        "given_name": "Ragesh K."
      },
      {
        "surname": "Vieira",
        "given_name": "Marcos A.M."
      },
      {
        "surname": "Sukhatme",
        "given_name": "Gaurav S."
      }
    ]
  },
  {
    "title": "Kinematics optimization of a novel 7-DOF redundant manipulator",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104377",
    "abstract": "Redundant manipulators can accomplish complex tasks due to the redundant degree of freedom (DOF). At the same time, their kinematics calculations are complicated. In this study, the kinematics solution for a self-designed 7-DOF redundant anthropomorphic manipulator is obtained, and an optimization method is provided to optimize the motion time of the manipulator in the same trajectory. Kinematics analysis of the spherical parallel shoulder joint was performed by using a geometric method and coordinate transformation. Kinematics analysis of the redundant manipulator was performed by a geometric method with an optimizing arm angle. Linearly decreasing weight particle swarm optimization (LDWPSO) was used to optimize the arm angle to minimize the motion time of the manipulator. The kinematics calculation of the shoulder joint was verified by a combination of SOLIDWORKS T M and MATLAB T M software. The kinematics calculation of the redundant manipulator was verified by MATLAB T M . The linear, circular and 8-shaped motion trajectories were used to evaluate the proposed method in the simulation. The simulation results showed that the motion time with optimization of the arm angle was only 16%–30% of that without optimization. Furthermore, the proposed method was evaluated through real manipulator experiments, and the experimental results were similar to those in the simulation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000167",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Astronomy",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Forward kinematics",
      "Inverse kinematics",
      "Kinematics",
      "Parallel manipulator",
      "Particle swarm optimization",
      "Physics",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Yanlin"
      },
      {
        "surname": "Zhang",
        "given_name": "Xianmin"
      },
      {
        "surname": "Huang",
        "given_name": "Yanjiang"
      },
      {
        "surname": "Wu",
        "given_name": "Yanbin"
      },
      {
        "surname": "Ota",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Hierarchical mixture of experts for autonomous unmanned aerial vehicles utilizing thrust models and acoustics",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104369",
    "abstract": "Accurate position, velocity, attitude, and angular velocity state estimation is crucial for unmanned aerial vehicles, especially in enabling them with autonomous capabilities. It is necessary to adequately model and account for all the environmental and dynamic flight parameters. A hierarchical mixture of experts (HME) framework has been viable in improving state estimation accuracy in interplanetary orbit determination problems, and this paper proposes an extension for quadcopters. It is shown that the state and motor angular velocity estimation accuracy can be significantly improved by processing different thrust models, and acoustic parameters have an important, previously unreported, role in this improvement. Higher motor angular velocities produce higher noise levels, and thus, the relationships of the onboard acoustic measurements to the vehicle state parameters play an essential part in estimation. The motor angular velocities’ estimations depend on the extended Kalman filter solutions or an acoustic curve fit. The experts in the HME framework utilize the state estimation solutions from the extended Kalman filters and the motor angular velocity estimations to compare against the telemetry data as truth. The overall HME solution is compared against a non-acoustic static thrust model. Illustrative examples and analysis presented in this paper reveal that the proposed estimation solutions can also apply to other flight vehicles for onboard real-time implementation to leverage autonomy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000088",
    "keywords": [
      "Acoustics",
      "Aerospace engineering",
      "Angular velocity",
      "Artificial intelligence",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Extended Kalman filter",
      "Kalman filter",
      "Leverage (statistics)",
      "Physics",
      "Quantum mechanics",
      "Simulation",
      "Thrust"
    ],
    "authors": [
      {
        "surname": "Kawamura",
        "given_name": "Evan"
      },
      {
        "surname": "Azimov",
        "given_name": "Dilmurat"
      },
      {
        "surname": "Allen",
        "given_name": "John S."
      },
      {
        "surname": "Ippolito",
        "given_name": "Corey"
      }
    ]
  },
  {
    "title": "Distributed control for a robotic swarm to pass through a curve virtual tube",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104368",
    "abstract": "To guide a robotic swarm in a cluttered environment, a curve virtual tube is designed in this paper. There is no obstacle within the curve virtual tube, and the area inside can be seen as a safety zone. Then, a distributed swarm controller is proposed with three elaborate control terms. Formal analyses and proofs show that the curve virtual tube passing-through control problem can be solved in a finite time. For convenience in practical use, a modified controller with an approximate control performance is put forward. Some control laws for different types of robots to track their vector fields are also presented. The effectiveness of the proposed method is validated by numerical simulations and real experiments. To show the advantages of the proposed method, the comparisons between our method and other methods are also presented.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000076",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Engineering",
      "Geometry",
      "Law",
      "Mathematical proof",
      "Mathematics",
      "Mechanical engineering",
      "Mobile robot",
      "Obstacle",
      "Obstacle avoidance",
      "Operating system",
      "Political science",
      "Robot",
      "Simulation",
      "Swarm behaviour",
      "Tube (container)",
      "Virtual machine"
    ],
    "authors": [
      {
        "surname": "Quan",
        "given_name": "Quan"
      },
      {
        "surname": "Gao",
        "given_name": "Yan"
      },
      {
        "surname": "Bai",
        "given_name": "Chenggang"
      }
    ]
  },
  {
    "title": "A causal-based approach to explain, predict and prevent failures in robotic tasks",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104376",
    "abstract": "Robots working in human environments need to adapt to unexpected changes to avoid failures. This is an open and complex challenge that requires robots to timely predict and identify the causes of failures in order to prevent them. In this paper, we present a causal-based method that will enable robots to predict when errors are likely to occur and prevent them from happening by executing a corrective action. Our proposed method is able to predict immediate failures and also failures that will occur in the future. The latter type of failure is very challenging, and we call them timely-shifted action failures (e.g., the current action was successful but will negatively affect the success of future actions). First, our method detects the cause–effect relationships between task executions and their consequences by learning a causal Bayesian network (BN). The obtained model is transferred from simulated data to real scenarios to demonstrate the robustness and generalization of the obtained models. Based on the causal BN, the robot can predict if and why the executed action will succeed or not in its current state. Then, we introduce a novel method that finds the closest success state through a contrastive Breadth-First-Search if the current action was predicted to fail. We evaluate our approach for the problem of stacking cubes in two cases; (a) single stacks (stacking one cube) and; (b) multiple stacks (stacking three cubes). In the single-stack case, our method was able to reduce the error rate by 97%. We also show that our approach can scale to capture various actions in one model, allowing us to measure the impact of an imprecise stack of the first cube on the stacking success of the third cube. For these complex situations, our model was able to prevent around 95% of the stacking errors. Thus, demonstrating that our method is able to explain, predict, and prevent execution failures, which even scales to complex scenarios that require an understanding of how the action history impacts future actions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000155",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Bayesian network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Economics",
      "Gene",
      "Generalization",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Robot",
      "Robustness (evolution)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Diehl",
        "given_name": "Maximilian"
      },
      {
        "surname": "Ramirez-Amaro",
        "given_name": "Karinne"
      }
    ]
  },
  {
    "title": "Online task segmentation by merging symbolic and data-driven skill recognition during kinesthetic teaching",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104367",
    "abstract": "Programming by Demonstration (PbD) is used to transfer a task from a human teacher to a robot, where it is of high interest to understand the underlying structure of what has been demonstrated. Such a demonstrated task can be represented as a sequence of so-called actions or skills. This work focuses on the recognition part of the task transfer. We propose a framework that recognizes skills online during a kinesthetic demonstration by means of position and force–torque (wrench) sensing. Therefore, our framework works independently of visual perception. The recognized skill sequence constitutes a task representation that lets the user intuitively understand what the robot has learned. The skill recognition algorithm combines symbolic skill segmentation, which makes use of pre- and post-conditions, and data-driven prediction, which uses support vector machines for skill classification. This combines the advantages of both techniques, which is inexpensive evaluation of symbols and usage of data-driven classification of complex observations. The framework is thus able to detect a larger variety of skills, such as manipulation and force-based skills that can be used in assembly tasks. The applicability of our framework is proven in a user study that achieves a 96% accuracy in the online skill recognition capabilities and highlights the benefits of the generated task representation in comparison to a baseline representation. The results show that the task load could be reduced, trust and explainability could be increased, and, that the users were able to debug the robot program using the generated task representation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000064",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Debugging",
      "Developmental psychology",
      "Economics",
      "Human–computer interaction",
      "Kinesthetic learning",
      "Law",
      "Machine learning",
      "Management",
      "Political science",
      "Politics",
      "Programming by demonstration",
      "Programming language",
      "Psychology",
      "Representation (politics)",
      "Robot",
      "Segmentation",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Eiband",
        "given_name": "Thomas"
      },
      {
        "surname": "Liebl",
        "given_name": "Johanna"
      },
      {
        "surname": "Willibald",
        "given_name": "Christoph"
      },
      {
        "surname": "Lee",
        "given_name": "Dongheui"
      }
    ]
  },
  {
    "title": "Rendering the Directional TSDF for Tracking and Multi-Sensor Registration with Point-To-Plane Scale ICP",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104337",
    "abstract": "Dense real-time tracking and mapping from RGB-D images is an important tool for many robotic applications, such as navigation and manipulation. The recently presented Directional Truncated Signed Distance Function (DTSDF) is an augmentation of the regular TSDF that shows potential for more coherent maps and improved tracking performance. In this work, we present methods for rendering depth- and color images from the DTSDF, making it a true drop-in replacement for the regular TSDF in established trackers. We evaluate the algorithm on well-established datasets and observe that our method improves tracking performance and increases re-usability of mapped scenes. Furthermore, we add color integration which notably improves color-correctness at adjacent surfaces. Our novel formulation of combined ICP with frame-to-keyframe photometric error minimization further improves tracking results. Lastly, we introduce Sim (3) point-to-plane ICP for refining pose priors in a multi-sensor scenario with different scale factors.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002263",
    "keywords": [
      "Artificial intelligence",
      "Cartography",
      "Computer graphics (images)",
      "Computer science",
      "Computer vision",
      "Geography",
      "Geometry",
      "Mathematics",
      "Pedagogy",
      "Point (geometry)",
      "Psychology",
      "Rendering (computer graphics)",
      "Scale (ratio)",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Splietker",
        "given_name": "Malte"
      },
      {
        "surname": "Behnke",
        "given_name": "Sven"
      }
    ]
  },
  {
    "title": "Smart agriculture: Development of a skid-steer autonomous robot with advanced model predictive controllers",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104364",
    "abstract": "The agricultural domain has been experiencing extensive automation interest over the past decade. The established process for measuring physiological and morphological traits (phenotypes) of crops is labour-intensive and error-prone. In this paper, a mobile robotic platform, namely The Autonomous Robot for Orchard Surveying (AROS), was developed to automate the process of collecting spatial and visual data autonomously. Furthermore, six different control frameworks are presented to evaluate the feasibility of using a kinematic model in agricultural environments. The kinematic model does not consider wheel slippage or any forces associated with dynamic motion. Thus, the following six controllers are evaluated: Proportional-Derivative (PD) controller, Sliding Mode Controller (SMC), Control-Lyapunov Function (CLF), Nonlinear Model Predictive Controller (NMPC), Tube-Based Nonlinear Model Predictive Controller (TBNMPC), and Model Predictive Sliding Mode Control (MPSMC). This paper provides insight into the degree of disturbance rejection that the mentioned control architectures can achieve in outdoor environments. Experimental results validate that all control architectures are capable of rejecting the present disturbances associated with unmodelled dynamics and wheel slip on soft ground conditions. Additionally, the optimal-based controllers managed to perform better than the non-optimal controllers. Performance improvements of the TBNMPC of up to 209.72% are realized when compared to non-optimal methods. Results also show that the non-optimal controllers had low performance due to the underactuated constraint present in the kinematic model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000039",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Engineering",
      "Kinematics",
      "Lyapunov function",
      "Model predictive control",
      "Nonlinear system",
      "PID controller",
      "Physics",
      "Quantum mechanics",
      "Temperature control"
    ],
    "authors": [
      {
        "surname": "Wen Zhu",
        "given_name": "Cesar"
      },
      {
        "surname": "Hill",
        "given_name": "Elyse"
      },
      {
        "surname": "Biglarbegian",
        "given_name": "Mohammad"
      },
      {
        "surname": "Gadsden",
        "given_name": "S. Andrew"
      },
      {
        "surname": "Cline",
        "given_name": "John A."
      }
    ]
  },
  {
    "title": "Precision fingertip grasp: A human-inspired grasp planning and inverse kinematics approach for integrated arm–hand systems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104348",
    "abstract": "In this paper, we present a human-inspired approach to solve grasp planning and inverse kinematics (IK) problems, simultaneously. Our proposed solution is for integrated arm–hand systems. Conventional approaches consider the robot manipulator (arm) and the robotic hand separately and solve the problems of grasp planning and IK in sequence. Such separate considerations of the arm and hand often introduce errors in the IK solution. The sequential approaches waste significant computational power in searching for infeasible grasps. To address these issues, we propose to consider the robotic arm and the hand as a kinematically integrated system. We then introduce a coarse-to-fine strategy to solve grasp planning and IK problems simultaneously. The proposed approach achieves force-closure fingertip grasping without using reachability information a priori. Instead, through an integrated grasp planning and IK solution, the reachability information is obtained from the IK solution and is used to filter out infeasible grasps. This strategy will dramatically reduce the search space and save significant computational power. Numerical examples will be used to demonstrate the efficiency of the proposed approach, in comparison to a sequential solution of the grasp planning and IK for integrated arm–hand systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002378",
    "keywords": [
      "A priori and a posteriori",
      "Algorithm",
      "Artificial intelligence",
      "Classical mechanics",
      "Computer science",
      "Epistemology",
      "GRASP",
      "Kinematics",
      "Motion planning",
      "Philosophy",
      "Physics",
      "Programming language",
      "Reachability",
      "Robot",
      "Robotic arm",
      "Workspace"
    ],
    "authors": [
      {
        "surname": "Qiu",
        "given_name": "Shuwei"
      },
      {
        "surname": "Kermani",
        "given_name": "Mehrdad R."
      }
    ]
  },
  {
    "title": "Energy efficient path planning for autonomous ground vehicles with ackermann steering",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104366",
    "abstract": "The autonomous ground vehicles have attracted a great deal of attention as viable solutions to a wide variety of military and civilian applications. However, the energy consumption plays a major role in the navigation of autonomous ground vehicles in challenging environments, especially if they are left to operate unattended under limited on-board power, such as planetary exploration, border patrol, etc. The autonomous ground vehicles are expected to perform more tasks more efficiently with limited power in these scenarios. Although plenty of research has developed an effective methodology for generating dynamically feasible and energy efficient trajectories for skid steering or differential steering vehicles, few studies on path planning for ackermann steering autonomous ground vehicles are available. In this study, an energy efficient path planning method with guarantee on completeness is proposed for autonomous ground vehicle with ackermann steering which is based on A ∗ search algorithm. Firstly, the energy cost model is established for the autonomous ground vehicle using its kinematic constraints. Then, given the start and goal states, the energy-aware motion primitives are generated offline using the energy cost model to calculate the cost of each primary trajectory. Lastly, the energy efficient path planner is proposed and the analysis for completeness properties is given. The effectiveness of the proposed energy efficient path planner is verified by simulation over 150 randomly generated maps and real vehicle tests. The results show that a small increase in the distance of a path over the distance optimal path can result in a reduction of energy cost by nearly 26.9% in simulation and 21.09% in real test scenario for autonomous ground vehicles with ackermann steering.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000052",
    "keywords": [
      "Ackermann function",
      "Artificial intelligence",
      "Computer network",
      "Computer science",
      "Energy (signal processing)",
      "Geometry",
      "Inverse",
      "Mathematics",
      "Motion planning",
      "Path (computing)",
      "Physics",
      "Quantum mechanics",
      "Robot",
      "Simulation"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Haojie"
      },
      {
        "surname": "Zhang",
        "given_name": "Yudong"
      },
      {
        "surname": "Liu",
        "given_name": "Chuankai"
      },
      {
        "surname": "Zhang",
        "given_name": "Zuoyu"
      }
    ]
  },
  {
    "title": "Seeking at-home long-term autonomy of assistive mobile robots through the integration with an IoT-based monitoring system",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104346",
    "abstract": "In this paper, we propose a system that stems from the integration of an autonomous mobile robot with an IoT-based monitoring system to provide monitoring, assistance, and stimulation to older adults living alone in their own houses. The creation of an Internet of Robotics Things (IoRT) based on the interplay between pervasive smart objects and autonomous robotic systems is claimed to enable the creation of innovative services conceived for assisting the final user, especially in elderly care. The synergy between IoT and a Socially Assistive Robot (SAR) was conceived to offer robustness, reconfiguration, heterogeneity, and scalability, by bringing a strong added value to both the current SAR and IoT technologies. First, we propose a method to achieve the synergy and integration between the IoT system and the robot; then, we show how our method increases the performance and effectiveness of both to provide long-term support to the older adults. To do so, we present a case-study, where we focus on the detection of signs of the frailty syndrome, a set of vulnerabilities typically conveyed by a cognitive and physical decline in older people that concur in amplifying the risks of major diseases hindering the capabilities of independent living. Experimental evaluation is performed in both controlled settings and in a long-term real-world pilot study with 9 older adults in their own apartments, where the system was deployed autonomously for, on average, 12 weeks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002354",
    "keywords": [
      "Artificial intelligence",
      "Assisted living",
      "Autonomy",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Control reconfiguration",
      "Database",
      "Embedded system",
      "Gene",
      "Gerontology",
      "Human–computer interaction",
      "Independent living",
      "Internet of Things",
      "Law",
      "Medicine",
      "Mobile robot",
      "Nursing",
      "Political science",
      "Robot",
      "Robotics",
      "Robustness (evolution)",
      "Scalability"
    ],
    "authors": [
      {
        "surname": "Luperto",
        "given_name": "Matteo"
      },
      {
        "surname": "Monroy",
        "given_name": "Javier"
      },
      {
        "surname": "Moreno",
        "given_name": "Francisco-Angel"
      },
      {
        "surname": "Lunardini",
        "given_name": "Francesca"
      },
      {
        "surname": "Renoux",
        "given_name": "Jennifer"
      },
      {
        "surname": "Krpic",
        "given_name": "Andrej"
      },
      {
        "surname": "Galindo",
        "given_name": "Cipriano"
      },
      {
        "surname": "Ferrante",
        "given_name": "Simona"
      },
      {
        "surname": "Basilico",
        "given_name": "Nicola"
      },
      {
        "surname": "Gonzalez-Jimenez",
        "given_name": "Javier"
      },
      {
        "surname": "Borghese",
        "given_name": "N. Alberto"
      }
    ]
  },
  {
    "title": "Bimanual telemanipulation with force and haptic feedback through an anthropomorphic avatar system",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104338",
    "abstract": "Robotic teleoperation is a key technology for a wide variety of applications. It allows sending robots instead of humans in remote, possibly dangerous locations while still using the human brain with its enormous knowledge and creativity, especially for solving unexpected problems. A main challenge in teleoperation consists of providing enough feedback to the human operator for situation awareness and thus create full immersion, as well as offering the operator suitable control interfaces to achieve efficient and robust task fulfillment. We present a bimanual telemanipulation system consisting of an anthropomorphic avatar robot and an operator station providing force and haptic feedback to the human operator. The avatar arms are controlled in Cartesian space with a direct mapping of the operator movements. The measured forces and torques on the avatar side are haptically displayed to the operator. We developed a predictive avatar model for limit avoidance which runs on the operator side, ensuring low latency. The system was successfully evaluated during the ANA Avatar XPRIZE competition semifinals. In addition, we performed in lab experiments and carried out a small user study with mostly untrained operators.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002275",
    "keywords": [
      "Artificial intelligence",
      "Avatar",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Engineering",
      "Gene",
      "Haptic technology",
      "Human–computer interaction",
      "Immersion (mathematics)",
      "Mathematics",
      "Mobile robot",
      "Operator (biology)",
      "Pure mathematics",
      "Repressor",
      "Robot",
      "Simulation",
      "Systems engineering",
      "Task (project management)",
      "Teleoperation",
      "Telerobotics",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Lenz",
        "given_name": "Christian"
      },
      {
        "surname": "Behnke",
        "given_name": "Sven"
      }
    ]
  },
  {
    "title": "Design and development of software stack of an autonomous vehicle using robot operating system",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104340",
    "abstract": "In recent research activities, autonomous vehicles and self-driving technology have gained lot of attention among scientists. The idea of autonomous vehicles can be anticipated in the 1920s when the design of the first radio-controlled vehicles was in progress. Autonomous vehicles are going to be the trend of the future in this modern era of automation and technology. In this paper various autonomous driving aspects, highlighting the software stack and hardware components are discussed. The software architecture covers mainly robot operating system (ROS), machine learning (ML), deep learning (DL), and OpenCV frameworks, along with the calibration of sensors and cameras. The paper also discussed about simultaneous localization and mapping (SLAM) based-path tracking, computer vision-based controller, and intelligent object avoidance. Further, point cloud, ground, radius, and raycast filters was implemented to distinguish between the real-time objects, ground, and its own parts or obstacle shadows. The paper highlights the overall hardware modules responsible for controlling the car.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002299",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Automation",
      "Biology",
      "Computer science",
      "Controller (irrigation)",
      "Embedded system",
      "Engineering",
      "Law",
      "Mechanical engineering",
      "Mobile robot",
      "Object (grammar)",
      "Obstacle",
      "Obstacle avoidance",
      "Operating system",
      "Political science",
      "Real-time computing",
      "Robot",
      "Software",
      "Unmanned ground vehicle"
    ],
    "authors": [
      {
        "surname": "Prasad",
        "given_name": "Abhisek Omkar"
      },
      {
        "surname": "Mishra",
        "given_name": "Pradumn"
      },
      {
        "surname": "Jain",
        "given_name": "Urja"
      },
      {
        "surname": "Pandey",
        "given_name": "Anish"
      },
      {
        "surname": "Sinha",
        "given_name": "Anushka"
      },
      {
        "surname": "Yadav",
        "given_name": "Anil Singh"
      },
      {
        "surname": "Kumar",
        "given_name": "Rajan"
      },
      {
        "surname": "Sharma",
        "given_name": "Abhishek"
      },
      {
        "surname": "Kumar",
        "given_name": "Gaurav"
      },
      {
        "surname": "Hazim Salem",
        "given_name": "Karrar"
      },
      {
        "surname": "Sharma",
        "given_name": "Avdhesh"
      },
      {
        "surname": "Dixit",
        "given_name": "Anil Kumar"
      }
    ]
  },
  {
    "title": "Quantum planning for swarm robotics",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104362",
    "abstract": "Computational resources of quantum computing can enhance robotic motion, decision making, and path planning. While the quantum paradigm is being applied to individual robots, its approach to swarms of simple and interacting robots remains largely unexplored. In this paper, we attempt to bridge the gap between swarm robotics and quantum computing, in the framework of a search and rescue mission. We focus on a decision-making and path-planning collective task. Thus, we present a quantum-based path-planning algorithm for a swarm of robots. Quantization enters position and reward information (measured as a robot’s proximity to the target) and path-planning decisions. Pairwise information-exchange is modeled through a logic gate, implemented with a quantum circuit. Path planning draws upon Grover’s search algorithm, implemented with another quantum circuit. Our case study involves a search and rescue scenario, inspired by ant-foraging behavior in nature, as an example of swarm intelligence. We show that our method outperforms two ant-behavior simulations, in NetLogo and Java, respectively, presenting a faster convergence to the target, represented here by the source of food. This study can shed light on future applications of quantum computing to swarm robotics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000015",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Physics",
      "Quantum",
      "Quantum mechanics",
      "Robot",
      "Robotics",
      "Swarm behaviour",
      "Swarm robotics"
    ],
    "authors": [
      {
        "surname": "Chella",
        "given_name": "Antonio"
      },
      {
        "surname": "Gaglio",
        "given_name": "Salvatore"
      },
      {
        "surname": "Mannone",
        "given_name": "Maria"
      },
      {
        "surname": "Pilato",
        "given_name": "Giovanni"
      },
      {
        "surname": "Seidita",
        "given_name": "Valeria"
      },
      {
        "surname": "Vella",
        "given_name": "Filippo"
      },
      {
        "surname": "Zammuto",
        "given_name": "Salvatore"
      }
    ]
  },
  {
    "title": "Disturbance-aware reinforcement learning for rejecting excessive disturbances",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104341",
    "abstract": "This paper presents a disturbance-aware Reinforcement Learning (RL) approach for stabilizing a free-floating platform under excessive external disturbances. In particular, we consider the scenarios where disturbances frequently exceed actuator limits and largely affect the dynamics characterizing the disturbed platform. This stabilization problem is better described by a set of Unknown Partially Observable Markovian Decision Processes (POMDPs), as opposed to a single-POMDP formulation, making online disturbance awareness necessary. This paper proposes a new Disturbance-Observer network (DO-net) that mimics prediction procedures through an auxiliary Gated Recurrent Unit (GRU), for the purpose of estimating and encoding the disturbance states and the disturbance transition functions, respectively. Then the controller subnetwork is trained with joint optimization of the observer subnetwork in an RL manner for mutual robustness and runtime efficiency. Numerical simulations on position regulation tasks have demonstrated that the DO-net outperforms the DOB-net and reduces the gap with an ideal performance estimate, the latter of which is obtained by a commercial solver given precise disturbance knowledge.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002305",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Control theory (sociology)",
      "Disturbance (geology)",
      "Gene",
      "Machine learning",
      "Markov chain",
      "Markov model",
      "Paleontology",
      "Partially observable Markov decision process",
      "Programming language",
      "Reinforcement learning",
      "Robustness (evolution)",
      "Solver",
      "Subnetwork"
    ],
    "authors": [
      {
        "surname": "Lu",
        "given_name": "Wenjie"
      },
      {
        "surname": "Hu",
        "given_name": "Manman"
      }
    ]
  },
  {
    "title": "Addressing time discrepancy between digital and physical twins",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104347",
    "abstract": "Digital twins (DTs) represent a key technology in the development, real-time monitoring and optimisation of cyber–physical systems (CPSs). Such potential emerges as a result of the real-time coupling between DTs and their physical counterparts, where it is possible to make use of operational data as it is being generated in order to aid decision-making. Harnessing this potential presents several design challenges, such as the parallel operation of the DT and its physical twin (PT), and the necessary synchronisation thereof, to ensure coherent execution of the system in ensemble. In this paper we present an approach that handles situations where a DT and its PT get out of sync as a result of disturbances in the normal operational conditions of the DT–PT system, e.g., due to network degradation or temporary network drop. The purpose is to provide a best-effort functionality covering: user notification, degradation of DT to digital shadow (DS), with recovery mechanisms to re-establish the synchronisation between DT and PT.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002366",
    "keywords": [
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Computer security",
      "Cyber-physical system",
      "Degradation (telecommunications)",
      "Distributed computing",
      "Key (lock)",
      "Operating system",
      "Real-time computing",
      "Synchronization (alternating current)",
      "Telecommunications",
      "sync"
    ],
    "authors": [
      {
        "surname": "Frasheri",
        "given_name": "Mirgita"
      },
      {
        "surname": "Ejersbo",
        "given_name": "Henrik"
      },
      {
        "surname": "Thule",
        "given_name": "Casper"
      },
      {
        "surname": "Gomes",
        "given_name": "Cláudio"
      },
      {
        "surname": "Kvistgaard",
        "given_name": "Jakob Levisen"
      },
      {
        "surname": "Larsen",
        "given_name": "Peter Gorm"
      },
      {
        "surname": "Esterle",
        "given_name": "Lukas"
      }
    ]
  },
  {
    "title": "Multi-robot task allocation clustering based on game theory",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104314",
    "abstract": "A cooperative game theory framework is proposed to solve multi-robot task allocation (MRTA) problems. In particular, a cooperative game is built to assess the performance of sets of robots and tasks so that the Shapley value of the game can be used to compute their average marginal contribution. This fact allows us to partition the initial MRTA problem into a set of smaller and simpler MRTA subproblems, which are formed by ranking and clustering robots and tasks according to their Shapley value. A large-scale simulation case study illustrates the benefits of the proposed scheme, which is assessed using a genetic algorithm (GA) as a baseline method. The results show that the game theoretical approach outperforms GA both in performance and computation time for a range of problem instances.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002032",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Combinatorics",
      "Composite material",
      "Computation",
      "Computer science",
      "Cooperative game theory",
      "Economics",
      "Game theory",
      "Management",
      "Materials science",
      "Mathematical economics",
      "Mathematical optimization",
      "Mathematics",
      "Partition (number theory)",
      "Programming language",
      "Range (aeronautics)",
      "Ranking (information retrieval)",
      "Robot",
      "Set (abstract data type)",
      "Shapley value",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Martin",
        "given_name": "Javier G."
      },
      {
        "surname": "Muros",
        "given_name": "Francisco Javier"
      },
      {
        "surname": "Maestre",
        "given_name": "José María"
      },
      {
        "surname": "Camacho",
        "given_name": "Eduardo F."
      }
    ]
  },
  {
    "title": "OGATE: A framework for autonomous controllers assessment",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104325",
    "abstract": "Autonomous robots can face a variety of applications integrating Artificial Intelligence (AI) techniques, for instance Planning & Scheduling (P&S). While robotics and planning systems are commonly well assessed through test benchs and metrics, in autonomous robots literature it is usual to present isolated case studies for evaluating such works. For instance, experiments are presented in very specific circumstances and often the data provided is not enough to enable a characterization of the autonomous features performance, providing only a demonstration of effectiveness. The main issue is the absence of a framework to assess autonomous controllers from a general perspective. We propose a research focused on a set of general applicable metrics to enable assessment of autonomous controllers. In this way, our objective is to analyse the deliberation and reaction capabilities of an autonomous robot in real operative scenarios. Such metrics are implemented in OGATE, a domain independent tool that automatically carries on with controllers’ testing, generating objective and reproducible performance assessments. To test this framework we have used two autonomous controllers that rely on different technologies for P&S. Results show that we are able to obtain relevant data, enabling the characterization of different P&S integration in robotics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002147",
    "keywords": [
      "Artificial intelligence",
      "Autonomous robot",
      "Autonomous system (mathematics)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Economics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Mobile robot",
      "Operations management",
      "Programming language",
      "Robot",
      "Robotics",
      "Scheduling (production processes)",
      "Set (abstract data type)",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Muñoz",
        "given_name": "Pablo"
      },
      {
        "surname": "Cesta",
        "given_name": "Amedeo"
      },
      {
        "surname": "Orlandini",
        "given_name": "Andrea"
      },
      {
        "surname": "R-Moreno",
        "given_name": "María D."
      }
    ]
  },
  {
    "title": "A hybrid skill parameterisation model combining symbolic and subsymbolic elements for introspective robots",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104350",
    "abstract": "In the design of robot skills, the focus generally lies on increasing the flexibility and reliability of the robot execution process; however, typical skill representations are not designed for analysing execution failures if they occur or for explicitly learning from failures. In this paper, we describe a learning-based hybrid representation for skill parameterisation called an execution model, which considers execution failures to be a natural part of the execution process. We then (i) demonstrate how execution contexts can be included in execution models, (ii) introduce a technique for generalising models between object categories by combining generalisation attempts performed by a robot with knowledge about object similarities represented in an ontology, and (iii) describe a procedure that uses an execution model for identifying a likely hypothesis of a parameterisation failure. The feasibility of the proposed methods is evaluated in multiple experiments performed with a physical robot in the context of handle grasping, object grasping, and object pulling. The experimental results suggest that execution models contribute towards avoiding execution failures, but also represent a first step towards more introspective robots that are able to analyse some of their execution failures in an explicit manner.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002391",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Flexibility (engineering)",
      "Focus (optics)",
      "Law",
      "Machine learning",
      "Mathematics",
      "Object (grammar)",
      "Optics",
      "Paleontology",
      "Physics",
      "Political science",
      "Politics",
      "Power (physics)",
      "Process (computing)",
      "Programming language",
      "Quantum mechanics",
      "Reliability (semiconductor)",
      "Representation (politics)",
      "Robot",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Mitrevski",
        "given_name": "Alex"
      },
      {
        "surname": "Plöger",
        "given_name": "Paul G."
      },
      {
        "surname": "Lakemeyer",
        "given_name": "Gerhard"
      }
    ]
  },
  {
    "title": "Social interaction model enhanced with speculation stage for human trajectory prediction",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104352",
    "abstract": "Accurate human trajectory prediction is still challenging due to the complicated interactions with surroundings. A Spatio-Temporal Graph Convolution Neural Network based Social Interaction Model (STGCNN-SIM) is proposed to address this challenge. In addition to historical trajectory information, the presented method employs the speculated trajectories in the future to extract social interactive features and model interaction behaviors. Three social interactive features are extracted explicitly from the observed and speculated trajectories: (1) the relative distance, (2) the angle between the velocity vectors of two interacting partners, and (3) the angles between the velocity vectors of interacting partners and the distance vector. STGCNN-SIM utilizes these social interactive features to model interactions with surroundings in the historical and speculated stages. Then an attention mechanism is adopted to improve the model by focusing on more relevant features. Experimental results on three public datasets demonstrate that STGCNN-SIM achieves higher accuracy and stability than the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902200241X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Computer science",
      "Convolution (computer science)",
      "Economics",
      "Graph",
      "Interaction information",
      "Machine learning",
      "Macroeconomics",
      "Mathematics",
      "Mechanism (biology)",
      "Physics",
      "Quantum mechanics",
      "Speculation",
      "Stability (learning theory)",
      "Statistics",
      "Theoretical computer science",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Pi",
        "given_name": "Lei"
      },
      {
        "surname": "Zhang",
        "given_name": "Qiang"
      },
      {
        "surname": "Yang",
        "given_name": "Lingfang"
      },
      {
        "surname": "Huang",
        "given_name": "Zhi"
      }
    ]
  },
  {
    "title": "Object-wise comparison of LiDAR occupancy grid scan rendering methods",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2023.104363",
    "abstract": "Computing Occupancy grids with LiDAR data, is a popular strategy for environment representation. In the last two decades, several authors have proposed different methods to render the sensed information into the grids, seeking to obtain computational efficiency or accurate environment modeling. However, no comparison regarding their performance under object detection in autonomous driving applications has been found in the literature. As a result, this work compares six representative LiDAR scan rendering strategies in a quantitative manner. To that end, a novel quantitative evaluation framework for occupancy grids is proposed. It addresses the two main steps of object detection: object segmentation and features estimation, proposing a meaningful procedure, repeatable with other OG approaches. The code of this evaluation framework is available in https://git-autopia.car.upm-csic.es/open_source/occupancy_grid_object_detection_evaluation.git.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889023000027",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Data mining",
      "Ecology",
      "Geology",
      "Geometry",
      "Grid",
      "Lidar",
      "Mathematics",
      "Mobile robot",
      "Object (grammar)",
      "Object detection",
      "Occupancy",
      "Occupancy grid mapping",
      "Ranging",
      "Remote sensing",
      "Rendering (computer graphics)",
      "Robot",
      "Segmentation",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Jiménez",
        "given_name": "Víctor"
      },
      {
        "surname": "Godoy",
        "given_name": "Jorge"
      },
      {
        "surname": "Artuñedo",
        "given_name": "Antonio"
      },
      {
        "surname": "Villagra",
        "given_name": "Jorge"
      }
    ]
  },
  {
    "title": "External six-bar mechanism rehabilitation device for index finger: Development and shape synthesis",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104336",
    "abstract": "This work proposes a novel external Stephenson-III six-bar mechanism-based rehabilitation device. This device has been designed to rehabilitate the patient’s finger for the action of grabbing, also known as flexion and extension. A predefined trajectory is used to synthesize the mechanism using TeachingLearning-Optimization algorithm (TLBO) and Particle swarm optimization algorithm (PSO). The trajectory data was obtained after image processing by grabbing a particular object 30 times to record the flexion and extension motion of the index finger. An optimization problem was formulated and results of TLBO and PSO were compared. The mechanism obtained from TLBO algorithm was deemed better in terms of precision and feasible configuration. Using clinical biomechanical data for flexion/extension of index finger, position and static force analysis are performed. The CAD model of the mechanism was then tested for feasibility in a CAD/Software. Excess mass was removed using topology optimization and a 20% mean reduction for every link was achieved. An index finger rehabilitation device employing an external six-bar mechanism was obtained, that would help a patient with motor control loss to rehabilitate and bring normalcy to life. The design of exoskeleton was able to match the trajectory of the index. Shape synthesis ensured a 20% reduction in overall mass of the linkages.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002251",
    "keywords": [
      "Algorithm",
      "Anatomy",
      "Artificial intelligence",
      "Astronomy",
      "Bar (unit)",
      "CAD",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Engineering drawing",
      "Exoskeleton",
      "Four-bar linkage",
      "Geometry",
      "Index finger",
      "Mathematics",
      "Mechanism (biology)",
      "Medicine",
      "Meteorology",
      "Motion (physics)",
      "Particle swarm optimization",
      "Physics",
      "Quantum mechanics",
      "Reduction (mathematics)",
      "Simulation",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Chakraborty",
        "given_name": "Debaditya"
      },
      {
        "surname": "Rathi",
        "given_name": "Ayush"
      },
      {
        "surname": "Singh",
        "given_name": "Ramanpreet"
      },
      {
        "surname": "Pathak",
        "given_name": "Vimal Kumar"
      },
      {
        "surname": "Srivastava",
        "given_name": "Ashish Kumar"
      },
      {
        "surname": "Sharma",
        "given_name": "Abhishek"
      },
      {
        "surname": "Saxena",
        "given_name": "Kuldeep K."
      },
      {
        "surname": "Kumar",
        "given_name": "Gaurav"
      },
      {
        "surname": "Kumar",
        "given_name": "Sandeep"
      }
    ]
  },
  {
    "title": "Reinforcement learning under temporal logic constraints as a sequence modeling problem",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104351",
    "abstract": "Reinforcement learning (RL) under temporal logic typically suffers from slow propagation for credit assignment. Inspired by recent advancements called trajectory transformer in machine learning, the reinforcement learning under Temporal Logic (TL) is modeled as a sequence modeling problem in this paper, where an agent utilizes the transformer to fit the optimal policy satisfying the Finite Linear Temporal Logic ( LTL f ) tasks. To combat the sparse reward issue, dense reward functions for LTL f are designed. For the sake of reducing the computational complexity, a sparse transformer with local and global attention is constructed to automatically conduct credit assignment, which removes the time-consuming value iteration process. The optimal action is found by the beam search performed in transformers. The proposed method generates a series of policies fitted by sparse transformers, which has sustainably high accuracy in fitting the demonstrations. At last, the effectiveness of the proposed method is demonstrated by simulations in Mini-Grid environments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002408",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Geometry",
      "Grid",
      "Machine learning",
      "Mathematics",
      "Physics",
      "Q-learning",
      "Quantum mechanics",
      "Reinforcement learning",
      "Temporal logic",
      "Theoretical computer science",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Daiying"
      },
      {
        "surname": "Fang",
        "given_name": "Hao"
      },
      {
        "surname": "Yang",
        "given_name": "Qingkai"
      },
      {
        "surname": "Yu",
        "given_name": "Haoyong"
      },
      {
        "surname": "Liang",
        "given_name": "Wenyu"
      },
      {
        "surname": "Wu",
        "given_name": "Yan"
      }
    ]
  },
  {
    "title": "UV Disinfection Robots: A Review",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104332",
    "abstract": "The novel coronavirus (COVID-19) pandemic has completely changed our lives and how we interact with the world. The pandemic has brought about a pressing need to have effective disinfection practices that can be incorporated into daily life. They are needed to limit the spread of infections through surfaces and air, particularly in public settings. Most of the current methods utilize chemical disinfectants, which can be laborious and time-consuming. Ultraviolet (UV) irradiation is a proven and powerful means of disinfection. There has been a rising interest in the implementation of UV disinfection robots by various public institutions, such as hospitals, long-term care homes, airports, and shopping malls. The use of UV-based disinfection robots could make the disinfection process faster and more efficient. The objective of this review is to equip readers with the necessary background on UV disinfection and provide relevant discussion on various aspects of UV robots.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002214",
    "keywords": [
      "2019-20 coronavirus outbreak",
      "Artificial intelligence",
      "Business",
      "Computer science",
      "Coronavirus disease 2019 (COVID-19)",
      "Disease",
      "Environmental engineering",
      "Environmental science",
      "Infectious disease (medical specialty)",
      "Materials science",
      "Medicine",
      "Operating system",
      "Optoelectronics",
      "Outbreak",
      "Pandemic",
      "Pathology",
      "Process (computing)",
      "Risk analysis (engineering)",
      "Robot",
      "Ultraviolet",
      "Virology",
      "Water disinfection"
    ],
    "authors": [
      {
        "surname": "Mehta",
        "given_name": "Ishaan"
      },
      {
        "surname": "Hsueh",
        "given_name": "Hao-Ya"
      },
      {
        "surname": "Taghipour",
        "given_name": "Sharareh"
      },
      {
        "surname": "Li",
        "given_name": "Wenbin"
      },
      {
        "surname": "Saeedi",
        "given_name": "Sajad"
      }
    ]
  },
  {
    "title": "Reinforcement learning under temporal logic constraints as a sequence modeling problem",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104351",
    "abstract": "Reinforcement learning (RL) under temporal logic typically suffers from slow propagation for credit assignment. Inspired by recent advancements called trajectory transformer in machine learning, the reinforcement learning under Temporal Logic (TL) is modeled as a sequence modeling problem in this paper, where an agent utilizes the transformer to fit the optimal policy satisfying the Finite Linear Temporal Logic ( LTL f ) tasks. To combat the sparse reward issue, dense reward functions for LTL f are designed. For the sake of reducing the computational complexity, a sparse transformer with local and global attention is constructed to automatically conduct credit assignment, which removes the time-consuming value iteration process. The optimal action is found by the beam search performed in transformers. The proposed method generates a series of policies fitted by sparse transformers, which has sustainably high accuracy in fitting the demonstrations. At last, the effectiveness of the proposed method is demonstrated by simulations in Mini-Grid environments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002408",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Geometry",
      "Grid",
      "Machine learning",
      "Mathematics",
      "Physics",
      "Q-learning",
      "Quantum mechanics",
      "Reinforcement learning",
      "Temporal logic",
      "Theoretical computer science",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Daiying"
      },
      {
        "surname": "Fang",
        "given_name": "Hao"
      },
      {
        "surname": "Yang",
        "given_name": "Qingkai"
      },
      {
        "surname": "Yu",
        "given_name": "Haoyong"
      },
      {
        "surname": "Liang",
        "given_name": "Wenyu"
      },
      {
        "surname": "Wu",
        "given_name": "Yan"
      }
    ]
  },
  {
    "title": "Optimal strategies of a pursuit-evasion game with three pursuers and one superior evader",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104360",
    "abstract": "We attempt to solve the pursuit-evasion game of a faster evader being surrounded by three pursuers. The complexity of the game under study stems from the holonomic motion of the agents. This game has not been solved either in the sense of presenting optimal trajectories or in the sense of feedback strategies. There exist heuristic strategies, and solutions to similar but simpler games which will be of use. We present a solution for the optimal trajectories of the game, but we do not prove optimality. Then, we synthesize feedback strategies for both parties based on the proposed trajectories.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002494",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Evasion (ethics)",
      "Game theory",
      "Heuristic",
      "Holonomic",
      "Immune system",
      "Immunology",
      "Mathematical economics",
      "Mathematical optimization",
      "Mathematics",
      "Motion (physics)",
      "Pursuit-evasion",
      "Sequential game"
    ],
    "authors": [
      {
        "surname": "Szőts",
        "given_name": "János"
      },
      {
        "surname": "Harmati",
        "given_name": "István"
      }
    ]
  },
  {
    "title": "Message flow analysis with complex causal links for distributed ROS 2 systems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104361",
    "abstract": "Distributed robotic systems rely heavily on the publish–subscribe communication paradigm and middleware frameworks that support it, such as the Robot Operating System (ROS), to efficiently implement modular computation graphs. The ROS 2 executor, a high-level task scheduler which handles ROS 2 messages, is a performance bottleneck. We extend ros2_tracing, a framework with instrumentation and tools for real-time tracing of ROS 2, with the analysis and visualization of the flow of messages across distributed ROS 2 systems. Our method detects one-to-many and many-to-many causal links between input and output messages, including indirect causal links through simple user-level annotations. We validate our method on both synthetic and real robotic systems, and demonstrate its low runtime overhead. Moreover, the underlying intermediate execution representation database can be further leveraged to extract additional metrics and high-level results. This can provide valuable timing and scheduling information to further study and improve the ROS 2 executor as well as optimize any ROS 2 system. The source code is available at: github.com/christophebedard/ros2-message-flow-analysis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002500",
    "keywords": [],
    "authors": [
      {
        "surname": "Bédard",
        "given_name": "Christophe"
      },
      {
        "surname": "Lajoie",
        "given_name": "Pierre-Yves"
      },
      {
        "surname": "Beltrame",
        "given_name": "Giovanni"
      },
      {
        "surname": "Dagenais",
        "given_name": "Michel"
      }
    ]
  },
  {
    "title": "Contact-based object inspection with mobile manipulators at near-optimal base locations",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104345",
    "abstract": "This paper presents a control and motion planning algorithm for a mobile vehicle-manipulator system such that the mobile vehicle and the manipulator mounted on it work in harmony to inspect unknown objects. Forward Dynamic Control method is used for the manipulator to accomplish a stable interaction with the environment and constrained particle swarm optimization is applied so that the vehicle can be localized at the estimated points maximizing the dexterity of the manipulator. Quartic splines are implemented to generate a smooth path for the vehicle in between the optimal locations. The proposed architecture is validated via an experimental setup consisting of a robotic arm with a force sensor at its end-effector mounted on a parallel manipulator. These experiments emulate an underwater vehicle-manipulator system, where the mobile base is subject to disturbances due to the physical interaction of the end-effector with the environment, typically a pipe. The advantage of the proposed approach is that it allows continuous and smooth movement of the base in harmony with the robotic manipulator while executing a task on a large surface (larger than the manipulator workspace can cover from a fixed position) and maintains a high level of dexterity index for the manipulator.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002342",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Harmony search",
      "Mobile manipulator",
      "Mobile robot",
      "Parallel manipulator",
      "Robot",
      "Robot end effector",
      "Serial manipulator",
      "Simulation",
      "Workspace"
    ],
    "authors": [
      {
        "surname": "Tugal",
        "given_name": "Harun"
      },
      {
        "surname": "Cetin",
        "given_name": "Kamil"
      },
      {
        "surname": "Petillot",
        "given_name": "Yvan"
      },
      {
        "surname": "Dunnigan",
        "given_name": "Matthew"
      },
      {
        "surname": "Erden",
        "given_name": "Mustafa Suphi"
      }
    ]
  },
  {
    "title": "Human-assisted robotic detection of foreign object debris inside confined spaces of marine vessels using probabilistic mapping",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104349",
    "abstract": "Many complex vehicular systems, such as large marine vessels, contain confined spaces like water tanks, which are critical for the safe functioning of the vehicles. It is particularly hazardous for humans to inspect such spaces due to limited accessibility, poor visibility, and unstructured configuration. While robots provide a viable alternative, they encounter the same set of challenges in realizing robust autonomy. In this work, we specifically address the problem of detecting foreign object debris (FODs) left inside the confined spaces using a visual mapping-based system that relies on Mahalanobis distance-driven comparisons between the nominal and online maps for local outlier identification. The identified outliers, corresponding to candidate FODs, are used to generate waypoints that are fed to a mobile ground robot to take camera photos. The photos are subsequently labeled by humans for final identification of the presence and types of FODs, leading to high detection accuracy while mitigating the effect of recall–precision tradeoff. Preliminary simulation studies, followed by extensive physical trials on a prototype tank, demonstrate the capability and potential of our FOD detection system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902200238X",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Computer science",
      "Computer vision",
      "False positive paradox",
      "Identification (biology)",
      "Mahalanobis distance",
      "Object (grammar)",
      "Outlier",
      "Probabilistic logic",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Wong",
        "given_name": "Benjamin"
      },
      {
        "surname": "Marquette",
        "given_name": "Wade"
      },
      {
        "surname": "Bykov",
        "given_name": "Nikolay"
      },
      {
        "surname": "Paine",
        "given_name": "Tyler M."
      },
      {
        "surname": "Banerjee",
        "given_name": "Ashis G."
      }
    ]
  },
  {
    "title": "Human-in-the-loop layered architecture for control of a wearable ankle–foot robot",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104353",
    "abstract": "Intelligent wearable robotics is a promising approach for the development of devices that can interact with people and assist them in daily activities. This work presents a novel human-in-the-loop layered architecture to control a wearable robot while interacting with the human body. The proposed control architecture is composed of high-, mid- and low-level computational and control layers, together with wearable sensors, for the control of a wearable ankle–foot robot. The high-level layer uses Bayesian formulation and a competing accumulator model to estimate the human posture during the gait cycle. The mid-level layer implements a Finite State Machine (FSM) to prepare the control parameters for the wearable robot based on the decisions from the high-level layer. The low-level layer is responsible for the precise control of the wearable robot over time using a cascade proportional–integral–derivative (PID) control approach. The human-in-the-loop layered architecture is systematically validated with the control of a 3D printed wearable ankle–foot robot to assist the human foot while walking. The assistance is applied lifting up the human foot when the toe-off event is detected in the walking cycle, and the assistance is removed allowing the human foot to move down and contact the ground when the heel-contact event is detected. Overall, the experiments in offline and real-time modes, undertaken for the validation process, show the potential of the human-in-the-loop layered architecture to develop intelligent wearable robots capable of making decisions and responding fast and accurately based on the interaction with the human body.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002421",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Embedded system",
      "Robot",
      "Robotics",
      "Simulation",
      "Wearable computer"
    ],
    "authors": [
      {
        "surname": "Martinez-Hernandez",
        "given_name": "Uriel"
      },
      {
        "surname": "Firouzy",
        "given_name": "Sina"
      },
      {
        "surname": "Mehryar",
        "given_name": "Pouyan"
      },
      {
        "surname": "Meng",
        "given_name": "Lin"
      },
      {
        "surname": "Childs",
        "given_name": "Craig"
      },
      {
        "surname": "Buis",
        "given_name": "Arjan"
      },
      {
        "surname": "Dehghani-Sanij",
        "given_name": "Abbas A."
      }
    ]
  },
  {
    "title": "Design and control of an aerial-ground tethered tendon-driven continuum robot with hybrid routing",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104344",
    "abstract": "Combining aerial and continuum robots harnesses both their flexibility and manoeuvrability to potentially perform dangerous maintenance tasks. However, such systems require heavy payloads to interact with its environment. An aerial-ground tethered tendon-driven continuum robot is thus proposed to tackle the limitations of on-board payload aerial systems and the underactuation of multirotors. Due to the natural limitation on the tendons used in the implementation of aerial ground tethered continuum robots, we explore the use of hybrid polynomial and parallel routes to achieve desired workspace profiles, while providing intuition on choosing suitable tendon routes. In this work, we leverage on geometrically exact methods to derive the differential kinematics of the aerial continuum robot using actuation sensors particularly for polynomial tendon routes. We demonstrate that both position and orientation can be controlled using a single stage continuum robot with hybrid tendon routing. Finally, a simple manoeuvre is executed by the aerial continuum robot prototype to validate the proposed proof of concept.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002330",
    "keywords": [
      "Artificial intelligence",
      "Classical mechanics",
      "Computer science",
      "Kinematics",
      "Physics",
      "Robot",
      "Simulation",
      "Underactuation",
      "Workspace"
    ],
    "authors": [
      {
        "surname": "Chien",
        "given_name": "Jer Luen"
      },
      {
        "surname": "Leong",
        "given_name": "Clarissa"
      },
      {
        "surname": "Liu",
        "given_name": "Jingmin"
      },
      {
        "surname": "Foong",
        "given_name": "Shaohui"
      }
    ]
  },
  {
    "title": "A survey of multi-agent Human–Robot Interaction systems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104335",
    "abstract": "This article presents a survey of literature in the area of Human–Robot Interaction (HRI), specifically on systems containing more than two agents (i.e., having multiple humans and/or multiple robots). We identify three core aspects of “Multi-agent” HRI systems that are useful for understanding how these systems differ from dyadic systems and from one another. These are the Team structure, Interaction style among agents, and the system’s Computational characteristics. Under these core aspects, we present five attributes of HRI systems, namely Team size, Team composition, Interaction model, Communication modalities, and Robot control. These attributes are used to characterize and distinguish one system from another. We populate resulting categories with examples from the recent literature along with a brief discussion of their applications. We also analyze how these attributes in multi-agent systems differ from the case of dyadic human–robot systems. Through this survey, we summarize key observations from the current literature, and identify challenges and promising areas for future research in this domain. In order to realize the vision of robots being part of the society and interacting seamlessly with humans, there is a need to expand research on multi-human–multi-robot systems. Not only do these systems require coordination among several agents, they also involve multi-agent and indirect interactions which are absent from dyadic HRI systems. Including multiple agents in HRI systems requires more advanced interaction schemes, behavior understanding and control methods to allow natural interactions among humans and robots. In addition, research on human behavioral understanding in mixed human–robot teams also requires more attention. This will help formulate and implement effective robot control policies in HRI systems with large numbers of heterogeneous robots and humans; a team composition reflecting many real-world scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902200224X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Core (optical fiber)",
      "Domain (mathematical analysis)",
      "Human–computer interaction",
      "Human–robot interaction",
      "Mathematical analysis",
      "Mathematics",
      "Modalities",
      "Multi-agent system",
      "Robot",
      "Social science",
      "Sociology",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Dahiya",
        "given_name": "Abhinav"
      },
      {
        "surname": "Aroyo",
        "given_name": "Alexander M."
      },
      {
        "surname": "Dautenhahn",
        "given_name": "Kerstin"
      },
      {
        "surname": "Smith",
        "given_name": "Stephen L."
      }
    ]
  },
  {
    "title": "A Review of quadrotor UAV: Control and SLAM methodologies ranging from conventional to innovative approaches",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104342",
    "abstract": "There are two indispensable methodologies for autonomous flights performed by unmanned aerial vehicles (UAV). The first is flight control, and the other is simultaneous localization and mapping (SLAM). In the literature, these two issues are generally considered separately. However, they have very close relationships with each other. In this study, both methods were extensively examined in the literature, especially for quadrotors. Quadrotors, also known as quadrotors, are rotary-wing UAVs capable of vertical take-off and landing. As their use becomes widespread worldwide, the number of studies conducted to enable autonomous tasks is growing. The study was prepared under three subtitles. First, a fast and simple introduction of quadrotors was made, and the advances in this area were discussed. In the next section, studies on the position, attitude, and altitude control methods required for the autonomous use of such aircraft are analyzed based on linear, nonlinear, and intelligent methods. As the third subheading, research on SLAM techniques was widely discussed. Frequently used performance metrics, application environments, and results were presented in detailed tables for studies in both areas. Comparative studies were particularly emphasized, and the best results obtained were expressed in tables. The hardware implementations of the mentioned applications were also reviewed. Thus, hardware and method-based quick reference resource were created for researchers. As a consequence, the objective of this research is to provide a comprehensive resource for researchers working on quadrotor navigation systems to effectively select the flight control and SLAM methods they will employ.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002317",
    "keywords": [
      "Artificial intelligence",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Engineering",
      "Implementation",
      "Mobile robot",
      "Ranging",
      "Resource (disambiguation)",
      "Robot",
      "Simultaneous localization and mapping",
      "Software engineering",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "SONUGÜR",
        "given_name": "Güray"
      }
    ]
  },
  {
    "title": "A fault-tolerant sensor fusion in mobile robots using multiple model Kalman filters",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104343",
    "abstract": "Accurate localization is crucial in the navigation of mobile robots. However, in other circumstances, single-sensor localization faces different challenges, including software and hardware problems or data outages. Sensor fusion is used in most autonomous vehicles (including aerial and ground vehicles) to overcome such challenges. In this paper, the localization of a mobile robot is studied in the presence of sensor faults. The mobile robot has two sensors: two Inertial Measurement Units (IMU) and wheel encoders. Regarding the fault-tolerant scheme, measurements of both sets of sensors are fused using an Interacting Multiple Model (IMM) Kalman filter based on both unscented and extended Kalman filters (UKF and EKF). UKF and EKF-based IMM are chosen for this study since the dynamic model of the localization is highly nonlinear. Regarding contributions, it should be noted that this scheme eliminates the need to model every single fault scenario and use an additional sensor to oversee the performance of the sensing system. Also, comparing this method with similar approaches adopted by other studies shows better performance regarding the cost of computations and RMSE. To evaluate performance, the outputs of the proposed filters are simulated and compared for different trajectories where the data of each sensor is intentionally corrupted to observe the fault detection capability. Simulations are performed for different trajectories and noises to demonstrate this method’s efficiency in different situations. In addition, the results of unscented and extended Kalman filter-based IMM are compared in terms of error and computational costs to evaluate their performance. Overall, simulation and experiments indicate accurate 3D estimations in all cases. Moreover, designated weights vividly show that sensor fault detection is achieved by both unscented and extended IMM Kalman filters, which enable complete fault isolation consequently. This approach provides mobile robots with a reliable and straightforward sensor fault detection and localization solution.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002329",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Distributed computing",
      "Extended Kalman filter",
      "Fault (geology)",
      "Fault tolerance",
      "Fusion",
      "Geology",
      "Kalman filter",
      "Linguistics",
      "Mobile robot",
      "Philosophy",
      "Real-time computing",
      "Robot",
      "Seismology",
      "Sensor fusion"
    ],
    "authors": [
      {
        "surname": "Kheirandish",
        "given_name": "M."
      },
      {
        "surname": "Yazdi",
        "given_name": "E. Azadi"
      },
      {
        "surname": "Mohammadi",
        "given_name": "H."
      },
      {
        "surname": "Mohammadi",
        "given_name": "M."
      }
    ]
  },
  {
    "title": "A neural network based framework for variable impedance skills learning from demonstrations",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104312",
    "abstract": "Robots are becoming standard collaborators not only in factories, hospitals, and offices, but also in people’s homes, where they can play an important role in situations where a human cannot complete a task alone or needs the help of another person (i.e., collaborative tasks). Variable impedance control with contact forces is critical for robots to successfully perform such manipulation tasks, and robots should be equipped with adaptive capabilities because conditions vary significantly for different robotic tasks in dynamic environments. This can be achieved by learning human motion capabilities and variable impedance skills. In this paper, a neural-network-based framework for learning variable impedance skills is proposed. The proposed approach builds the full stiffness function with the acquired forces and position learned from demonstrations, and then is used together with the sensed data to achieve the variable impedance control. The proposed algorithm can adapt to unknown situations that change the learned motion skill as needed (e.g., adapt to intermediate via-points or avoid obstacles). The proposed framework consists of two parts: Learning motion features and learning impedance features. The motion features learning is validated by reproducing, generalizing, and adapting to transit points and avoiding obstacles in the LASA dataset. Impedance features learning is validated based on a virtual variable stiffness system that achieves higher accuracy (approximately 90%) compared to traditional methods in a manual dataset, and the whole framework is validated through a co-manipulation task between a person and the Franka Emika robot.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002019",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Electrical engineering",
      "Electrical impedance",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Impedance control",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Motion (physics)",
      "Robot",
      "Systems engineering",
      "Task (project management)",
      "Variable (mathematics)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yu"
      },
      {
        "surname": "Cheng",
        "given_name": "Long"
      },
      {
        "surname": "Cao",
        "given_name": "Ran"
      },
      {
        "surname": "Li",
        "given_name": "Houcheng"
      },
      {
        "surname": "Yang",
        "given_name": "Chenguang"
      }
    ]
  },
  {
    "title": "MVGrasp: Real-time multi-view 3D object grasping in highly cluttered environments",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104313",
    "abstract": "Nowadays robots play an increasingly important role in our daily life. In human-centered environments, robots often encounter piles of objects, packed items, or isolated objects. Therefore, a robot must be able to grasp and manipulate different objects in various situations to help humans with daily tasks. In this paper, we propose a multi-view deep learning approach to handle robust object grasping in human-centric domains. In particular, our approach takes a point cloud of an arbitrary object as an input, and then, generates orthographic views of the given object. The obtained views are finally used to estimate pixel-wise grasp synthesis for each object. We train the model end-to-end using a synthetic object grasp dataset and test it on both simulation and real-world data without any further fine-tuning. To evaluate the performance of the proposed approach, we performed extensive sets of experiments in four everyday scenarios, including isolated objects, packed items, pile of objects, and highly cluttered scenes. Experimental results show that our approach performed very well in all simulation and real-robot scenarios. More specifically, the proposed approach outperforms previous state-of-the-art approaches and achieves a success rate of > 90 % in all simulated and real scenarios, except for the pile of objects which is 82%. Additionally, our method demonstrated reliable closed-loop grasping of novel objects in a variety of scene configurations. The video of our experiments can be found here: https://youtu.be/c-4lzjbF7fY.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002020",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "GRASP",
      "Geometry",
      "Human–computer interaction",
      "Mathematics",
      "Object (grammar)",
      "Point (geometry)",
      "Point cloud",
      "Programming language",
      "Robot",
      "Robotics"
    ],
    "authors": [
      {
        "surname": "Kasaei",
        "given_name": "Hamidreza"
      },
      {
        "surname": "Kasaei",
        "given_name": "Mohammadreza"
      }
    ]
  },
  {
    "title": "A novel multi objective constraints based industrial gripper design with optimized stiffness for object grasping",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104303",
    "abstract": "Soft gripper design is a rising area of research due of its great possibilities in automation. One difficult problem in robot design is the ability to grasp a broader variety of items with variable stiffness, forms, and sizes in a single gripper. An ideal soft robotic gripper design with variable stiffness was designed in this research as a grasping model. Its distinctiveness is found in the methods utilized for modelling actuators and in the shifting stiffness characteristics of silicon soft gripper. When modelling the actuator in this case, multi-objective functions like gripping displacement and force transmission ratio are taken into account, and the actuator functions are controlled by the MDF (multiple degrees of freedom). The precise stiffness needed to grasp the item is then chosen using an adaptive optimization method. This enhanced weight-based horse herd (IHH) optimization method carries out the stiffness adjustment based on actuation pressure. Additionally, the suggested soft robotic gripper with variable stiffness employs the adaptive level set (ALS) technique to build the gripping force model. Additionally, several validations are offered in relation to the outcomes for item gripping by the suggested soft gripper. This shown that the results of the created soft gripper excelled those of other methods. The developed ABBIRB 1410 robot gripper type may enhance the work cycle in industrial applications and performs object grabbing with dependability and speed. The experimental validations show that the developed gripper model provides an enhanced object grasp with a range of curvatures, delivering a maximum pulling force of 121.07 kPa at 50 kpa, 119.15 kPa for patterned pulling, and 45.05 kPa for non-patterned pulling. The designed gripper type has a curve with a minimum size of 1.1 mm and a maximum size of 218 mm. Additionally, the soft gripper for industrial applications is examined with variously sized and weighted items. The suggested gripper model achieved an RMSE performance of 2.9 and a Pearson correlation of 0.993.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001920",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Computer science",
      "Control engineering",
      "Displacement (psychology)",
      "Engineering",
      "GRASP",
      "Grippers",
      "Mechanical engineering",
      "Programming language",
      "Psychology",
      "Psychotherapist",
      "Robot",
      "Simulation",
      "Soft robotics",
      "Stiffness",
      "Structural engineering"
    ],
    "authors": [
      {
        "surname": "Dinakaran",
        "given_name": "Venkatesa Prabu"
      },
      {
        "surname": "Balasubramaniyan",
        "given_name": "Meenakshi Priya"
      },
      {
        "surname": "Le",
        "given_name": "Quynh Hoang"
      },
      {
        "surname": "Alrubaie",
        "given_name": "Ali Jawad"
      },
      {
        "surname": "Al-khaykan",
        "given_name": "Ameer"
      },
      {
        "surname": "Muthusamy",
        "given_name": "Suresh"
      },
      {
        "surname": "Panchal",
        "given_name": "Hitesh"
      },
      {
        "surname": "Jaber",
        "given_name": "Mustafa Musa"
      },
      {
        "surname": "Dixit",
        "given_name": "Anil Kumar"
      },
      {
        "surname": "Prakash",
        "given_name": "Chander"
      }
    ]
  },
  {
    "title": "Evaluation of safety-related performance of wearable lower limb exoskeleton robot (WLLER): A systematic review",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104308",
    "abstract": "Wearable lower limb exoskeleton robots (WLLER) have broad development prospects in the military, industrial and medical fields. The intelligent device comes into intimate contact with the human body, and its safety is an essential factor that developers must consider. With the increasing research on the safety of WLLER, its safety test methods and indicators should gradually improve. By examining current test methods and indicators, this study aims to mobilize this information and summarize the most recent safety research. The safety-related studies reviewed in this paper are not limited to evaluating subjects in clinical trials but are concerned with extensive safety research. The focus of our analysis is the test performance indicators. Some functional evaluation indicators are also summarized to explore a broader and more applicable approach on the safety metrics. We found that, in general, most researchers pay attention to the power-assisting performance of WLLER, but the stability and comfort have been largely ignored. At the same time, our analysis also reveals that although there are a wide variety of existing evaluation indicators, uniform and standard test methods and indicators for safety testing of WLLER are still deficient. Based on these results, we identified and discussed several promising research directions that may help the community to attain a widely accepted test method that can objectively evaluate the safety of WLLER.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902200197X",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Embedded system",
      "Exoskeleton",
      "Medicine",
      "Paleontology",
      "Risk analysis (engineering)",
      "Robot",
      "Simulation",
      "Test (biology)",
      "Variety (cybernetics)",
      "Wearable computer"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Duojin"
      },
      {
        "surname": "Gu",
        "given_name": "Xiaoping"
      },
      {
        "surname": "Li",
        "given_name": "Wenzhuo"
      },
      {
        "surname": "Jin",
        "given_name": "Yaoxiang"
      },
      {
        "surname": "Yang",
        "given_name": "Maisi"
      },
      {
        "surname": "Yu",
        "given_name": "Hongliu"
      }
    ]
  },
  {
    "title": "A BPMN-driven framework for Multi-Robot System development",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104322",
    "abstract": "Programming robotic systems is often a challenging task requiring advanced skills, especially when the goal is to ensure loosely-coupled coordination in heterogeneous Multi-Robot Systems (MRSs). Model-driven approaches for robotic system engineering have shown their benefits in facilitating the development of robots’ behavior, controllers, and system components. However, the state of the art still lacks contributions addressing crucial aspects of the model-driven approach applied to MRSs, such as developing robots’ distributed cooperation through models supporting the communication among robots. In this paper, we present a novel framework for modeling, configuring and enacting the cooperative behaviors of MRSs through collaboration diagrams as provided by the BPMN 2.0 standard. The advantages of our solution lie, indeed, in the use of BPMN, which provides easily understandable and highly expressive diagrams for representing the cooperation among distributed robots, and benefits from a wide list of supporting tools. Starting from the selection of BPMNelements, we define a set of guidelines for driving the developer in modeling an MRS mission using BPMN. The developer configures the resulting collaboration diagram to link elements in the model to the robotic middleware, ROS2 in the toolchain we implemented. Finally, the configured model is enacted by BPMN engines integrated into the ROS2 middleware run by each robot involved in the MRS, thus obtaining a fully distributed cooperation. We assess our framework’s effectiveness through experiments in simulated and real environments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002111",
    "keywords": [
      "Artificial intelligence",
      "Business",
      "Business Process Model and Notation",
      "Business process",
      "Business process modeling",
      "Computer science",
      "Distributed computing",
      "Engineering",
      "Human–computer interaction",
      "Marketing",
      "Metamodeling",
      "Middleware (distributed applications)",
      "Programming language",
      "Robot",
      "Set (abstract data type)",
      "Software",
      "Software engineering",
      "Systems engineering",
      "Toolchain",
      "Work in process"
    ],
    "authors": [
      {
        "surname": "Corradini",
        "given_name": "Flavio"
      },
      {
        "surname": "Pettinari",
        "given_name": "Sara"
      },
      {
        "surname": "Re",
        "given_name": "Barbara"
      },
      {
        "surname": "Rossi",
        "given_name": "Lorenzo"
      },
      {
        "surname": "Tiezzi",
        "given_name": "Francesco"
      }
    ]
  },
  {
    "title": "The human-following strategy for mobile robots in mixed environments",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104317",
    "abstract": "The robot behavior strategy is considered as a crucial part in the human-following task to help the robot maintain an appropriate distance and orientation to the selected target person (STP) with a smooth and safe manner. As usual, the robot is uniquely considered to follow the STP in a specific class of environments, such as unknown environments (non-mapped environments) or known environments (mapped environments). However, in real-life applications, the robot is sometimes requested to follow the STP in various types of environments, both in known and unknown ones. This observation raises the need to propose an alternative method to challenge the mentioned issue, as well as to break the current limit of the human-following function. In this paper, a new approach for the human-following strategy is proposed in which the mobile robot is enabled to follow the STP in mixed environments (non-mapped and mapped). In non-mapped environments, only the STP and the obstacle information with respect to the robot local coordinates are considered, whose purpose is to make the robot work without any prior understandings about its working environment. However, after the robot entered mapped environments, its prior knowledge of the working environment is leveraged to fulfill some additional requirements during the cooperation, such as the mobile robot in factories is not allowed to enter some specific areas even when the STP is executing technical tasks inside. Additionally, in this paper, a human-like inference mechanism is also introduced for the human-following strategy by using an extended hedge algebras. The proposed method is experimentally verified both in factories and laboratories. Demo Video Link: https://www.youtube.com/watch?v=YGrWU6ldKuw Since real videos in the factory are not allowed to publish, only visualization (in Rviz) is presented for demos in such kinds of environments. The visualization is synchronous with the real executions of the human–robot interactions. The robot used in the factory is an autonomous mobile robot (dimension 0.5 (m) ×1.0 (m), weight 120 (kg), carrying a tool cabinet around 300(kg))). The mobile robot is following the worker to support them during the technical processes in the car production line. In the video, the robot is represented by a green rectangular, and the STP is represented by a cylinder (with a sphere on its head) The events in the demo video are described more clearly in Appendix A.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002068",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Human–computer interaction",
      "Law",
      "Management",
      "Mobile robot",
      "Obstacle",
      "Political science",
      "Robot",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Toan",
        "given_name": "Nguyen Van"
      },
      {
        "surname": "Do Hoang",
        "given_name": "Minh"
      },
      {
        "surname": "Khoi",
        "given_name": "Phan Bui"
      },
      {
        "surname": "Yi",
        "given_name": "Soo-Yeong"
      }
    ]
  },
  {
    "title": "Best Axes Composition extended: Multiple gyroscopes and accelerometers data fusion to reduce systematic error",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104316",
    "abstract": "Multiple rigidly attached Inertial Measurement Unit (IMU) sensors provide a richer flow of data compared to a single IMU. State-of-the-art methods follow a probabilistic model of IMU measurements based on the random nature of errors combined under a Bayesian framework. However, affordable low-grade IMUs, in addition, suffer from systematic errors due to their imperfections not covered by their corresponding probabilistic model. In this paper, we propose a method, the Best Axes Composition (BAC) of combining Multiple IMU (MIMU) sensors data for accurate 3D-pose estimation that takes into account both random and systematic errors by dynamically choosing the best IMU axes from the set of all available axes. We evaluate our approach on our MIMU visual–inertial sensor and compare the performance of the method with a purely probabilistic state-of-the-art approach of MIMU data fusion. We show that BAC outperforms the latter and achieves up to 20% accuracy improvement for both orientation and position estimation in open loop, but needs proper treatment to keep the obtained gain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002056",
    "keywords": [
      "Accelerometer",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Geometry",
      "Gyroscope",
      "Inertial measurement unit",
      "Inertial navigation system",
      "Mathematics",
      "Operating system",
      "Orientation (vector space)",
      "Physics",
      "Probabilistic logic",
      "Quantum mechanics",
      "Sensor fusion",
      "Statistical model",
      "Units of measurement"
    ],
    "authors": [
      {
        "surname": "Faizullin",
        "given_name": "Marsel"
      },
      {
        "surname": "Ferrer",
        "given_name": "Gonzalo"
      }
    ]
  },
  {
    "title": "On the parameter identification of free-flying space manipulator systems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104310",
    "abstract": "A novel parameter identification method is proposed, which identifies all the parameters required for the reconstruction of free-flying space manipulator system dynamics. Its key advantage is that it does not use acceleration measurements; thus, it is less sensitive to sensor noise than other methods. The method is based on the conservation of angular momentum and on a kinematic equation including a Jacobian. To apply the method, all manipulator joints are commanded to follow optimized exciting trajectories, while the system is in free-floating mode. The estimated parameters render the free-flying system dynamics fully identified and available to model-based control. The method applies to multi-arm systems and is validated by simulation and experiments with excellent results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001993",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Free space",
      "Identification (biology)",
      "Manipulator (device)",
      "Mathematics",
      "Operating system",
      "Optics",
      "Parameter space",
      "Physics",
      "Robot",
      "Space (punctuation)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Christidi-Loumpasefski",
        "given_name": "Olga-Orsalia"
      },
      {
        "surname": "Papadopoulos",
        "given_name": "Evangelos"
      }
    ]
  },
  {
    "title": "Adaptive estimation of UAV altitude in complex indoor environments using degraded and time-delayed measurements with time-varying uncertainties",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104315",
    "abstract": "A novel approach for robust Unmanned Aerial Vehicle (UAV) altitude estimation relying on laser measurements that is designed for use in complex indoor environments is proposed in this paper. Specifically, we aim to design a system with general usability inside multi-floor buildings. The multi-floor buildings are characterized by areas lacking distinct vertical geometric features to be used as reference by 3D Light Detection and Ranging (LiDAR) localization algorithms, and by areas with either flat floors or limited areas with inconsistent ground elevation. The proposed approach solves the problem of adaptive fusion of data from multiple sources with apriori-unknown confidence dependent on the current environmental properties. Whenever the environment contains enough geometric structure, altitude data from a 3D LiDAR-based Simultaneous Localization and Mapping (SLAM) algorithm are utilized. In environments that are too symmetrical for reliable SLAM operation, the approach relies mostly on measurements from a downward-facing 1D laser rangefinder, while simultaneously detecting inconsistent ground elevation areas. These measurements are fused with barometer data, Inertial Measurement Unit (IMU) data, and information from the UAV position controllers. Furthermore, our approach correctly handles the measurement delay caused by 3D LiDAR data processing that significantly differs from other sensor delays. The performance of the proposed approach has been validated in complex simulations and real-world experiments with the produced altitude estimate utilized in the control loop of the UAV. The proposed approach is released as open-source as part of the MRS UAV System.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002044",
    "keywords": [
      "A priori and a posteriori",
      "Altitude (triangle)",
      "Artificial intelligence",
      "Barometer",
      "Computer science",
      "Computer vision",
      "Elevation (ballistics)",
      "Epistemology",
      "Geography",
      "Geometry",
      "Ground truth",
      "Inertial measurement unit",
      "Lidar",
      "Mathematics",
      "Meteorology",
      "Mobile robot",
      "Philosophy",
      "Ranging",
      "Real-time computing",
      "Remote sensing",
      "Robot",
      "Sensor fusion",
      "Simultaneous localization and mapping",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Pritzl",
        "given_name": "Václav"
      },
      {
        "surname": "Vrba",
        "given_name": "Matouš"
      },
      {
        "surname": "Tortorici",
        "given_name": "Claudio"
      },
      {
        "surname": "Ashour",
        "given_name": "Reem"
      },
      {
        "surname": "Saska",
        "given_name": "Martin"
      }
    ]
  },
  {
    "title": "Dynamic obstacle avoidance for Multi-rotor UAV using chance-constraints based on obstacle velocity",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104320",
    "abstract": "To ensure the safety of autonomous Multi-rotor UAVs flying in urban airspace, they should be capable of avoiding collisions with unpredictable dynamic obstacles, such as birds. UAVs must consider both relative position and relative velocity to avoid moving obstacles. Model predictive control (MPC) can consider the multiple collision avoidance constraints in a constrained optimisation framework. This study proposes a chance-constraints based on obstacle velocity (CCOV) method, which can be combined with previous positional chance constraint methods to account for uncertainty in both position and velocity. This effectively prevents collision with high-velocity obstacles, even in a noisy environment. The proposed method has been performed on a numerical simulation built in MATLAB.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002093",
    "keywords": [
      "Artificial intelligence",
      "Collision",
      "Collision avoidance",
      "Computer science",
      "Computer security",
      "Constraint (computer-aided design)",
      "Control (management)",
      "Control theory (sociology)",
      "Economics",
      "Engineering",
      "Finance",
      "Geometry",
      "Law",
      "MATLAB",
      "Mathematics",
      "Mechanical engineering",
      "Mobile robot",
      "Obstacle",
      "Obstacle avoidance",
      "Operating system",
      "Physics",
      "Political science",
      "Position (finance)",
      "Quantum mechanics",
      "Relative velocity",
      "Robot",
      "Rotor (electric)",
      "Simulation"
    ],
    "authors": [
      {
        "surname": "Wakabayashi",
        "given_name": "Takumi"
      },
      {
        "surname": "Yukimasa Suzuki",
        "given_name": ""
      },
      {
        "surname": "Suzuki",
        "given_name": "Satoshi"
      }
    ]
  },
  {
    "title": "Learning and extrapolation of robotic skills using task-parameterized equation learner networks",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104309",
    "abstract": "Imitation learning approaches achieve good generalization within the range of the training data, but tend to generate unpredictable motions when querying outside this range. We present a novel approach to imitation learning with enhanced extrapolation capabilities that exploits the so-called Equation Learner Network (EQLN). Unlike conventional approaches, EQLNs use supervised learning to fit a set of analytical expressions that allows them to extrapolate beyond the range of the training data. We augment the task demonstrations with a set of task-dependent parameters representing spatial properties of each motion and use them to train the EQLN. At run time, the features are used to query the Task-Parameterized Equation Learner Network (TP-EQLN) and generate the corresponding robot trajectory. The set of features encodes kinematic constraints of the task such as desired height or a final point to reach. We validate the results of our approach on manipulation tasks where it is important to preserve the shape of the motion in the extrapolation domain. Our approach is also compared with existing state-of-the-art approaches, in simulation and in real setups. The experimental results show that TP-EQLN can respect the constraints of the trajectory encoded in the feature parameters, even in the extrapolation domain, while preserving the overall shape of the trajectory provided in the demonstrations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001981",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Astronomy",
      "Classical mechanics",
      "Composite material",
      "Computer science",
      "Economics",
      "Extrapolation",
      "Feature (linguistics)",
      "Generalization",
      "Kinematics",
      "Linguistics",
      "Machine learning",
      "Management",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Motion (physics)",
      "Parameterized complexity",
      "Philosophy",
      "Physics",
      "Programming language",
      "Range (aeronautics)",
      "Robot",
      "Set (abstract data type)",
      "Task (project management)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Perez-Villeda",
        "given_name": "Hector"
      },
      {
        "surname": "Piater",
        "given_name": "Justus"
      },
      {
        "surname": "Saveriano",
        "given_name": "Matteo"
      }
    ]
  },
  {
    "title": "Skill-based design of dependable robotic architectures",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104318",
    "abstract": "Software architectures for autonomous systems are generally structured with 3 layers: a decisional layer managing autonomous reasoning, a functional layer managing reactive tasks and processing, and an executive layer bridging the gap between both. The executive layer plays a central role, as it links high-level tasks with low-level processing, and is generally responsible for the robustness or the fault-tolerance of the overall system. In this paper, we propose a development process for such an executive layer that emphasizes on the dependability of this layer. To do so, we structure the executive layer using skills, that are formally defined using a specific language, and we then provide some tools to verify these models, generate some code, and a methodology to assess the fault-tolerance of the resulting architecture.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902200207X",
    "keywords": [
      "Architecture",
      "Art",
      "Biochemistry",
      "Bridging (networking)",
      "Chemistry",
      "Computer architecture",
      "Computer network",
      "Computer science",
      "Dependability",
      "Distributed computing",
      "Embedded system",
      "Fault tolerance",
      "Gene",
      "Layer (electronics)",
      "Organic chemistry",
      "Process (computing)",
      "Programming language",
      "Robustness (evolution)",
      "Software",
      "Software engineering",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Albore",
        "given_name": "Alexandre"
      },
      {
        "surname": "Doose",
        "given_name": "David"
      },
      {
        "surname": "Grand",
        "given_name": "Christophe"
      },
      {
        "surname": "Guiochet",
        "given_name": "Jérémie"
      },
      {
        "surname": "Lesire",
        "given_name": "Charles"
      },
      {
        "surname": "Manecy",
        "given_name": "Augustin"
      }
    ]
  },
  {
    "title": "A resilient solution to Range-Only SLAM based on a decoupled landmark range and bearing reconstruction",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104324",
    "abstract": "A Range Only Simultaneous Localization and Mapping (RO-SLAM) problem is considered in this paper. The robot is a unicycle like vehicle equipped with encoders on the actuated wheels, which measures the distance to a set of UWB landmarks located in unknown position in the surrounding. A Multi Hypotheses Extended Kalman Filter (MHEKF), one for each landmark, is designed to dynamically estimate the range and the bearing of the observed landmark. These estimates, regarded as measurements with a proper covariance matrix, are used in an EKF SLAM algorithm, endowed with a resilient module to discern and possibly to temporarily discard landmarks with an unreliable range and bearing estimate. This allows to cope with the initial uncertainty characterizing the bearing reconstruction, but also to resist the effects of outliers and to detect possible abnormal situations. Simulation and experimental results illustrate the effectiveness of the proposed approach compared to other methods available in the literature, especially in case of significant perturbations, like the sudden and unmodeled shift of the landmarks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002135",
    "keywords": [
      "Artificial intelligence",
      "Bearing (navigation)",
      "Composite material",
      "Computer science",
      "Computer vision",
      "Covariance",
      "Economics",
      "Extended Kalman filter",
      "Finance",
      "Kalman filter",
      "Landmark",
      "Materials science",
      "Mathematics",
      "Mobile robot",
      "Outlier",
      "Position (finance)",
      "Range (aeronautics)",
      "Robot",
      "Simultaneous localization and mapping",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Martinelli",
        "given_name": "Francesco"
      },
      {
        "surname": "Mattogno",
        "given_name": "Simone"
      },
      {
        "surname": "Romanelli",
        "given_name": "Fabrizio"
      }
    ]
  },
  {
    "title": "Online gait generator for lower limb exoskeleton robots: Suitable for level ground, slopes, stairs, and obstacle avoidance",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104319",
    "abstract": "The development of lower limb exoskeletons has seen significant interest in recent times. Two types of them are more used that cover two types of needs: gait rehabilitation and human locomotion assistance. An essential subject in controlling the latter kind is trajectory generation, in which there are still challenges. For online controlling of the exoskeleton, gait parameters must have the ability to change at any moment during walking, taking into account human intention and particular conditions. In this paper, an online gait generation method is provided that is suitable for different walking modes. For this purpose, three trajectory generator blocks are proposed. The first block is for the center of mass (CoM) in the double support phase, where the trajectory is generated to make the patient feel more comfortable. The second block is for the support leg in the single support phase. The trajectory is generated using the center of pressure (CoP) criterion to secure backward balance and reduce the forces applied to the arms. The last block is for the swing leg in the single support phase, where a cost function is proposed to minimize the torques of the motors. The performance analysis of the proposed trajectory generator blocks was evaluated, and walking patterns were examined via simulations. Finally, three experimental tests were implemented with a healthy subject wearing Exoped® exoskeleton on level-ground with an obstacle, and stairs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002081",
    "keywords": [
      "Aerodynamics",
      "Aerospace engineering",
      "Artificial intelligence",
      "Astronomy",
      "Block (permutation group theory)",
      "Center of pressure (fluid mechanics)",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Exoskeleton",
      "Gait",
      "Generator (circuit theory)",
      "Geometry",
      "Ground reaction force",
      "Kinematics",
      "Law",
      "Mathematics",
      "Medicine",
      "Obstacle",
      "Physical medicine and rehabilitation",
      "Physics",
      "Political science",
      "Power (physics)",
      "Powered exoskeleton",
      "Preferred walking speed",
      "Quantum mechanics",
      "Robot",
      "Simulation",
      "Stairs",
      "Structural engineering",
      "Thermodynamics",
      "Torque",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Mohamad",
        "given_name": "Habib"
      },
      {
        "surname": "Ozgoli",
        "given_name": "Sadjaad"
      }
    ]
  },
  {
    "title": "A robotic learning and generalization framework for curved surface based on modified DMP",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104323",
    "abstract": "How to reproduce and generalize the skills acquired by demonstrating is a hot topic for researchers. (1) A compliant continuous drag demonstration system based on discrete admittance model was designed to continuously and smoothly drag or demonstrate. (2) The modified DMP including the scaling factor and the force coupling term was used to improve the poor generalization ability of the classical DMP. (3) Curve drawing experiments were carried out to show the effectiveness of our proposed learning and generalization framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002123",
    "keywords": [
      "Admittance",
      "Artificial intelligence",
      "Computer science",
      "Drag",
      "Electrical impedance",
      "Generalization",
      "Geometry",
      "Mathematical analysis",
      "Mathematics",
      "Mechanics",
      "Physics",
      "Quantum mechanics",
      "Scaling",
      "Surface (topology)"
    ],
    "authors": [
      {
        "surname": "Xue",
        "given_name": "Xianfa"
      },
      {
        "surname": "Dong",
        "given_name": "Jiale"
      },
      {
        "surname": "Lu",
        "given_name": "Zhenyu"
      },
      {
        "surname": "Wang",
        "given_name": "Ning"
      }
    ]
  },
  {
    "title": "A Survey on the autonomous exploration of confined subterranean spaces: Perspectives from real-word and industrial robotic deployments",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104304",
    "abstract": "Confined and subterranean areas are common in many civilian and industrial sites, although they are hazardous for humans given the presence of noxious gases, extreme temperatures, narrow spaces, unhealthy oxygen levels, flooding, and collapsing structures. Therefore, exploration, routine inspections, and surveillance tasks can benefit from using autonomous mobile robots to improve safety by reducing the presence of humans in those scenarios. However, despite advances in the field, there are still challenges to overcome for confined and subterranean robot operation. Real word robotic exploration requires robust and reliable map generation, precise localization, safe navigation, and efficient path planning. These requirements make exploration in complex 3D environments with rugged terrain difficult. The challenge is increased when considering multi-robot teams, as there is no guarantee of a functional network infrastructure. Despite consistent increasing interest in the area, there is a lack of research summarizing the results and best practices for exploring such environments. Therefore, in this paper, we provide a review and discuss state-of-the-art robotic exploration techniques, including single and cooperative approaches with homogeneous and heterogeneous teams, with a focus on complex subterranean and confined 3D scenarios. We also present a comprehensive list of insights on open challenges and possible directions for future investigation in the topic.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001932",
    "keywords": [
      "Aerospace engineering",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Data science",
      "Ecology",
      "Engineering",
      "Field (mathematics)",
      "Flooding (psychology)",
      "Focus (optics)",
      "Human–computer interaction",
      "Mathematics",
      "Mobile robot",
      "Open research",
      "Optics",
      "Physics",
      "Psychology",
      "Psychotherapist",
      "Pure mathematics",
      "Robot",
      "Search and rescue",
      "Situation awareness",
      "Terrain",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Azpúrua",
        "given_name": "Héctor"
      },
      {
        "surname": "Saboia",
        "given_name": "Maíra"
      },
      {
        "surname": "Freitas",
        "given_name": "Gustavo M."
      },
      {
        "surname": "Clark",
        "given_name": "Lillian"
      },
      {
        "surname": "Agha-mohammadi",
        "given_name": "Ali-akbar"
      },
      {
        "surname": "Pessin",
        "given_name": "Gustavo"
      },
      {
        "surname": "Campos",
        "given_name": "Mario F.M."
      },
      {
        "surname": "Macharet",
        "given_name": "Douglas G."
      }
    ]
  },
  {
    "title": "Skill generalization of tubular object manipulation with tactile sensing and Sim2Real learning",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104321",
    "abstract": "Tubular objects such as test tubes are common in chemistry and life sciences research laboratories, and robots that can handle them have the potential to accelerate experiments. Moreover, it is expected to train a robot to manipulate tubular objects in a simulator and then deploy it in a real-world environment. However, it is still challenging for a robot to learn to handle tubular objects through single sensing and bridge the gap between simulation and reality. In this paper, we propose a novel tactile–motor policy learning method to generalize tubular object manipulation skills from simulation to reality. In particular, we propose a Sim-to-Real transferable in-hand pose estimation network that generalizes to unseen tubular objects. The network utilizes a novel adversarial domain adaptation network to narrow the pixel-level domain gap for tactile tasks by introducing the attention mechanism and a task-related constraint. The in-hand pose estimation network is further implemented in a Reinforcement Learning-based policy learning framework for robotic insert-and-pullout manipulation tasks. The proposed method is applied to a human–robot collaborative tube placing scenario and a robotic pipetting scenario. The experimental results demonstrate the generalization capability of the learned tactile–motor policy toward tubular object manipulation in research laboratories.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902200210X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Constraint (computer-aided design)",
      "Domain (mathematical analysis)",
      "Economics",
      "Engineering",
      "Generalization",
      "Human–computer interaction",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Mechanical engineering",
      "Object (grammar)",
      "Reinforcement learning",
      "Robot",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Yongqiang"
      },
      {
        "surname": "Jing",
        "given_name": "Xingshuo"
      },
      {
        "surname": "Qian",
        "given_name": "Kun"
      },
      {
        "surname": "Gomes",
        "given_name": "Daniel Fernandes"
      },
      {
        "surname": "Luo",
        "given_name": "Shan"
      }
    ]
  },
  {
    "title": "Consistency optimal coordination control of underground heavy-load robot in nonstructural environment",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104281",
    "abstract": "In order to guarantee the dynamic stability of robots in nonstructural environment, this paper proposes a new consistency optimal coordination (COC) control strategy. Firstly, by analyzing the topological structure, motion correlation and control coupling relationship among subsystems, the general expression of multi-body coupling system (MCS) for underground heavy-load robot is realized. Then, the transient spatial output deviations are proposed as the characterization of dynamic stability for the underground heavy-load robot. Afterwards, in order to reduce the strong coupling relationship among subsystems, the underground heavy-load robot is decoupled into fixed-point and non-fixed-point operation modes, the Nyquist stability and Lyapunov stability are applied to discriminate the dynamic stability of two working modes respectively. Finally, based on the idea of minimum loop gain compensation of mechanism, the COC control strategy is proposed, which can coordinate the subsystems to be consistent, so as to realize the dynamic stability of overall system in nonstructural environment. Both the experimental and situational results verify that the COC control strategy proposed in this paper not only realizes stable output of robot, but also effectively reduces the lag caused by instability. The work of this paper improves the dynamic stability analysis theory for robots, and promotes adaptability and dynamic response capability of moving robots as well.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001701",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Consistency (knowledge bases)",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Coupling (piping)",
      "Engineering",
      "Lyapunov stability",
      "Machine learning",
      "Mathematics",
      "Mechanical engineering",
      "Nyquist stability criterion",
      "Parametric statistics",
      "Robot",
      "Stability (learning theory)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Fang",
        "given_name": "Lixia"
      },
      {
        "surname": "Wang",
        "given_name": "Tong"
      },
      {
        "surname": "Zheng",
        "given_name": "Weixiong"
      },
      {
        "surname": "Liu",
        "given_name": "Zhigang"
      },
      {
        "surname": "Ming",
        "given_name": "Liu"
      },
      {
        "surname": "Zheng",
        "given_name": "Xiaowen"
      },
      {
        "surname": "Wu",
        "given_name": "Miao"
      }
    ]
  },
  {
    "title": "Congestion control algorithms for robotic swarms with a common target based on the throughput of the target area",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104284",
    "abstract": "When a large number of robots try to reach a common area, congestions happen, causing severe delays. To minimise congestion in a robotic swarm system, traffic control algorithms must be employed in a decentralised manner. Based on strategies aimed to maximise the throughput of the common target area, we developed two novel algorithms for robots using artificial potential fields for obstacle avoidance and navigation. One algorithm is inspired by creating a queue to get to the target area (Single Queue Former — SQF), while the other makes the robots touch the boundary of the circular area by using vector fields (Touch and Run Vector Fields — TRVF). We performed simulation experiments to show that the proposed algorithms are bounded by the throughput of their inspired theoretical strategies and compare the two novel algorithms with state-of-art algorithms for the same problem (PCC, EE and PCC–EE). The SQF algorithm significantly outperforms all other algorithms for a large number of robots or when the circular target region radius is small. TRVF, on the other hand, is better than SQF only for a limited number of robots and outperforms only PCC for numerous robots. However, it allows us to analyse the potential impacts on the throughput when transferring an idea from a theoretical strategy to a concrete algorithm that considers changing linear speeds and distances between robots.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001737",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Boundary (topology)",
      "Computer network",
      "Computer science",
      "Mathematical analysis",
      "Mathematics",
      "Queue",
      "Real-time computing",
      "Robot",
      "Swarm behaviour",
      "Telecommunications",
      "Throughput",
      "Wireless"
    ],
    "authors": [
      {
        "surname": "Passos",
        "given_name": "Yuri Tavares dos"
      },
      {
        "surname": "Duquesne",
        "given_name": "Xavier"
      },
      {
        "surname": "Marcolino",
        "given_name": "Leandro Soriano"
      }
    ]
  },
  {
    "title": "Mapping beyond what you can see: Predicting the layout of rooms behind closed doors",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104282",
    "abstract": "The availability of maps of indoor environments is often fundamental for autonomous mobile robots to efficiently operate in industrial, office, and domestic applications. When robots build such maps, some areas of interest could be inaccessible, for instance, due to closed doors. As a consequence, these areas are not represented in the maps, possibly causing limitations in robot localization and navigation. In this paper, we provide a method that completes 2D grid maps by adding the predicted layout of the rooms behind closed doors. The main idea of our approach is to exploit the underlying geometrical structure of indoor environments to estimate the shape of unobserved rooms. Results show that our method is accurate in completing maps also when large portions of environments cannot be accessed by the robot during map building. We experimentally validate the quality of the completed maps by using them to perform path planning tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001713",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Doors",
      "Exploit",
      "Geometry",
      "Grid",
      "Grid reference",
      "Human–computer interaction",
      "Mathematics",
      "Mobile robot",
      "Motion planning",
      "Operating system",
      "Path (computing)",
      "Programming language",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Luperto",
        "given_name": "Matteo"
      },
      {
        "surname": "Amadelli",
        "given_name": "Federico"
      },
      {
        "surname": "Di Berardino",
        "given_name": "Moreno"
      },
      {
        "surname": "Amigoni",
        "given_name": "Francesco"
      }
    ]
  },
  {
    "title": "INDI-based aggressive quadrotor flight control with position and attitude constraints",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104292",
    "abstract": "Recent studies have significantly contributed to the extensive use of quadrotors for delivery, mapping, and inspection. To further increase the versatility of quadrotors under confined environments, we focus on the precise trajectory tracking problem with position and attitude constraints. In tightly constrained scenarios, any slight error will infect flight security, especially in a large attitude maneuver. We utilize the incremental nonlinear dynamic inversion (INDI) method to precisely linearize the nonlinearities in the system and generalize it to the entire rotation space to reach a globally expressed control law. Meanwhile, the thrust alignment is introduced to improve the robustness against the mismatch between actuator dynamics and rotational dynamics, guaranteeing higher tracking accuracy. Improvements over a conventional geometry tracking controller are demonstrated in experiments where the quadrotor flies through an inclined narrow gap with orientation up to 90°. Flight tests also indicate the high disturbance rejection capabilities with the thrust alignment in gap traverse flight.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001816",
    "keywords": [
      "Actuator",
      "Aerospace engineering",
      "Artificial intelligence",
      "Attitude control",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Economics",
      "Engineering",
      "Finance",
      "Gene",
      "Geodesy",
      "Geography",
      "Geometry",
      "Inversion (geology)",
      "Mathematics",
      "Nonlinear system",
      "Orientation (vector space)",
      "Paleontology",
      "Physics",
      "Position (finance)",
      "Quantum mechanics",
      "Robustness (evolution)",
      "Structural basin",
      "Thrust",
      "Traverse"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Jiesong"
      },
      {
        "surname": "Cai",
        "given_name": "Zhihao"
      },
      {
        "surname": "Zhao",
        "given_name": "Jiang"
      },
      {
        "surname": "Wang",
        "given_name": "Zexin"
      },
      {
        "surname": "Ding",
        "given_name": "Yongfei"
      },
      {
        "surname": "Wang",
        "given_name": "Yingxun"
      }
    ]
  },
  {
    "title": "A formal toolchain for offline and run-time verification of robotic systems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104301",
    "abstract": "Validation and Verification (V&V) of autonomous robotic system software is becoming a critical issue. Among the V&V techniques at our disposal, formal approaches are among the most rigorous and trustworthy ones. Yet, the level of skills and knowledge required to use and deploy formal methods is usually quite high and rare. In this paper, we describe an approach that starts from a regular, but rigorous, framework to specify and deploy robotic software components, which can also automatically synthesize a formal model of these components. We describe how we can execute the resulting formal model, in place of a traditional implementation, and show how this provides the opportunity to add powerful monitoring and runtime verification capabilities to a system, e.g., to prevent collisions, or trigger an emergency landing. Since the runtime used to execute formal models is specifically designed to be faithful to their semantics, every execution (in the implementation) can be mapped to a trace in the specification. As a result, we can also prove many interesting properties offline, using model-checking techniques. We give several examples, such as properties about schedulability, worst-case traversal time, or mutual exclusion. We believe that having a consistent workflow, from an initial specification of our system, down to a formal, executable specification is a major advance in robotics and opens the way for verification of functional components of autonomous robots and beyond. We illustrate this claim by describing a complete example based on a genuine drone flight controller.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001907",
    "keywords": [
      "Computer science",
      "Database",
      "Executable",
      "Formal methods",
      "Formal semantics (linguistics)",
      "Formal specification",
      "Formal verification",
      "Linguistics",
      "Model checking",
      "Philosophy",
      "Programming language",
      "Runtime verification",
      "Software",
      "Software construction",
      "Software engineering",
      "Software system",
      "Software verification",
      "TRACE (psycholinguistics)",
      "Toolchain",
      "Workflow"
    ],
    "authors": [
      {
        "surname": "Dal Zilio",
        "given_name": "Silvano"
      },
      {
        "surname": "Hladik",
        "given_name": "Pierre-Emmanuel"
      },
      {
        "surname": "Ingrand",
        "given_name": "Félix"
      },
      {
        "surname": "Mallet",
        "given_name": "Anthony"
      }
    ]
  },
  {
    "title": "A non-potential orthogonal vector field method for more efficient robot navigation and control",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104291",
    "abstract": "To navigate and control a single mobile robot or a robotic swarm with higher efficiency, a novel non-potential orthogonal vector field method is proposed in this paper, which is modified from the traditional artificial potential field method. The improvement strategy aims at making the overall repulsive vector field orthogonal to the attractive vector field in some conditions. And the same potential field function is still applied to the Lyapunov-based stability analysis. In short, such an improvement strategy combines the advantages of the artificial potential field method with the non-potential vector field method, namely a combination of theoretical completeness and control efficiency. Finally, the effectiveness of the proposed method is validated both by numerical simulations with statistical significance and real experiments. The comparisons between our method and other methods are also presented.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001804",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Field (mathematics)",
      "Geology",
      "Geometry",
      "Geophysics",
      "Lyapunov function",
      "Machine learning",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Potential field",
      "Pure mathematics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Swarm behaviour",
      "Vector field"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Yan"
      },
      {
        "surname": "Bai",
        "given_name": "Chenggang"
      },
      {
        "surname": "Fu",
        "given_name": "Rao"
      },
      {
        "surname": "Quan",
        "given_name": "Quan"
      }
    ]
  },
  {
    "title": "Human–robot handover with prior-to-pass soft/rigid object classification via tactile glove",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104311",
    "abstract": "Human–robot handovers constitute a challenging and fundamental aspect of physical human–robot interaction. This paper describes the design and implementation of a human–robot handover pipeline in the case in which both soft and rigid objects are passed by the human to the robot. These objects require different profiles of grasping torques by the robot hand fingers, so as to avoid damaging them. As a viable solution to this problem, a tactile glove worn by the human is used to provide real-time information to a deep neural network, which classifies each object as soft or rigid in the pre-handover phase: this information is passed to the robot, which applies the grasping torque profile suitable for the specific type of object. The proposed method is designed and validated based on experiments with eight human participants and 24 objects. The outcomes of these experiments regarding classification accuracy, force and torque profiles, and evaluation of the subjective experiences via questionnaires, are described and discussed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022002007",
    "keywords": [
      "Artificial intelligence",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Handover",
      "Human–computer interaction",
      "Human–robot interaction",
      "Object (grammar)",
      "Physics",
      "Pipeline (software)",
      "Programming language",
      "Robot",
      "Simulation",
      "Thermodynamics",
      "Torque"
    ],
    "authors": [
      {
        "surname": "Mazhitov",
        "given_name": "Ayan"
      },
      {
        "surname": "Syrymova",
        "given_name": "Togzhan"
      },
      {
        "surname": "Kappassov",
        "given_name": "Zhanat"
      },
      {
        "surname": "Rubagotti",
        "given_name": "Matteo"
      }
    ]
  },
  {
    "title": "Adaptive path planning for UAVs for multi-resolution semantic segmentation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104288",
    "abstract": "Efficient data collection methods play a major role in helping us better understand the Earth and its ecosystems. In many applications, the usage of unmanned aerial vehicles (UAVs) for monitoring and remote sensing is rapidly gaining momentum due to their high mobility, low cost, and flexible deployment. A key challenge is planning missions to maximize the value of acquired data in large environments given flight time limitations. This is, for example, relevant for monitoring agricultural fields. This paper addresses the problem of adaptive path planning for accurate semantic segmentation of using UAVs. We propose an online planning algorithm which adapts the UAV paths to obtain high-resolution semantic segmentations necessary in areas with fine details as they are detected in incoming images. This enables us to perform close inspections at low altitudes only where required, without wasting energy on exhaustive mapping at maximum image resolution. A key feature of our approach is a new accuracy model for deep learning-based architectures that captures the relationship between UAV altitude and semantic segmentation accuracy. We evaluate our approach on different domains using real-world data, proving the efficacy and generability of our solution.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001774",
    "keywords": [
      "Artificial intelligence",
      "Computer network",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Data mining",
      "Feature (linguistics)",
      "Key (lock)",
      "Linguistics",
      "Machine learning",
      "Motion planning",
      "Path (computing)",
      "Philosophy",
      "Real-time computing",
      "Robot",
      "Segmentation",
      "Software deployment",
      "Software engineering"
    ],
    "authors": [
      {
        "surname": "Stache",
        "given_name": "Felix"
      },
      {
        "surname": "Westheider",
        "given_name": "Jonas"
      },
      {
        "surname": "Magistri",
        "given_name": "Federico"
      },
      {
        "surname": "Stachniss",
        "given_name": "Cyrill"
      },
      {
        "surname": "Popović",
        "given_name": "Marija"
      }
    ]
  },
  {
    "title": "Online pole segmentation on range images for long-term LiDAR localization in urban environments",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104283",
    "abstract": "Robust and accurate localization is a basic requirement for mobile autonomous systems. Pole-like objects, such as traffic signs, poles, and lamps are frequently used landmarks for localization in urban environments due to their local distinctiveness and long-term stability. In this paper, we present a novel, accurate, and fast pole extraction approach based on geometric features that runs online and has little computational demands. Our method performs all computations directly on range images generated from 3D LiDAR scans, which avoids processing 3D point clouds explicitly and enables fast pole extraction for each scan. We further use the extracted poles as pseudo labels to train a deep neural network for online range image-based pole segmentation. We test both our geometric and learning-based pole extraction methods for localization on different datasets with different LiDAR scanners, routes, and seasonal changes. The experimental results show that our methods outperform other state-of-the-art approaches. Moreover, boosted with pseudo pole labels extracted from multiple datasets, our learning-based method can run across different datasets and achieve even better localization results compared to our geometry-based method. We released our pole datasets to the public for evaluating the performance of pole extractors, as well as the implementation of our approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001725",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Computer vision",
      "Geology",
      "Lidar",
      "Materials science",
      "Pattern recognition (psychology)",
      "Physics",
      "Point cloud",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Remote sensing",
      "Segmentation",
      "Term (time)"
    ],
    "authors": [
      {
        "surname": "Dong",
        "given_name": "Hao"
      },
      {
        "surname": "Chen",
        "given_name": "Xieyuanli"
      },
      {
        "surname": "Särkkä",
        "given_name": "Simo"
      },
      {
        "surname": "Stachniss",
        "given_name": "Cyrill"
      }
    ]
  },
  {
    "title": "Improvement of Strong Tracking UKF-SLAM Approach using Three-position Ultrasonic Detection",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104305",
    "abstract": "As for the uncertainty problem of detection and estimation of robot localization and mapping using ultrasonic sensor, this paper proposes the improvement of Strong Tracking UKF-SLAM approach using three-position ultrasonic detection. A three-position ultrasonic detection model is first of all built for reducing these uncertainties through topological relationship screening and environmental contour estimation. Then Strong Tracking UKF-SLAM approach is improved by using multiple fade factors to fuse the ultrasonic measurement data and motion model information of robot for obtaining more accurate localization and mapping. Finally, we construct simulation and indoor experimental environments and design the mobile robot system with ultrasonic sensor for verification. The simulation represents that the improved algorithm has less error and more accurate effect than original algorithms in localization and mapping of mobile robot. The indoor environmental experiment is performed for illustrating the feasibility and effectiveness of the proposed method. The proposed method has certain reference value for research of Simultaneous Localization and Mapping.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001944",
    "keywords": [
      "Acoustics",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Economics",
      "Electrical engineering",
      "Engineering",
      "Finance",
      "Fuse (electrical)",
      "Mobile robot",
      "Pedagogy",
      "Physics",
      "Position (finance)",
      "Psychology",
      "Robot",
      "Simultaneous localization and mapping",
      "Tracking (education)",
      "Ultrasonic sensor"
    ],
    "authors": [
      {
        "surname": "Yuan",
        "given_name": "Shuai"
      },
      {
        "surname": "Wu",
        "given_name": "Jian"
      },
      {
        "surname": "Luan",
        "given_name": "Fangjun"
      },
      {
        "surname": "Zhang",
        "given_name": "Lili"
      },
      {
        "surname": "Lv",
        "given_name": "Jiaqi"
      }
    ]
  },
  {
    "title": "Exploiting the confusions of semantic places to improve service robotic tasks in indoor environments",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104290",
    "abstract": "A significant challenge in service robots is the semantic understanding of their surrounding areas. Traditional approaches addressed this problem by segmenting the environment into regions corresponding to full rooms that are assigned labels consistent with human perception, e.g. office or kitchen. However, different areas inside the same room can be used in different ways: Could the table and the chair in my kitchen become my office ? What is the category of that area now? office or kitchen? To adapt to these circumstances we propose a new paradigm where we intentionally relax the resulting labeling of place classifiers by allowing confusions, and by avoiding further filtering leading to clean full room classifications. Our hypothesis is that confusions can be beneficial to a service robot and, therefore, they can be kept and better exploited. Our approach creates a subdivision of the environment into different regions by maintaining the confusions which are due to the scene appearance or to the distribution of objects. In this paper, we present a proof of concept implemented in simulated and real scenarios, that improves efficiency in the robotic task of searching for objects by exploiting the confusions in place classifications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001798",
    "keywords": [
      "Archaeology",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Data mining",
      "Economics",
      "Economy",
      "History",
      "Human–computer interaction",
      "Management",
      "Neuroscience",
      "Operating system",
      "Perception",
      "Proof of concept",
      "Robot",
      "Service (business)",
      "Service robot",
      "Subdivision",
      "Table (database)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Hernandez",
        "given_name": "Alejandra C."
      },
      {
        "surname": "Gomez",
        "given_name": "Clara"
      },
      {
        "surname": "Barber",
        "given_name": "Ramon"
      },
      {
        "surname": "Mozos",
        "given_name": "Oscar Martinez"
      }
    ]
  },
  {
    "title": "Real-time multi-modal semantic fusion on unmanned aerial vehicles with label propagation for cross-domain adaptation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104286",
    "abstract": "Unmanned aerial vehicles (UAVs) equipped with multiple complementary sensors have tremendous potential for fast autonomous or remote-controlled semantic scene analysis, e.g., for disaster examination. Here, we propose a UAV system for real-time semantic inference and fusion of multiple sensor modalities. Semantic segmentation of LiDAR scans and RGB images, as well as object detection on RGB and thermal images, run online onboard the UAV computer using lightweight CNN architectures and embedded inference accelerators. We follow a late fusion approach where semantic information from multiple sensor modalities augments 3D point clouds and image segmentation masks while also generating an allocentric semantic map. Label propagation on the semantic map allows for sensor-specific adaptation with cross-modality and cross-domain supervision. Our system provides augmented semantic images and point clouds with ≈ 9Hz. We evaluate the integrated system in real-world experiments in an urban environment and at a disaster test site.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001750",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Domain (mathematical analysis)",
      "Geology",
      "Inference",
      "Lidar",
      "Mathematical analysis",
      "Mathematics",
      "Point cloud",
      "Programming language",
      "RGB color model",
      "Real-time computing",
      "Remote sensing",
      "Segmentation",
      "Semantic mapping",
      "Semantics (computer science)"
    ],
    "authors": [
      {
        "surname": "Bultmann",
        "given_name": "Simon"
      },
      {
        "surname": "Quenzel",
        "given_name": "Jan"
      },
      {
        "surname": "Behnke",
        "given_name": "Sven"
      }
    ]
  },
  {
    "title": "Balanced task allocation and collision-free scheduling of multi-robot systems in large spacecraft structure manufacturing",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104289",
    "abstract": "The use of multiple cooperating industrial robots provides efficient and flexible solutions to the manufacturing of complex aerospace structures. Such applications require the workloads to be sufficiently shared between neighboring robots, this entails the collision-free scheduling of many discrete tasks, where precedence orders need to be assigned for specific tasks. In this paper, we first present a two-step task allocation method that handles workload balancing, then a scheduling algorithm combining construction heuristic with iterated local search to provide efficient schedules. Our key innovation is a collision model that encodes precedence constraints and a fast heuristic that constructs collision-free schedule under given constraints, the optimization of the schedule is then addressed by an iterated local search. The advantage in terms of minimizing makespan under different problem scales and conditions is validated by computational experiments. Finally, the use of our method is demonstrated by a physical multi-robot system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001786",
    "keywords": [
      "Aerospace",
      "Algorithm",
      "Artificial intelligence",
      "Collision",
      "Collision avoidance",
      "Computer science",
      "Computer security",
      "Distributed computing",
      "Heuristic",
      "Iterated local search",
      "Job shop scheduling",
      "Key (lock)",
      "Law",
      "Mathematical optimization",
      "Mathematics",
      "Metaheuristic",
      "Operating system",
      "Political science",
      "Robot",
      "Schedule",
      "Scheduling (production processes)",
      "Workload"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Shaorui"
      },
      {
        "surname": "Shen",
        "given_name": "Jianxin"
      },
      {
        "surname": "Tian",
        "given_name": "Wei"
      },
      {
        "surname": "Lin",
        "given_name": "Jiamei"
      },
      {
        "surname": "Li",
        "given_name": "Pengcheng"
      },
      {
        "surname": "Li",
        "given_name": "Bo"
      }
    ]
  },
  {
    "title": "Audio–visual language instruction understanding for robotic sorting",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104271",
    "abstract": "For robot in human environment, it has always been expected that the robot can execute specified tasks following language instructions. Most current methods only rely on visual perception to understand the language instruction, while it may be not sufficient to fully interpret some language instructions when visually identical objects exist. In this paper, we propose a task of audio–visual language instruction understanding for robotic sorting, in which the robot is able to use both the visual and audio information to fully understand and execute the given instruction. To solve the proposed task, an audio–visual fusion framework is developed, which combines the visual localization and audio recognition models together for the robotic sorting task following language instruction. We have also collected a multimodal dataset for evaluation, and extensive experiments are conducted within the dataset and generalized to new scenarios in physical world demonstrating the effectiveness of the proposed framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001609",
    "keywords": [
      "Artificial intelligence",
      "Audio visual",
      "Biology",
      "Computer science",
      "Economics",
      "Human–computer interaction",
      "Management",
      "Multimedia",
      "Neuroscience",
      "Perception",
      "Programming language",
      "Robot",
      "Sorting",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Di"
      },
      {
        "surname": "Liu",
        "given_name": "Huaping"
      },
      {
        "surname": "Sun",
        "given_name": "Fuchun"
      }
    ]
  },
  {
    "title": "Systematic solution for optimally energy-efficient turning radius for wheeled skid-steer rovers",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104306",
    "abstract": "A skid-steer rover’s power consumption is highly dependent on the turning radius of its path, with a point turn consuming much more power compared to straight line motion. As energy is the integration of instantaneous power over time, a trade-off between arcs’ turning radii and lengths should be made to minimize energy consumption. Because of the skid-steer rovers’ ability to do point turns the simplest and shortest way to traverse a distance between two points is by doing a point turn-line-point turn (PLP) maneuver. However, we show that wheeled skid-steer rovers there are scenarios where optimal Circle–Line–Circle (CLC) paths consume less energy than PLP paths. Therefore, the goal in this work is to find the best path from among CLC paths; Karush–Kuhn–Tucker (KKT) conditions are used to systematically obtain the optimally energy-efficient answer for the CLC paths. It is assumed that the rovers move forward on hard flat ground. For solving the problem, a new practical constraint constant-v c is suggested. In this paper, comparing the KKT conditions and experimental results reveals that the lowest total energy consumption for CLC paths with or without considering constant-v c constraint is obtained by selecting turning radii equal to R ′ (the half of slip-track).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001956",
    "keywords": [
      "Aerospace engineering",
      "Artificial intelligence",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Electrical engineering",
      "Energy consumption",
      "Engineering",
      "Geodesy",
      "Geography",
      "Karush–Kuhn–Tucker conditions",
      "Mathematical optimization",
      "Mathematics",
      "Path (computing)",
      "Programming language",
      "Simulation",
      "Traverse",
      "Turning radius"
    ],
    "authors": [
      {
        "surname": "Effati",
        "given_name": "Meysam"
      },
      {
        "surname": "Skonieczny",
        "given_name": "Krzysztof"
      }
    ]
  },
  {
    "title": "Power solutions for autonomous mobile robots: A survey",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104285",
    "abstract": "Autonomous mobile robots are a special class of robotic systems that can move a payload from one location to the other or perform a specific task. They allow efficient, precise, and streamlined workflow that makes human work less arduous. The market and research work related to these robots is increasing in anticipation of industry 5.0, where humans and machines are expected to co-exist and co-work. The future mobile robots are desired to have clean and cost-effective energy sources to have longer operation times and compliance with environmental requirements to allow application in diverse fields. The research on mechanical design, perception, navigation and control has carved out many commercially viable solutions for mobile robots. However, their widespread application is still limited due to the lack of efficient power systems for use in diverse and largely unknown/uncontrolled environments. The current power solutions incur high initial costs and require recharging or refuelling, which makes them unsuitable for unattended long-haul worktimes and cost-effective applications. These drawbacks are major hurdles in the wider applicability of terrain-based mobile robots to new domains and daily life scenarios, which are possible with the existing mechanical, perception, and control technologies. Keeping in view the need for advancement in this field and to gain a better understanding of the current state of the art and future directions, this work summarizes and reviews the energy solutions presented in the literature and used in notable commercially available terrain-based mobile robots. The provided solutions are categorized and discussed while the prospects and research gaps are also highlighted. A comparison of discussed power techniques is also provided, which can serve as a guideline for selecting a robot’s energy source according to the desired requirements.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001749",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer security",
      "Database",
      "Ecology",
      "Engineering",
      "Field (mathematics)",
      "Human–computer interaction",
      "Mathematics",
      "Mechanical engineering",
      "Medicine",
      "Mobile robot",
      "Network packet",
      "Payload (computing)",
      "Pure mathematics",
      "Risk analysis (engineering)",
      "Robot",
      "Simulation",
      "Terrain",
      "Work (physics)",
      "Workflow"
    ],
    "authors": [
      {
        "surname": "Farooq",
        "given_name": "Muhammad Umar"
      },
      {
        "surname": "Eizad",
        "given_name": "Amre"
      },
      {
        "surname": "Bae",
        "given_name": "Hyun-Ki"
      }
    ]
  },
  {
    "title": "Static map generation from 3D LiDAR point clouds exploiting ground segmentation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104287",
    "abstract": "A clean and reliable map of the environment is key for a variety of robotic tasks including localization, path planning, and navigation. Dynamic objects are an inherent part of our world, but their presence often deteriorates the performance of various mapping algorithms. This not only makes it important but necessary to remove these dynamic points from the map before they can be used for other tasks such as path planning. In this paper, we address the problem of building maps of the static aspects of the world by detecting and removing dynamic points from the source point clouds. We target a map cleaning approach that removes the dynamic points and maintains a high quality map of the static part of the world. To this end, we propose a novel offline ground segmentation method and integrate it into the OctoMap to better distinguish between the moving objects and static road backgrounds. We evaluate our approach using SemanticKITTI for both, dynamic object removal and ground segmentation algorithms as well as on the Apollo dataset. The evaluation results show that our method outperforms the baseline methods in both tasks and achieves good performance in generating clean maps over different datasets without any change in the parameters.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001762",
    "keywords": [
      "Artificial intelligence",
      "Baseline (sea)",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Geology",
      "Key (lock)",
      "Lidar",
      "Motion planning",
      "Object (grammar)",
      "Oceanography",
      "Point cloud",
      "Remote sensing",
      "Robot",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Arora",
        "given_name": "Mehul"
      },
      {
        "surname": "Wiesmann",
        "given_name": "Louis"
      },
      {
        "surname": "Chen",
        "given_name": "Xieyuanli"
      },
      {
        "surname": "Stachniss",
        "given_name": "Cyrill"
      }
    ]
  },
  {
    "title": "Deep reinforcement learning of event-triggered communication and consensus-based control for distributed cooperative transport",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104307",
    "abstract": "In this paper, we present a solution to a design problem of control strategies for multi-agent cooperative transport. Although existing learning-based methods assume that the number of agents is the same as that in the training environment, the number might differ in reality considering that the robots’ batteries may completely discharge, or additional robots may be introduced to reduce the time required to complete a task. Therefore, it is crucial that the learned strategy be applicable to scenarios wherein the number of agents differs from that in the training environment. In this paper, we propose a novel multi-agent reinforcement learning framework of event-triggered communication and consensus-based control for distributed cooperative transport. The proposed policy model estimates the resultant force and torque in a consensus manner using the estimates of the resultant force and torque with the neighborhood agents. Moreover, it computes the control and communication inputs to determine when to communicate with the neighboring agents under local observations and estimates of the resultant force and torque. Therefore, the proposed framework can balance the control performance and communication savings in scenarios wherein the number of agents differs from that in the training environment. We confirm the effectiveness of our approach by using a maximum of eight and six robots in the simulations and experiments, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001968",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Control (management)",
      "Distributed computing",
      "Economics",
      "Event (particle physics)",
      "Management",
      "Physics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Robot",
      "Task (project management)",
      "Thermodynamics",
      "Torque"
    ],
    "authors": [
      {
        "surname": "Shibata",
        "given_name": "Kazuki"
      },
      {
        "surname": "Jimbo",
        "given_name": "Tomohiko"
      },
      {
        "surname": "Matsubara",
        "given_name": "Takamitsu"
      }
    ]
  },
  {
    "title": "Robust deflection control and analysis of a fishing rod-type flexible robotic manipulator for collaborative robotics",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104293",
    "abstract": "Due to high-speed operation at low inertia, flexible manipulators are becoming more and more popular in today’s world. These manipulators produce excessive vibration, which must be reduced using an efficient control technique for the manipulator to function well. In the present study, a flexible manipulator model with a single link is built in such a manner that it can be considered as a flexible fishing rod. The free end of the flexible rod has a provision for applying a payload, which serves to give a deflection of the flexible rod. A lumped parameter method is adopted for modelling the flexible rod as well as the string using the Sim-Mechanics tool in MATLAB. Simulations were carried out for sudden and sinusoidal loading. It has been found that the flexible link produces excessive vibration under both sudden and sinusoidal loading. A proportional integral derivative (PID) controller is used to suppress the excessive vibration generated in the simulation model. Four different locations (Location 1: 15 cm; Location 2: 30 cm; Location 3: 45 cm; and Location 4: 60 cm) are selected for controller positioning. Simulation revealed that the minimum deflection was observed at location 4, i.e., at the tip for both sudden and sinusoidal loading. The developed model is validated using two loading conditions, viz., the beam’s self-weight and a point load of 30 N at the free end. It has been found that the simulation results resemble the analytical results with an error of 0.44% and 0.36% for both the loading conditions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001828",
    "keywords": [
      "Acoustics",
      "Artificial intelligence",
      "Classical mechanics",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Deflection (physics)",
      "Engineering",
      "Inertia",
      "MATLAB",
      "Network packet",
      "Operating system",
      "Optics",
      "PID controller",
      "Parallel manipulator",
      "Payload (computing)",
      "Physics",
      "Robot",
      "Robotics",
      "Simulation",
      "Soft robotics",
      "Temperature control",
      "Vibration"
    ],
    "authors": [
      {
        "surname": "Sarkhel",
        "given_name": "Prasenjit"
      },
      {
        "surname": "Dikshit",
        "given_name": "Mithilesh K."
      },
      {
        "surname": "Pathak",
        "given_name": "Vimal Kumar"
      },
      {
        "surname": "Saxena",
        "given_name": "Kuldeep K."
      },
      {
        "surname": "Prakash",
        "given_name": "C."
      },
      {
        "surname": "Buddhi",
        "given_name": "Dharam"
      }
    ]
  },
  {
    "title": "Learning to Control Highly Accelerated Ballistic Movements on Muscular Robots",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104230",
    "abstract": "High-speed and high-acceleration movements are inherently hard to control. Applying learning to the control of such motions on anthropomorphic robot arms can improve the control’s accuracy but might damage the system. The inherent exploration of learning approaches can lead to instabilities and the robot reaching joint limits at high speeds. Having hardware that enables safe exploration of high-speed and high-acceleration movements is therefore desirable. To address this issue, we propose to use robots actuated by pneumatic artificial muscles (PAMs). In this paper, we present a four degrees of freedom (DoFs) robot arm that reaches high joint angle accelerations of up to 28000°s-2 while avoiding dangerous joint limits thanks to the antagonistic actuation and limits on the air pressure ranges. With this robot arm, we can tune control parameters using Bayesian optimization directly on the hardware without additional safety considerations. The achieved tracking performance on a fast trajectory exceeds previous results on comparable PAM-driven robots. We also show that our system can be controlled well on slow trajectories with PID controllers due to careful construction considerations such as minimal bending of cables, lightweight kinematics, and minimal contact between PAMs and PAMs with the links. Finally, we propose a novel technique to control the co-contraction of antagonistic muscle pairs. Experimental results illustrate that choosing the optimal co-contraction level is vital to reach better tracking performance. Using PAM-driven robots and learning, we do a small step towards the future development of robots capable of more human-like motions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001348",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Human–computer interaction",
      "Robot",
      "Simulation"
    ],
    "authors": [
      {
        "surname": "Büchler",
        "given_name": "Dieter"
      },
      {
        "surname": "Calandra",
        "given_name": "Roberto"
      },
      {
        "surname": "Peters",
        "given_name": "Jan"
      }
    ]
  },
  {
    "title": "A survey of Semantic Reasoning frameworks for robotic systems",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104294",
    "abstract": "Robots are increasingly transitioning from specialized, single-task machines to general-purpose systems that operate in diverse and dynamic environments. To address the challenges associated with operation in real-world domains, robots must effectively generalize knowledge, learn, and be transparent in their decision making. This survey examines Semantic Reasoning techniques for robotic systems, which enable robots to encode and use semantic knowledge, including concepts, facts, ideas, and beliefs about the world. Continually perceiving, understanding, and generalizing semantic knowledge allows a robot to identify the meaningful patterns shared between problems and environments, and therefore more effectively perform a wide range of real-world tasks. We identify the three common components that make up a computational Semantic Reasoning Framework: knowledge sources, computational frameworks, and world representations. We analyze the existing implementations and the key characteristics of these components, highlight the many interactions that occur between them, and examine their integration for solving robotic tasks related to five aspects of the world, including objects, spaces, agents, tasks, and actions. By analyzing the computational formulation and underlying mechanisms of existing methods, we provide a unified view of the wide range of semantic reasoning techniques and identify open areas for future research.",
    "link": "https://www.sciencedirect.com/science/article/pii/S092188902200183X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Data science",
      "Engineering",
      "Human–computer interaction",
      "Implementation",
      "Key (lock)",
      "Robot",
      "Software engineering",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Weiyu"
      },
      {
        "surname": "Daruna",
        "given_name": "Angel"
      },
      {
        "surname": "Patel",
        "given_name": "Maithili"
      },
      {
        "surname": "Ramachandruni",
        "given_name": "Kartik"
      },
      {
        "surname": "Chernova",
        "given_name": "Sonia"
      }
    ]
  },
  {
    "title": "Consensus-based fast and energy-efficient multi-robot task allocation",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104270",
    "abstract": "In a multi-robot system, the appropriate allocation of the tasks to the individual robots is a very significant component. The availability of a centralized infrastructure can guarantee an optimal allocation of the tasks. However, in many important scenarios such as search and rescue, exploration, disaster-management, war-field, etc., on-the-fly allocation of the dynamic tasks to the robots in a decentralized fashion is the only possible option. Efficient communication among the robots plays a crucial role in any such decentralized setting. Existing works on distributed Multi-Robot Task Allocation (MRTA) either assume that the network is available or a naive communication paradigm is used. On the contrary, in most of these scenarios, the network infrastructure is either unstable or unavailable and ad-hoc networking is the only resort. Recent developments in synchronous-transmission (ST) based wireless communication protocols are shown to be more efficient than the traditional asynchronous transmission-based protocols in ad hoc networks such as Wireless Sensor Network (WSN)/Internet of Things (IoT) applications. The current work is the first effort that utilizes ST for MRTA. Specifically, we propose an algorithm that efficiently adapts ST-based many-to-many interaction and minimizes the information exchange to reach a consensus for task allocation. We showcase the efficacy of the proposed algorithm through an extensive simulation-based study of its latency and energy-efficiency under different settings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001592",
    "keywords": [
      "Artificial intelligence",
      "Asynchronous communication",
      "Computer network",
      "Computer science",
      "Distributed computing",
      "Economics",
      "Efficient energy use",
      "Electrical engineering",
      "Engineering",
      "Latency (audio)",
      "Management",
      "Robot",
      "Task (project management)",
      "Telecommunications",
      "Wireless",
      "Wireless ad hoc network",
      "Wireless sensor network"
    ],
    "authors": [
      {
        "surname": "Mahato",
        "given_name": "Prabhat"
      },
      {
        "surname": "Saha",
        "given_name": "Sudipta"
      },
      {
        "surname": "Sarkar",
        "given_name": "Chayan"
      },
      {
        "surname": "Shaghil",
        "given_name": "Md."
      }
    ]
  },
  {
    "title": "Caster Walker GAIT Trainer (CGT): A robotic assistive device",
    "journal": "Robotics and Autonomous Systems",
    "year": "2023",
    "doi": "10.1016/j.robot.2022.104302",
    "abstract": "Stroke has become one of the leading causes of lower limb paresis. Costing the patients, a fortune for its diagnosis and prognosis. Clinical experimentations have proven that one can regain ambulation if the rehabilitation is started in the acute or sub-acute stage. Traditional mode of rehabilitation include manual therapies which are labor-intensive and time consuming. Therefore, robotic training are preferred over manual therapies. Nevertheless, there are some limitations such as devices are bulky and complex, some are not portable, others need body weight support system, and costly. To address such issues, this paper proposes development of a new Caster Walker Gait Trainer (CGT) for gait rehabilitation. CGT is an end-effector based passive device in which Stephenson III six-bar linkage has been implemented to mimic the kinematics of a healthy gait. The trainer device uses a belt-pulley system for providing motion to the linkage. The lower limb of the patient gets the drive as he/she pushes the cater walker forward or backward. The paper also proposed the optimal design of defect-free Stephenson III six-bar linkage using loop-by-loop approach. To design the linkage, an optimal problem is formulated, and tear drop ankle trajectory is desired. The optimization problem is solved using a nature-inspired algorithm and it is found that the trajectory generated by the synthesized mechanism is able to mimic the desired trajectory. Then using the notion of inverse kinematics, hip and knee trajectories are obtained from the generated ankle trajectory for validation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0921889022001919",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Classical mechanics",
      "Computer science",
      "Gait",
      "Inverse kinematics",
      "Kinematics",
      "Medicine",
      "Physical medicine and rehabilitation",
      "Physical therapy",
      "Physics",
      "Rehabilitation",
      "Robot",
      "Simulation",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Singh",
        "given_name": "Ramanpreet"
      },
      {
        "surname": "Pathak",
        "given_name": "Vimal Kumar"
      },
      {
        "surname": "Sharma",
        "given_name": "Abhishek"
      },
      {
        "surname": "Chakraborty",
        "given_name": "Debaditya"
      },
      {
        "surname": "Saxena",
        "given_name": "Kuldeep K."
      },
      {
        "surname": "Prakash",
        "given_name": "C."
      },
      {
        "surname": "Buddhi",
        "given_name": "Dharam"
      },
      {
        "surname": "Salem",
        "given_name": "Karrar hazim"
      }
    ]
  }
]