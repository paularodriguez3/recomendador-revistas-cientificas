[
  {
    "title": "Learning lightweight super-resolution networks with weight pruning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.002",
    "abstract": "Single image super-resolution (SISR) has achieved significant performance improvements due to the deep convolutional neural networks (CNN). However, the deep learning-based method is computationally intensive and memory demanding, which limit its practical deployment, especially for mobile devices. Focusing on this issue, in this paper, we present a novel approach to compress SR networks by weight pruning. To achieve this goal, firstly, we explore a progressive optimization method to gradually zero out the redundant parameters. Then, we construct a sparse-aware attention module by exploring a pruning-based well-suited attention strategy. Finally, we propose an information multi-slicing network which extracts and integrates multi-scale features at a granular level to acquire a more lightweight and accurate SR network. Extensive experiments reflect the pruning method could reduce the model size without a noticeable drop in performance, making it possible to apply the start-of-the-art SR models in the real-world applications. Furthermore, our proposed pruning versions could achieve better accuracy and visual improvements than state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003075",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Construct (python library)",
      "Convolutional neural network",
      "Deep learning",
      "Heuristic",
      "Machine learning",
      "Mobile device",
      "Operating system",
      "Pattern recognition (psychology)",
      "Programming language",
      "Pruning",
      "Slicing",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Xinrui"
      },
      {
        "surname": "Wang",
        "given_name": "Nannan"
      },
      {
        "surname": "Xin",
        "given_name": "Jingwei"
      },
      {
        "surname": "Xia",
        "given_name": "Xiaobo"
      },
      {
        "surname": "Yang",
        "given_name": "Xi"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Schematic memory persistence and transience for efficient and robust continual learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.011",
    "abstract": "Continual learning is considered a promising step toward next-generation Artificial Intelligence (AI), where deep neural networks (DNNs) make decisions by continuously learning a sequence of different tasks akin to human learning processes. It is still quite primitive, with existing works focusing primarily on avoiding (catastrophic) forgetting. However, since forgetting is inevitable given bounded memory and unbounded task loads, ‘how to reasonably forget’ is a problem continual learning must address in order to reduce the performance gap between AIs and humans, in terms of (1) memory efficiency, (2) generalizability, and (3) robustness when dealing with noisy data. To address this, we propose a novel ScheMAtic memory peRsistence and Transience (SMART) 1 1 Code available at: https://github.com/YuyangGao/SMART. framework for continual learning with external memory that builds on recent advances in neuroscience. The efficiency and generalizability are enhanced by a novel long-term forgetting mechanism and schematic memory, using sparsity and ‘backward positive transfer’ constraints with theoretical guarantees on the error bound. Robust enhancement is achieved using a novel short-term forgetting mechanism inspired by background information-gated learning. Finally, an extensive experimental analysis on both benchmark and real-world datasets demonstrates the effectiveness and efficiency of our model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003166",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biochemistry",
      "Chemistry",
      "Cognitive psychology",
      "Computer science",
      "Deep learning",
      "Electronic engineering",
      "Engineering",
      "Forgetting",
      "Gene",
      "Generalizability theory",
      "Geodesy",
      "Geography",
      "Inference",
      "Machine learning",
      "Mathematics",
      "Psychology",
      "Robustness (evolution)",
      "Schematic",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Yuyang"
      },
      {
        "surname": "Ascoli",
        "given_name": "Giorgio A."
      },
      {
        "surname": "Zhao",
        "given_name": "Liang"
      }
    ]
  },
  {
    "title": "Performance of biologically grounded models of the early visual system on standard object recognition tasks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.009",
    "abstract": "Computational neuroscience models of vision and neural network models for object recognition are often framed by different research agendas. Computational neuroscience mainly aims at replicating experimental data, while (artificial) neural networks target high performance on classification tasks. However, we propose that models of vision should be validated on object recognition tasks. At some point, mechanisms of realistic neuro-computational models of the visual cortex have to convince in object recognition as well. In order to foster this idea, we report the recognition accuracy for two different neuro-computational models of the visual cortex on several object recognition datasets. The models were trained using unsupervised Hebbian learning rules on natural scene inputs for the emergence of receptive fields comparable to their biological counterpart. We assume that the emerged receptive fields result in a general codebook of features, which should be applicable to a variety of visual scenes. We report the performances on datasets with different levels of difficulty, ranging from the simple MNIST to the more complex CIFAR-10 or ETH-80. We found that both networks show good results on simple digit recognition, comparable with previously published biologically plausible models. We also observed that our deeper layer neurons provide for naturalistic datasets a better recognition codebook. As for most datasets, recognition results of biologically grounded models are not available yet, our results provide a broad basis of performance values to compare methodologically similar models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003142",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Codebook",
      "Cognitive neuroscience of visual object recognition",
      "Computational model",
      "Computational neuroscience",
      "Computer science",
      "Hebbian theory",
      "MNIST database",
      "Machine learning",
      "Neuroscience",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Psychology",
      "Visual cortex"
    ],
    "authors": [
      {
        "surname": "Teichmann",
        "given_name": "Michael"
      },
      {
        "surname": "Larisch",
        "given_name": "René"
      },
      {
        "surname": "Hamker",
        "given_name": "Fred H."
      }
    ]
  },
  {
    "title": "Working Memory Connections for LSTM",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.030",
    "abstract": "Recurrent Neural Networks with Long Short-Term Memory (LSTM) make use of gating mechanisms to mitigate exploding and vanishing gradients when learning long-term dependencies. For this reason, LSTMs and other gated RNNs are widely adopted, being the standard de facto for many sequence modeling tasks. Although the memory cell inside the LSTM contains essential information, it is not allowed to influence the gating mechanism directly. In this work, we improve the gate potential by including information coming from the internal cell state. The proposed modification, named Working Memory Connection, consists in adding a learnable nonlinear projection of the cell content into the network gates. This modification can fit into the classical LSTM gates without any assumption on the underlying task, being particularly effective when dealing with longer sequences. Previous research effort in this direction, which goes back to the early 2000s, could not bring a consistent improvement over vanilla LSTM. As part of this paper, we identify a key issue tied to previous connections that heavily limits their effectiveness, hence preventing a successful integration of the knowledge coming from the internal cell state. We show through extensive experimental evaluation that Working Memory Connections constantly improve the performance of LSTMs on a variety of tasks. Numerical results suggest that the cell state contains useful information that is worth including in the gate structure.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003439",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Connection (principal bundle)",
      "De facto",
      "Economics",
      "Engineering",
      "Epistemology",
      "Gating",
      "Genetics",
      "Law",
      "Machine learning",
      "Management",
      "Mechanism (biology)",
      "Memory cell",
      "Philosophy",
      "Physics",
      "Physiology",
      "Political science",
      "Projection (relational algebra)",
      "Quantum mechanics",
      "Recurrent neural network",
      "Sequence (biology)",
      "State (computer science)",
      "Structural engineering",
      "Task (project management)",
      "Transistor",
      "Variety (cybernetics)",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Landi",
        "given_name": "Federico"
      },
      {
        "surname": "Baraldi",
        "given_name": "Lorenzo"
      },
      {
        "surname": "Cornia",
        "given_name": "Marcella"
      },
      {
        "surname": "Cucchiara",
        "given_name": "Rita"
      }
    ]
  },
  {
    "title": "Neural-network-based discounted optimal control via an integrated value iteration with accuracy guarantee",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.025",
    "abstract": "A data-based value iteration algorithm with the bidirectional approximation feature is developed for discounted optimal control. The unknown nonlinear system dynamics is first identified by establishing a model neural network. To improve the identification precision, biases are introduced to the model network. The model network with biases is trained by the gradient descent algorithm, where the weights and biases across all layers are updated. The uniform ultimate boundedness stability with a proper learning rate is analyzed, by using the Lyapunov approach. Moreover, an integrated value iteration with the discounted cost is developed to fully guarantee the approximation accuracy of the optimal value function. Then, the effectiveness of the proposed algorithm is demonstrated by carrying out two simulation examples with physical backgrounds.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003385",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Evolutionary biology",
      "Function (biology)",
      "Function approximation",
      "Gradient descent",
      "Lyapunov function",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Value (mathematics)"
    ],
    "authors": [
      {
        "surname": "Ha",
        "given_name": "Mingming"
      },
      {
        "surname": "Wang",
        "given_name": "Ding"
      },
      {
        "surname": "Liu",
        "given_name": "Derong"
      }
    ]
  },
  {
    "title": "Incremental multi-view spectral clustering with sparse and connected graph learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.031",
    "abstract": "In recent years, a lot of excellent multi-view clustering methods have been proposed. Because most of them need to fuse all views at one time, they are infeasible as the number of views increases over time. If the present multi-view clustering methods are employed directly to re-fuse all views at each time, it is too expensive to store all historical views. In this paper, we proposed an efficient incremental multi-view spectral clustering method with sparse and connected graph learning (SCGL). In our method, only one consensus similarity matrix is stored to represent the structural information of all historical views. Once the newly collected view is available, the consensus similarity matrix is reconstructed by learning from its previous version and the current new view. To further improve the incremental multi-view clustering performance, the sparse graph learning and the connected graph learning are integrated into our model, which can not only reduce the noises, but also preserve the correct connections within clusters. Experiments on several multi-view datasets demonstrate that our method is superior to traditional methods in clustering accuracy, and is more suitable to deal with the multi-view clustering with the number of views increasing over time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003440",
    "keywords": [
      "Artificial intelligence",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Computer science",
      "Consensus clustering",
      "Correlation clustering",
      "Data mining",
      "Electrical engineering",
      "Engineering",
      "Fuse (electrical)",
      "Gaussian",
      "Graph",
      "Image (mathematics)",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Similarity (geometry)",
      "Sparse matrix",
      "Spectral clustering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Yin",
        "given_name": "Hongwei"
      },
      {
        "surname": "Hu",
        "given_name": "Wenjun"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhao"
      },
      {
        "surname": "Lou",
        "given_name": "Jungang"
      },
      {
        "surname": "Miao",
        "given_name": "Minmin"
      }
    ]
  },
  {
    "title": "Nonlinear tensor train format for deep neural network compression",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.028",
    "abstract": "Deep neural network (DNN) compression has become a hot topic in the research of deep learning since the scale of modern DNNs turns into too huge to implement on practical resource constrained platforms such as embedded devices. Among variant compression methods, tensor decomposition appears to be a relatively simple and efficient strategy owing to its solid mathematical foundations and regular data structure. Generally, tensorizing neural weights into higher-order tensors for better decomposition, and directly mapping efficient tensor structure to neural architecture with nonlinear activation functions, are the two most common ways. However, the considerable accuracy loss is still a fly in the ointment for the tensorizing way especially for convolutional neural networks (CNNs), while the number of studies in the mapping way is comparatively limited and corresponding compression ratio appears to be not considerable. Therefore, in this work, by researching multiple types of tensor decompositions, we realize that tensor train (TT), which has specific and efficient sequenced contractions, is potential to take into account both of tensorizing and mapping ways. Then we propose a novel nonlinear tensor train (NTT) format, which contains extra nonlinear activation functions embedded in sequenced contractions and convolutions on the top of the normal TT decomposition and the proposed TT format connected by convolutions, to compensate the accuracy loss that normal TT cannot give. Further than just shrinking the space complexity of original weight matrices and convolutional kernels, we prove that NTT can afford an efficient inference time as well. Extensive experiments and discussions demonstrate that the compressed DNNs in our NTT format can almost maintain the accuracy at least on MNIST, UCF11 and CIFAR-10 datasets, and the accuracy loss caused by normal TT could be compensated significantly on large-scale datasets such as ImageNet.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003415",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Compression (physics)",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Epistemology",
      "Inference",
      "Materials science",
      "Mathematics",
      "Nonlinear system",
      "Philosophy",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Simple (philosophy)",
      "Tensor (intrinsic definition)",
      "Tensor decomposition",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Dingheng"
      },
      {
        "surname": "Zhao",
        "given_name": "Guangshe"
      },
      {
        "surname": "Chen",
        "given_name": "Hengnu"
      },
      {
        "surname": "Liu",
        "given_name": "Zhexian"
      },
      {
        "surname": "Deng",
        "given_name": "Lei"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      }
    ]
  },
  {
    "title": "ARAE: Adversarially robust training of autoencoders improves novelty detection",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.014",
    "abstract": "Autoencoders have recently been widely employed to approach the novelty detection problem. Trained only on the normal data, the AE is expected to reconstruct the normal data effectively while failing to regenerate the anomalous data. Based on this assumption, one could utilize the AE for novelty detection. However, it is known that this assumption does not always hold. Such an AE can often perfectly reconstruct the anomalous data due to modeling low-level and generic features in the input. We propose a novel training algorithm for the AE that facilitates learning more semantically meaningful features to address this problem. For this purpose, we exploit the fact that adversarial robustness promotes the learning of significant features. Therefore, we force the AE to learn such features by making its bottleneck layer more stable against adversarial perturbations. This idea is general and can be applied to other autoencoder-based approaches as well. We show that despite using a much simpler architecture than the prior methods, the proposed AE outperforms or is competitive to the state-of-the-art on four benchmark datasets and two medical datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003646",
    "keywords": [],
    "authors": [
      {
        "surname": "Salehi",
        "given_name": "Mohammadreza"
      },
      {
        "surname": "Arya",
        "given_name": "Atrin"
      },
      {
        "surname": "Pajoum",
        "given_name": "Barbod"
      },
      {
        "surname": "Otoofi",
        "given_name": "Mohammad"
      },
      {
        "surname": "Shaeiri",
        "given_name": "Amirreza"
      },
      {
        "surname": "Rohban",
        "given_name": "Mohammad Hossein"
      },
      {
        "surname": "Rabiee",
        "given_name": "Hamid R."
      }
    ]
  },
  {
    "title": "A neural decoding algorithm that generates language from visual activity evoked by natural images",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.006",
    "abstract": "Transforming neural activities into language is revolutionary for human–computer interaction as well as functional restoration of aphasia. Present rapid development of artificial intelligence makes it feasible to decode the neural signals of human visual activities. In this paper, a novel Progressive Transfer Language Decoding Model (PT-LDM) is proposed to decode visual fMRI signals into phrases or sentences when natural images are being watched. The PT-LDM consists of an image-encoder, a fMRI encoder and a language-decoder. The results showed that phrases and sentences were successfully generated from visual activities. Similarity analysis showed that three often-used evaluation indexes BLEU, ROUGE and CIDEr reached 0.182, 0.197 and 0.680 averagely between the generated texts and the corresponding annotated texts in the testing set respectively, significantly higher than the baseline. Moreover, we found that higher visual areas usually had better performance than lower visual areas and the contribution curve of visual response patterns in language decoding varied at successively different time points. Our findings demonstrate that the neural representations elicited in visual cortices when scenes are being viewed have already contained semantic information that can be utilized to generate human language. Our study shows potential application of language-based brain–machine interfaces in the future, especially for assisting aphasics in communicating more efficiently with fMRI signals.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003117",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Decoding methods",
      "Encoder",
      "Encoding (memory)",
      "Natural language",
      "Natural language processing",
      "Neural decoding",
      "Operating system",
      "Pattern recognition (psychology)",
      "Programming language",
      "Set (abstract data type)",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Wei"
      },
      {
        "surname": "Yan",
        "given_name": "Hongmei"
      },
      {
        "surname": "Cheng",
        "given_name": "Kaiwen"
      },
      {
        "surname": "Wang",
        "given_name": "Chong"
      },
      {
        "surname": "Li",
        "given_name": "Jiyi"
      },
      {
        "surname": "Wang",
        "given_name": "Yuting"
      },
      {
        "surname": "Li",
        "given_name": "Chen"
      },
      {
        "surname": "Li",
        "given_name": "Chaorong"
      },
      {
        "surname": "Li",
        "given_name": "Yunhan"
      },
      {
        "surname": "Zuo",
        "given_name": "Zhentao"
      },
      {
        "surname": "Chen",
        "given_name": "Huafu"
      }
    ]
  },
  {
    "title": "One-stage CNN detector-based benthonic organisms detection with limited training dataset",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.014",
    "abstract": "In this paper, focusing on the challenges in unique shape dimension and limited training dataset of benthonic organisms, an one-stage CNN detector-based benthonic organisms detection (OSCD-BOD) scheme is proposed. Main contributions are as follows: (1) The regression loss between the predicted bounding box and ground truth box is innovatively measured by the generalized intersection over union (GIoU), such that localization accuracy of benthonic organisms is dramatically enhanced. (2) By devising K-means-based dimension clustering, multiple benthonic organisms anchor boxes (BOAB) sufficiently exploring a priori dimension information can be finely derived from limited training dataset, and thereby significantly promoting the recall ability. (3) Geometric and color transformations (GCT)-based data augmentation technique is further resorted to not only efficiently prevent over-fitting training but also to significantly enhance detection generalization in complex and changeable underwater environments. (4) The OSCD-BOD scheme is eventually established in a modular manner by integrating GIoU, BOAB and GCT functionals. Comprehensive experiments and comparisons sufficiently demonstrate that the proposed OSCD-BOD scheme outperforms typical approaches including Faster R-CNN, SSD, YOLOv2, YOLOv3 and CenterNet in terms of mean average precision by 6.88%, 10.92%, 12.44%, 3.05% and 1.09%, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003191",
    "keywords": [
      "A priori and a posteriori",
      "Aerospace engineering",
      "Algorithm",
      "Artificial intelligence",
      "Bounding overwatch",
      "Cluster analysis",
      "Computer science",
      "Detector",
      "Dimension (graph theory)",
      "Engineering",
      "Epistemology",
      "Generalization",
      "Geology",
      "Image (mathematics)",
      "Intersection (aeronautics)",
      "Mathematical analysis",
      "Mathematics",
      "Minimum bounding box",
      "Modular design",
      "Operating system",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pure mathematics",
      "Scheme (mathematics)",
      "Stage (stratigraphy)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Tingkai"
      },
      {
        "surname": "Wang",
        "given_name": "Ning"
      },
      {
        "surname": "Wang",
        "given_name": "Rongfeng"
      },
      {
        "surname": "Zhao",
        "given_name": "Hong"
      },
      {
        "surname": "Zhang",
        "given_name": "Guichen"
      }
    ]
  },
  {
    "title": "P-DIFF+: Improving learning classifier with noisy labels by Noisy Negative Learning loss",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.024",
    "abstract": "Learning deep neural network (DNN) classifier with noisy labels is a challenging task because the DNN can easily over-fit on these noisy labels due to its high capability. In this paper, we present a very simple but effective training paradigm called P-DIFF+, which can train DNN classifiers but obviously alleviate the adverse impact of noisy labels. Our proposed probability difference distribution implicitly reflects the probability of a training sample to be clean, then this probability is employed to re-weight the corresponding sample during the training process. Moreover, Noisy Negative Learning(NNL) loss can be further employed to re-weight samples. P-DIFF+ can achieve good performance even without prior-knowledge on the noise rate of training samples. Experiments on benchmark datasets demonstrate that P-DIFF+ is superior to the state-of-the-art sample selection methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002872",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "QiHao"
      },
      {
        "surname": "Hu",
        "given_name": "Wei"
      },
      {
        "surname": "Huang",
        "given_name": "Yangyu"
      },
      {
        "surname": "Zhang",
        "given_name": "Fan"
      }
    ]
  },
  {
    "title": "Optimizing Deeper Spiking Neural Networks for Dynamic Vision Sensing",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.022",
    "abstract": "Spiking Neural Networks (SNNs) have recently emerged as a new generation of low-power deep neural networks due to sparse, asynchronous, and binary event-driven processing. Most previous deep SNN optimization methods focus on static datasets (e.g., MNIST) from a conventional frame-based camera. On the other hand, optimization techniques for event data from Dynamic Vision Sensor (DVS) cameras are still at infancy. Most prior SNN techniques handling DVS data are limited to shallow networks and thus, show low performance. Generally, we observe that the integrate-and-fire behavior of spiking neurons diminishes spike activity in deeper layers. The sparse spike activity results in a sub-optimal solution during training (i.e., performance degradation). To address this limitation, we propose novel algorithmic and architectural advances to accelerate the training of very deep SNNs on DVS data. Specifically, we propose Spike Activation Lift Training (SALT) which increases spike activity across all layers by optimizing both weights and thresholds in convolutional layers. After applying SALT, we train the weights based on the cross-entropy loss. SALT helps the networks to convey ample information across all layers during training and therefore improves the performance. Furthermore, we propose a simple and effective architecture, called Switched-BN, which exploits Batch Normalization (BN). Previous methods show that the standard BN is incompatible with the temporal dynamics of SNNs. Therefore, in Switched-BN architecture, we apply BN to the last layer of an SNN after accumulating all the spikes from previous layer with a spike voltage accumulator (i.e., converting temporal spike information to float value). Even though we apply BN in just one layer of SNNs, our results demonstrate a considerable performance gain without any significant computational overhead. Through extensive experiments, we show the effectiveness of SALT and Switched-BN for training very deep SNNs from scratch on various benchmarks including, DVS-Cifar10, N-Caltech, DHP19, CIFAR10, and CIFAR100. To the best of our knowledge, this is the first work showing state-of-the-art performance with deep SNNs on DVS data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003841",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "FLOPS",
      "MNIST database",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Software engineering",
      "Spike (software development)",
      "Spike train",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Youngeun"
      },
      {
        "surname": "Panda",
        "given_name": "Priyadarshini"
      }
    ]
  },
  {
    "title": "Observer-based event-triggered control for zero-sum games of input constrained multi-player nonlinear systems",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.012",
    "abstract": "In this paper, an event-triggered control (ETC) method is investigated to solve zero-sum game (ZSG) problems of unknown multi-player continuous-time nonlinear systems with input constraints by using adaptive dynamic programming (ADP). To relax the requirement of system dynamics, a neural network (NN) observer is constructed to identify the dynamics of multi-player system via the input and output data. Then, the event-triggered Hamilton–Jacobi–Isaacs (HJI) equation of the ZSG can be solved by constructing a critic NN, and the approximated optimal control law and the worst disturbance law can be obtained directly. A triggering scheme which determines the updating time instants of the control law and the disturbance law is developed. Thus, the proposed ADP-based ETC method cannot only reduce the computational burden, but also save communication resource and bandwidths. Furthermore, we prove that the signals of the closed-loop system and the approximate errors of the critic NN weights are uniformly ultimately bounded by using Lyapunov’s direct method, and the Zeno behavior is excluded. Finally, two simulation examples are provided to demonstrate the effectiveness of the proposed ETC scheme.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003178",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Observer (physics)",
      "Optimal control",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Shunchao"
      },
      {
        "surname": "Zhao",
        "given_name": "Bo"
      },
      {
        "surname": "Liu",
        "given_name": "Derong"
      },
      {
        "surname": "Zhang",
        "given_name": "Yongwei"
      }
    ]
  },
  {
    "title": "Adversarial parameter defense by multi-step risk minimization",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.022",
    "abstract": "Previous studies demonstrate DNNs’ vulnerability to adversarial examples and adversarial training can establish a defense to adversarial examples. In addition, recent studies show that deep neural networks also exhibit vulnerability to parameter corruptions. The vulnerability of model parameters is of crucial value to the study of model robustness and generalization. In this work, we introduce the concept of parameter corruption and propose to leverage the loss change indicators for measuring the flatness of the loss basin and the parameter robustness of neural network parameters. On such basis, we analyze parameter corruptions and propose the multi-step adversarial corruption algorithm. To enhance neural networks, we propose the adversarial parameter defense algorithm that minimizes the average risk of multiple adversarial parameter corruptions. Experimental results show that the proposed algorithm can improve both the parameter robustness and accuracy of neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003270",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Deep neural networks",
      "Gene",
      "Leverage (statistics)",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Minification",
      "Robustness (evolution)",
      "Vulnerability (computing)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Zhiyuan"
      },
      {
        "surname": "Luo",
        "given_name": "Ruixuan"
      },
      {
        "surname": "Ren",
        "given_name": "Xuancheng"
      },
      {
        "surname": "Su",
        "given_name": "Qi"
      },
      {
        "surname": "Li",
        "given_name": "Liangyou"
      },
      {
        "surname": "Sun",
        "given_name": "Xu"
      }
    ]
  },
  {
    "title": "A conversational model for eliciting new chatting topics in open-domain conversation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.021",
    "abstract": "In human conversations, the emergence of new topics is a key factor in enabling dialogues to last longer. Additional information brought by new topics can make the conversation more diverse and interesting. Chat-bots also need to be equipped with this ability to proactively elicit new chatting topics. However, previous studies have neglected the elicitation of new topics in open-domain conversations. At the same time, previous works have represented topics with word-level keywords or entities. However, a topic is open to multiple keywords and a keyword can reflect multiple potential topics. To move towards a fine-grained topic representation, we represent topic with topically related words. In this paper, we design a novel model, named CMTE, which focuses not only on coherence with context, but also brings up new chatting topics. In order to extract topic information from conversational utterances, a Topic Fetcher module is designed to fetch semantic-coherent topics with the help of topic model. To equip model with the ability to elicit new topics, a Topic Manager module is designed to associate the new topic with context. Finally, responses are generated by a well-designed fusion decoding mechanism to explicitly distinguish between topic words and general words. Experiment results show that our model is better than state of the art in automatic metrics and manual evaluations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003269",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Coherence (philosophical gambling strategy)",
      "Computer science",
      "Context (archaeology)",
      "Conversation",
      "Domain (mathematical analysis)",
      "Law",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Natural language processing",
      "Open domain",
      "Paleontology",
      "Philosophy",
      "Physics",
      "Political science",
      "Politics",
      "Quantum mechanics",
      "Question answering",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Weizhao"
      },
      {
        "surname": "Ge",
        "given_name": "Feng"
      },
      {
        "surname": "Cai",
        "given_name": "Yi"
      },
      {
        "surname": "Ren",
        "given_name": "Da"
      }
    ]
  },
  {
    "title": "Bipartite synchronization of signed networks via aperiodically intermittent control based on discrete-time state observations",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.035",
    "abstract": "In this paper, bipartite synchronization of signed networks with stochastic disturbances via aperiodically intermittent control is investigated. The aperiodically intermittent control presented is based on discrete-time state observations rather than continuous-time ones. To formulate signed networks and exhibit the competitive relation, a structurally balanced signed network is built and all the units are divided into two subcommunities. By employing Lyapunov method and graph theory, some sufficient conditions on bipartite synchronization are given. Meanwhile, when aperiodically intermittent control degenerates into periodically intermittent control and feedback control respectively, two corollaries are also provided to ensure the bipartite synchronization of the signed networks. Ultimately, two applications to coupled single-link robot arms and coupled oscillators are presented and corresponding numerical examples are respectively provided to verify the feasibility and effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003488",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Bipartite graph",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Discrete mathematics",
      "Discrete time and continuous time",
      "Engineering",
      "Graph",
      "Intermittent control",
      "Mathematics",
      "State (computer science)",
      "Statistics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Dongsheng"
      },
      {
        "surname": "Pang",
        "given_name": "Jiahuan"
      },
      {
        "surname": "Su",
        "given_name": "Huan"
      }
    ]
  },
  {
    "title": "TGAN: A simple model update strategy for visual tracking via template-guidance attention network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.010",
    "abstract": "Visual attention has been widely used in various fields of visual tasks in recent years. Recently, visual trackers based on probabilistic discriminative model prediction (PrDiMP) and Siamese box adaptive network (SiamBAN) have attracted much attention due to their excellent performance and high efficiency. However, the target template of the model in both the PrDiMP and SiamBAN is not updated online, and feature vectors of the template image and the search image are independent of each other in the IoU-Net and Siamese frameworks. In this research, we proposed a template-guidance attention network in both the IoU-Net (denoted as TGAN-I) and Siamese (denoted as TGAN-S) frameworks for visual tracking. TGAN-I and TGAN-S can comprehensively utilize the feature information of the template image and search image, and provide an implicit way to update the template. By utilizing a simple template update strategy, the TGAN-I and TGAN-S trackers can be more robust under certain challenging conditions such as occlusion and deformation. Besides, we introduce a channel and spatial attention module in feature maps of the template image and search image for adaptive feature refinement. Deformable convolutional networks are further used to enhance the model generalization capability in various transformations aspect ratios and scales of tracking targets. To verify the effectiveness of the proposed method, we evaluate the TGAN-I and TGAN-S trackers on six benchmarks and achieve state-of-the-art results. In particular, the TGAN-I method outperforms the strong baseline, PrDiMP, by 0.323 → 0.355 and 0.471 → 0.501 of EAO score on VOT2019 and VOT2016, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003154",
    "keywords": [
      "Artificial intelligence",
      "BitTorrent tracker",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Discriminative model",
      "Eye tracking",
      "Feature (linguistics)",
      "Generalization",
      "Image (mathematics)",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Template matching"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Kai"
      },
      {
        "surname": "Zhang",
        "given_name": "Haijun"
      },
      {
        "surname": "Zhou",
        "given_name": "Dongliang"
      },
      {
        "surname": "Liu",
        "given_name": "Linlin"
      }
    ]
  },
  {
    "title": "TACN: A Topical Adversarial Capsule Network for textual network embedding",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.026",
    "abstract": "Combining topological information and attributed information of nodes in networks effectively is a valuable task in network embedding. Nevertheless, many prior network embedding methods regarded attributed information of nodes as simple attribute sets or ignored them totally. In some scenarios, the hidden information contained in vertex attributes are essential to network embedding. For instance, networks that contain vertexes with text information play an increasingly important role in our life, including citation networks, social networks, and entry networks. In these textual networks, the latent topic relevance information of different vertexes contained in textual attributes information are valuable in the network analysis process. Shared latent topics of nodes in networks may influence the interaction between them, which is critical to network embedding. However, much prior work for textual network embedding only regarded the text information as simple word sets while ignored the embedded topic information. In this paper, we develop a model named Topical Adversarial Capsule Network (TACN) for textual network embedding, which extracts a low-dimensional latent space of the original network from node structures, vertex attributes, and topic information contained in text of nodes. The proposed TACN contains three parts. The first part is an embedding model, which extracts the embedding representation from the topological structure, vertex attributes, and document-topic distributions. To ensure a consistent training process by back-propagation, we generate document-topic distributions by the neural topic model with Gaussian Softmax constructions. The second part is a prediction model, which is used to exploit labels of vertices. In the third part, an adversarial capsule model is used to help distinguish the latent representations from node structure domain, vertex attribute domain, or document-topic distribution domain. The latent representations, which may come from the three domains, are the output of the embedding model. We incorporate the adversarial idea into the adversarial capsule model to combine the information from these three domains, rather than to distinguish the representations conventionally. Experiments on seven real-world datasets validate the effectiveness of our method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003889",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Embedding",
      "Exploit",
      "Graph",
      "Information retrieval",
      "Law",
      "Political science",
      "Relevance (law)",
      "Softmax function",
      "Theoretical computer science",
      "Vertex (graph theory)"
    ],
    "authors": [
      {
        "surname": "Qin",
        "given_name": "Xiaorui"
      },
      {
        "surname": "Rao",
        "given_name": "Yanghui"
      },
      {
        "surname": "Xie",
        "given_name": "Haoran"
      },
      {
        "surname": "Wang",
        "given_name": "Jiahai"
      },
      {
        "surname": "Wang",
        "given_name": "Fu Lee"
      }
    ]
  },
  {
    "title": "Intermittent control for finite-time synchronization of fractional-order complex networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.004",
    "abstract": "This paper is concerned with the finite-time synchronization problem for fractional-order complex dynamical networks (FCDNs) with intermittent control. Using the definition of Caputo’s fractional derivative and the properties of Beta function, the Caputo fractional-order derivative of the power function is evaluated. A general fractional-order intermittent differential inequality is obtained with fewer additional constraints. Then, the criteria are established for the finite-time convergence of FCDNs under intermittent feedback control, intermittent adaptive control and intermittent pinning control indicate that the setting time is related to order of FCDNs and initial conditions. Finally, these theoretical results are illustrated by numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003099",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Differential inclusion",
      "Economic growth",
      "Economics",
      "Engineering",
      "Evolutionary biology",
      "Finance",
      "Fractional calculus",
      "Function (biology)",
      "Intermittent control",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Order (exchange)",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Lingzhong"
      },
      {
        "surname": "Zhong",
        "given_name": "Jie"
      },
      {
        "surname": "Lu",
        "given_name": "Jianquan"
      }
    ]
  },
  {
    "title": "Parallel and hierarchical neural mechanisms for adaptive and predictive behavioral control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.009",
    "abstract": "Our brain can be recognized as a network of largely hierarchically organized neural circuits that operate to control specific functions, but when acting in parallel, enable the performance of complex and simultaneous behaviors. Indeed, many of our daily actions require concurrent information processing in sensorimotor, associative, and limbic circuits that are dynamically and hierarchically modulated by sensory information and previous learning. This organization of information processing in biological organisms has served as a major inspiration for artificial intelligence and has helped to create in silico systems capable of matching or even outperforming humans in several specific tasks, including visual recognition and strategy-based games. However, the development of human-like robots that are able to move as quickly as humans and respond flexibly in various situations remains a major challenge and indicates an area where further use of parallel and hierarchical architectures may hold promise. In this article we review several important neural and behavioral mechanisms organizing hierarchical and predictive processing for the acquisition and realization of flexible behavioral control. Then, inspired by the organizational features of brain circuits, we introduce a multi-timescale parallel and hierarchical learning framework for the realization of versatile and agile movement in humanoid robots.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003592",
    "keywords": [
      "Agile software development",
      "Artificial intelligence",
      "Artificial neural network",
      "Associative property",
      "Biological neural network",
      "Computer science",
      "Content-addressable memory",
      "Human–computer interaction",
      "Information processing",
      "Machine learning",
      "Mathematics",
      "Neuroscience",
      "Psychology",
      "Pure mathematics",
      "Realization (probability)",
      "Software engineering",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Macpherson",
        "given_name": "Tom"
      },
      {
        "surname": "Matsumoto",
        "given_name": "Masayuki"
      },
      {
        "surname": "Gomi",
        "given_name": "Hiroaki"
      },
      {
        "surname": "Morimoto",
        "given_name": "Jun"
      },
      {
        "surname": "Uchibe",
        "given_name": "Eiji"
      },
      {
        "surname": "Hikida",
        "given_name": "Takatoshi"
      }
    ]
  },
  {
    "title": "Active inference through whiskers",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.037",
    "abstract": "Rodents use whisking to probe actively their environment and to locate objects in space, hence providing a paradigmatic biological example of active sensing. Numerous studies show that the control of whisking has anticipatory aspects. For example, rodents target their whisker protraction to the distance at which they expect objects, rather than just reacting fast to contacts with unexpected objects. Here we characterize the anticipatory control of whisking in rodents as an active inference process. In this perspective, the rodent is endowed with a prior belief that it will touch something at the end of the whisker protraction, and it continuously modulates its whisking amplitude to minimize (proprioceptive and somatosensory) prediction errors arising from an unexpected whisker–object contact, or from a lack of an expected contact. We will use the model to qualitatively reproduce key empirical findings about the ways rodents modulate their whisker amplitude during exploration and the scanning of (expected or unexpected) objects. Furthermore, we will discuss how the components of active inference model can in principle map to the neurobiological circuits of rodent whisking.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003506",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Communication",
      "Computer science",
      "Computer vision",
      "Inference",
      "Neuroscience",
      "Operating system",
      "Physical chemistry",
      "Process (computing)",
      "Psychology",
      "Somatosensory system",
      "Whisker",
      "Whisking in animals"
    ],
    "authors": [
      {
        "surname": "Mannella",
        "given_name": "Francesco"
      },
      {
        "surname": "Maggiore",
        "given_name": "Federico"
      },
      {
        "surname": "Baltieri",
        "given_name": "Manuel"
      },
      {
        "surname": "Pezzulo",
        "given_name": "Giovanni"
      }
    ]
  },
  {
    "title": "Predictive coding feedback results in perceived illusory contours in a recurrent neural network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.024",
    "abstract": "Modern feedforward convolutional neural networks (CNNs) can now solve some computer vision tasks at super-human levels. However, these networks only roughly mimic human visual perception. One difference from human vision is that they do not appear to perceive illusory contours (e.g. Kanizsa squares) in the same way humans do. Physiological evidence from visual cortex suggests that the perception of illusory contours could involve feedback connections. Would recurrent feedback neural networks perceive illusory contours like humans? In this work we equip a deep feedforward convolutional network with brain-inspired recurrent dynamics. The network was first pretrained with an unsupervised reconstruction objective on a natural image dataset, to expose it to natural object contour statistics. Then, a classification decision head was added and the model was finetuned on a form discrimination task: squares vs. randomly oriented inducer shapes (no illusory contour). Finally, the model was tested with the unfamiliar “illusory contour” configuration: inducer shapes oriented to form an illusory square. Compared with feedforward baselines, the iterative “predictive coding” feedback resulted in more illusory contours being classified as physical squares. The perception of the illusory contour was measurable in the luminance profile of the image reconstructions produced by the model, demonstrating that the model really “sees” the illusion. Ablation studies revealed that natural image pretraining and feedback error correction are both critical to the perception of the illusion. Finally we validated our conclusions in a deeper network (VGG): adding the same predictive coding feedback dynamics again leads to the perception of illusory contours.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003373",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Coding (social sciences)",
      "Cognitive psychology",
      "Computer science",
      "Computer vision",
      "Control engineering",
      "Convolutional neural network",
      "Engineering",
      "Feed forward",
      "Illusion",
      "Illusory contours",
      "Mathematics",
      "Neural coding",
      "Neuroscience",
      "Optical illusion",
      "Pattern recognition (psychology)",
      "Perception",
      "Psychology",
      "Statistics",
      "Visual cortex"
    ],
    "authors": [
      {
        "surname": "Pang",
        "given_name": "Zhaoyang"
      },
      {
        "surname": "O’May",
        "given_name": "Callum Biggs"
      },
      {
        "surname": "Choksi",
        "given_name": "Bhavin"
      },
      {
        "surname": "VanRullen",
        "given_name": "Rufin"
      }
    ]
  },
  {
    "title": "Highly parallelized memristive binary neural network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.016",
    "abstract": "At present, in the new hardware design work of deep learning, memristor as a non-volatile memory with computing power has become a research hotspot. The weights in the deep neural network are the floating-point number. Writing a floating-point value into a memristor will result in a loss of accuracy, and the writing process will take more time. The binarized neural network (BNN) binarizes the weights and activation values that were originally floating-point numbers to +1 and -1. This will greatly reduce the storage space consumption and time consumption of programming the resistance value of the memristor. Furthermore, this will help to simplify the programming of memristors in deep neural network circuits and speed up the inference process. This paper provides a complete solution for implementing memristive BNN. Furthermore, we improved the design of the memristor crossbar by converting the input feature map and kernel before performing the convolution operation that can ensure the sign of the input voltage of each port constant. Therefore, we do not need to determine the sign of the input voltage required by the port in advance which simplifies the process of inputting the feature map elements to each port of the crossbar in the form of voltage. At the same time, in order to ensure that the output of the current convolution layer can be directly used as the input of the next layer, we have added a corresponding processing circuit, which integrates batch-normalization and binarization operations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100366X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer hardware",
      "Computer science",
      "Crossbar switch",
      "Deep learning",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "Floating point",
      "Memistor",
      "Memristor",
      "Resistive random-access memory",
      "Telecommunications",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Jiadong"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Shi",
        "given_name": "Kaibo"
      },
      {
        "surname": "Yang",
        "given_name": "Yin"
      }
    ]
  },
  {
    "title": "ACSL: Adaptive correlation-driven sparsity learning for deep neural network compression",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.012",
    "abstract": "Deep convolutional neural network compression has attracted lots of attention due to the need to deploy accurate models on resource-constrained edge devices. Existing techniques mostly focus on compressing networks for image-level classification, and it is not clear if they generalize well on network architectures for more challenging pixel-level tasks, e.g., dense crowd counting or semantic segmentation. In this paper, we propose an adaptive correlation-driven sparsity learning (ACSL) framework for channel pruning that outperforms state-of-the-art methods on both image-level and pixel-level tasks. In our ACSL framework, we first quantify the data-dependent channel correlation information with a channel affinity matrix. Next, we leverage these inter-dependencies to induce sparsity into the channels with the introduced adaptive penalty strength. After removing the redundant channels, we obtain compact and efficient models, which have significantly less number of parameters while maintaining comparable performance with the original models. We demonstrate the advantages of our proposed approach on three popular vision tasks, i.e., dense crowd counting, semantic segmentation, and image-level classification. The experimental results demonstrate the superiority of our framework. In particular, for crowd counting on the Mall dataset, the proposed ACSL framework is able to reduce up to 94% parameters (VGG16-Decoder) and 84% FLOPs (ResNet101), while maintaining the same performance of (at times outperforming) the original model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003622",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Enhanced Data Rates for GSM Evolution",
      "Leverage (statistics)",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Pruning",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Wei"
      },
      {
        "surname": "Wu",
        "given_name": "Meiqing"
      },
      {
        "surname": "Lam",
        "given_name": "Siew-Kei"
      }
    ]
  },
  {
    "title": "Decentralized control and local information for robust and adaptive decentralized Deep Reinforcement Learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.017",
    "abstract": "Decentralization is a central characteristic of biological motor control that allows for fast responses relying on local sensory information. In contrast, the current trend of Deep Reinforcement Learning (DRL) based approaches to motor control follows a centralized paradigm using a single, holistic controller that has to untangle the whole input information space. This motivates to ask whether decentralization as seen in biological control architectures might also be beneficial for embodied sensori-motor control systems when using DRL. To answer this question, we provide an analysis and comparison of eight control architectures for adaptive locomotion that were derived for a four-legged agent, but with their degree of decentralization varying systematically between the extremes of fully centralized and fully decentralized. Our comparison shows that learning speed is significantly enhanced in distributed architectures—while still reaching the same high performance level of centralized architectures—due to smaller search spaces and local costs providing more focused information for learning. Second, we find an increased robustness of the learning process in the decentralized cases—it is less demanding to hyperparameter selection and less prone to becoming trapped in poor local minima. Finally, when examining generalization to uneven terrains—not used during training—we find best performance for an intermediate architecture that is decentralized, but integrates only local information from both neighboring legs. Together, these findings demonstrate beneficial effects of distributing control into decentralized units and relying on local information. This appears as a promising approach towards more robust DRL and better generalization towards adaptive behavior.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003671",
    "keywords": [
      "Adaptive control",
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Control (management)",
      "Decentralised system",
      "Decentralization",
      "Ecology",
      "Gene",
      "Law",
      "Machine learning",
      "Political science",
      "Reinforcement learning",
      "Robustness (evolution)",
      "Terrain"
    ],
    "authors": [
      {
        "surname": "Schilling",
        "given_name": "Malte"
      },
      {
        "surname": "Melnik",
        "given_name": "Andrew"
      },
      {
        "surname": "Ohl",
        "given_name": "Frank W."
      },
      {
        "surname": "Ritter",
        "given_name": "Helge J."
      },
      {
        "surname": "Hammer",
        "given_name": "Barbara"
      }
    ]
  },
  {
    "title": "Personalised predictive modelling with brain-inspired spiking neural networks of longitudinal MRI neuroimaging data and the case study of dementia",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.013",
    "abstract": "Background: Longitudinal neuroimaging provides spatiotemporal brain data (STBD) measurement that can be utilised to understand dynamic changes in brain structure and/or function underpinning cognitive activities. Making sense of such highly interactive information is challenging, given that the features manifest intricate temporal, causal relations between the spatially distributed neural sources in the brain. Methods: The current paper argues for the advancement of deep learning algorithms in brain-inspired spiking neural networks (SNN), capable of modelling structural data across time (longitudinal measurement) and space (anatomical components). The paper proposes a methodology and a computational architecture based on SNN for building personalised predictive models from longitudinal brain data to accurately detect, understand, and predict the dynamics of an individual’s functional brain state. The methodology includes finding clusters of similar data to each individual, data interpolation, deep learning in a 3-dimensional brain-template structured SNN model, classification and prediction of individual outcome, visualisation of structural brain changes related to the predicted outcomes, interpretation of results, and individual and group predictive marker discovery. Results: To demonstrate the functionality of the proposed methodology, the paper presents experimental results on a longitudinal magnetic resonance imaging (MRI) dataset derived from 175 older adults of the internationally recognised community-based cohort Sydney Memory and Ageing Study (MAS) spanning 6 years of follow-up. Significance: The models were able to accurately classify and predict 2 years ahead of cognitive decline, such as mild cognitive impairment (MCI) and dementia with 95% and 91% accuracy, respectively. The proposed methodology also offers a 3-dimensional visualisation of the MRI models reflecting the dynamic patterns of regional changes in white matter hyperintensity (WMH) and brain volume over 6 years. Conclusion: The method is efficient for personalised predictive modelling on a wide range of neuroimaging longitudinal data, including also demographic, genetic, and clinical data. As a case study, it resulted in finding predictive markers for MCI and dementia as dynamic brain patterns using MRI data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003634",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognition",
      "Computer science",
      "Deep learning",
      "Functional magnetic resonance imaging",
      "Machine learning",
      "Neuroimaging",
      "Neuroscience",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Doborjeh",
        "given_name": "Maryam"
      },
      {
        "surname": "Doborjeh",
        "given_name": "Zohreh"
      },
      {
        "surname": "Merkin",
        "given_name": "Alexander"
      },
      {
        "surname": "Bahrami",
        "given_name": "Helena"
      },
      {
        "surname": "Sumich",
        "given_name": "Alexander"
      },
      {
        "surname": "Krishnamurthi",
        "given_name": "Rita"
      },
      {
        "surname": "Medvedev",
        "given_name": "Oleg N."
      },
      {
        "surname": "Crook-Rumsey",
        "given_name": "Mark"
      },
      {
        "surname": "Morgan",
        "given_name": "Catherine"
      },
      {
        "surname": "Kirk",
        "given_name": "Ian"
      },
      {
        "surname": "Sachdev",
        "given_name": "Perminder S."
      },
      {
        "surname": "Brodaty",
        "given_name": "Henry"
      },
      {
        "surname": "Kang",
        "given_name": "Kristan"
      },
      {
        "surname": "Wen",
        "given_name": "Wei"
      },
      {
        "surname": "Feigin",
        "given_name": "Valery"
      },
      {
        "surname": "Kasabov",
        "given_name": "Nikola"
      }
    ]
  },
  {
    "title": "An end-to-end 3D convolutional neural network for decoding attentive mental state",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.019",
    "abstract": "The detection of attentive mental state plays an essential role in the neurofeedback process and the treatment of Attention Deficit and Hyperactivity Disorder (ADHD). However, the performance of the detection methods is still not satisfactory. One of the challenges is to find a proper representation for the electroencephalogram (EEG) data, which could preserve the temporal information and maintain the spatial topological characteristics. Inspired by the deep learning (DL) methods in the research of brain–computer interface (BCI) field, a 3D representation of EEG signal was introduced into attention detection task, and a 3D convolutional neural network model with cascade and parallel convolution operations was proposed. The model utilized three cascade blocks, each consisting of two parallel 3D convolution branches, to simultaneously extract the multi-scale features. Evaluated on a public dataset containing twenty-six subjects, the proposed model achieved better performance compared with the baseline methods under the intra-subject, inter-subject and subject-adaptive classification scenarios. This study demonstrated the promising potential of the 3D CNN model for detecting attentive mental state.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003245",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Brain–computer interface",
      "Cascade",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Electroencephalography",
      "Law",
      "Machine learning",
      "Neurofeedback",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Psychology",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yangsong"
      },
      {
        "surname": "Cai",
        "given_name": "Huan"
      },
      {
        "surname": "Nie",
        "given_name": "Li"
      },
      {
        "surname": "Xu",
        "given_name": "Peng"
      },
      {
        "surname": "Zhao",
        "given_name": "Sirui"
      },
      {
        "surname": "Guan",
        "given_name": "Cuntai"
      }
    ]
  },
  {
    "title": "Highly parallelized memristive binary neural network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.016",
    "abstract": "At present, in the new hardware design work of deep learning, memristor as a non-volatile memory with computing power has become a research hotspot. The weights in the deep neural network are the floating-point number. Writing a floating-point value into a memristor will result in a loss of accuracy, and the writing process will take more time. The binarized neural network (BNN) binarizes the weights and activation values that were originally floating-point numbers to +1 and -1. This will greatly reduce the storage space consumption and time consumption of programming the resistance value of the memristor. Furthermore, this will help to simplify the programming of memristors in deep neural network circuits and speed up the inference process. This paper provides a complete solution for implementing memristive BNN. Furthermore, we improved the design of the memristor crossbar by converting the input feature map and kernel before performing the convolution operation that can ensure the sign of the input voltage of each port constant. Therefore, we do not need to determine the sign of the input voltage required by the port in advance which simplifies the process of inputting the feature map elements to each port of the crossbar in the form of voltage. At the same time, in order to ensure that the output of the current convolution layer can be directly used as the input of the next layer, we have added a corresponding processing circuit, which integrates batch-normalization and binarization operations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100366X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer hardware",
      "Computer science",
      "Crossbar switch",
      "Deep learning",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "Floating point",
      "Memistor",
      "Memristor",
      "Resistive random-access memory",
      "Telecommunications",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Jiadong"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Shi",
        "given_name": "Kaibo"
      },
      {
        "surname": "Yang",
        "given_name": "Yin"
      }
    ]
  },
  {
    "title": "A novel meta-learning framework: Multi-features adaptive aggregation method with information enhancer",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.029",
    "abstract": "Deep learning has shown its great potential in the field of image classification due to its powerful feature extraction ability, which heavily depends on the number of available training samples. However, it is still a huge challenge on how to obtain an effective feature representation and further learn a promising classifier by deep networks when faced with few-shot classification tasks. This paper proposes a multi-features adaptive aggregation meta-learning method with an information enhancer for few-shot classification tasks, referred to as MFAML. It contains three main modules, including a feature extraction module, an information enhancer, and a multi-features adaptive aggregation classifier (MFAAC). During the meta-training stage, the information enhancer comprised of some deconvolutional layers is designed to promote the effective utilization of samples and thereby capturing more valuable information in the process of feature extraction. Simultaneously, the MFAAC module integrates the features from several convolutional layers of the feature extraction module. The obtained features then feed into the similarity module so that implementing the adaptive adjustment of the predicted label. The information enhancer and MFAAC are connected by a hybrid loss, providing an excellent feature representation. During the meta-test stage, the information enhancer is removed and we keep the remaining architecture for fast adaption on the final target task. The whole MFAML framework is solved by the optimization strategy of model-agnostic meta-learner (MAML) and can effectively improve generalization performance. Experimental results on several benchmark datasets demonstrate the superiority of the proposed method over other representative few-shot classification methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003919",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy"
    ],
    "authors": [
      {
        "surname": "Ye",
        "given_name": "Hailiang"
      },
      {
        "surname": "Wang",
        "given_name": "Yi"
      },
      {
        "surname": "Cao",
        "given_name": "Feilong"
      }
    ]
  },
  {
    "title": "Natural and Artificial Intelligence: A brief introduction to the interplay between AI and neuroscience research",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.018",
    "abstract": "Neuroscience and artificial intelligence (AI) share a long history of collaboration. Advances in neuroscience, alongside huge leaps in computer processing power over the last few decades, have given rise to a new generation of in silico neural networks inspired by the architecture of the brain. These AI systems are now capable of many of the advanced perceptual and cognitive abilities of biological systems, including object recognition and decision making. Moreover, AI is now increasingly being employed as a tool for neuroscience research and is transforming our understanding of brain functions. In particular, deep learning has been used to model how convolutional layers and recurrent connections in the brain’s cerebral cortex control important functions, including visual processing, memory, and motor control. Excitingly, the use of neuroscience-inspired AI also holds great promise for understanding how changes in brain networks result in psychopathologies, and could even be utilized in treatment regimes. Here we discuss recent advancements in four areas in which the relationship between neuroscience and AI has led to major advancements in the field; (1) AI models of working memory, (2) AI visual processing, (3) AI analysis of big neuroscience datasets, and (4) computational psychiatry.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003683",
    "keywords": [
      "Artificial intelligence",
      "Central nervous system",
      "Cognition",
      "Cognitive neuroscience",
      "Cognitive science",
      "Computational neuroscience",
      "Computer science",
      "Myelin",
      "Neuroinformatics",
      "Neuroscience",
      "Oligodendrocyte",
      "Perception",
      "Psychology",
      "Systems neuroscience",
      "Visual processing"
    ],
    "authors": [
      {
        "surname": "Macpherson",
        "given_name": "Tom"
      },
      {
        "surname": "Churchland",
        "given_name": "Anne"
      },
      {
        "surname": "Sejnowski",
        "given_name": "Terry"
      },
      {
        "surname": "DiCarlo",
        "given_name": "James"
      },
      {
        "surname": "Kamitani",
        "given_name": "Yukiyasu"
      },
      {
        "surname": "Takahashi",
        "given_name": "Hidehiko"
      },
      {
        "surname": "Hikida",
        "given_name": "Takatoshi"
      }
    ]
  },
  {
    "title": "World model learning and inference",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.011",
    "abstract": "Understanding information processing in the brain—and creating general-purpose artificial intelligence—are long-standing aspirations of scientists and engineers worldwide. The distinctive features of human intelligence are high-level cognition and control in various interactions with the world including the self, which are not defined in advance and are vary over time. The challenge of building human-like intelligent machines, as well as progress in brain science and behavioural analyses, robotics, and their associated theoretical formalisations, speaks to the importance of the world-model learning and inference. In this article, after briefly surveying the history and challenges of internal model learning and probabilistic learning, we introduce the free energy principle, which provides a useful framework within which to consider neuronal computation and probabilistic world models. Next, we showcase examples of human behaviour and cognition explained under that principle. We then describe symbol emergence in the context of probabilistic modelling, as a topic at the frontiers of cognitive robotics. Lastly, we review recent progress in creating human-like intelligence by using novel probabilistic programming languages. The striking consensus that emerges from these studies is that probabilistic descriptions of learning and inference are powerful and effective ways to create human-like artificial intelligent machines and to understand intelligence in the context of how humans interact with their world.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003610",
    "keywords": [
      "Artificial general intelligence",
      "Artificial intelligence",
      "Biology",
      "Cognition",
      "Cognitive robotics",
      "Cognitive science",
      "Computer science",
      "Context (archaeology)",
      "Human intelligence",
      "Inference",
      "Machine learning",
      "Neuroscience",
      "Paleontology",
      "Probabilistic logic",
      "Psychology",
      "Robot"
    ],
    "authors": [
      {
        "surname": "Friston",
        "given_name": "Karl"
      },
      {
        "surname": "Moran",
        "given_name": "Rosalyn J."
      },
      {
        "surname": "Nagai",
        "given_name": "Yukie"
      },
      {
        "surname": "Taniguchi",
        "given_name": "Tadahiro"
      },
      {
        "surname": "Gomi",
        "given_name": "Hiroaki"
      },
      {
        "surname": "Tenenbaum",
        "given_name": "Josh"
      }
    ]
  },
  {
    "title": "Weak sub-network pruning for strong and efficient neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.015",
    "abstract": "Pruning methods to compress and accelerate deep convolutional neural networks (CNNs) have recently attracted growing attention, with the view of deploying pruned networks on resource-constrained hardware devices. However, most existing methods focus on small granularities, such as weight, kernel and filter, for the exploration of pruning. Thus, it will be bound to iteratively prune the whole neural networks based on those small granularities for high compression ratio with little performance loss. To address these issues, we theoretically analyze the relationship between the activation and gradient sparsity, and the channel saliency. Based on our findings, we propose a novel and effective method of weak sub-network pruning (WSP). Specifically, for a well-trained network model, we divide the whole compression process into two non-iterative stages. The first stage is to directly obtain a strong sub-network by pruning the weakest one. We first identify the less important channels from all the layers and determine the weakest sub-network, whereby each selected channel makes a minimal contribution to both the feed-forward and feed-backward processes. Then, a one-shot pruning strategy is executed to form a strong sub-network enabling fine tuning, while significantly reducing the impact of the network depth and width on the compression efficiency, especially for deep and wide network architectures. The second stage is to globally fine-tune the strong sub-network using several epochs to restore its original recognition accuracy. Furthermore, our proposed method impacts on the fully-connected layers as well as the convolutional layers for simultaneous compression and acceleration. Comprehensive experiments on VGG16 and ResNet-50 involving a variety of popular benchmarks, such as ImageNet-1K, CIFAR-10, CUB-200 and PASCAL VOC, demonstrate that our WSP method achieves superior performance on classification, domain adaption and object detection tasks with small model size. Our source code is available at https://github.com/QingbeiGuo/WSP.git.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003658",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Convolutional neural network",
      "Filter (signal processing)",
      "Focus (optics)",
      "Kernel (algebra)",
      "Mathematics",
      "Network architecture",
      "Operating system",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Process (computing)",
      "Pruning"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Qingbei"
      },
      {
        "surname": "Wu",
        "given_name": "Xiao-Jun"
      },
      {
        "surname": "Kittler",
        "given_name": "Josef"
      },
      {
        "surname": "Feng",
        "given_name": "Zhiquan"
      }
    ]
  },
  {
    "title": "Physics-incorporated convolutional recurrent neural networks for source identification and forecasting of dynamical systems",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.033",
    "abstract": "Spatio-temporal dynamics of physical processes are generally modeled using partial differential equations (PDEs). Though the core dynamics follows some principles of physics, real-world physical processes are often driven by unknown external sources. In such cases, developing a purely analytical model becomes very difficult and data-driven modeling can be of assistance. In this paper, we present a hybrid framework combining physics-based numerical models with deep learning for source identification and forecasting of spatio-temporal dynamical systems with unobservable time-varying external sources. We formulate our model PhICNet as a convolutional recurrent neural network (RNN) which is end-to-end trainable for spatio-temporal evolution prediction of dynamical systems and learns the source behavior as an internal state of the RNN. Experimental results show that the proposed model can forecast the dynamics for a relatively long time and identify the sources as well.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003464",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Botany",
      "Computer science",
      "Convolutional neural network",
      "Data modeling",
      "Database",
      "Deep learning",
      "Dynamical system (definition)",
      "Dynamical systems theory",
      "Econometrics",
      "Identification (biology)",
      "Machine learning",
      "Mathematics",
      "Observable",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "System identification",
      "Unobservable"
    ],
    "authors": [
      {
        "surname": "Saha",
        "given_name": "Priyabrata"
      },
      {
        "surname": "Dash",
        "given_name": "Saurabh"
      },
      {
        "surname": "Mukhopadhyay",
        "given_name": "Saibal"
      }
    ]
  },
  {
    "title": "Pinning multisynchronization of delayed fractional-order memristor-based neural networks with nonlinear coupling and almost-periodic perturbations",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.029",
    "abstract": "This paper concerns the multisynchronization issue for delayed fractional-order memristor-based neural networks with nonlinear coupling and almost-periodic perturbations. First, the coexistence of multiple equilibrium states for isolated subnetwork is analyzed. By means of state-space decomposition, fractional-order Halanay inequality and Caputo derivative properties, the novel algebraic sufficient conditions are derived to ensure that the addressed networks with arbitrary activation functions have multiple locally stable almost periodic orbits or equilibrium points. Then, based on the obtained multistability results, a pinning control strategy is designed to realize the multisynchronization of the N coupled networks. By the aid of graph theory, depth first search method and pinning control law, some sufficient conditions are formulated such that the considered neural networks can possess multiple synchronization manifolds. Finally, the multistability and multisynchronization performance of the considered neural networks with different activation functions are illustrated by numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003427",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differential equation",
      "Equilibrium point",
      "Fractional calculus",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Memristor",
      "Multistability",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Libiao"
      },
      {
        "surname": "Li",
        "given_name": "Xifeng"
      },
      {
        "surname": "Bi",
        "given_name": "Dongjie"
      },
      {
        "surname": "Xie",
        "given_name": "Xuan"
      },
      {
        "surname": "Xie",
        "given_name": "Yongle"
      }
    ]
  },
  {
    "title": "Deep learning based spectral CT imaging",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.026",
    "abstract": "Spectral computed tomography (CT) has attracted much attention in radiation dose reduction, metal artifacts removal, tissue quantification and material discrimination. The x-ray energy spectrum is divided into several bins, each energy-bin-specific projection has a low signal-noise-ratio (SNR) than the current-integrating counterpart, which makes image reconstruction a unique challenge. Traditional wisdom is to use prior knowledge based iterative methods. However, this kind of methods demands a great computational cost. Inspired by deep learning, here we first develop a deep learning based reconstruction method; i.e., U-net with L p p -norm, Total variation, Residual learning, and Anisotropic adaption (ULTRA). Specifically, we emphasize the various multi-scale feature fusion and multichannel filtering enhancement with a denser connection encoding architecture for residual learning and feature fusion. To address the image deblurring problem associated with the L 2 2 - loss, we propose a general L p p -loss, p > 0 . Furthermore, the images from different energy bins share similar structures of the same object, the regularization characterizing correlations of different energy bins is incorporated into the L p p - loss function, which helps unify the deep learning based methods with traditional compressed sensing based methods. Finally, the anisotropically weighted total variation is employed to characterize the sparsity in the spatial–spectral domain to regularize the proposed network In particular, we validate our ULTRA networks on three large-scale spectral CT datasets, and obtain excellent results relative to the competing algorithms. In conclusion, our quantitative and qualitative results in numerical simulation and preclinical experiments demonstrate that our proposed approach is accurate, efficient and robust for high-quality spectral CT image reconstruction.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003397",
    "keywords": [],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Weiwen"
      },
      {
        "surname": "Hu",
        "given_name": "Dianlin"
      },
      {
        "surname": "Niu",
        "given_name": "Chuang"
      },
      {
        "surname": "Broeke",
        "given_name": "Lieza Vanden"
      },
      {
        "surname": "Butler",
        "given_name": "Anthony P.H."
      },
      {
        "surname": "Cao",
        "given_name": "Peng"
      },
      {
        "surname": "Atlas",
        "given_name": "James"
      },
      {
        "surname": "Chernoglazov",
        "given_name": "Alexander"
      },
      {
        "surname": "Vardhanabhuti",
        "given_name": "Varut"
      },
      {
        "surname": "Wang",
        "given_name": "Ge"
      }
    ]
  },
  {
    "title": "An empirical evaluation of active inference in multi-armed bandits",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.018",
    "abstract": "A key feature of sequential decision making under uncertainty is a need to balance between exploiting—choosing the best action according to the current knowledge, and exploring—obtaining information about values of other actions. The multi-armed bandit problem, a classical task that captures this trade-off, served as a vehicle in machine learning for developing bandit algorithms that proved to be useful in numerous industrial applications. The active inference framework, an approach to sequential decision making recently developed in neuroscience for understanding human and animal behaviour, is distinguished by its sophisticated strategy for resolving the exploration–exploitation trade-off. This makes active inference an exciting alternative to already established bandit algorithms. Here we derive an efficient and scalable approximate active inference algorithm and compare it to two state-of-the-art bandit algorithms: Bayesian upper confidence bound and optimistic Thompson sampling. This comparison is done on two types of bandit problems: a stationary and a dynamic switching bandit. Our empirical evaluation shows that the active inference algorithm does not produce efficient long-term behaviour in stationary bandits. However, in the more challenging switching bandit problem active inference performs substantially better than the two state-of-the-art bandit algorithms. The results open exciting venues for further research in theoretical and applied machine learning, as well as lend additional credibility to active inference as a general framework for studying human and animal behaviour.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003233",
    "keywords": [
      "Artificial intelligence",
      "Bayesian inference",
      "Bayesian probability",
      "Computer science",
      "Database",
      "Inference",
      "Machine learning",
      "Multi-armed bandit",
      "Regret",
      "Scalability",
      "Thompson sampling"
    ],
    "authors": [
      {
        "surname": "Marković",
        "given_name": "Dimitrije"
      },
      {
        "surname": "Stojić",
        "given_name": "Hrvoje"
      },
      {
        "surname": "Schwöbel",
        "given_name": "Sarah"
      },
      {
        "surname": "Kiebel",
        "given_name": "Stefan J."
      }
    ]
  },
  {
    "title": "Distributed associative memory network with memory refreshing loss",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.030",
    "abstract": "Despite recent progress in memory augmented neural network (MANN) research, associative memory networks with a single external memory still show limited performance on complex relational reasoning tasks. Especially the content-based addressable memory networks often fail to encode input data into rich enough representation for relational reasoning and this limits the relation modeling performance of MANN for long temporal sequence data. To address these problems, here we introduce a novel Distributed Associative Memory architecture (DAM) with Memory Refreshing Loss (MRL) which enhances the relation reasoning performance of MANN. Inspired by how the human brain works, our framework encodes data with distributed representation across multiple memory blocks and repeatedly refreshes the contents for enhanced memorization similar to the rehearsal process of the brain. For this procedure, we replace a single external memory with a set of multiple smaller associative memory blocks and update these sub-memory blocks simultaneously and independently for the distributed representation of input data. Moreover, we propose MRL which assists a task’s target objective while learning relational information existing in data. MRL enables MANN to reinforce an association between input data and task objective by reproducing stochastically sampled input data from stored memory contents. With this procedure, MANN further enriches the stored representations with relational information. In experiments, we apply our approaches to Differential Neural Computer (DNC), which is one of the representative content-based addressing memory models and achieves the state-of-the-art performance on both memorization and relational reasoning tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003014",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Associative property",
      "Bidirectional associative memory",
      "Cognitive psychology",
      "Computer science",
      "Content-addressable memory",
      "Economics",
      "Law",
      "Management",
      "Mathematics",
      "Memorization",
      "Memory model",
      "Parallel computing",
      "Political science",
      "Politics",
      "Programming language",
      "Psychology",
      "Pure mathematics",
      "Representation (politics)",
      "Set (abstract data type)",
      "Shared memory",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Park",
        "given_name": "Taewon"
      },
      {
        "surname": "Choi",
        "given_name": "Inchul"
      },
      {
        "surname": "Lee",
        "given_name": "Minho"
      }
    ]
  },
  {
    "title": "Disturbance-immune weight sharing for neural architecture search",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.002",
    "abstract": "Neural architecture search (NAS) has gained increasing attention in the community of architecture design. One of the key factors behind the success lies in the training efficiency brought by the weight sharing (WS) technique. However, WS-based NAS methods often suffer from a performance disturbance (PD) issue. That is, the training of subsequent architectures inevitably disturbs the performance of previously trained architectures due to the partially shared weights. This leads to inaccurate performance estimation for the previous architectures, which makes it hard to learn a good search strategy. To alleviate the performance disturbance issue, we propose a new disturbance-immune update strategy for model updating. Specifically, to preserve the knowledge learned by previous architectures, we constrain the training of subsequent architectures in an orthogonal space via orthogonal gradient descent. Equipped with this strategy, we propose a novel disturbance-immune training scheme for NAS. We theoretically analyze the effectiveness of our strategy in alleviating the PD risk. Extensive experiments on CIFAR-10 and ImageNet verify the superiority of our method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100352X",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer security",
      "Disturbance (geology)",
      "Gradient descent",
      "Key (lock)",
      "Machine learning",
      "Paleontology",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Niu",
        "given_name": "Shuaicheng"
      },
      {
        "surname": "Wu",
        "given_name": "Jiaxiang"
      },
      {
        "surname": "Zhang",
        "given_name": "Yifan"
      },
      {
        "surname": "Guo",
        "given_name": "Yong"
      },
      {
        "surname": "Zhao",
        "given_name": "Peilin"
      },
      {
        "surname": "Huang",
        "given_name": "Junzhou"
      },
      {
        "surname": "Tan",
        "given_name": "Mingkui"
      }
    ]
  },
  {
    "title": "The whole brain architecture approach: Accelerating the development of artificial general intelligence by referring to the brain",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.004",
    "abstract": "The vastness of the design space that is created by the combination of numerous computational mechanisms, including machine learning, is an obstacle to creating artificial general intelligence (AGI). Brain-inspired AGI development; that is, the reduction of the design space to resemble a biological brain more closely, is a promising approach for solving this problem. However, it is difficult for an individual to design a software program that corresponds to the entire brain as the neuroscientific data that are required to understand the architecture of the brain are extensive and complicated. The whole-brain architecture approach divides the brain-inspired AGI development process into the task of designing the brain reference architecture (BRA), which provides the flow of information and a diagram of the corresponding components, and the task of developing each component using the BRA. This is known as BRA-driven development. Another difficulty lies in the extraction of the operating principles that are necessary for reproducing the cognitive–behavioral function of the brain from neuroscience data. Therefore, this study proposes structure-constrained interface decomposition (SCID), which is a hypothesis-building method for creating a hypothetical component diagram that is consistent with neuroscientific findings. The application of this approach has been initiated for constructing various regions of the brain. In the future, we will examine methods for evaluating the biological plausibility of brain-inspired software. This evaluation will also be used to prioritize different computational mechanisms, which should be integrated and associated with the same regions of the brain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003543",
    "keywords": [
      "Archaeology",
      "Architecture",
      "Art",
      "Artificial general intelligence",
      "Artificial intelligence",
      "Cognitive science",
      "Component (thermodynamics)",
      "Computer science",
      "Data flow diagram",
      "Database",
      "Engineering",
      "History",
      "Human–computer interaction",
      "Physics",
      "Plan (archaeology)",
      "Process (computing)",
      "Programming language",
      "Psychology",
      "Software",
      "Systems engineering",
      "Task (project management)",
      "Thermodynamics",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Yamakawa",
        "given_name": "Hiroshi"
      }
    ]
  },
  {
    "title": "Uncertainty propagation for dropout-based Bayesian neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.005",
    "abstract": "Uncertainty evaluation is a core technique when deep neural networks (DNNs) are used in real-world problems. In practical applications, we often encounter unexpected samples that have not seen in the training process. Not only achieving the high-prediction accuracy but also detecting uncertain data is significant for safety-critical systems. In statistics and machine learning, Bayesian inference has been exploited for uncertainty evaluation. The Bayesian neural networks (BNNs) have recently attracted considerable attention in this context, as the DNN trained using dropout is interpreted as a Bayesian method. Based on this interpretation, several methods to calculate the Bayes predictive distribution for DNNs have been developed. Though the Monte-Carlo method called MC dropout is a popular method for uncertainty evaluation, it requires a number of repeated feed-forward calculations of DNNs with randomly sampled weight parameters. To overcome the computational issue, we propose a sampling-free method to evaluate uncertainty. Our method converts a neural network trained using dropout to the corresponding Bayesian neural network with variance propagation. Our method is available not only to feed-forward NNs but also to recurrent NNs such as LSTM. We report the computational efficiency and statistical reliability of our method in numerical experiments of language modeling using RNNs, and the out-of-distribution detection with DNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003555",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bayesian inference",
      "Bayesian probability",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Dropout (neural networks)",
      "Importance sampling",
      "Inference",
      "Machine learning",
      "Mathematics",
      "Monte Carlo method",
      "Paleontology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Mae",
        "given_name": "Yuki"
      },
      {
        "surname": "Kumagai",
        "given_name": "Wataru"
      },
      {
        "surname": "Kanamori",
        "given_name": "Takafumi"
      }
    ]
  },
  {
    "title": "Adversarial text-to-image synthesis: A review",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.019",
    "abstract": "With the advent of generative adversarial networks, synthesizing images from text descriptions has recently become an active research area. It is a flexible and intuitive way for conditional image generation with significant progress in the last years regarding visual realism, diversity, and semantic alignment. However, the field still faces several challenges that require further research efforts such as enabling the generation of high-resolution images with multiple objects, and developing suitable and reliable evaluation metrics that correlate with human judgement. In this review, we contextualize the state of the art of adversarial text-to-image synthesis models, their development since their inception five years ago, and propose a taxonomy based on the level of supervision. We critically examine current strategies to evaluate text-to-image synthesis models, highlight shortcomings, and identify new areas of research, ranging from the development of better datasets and evaluation metrics to possible improvements in architectural design and model training. This review complements previous surveys on generative adversarial networks with a focus on text-to-image synthesis which we believe will help researchers to further advance the field.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002823",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Computer science",
      "Data science",
      "Deep learning",
      "Field (mathematics)",
      "Focus (optics)",
      "Generative grammar",
      "Image (mathematics)",
      "Image synthesis",
      "Judgement",
      "Law",
      "Mathematics",
      "Open research",
      "Optics",
      "Physics",
      "Political science",
      "Pure mathematics",
      "Taxonomy (biology)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Frolov",
        "given_name": "Stanislav"
      },
      {
        "surname": "Hinz",
        "given_name": "Tobias"
      },
      {
        "surname": "Raue",
        "given_name": "Federico"
      },
      {
        "surname": "Hees",
        "given_name": "Jörn"
      },
      {
        "surname": "Dengel",
        "given_name": "Andreas"
      }
    ]
  },
  {
    "title": "Deep Tobit networks: A novel machine learning approach to microeconometrics",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.003",
    "abstract": "Tobit models (also called as “censored regression models” or classified as “sample selection models” in microeconometrics) have been widely applied to microeconometric problems with censored outcomes. However, due to their linear parametric settings and restrictive normality assumptions, the traditional Tobit models fail to capture the pervading nonlinearities and thus may be inadequate for microeconometric analysis with large-scale datasets. This paper proposes two novel deep neural networks for Tobit problems and explores machine learning approaches in the context of microeconometric modeling. We connect the censored outputs in Tobit models with some deep learning techniques, which are thought to be unrelated to microeconometrics, and use the rectified linear unit activation and a particularly designed network structure to implement the censored output mechanisms and realize the underlying econometric conceptions. The benchmark Tobit-I and Tobit-II models are then reformulated as two carefully designed deep feedforward neural networks named deep Tobit-I network and deep Tobit-II network, respectively. A novel significance testing method is developed based on the proposed networks. Compared with the traditional models, our networks with deep structures can effectively describe the underlying highly nonlinear relationships and achieve considerable improvements in fitting and prediction. With the novel testing method, the proposed networks enable highly accurate and sophisticated econometric analysis with minimal random assumptions. The encouraging numerical experiments on synthetic and realistic datasets demonstrate the utility and advantages of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003531",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Deep learning",
      "Econometrics",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematics",
      "Nonparametric statistics",
      "Paleontology",
      "Parametric model",
      "Parametric statistics",
      "Statistics",
      "Tobit model"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Jiaming"
      },
      {
        "surname": "Li",
        "given_name": "Zhanfeng"
      },
      {
        "surname": "Song",
        "given_name": "Xinyuan"
      },
      {
        "surname": "Ning",
        "given_name": "Hanwen"
      }
    ]
  },
  {
    "title": "Non-differentiable saddle points and sub-optimal local minima exist for deep ReLU networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.005",
    "abstract": "Whether sub-optimal local minima and saddle points exist in the highly non-convex loss landscape of deep neural networks has a great impact on the performance of optimization algorithms. Theoretically, we study in this paper the existence of non-differentiable sub-optimal local minima and saddle points for deep ReLU networks with arbitrary depth. We prove that there always exist non-differentiable saddle points in the loss surface of deep ReLU networks with squared loss or cross-entropy loss under reasonable assumptions. We also prove that deep ReLU networks with cross-entropy loss will have non-differentiable sub-optimal local minima if some outermost samples do not belong to a certain class. Experimental results on real and synthetic datasets verify our theoretical findings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003105",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Differentiable function",
      "Entropy (arrow of time)",
      "Geometry",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Maxima and minima",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Saddle",
      "Saddle point"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Bo"
      },
      {
        "surname": "Liu",
        "given_name": "Zhaoying"
      },
      {
        "surname": "Zhang",
        "given_name": "Ting"
      },
      {
        "surname": "Yuan",
        "given_name": "Tongtong"
      }
    ]
  },
  {
    "title": "Uncertainty propagation for dropout-based Bayesian neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.005",
    "abstract": "Uncertainty evaluation is a core technique when deep neural networks (DNNs) are used in real-world problems. In practical applications, we often encounter unexpected samples that have not seen in the training process. Not only achieving the high-prediction accuracy but also detecting uncertain data is significant for safety-critical systems. In statistics and machine learning, Bayesian inference has been exploited for uncertainty evaluation. The Bayesian neural networks (BNNs) have recently attracted considerable attention in this context, as the DNN trained using dropout is interpreted as a Bayesian method. Based on this interpretation, several methods to calculate the Bayes predictive distribution for DNNs have been developed. Though the Monte-Carlo method called MC dropout is a popular method for uncertainty evaluation, it requires a number of repeated feed-forward calculations of DNNs with randomly sampled weight parameters. To overcome the computational issue, we propose a sampling-free method to evaluate uncertainty. Our method converts a neural network trained using dropout to the corresponding Bayesian neural network with variance propagation. Our method is available not only to feed-forward NNs but also to recurrent NNs such as LSTM. We report the computational efficiency and statistical reliability of our method in numerical experiments of language modeling using RNNs, and the out-of-distribution detection with DNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003555",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bayesian inference",
      "Bayesian probability",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Dropout (neural networks)",
      "Importance sampling",
      "Inference",
      "Machine learning",
      "Mathematics",
      "Monte Carlo method",
      "Paleontology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Mae",
        "given_name": "Yuki"
      },
      {
        "surname": "Kumagai",
        "given_name": "Wataru"
      },
      {
        "surname": "Kanamori",
        "given_name": "Takafumi"
      }
    ]
  },
  {
    "title": "Broad-UNet: Multi-scale feature learning for nowcasting tasks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.036",
    "abstract": "Weather nowcasting consists of predicting meteorological components in the short term at high spatial resolutions. Due to its influence in many human activities, accurate nowcasting has recently gained plenty of attention. In this paper, we treat the nowcasting problem as an image-to-image translation problem using satellite imagery. We introduce Broad-UNet, a novel architecture based on the core UNet model, to efficiently address this problem. In particular, the proposed Broad-UNet is equipped with asymmetric parallel convolutions as well as Atrous Spatial Pyramid Pooling (ASPP) module. In this way, the Broad-UNet model learns more complex patterns by combining multi-scale features while using fewer parameters than the core UNet model. The proposed model is applied on two different nowcasting tasks, i.e. precipitation maps and cloud cover nowcasting. The obtained numerical results show that the introduced Broad-UNet model performs more accurate predictions compared to the other examined architectures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100349X",
    "keywords": [
      "Artificial intelligence",
      "Cartography",
      "Computer science",
      "Computer vision",
      "Feature (linguistics)",
      "Geography",
      "Geometry",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Meteorology",
      "Nowcasting",
      "Philosophy",
      "Pooling",
      "Pyramid (geometry)",
      "Remote sensing",
      "Scale (ratio)"
    ],
    "authors": [
      {
        "surname": "Fernández",
        "given_name": "Jesús García"
      },
      {
        "surname": "Mehrkanoon",
        "given_name": "Siamak"
      }
    ]
  },
  {
    "title": "A language modeling-like approach to sketching",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.020",
    "abstract": "Sketching is a universal communication tool that, despite its simplicity, is able to efficiently express a large variety of concepts and, in some limited contexts, it can be even more immediate and effective than natural language. In this paper we explore the feasibility of using neural networks to approach sketching in the same way they are commonly used in Language Modeling. We propose a novel approach to what we refer to as “Sketch Modeling”, in which a neural network is exploited to learn a probabilistic model that estimates the probability of sketches. We focus on simple sketches and, in particular, on the case in which sketches are represented as sequences of segments. Segments and sequences can be either given – when the sketches are originally drawn in this format – or automatically generated from the input drawing by means of a procedure that we designed to create short sequences, loosely inspired by the human behavior. A Recurrent Neural Network is used to learn the sketch model and, afterward, the network is seeded with an incomplete sketch that it is asked to complete, generating one segment at each time step. We propose a set of measures to evaluate the outcome of a Beam Search-based generation procedure, showing how they can be used to identify the most promising generations. Our experimental analysis assesses the feasibility of this way of modeling sketches, also in the case in which several different categories of sketches are considered.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003828",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Epistemology",
      "Focus (optics)",
      "Language model",
      "Machine learning",
      "Natural language",
      "Optics",
      "Philosophy",
      "Physics",
      "Probabilistic logic",
      "Programming language",
      "Set (abstract data type)",
      "Simple (philosophy)",
      "Simplicity",
      "Sketch",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Graziani",
        "given_name": "Lisa"
      },
      {
        "surname": "Gori",
        "given_name": "Marco"
      },
      {
        "surname": "Melacci",
        "given_name": "Stefano"
      }
    ]
  },
  {
    "title": "Deep-Hook: A trusted deep learning-based framework for unknown malware detection and classification in Linux cloud environments",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.019",
    "abstract": "Since the beginning of the 21st century, the use of cloud computing has increased rapidly, and it currently plays a significant role among most organizations’ information technology (IT) infrastructure. Virtualization technologies, particularly virtual machines (VMs), are widely used and lie at the core of cloud computing. While different operating systems can run on top of VM instances, in public cloud environments the Linux operating system is used 90% of the time. Because of their prevalence, organizational Linux-based virtual servers have become an attractive target for cyber-attacks, mainly launched by sophisticated malware designed at causing harm, sabotaging operations, obtaining data, or gaining financial profit. This has resulted in the need for an advanced and reliable unknown malware detection mechanism for Linux cloud-based environments. Antivirus software and today’s even more advanced malware detection solutions have limitations in detecting new, unseen, and evasive malware. Moreover, many existing solutions are considered untrusted, as they operate on the inspected machine and can be interfered with, and can even be detected by the malware itself, allowing malware to evade detection and cause damage. In this paper, we propose Deep-Hook, a trusted framework for unknown malware detection in Linux-based cloud environments. Deep-Hook hooks the VM’s volatile memory in a trusted manner and acquires the memory dump to discover malware footprints while the VM operates. The memory dumps are transformed into visual images which are analyzed using a convolutional neural network (CNN) based classifier. The proposed framework has some key advantages, such as its agility, its ability to eliminate the need for features defined by a cyber domain expert, and most importantly, its ability to analyze the entire memory dump and thus to better utilize the existing indication it conceals, thus allowing the induction of a more accurate detection model. Deep-Hook was evaluated on widely used Linux virtual servers; four state-of-the-art CNN architectures; eight image resolutions; and a total of 22,400 volatile memory dumps representing the execution of a broad set of benign and malicious Linux applications. Our experimental evaluation results demonstrate Deep-Hook’s ability to effectively, efficiently, and accurately detect and classify unknown malware (even evasive malware like rootkits), with an AUC and accuracy of up to 99.9%.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003695",
    "keywords": [
      "Artificial intelligence",
      "Cloud computing",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Cryptovirology",
      "Deep learning",
      "Hypervisor",
      "Malware",
      "Operating system",
      "Server",
      "Virtual machine",
      "Virtualization"
    ],
    "authors": [
      {
        "surname": "Landman",
        "given_name": "Tom"
      },
      {
        "surname": "Nissim",
        "given_name": "Nir"
      }
    ]
  },
  {
    "title": "Combining STDP and binary networks for reinforcement learning from images and sparse rewards",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.010",
    "abstract": "Spiking neural networks (SNNs) aim to replicate energy efficiency, learning speed and temporal processing of biological brains. However, accuracy and learning speed of such networks is still behind reinforcement learning (RL) models based on traditional neural models. This work combines a pre-trained binary convolutional neural network with an SNN trained online through reward-modulated STDP in order to leverage advantages of both models. The spiking network is an extension of its previous version, with improvements in architecture and dynamics to address a more challenging task. We focus on extensive experimental evaluation of the proposed model with optimized state-of-the-art baselines, namely proximal policy optimization (PPO) and deep Q network (DQN). The models are compared on a grid-world environment with high dimensional observations, consisting of RGB images with up to 256 × 256 pixels. The experimental results show that the proposed architecture can be a competitive alternative to deep reinforcement learning (DRL) in the evaluated environment and provide a foundation for more complex future applications of spiking networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003609",
    "keywords": [
      "Arithmetic",
      "Artificial intelligence",
      "Artificial neural network",
      "Binary number",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Leverage (statistics)",
      "Machine learning",
      "Mathematics",
      "Reinforcement learning",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Chevtchenko",
        "given_name": "Sérgio F."
      },
      {
        "surname": "Ludermir",
        "given_name": "Teresa B."
      }
    ]
  },
  {
    "title": "Detection of pancreatic cancer by convolutional-neural-network-assisted spontaneous Raman spectroscopy with critical feature visualization",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.006",
    "abstract": "Pancreatic cancer is the deadliest cancer type with a five-year survival rate of less than 9%. Detection of tumor margins plays an essential role in the success of surgical resection. However, histopathological assessment is time-consuming, expensive, and labor-intensive. We constructed a lab-designed, hand-held Raman spectroscopic system that could enable intraoperative tissue diagnosis using convolutional neural network (CNN) models to efficiently distinguish between cancerous and normal pancreatic tissue. To our best knowledge, this is the first reported effort to diagnose pancreatic cancer by CNN-aided spontaneous Raman scattering with a lab-developed system designed for intraoperative applications. Classification based on the original one-dimensional (1D) Raman, two-dimensional (2D) Raman images, and the first principal component (PC1) from the principal component analysis on the 2D image, could all achieve high performance: the testing sensitivity, specificity, and accuracy were over 95%, and the area under the curve approached 0.99. Although CNN models often show great success in classification, it has always been challenging to visualize the CNN features in these models, which has never been achieved in the Raman spectroscopy application in cancer diagnosis. By studying individual Raman regions and by extracting and visualizing CNN features from max-pooling layers, we identified critical Raman peaks that could aid in the classification of cancerous and noncancerous tissues. 2D Raman PC1 yielded more critical peaks for pancreatic cancer identification than that of 1D Raman, as the Raman intensity was amplified by 2D Raman PC1. To our best knowledge, the feature visualization was achieved for the first time in the field of CNN-aided spontaneous Raman spectroscopy for cancer diagnosis. Based on these CNN feature peaks and their frequency at specific wavenumbers, pancreatic cancerous tissue was found to contain more biochemical components related to the protein contents (particularly collagen), whereas normal pancreatic tissue was found to contain more lipids and nucleic acid (particularly deoxyribonucleic acid/ribonucleic acid). Overall, the CNN model in combination with Raman spectroscopy could serve as a useful tool for the extraction of key features that can help differentiate pancreatic cancer from a normal pancreas.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003567",
    "keywords": [
      "Artificial intelligence",
      "Cancer",
      "Computer science",
      "Convolutional neural network",
      "Feature (linguistics)",
      "Internal medicine",
      "Linguistics",
      "Medicine",
      "Optics",
      "Pancreatic cancer",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Pooling",
      "Principal component analysis",
      "Raman scattering",
      "Raman spectroscopy",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Zhongqiang"
      },
      {
        "surname": "Li",
        "given_name": "Zheng"
      },
      {
        "surname": "Chen",
        "given_name": "Qing"
      },
      {
        "surname": "Ramos",
        "given_name": "Alexandra"
      },
      {
        "surname": "Zhang",
        "given_name": "Jian"
      },
      {
        "surname": "Boudreaux",
        "given_name": "J. Philip"
      },
      {
        "surname": "Thiagarajan",
        "given_name": "Ramcharan"
      },
      {
        "surname": "Bren-Mattison",
        "given_name": "Yvette"
      },
      {
        "surname": "Dunham",
        "given_name": "Michael E."
      },
      {
        "surname": "McWhorter",
        "given_name": "Andrew J."
      },
      {
        "surname": "Li",
        "given_name": "Xin"
      },
      {
        "surname": "Feng",
        "given_name": "Ji-Ming"
      },
      {
        "surname": "Li",
        "given_name": "Yanping"
      },
      {
        "surname": "Yao",
        "given_name": "Shaomian"
      },
      {
        "surname": "Xu",
        "given_name": "Jian"
      }
    ]
  },
  {
    "title": "Combination of certainty and uncertainty: Using FusionGAN to create abstract paintings",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.001",
    "abstract": "In the study of generative art, it is relatively easy at present to achieve a high degree of certainty or uncertainty. However, the combination of certainty and uncertainty has always been an area of difficulty in generative art. In this paper, we present a novel FusionGAN system to automate the generation of abstract paintings. These generated abstract paintings combine the factors of certainty and uncertainty. First, we collect an APdataset consisting of three parts: abstract paintings drawn by artists, sketches, and abstract paintings generated by other neural network methods. We then train the proposed FusionGAN system on the collected dataset to learn the expression of abstract paintings. Corresponding to the two-step operation of the combination of certainty and uncertainty in the artist’s creation, the proposed FusionGAN system is also divided into two steps for the generation of abstract paintings. More specifically, the first step is the basic structure establishment, which corresponds to the fundamental certainty element in the painting creation. The second step is the realization of details, which integrates the uncertain details based on the basic structure. The experimental results achieved by our system in abstract painting generation enrich the diversity of artistic creation and have been recognized by art institutions, with some results displayed on their websites.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003518",
    "keywords": [
      "Art",
      "Artificial intelligence",
      "Certainty",
      "Computer science",
      "Element (criminal law)",
      "Expression (computer science)",
      "Generative grammar",
      "Geometry",
      "Law",
      "Mathematics",
      "Painting",
      "Political science",
      "Programming language",
      "Realization (probability)",
      "Statistics",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Mao"
      },
      {
        "surname": "Lv",
        "given_name": "Jiancheng"
      },
      {
        "surname": "Tang",
        "given_name": "Chenwei"
      },
      {
        "surname": "Wang",
        "given_name": "Jian"
      },
      {
        "surname": "Lai",
        "given_name": "Zhichen"
      },
      {
        "surname": "Huang",
        "given_name": "Youcheng"
      }
    ]
  },
  {
    "title": "Extreme neural machines",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.021",
    "abstract": "Recurrent neural networks can solve a variety of computational tasks and produce patterns of activity that capture key properties of brain circuits. However, learning rules designed to train these models are time-consuming and prone to inaccuracies when tuning connection weights located deep within the network. Here, we describe a rapid one-shot learning rule to train recurrent networks composed of biologically-grounded neurons. First, inputs to the model are compressed onto a smaller number of recurrent neurons. Then, a non-iterative rule adjusts the output weights of these neurons based on a target signal. The model learned to reproduce natural images, sequential patterns, as well as a high-resolution movie scene. Together, results provide a novel avenue for one-shot learning in biologically realistic recurrent networks and open a path to solving complex tasks by merging brain-inspired models with rapid optimization rules.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100383X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Key (lock)",
      "Learning rule",
      "Machine learning",
      "Path (computing)",
      "Pattern recognition (psychology)",
      "Programming language",
      "Recurrent neural network",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Boucher-Routhier",
        "given_name": "Megan"
      },
      {
        "surname": "Zhang",
        "given_name": "Bill Ling Feng"
      },
      {
        "surname": "Thivierge",
        "given_name": "Jean-Philippe"
      }
    ]
  },
  {
    "title": "Neural network surgery: Combining training with topology optimization",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.034",
    "abstract": "With ever increasing computational capacities, neural networks become more and more proficient at solving complex tasks. However, picking a sufficiently good network topology usually relies on expert human knowledge. Neural architecture search aims to reduce the extent of expertise that is needed. Modern architecture search techniques often rely on immense computational power, or apply trained meta-controllers for decision making. We develop a framework for a genetic algorithm that is both computationally cheap and makes decisions based on mathematical criteria rather than trained parameters. It is a hybrid approach that fuses training and topology optimization together into one process. Structural modifications that are performed include adding or removing layers of neurons, with some re-training applied to make up for any incurred change in input–output behaviour. Our ansatz is tested on several benchmark datasets with limited computational overhead compared to training only the baseline. This algorithm can achieve a significant increase in accuracy (as compared to a fully trained baseline), rescue insufficient topologies that in their current state are only able to learn to a limited extent, and dynamically reduce network size without loss in achieved accuracy. On standard ML datasets, accuracy improvements compared to baseline performance can range from 20% for well performing starting topologies to more than 40% in case of insufficient baselines, or reduce network size by almost 15%.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003476",
    "keywords": [
      "Aerospace engineering",
      "Artificial intelligence",
      "Artificial neural network",
      "Baseline (sea)",
      "Benchmark (surveying)",
      "Combinatorics",
      "Computer science",
      "Computer security",
      "Engineering",
      "Finite element method",
      "Geodesy",
      "Geography",
      "Geology",
      "Machine learning",
      "Mathematics",
      "Network architecture",
      "Network topology",
      "Oceanography",
      "Operating system",
      "Overhead (engineering)",
      "Process (computing)",
      "Range (aeronautics)",
      "Structural engineering",
      "Topology (electrical circuits)",
      "Topology optimization"
    ],
    "authors": [
      {
        "surname": "Schiessler",
        "given_name": "Elisabeth J."
      },
      {
        "surname": "Aydin",
        "given_name": "Roland C."
      },
      {
        "surname": "Linka",
        "given_name": "Kevin"
      },
      {
        "surname": "Cyron",
        "given_name": "Christian J."
      }
    ]
  },
  {
    "title": "Impact of axonal delay on structure development in a multi-layered network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.023",
    "abstract": "The mechanisms underlying how activity in the visual pathway gives rise through neural plasticity to many features observed experimentally in early stages of visual processing was provided by Linsker in a seminal, three-paper series. Owing to the complexity of multi-layer models, an implicit assumption in Linsker’s and subsequent papers has been that propagation delay is homogeneous, playing little functional role in neural behavior. In this paper, we relax this assumption to examine the impact of distance-dependent axonal propagation delay on neural learning. We show that propagation delay induces low-pass filtering by dispersing arrival times of spikes from presynaptic neurons, providing a natural correlation cancellation mechanism for distal connections. The cut-off frequency decreases as radial propagation delay within a layer increases relative to propagation delay between layers, introducing an upper limit on temporal resolution. Given that the postsynaptic potential acts as a low-pass filter, we show that the effective time constant of each should enable processing of similar scales of temporal information. This has implications for the visual system, in which receptive field size and, thus, propagation delay, increases with eccentricity. Furthermore, network response is frequency dependent since higher frequencies require increased input amplitude to compensate for attenuation. This concords with frequency-dependent contrast sensitivity, which changes with eccentricity and receptive field size. We further show that the proportion of inhibition relative to excitation is larger where radial propagation delay is long relative to inter-laminar delay, and that delay reduces the range in on-center size, providing stability to variations in homeostatic parameters.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003282",
    "keywords": [
      "Acoustics",
      "Artificial intelligence",
      "Attenuation",
      "Computer science",
      "Computer vision",
      "Eccentricity (behavior)",
      "Filter (signal processing)",
      "Optics",
      "Physics",
      "Psychology",
      "Receptive field",
      "Social psychology"
    ],
    "authors": [
      {
        "surname": "Davey",
        "given_name": "Catherine E."
      },
      {
        "surname": "Grayden",
        "given_name": "David B."
      },
      {
        "surname": "Burkitt",
        "given_name": "Anthony N."
      }
    ]
  },
  {
    "title": "Biologically motivated learning method for deep neural networks using hierarchical competitive learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.027",
    "abstract": "This study proposes a novel biologically motivated learning method for deep convolutional neural networks (CNNs). The combination of CNNs and backpropagation learning is the most powerful method in recent machine learning regimes. However, it requires a large amount of labeled data for training, and this requirement can occasionally become a barrier for real world applications. To address this problem and use unlabeled data, we introduce unsupervised competitive learning, which only requires forward propagating signals for CNNs. The method was evaluated on image discrimination tasks using the MNIST, CIFAR-10, and ImageNet datasets, and it achieved state-of-the-art performance with respect to other biologically motivated methods in the ImageNet benchmark. The results suggest that the method enables higher-level learning representations solely based on the forward propagating signals without the need for a backward error signal for training convolutional layers. The proposed method could be useful for a variety of poorly labeled data, for example, time series or medical data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003403",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Competitive learning",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Geodesy",
      "Geography",
      "MNIST database",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Shinozaki",
        "given_name": "Takashi"
      }
    ]
  },
  {
    "title": "Extremely randomized neural networks for constructing prediction intervals",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.020",
    "abstract": "The aim of this paper is to propose a novel prediction model based on an ensemble of deep neural networks adapting the extremely randomized trees method originally developed for random forests. The extra-randomness introduced in the ensemble reduces the variance of the predictions and improves out-of-sample accuracy. As a byproduct, we are able to compute the uncertainty about our model predictions and construct interval forecasts. Some of the limitations associated with bootstrap-based algorithms can be overcome by not performing data resampling and thus, by ensuring the suitability of the methodology in low and mid-dimensional settings, or when the i . i . d . assumption does not hold. An extensive Monte Carlo simulation exercise shows the good performance of this novel prediction method in terms of mean square prediction error and the accuracy of the prediction intervals in terms of out-of-sample prediction interval coverage probabilities. The advanced approach delivers better out-of-sample accuracy in experimental settings, improving upon state-of-the-art methods like MC dropout and bootstrap procedures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003257",
    "keywords": [
      "Accounting",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bootstrap aggregating",
      "Business",
      "Chemistry",
      "Chromatography",
      "Combinatorics",
      "Computer science",
      "Dropout (neural networks)",
      "Interval (graph theory)",
      "Machine learning",
      "Mathematics",
      "Mean squared error",
      "Monte Carlo method",
      "Prediction interval",
      "Random forest",
      "Randomness",
      "Resampling",
      "Sample (material)",
      "Statistics",
      "Variance (accounting)"
    ],
    "authors": [
      {
        "surname": "Mancini",
        "given_name": "Tullio"
      },
      {
        "surname": "Calvo-Pardo",
        "given_name": "Hector"
      },
      {
        "surname": "Olmo",
        "given_name": "Jose"
      }
    ]
  },
  {
    "title": "Recurrent neural network from adder’s perspective: Carry-lookahead RNN",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.032",
    "abstract": "The recurrent network architecture is a widely used model in sequence modeling, but its serial dependency hinders the computation parallelization, which makes the operation inefficient. The same problem was encountered in serial adder at the early stage of digital electronics. In this paper, we discuss the similarities between recurrent neural network (RNN) and serial adder. Inspired by carry-lookahead adder, we introduce carry-lookahead module to RNN, which makes it possible for RNN to run in parallel. Then, we design the method of parallel RNN computation, and finally Carry-lookahead RNN (CL-RNN) is proposed. CL-RNN takes advantages in parallelism and flexible receptive field. Through a comprehensive set of tests, we verify that CL-RNN can perform better than existing typical RNNs in sequence modeling tasks which are specially designed for RNNs. Code and models are available at: https://github.com/WinnieJiangHW/Carry-lookahead_RNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003452",
    "keywords": [
      "Adder",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Carry (investment)",
      "Computation",
      "Computer science",
      "Economics",
      "Finance",
      "Latency (audio)",
      "Parallel computing",
      "Recurrent neural network",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Haowei"
      },
      {
        "surname": "Qin",
        "given_name": "Feiwei"
      },
      {
        "surname": "Cao",
        "given_name": "Jin"
      },
      {
        "surname": "Peng",
        "given_name": "Yong"
      },
      {
        "surname": "Shao",
        "given_name": "Yanli"
      }
    ]
  },
  {
    "title": "Theory of deep convolutional neural networks III: Approximating radial functions",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.09.027",
    "abstract": "We consider a family of deep neural networks consisting of two groups of convolutional layers, a downsampling operator, and a fully connected layer. The network structure depends on two structural parameters which determine the numbers of convolutional layers and the width of the fully connected layer. We establish an approximation theory with explicit approximation rates when the approximated function takes a composite form f ∘ Q with a feature polynomial Q and a univariate function f . In particular, we prove that such a network can outperform fully connected shallow networks in approximating radial functions with Q ( x ) = | x | 2 , when the dimension d of data from R d is large. This gives the first rigorous proof for the superiority of deep convolutional neural networks in approximating functions with special structures. Then we carry out generalization analysis for empirical risk minimization with such a deep network in a regression framework with the regression function of the form f ∘ Q . Our network structure which does not use any composite information or the functions Q and f can automatically extract features and make use of the composite nature of the regression function via tuning the structural parameters. Our analysis provides an error bound which decreases with the network depth to a minimum and then increases, verifying theoretically a trade-off phenomenon observed for network depths in many practical applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003890",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Evolutionary biology",
      "Feature (linguistics)",
      "Function (biology)",
      "Image (mathematics)",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Philosophy",
      "Polynomial",
      "Upsampling"
    ],
    "authors": [
      {
        "surname": "Mao",
        "given_name": "Tong"
      },
      {
        "surname": "Shi",
        "given_name": "Zhongjie"
      },
      {
        "surname": "Zhou",
        "given_name": "Ding-Xuan"
      }
    ]
  },
  {
    "title": "Multi-view spectral clustering via common structure maximization of local and global representations",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.020",
    "abstract": "The essential problem of multi-view spectral clustering is to learn a good common representation by effectively utilizing multi-view information. A popular strategy for improving the quality of the common representation is utilizing global and local information jointly. Most existing methods capture local manifold information by graph regularization. However, once local graphs are constructed, they do not change during the whole optimization process. This may lead to a degenerated common representation in the case of existing unreliable graphs. To address this problem, rather than directly using fixed local representations, we propose a dynamic strategy to construct a common local representation. Then, we impose a fusion term to maximize the common structure of the local and global representations so that they can boost each other in a mutually reinforcing manner. With this fusion term, we integrate local and global representation learning in a unified framework and design an alternative iteration based optimization procedure to solve it. Extensive experiments conducted on a number of benchmark datasets support the superiority of our algorithm over several state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002835",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Cluster analysis",
      "Computer science",
      "Geodesy",
      "Geography",
      "Graph",
      "Law",
      "Mathematical optimization",
      "Mathematics",
      "Political science",
      "Politics",
      "Regularization (linguistics)",
      "Representation (politics)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Hao",
        "given_name": "Wenyu"
      },
      {
        "surname": "Pang",
        "given_name": "Shanmin"
      },
      {
        "surname": "Chen",
        "given_name": "Zhikai"
      }
    ]
  },
  {
    "title": "Learning hierarchically-structured concepts",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.033",
    "abstract": "We use a recently developed synchronous Spiking Neural Network (SNN) model to study the problem of learning hierarchically-structured concepts. We introduce an abstract data model that describes simple hierarchical concepts. We define a feed-forward layered SNN model, with learning modeled using Oja’s local learning rule, a well known biologically-plausible rule for adjusting synapse weights. We define what it means for such a network to recognize hierarchical concepts; our notion of recognition is robust, in that it tolerates a bounded amount of noise. Then, we present a learning algorithm by which a layered network may learn to recognize hierarchical concepts according to our robust definition. We analyze correctness and performance rigorously; the amount of time required to learn each concept, after learning all of the sub-concepts, is approximately O 1 η k ℓmax log ( k ) + 1 ɛ + b log ( k ) , where k is the number of sub-concepts per concept, ℓmax is the maximum hierarchical depth, η is the learning rate, ɛ describes the amount of uncertainty allowed in robust recognition, and b describes the amount of weight decrease for “irrelevant” edges. An interesting feature of this algorithm is that it allows the network to learn sub-concepts in a highly interleaved manner. This algorithm assumes that the concepts are presented in a noise-free way; we also extend these results to accommodate noise in the learning process. Finally, we give a simple lower bound saying that, in order to recognize concepts with hierarchical depth two with noise-tolerance, a neural network should have at least two layers. The results in this paper represent first steps in the theoretical study of hierarchical concepts using SNNs. The cases studied here are basic, but they suggest many directions for extensions to more elaborate and realistic cases.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100304X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Cognitive science",
      "Complement (music)",
      "Complementation",
      "Computer science",
      "Economics",
      "Finance",
      "Gene",
      "Learning rule",
      "Machine learning",
      "Order (exchange)",
      "Phenotype",
      "Psychology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Lynch",
        "given_name": "Nancy"
      },
      {
        "surname": "Mallmann-Trenn",
        "given_name": "Frederik"
      }
    ]
  },
  {
    "title": "The asymmetric learning rates of murine exploratory behavior in sparse reward environments",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.030",
    "abstract": "Goal-oriented behaviors of animals can be modeled by reinforcement learning algorithms. Such algorithms predict future outcomes of selected actions utilizing action values and updating those values in response to the positive and negative outcomes. In many models of animal behavior, the action values are updated symmetrically based on a common learning rate, that is, in the same way for both positive and negative outcomes. However, animals in environments with scarce rewards may have uneven learning rates. To investigate the asymmetry in learning rates in reward and non-reward, we analyzed the exploration behavior of mice in five-armed bandit tasks using a Q-learning model with differential learning rates for positive and negative outcomes. The positive learning rate was significantly higher in a scarce reward environment than in a rich reward environment, and conversely, the negative learning rate was significantly lower in the scarce environment. The positive to negative learning rate ratio was about 10 in the scarce environment and about 2 in the rich environment. This result suggests that when the reward probability was low, the mice tend to ignore failures and exploit the rare rewards. Computational modeling analysis revealed that the increased learning rates ratio could cause an overestimation of and perseveration on rare-rewarding events, increasing total reward acquisition in the scarce environment but disadvantaging impartial exploration.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002264",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Cognition",
      "Cognitive psychology",
      "Computer science",
      "Economics",
      "Machine learning",
      "Microeconomics",
      "Neuroscience",
      "Perseveration",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Reinforcement learning",
      "Scarcity"
    ],
    "authors": [
      {
        "surname": "Ohta",
        "given_name": "Hiroyuki"
      },
      {
        "surname": "Satori",
        "given_name": "Kuniaki"
      },
      {
        "surname": "Takarada",
        "given_name": "Yu"
      },
      {
        "surname": "Arake",
        "given_name": "Masashi"
      },
      {
        "surname": "Ishizuka",
        "given_name": "Toshiaki"
      },
      {
        "surname": "Morimoto",
        "given_name": "Yuji"
      },
      {
        "surname": "Takahashi",
        "given_name": "Tatsuji"
      }
    ]
  },
  {
    "title": "Enhanced image prior for unsupervised remoting sensing super-resolution",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.005",
    "abstract": "Numerous approaches based on training low-high resolution image pairs have been proposed to address the super-resolution (SR) task. Despite their success, low-high resolution image pairs are usually difficult to obtain in certain scenarios, and these methods are limited in the actual scene (unknown or non-ideal image acquisition process). In this paper, we proposed a novel unsupervised learning framework, termed Enhanced Image Prior (EIP), which achieves SR tasks without low/high resolution image pairs. We first feed random noise maps into a designed generative adversarial network (GAN) for satellite image SR reconstruction. Then, we convert the reference image to latent space as the enhanced image prior. Finally, we update the input noise in the latent space with a recurrent updating strategy, and further transfer the texture and structured information from the reference image. Results on extensive experiments on the Draper dataset show that EIP achieves significant improvements over state-of-the-art unsupervised SR methods both quantitatively and qualitatively. Our experiments on satellite (SuperView-1) images reveal the potential of the proposed approach in improving the resolution of remote sensing imagery compared with the supervised algorithms. Source code is available at https://github.com/jiaming-wang/EIP.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002379",
    "keywords": [
      "Artificial intelligence",
      "Code (set theory)",
      "Computer science",
      "Computer vision",
      "Image (mathematics)",
      "Image resolution",
      "Noise (video)",
      "Pattern recognition (psychology)",
      "Programming language",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jiaming"
      },
      {
        "surname": "Shao",
        "given_name": "Zhenfeng"
      },
      {
        "surname": "Huang",
        "given_name": "Xiao"
      },
      {
        "surname": "Lu",
        "given_name": "Tao"
      },
      {
        "surname": "Zhang",
        "given_name": "Ruiqian"
      },
      {
        "surname": "Ma",
        "given_name": "Jiayi"
      }
    ]
  },
  {
    "title": "A semi-supervised zero-shot image classification method based on soft-target",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.019",
    "abstract": "Zero-shot learning (ZSL) aims at training a classification model with data only from seen categories to recognize data from disjoint unseen categories. Domain shift and generalization capability are two fundamental challenges in ZSL. In this paper, we address them with a novel Soft-Target Semi-supervised Classification (STSC) model. Specifically, an autoencoder network is leveraged, where both labeled seen data from the seen categories and unlabeled ancillary data collected from Internet or other datasets are employed as two branches, respectively. For the branch of labeled seen data, side information are employed as the latent vectors to separately connect the input of encoder and the output of decoder. In this way, visual and side information are implicitly aligned. For the branch of unlabeled ancillary data, it explicitly strengthens the reconstruction ability of the network. Meanwhile, these ancillary data can be viewed as a smooth to the domain distribution, which contributes to the alleviation of the domain shift problem. To further guarantee the generation ability, a Softmax-T loss function is proposed by making full use of the soft target. Extensive experiments on three benchmark datasets show the superiority of the proposed approach under tasks of both traditional zero-shot learning and generalized zero-shot learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100215X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Benchmark (surveying)",
      "Combinatorics",
      "Computer science",
      "Data mining",
      "Disjoint sets",
      "Domain (mathematical analysis)",
      "Encoder",
      "Generalization",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Softmax function"
    ],
    "authors": [
      {
        "surname": "Ji",
        "given_name": "Zhong"
      },
      {
        "surname": "Wang",
        "given_name": "Qiang"
      },
      {
        "surname": "Cui",
        "given_name": "Biying"
      },
      {
        "surname": "Pang",
        "given_name": "Yanwei"
      },
      {
        "surname": "Cao",
        "given_name": "Xianbin"
      },
      {
        "surname": "Li",
        "given_name": "Xuelong"
      }
    ]
  },
  {
    "title": "Robust cost-sensitive kernel method with Blinex loss and its applications in credit risk evaluation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.016",
    "abstract": "Credit risk evaluation is a crucial yet challenging problem in financial analysis. It can not only help institutions reduce risk and ensure profitability, but also improve consumers’ fair practices. The data-driven algorithms such as artificial intelligence techniques regard the evaluation as a classification problem and aim to classify transactions as default or non-default. Since non-default samples greatly outnumber default samples, it is a typical imbalanced learning problem and each class or each sample needs special treatment. Numerous data-level, algorithm-level and hybrid methods are presented, and cost-sensitive support vector machines (CSSVMs) are representative algorithm-level methods. Based on the minimization of symmetric and unbounded loss functions, CSSVMs impose higher penalties on the misclassification costs of minority instances using domain specific parameters. However, such loss functions as error measurement cannot have an obvious cost-sensitive generalization. In this paper, we propose a robust cost-sensitive kernel method with Blinex loss (CSKB), which can be applied in credit risk evaluation. By inheriting the elegant merits of Blinex loss function, i.e., asymmetry and boundedness, CSKB not only flexibly controls distinct costs for both classes, but also enjoys noise robustness. As a data-driven decision-making paradigm of credit risk evaluation, CSKB can achieve the “win-win” situation for both the financial institutions and consumers. We solve linear and nonlinear CSKB by Nesterov accelerated gradient algorithm and Pegasos algorithm respectively. Moreover, the generalization capability of CSKB is theoretically analyzed. Comprehensive experiments on synthetic, UCI and credit risk evaluation datasets demonstrate that CSKB compares more favorably than other benchmark methods in terms of various measures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002483",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Credit risk",
      "Data mining",
      "Economics",
      "Finance",
      "Gene",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Profitability index",
      "Robustness (evolution)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Jingjing"
      },
      {
        "surname": "Li",
        "given_name": "Jiahui"
      },
      {
        "surname": "Xu",
        "given_name": "Weiqi"
      },
      {
        "surname": "Tian",
        "given_name": "Yingjie"
      },
      {
        "surname": "Ju",
        "given_name": "Xuchan"
      },
      {
        "surname": "Zhang",
        "given_name": "Jie"
      }
    ]
  },
  {
    "title": "A brain-inspired computational model for spatio-temporal information processing",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.015",
    "abstract": "Spatio-temporal information processing is fundamental in both brain functions and AI applications. Current strategies for spatio-temporal pattern recognition usually involve explicit feature extraction followed by feature aggregation, which requires a large amount of labeled data. In the present study, motivated by the subcortical visual pathway and early stages of the auditory pathway for motion and sound processing, we propose a novel brain-inspired computational model for generic spatio-temporal pattern recognition. The model consists of two modules, a reservoir module and a decision-making module. The former projects complex spatio-temporal patterns into spatially separated neural representations via its recurrent dynamics, the latter reads out neural representations via integrating information over time, and the two modules are linked together using known examples. Using synthetic data, we demonstrate that the model can extract the frequency and order information of temporal inputs. We apply the model to reproduce the looming pattern discrimination behavior as observed in experiments successfully. Furthermore, we apply the model to the gait recognition task, and demonstrate that our model accomplishes the recognition in an event-based manner and outperforms deep learning counterparts when training data is limited.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002112",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Economics",
      "Feature (linguistics)",
      "Feature extraction",
      "Linguistics",
      "Machine learning",
      "Management",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Task (project management)",
      "Temporal database"
    ],
    "authors": [
      {
        "surname": "Lin",
        "given_name": "Xiaohan"
      },
      {
        "surname": "Zou",
        "given_name": "Xiaolong"
      },
      {
        "surname": "Ji",
        "given_name": "Zilong"
      },
      {
        "surname": "Huang",
        "given_name": "Tiejun"
      },
      {
        "surname": "Wu",
        "given_name": "Si"
      },
      {
        "surname": "Mi",
        "given_name": "Yuanyuan"
      }
    ]
  },
  {
    "title": "A novel density-based neural mass model for simulating neuronal network dynamics with conductance-based synapses and membrane current adaptation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.009",
    "abstract": "Despite its success in understanding brain rhythms, the neural mass model, as a low-dimensional mean-field network model, is phenomenological in nature, so that it cannot replicate some of rich repertoire of responses seen in real neuronal tissues. Here, using a colored-synapse population density method, we derived a novel neural mass model, termed density-based neural mass model (dNMM), as the mean-field description of network dynamics of adaptive exponential integrate-and-fire (aEIF) neurons, in which two critical neuronal features, i.e., voltage-dependent conductance-based synaptic interactions and adaptation of firing rate responses, were included. Our results showed that the dNMM was capable of correctly estimating firing rate responses of a neuronal population of aEIF neurons receiving stationary or time-varying excitatory and inhibitory inputs. Finally, it was also able to quantitatively describe the effect of spike-frequency adaptation in the generation of asynchronous irregular activity of excitatory–inhibitory cortical networks. We conclude that in terms of its biological reality and calculation efficiency, the dNMM is a suitable candidate to build significantly large-scale network models involving multiple brain areas, where the neuronal population is the smallest dynamic unit.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002410",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biological neural network",
      "Biological system",
      "Biology",
      "Computer science",
      "Demography",
      "Excitatory postsynaptic potential",
      "Inhibitory postsynaptic potential",
      "Local field potential",
      "Neuroscience",
      "Population",
      "Sociology",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Chih-Hsu"
      },
      {
        "surname": "Lin",
        "given_name": "Chou-Ching K."
      }
    ]
  },
  {
    "title": "Periodic clustering of simple and complex cells in visual cortex",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.002",
    "abstract": "Neurons in the primary visual cortex (V1) are often classified as simple or complex cells, but it is debated whether they are discrete hierarchical classes of neurons or if they represent a continuum of variation within a single class of cells. Herein, we show that simple and complex cells may arise commonly from the feedforward projections from the retina. From analysis of the cortical receptive fields in cats, we show evidence that simple and complex cells originate from the periodic variation of ON–OFF segregation in the feedforward projection of retinal mosaics, by which they organize into periodic clusters in V1. From data in cats, we observed that clusters of simple and complex receptive fields correlate topographically with orientation maps, which supports our model prediction. Our results suggest that simple and complex cells are not two distinct neural populations but arise from common retinal afferents, simultaneous with orientation tuning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002343",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Binocular neurons",
      "Biochemistry",
      "Biological system",
      "Biology",
      "Cluster analysis",
      "Computer science",
      "Control engineering",
      "Engineering",
      "Epistemology",
      "Feed forward",
      "Geometry",
      "Mathematics",
      "Neuroscience",
      "Orientation (vector space)",
      "Orientation column",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Projection (relational algebra)",
      "Receptive field",
      "Retina",
      "Retinal",
      "Simple (philosophy)",
      "Simple cell",
      "Striate cortex",
      "Visual cortex"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Gwangsu"
      },
      {
        "surname": "Jang",
        "given_name": "Jaeson"
      },
      {
        "surname": "Paik",
        "given_name": "Se-Bum"
      }
    ]
  },
  {
    "title": "Exponential passivity of discrete-time switched neural networks with transmission delays via an event-triggered sliding mode control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.014",
    "abstract": "This paper investigates the exponential passivity of discrete-time switched neural networks (DSNNs) with transmission delays via an event-triggered sliding mode control (SMC). Firstly, a novel discrete-time switched SMC scheme is constructed on the basis of sliding mode control method and event-triggered mechanism. Next, a state observer with transmission delays is designed to estimate the system state. Moreover, some new weighted summation inequalities are further proposed to effectively evaluate the exponential passivity criteria for the closed-loop system. Finally, the effectiveness of theoretical results is showed through a simulative analysis on a multi-area power system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100246X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Electrical engineering",
      "Engineering",
      "Exponential function",
      "Mathematical analysis",
      "Mathematics",
      "Mode (computer interface)",
      "Nonlinear system",
      "Observer (physics)",
      "Operating system",
      "Passivity",
      "Physics",
      "Quantum mechanics",
      "Sliding mode control",
      "State observer",
      "Statistics",
      "Telecommunications",
      "Transmission (telecommunications)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jinling"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Ma",
        "given_name": "Tianlong"
      }
    ]
  },
  {
    "title": "Adaptive neural network asymptotic tracking control for nonstrict feedback stochastic nonlinear systems",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.011",
    "abstract": "The adaptive neural network asymptotic tracking control issue of nonstrict feedback stochastic nonlinear systems is studied in our article by adopting backstepping algorithm. Compared with the existing research, the hypothesis about unknown virtual control coefficients (UVCC) is overcome in the control design. By using the bound estimation scheme and some smooth functions, associating with approximation-based neural network, the asymptotic tracking controller is recursively constructed. With the aid of Lyapunov function and beneficial inequalities, the asymptotic convergence character and stability with stochastic disturbance and unknown UVCC can be ensured. Finally, the theoretical finding is verified via a simulation example.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002434",
    "keywords": [
      "Adaptive control",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Mathematics",
      "Nonlinear system",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Recurrent neural network",
      "Stochastic neural network",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Yongchao"
      },
      {
        "surname": "Zhu",
        "given_name": "Qidan"
      }
    ]
  },
  {
    "title": "Refined UNet v3: Efficient end-to-end patch-wise network for cloud and shadow segmentation with multi-channel spectral features",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.008",
    "abstract": "Semantic segmentation is one of the essential prerequisites for computer vision tasks, but edge-precise segmentation stays challenging due to the potential lack of a proper model indicating the low-level relation between pixels. We have presented Refined UNet v2, a concatenation of a network backbone and a subsequent embedded conditional random field (CRF) layer, which coarsely performs pixel-wise classification and refines edges of segmentation regions in a one-stage way. However, the CRF layer of v2 employs a gray-scale global observation (image) to construct contrast-sensitive bilateral features, which is not able to achieve the desired performance on ambiguous edges. In addition, the naïve depth-wise Gaussian filter cannot always compute efficiently, especially for a longer-range message-passing step. To address the aforementioned issues, we upgrade the bilateral message-passing kernel and the efficient implementation of Gaussian filtering in the CRF layer in this paper, referred to as Refined UNet v3, which is able to effectively capture ambiguous edges and accelerate the message-passing procedure. Specifically, the inherited UNet is employed to coarsely locate cloud and shadow regions and the embedded CRF layer refines the edges of the forthcoming segmentation proposals. The multi-channel guided Gaussian filter is applied to the bilateral message-passing step, which improves detecting ambiguous edges that are hard for the gray-scale counterpart to identify, and fast Fourier transform-based (FFT-based) Gaussian filtering facilitates an efficient and potentially range-agnostic implementation. Furthermore, Refined UNet v3 is able to be extended to segmentation on multi-spectral datasets, and the corresponding refinement examination confirms the development of shadow retrieval. Experiments and corresponding results demonstrate that the proposed update can outperform its counterpart in terms of the detection of vague edges, shadow retrieval, and isolated redundant regions, and it is practically efficient in our TensorFlow implementation. The demo source code is available at https://github.com/92xianshen/refined-unet-v3.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003130",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Conditional random field",
      "Fast Fourier transform",
      "Gaussian",
      "Gaussian filter",
      "Gaussian function",
      "Image (mathematics)",
      "Image segmentation",
      "Pattern recognition (psychology)",
      "Physics",
      "Pixel",
      "Quantum mechanics",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Jiao",
        "given_name": "Libin"
      },
      {
        "surname": "Huo",
        "given_name": "Lianzhi"
      },
      {
        "surname": "Hu",
        "given_name": "Changmiao"
      },
      {
        "surname": "Tang",
        "given_name": "Ping"
      }
    ]
  },
  {
    "title": "Reliable impulsive synchronization for fuzzy neural networks with mixed controllers",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.013",
    "abstract": "This work studies the synchronization of the master–slave (MS) fuzzy neural networks (FNNs) with random actuator failure, where the state information of the master FNNs can not be obtained directly. To reduce the loads of the communication channel and the controller, the simultaneously impulsive driven strategy of the communication channel and the controller is proposed. On the basis of the received measurements of the master FNNs, the mixed controller consisting of observer based controller and the static controller is designed. The randomly occurred actuator failure is also considered. According to the Lyapunov method, the sufficient conditions are achieved to ensure the synchronization of the MS FNNs, and the controller gains are designed by using the obtained results. The validity of the derived results is illustrated by a numerical example.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100318X",
    "keywords": [
      "Actuator",
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Engineering",
      "Fuzzy logic",
      "Master/slave",
      "Observer (physics)",
      "Operating system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Fen"
      },
      {
        "surname": "Liu",
        "given_name": "Chang"
      },
      {
        "surname": "Rao",
        "given_name": "Hongxia"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Active sensing with artificial neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.007",
    "abstract": "The fitness of behaving agents depends on their knowledge of the environment, which demands efficient exploration strategies. Active sensing formalizes exploration as reduction of uncertainty about the current state of the environment. Despite strong theoretical justifications, active sensing has had limited applicability due to difficulty in estimating information gain. Here we address this issue by proposing a linear approximation to information gain and by implementing efficient gradient-based action selection within an artificial neural network setting. We compare information gain estimation with state of the art, and validate our model on an active sensing task based on MNIST dataset. We also propose an approximation that exploits the amortized inference network, and performs equally well in certain contexts.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003129",
    "keywords": [
      "Action selection",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer security",
      "Economics",
      "Exploit",
      "Inference",
      "Information gain",
      "MNIST database",
      "Machine learning",
      "Management",
      "Mutual information",
      "Neuroscience",
      "Perception",
      "Selection (genetic algorithm)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Solopchuk",
        "given_name": "Oleg"
      },
      {
        "surname": "Zénon",
        "given_name": "Alexandre"
      }
    ]
  },
  {
    "title": "Smoothing neural network for L 0 regularized optimization problem with general convex constraints",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.001",
    "abstract": "In this paper, we propose a neural network modeled by a differential inclusion to solve a class of discontinuous and nonconvex sparse regression problems with general convex constraints, whose objective function is the sum of a convex but not necessarily differentiable loss function and L 0 regularization. We construct a smoothing relaxation function of L 0 regularization and propose a neural network to solve the considered problem. We prove that the solution of proposed neural network with any initial point satisfying linear equality constraints is global existent, bounded and reaches the feasible region in finite time and remains there thereafter. Moreover, the solution of proposed neural network is its slow solution and any accumulation point of it is a Clarke stationary point of the brought forward nonconvex smoothing approximation problem. In the box-constrained case, all accumulation points of the solution own a unified lower bound property and have a common support set. Except for a special case, any accumulation point of the solution is a local minimizer of the considered problem. In particular, the proposed neural network has a simple structure than most existing neural networks for solving the locally Lipschitz continuous but nonsmooth nonconvex problems. Finally, we give some numerical experiments to show the efficiency of proposed neural network.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003063",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Convex function",
      "Differentiable function",
      "Differential inclusion",
      "Geometry",
      "Lipschitz continuity",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Regular polygon",
      "Regularization (linguistics)",
      "Smoothing"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Wenjing"
      },
      {
        "surname": "Bian",
        "given_name": "Wei"
      }
    ]
  },
  {
    "title": "A hybrid quantum–classical neural network with deep residual learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.028",
    "abstract": "Inspired by the success of classical neural networks, there has been tremendous effort to develop classical effective neural networks into quantum concept. In this paper, a novel hybrid quantum–classical neural network with deep residual learning (Res-HQCNN) is proposed. We firstly analyse how to connect residual block structure with a quantum neural network, and give the corresponding training algorithm. At the same time, the advantages and disadvantages of transforming deep residual learning into quantum concept are provided. As a result, the model can be trained in an end-to-end fashion, analogue to the backpropagation in classical neural networks. To explore the effectiveness of Res-HQCNN , we perform extensive experiments for quantum data with or without noisy on classical computer. The experimental results show the Res-HQCNN performs better to learn an unknown unitary transformation and has stronger robustness for noisy data, when compared to state of the arts. Moreover, the possible methods of combining residual learning with quantum neural networks are also discussed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002240",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Gene",
      "Physics",
      "Quantum",
      "Quantum computer",
      "Quantum mechanics",
      "Recurrent neural network",
      "Residual",
      "Robustness (evolution)",
      "Types of artificial neural networks"
    ],
    "authors": [
      {
        "surname": "Liang",
        "given_name": "Yanying"
      },
      {
        "surname": "Peng",
        "given_name": "Wei"
      },
      {
        "surname": "Zheng",
        "given_name": "Zhu-Jun"
      },
      {
        "surname": "Silvén",
        "given_name": "Olli"
      },
      {
        "surname": "Zhao",
        "given_name": "Guoying"
      }
    ]
  },
  {
    "title": "Visual-guided attentive attributes embedding for zero-shot learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.031",
    "abstract": "Zero-shot learning (ZSL) aims to learn a classifier for unseen classes by exploiting both training data from seen classes and external knowledge. In many visual tasks such as image classification, a set of high-level attributes that describe the semantic properties of classes are used as the external knowledge to bridge seen and unseen classes. While the attributes are usually treated equally by previous ZSL studies, we observe that the contribution of different attributes varies significantly over model training. To adaptively exploit the discriminative information embedded in different attributes, we propose a novel encoder–decoder framework with attention mechanism on the attribute level for zero-shot learning. Specifically, by mapping the visual features into a semantic space, the more discriminative attributes are emphasized with larger attention weights. Further, the attentive attributes and the class prototypes are simultaneously decoded to the visual space so that the hubness problem can be eased. Finally, the labels are predicted in the visual space. Extensive experiments on multiple benchmark datasets demonstrate that our proposed model achieves a significant boost over several state-of-the-art methods for ZSL task and comparative results for generalized ZSL task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003026",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Class (philosophy)",
      "Classifier (UML)",
      "Computer science",
      "Computer security",
      "Discriminative model",
      "Economics",
      "Embedding",
      "Encoder",
      "Exploit",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Management",
      "Neuroscience",
      "Operating system",
      "Pattern recognition (psychology)",
      "Perception",
      "Task (project management)",
      "Visual space"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Rui"
      },
      {
        "surname": "Zhu",
        "given_name": "Qi"
      },
      {
        "surname": "Xu",
        "given_name": "Xiangyu"
      },
      {
        "surname": "Zhang",
        "given_name": "Daoqiang"
      },
      {
        "surname": "Huang",
        "given_name": "Sheng-Jun"
      }
    ]
  },
  {
    "title": "Effective and direct control of neural TTS prosody by removing interactions between different attributes",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.006",
    "abstract": "End-to-end TTS advancement has shown that synthesized speech prosody can be controlled by conditioning the decoder with speech prosody attribute labels. However, to annotate quantitatively the prosody patterns of a large set of training data is both time consuming and expensive. To use unannotated data, variational autoencoder (VAE) has been proposed to model individual prosody attribute as a random variable in the latent space. The VAE is an unsupervised approach and the corresponding latent variables are in general correlated with each other. For more effective and direct control of speech prosody along each attribute dimension, it is highly desirable to disentangle the correlated latent variables. Additionally, being able to interpret the disentangled attributes as speech perceptual cues is useful for designing more efficient prosody control of TTS. In this paper, we propose two attribute separation schemes: (1) using 3 separate VAEs to model the real-valued, different prosodic features, i.e., F 0 , energy and duration; (2) minimizing mutual information between different prosody attributes to remove their mutual correlations, for facilitating more direct prosody control. Experimental results confirm that the two proposed schemes can indeed make individual prosody attributes more interpretable and direct TTS prosody control more effective. The improvements are measured objectively by F 0 Frame Error (FFE) and subjectively with MOS and A/B comparison listening tests, respectively. The scatter diagrams of t-SNE also demonstrate the correlations between prosody attributes, which are well disentangled by minimizing their mutual information. Synthesized TTS samples can be found at https://xiaochunan.github.io/prosody/index.html.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002380",
    "keywords": [
      "Active listening",
      "Artificial intelligence",
      "Communication",
      "Computer science",
      "Control (management)",
      "Mutual information",
      "Natural language processing",
      "Programming language",
      "Prosody",
      "Psychology",
      "Set (abstract data type)",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "An",
        "given_name": "Xiaochun"
      },
      {
        "surname": "Soong",
        "given_name": "Frank K."
      },
      {
        "surname": "Yang",
        "given_name": "Shan"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      }
    ]
  },
  {
    "title": "Variational policy search using sparse Gaussian process priors for learning multimodal optimal actions",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.010",
    "abstract": "Policy search reinforcement learning has been drawing much attention as a method of learning a robot control policy. In particular, policy search using such non-parametric policies as Gaussian process regression can learn optimal actions with high-dimensional and redundant sensors as input. However, previous methods implicitly assume that the optimal action becomes unique for each state. This assumption can severely limit such practical applications as robot manipulations since designing a reward function that appears in only one optimal action for complex tasks is difficult. The previous methods might have caused critical performance deterioration because the typical non-parametric policies cannot capture the optimal actions due to their unimodality. We propose novel approaches in non-parametric policy searches with multiple optimal actions and offer two different algorithms commonly based on a sparse Gaussian process prior and variational Bayesian inference. The following are the key ideas: (1) multimodality for capturing multiple optimal actions and (2) mode-seeking for capturing one optimal action by ignoring the others. First, we propose a multimodal sparse Gaussian process policy search that uses multiple overlapped GPs as a prior. Second, we propose a mode-seeking sparse Gaussian process policy search that uses the student-t distribution for a likelihood function. The effectiveness of those algorithms is demonstrated through applications to object manipulation tasks with multiple optimal actions in simulations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002422",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Bayesian probability",
      "Biology",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Gaussian",
      "Gaussian process",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Operating system",
      "Parametric statistics",
      "Physics",
      "Prior probability",
      "Process (computing)",
      "Quantum mechanics",
      "Reinforcement learning",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Sasaki",
        "given_name": "Hikaru"
      },
      {
        "surname": "Matsubara",
        "given_name": "Takamitsu"
      }
    ]
  },
  {
    "title": "A hybrid quantum–classical neural network with deep residual learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.028",
    "abstract": "Inspired by the success of classical neural networks, there has been tremendous effort to develop classical effective neural networks into quantum concept. In this paper, a novel hybrid quantum–classical neural network with deep residual learning (Res-HQCNN) is proposed. We firstly analyse how to connect residual block structure with a quantum neural network, and give the corresponding training algorithm. At the same time, the advantages and disadvantages of transforming deep residual learning into quantum concept are provided. As a result, the model can be trained in an end-to-end fashion, analogue to the backpropagation in classical neural networks. To explore the effectiveness of Res-HQCNN , we perform extensive experiments for quantum data with or without noisy on classical computer. The experimental results show the Res-HQCNN performs better to learn an unknown unitary transformation and has stronger robustness for noisy data, when compared to state of the arts. Moreover, the possible methods of combining residual learning with quantum neural networks are also discussed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002240",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Gene",
      "Physics",
      "Quantum",
      "Quantum computer",
      "Quantum mechanics",
      "Recurrent neural network",
      "Residual",
      "Robustness (evolution)",
      "Types of artificial neural networks"
    ],
    "authors": [
      {
        "surname": "Liang",
        "given_name": "Yanying"
      },
      {
        "surname": "Peng",
        "given_name": "Wei"
      },
      {
        "surname": "Zheng",
        "given_name": "Zhu-Jun"
      },
      {
        "surname": "Silvén",
        "given_name": "Olli"
      },
      {
        "surname": "Zhao",
        "given_name": "Guoying"
      }
    ]
  },
  {
    "title": "Recurrent neural network pruning using dynamical systems and iterative fine-tuning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.001",
    "abstract": "Network pruning techniques are widely employed to reduce the memory requirements and increase the inference speed of neural networks. This work proposes a novel RNN pruning method that considers the RNN weight matrices as collections of time-evolving signals. Such signals that represent weight vectors can be modelled using Linear Dynamical Systems (LDSs). In this way, weight vectors with similar temporal dynamics can be pruned as they have limited effect on the performance of the model. Additionally, during the fine-tuning of the pruned model, a novel discrimination-aware variation of the L2 regularization is introduced to penalize network weights (i.e., reduce the magnitude), whose impact on the output of an RNN network is minimal. Finally, an iterative fine-tuning approach is proposed that employs a bigger model to guide an increasingly smaller pruned one, as a steep decrease of the network parameters can irreversibly harm the performance of the pruned model. Extensive experimentation with different network architectures demonstrates the potential of the proposed method to create pruned models with significantly improved perplexity by at least 0.62% on the PTB dataset and improved F1-score by 1.39% on the SQuAD dataset, contrary to other state-of-the-art approaches that slightly improve or even deteriorate models’ performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002641",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Fine-tuning",
      "Inference",
      "Language model",
      "Machine learning",
      "Perplexity",
      "Physics",
      "Pruning",
      "Quantum mechanics",
      "Recurrent neural network",
      "Regularization (linguistics)"
    ],
    "authors": [
      {
        "surname": "Chatzikonstantinou",
        "given_name": "Christos"
      },
      {
        "surname": "Konstantinidis",
        "given_name": "Dimitrios"
      },
      {
        "surname": "Dimitropoulos",
        "given_name": "Kosmas"
      },
      {
        "surname": "Daras",
        "given_name": "Petros"
      }
    ]
  },
  {
    "title": "Internal manipulation of perceptual representations in human flexible cognition: A computational model",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.013",
    "abstract": "Executive functions represent a set of processes in goal-directed cognition that depend on integrated cortical-basal ganglia brain systems and form the basis of flexible human behaviour. Several computational models have been proposed for studying cognitive flexibility as a key executive function and the Wisconsin card sorting test (WCST) that represents an important neuropsychological tool to investigate it. These models clarify important aspects that underlie cognitive flexibility, particularly decision-making, motor response, and feedback-dependent learning processes. However, several studies suggest that the categorisation processes involved in the solution of the WCST include an additional computational stage of category representation that supports the other processes. Surprisingly, all models of the WCST ignore this fundamental stage and they assume that decision making directly triggers actions. Thus, we propose a novel hypothesis where the key mechanisms of cognitive flexibility and goal-directed behaviour rely on the acquisition of suitable representations of percepts and their top-down internal manipulation. Moreover, we propose a neuro-inspired computational model to operationalise this hypothesis. The capacity of the model to support cognitive flexibility was validated by systematically reproducing and interpreting the behaviour exhibited in the WCST by young and old healthy adults, and by frontal and Parkinson patients. The results corroborate and further articulate the hypothesis that the internal manipulation of representations is a core process in goal-directed flexible cognition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002768",
    "keywords": [
      "Artificial intelligence",
      "Card sorting",
      "Cognition",
      "Cognitive flexibility",
      "Cognitive psychology",
      "Cognitive science",
      "Computational model",
      "Computer science",
      "Economics",
      "Executive functions",
      "Flexibility (engineering)",
      "Law",
      "Management",
      "Mathematics",
      "Neurocognitive",
      "Neuropsychology",
      "Neuroscience",
      "Operating system",
      "Perception",
      "Political science",
      "Politics",
      "Process (computing)",
      "Programming language",
      "Psychology",
      "Representation (politics)",
      "Set (abstract data type)",
      "Statistics",
      "Task (project management)",
      "Task switching",
      "Wisconsin Card Sorting Test"
    ],
    "authors": [
      {
        "surname": "Granato",
        "given_name": "Giovanni"
      },
      {
        "surname": "Baldassarre",
        "given_name": "Gianluca"
      }
    ]
  },
  {
    "title": "A full-parallel implementation of Self-Organizing Maps on hardware",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.021",
    "abstract": "Self-Organizing Maps (SOMs) are extensively used for data clustering and dimensionality reduction. However, if applications are to fully benefit from SOM based techniques, high-speed processing is demanding, given that data tends to be both highly dimensional and yet “big”. Hence, a fully parallel architecture for the SOM is introduced to optimize the system’s data processing time. Unlike most literature approaches, the architecture proposed here does not contain sequential steps — a common limiting factor for processing speed. The architecture was validated on FPGA and evaluated concerning hardware throughput and the use of resources. Comparisons to the state of the art show a speedup of 8 . 91 × over a partially serial implementation, using less than 15% of hardware resources available. Thus, the method proposed here points to a hardware architecture that will not be obsolete quickly.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002173",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Cluster analysis",
      "Computer architecture",
      "Computer hardware",
      "Computer science",
      "Dimensionality reduction",
      "Field-programmable gate array",
      "Geometry",
      "Hardware architecture",
      "Mathematics",
      "Parallel computing",
      "Parallel processing",
      "Programming language",
      "Reduction (mathematics)",
      "Software",
      "Speedup",
      "Telecommunications",
      "Throughput",
      "Visual arts",
      "Wireless"
    ],
    "authors": [
      {
        "surname": "Dias",
        "given_name": "Leonardo A."
      },
      {
        "surname": "Damasceno",
        "given_name": "Augusto M.P."
      },
      {
        "surname": "Gaura",
        "given_name": "Elena"
      },
      {
        "surname": "Fernandes",
        "given_name": "Marcelo A.C."
      }
    ]
  },
  {
    "title": "Bidirectional interaction between visual and motor generative models using Predictive Coding and Active Inference",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.016",
    "abstract": "In this work, we build upon the Active Inference (AIF) and Predictive Coding (PC) frameworks to propose a neural architecture comprising a generative model for sensory prediction, and a distinct generative model for motor trajectories. We highlight how sequences of sensory predictions can act as rails guiding learning, control and online adaptation of motor trajectories. We furthermore inquire the effects of bidirectional interactions between the motor and the visual modules. The architecture is tested on the control of a simulated robotic arm learning to reproduce handwritten letters.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002793",
    "keywords": [
      "Artificial intelligence",
      "Coding (social sciences)",
      "Computer science",
      "Generative grammar",
      "Generative model",
      "Inference",
      "Machine learning",
      "Mathematics",
      "Predictive coding",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Annabi",
        "given_name": "Louis"
      },
      {
        "surname": "Pitti",
        "given_name": "Alexandre"
      },
      {
        "surname": "Quoy",
        "given_name": "Mathias"
      }
    ]
  },
  {
    "title": "Constrained plasticity reserve as a natural way to control frequency and weights in spiking neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.016",
    "abstract": "Biological neurons have adaptive nature and perform complex computations involving the filtering of redundant information. However, most common neural cell models, including biologically plausible, such as Hodgkin–Huxley or Izhikevich, do not possess predictive dynamics on a single-cell level. Moreover, the modern rules of synaptic plasticity or interconnections weights adaptation also do not provide grounding for the ability of neurons to adapt to the ever-changing input signal intensity. While natural neuron synaptic growth is precisely controlled and restricted by protein supply and recycling, weight correction rules such as widely used STDP are efficiently unlimited in change rate and scale. The present article introduces new mechanics of interconnection between neuron firing rate homeostasis and weight change through STDP growth bounded by abstract protein reserve, controlled by the intracellular optimization algorithm. We show how these cellular dynamics help neurons filter out the intense noise signals to help neurons keep a stable firing rate. We also examine that such filtering does not affect the ability of neurons to recognize the correlated inputs in unsupervised mode. Such an approach might be used in the machine learning domain to improve the robustness of AI systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100321X",
    "keywords": [],
    "authors": [
      {
        "surname": "Nikitin",
        "given_name": "Oleg"
      },
      {
        "surname": "Lukyanova",
        "given_name": "Olga"
      },
      {
        "surname": "Kunin",
        "given_name": "Alex"
      }
    ]
  },
  {
    "title": "A global neural network learning machine: Coupled integer and fractional calculus operator with an adaptive learning scheme",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.021",
    "abstract": "Find the global optimal solution of the model is one promising research topic in computational intelligent community. Dependent on analogies to natural processes, the evolutionary swarm intelligent algorithms are widely used for solving global optimization problems which directed by the fitness values. In this paper, we propose one efficient fractional global learning machine (Fragmachine) which includes two stages (descending and ascending) to determine the optimal search path. The neural network model is used to approach the given fitness value. Specifically, for the descending stage, the integer gradient of the network output with respect the current location is employed to find the next descending point, while for the ascending stage, the fractional gradient is implemented to climb and escape from the local optimal point. We further propose one adaptive learning rate during training which relies on both the current gradient (integer or fractional) information and the fitness value. Finally, a series of numerical experiments verify the effectiveness of the proposed algorithm, Fragmachine.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002537",
    "keywords": [
      "Adaptive learning",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Gene",
      "Global optimization",
      "Integer (computer science)",
      "Mathematical optimization",
      "Mathematics",
      "Operator (biology)",
      "Path (computing)",
      "Programming language",
      "Repressor",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Huaqing"
      },
      {
        "surname": "Pu",
        "given_name": "Yi-Fei"
      },
      {
        "surname": "Xie",
        "given_name": "Xuetao"
      },
      {
        "surname": "Zhang",
        "given_name": "Bingran"
      },
      {
        "surname": "Wang",
        "given_name": "Jian"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Locality preserving dense graph convolutional networks with graph context-aware node representations",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.031",
    "abstract": "Graph convolutional networks (GCNs) have been widely used for representation learning on graph data, which can capture structural patterns on a graph via specifically designed convolution and readout operations. In many graph classification applications, GCN-based approaches have outperformed traditional methods. However, most of the existing GCNs are inefficient to preserve local information of graphs — a limitation that is especially problematic for graph classification. In this work, we propose a locality-preserving dense GCN with graph context-aware node representations. Specifically, our proposed model incorporates a local node feature reconstruction module to preserve initial node features into node representations, which is realized via a simple but effective encoder–decoder mechanism. To capture local structural patterns in neighborhoods representing different ranges of locality, dense connectivity is introduced to connect each convolutional layer and its corresponding readout with all previous convolutional layers. To enhance node representativeness, the output of each convolutional layer is concatenated with the output of the previous layer’s readout to form a global context-aware node representation. In addition, a self-attention module is introduced to aggregate layer-wise representations to form the final graph-level representation. Experiments on benchmark datasets demonstrate the superiority of the proposed model over state-of-the-art methods in terms of classification accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002276",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Graph",
      "Linguistics",
      "Locality",
      "Paleontology",
      "Philosophy",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Wenfeng"
      },
      {
        "surname": "Gong",
        "given_name": "Maoguo"
      },
      {
        "surname": "Tang",
        "given_name": "Zedong"
      },
      {
        "surname": "Qin",
        "given_name": "A.K."
      },
      {
        "surname": "Sheng",
        "given_name": "Kai"
      },
      {
        "surname": "Xu",
        "given_name": "Mingliang"
      }
    ]
  },
  {
    "title": "Capsule networks with non-iterative cluster routing",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.032",
    "abstract": "Capsule networks use routing algorithms to flow information between consecutive layers. In the existing routing procedures, capsules produce predictions (termed votes) for capsules of the next layer. In a nutshell, the next-layer capsule’s input is a weighted sum over all the votes it receives. In this paper, we propose non-iterative cluster routing for capsule networks. In the proposed cluster routing, capsules produce vote clusters instead of individual votes for next-layer capsules, and each vote cluster sends its centroid to a next-layer capsule. Generally speaking, the next-layer capsule’s input is a weighted sum over the centroid of each vote cluster it receives. The centroid that comes from a cluster with a smaller variance is assigned a larger weight in the weighted sum process. Compared with the state-of-the-art capsule networks, the proposed capsule networks achieve the best accuracy on the Fashion-MNIST and SVHN datasets with fewer parameters, and achieve the best accuracy on the smallNORB and CIFAR-10 datasets with a moderate number of parameters. The proposed capsule networks also produce capsules with disentangled representation and generalize well to images captured at novel viewpoints. The proposed capsule networks also preserve 2D spatial information of an input image in the capsule channels: if the capsule channels are rotated, the object reconstructed from these channels will be rotated by the same transformation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003038",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Botany",
      "Capsule",
      "Centroid",
      "Chemistry",
      "Cluster (spacecraft)",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Data mining",
      "Gene",
      "Layer (electronics)",
      "MNIST database",
      "Mathematics",
      "Operating system",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Routing (electronic design automation)",
      "Topology (electrical circuits)",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Zhihao"
      },
      {
        "surname": "Cheng",
        "given_name": "Samuel"
      }
    ]
  },
  {
    "title": "Experimental stability analysis of neural networks in classification problems with confidence sets for persistence diagrams",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.007",
    "abstract": "We investigate classification performance of neural networks (NNs) based on topological insight in an attempt to guarantee stability of their inference. NNs which can accurately classify a dataset map it into a hidden space while disentangling intertwined data. NNs sometimes acquire forcible mapping to disentangle the data, and this forcible mapping generates outliers. The mapping around the outliers is unstable because the outputs change drastically. Hence, we define stable NNs to mean that they do not generate outliers. To investigate the possibility of the existence of outliers, we use persistent homology and a method to estimate the confidence set for persistence diagrams. The combined use enables us to test whether the focused geometry is topologically simple, that is, no outliers. In this work, we use the MNIST and CIFAR-10 datasets and investigate the relationship between the classification performance and the topological characteristics with several NNs. Investigation results with the MNIST dataset show that the test accuracy of all the networks is superior, exceeding 98%, even though the transformed dataset is not topologically simple. Results with the CIFAR-10 dataset also show that the possibility of the existence of outliers is shown in the mapping by the accurate convolutional NNs. Therefore, we conclude that the presented investigation is necessary to guarantee that the NNs, in particular deep NNs, do not acquire unstable mapping for forcible classification.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001994",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Inference",
      "MNIST database",
      "Machine learning",
      "Outlier",
      "Pattern recognition (psychology)",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Akai",
        "given_name": "Naoki"
      },
      {
        "surname": "Hirayama",
        "given_name": "Takatsugu"
      },
      {
        "surname": "Murase",
        "given_name": "Hiroshi"
      }
    ]
  },
  {
    "title": "Label propagation via local geometry preserving for deep semi-supervised image recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.007",
    "abstract": "In this paper, we propose a novel transductive pseudo-labeling based method for deep semi-supervised image recognition. Inspired from the superiority of pseudo labels inferred by label propagation compared with those inferred from network, we argue that information flow from labeled data to unlabeled data should be kept noiseless and with minimum loss. Previous research works use scarce labeled data for feature learning and solely consider the relationship between two feature vectors to construct the similarity graph in feature space, which causes two problems that ultimately lead to noisy and incomplete information flow from labeled data to unlabeled data. The first problem is that the learned feature mapping is highly likely to be biased and can easily over-fit noise. The second problem is the loss of local geometry information in feature space during label propagation. Accordingly, we firstly propose to incorporate self-supervised learning into feature learning for cleaner information flow in feature space during subsequent label propagation. Secondly, we propose to use reconstruction concept to measure pairwise similarity in feature space, such that local geometry information can be preserved. Ablation study confirms synergistic effects from features learned with self-supervision and similarity graph with local geometry preserving. Extensive experiments conducted on benchmark datasets have verified the effectiveness of our proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002392",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Feature (linguistics)",
      "Feature learning",
      "Feature vector",
      "Geodesy",
      "Geography",
      "Graph",
      "Image (mathematics)",
      "Linguistics",
      "Mathematics",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Semi-supervised learning",
      "Similarity (geometry)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Qing",
        "given_name": "Yuanyuan"
      },
      {
        "surname": "Zeng",
        "given_name": "Yijie"
      },
      {
        "surname": "Huang",
        "given_name": "Guang-Bin"
      }
    ]
  },
  {
    "title": "Hebbian semi-supervised learning in a sample efficiency setting",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.003",
    "abstract": "We propose to address the issue of sample efficiency, in Deep Convolutional Neural Networks (DCNN), with a semi-supervised training strategy that combines Hebbian learning with gradient descent: all internal layers (both convolutional and fully connected) are pre-trained using an unsupervised approach based on Hebbian learning, and the last fully connected layer (the classification layer) is trained using Stochastic Gradient Descent (SGD). In fact, as Hebbian learning is an unsupervised learning method, its potential lies in the possibility of training the internal layers of a DCNN without labels. Only the final fully connected layer has to be trained with labeled examples. We performed experiments on various object recognition datasets, in different regimes of sample efficiency, comparing our semi-supervised (Hebbian for internal layers + SGD for the final fully connected layer) approach with end-to-end supervised backprop training, and with semi-supervised learning based on Variational Auto-Encoder (VAE). The results show that, in regimes where the number of available labeled samples is low, our semi-supervised approach outperforms the other approaches in almost all the cases.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003087",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Chromatography",
      "Competitive learning",
      "Computer science",
      "Encoder",
      "Gradient descent",
      "Hebbian theory",
      "Layer (electronics)",
      "Machine learning",
      "Operating system",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Sample (material)",
      "Semi-supervised learning",
      "Stochastic gradient descent",
      "Supervised learning",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Lagani",
        "given_name": "Gabriele"
      },
      {
        "surname": "Falchi",
        "given_name": "Fabrizio"
      },
      {
        "surname": "Gennaro",
        "given_name": "Claudio"
      },
      {
        "surname": "Amato",
        "given_name": "Giuseppe"
      }
    ]
  },
  {
    "title": "Continual learning for recurrent neural networks: An empirical evaluation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.021",
    "abstract": "Learning continuously during all model lifetime is fundamental to deploy machine learning solutions robust to drifts in the data distribution. Advances in Continual Learning (CL) with recurrent neural networks could pave the way to a large number of applications where incoming data is non stationary, like natural language processing and robotics. However, the existing body of work on the topic is still fragmented, with approaches which are application-specific and whose assessment is based on heterogeneous learning protocols and datasets. In this paper, we organize the literature on CL for sequential data processing by providing a categorization of the contributions and a review of the benchmarks. We propose two new benchmarks for CL with sequential data based on existing datasets, whose characteristics resemble real-world applications. We also provide a broad empirical evaluation of CL and Recurrent Neural Networks in class-incremental scenario, by testing their ability to mitigate forgetting with a number of different strategies which are not specific to sequential data processing. Our results highlight the key role played by the sequence length and the importance of a clear specification of the CL scenario.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002847",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Categorization",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Forgetting",
      "Key (lock)",
      "Linguistics",
      "Machine learning",
      "Philosophy",
      "Recurrent neural network"
    ],
    "authors": [
      {
        "surname": "Cossu",
        "given_name": "Andrea"
      },
      {
        "surname": "Carta",
        "given_name": "Antonio"
      },
      {
        "surname": "Lomonaco",
        "given_name": "Vincenzo"
      },
      {
        "surname": "Bacciu",
        "given_name": "Davide"
      }
    ]
  },
  {
    "title": "Sensitivity – Local index to control chaoticity or gradient globally –",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.015",
    "abstract": "Here, we introduce a fully local index named “sensitivity” for each neuron to control chaoticity or gradient globally in a neural network (NN). We also propose a learning method to adjust it named “sensitivity adjustment learning (SAL)”. The index is the gradient magnitude of its output with respect to its inputs. By adjusting its time average to 1.0 in each neuron, information transmission in the neuron changes to be moderate without shrinking or expanding for both forward and backward computations. That results in moderate information transmission through a layer of neurons when the weights and inputs are random. Therefore, SAL can control the chaoticity of the network dynamics in a recurrent NN (RNN). It can also solve the vanishing gradient problem in error backpropagation (BP) learning in a deep feedforward NN or an RNN. We demonstrate that when applying SAL to an RNN with small and random initial weights, log-sensitivity, which is the logarithm of RMS (root mean square) sensitivity over all the neurons, is equivalent to the maximum Lyapunov exponent until it reaches 0.0. We also show that SAL works with BP or BPTT (BP through time) to avoid the vanishing gradient problem in a 300-layer NN or an RNN that learns a problem with a lag of 300 steps between the first input and the output. Compared with manually fine-tuning the spectral radius of the weight matrix before learning, SAL’s continuous nonlinear learning nature prevents loss of sensitivities during learning, resulting in a significant improvement in learning performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002471",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Electronic engineering",
      "Engineering",
      "Feed forward",
      "Feedforward neural network",
      "Gradient descent",
      "Mathematics",
      "Recurrent neural network",
      "Sensitivity (control systems)"
    ],
    "authors": [
      {
        "surname": "Shibata",
        "given_name": "Katsunari"
      },
      {
        "surname": "Ejima",
        "given_name": "Takuya"
      },
      {
        "surname": "Tokumaru",
        "given_name": "Yuki"
      },
      {
        "surname": "Matsuki",
        "given_name": "Toshitaka"
      }
    ]
  },
  {
    "title": "Online sensorimotor learning and adaptation for inverse dynamics control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.029",
    "abstract": "We propose a micro-data ( < 10 trials) sensorimotor learning and adaptation (SEED) model for human-like arm inverse dynamics control. The SEED model consists of a feedforward Gaussian motor primitive (GATE) neural network and an adaptive feedback impedance (AIM) mechanism. Sensorimotor weights over trials are learned in the GATE network, while the AIM mechanism is used to online tune impedance gains in a trial. The model was validated by periodic and non-periodic tracking tasks on a two-joint robot arm. As a result, the proposed model enables the arm to stably learn the tasks within 10 trials, compared to thousands of trials required by state-of-art deep learning. This model facilitates the exploration of unknown arm dynamics, in which the elbow joint requires much less active control compared to the shoulder. This control goes below 3% of the overall effort. This finding complies with a proximal–distal control gradient in human arm control. Taken together, the proposed SEED model paves a way for implementing data-efficient sensorimotor learning and adaptation of human-like arm movement.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002616",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Artificial neural network",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Epistemology",
      "Feed forward",
      "Inverse dynamics",
      "Kinematics",
      "Mechanism (biology)",
      "Neuroscience",
      "Philosophy",
      "Physics",
      "Psychology",
      "Recurrent neural network",
      "Robotic arm"
    ],
    "authors": [
      {
        "surname": "Xiong",
        "given_name": "Xiaofeng"
      },
      {
        "surname": "Manoonpong",
        "given_name": "Poramate"
      }
    ]
  },
  {
    "title": "Low-shot transfer with attention for highly imbalanced cursive character recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.003",
    "abstract": "Recognition of ancient Korean–Chinese cursive character (Hanja) is a challenging problem mainly because of large number of classes, damaged cursive characters, various hand-writing styles, and similar confusable characters. They also suffer from lack of training data and class imbalance issues. To address these problems, we propose a unified Regularized Low-shot Attention Transfer with Imbalance τ -Normalizing ( R E L A T I N ) framework. This handles the problem with instance-poor classes using a novel low-shot regularizer that encourages the norm of the weight vectors for classes with few samples to be aligned to those of many-shot classes. To overcome the class imbalance problem, we incorporate a decoupled classifier to rectify the decision boundaries via classifier weight-scaling into the proposed low-shot regularizer framework. To address the limited training data issue, the proposed framework performs Jensen–Shannon divergence based data augmentation and incorporate an attention module that aligns the most attentive features of the pretrained network to a target network. We verify the proposed RELATIN framework using highly-imbalanced ancient cursive handwritten character datasets. The results suggest that (i) the extreme class imbalance has a detrimental effect on classification performance; (ii) the proposed low-shot regularizer aligns the norm of the classifier in favor of classes with few samples; (iii) weight-scaling of decoupled classifier for addressing class imbalance appeared to be dominant in all the other baseline conditions; (iv) further addition of the attention module attempts to select more representative features maps from base pretrained model; (v) the proposed ( R E L A T I N ) framework results in superior representations to address extreme class imbalance issue.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002665",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Cursive",
      "Geometry",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Scaling"
    ],
    "authors": [
      {
        "surname": "Jalali",
        "given_name": "Amin"
      },
      {
        "surname": "Kavuri",
        "given_name": "Swathi"
      },
      {
        "surname": "Lee",
        "given_name": "Minho"
      }
    ]
  },
  {
    "title": "HiAM: A Hierarchical Attention based Model for knowledge graph multi-hop reasoning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.008",
    "abstract": "Learning to reason in large-scale knowledge graphs has attracted much attention from research communities recently. This paper targets a practical task of multi-hop reasoning in knowledge graphs, which can be applied in various downstream tasks such as question answering, and recommender systems. A key challenge in multi-hop reasoning is to synthesize structural information (e.g., paths) in knowledge graphs to perform deeper reasoning. Existing methods usually focus on connection paths between each entity pair. However, these methods ignore predecessor paths before connection paths and regard entities and relations within every single path as equally important. With our observations, predecessor paths before connection paths can provide more accurate semantic representations. Furthermore, entities and relations in a single path contribute variously to the right answers. To this end, we propose a novel model HiAM (Hierarchical Attention based Model) for knowledge graph multi-hop reasoning. HiAM makes use of predecessor paths to provide more accurate semantics for entities and explores the effects of different granularities. Firstly, we extract predecessor paths of head entities and connection paths between each entity pair. Then, a hierarchical attention mechanism is designed to capture the information of different granularities, including entity/relation-level and path-level features. Finally, multi-granularity features are fused together to predict the right answers. We go one step further to select the most significant path as the explanation for predicted answers. Comprehensive experimental results demonstrate that our method achieves competitive performance compared with the baselines on three benchmark datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002409",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Knowledge graph",
      "Path (computing)",
      "Programming language",
      "Question answering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Ma",
        "given_name": "Ting"
      },
      {
        "surname": "Lv",
        "given_name": "Shangwen"
      },
      {
        "surname": "Huang",
        "given_name": "Longtao"
      },
      {
        "surname": "Hu",
        "given_name": "Songlin"
      }
    ]
  },
  {
    "title": "Distributed learning for sketched kernel regression",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.020",
    "abstract": "We study distributed learning for regularized least squares regression in a reproducing kernel Hilbert space (RKHS). The divide-and-conquer strategy is a frequently used approach for dealing with very large data sets, which computes an estimate on each subset and then takes an average of the estimators. Existing theoretical constraint on the number of subsets implies the size of each subset can still be large. Random sketching can thus be used to produce the local estimators on each subset to further reduce the computation compared to vanilla divide-and-conquer. In this setting, sketching and divide-and-conquer are complementary to each other in dealing with the large sample size. We show that optimal learning rates can be retained. Simulations are performed to compare sketched and non-standard divide-and-conquer methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002525",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computation",
      "Computer science",
      "Constraint (computer-aided design)",
      "Discrete mathematics",
      "Divide and conquer algorithms",
      "Estimator",
      "Geometry",
      "Hilbert space",
      "Kernel (algebra)",
      "Kernel method",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Reproducing kernel Hilbert space",
      "Statistics",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Lian",
        "given_name": "Heng"
      },
      {
        "surname": "Liu",
        "given_name": "Jiamin"
      },
      {
        "surname": "Fan",
        "given_name": "Zengyan"
      }
    ]
  },
  {
    "title": "A distributed optimisation framework combining natural gradient with Hessian-free for discriminative sequence training",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.011",
    "abstract": "This paper presents a novel natural gradient and Hessian-free (NGHF) optimisation framework for neural network training that can operate efficiently in a distributed manner. It relies on the linear conjugate gradient (CG) algorithm to combine the natural gradient (NG) method with local curvature information from Hessian-free (HF). A solution to a numerical issue in CG allows effective parameter updates to be generated with far fewer CG iterations than usually used (e.g. 5-8 instead of 200). This work also presents a novel preconditioning approach to improve the progress made by individual CG iterations for models with shared parameters. Although applicable to other training losses and model structures, NGHF is investigated in this paper for lattice-based discriminative sequence training for hybrid hidden Markov model acoustic models using a standard recurrent neural network, long short-term memory, and time delay neural network models for output probability calculation. Automatic speech recognition experiments are reported on the multi-genre broadcast data set for a range of different acoustic model types. These experiments show that NGHF achieves larger word error rate reductions than standard stochastic gradient descent or Adam, while requiring orders of magnitude fewer parameter updates.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002033",
    "keywords": [],
    "authors": [
      {
        "surname": "Haider",
        "given_name": "Adnan"
      },
      {
        "surname": "Zhang",
        "given_name": "Chao"
      },
      {
        "surname": "Kreyssig",
        "given_name": "Florian L."
      },
      {
        "surname": "Woodland",
        "given_name": "Philip C."
      }
    ]
  },
  {
    "title": "IGAGCN: Information geometry and attention-based spatiotemporal graph convolutional networks for traffic flow prediction",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.035",
    "abstract": "In this study, a novel spatiotemporal graph convolutional networks model is proposed for traffic flow prediction in urban road networks by fully considering an information geometry approach and attention-based mechanism. Accurate traffic flow prediction in real urban road networks is challenging due to the presence of dynamic spatiotemporal data and external factors in the urban environment. Moreover, the dynamic spatial and temporal dependencies of urban traffic flow data are very important for predicting traffic flow, and it has been shown that a recent attention mechanism has a relatively good ability to capture these dynamic dependencies, which are not fully considered by most existing algorithms. Therefore, in the novel model abbreviated as IGAGCN, the information geometry method is utilized to determine the dynamic data distribution difference between different sensors. The attention mechanism is employed with the information geometry method, in which a matrix is derived by analyzing the distributions of sensor data, and the spatiotemporal dynamic connections in traffic flow data features are better at capturing the spatial dependencies of traffic between different sensors in urban road networks. Furthermore, a parallel sub-model architecture is proposed to consider long time spans, where each dilated causal convolution sub-model is applied to short time spans. Two well-known data sets were employed to demonstrate that our proposed method obtains better performance and is better at capturing the dynamic spatial dependencies of traffic than the existing only-attention-based models. In addition a real-world urban road network in Shenzhen, China, was studied to test and verify the proposed model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002318",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Data mining",
      "Dynamic data",
      "Graph",
      "Programming language",
      "Theoretical computer science",
      "Traffic flow (computer networking)"
    ],
    "authors": [
      {
        "surname": "An",
        "given_name": "Jiyao"
      },
      {
        "surname": "Guo",
        "given_name": "Liang"
      },
      {
        "surname": "Liu",
        "given_name": "Wei"
      },
      {
        "surname": "Fu",
        "given_name": "Zhiqiang"
      },
      {
        "surname": "Ren",
        "given_name": "Ping"
      },
      {
        "surname": "Liu",
        "given_name": "Xinzhi"
      },
      {
        "surname": "Li",
        "given_name": "Tao"
      }
    ]
  },
  {
    "title": "Content-aware convolutional neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.030",
    "abstract": "Convolutional Neural Networks (CNNs) have achieved great success due to the powerful feature learning ability of convolution layers. Specifically, the standard convolution traverses the input images/features using a sliding window scheme to extract features. However, not all the windows contribute equally to the prediction results of CNNs. In practice, the convolutional operation on some of the windows (e.g., smooth windows that contain very similar pixels) can be very redundant and may introduce noises into the computation. Such redundancy may not only deteriorate the performance but also incur the unnecessary computational cost. Thus, it is important to reduce the computational redundancy of convolution to improve the performance. To this end, we propose a Content-aware Convolution (CAC) that automatically detects the smooth windows and applies a 1 ×1 convolutional kernel to replace the original large kernel. In this sense, we are able to effectively avoid the redundant computation on similar pixels. By replacing the standard convolution in CNNs with our CAC, the resultant models yield significantly better performance and lower computational cost than the baseline models with the standard convolution. More critically, we are able to dynamically allocate suitable computation resources according to the data smoothness of different images, making it possible for content-aware computation. Extensive experiments on various computer vision tasks demonstrate the superiority of our method over existing methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002628",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computation",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Functional programming",
      "Kernel (algebra)",
      "Lazy evaluation",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Pixel",
      "Redundancy (engineering)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Yong"
      },
      {
        "surname": "Chen",
        "given_name": "Yaofo"
      },
      {
        "surname": "Tan",
        "given_name": "Mingkui"
      },
      {
        "surname": "Jia",
        "given_name": "Kui"
      },
      {
        "surname": "Chen",
        "given_name": "Jian"
      },
      {
        "surname": "Wang",
        "given_name": "Jingdong"
      }
    ]
  },
  {
    "title": "How to handle noisy labels for robust learning from uncertainty",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.012",
    "abstract": "Most deep neural networks (DNNs) are trained with large amounts of noisy labels when they are applied. As DNNs have the high capacity to fit any noisy labels, it is known to be difficult to train DNNs robustly with noisy labels. These noisy labels cause the performance degradation of DNNs due to the memorization effect by over-fitting. Earlier state-of-the-art methods used small loss tricks to efficiently resolve the robust training problem with noisy labels. In this paper, relationship between the uncertainties and the clean labels is analyzed. We present novel training method to use not only small loss trick but also labels that are likely to be clean labels selected from uncertainty called “Uncertain Aware Co-Training (UACT)”. Our robust learning techniques (UACT) avoid over-fitting the DNNs by extremely noisy labels. By making better use of the uncertainty acquired from the network itself, we achieve good generalization performance. We compare the proposed method to the current state-of-the-art algorithms for noisy versions of MNIST, CIFAR-10, CIFAR-100, T-ImageNet and News to demonstrate its excellence.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002446",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Machine learning"
    ],
    "authors": [
      {
        "surname": "Ji",
        "given_name": "Daehyun"
      },
      {
        "surname": "Oh",
        "given_name": "Dokwan"
      },
      {
        "surname": "Hyun",
        "given_name": "Yoonsuk"
      },
      {
        "surname": "Kwon",
        "given_name": "Oh-Min"
      },
      {
        "surname": "Park",
        "given_name": "Myeong-Jin"
      }
    ]
  },
  {
    "title": "Augmented semantic feature based generative network for generalized zero-shot learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.014",
    "abstract": "Zero-shot learning (ZSL) aims to recognize objects in images when no training data is available for the object classes. Under generalized zero-shot learning (GZSL) setting, the test objects belong to seen or unseen categories. In many recent studies, zero-shot learning is performed by leveraging generative networks to synthesize visual features for unseen class from class-specific semantic features. The user-defined semantic information is incomplete and lack of discriminability. However, most generative methods use user-defined semantic information directly as constraints of the generative model, which makes the visual features synthesized by the models lack of diversity and separability. In this paper, we propose a novel method to improve the semantic feature by utilizing discriminative visual features. Furthermore, a novel Augmented Semantic Feature Based Generative Network (ASFGN) is built to synthesize the separable visual representations for unseen classes. Since GAN-based generative model may suffer from mode collapse, we propose a novel collapse-alleviate loss to improve the training stability and generalization performance of our generative network. Extensive experiments on four benchmark datasets prove that our method outperforms the state-of-art approaches in both ZSL and GZSL settings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001519",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Class (philosophy)",
      "Computer science",
      "Discriminative model",
      "Feature (linguistics)",
      "Generalization",
      "Generative grammar",
      "Generative model",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Semantic feature"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Zhiqun"
      },
      {
        "surname": "Chen",
        "given_name": "Qiong"
      },
      {
        "surname": "Liu",
        "given_name": "Qingfa"
      }
    ]
  },
  {
    "title": "Equivalent-input-disturbance estimator-based event-triggered control design for master–slave neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.023",
    "abstract": "This paper investigates the robust synchronization problem for a class of master–slave neural networks (MSNNs) subject to network-induced delays, unknown time-varying uncertainty, and exogenous disturbances. An equivalent-input-disturbance (EID) estimation technique is applied to compensate for the effects of unknown uncertainty and disturbances in the system output. In addition, to reduce the burden of the communication channel in the addressed MSNNs and improve the utilization of bandwidth an event-triggered control protocol is developed to obtain the synchronization of MSNNs. In particular, event-triggering conditions are verified periodically at every sampling instant in both sensors and actuators to avoid the Zeno behavior in the networks. By designing an appropriate low-pass filter in the EID estimator block, the accuracy of disturbance estimation performance is improved. Moreover, by concatenating the synchronization error, observer, and filter states as a single state vector, an augmented system is formulated. Then the tangible delay-dependent stability condition for that augmented system is established by employing the Lyapunov stability theory and reciprocally convex approach. Based on the feasible solutions of the derived stability conditions, the event-triggering parameters, controller, and observer gains are co-designed. Finally, two toy examples are given to illustrate the established theoretical findings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002550",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Estimator",
      "Filter (signal processing)",
      "Lyapunov stability",
      "Mathematics",
      "Observer (physics)",
      "Physics",
      "Quantum mechanics",
      "Statistics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Selvaraj",
        "given_name": "P."
      },
      {
        "surname": "Kwon",
        "given_name": "O.M."
      },
      {
        "surname": "Lee",
        "given_name": "S.H."
      },
      {
        "surname": "Sakthivel",
        "given_name": "R."
      }
    ]
  },
  {
    "title": "Fast mesh data augmentation via Chebyshev polynomial of spectral filtering",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.025",
    "abstract": "Deep neural networks have recently been recognized as one of the powerful learning techniques in computer vision and medical image analysis. Trained deep neural networks need to be generalizable to new data that are not seen before. In practice, there is often insufficient training data available, which can be solved via data augmentation. Nevertheless, there is a lack of augmentation methods to generate data on graphs or surfaces, even though graph convolutional neural network (graph-CNN) has been widely used in deep learning. This study proposed two unbiased augmentation methods, Laplace–Beltrami eigenfunction Data Augmentation (LB-eigDA) and Chebyshev polynomial Data Augmentation (C-pDA), to generate new data on surfaces, whose mean was the same as that of observed data. LB-eigDA augmented data via the resampling of the LB coefficients. In parallel with LB-eigDA, we introduced a fast augmentation approach, C-pDA, that employed a polynomial approximation of LB spectral filters on surfaces. We designed LB spectral bandpass filters by Chebyshev polynomial approximation and resampled signals filtered via these filters in order to generate new data on surfaces. We first validated LB-eigDA and C-pDA via simulated data and demonstrated their use for improving classification accuracy. We then employed brain images of the Alzheimer’s Disease Neuroimaging Initiative (ADNI) and extracted cortical thickness that was represented on the cortical surface to illustrate the use of the two augmentation methods. We demonstrated that augmented cortical thickness had a similar pattern to observed data. We also showed that C-pDA was faster than LB-eigDA and can improve the AD classification accuracy of graph-CNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002215",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Chebyshev filter",
      "Chebyshev polynomials",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Graph",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Polynomial",
      "Resampling",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Shih-Gu"
      },
      {
        "surname": "Chung",
        "given_name": "Moo K."
      },
      {
        "surname": "Qiu",
        "given_name": "Anqi"
      }
    ]
  },
  {
    "title": "Convolutional fusion network for monaural speech enhancement",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.017",
    "abstract": "Convolutional neural network (CNN) based methods, such as the convolutional encoder–decoder network, offer state-of-the-art results in monaural speech enhancement. In the conventional encoder–decoder network, large kernel size is often used to enhance the model capacity, which, however, results in low parameter efficiency. This could be addressed by using group convolution, as in AlexNet, where group convolutions are performed in parallel in each layer, before their outputs are concatenated. However, with the simple concatenation, the inter-channel dependency information may be lost. To address this, the Shuffle network re-arranges the outputs of each group before concatenating them, by taking part of the whole input sequence as the input to each group of convolution. In this work, we propose a new convolutional fusion network (CFN) for monaural speech enhancement by improving model performance, inter-channel dependency, information reuse and parameter efficiency. First, a new group convolutional fusion unit (GCFU) consisting of the standard and depth-wise separable CNN is used to reconstruct the signal. Second, the whole input sequence (full information) is fed simultaneously to two convolution networks in parallel, and their outputs are re-arranged (shuffled) and then concatenated, in order to exploit the inter-channel dependency within the network. Third, the intra skip connection mechanism is used to connect different layers inside the encoder as well as decoder to further improve the model performance. Extensive experiments are performed to show the improved performance of the proposed method as compared with three recent baseline methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002136",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Concatenation (mathematics)",
      "Convolution (computer science)",
      "Convolutional code",
      "Convolutional neural network",
      "Decoding methods",
      "Dependency (UML)",
      "Encoder",
      "Kernel (algebra)",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Xian",
        "given_name": "Yang"
      },
      {
        "surname": "Sun",
        "given_name": "Yang"
      },
      {
        "surname": "Wang",
        "given_name": "Wenwu"
      },
      {
        "surname": "Naqvi",
        "given_name": "Syed Mohsen"
      }
    ]
  },
  {
    "title": "Synchronization of recurrent neural networks with unbounded delays and time-varying coefficients via generalized differential inequalities",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.022",
    "abstract": "In this paper, we revisit the drive-response synchronization of a class of recurrent neural networks with unbounded delays and time-varying coefficients, contrary to usual in the literature about time-varying neural networks, the signs of self-feedback coefficients are permitted to be indefinite or the time-varying coefficients can be unbounded. A generalized scalar delay differential inequality considering indefinite self-feedback coefficient and unbounded delay simultaneously is established, which covers the existing result with bounded delay, the applicabilities of the sufficient conditions are discussed. Some novel criteria for network synchronization are then derived by constructing different candidate functions. These results have been improved in some aspects compared with the existing ones. Differential inequality in vector form is also derived to obtain a more refined synchronization criterion which removes some strong assumptions. Three examples are presented to verify the effectiveness and show the superiorities of our theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002185",
    "keywords": [
      "Aerospace engineering",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Delay differential equation",
      "Differential (mechanical device)",
      "Differential equation",
      "Engineering",
      "Geometry",
      "Mathematical analysis",
      "Mathematics",
      "Scalar (mathematics)",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Hao"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "Levenberg–Marquardt multi-classification using hinge loss function",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.010",
    "abstract": "Incorporating higher-order optimization functions, such as Levenberg–Marquardt (LM) have revealed better generalizable solutions for deep learning problems. However, these higher-order optimization functions suffer from very large processing time and training complexity especially as training datasets become large, such as in multi-view classification problems, where finding global optima is a very costly problem. To solve this issue, we develop a solution for LM-enabled classification with, to the best of knowledge first-time implementation of hinge loss, for multiview classification. Hinge loss allows the neural network to converge faster and perform better than other loss functions such as logistic or square loss rates. We prove our method by experimenting with various multiclass classification challenges of varying complexity and training data size. The empirical results show the training time and accuracy rates achieved, highlighting how our method outperforms in all cases, especially when training time is limited. Our paper presents important results in the relationship between optimization and loss functions and how these can impact deep learning problems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002732",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Deep learning",
      "Evolutionary biology",
      "Function (biology)",
      "Hinge loss",
      "Levenberg–Marquardt algorithm",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Pattern recognition (psychology)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Ozyildirim",
        "given_name": "Buse Melis"
      },
      {
        "surname": "Kiran",
        "given_name": "Mariam"
      }
    ]
  },
  {
    "title": "Neural adaptive fault-tolerant finite-time control for nonstrict feedback systems: An event-triggered mechanism",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.019",
    "abstract": "The problem of event-triggered neural adaptive fault-tolerant finite-time control is investigated for a class of nonstrict feedback nonlinear systems in the presence of nonaffine nonlinear faults. The event-triggered signal is designed by using a relative-threshold to reduce communication burden. The dynamic surface control method is used to relax the assumption of the reference signal and deal with the computational complexity issue. Based on the finite-time stability, a new neural adaptive backstepping design method is developed. The event-triggered neural adaptive fault-tolerant control law is developed for the closed-loop system so that not only the semi-global practical finite-time stability is ensured, but also the tracking performance with a small residual set is guaranteed. Finally, the effectiveness of the proposed control law is verified via simulation results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002513",
    "keywords": [
      "Adaptive control",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backstepping",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Distributed computing",
      "Fault (geology)",
      "Fault tolerance",
      "Geology",
      "Nonlinear system",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Residual",
      "SIGNAL (programming language)",
      "Seismology",
      "Tracking error"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "K."
      },
      {
        "surname": "Qiu",
        "given_name": "J."
      },
      {
        "surname": "Karimi",
        "given_name": "H.R."
      }
    ]
  },
  {
    "title": "Learning to recognize while learning to speak: Self-supervision and developing a speaking motor",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.006",
    "abstract": "Traditionally, learning speech synthesis and speech recognition were investigated as two separate tasks. This separation hinders incremental development for concurrent synthesis and recognition, where partially-learned synthesis and partially-learned recognition must help each other throughout lifelong learning. This work is a paradigm shift—we treat synthesis and recognition as two intertwined aspects of a lifelong learning agent. Furthermore, in contrast to existing recognition or synthesis systems, babies do not need their mothers to directly supervise their vocal tracts at every moment during the learning. We argue that self-generated non-symbolic states/actions at fine-grained time level help such a learner as necessary temporal contexts. Here, we approach a new and challenging problem—how to enable an autonomous learning system to develop an artificial speaking motor for generating temporally-dense (e.g., frame-wise) actions on the fly without human handcrafting a set of symbolic states. The self-generated states/actions are Muscles-like, High-dimensional, Temporally-dense and Globally-smooth (MHTG), so that these states/actions are directly attended for concurrent synthesis and recognition for each time frame. Human teachers are relieved from supervising learner’s motor ends. The Candid Covariance-free Incremental (CCI) Principal Component Analysis (PCA) is applied to develop such an artificial speaking motor where PCA features drive the motor. Since each life must develop normally, each Developmental Network-2 (DN-2) reaches the same network (maximum likelihood, ML) regardless of randomly initialized weights, where ML is not just for a function approximator but rather an emergent Turing Machine. The machine-synthesized sounds are evaluated by both the neural network and humans with recognition experiments. Our experimental results showed learning-to-synthesize and learning-to-recognize-through-synthesis for phonemes. This work corresponds to a key step toward our goal to close a great gap toward fully autonomous machine learning directly from the physical world.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001982",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Frame (networking)",
      "Lifelong learning",
      "Machine learning",
      "Motor learning",
      "Neuroscience",
      "Pedagogy",
      "Programming language",
      "Psychology",
      "Reinforcement learning",
      "Set (abstract data type)",
      "Speech recognition",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Xiang"
      },
      {
        "surname": "Weng",
        "given_name": "Juyang"
      }
    ]
  },
  {
    "title": "On the effective initialisation for restricted Boltzmann machines via duality with Hopfield model",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.017",
    "abstract": "Restricted Boltzmann machines (RBMs) with a binary visible layer of size N and a Gaussian hidden layer of size P have been proved to be equivalent to a Hopfield neural network (HNN) made of N binary neurons and storing P patterns ξ , as long as the weights w in the former are identified with the patterns. Here we aim to leverage this equivalence to find effective initialisations for weights in the RBM when what is available is a set of noisy examples of each pattern, aiming to translate statistical mechanics background available for HNN to the study of RBM’s learning and retrieval abilities. In particular, given a set of definite, structureless patterns we build a sample of blurred examples and prove that the initialisation where w corresponds to the empirical average ξ ¯ over the sample is a fixed point under stochastic gradient descent. Further, as a toy application of the duality between HNN and RBM, we consider the simplest random auto-encoder (a three layer network made of two RBMs coupled by their hidden layer) and evidence that, as long as the parameter setting corresponds to the retrieval region of the dual HNN, reconstruction and denoising can be accomplished trivially, while when the system is in the spin-glass phase inference algorithms are necessary. This questions the need for larger retrieval regions which we obtain by applying a Gram–Schmidt orthogonalisation to the patterns: in fact, this procedure yields to a set of patterns devoid of correlations and for which the largest retrieval region can be accomplished. Finally we consider an application of duality also in a structured case: we test this approach on the MNIST dataset, and obtain that the network performs already ∼ 67 % of successful classifications, suggesting it can be exploited as a computationally-cheap pre-training.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002495",
    "keywords": [
      "Algorithm",
      "Arithmetic",
      "Artificial intelligence",
      "Artificial neural network",
      "Binary number",
      "Boltzmann machine",
      "Computer science",
      "Discrete mathematics",
      "Equivalence (formal languages)",
      "Gradient descent",
      "Hopfield network",
      "Inference",
      "Leverage (statistics)",
      "Mathematics",
      "Programming language",
      "Restricted Boltzmann machine",
      "Set (abstract data type)",
      "Stochastic gradient descent"
    ],
    "authors": [
      {
        "surname": "Leonelli",
        "given_name": "Francesca Elisa"
      },
      {
        "surname": "Agliari",
        "given_name": "Elena"
      },
      {
        "surname": "Albanese",
        "given_name": "Linda"
      },
      {
        "surname": "Barra",
        "given_name": "Adriano"
      }
    ]
  },
  {
    "title": "CommPOOL: An interpretable graph pooling framework for hierarchical graph representation learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.028",
    "abstract": "Recent years have witnessed the emergence and flourishing of hierarchical graph pooling neural networks (HGPNNs) which are effective graph representation learning approaches for graph level tasks such as graph classification. However, current HGPNNs do not take full advantage of the graph’s intrinsic structures (e.g., community structure). Moreover, the pooling operations in existing HGPNNs are difficult to be interpreted. In this paper, we propose a new interpretable graph pooling framework — CommPOOL, that can capture and preserve the hierarchical community structure of graphs in the graph representation learning process. Specifically, the proposed community pooling mechanism in CommPOOL utilizes an unsupervised approach for capturing the inherent community structure of graphs in an interpretable manner. CommPOOL is a general and flexible framework for hierarchical graph representation learning that can further facilitate various graph-level tasks. Evaluations on five public benchmark datasets and one synthetic dataset demonstrate the superior performance of CommPOOL in graph representation learning for graph classification compared to the state-of-the-art baseline methods, and its effectiveness in capturing and preserving the community structure of graphs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002999",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Feature learning",
      "Graph",
      "Machine learning",
      "Pooling",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Haoteng"
      },
      {
        "surname": "Ma",
        "given_name": "Guixiang"
      },
      {
        "surname": "He",
        "given_name": "Lifang"
      },
      {
        "surname": "Huang",
        "given_name": "Heng"
      },
      {
        "surname": "Zhan",
        "given_name": "Liang"
      }
    ]
  },
  {
    "title": "A theory of capacity and sparse neural encoding",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.005",
    "abstract": "Motivated by biological considerations, we study sparse neural maps from an input layer to a target layer with sparse activity, and specifically the problem of storing K input-target associations ( x , y ) , or memories, when the target vectors y are sparse. We mathematically prove that K undergoes a phase transition and that in general, and somewhat paradoxically, sparsity in the target layers increases the storage capacity of the map. The target vectors can be chosen arbitrarily, including in random fashion, and the memories can be both encoded and decoded by networks trained using local learning rules, including the simple Hebb rule. These results are robust under a variety of statistical assumptions on the data. The proofs rely on elegant properties of random polytopes and sub-gaussian random vector variables. Open problems and connections to capacity theories and polynomial threshold maps are discussed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001970",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Discrete mathematics",
      "Encoding (memory)",
      "Epistemology",
      "Gaussian",
      "Geometry",
      "Layer (electronics)",
      "Mathematical proof",
      "Mathematics",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Polytope",
      "Quantum mechanics",
      "Simple (philosophy)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Baldi",
        "given_name": "Pierre"
      },
      {
        "surname": "Vershynin",
        "given_name": "Roman"
      }
    ]
  },
  {
    "title": "On the approximation of functions by tanh neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.08.015",
    "abstract": "We derive bounds on the error, in high-order Sobolev norms, incurred in the approximation of Sobolev-regular as well as analytic functions by neural networks with the hyperbolic tangent activation function. These bounds provide explicit estimates on the approximation error with respect to the size of the neural networks. We show that tanh neural networks with only two hidden layers suffice to approximate functions at comparable or better rates than much deeper ReLU neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003208",
    "keywords": [],
    "authors": [
      {
        "surname": "De Ryck",
        "given_name": "Tim"
      },
      {
        "surname": "Lanthaler",
        "given_name": "Samuel"
      },
      {
        "surname": "Mishra",
        "given_name": "Siddhartha"
      }
    ]
  },
  {
    "title": "Equivalent-input-disturbance estimator-based event-triggered control design for master–slave neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.023",
    "abstract": "This paper investigates the robust synchronization problem for a class of master–slave neural networks (MSNNs) subject to network-induced delays, unknown time-varying uncertainty, and exogenous disturbances. An equivalent-input-disturbance (EID) estimation technique is applied to compensate for the effects of unknown uncertainty and disturbances in the system output. In addition, to reduce the burden of the communication channel in the addressed MSNNs and improve the utilization of bandwidth an event-triggered control protocol is developed to obtain the synchronization of MSNNs. In particular, event-triggering conditions are verified periodically at every sampling instant in both sensors and actuators to avoid the Zeno behavior in the networks. By designing an appropriate low-pass filter in the EID estimator block, the accuracy of disturbance estimation performance is improved. Moreover, by concatenating the synchronization error, observer, and filter states as a single state vector, an augmented system is formulated. Then the tangible delay-dependent stability condition for that augmented system is established by employing the Lyapunov stability theory and reciprocally convex approach. Based on the feasible solutions of the derived stability conditions, the event-triggering parameters, controller, and observer gains are co-designed. Finally, two toy examples are given to illustrate the established theoretical findings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002550",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Estimator",
      "Filter (signal processing)",
      "Lyapunov stability",
      "Mathematics",
      "Observer (physics)",
      "Physics",
      "Quantum mechanics",
      "Statistics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Selvaraj",
        "given_name": "P."
      },
      {
        "surname": "Kwon",
        "given_name": "O.M."
      },
      {
        "surname": "Lee",
        "given_name": "S.H."
      },
      {
        "surname": "Sakthivel",
        "given_name": "R."
      }
    ]
  },
  {
    "title": "Transfer-RLS method and transfer-FORCE learning for simple and fast training of reservoir computing models",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.031",
    "abstract": "Reservoir computing is a machine learning framework derived from a special type of recurrent neural network. Following recent advances in physical reservoir computing, some reservoir computing devices are thought to be promising as energy-efficient machine learning hardware for real-time information processing. To realize efficient online learning with low-power reservoir computing devices, it is beneficial to develop fast convergence learning methods with simpler operations. This study proposes a training method located in the middle between the recursive least squares (RLS) method and the least mean squares (LMS) method, which are standard online learning methods for reservoir computing models. The RLS method converges fast but requires updates of a huge matrix called a gain matrix, whereas the LMS method does not use a gain matrix but converges very slow. On the other hand, the proposed method called a transfer-RLS method does not require updates of the gain matrix in the main-training phase by updating that in advance (i.e., in a pre-training phase). As a result, the transfer-RLS method can work with simpler operations than the original RLS method without sacrificing much convergence speed. We numerically and analytically show that the transfer-RLS method converges much faster than the LMS method. Furthermore, we show that a modified version of the transfer-RLS method (called transfer-FORCE learning) can be applied to the first-order reduced and controlled error (FORCE) learning for a reservoir computing model with a closed-loop, which is challenging to train.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100263X",
    "keywords": [
      "Adaptive filter",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Machine learning",
      "Materials science",
      "Matrix (chemical analysis)",
      "Recurrent neural network",
      "Recursive least squares filter",
      "Reservoir computing",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Tamura",
        "given_name": "Hiroto"
      },
      {
        "surname": "Tanaka",
        "given_name": "Gouhei"
      }
    ]
  },
  {
    "title": "On the characterization of cognitive tasks using activity-specific short-lived synchronization between electroencephalography channels",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.022",
    "abstract": "Accurate characterization of brain activity during a cognitive task is challenging due to the dynamically changing and the complex nature of the brain. The majority of the proposed approaches assume stationarity in brain activity and disregard the systematic timing organization among brain regions during cognitive tasks. In this study, we propose a novel cognitive activity recognition method that captures the activity-specific timing parameters from training data that elicits maximal average short-lived pairwise synchronization between electroencephalography signals. We evaluated the characterization power of the activity-specific timing parameter triplets in a motor imagery activity recognition framework. The activity-specific timing parameter triplets consist of latency of the maximally synchronized signal segments from activity onset Δ t , the time lag between maximally synchronized signal segments τ , and the duration of the maximally synchronized signal segments w . We used cosine-based similarity, wavelet bi-coherence, phase-locking value, phase coherence value, linearized mutual information, and cross-correntropy to calculate the channel synchronizations at the specific timing parameters. Recognition performances as well as statistical analyses on both BCI Competition-III dataset IVa and PhysioNet Motor Movement/Imagery dataset, indicate that the inter-channel short-lived synchronization calculated using activity-specific timing parameter triplets elicit significantly distinct synchronization profiles for different motor imagery tasks and can thus reliably be used for cognitive task recognition purposes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002549",
    "keywords": [
      "Artificial intelligence",
      "Brain activity and meditation",
      "Brain–computer interface",
      "Channel (broadcasting)",
      "Cognition",
      "Coherence (philosophical gambling strategy)",
      "Computer network",
      "Computer science",
      "Economics",
      "Electroencephalography",
      "Elementary cognitive task",
      "Management",
      "Mathematics",
      "Motor imagery",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Phase synchronization",
      "Psychology",
      "Speech recognition",
      "Statistics",
      "Synchronization (alternating current)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Orkan Olcay",
        "given_name": "B."
      },
      {
        "surname": "Özgören",
        "given_name": "Murat"
      },
      {
        "surname": "Karaçalı",
        "given_name": "Bilge"
      }
    ]
  },
  {
    "title": "Dynamical and static multisynchronization analysis for coupled multistable memristive neural networks with hybrid control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.004",
    "abstract": "This paper investigates the dynamical multisynchronization (DMS) and static multisynchronization (SMS) problems for a class of delayed coupled multistable memristive neural networks (DCMMNNs) via a novel hybrid controller which includes delayed impulsive control and state feedback control. Based on the state–space partition method and the geometrical properties of the activation function, each subnetwork has multiple locally exponential stable equilibrium states. By employing a new Halanay-type inequality and the impulsive control theory, some new linear matrix inequalities (LMIs)-based sufficient conditions are proposed. It is shown that the delayed impulsive control with suitable impulsive interval and allowable time-varying delay can still guarantee the DMS and SMS of DCMMNNs. Finally, a numerical example is presented to illustrate the effectiveness of the hybrid controller.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002677",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Electrical engineering",
      "Engineering",
      "Exponential stability",
      "Mathematics",
      "Memristor",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "State (computer science)",
      "State space",
      "Statistics",
      "Subnetwork"
    ],
    "authors": [
      {
        "surname": "Lv",
        "given_name": "Xiaoxiao"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Rutkowski",
        "given_name": "Leszek"
      }
    ]
  },
  {
    "title": "A computational model of familiarity detection for natural pictures, abstract images, and random patterns: Combination of deep learning and anti-Hebbian training",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.022",
    "abstract": "We present a neural network model for familiarity recognition of different types of images in the perirhinal cortex (the FaRe model). The model is designed as a two-stage system. At the first stage, the parameters of an image are extracted by a pretrained deep learning convolutional neural network. At the second stage, a two-layer feed forward neural network with anti-Hebbian learning is used to make the decision about the familiarity of the image. FaRe model simulations demonstrate high capacity of familiarity recognition memory for natural pictures and low capacity for both abstract images and random patterns. These findings are in agreement with psychological experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002859",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Cognition",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Generalization error",
      "Hebbian theory",
      "Image (mathematics)",
      "Layer (electronics)",
      "Leabra",
      "Machine learning",
      "Neuroscience",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Perirhinal cortex",
      "Psychology",
      "Recognition memory",
      "Wake-sleep algorithm"
    ],
    "authors": [
      {
        "surname": "Kazanovich",
        "given_name": "Yakov"
      },
      {
        "surname": "Borisyuk",
        "given_name": "Roman"
      }
    ]
  },
  {
    "title": "Neural optimal tracking control of constrained nonaffine systems with a wastewater treatment application",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.027",
    "abstract": "In this paper, we aim to solve the optimal tracking control problem for a class of nonaffine discrete-time systems with actuator saturation. First, a data-based neural identifier is constructed to learn the unknown system dynamics. Then, according to the expression of the trained neural identifier, we can obtain the steady control corresponding to the reference trajectory. Next, by involving the iterative dual heuristic dynamic programming algorithm, the new costate function and the tracking control law are developed. Two other neural networks are used to estimate the costate function and approximate the tracking control law. Considering approximation errors of neural networks, the stability analysis of the proposed algorithm for the specific systems is provided by introducing the Lyapunov approach. Finally, via conducting simulation and comparison, the superiority of the developed optimal tracking method is confirmed. Moreover, the trajectory tracking performance of the wastewater treatment application is also involved for further verifying the proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002239",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Dynamic programming",
      "Heuristic",
      "Identifier",
      "Lyapunov function",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Optimal control",
      "Pedagogy",
      "Physics",
      "Programming language",
      "Psychology",
      "Quantum mechanics",
      "Tracking (education)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Ding"
      },
      {
        "surname": "Zhao",
        "given_name": "Mingming"
      },
      {
        "surname": "Ha",
        "given_name": "Mingming"
      },
      {
        "surname": "Ren",
        "given_name": "Jin"
      }
    ]
  },
  {
    "title": "Quantum neuron with real weights",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.034",
    "abstract": "This paper proposes a new model of a real weights quantum neuron exploiting the so-called quantum parallelism which allows for an exponential speedup of computations. The quantum neurons were trained in a classical–quantum approach, considering the delta rule to update the values of the weights in an image database of three distinct patterns. We performed classical simulations and also executed experiments in an actual small-scale quantum processor. The results of the experiments show that the proposed quantum real neuron model has a good generalisation capacity, demonstrating better accuracy than the traditional binary quantum perceptron model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003051",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biological neuron model",
      "Computation",
      "Computer science",
      "Parallel computing",
      "Physics",
      "Quantum",
      "Quantum algorithm",
      "Quantum computer",
      "Quantum mechanics",
      "Quantum network",
      "Quantum sort",
      "Speedup"
    ],
    "authors": [
      {
        "surname": "Monteiro",
        "given_name": "Cláudio A."
      },
      {
        "surname": "Filho",
        "given_name": "Gustavo I.S."
      },
      {
        "surname": "Costa",
        "given_name": "Matheus Hopper J."
      },
      {
        "surname": "de Paula Neto",
        "given_name": "Fernando M."
      },
      {
        "surname": "de Oliveira",
        "given_name": "Wilson R."
      }
    ]
  },
  {
    "title": "Correlating subword articulation with lip shapes for embedding aware audio-visual speech enhancement",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.003",
    "abstract": "In this paper, we propose a visual embedding approach to improve embedding aware speech enhancement (EASE) by synchronizing visual lip frames at the phone and place of articulation levels. We first extract visual embedding from lip frames using a pre-trained phone or articulation place recognizer for visual-only EASE (VEASE). Next, we extract audio-visual embedding from noisy speech and lip frames in an information intersection manner, utilizing a complementarity of audio and visual features for multi-modal EASE (MEASE). Experiments on the TCD-TIMIT corpus corrupted by simulated additive noises show that our proposed subword based VEASE approach is more effective than conventional embedding at the word level. Moreover, visual embedding at the articulation place level, leveraging upon a high correlation between place of articulation and lip shapes, demonstrates an even better performance than that at the phone level. Finally the experiments establish that the proposed MEASE framework, incorporating both audio and visual embeddings, yields significantly better speech quality and intelligibility than those obtained with the best visual-only and audio-only EASE systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002355",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Consonant",
      "Embedding",
      "Epistemology",
      "Hidden Markov model",
      "Intelligibility (philosophy)",
      "Keyword spotting",
      "Linguistics",
      "Philosophy",
      "Phone",
      "Place of articulation",
      "Speech recognition",
      "TIMIT",
      "Vowel"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Hang"
      },
      {
        "surname": "Du",
        "given_name": "Jun"
      },
      {
        "surname": "Hu",
        "given_name": "Yu"
      },
      {
        "surname": "Dai",
        "given_name": "Li-Rong"
      },
      {
        "surname": "Yin",
        "given_name": "Bao-Cai"
      },
      {
        "surname": "Lee",
        "given_name": "Chin-Hui"
      }
    ]
  },
  {
    "title": "Graph routing between capsules",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.018",
    "abstract": "Routing methods in capsule networks often learn a hierarchical relationship for capsules in successive layers, but the intra-relation between capsules in the same layer is less studied, while this intra-relation is a key factor for the semantic understanding in text data. Therefore, in this paper, we introduce a new capsule network with graph routing to learn both relationships, where capsules in each layer are treated as the nodes of a graph. We investigate strategies to yield adjacency and degree matrix with three different distances from a layer of capsules, and propose the graph routing mechanism between those capsules. We validate our approach on five text classification datasets, and our findings suggest that the approach combining bottom-up routing and top-down attention performs the best. Such an approach demonstrates generalization capability across datasets. Compared to the state-of-the-art routing methods, the improvements in accuracy in the five datasets we used were 0.82, 0.39, 0.07, 1.01, and 0.02, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002501",
    "keywords": [
      "Adjacency list",
      "Adjacency matrix",
      "Algorithm",
      "Artificial intelligence",
      "Computer network",
      "Computer science",
      "Data mining",
      "Generalization",
      "Graph",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Relation (database)",
      "Routing (electronic design automation)",
      "Routing algorithm",
      "Routing protocol",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Yang"
      },
      {
        "surname": "Zhao",
        "given_name": "Wei"
      },
      {
        "surname": "Cambria",
        "given_name": "Erik"
      },
      {
        "surname": "Wang",
        "given_name": "Suhang"
      },
      {
        "surname": "Eger",
        "given_name": "Steffen"
      }
    ]
  },
  {
    "title": "Finite time convergence of pinning synchronization with a single nonlinear controller",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.036",
    "abstract": "In this paper, we discuss distributive synchronization of complex networks in finite time, with a single nonlinear pinning controller. The results apply to heterogeneous dynamic networks, too. Different from many models, which assume the coupling matrix being symmetric (or the connecting graph is undirected), here, the coupling matrix is asymmetric (or the connecting graph is directed).",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100232X",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Complex network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Convergence (economics)",
      "Coupling (piping)",
      "Directed graph",
      "Distributive property",
      "Economic growth",
      "Economics",
      "Eigenvalues and eigenvectors",
      "Engineering",
      "Graph",
      "Graph theory",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear system",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Symmetric matrix",
      "Synchronization (alternating current)",
      "Theoretical computer science",
      "Topology (electrical circuits)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Tianping"
      },
      {
        "surname": "Lu",
        "given_name": "Wenlian"
      },
      {
        "surname": "Liu",
        "given_name": "Xiwei"
      }
    ]
  },
  {
    "title": "Finite time convergence of pinning synchronization with a single nonlinear controller",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.036",
    "abstract": "In this paper, we discuss distributive synchronization of complex networks in finite time, with a single nonlinear pinning controller. The results apply to heterogeneous dynamic networks, too. Different from many models, which assume the coupling matrix being symmetric (or the connecting graph is undirected), here, the coupling matrix is asymmetric (or the connecting graph is directed).",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100232X",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Complex network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Convergence (economics)",
      "Coupling (piping)",
      "Directed graph",
      "Distributive property",
      "Economic growth",
      "Economics",
      "Eigenvalues and eigenvectors",
      "Engineering",
      "Graph",
      "Graph theory",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear system",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Symmetric matrix",
      "Synchronization (alternating current)",
      "Theoretical computer science",
      "Topology (electrical circuits)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Tianping"
      },
      {
        "surname": "Lu",
        "given_name": "Wenlian"
      },
      {
        "surname": "Liu",
        "given_name": "Xiwei"
      }
    ]
  },
  {
    "title": "A continuous-time neurodynamic approach and its discretization for distributed convex optimization over multi-agent systems",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.020",
    "abstract": "Distributed optimization problem (DOP) over multi-agent systems, which can be described by minimizing the sum of agents’ local objective functions, has recently attracted widespread attention owing to its applications in diverse domains. In this paper, inspired by penalty method and subgradient descent method, a continuous-time neurodynamic approach is proposed for solving a DOP with inequality and set constraints. The state of continuous-time neurodynamic approach exists globally and converges to an optimal solution of the considered DOP. Comparisons reveal that the proposed neurodynamic approach can not only resolve more general convex DOPs, but also has lower dimension of solution space. Additionally, the discretization of the neurodynamic approach is also introduced for the convenience of implementation in practice. The iteration sequence of discrete-time method is also convergent to an optimal solution of DOP from any initial point. The effectiveness of the neurodynamic approach is verified by simulation examples and an application in L 1 -norm minimization problem in the end.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002161",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convex optimization",
      "Discretization",
      "Geometry",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Multi-agent system",
      "Regular polygon"
    ],
    "authors": [
      {
        "surname": "Wen",
        "given_name": "Xingnan"
      },
      {
        "surname": "Luan",
        "given_name": "Linhua"
      },
      {
        "surname": "Qin",
        "given_name": "Sitian"
      }
    ]
  },
  {
    "title": "Task-relevant and task-irrelevant variability causally shape error-based motor learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.015",
    "abstract": "Recent studies of motor learning show dissociable roles of reward- and sensory-prediction errors in updating motor commands by using typical adaptation paradigms where force or visual perturbations are imposed on hand movements. Such classic adaptation paradigms ignore a problem of redundancy inherently embedded in the motor pathways where the central nervous system has to find a unique solution in the high-dimensional motor command space. Computationally, a possible way of solving such a redundancy problem is exploring and updating motor commands based on the learned knowledge of the structures of both the motor pathways and the tasks. However, the effects of task-irrelevant motor command exploration in structure learning and its effects on reward-based and error-based learning have yet to be examined. Here, we used a redundant motor task where participants manipulated a cursor on a monitor screen with their hand gesture movements and then analyzed single-trial motor learning by fitting models consisting of reward-based and error-based learning contributions. We found that the error-based learning rate positively correlated with both task-relevant and task-irrelevant variability, likely reflecting the effect of motor exploration in structure learning. Further modeling results show that the effects of both task-relevant and task-irrelevant variability are simultaneous, and not mediated by one another. In contrast, the reward-based learning rate correlated with neither task-relevant nor task-irrelevant variability. Thus, although not having a direct influence on the task outcome, exploration in the task-irrelevant space late in training has a significant effect on the learning of a task structure used for error-based learning. This suggests that motor exploration, in both task-relevant and task-irrelevant spaces, has an essential role in error-based motor learning in a redundant motor mechanism.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002781",
    "keywords": [
      "Artificial intelligence",
      "Cognitive psychology",
      "Computer science",
      "Economics",
      "Machine learning",
      "Management",
      "Motor control",
      "Motor learning",
      "Motor skill",
      "Neuroscience",
      "Psychology",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Dal’Bello",
        "given_name": "Lucas Rebelo"
      },
      {
        "surname": "Izawa",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Multistability and associative memory of neural networks with Morita-like activation functions",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.035",
    "abstract": "This paper presents the multistability analysis and associative memory of neural networks (NNs) with Morita-like activation functions. In order to seek larger memory capacity, this paper proposes Morita-like activation functions. In a weakened condition, this paper shows that the NNs with n -neurons have ( 2 m + 1 ) n equilibrium points (Eps) and ( m + 1 ) n of them are locally exponentially stable, where the parameter m depends on the Morita-like activation functions, called Morita parameter. Also the attraction basins are estimated based on the state space partition. Moreover, this paper applies these NNs into associative memories (AMs). Compared with the previous related works, the number of Eps and AM’s memory capacity are extensively increased. The simulation results are illustrated and some reliable associative memories examples are shown at the end of this paper.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001726",
    "keywords": [
      "Activation function",
      "Artificial intelligence",
      "Artificial neural network",
      "Associative property",
      "Bidirectional associative memory",
      "Combinatorics",
      "Computer science",
      "Content-addressable memory",
      "Mathematics",
      "Morita therapy",
      "Multistability",
      "Nonlinear system",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Yuanchu"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      },
      {
        "surname": "Liu",
        "given_name": "Xiaoyang"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Spectral embedding network for attributed graph clustering",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.026",
    "abstract": "Attributed graph clustering aims to discover node groups by utilizing both graph structure and node features. Recent studies mostly adopt graph neural networks to learn node embeddings, then apply traditional clustering methods to obtain clusters. However, they usually suffer from the following issues: (1) they adopt original graph structure which is unfavorable for clustering due to its noise and sparsity problems; (2) they mainly utilize non-clustering driven losses that cannot well capture the global cluster structure, thus the learned embeddings are not sufficient for the downstream clustering task. In this paper, we propose a spectral embedding network for attributed graph clustering (SENet), which improves graph structure by leveraging the information of shared neighbors, and learns node embeddings with the help of a spectral clustering loss. By combining the original graph structure and shared neighbor based similarity, both the first-order and second-order proximities are encoded into the improved graph structure, thus alleviating the noise and sparsity issues. To make the spectral loss well adapt to attributed graphs, we integrate both structure and feature information into kernel matrix via a higher-order graph convolution. Experiments on benchmark attributed graphs show that SENet achieves superior performance over state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002227",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Clustering coefficient",
      "Computer science",
      "Embedding",
      "Graph",
      "Graph kernel",
      "Kernel embedding of distributions",
      "Kernel method",
      "Pattern recognition (psychology)",
      "Spectral clustering",
      "Support vector machine",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Xiaotong"
      },
      {
        "surname": "Liu",
        "given_name": "Han"
      },
      {
        "surname": "Wu",
        "given_name": "Xiao-Ming"
      },
      {
        "surname": "Zhang",
        "given_name": "Xianchao"
      },
      {
        "surname": "Liu",
        "given_name": "Xinyue"
      }
    ]
  },
  {
    "title": "Deep attributed graph clustering with self-separation regularization and parameter-free cluster estimation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.012",
    "abstract": "Detecting clusters over attributed graphs is a fundamental task in the graph analysis field. The goal is to partition nodes into dense clusters based on both their attributes and structures. Modern graph neural networks provide facilitation to jointly capture the above information in attributed graphs with a feature aggregation manner, and have achieved great success in attributed graph clustering. However, existing methods mainly focus on capturing the proximity information in graphs and often fail to learn cluster-friendly features during the training of models. Besides, similar to many deep clustering frameworks, current methods based on graph neural networks require a preassigned cluster number before estimating the clusters. To address these limitations, we propose in this paper a deep attributed clustering method based on self-separated graph neural networks and parameter-free cluster estimation. First, to learn cluster-friendly features, we jointly optimize a jumping graph convolutional auto-encoder with a self-separation regularizer, which learns clusters with changing sizes while keeping dense intra-cluster structures and sparse inter structures. Second, an additional softmax auto-encoder is trained to determine the natural cluster number from the data. The hidden units capture cluster structures and can be used to estimate the number of clusters. Extensive experiments show the effectiveness of the proposed model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002756",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster (spacecraft)",
      "Cluster analysis",
      "Clustering coefficient",
      "Computer science",
      "Correlation clustering",
      "Data mining",
      "Deep learning",
      "Graph",
      "Pattern recognition (psychology)",
      "Programming language",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Ji",
        "given_name": "Junzhong"
      },
      {
        "surname": "Liang",
        "given_name": "Ye"
      },
      {
        "surname": "Lei",
        "given_name": "Minglong"
      }
    ]
  },
  {
    "title": "Novel methods to global Mittag-Leffler stability of delayed fractional-order quaternion-valued neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.005",
    "abstract": "In this paper, a type of fractional-order quaternion-valued neural networks (FOQVNNs) with leakage and time-varying delays is established to simulate real-world situations, and the global Mittag-Leffler stability of the system is investigated by using the non-decomposition method. First, to avoid decomposing the system into two complex-valued systems or four real-valued systems, a new sign function for quaternion numbers is introduced based on the ones for real and complex numbers. And two novel lemmas for quaternion-valued sign function and Caputo fractional derivative are established in quaternion domain, which are used to investigate the stability of FOQVNNs. Second, a concise and flexible quaternion-valued state feedback controller is directly designed and a novel 1-norm Lyapunov function composed of the absolute values of real and imaginary parts is established. Then, based on the designed quaternion-valued state feedback controller and the proposed lemmas, some sufficient conditions are given to ensure the global Mittag-Leffler stability of the system. Finally, a numerical simulation is given to verify the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002689",
    "keywords": [
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Fractional calculus",
      "Geometry",
      "Law",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Norm (philosophy)",
      "Physics",
      "Political science",
      "Quantum mechanics",
      "Quaternion",
      "Sign (mathematics)",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Yan",
        "given_name": "Hongyun"
      },
      {
        "surname": "Qiao",
        "given_name": "Yuanhua"
      },
      {
        "surname": "Duan",
        "given_name": "Lijuan"
      },
      {
        "surname": "Miao",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Probabilistic robustness estimates for feed-forward neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.037",
    "abstract": "Robustness of deep neural networks is a critical issue in practical applications. In the general case of feed-forward neural networks (including convolutional deep neural network architectures), under random noise attacks, we propose to study the probability that the output of the network deviates from its nominal value by a given threshold. We derive a simple concentration inequality for the propagation of the input uncertainty through the network using the Cramer–Chernoff method and estimates of the local variation of the neural network mapping computed at the training points. We further discuss and exploit the resulting condition on the network to regularize the loss function during training. Finally, we assess the proposed tail probability estimates empirically on various public datasets and show that the observed robustness is very well estimated by the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100174X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Exploit",
      "Gene",
      "Machine learning",
      "Probabilistic logic",
      "Probabilistic neural network",
      "Robustness (evolution)",
      "Time delay neural network"
    ],
    "authors": [
      {
        "surname": "Couellan",
        "given_name": "Nicolas"
      }
    ]
  },
  {
    "title": "Cluster synchronization of delayed coupled neural networks: Delay-dependent distributed impulsive control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.026",
    "abstract": "This paper investigates the issue of cluster synchronization (CS) for the coupled neural networks (CNNs) with time-varying delays via the delay-dependent distributed impulsive control. A new Halanay-like inequality, where delayed impulses are taken into consideration, is proposed. Based on the Lyapunov theory and the new differential inequality, sufficient conditions of CS for delayed CNNs with fixed and switching coupling topology are obtained, respectively. Moreover, delay-dependent distributed impulsive controllers with fixed or switching topology are designed thereby. Finally, we present a numerical example of CNNs with fixed or switching coupling to verify the effectiveness of our results, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001635",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster (spacecraft)",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Coupling (piping)",
      "Engineering",
      "Lyapunov function",
      "Mathematics",
      "Mechanical engineering",
      "Network topology",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Xiaoyu"
      },
      {
        "surname": "Li",
        "given_name": "Chuandong"
      },
      {
        "surname": "He",
        "given_name": "Zhilong"
      }
    ]
  },
  {
    "title": "Towards a mathematical framework to inform neural network modelling via polynomial regression",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.036",
    "abstract": "Even when neural networks are widely used in a large number of applications, they are still considered as black boxes and present some difficulties for dimensioning or evaluating their prediction error. This has led to an increasing interest in the overlapping area between neural networks and more traditional statistical methods, which can help overcome those problems. In this article, a mathematical framework relating neural networks and polynomial regression is explored by building an explicit expression for the coefficients of a polynomial regression from the weights of a given neural network, using a Taylor expansion approach. This is achieved for single hidden layer neural networks in regression problems. The validity of the proposed method depends on different factors like the distribution of the synaptic potentials or the chosen activation function. The performance of this method is empirically tested via simulation of synthetic data generated from polynomials to train neural networks with different structures and hyperparameters, showing that almost identical predictions can be obtained when certain conditions are met. Lastly, when learning from polynomial generated data, the proposed method produces polynomials that approximate correctly the data locally.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001738",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Hyperparameter",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Polynomial",
      "Polynomial regression",
      "Regression",
      "Regression analysis",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Morala",
        "given_name": "Pablo"
      },
      {
        "surname": "Cifuentes",
        "given_name": "Jenny Alexandra"
      },
      {
        "surname": "Lillo",
        "given_name": "Rosa E."
      },
      {
        "surname": "Ucar",
        "given_name": "Iñaki"
      }
    ]
  },
  {
    "title": "An interaction-modeling mechanism for context-dependent Text-to-SQL translation based on heterogeneous graph aggregation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.014",
    "abstract": "For the context-dependent Text-to-SQL task, the generation of SQL query is placed in a multi-turn interaction scenario. Each turn of Text-to-SQL must take historical interactive information and database schema into account. Accordingly, how to encode and integrate these different types of texts (the question sentence, the corresponding SQL query, and database schema) is a tough problem. In previous work, these series of texts are usually concatenated into sequences and encoded by various variants of recurrent neural networks (RNN). However, the RNNs cannot model the intrinsic relationship of the text directly. To this end, we propose an interaction-modeling mechanism to represent and aggregate these texts. Firstly, different types of texts are represented as individual graphs. Then, heterogeneous graph aggregation is used to capture the interactions and aggregate graphs into a holistic representation. Finally, the corresponding SQL query is generated based on the current question and the aggregated information. We evaluate our model on the SparC and CoSQL dataset to demonstrate the benefits of interaction-modeling. Experimentally, our model has a competitive performance and space–time cost.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100277X",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "ENCODE",
      "Gene",
      "Information retrieval",
      "Natural language processing",
      "Programming language",
      "Query by Example",
      "SQL",
      "Schema (genetic algorithms)",
      "Search engine",
      "Sentence",
      "Theoretical computer science",
      "Web search query"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Wei"
      },
      {
        "surname": "Chang",
        "given_name": "Tao"
      },
      {
        "surname": "Guo",
        "given_name": "Xiaoting"
      },
      {
        "surname": "Wang",
        "given_name": "Mengzhu"
      },
      {
        "surname": "Wang",
        "given_name": "Xiaodong"
      }
    ]
  },
  {
    "title": "Growth strategy determines the memory and structural properties of brain networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.027",
    "abstract": "The interplay between structure and function affects the emerging properties of many natural systems. Here we use an adaptive neural network model that couples activity and topological dynamics and reproduces the experimental temporal profiles of synaptic density observed in the brain. We prove that the existence of a transient period of relatively high synaptic connectivity is critical for the development of the system under noise circumstances, such that the resulting network can recover stored memories. Moreover, we show that intermediate synaptic densities provide optimal developmental paths with minimum energy consumption, and that ultimately it is the transient heterogeneity in the network that determines its evolution. These results could explain why the pruning curves observed in actual brain areas present their characteristic temporal profiles and they also suggest new design strategies to build biologically inspired neural networks with particular information processing capabilities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001647",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biological system",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Discrete mathematics",
      "Hippocampus",
      "Image (mathematics)",
      "Immunology",
      "Inflammation",
      "Mathematics",
      "Memory formation",
      "Microglia",
      "Network dynamics",
      "Neuroscience",
      "Noise (video)",
      "Operating system",
      "Pruning",
      "Psychology",
      "Synaptic pruning",
      "Topology (electrical circuits)",
      "Transient (computer programming)"
    ],
    "authors": [
      {
        "surname": "Millán",
        "given_name": "Ana P."
      },
      {
        "surname": "Torres",
        "given_name": "Joaquín J."
      },
      {
        "surname": "Johnson",
        "given_name": "Samuel"
      },
      {
        "surname": "Marro",
        "given_name": "J."
      }
    ]
  },
  {
    "title": "Novel criteria for global robust stability of dynamical neural networks with multiple time delays",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.039",
    "abstract": "This research article considers the problem regarding global robust asymptotic stability of the general type of dynamical neural networks involving multiple constant time delays. Some new sufficient criteria are proposed for the existence, uniqueness and global asymptotic stability of the equilibrium point of this neural network model whose network parameters possess uncertainties. This paper will first address the existence and uniqueness problem for equilibrium points by utilizing the Homomorphic transformation theory. Secondly, by exploiting a novel Lyapunov functional candidate, the sufficient conditions for asymptotic stability of equilibrium points of this class of delayed neural networks will be established. The derived robust stability conditions are expressed independently of the constant time delay parameters and define some novel relationships among network parameters of the considered neural network. Thus, the applicability and validity of the obtained robust stability conditions for delayed-type neural networks can be easily tested. The comprehensive comparisons among the results of the current article and some of previously derived corresponding results will also be made by giving an illustrative numerical example.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001763",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Constant (computer programming)",
      "Control (management)",
      "Control theory (sociology)",
      "Differential equation",
      "Dynamical systems theory",
      "Equilibrium point",
      "Exponential stability",
      "Gene",
      "Lyapunov function",
      "Lyapunov stability",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Transformation (genetics)",
      "Uniqueness"
    ],
    "authors": [
      {
        "surname": "Arslan",
        "given_name": "Emel"
      }
    ]
  },
  {
    "title": "Streaming cascade-based speech translation leveraged by a direct segmentation model",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.013",
    "abstract": "The cascade approach to Speech Translation (ST) is based on a pipeline that concatenates an Automatic Speech Recognition (ASR) system followed by a Machine Translation (MT) system. Nowadays, state-of-the-art ST systems are populated with deep neural networks that are conceived to work in an offline setup in which the audio input to be translated is fully available in advance. However, a streaming setup defines a completely different picture, in which an unbounded audio input gradually becomes available and at the same time the translation needs to be generated under real-time constraints. In this work, we present a state-of-the-art streaming ST system in which neural-based models integrated in the ASR and MT components are carefully adapted in terms of their training and decoding procedures in order to run under a streaming setup. In addition, a direct segmentation model that adapts the continuous ASR output to the capacity of simultaneous MT systems trained at the sentence level is introduced to guarantee low latency while preserving the translation quality of the complete ST system. The resulting ST system is thoroughly evaluated on the real-life streaming Europarl-ST benchmark to gauge the trade-off between quality and latency for each component individually as well as for the complete ST system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002057",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biochemistry",
      "Cascade",
      "Chemistry",
      "Chromatography",
      "Computer engineering",
      "Computer science",
      "Decoding methods",
      "Gene",
      "Geodesy",
      "Geography",
      "Latency (audio)",
      "Machine translation",
      "Pipeline (software)",
      "Programming language",
      "Robustness (evolution)",
      "Segmentation",
      "Speech recognition",
      "Speech translation",
      "Telecommunications",
      "Throughput",
      "Wireless"
    ],
    "authors": [
      {
        "surname": "Iranzo-Sánchez",
        "given_name": "Javier"
      },
      {
        "surname": "Jorge",
        "given_name": "Javier"
      },
      {
        "surname": "Baquero-Arnal",
        "given_name": "Pau"
      },
      {
        "surname": "Silvestre-Cerdà",
        "given_name": "Joan Albert"
      },
      {
        "surname": "Giménez",
        "given_name": "Adrià"
      },
      {
        "surname": "Civera",
        "given_name": "Jorge"
      },
      {
        "surname": "Sanchis",
        "given_name": "Albert"
      },
      {
        "surname": "Juan",
        "given_name": "Alfons"
      }
    ]
  },
  {
    "title": "Statistical guarantees for regularized neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.034",
    "abstract": "Neural networks have become standard tools in the analysis of data, but they lack comprehensive mathematical theories. For example, there are very few statistical guarantees for learning neural networks from data, especially for classes of estimators that are used in practice or at least similar to such. In this paper, we develop a general statistical guarantee for estimators that consist of a least-squares term and a regularizer. We then exemplify this guarantee with ℓ 1 -regularization, showing that the corresponding prediction error increases at most logarithmically in the total number of parameters and can even decrease in the number of layers. Our results establish a mathematical basis for regularized estimation of neural networks, and they deepen our mathematical understanding of neural networks and deep learning more generally.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001714",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Estimator",
      "Machine learning",
      "Mathematics",
      "Regularization (linguistics)",
      "Statistical analysis",
      "Statistical learning",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Taheri",
        "given_name": "Mahsa"
      },
      {
        "surname": "Xie",
        "given_name": "Fang"
      },
      {
        "surname": "Lederer",
        "given_name": "Johannes"
      }
    ]
  },
  {
    "title": "Flexible multi-view semi-supervised learning with unified graph",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.033",
    "abstract": "At present, the diversity of data acquisition boosts the growth of multi-view data and the lack of label information. Since manually labeling is expensive and impractical, it is practical to enhance learning performance with a small amount of labeled data and a large amount of unlabeled data. In this study, we propose a novel multi-view semi-supervised learning (MSEL) framework termed flexible MSEL (FMSEL) with unified graph. In this framework, two flexible regression residual terms are introduced. One is a linear penalty term, which adaptively weighs the diverse contributions of different views and properly learns a well structured unified graph. The other is a relaxation regularization term, which finds the optimal prediction and the linear regression function. Both the prediction of samples in the database and new-coming data are supported. Moreover, during the process, the unified graph learns depending on the data structure and dynamically updated label information. Further, we provide an alternating optimization algorithm to iteratively solve the resultant objective problem and theoretically analyze the corresponding complexities. Extensive experiments conducted on synthetic and public datasets demonstrate the superiority of FMSEL.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001702",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Graph",
      "Machine learning",
      "Mathematics",
      "Regression",
      "Regularization (linguistics)",
      "Residual",
      "Semi-supervised learning",
      "Statistics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Zhongheng"
      },
      {
        "surname": "Qiang",
        "given_name": "Qianyao"
      },
      {
        "surname": "Zhang",
        "given_name": "Bin"
      },
      {
        "surname": "Wang",
        "given_name": "Fei"
      },
      {
        "surname": "Nie",
        "given_name": "Feiping"
      }
    ]
  },
  {
    "title": "Anti-transfer learning for task invariance in convolutional neural networks for speech processing",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.012",
    "abstract": "We introduce the novel concept of anti-transfer learning for speech processing with convolutional neural networks. While transfer learning assumes that the learning process for a target task will benefit from re-using representations learned for another task, anti-transfer avoids the learning of representations that have been learned for an orthogonal task, i.e., one that is not relevant and potentially confounding for the target task, such as speaker identity for speech recognition or speech content for emotion recognition. This extends the potential use of pre-trained models that have become increasingly available. In anti-transfer learning, we penalize similarity between activations of a network being trained on a target task and another one previously trained on an orthogonal task, which yields more suitable representations. This leads to better generalization and provides a degree of control over correlations that are spurious or undesirable, e.g. to avoid social bias. We have implemented anti-transfer for convolutional neural networks in different configurations with several similarity metrics and aggregation functions, which we evaluate and analyze with several speech and audio tasks and settings, using six datasets. We show that anti-transfer actually leads to the intended invariance to the orthogonal task and to more appropriate features for the target task at hand. Anti-transfer learning consistently improves classification accuracy in all test cases. While anti-transfer creates computation and memory cost at training time, there is relatively little computation cost when using pre-trained models for orthogonal tasks. Anti-transfer is widely applicable and particularly useful where a specific invariance is desirable or where labeled data for orthogonal tasks are difficult to obtain on a given dataset but pre-trained models are available.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002045",
    "keywords": [],
    "authors": [
      {
        "surname": "Guizzo",
        "given_name": "Eric"
      },
      {
        "surname": "Weyde",
        "given_name": "Tillman"
      },
      {
        "surname": "Tarroni",
        "given_name": "Giacomo"
      }
    ]
  },
  {
    "title": "Candidate region aware nested named entity recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.019",
    "abstract": "Named entity recognition (NER) is crucial in various natural language processing (NLP) tasks. However, the nested entities which are common in practical corpus are often ignored in most of current NER models. To extract the nested entities, two categories of models (i.e., feature-based and neural network-based approaches) are proposed. However, the feature-based models suffer from the complicated feature engineering and often heavily rely on the external resources. Discarding the heavy feature engineering, recent neural network-based methods which treat the nested NER as a classification task are designed but still suffer from the heavy class imbalance issue and the high computational cost. To solve these problems, we propose a neural multi-task model with two modules: Binary Sequence Labeling and Candidate Region Classification to extract the nested entities. Extensive experiments are conducted on the public datasets. Comparing with recent neural network-based approaches, our proposed model achieves the better performance and obtains the higher efficiency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000691",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Binary classification",
      "Class (philosophy)",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Economics",
      "Feature (linguistics)",
      "Feature engineering",
      "Linguistics",
      "Machine learning",
      "Management",
      "Named-entity recognition",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Support vector machine",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Deng"
      },
      {
        "surname": "Ren",
        "given_name": "Haopeng"
      },
      {
        "surname": "Cai",
        "given_name": "Yi"
      },
      {
        "surname": "Xu",
        "given_name": "Jingyun"
      },
      {
        "surname": "Liu",
        "given_name": "Yanxia"
      },
      {
        "surname": "Leung",
        "given_name": "Ho-fung"
      }
    ]
  },
  {
    "title": "H-VECTORS: Improving the robustness in utterance-level speaker embeddings using a hierarchical attention model",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.024",
    "abstract": "In this paper, a hierarchical attention network is proposed to generate robust utterance-level embeddings (H-vectors) for speaker identification and verification. Since different parts of an utterance may have different contributions to speaker identities, the use of hierarchical structure aims to learn speaker related information locally and globally. In the proposed approach, frame-level encoder and attention are applied on segments of an input utterance and generate individual segment vectors. Then, segment level attention is applied on the segment vectors to construct an utterance representation. To evaluate the quality of the learned utterance-level speaker embeddings on speaker identification and verification, the proposed approach is tested on several benchmark datasets, such as the NIST SRE2008 Part1, the Switchboard Cellular (Part1), the CallHome American English Speech ,the Voxceleb1 and Voxceleb2 datasets. In comparison with some strong baselines, the obtained results show that the use of H-vectors can achieve better identification and verification performances in various acoustic conditions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002203",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biochemistry",
      "Biology",
      "Botany",
      "Chemistry",
      "Computer science",
      "Gene",
      "Geodesy",
      "Geography",
      "Identification (biology)",
      "Law",
      "NIST",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Robustness (evolution)",
      "Speaker diarisation",
      "Speaker identification",
      "Speaker recognition",
      "Speaker verification",
      "Speech recognition",
      "Utterance"
    ],
    "authors": [
      {
        "surname": "Shi",
        "given_name": "Yanpei"
      },
      {
        "surname": "Huang",
        "given_name": "Qiang"
      },
      {
        "surname": "Hain",
        "given_name": "Thomas"
      }
    ]
  },
  {
    "title": "A CNN model embedded with local feature knowledge and its application to time-varying signal classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.018",
    "abstract": "A novel convolutional neural network is proposed for local prior feature embedding and imbalanced dataset modeling for multi-channel time-varying signal classification. This model consists of a single-channel signal feature parallel extraction unit, a multi-channel signal feature integration unit, a local feature embedding and feature similarity measurement unit, a full connection layer, and a Softmax classifier. An algorithm combining dynamic clustering and sliding window was used to select segments signals with typical local features in each pattern class, forming a typical local feature set. The one-dimensional CNNs were used to extract features from the single-channel signal in parallel, a comprehensive feature matrix of the multi-channel signal and the local feature matrix templates were produced. Using the method of external embedding, based on the sliding window and dynamic time warping (DTW) algorithm, the local feature similarities between the local feature template of each pattern class and the comprehensive feature sub-matrix of the input signal were measured, and the maximum values were selected to construct a local feature similarity vector in order. The information fusion was realized through a full connection layer. The proposed methodology can extract and represent both global and local signals features, strengthen the role of prior local feature in classification and improve the modeling properties of imbalanced datasets. A comprehensive learning algorithm is presented in this paper. The classification diagnosis of cardiovascular disease based on 12-lead ECG signals was used as a verification experiment. Results showed that the accuracy and generalization for the proposed technique were significantly improved.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002811",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Embedding",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature vector",
      "Linguistics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Sliding window protocol",
      "Softmax function",
      "Window (computing)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Ruiping"
      },
      {
        "surname": "Zha",
        "given_name": "Xianyu"
      },
      {
        "surname": "Liu",
        "given_name": "Kun"
      },
      {
        "surname": "Xu",
        "given_name": "Shaohua"
      }
    ]
  },
  {
    "title": "Classification of visuomotor tasks based on electroencephalographic data depends on age-related differences in brain activity patterns",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.029",
    "abstract": "Classification of physiological data provides a data driven approach to study central aspects of motor control, which changes with age. To implement such results in real-life applications for elderly it is important to identify age-specific characteristics of movement classification. We compared task-classification based on EEG derived activity patterns related to brain network characteristics between older and younger adults performing force tracking with two task characteristics (sinusoidal; constant) with the right or left hand. We extracted brain network patterns with dynamic mode decomposition (DMD) and classified the tasks on an individual level using linear discriminant analysis (LDA). Next, we compared the models’ performance between the groups. Studying brain activity patterns, we identified signatures of altered motor network function reflecting dedifferentiated and compensational brain activation in older adults. We found that the classification performance of the body side was lower in older adults. However, classification performance with respect to task characteristics was better in older adults. This may indicate a higher susceptibility of brain network mechanisms to task difficulty in elderly. Signatures of dedifferentiation and compensation refer to an age-related reorganization of functional brain networks, which suggests that classification of visuomotor tracking tasks is influenced by age-specific characteristics of brain activity patterns. In addition to insights into central aspects of fine motor control, the results presented here are relevant in application-oriented areas such as brain computer interfaces.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001660",
    "keywords": [
      "Artificial intelligence",
      "Brain activity and meditation",
      "Computer science",
      "Economics",
      "Electroencephalography",
      "Linear discriminant analysis",
      "Management",
      "Medicine",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Physical medicine and rehabilitation",
      "Psychology",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Goelz",
        "given_name": "C."
      },
      {
        "surname": "Mora",
        "given_name": "K."
      },
      {
        "surname": "Rudisch",
        "given_name": "J."
      },
      {
        "surname": "Gaidai",
        "given_name": "R."
      },
      {
        "surname": "Reuter",
        "given_name": "E."
      },
      {
        "surname": "Godde",
        "given_name": "B."
      },
      {
        "surname": "Reinsberger",
        "given_name": "C."
      },
      {
        "surname": "Voelcker-Rehage",
        "given_name": "C."
      },
      {
        "surname": "Vieluf",
        "given_name": "S."
      }
    ]
  },
  {
    "title": "FastGAE: Scalable graph autoencoders with stochastic subgraph decoding",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.015",
    "abstract": "Graph autoencoders (AE) and variational autoencoders (VAE) are powerful node embedding methods, but suffer from scalability issues. In this paper, we introduce FastGAE, a general framework to scale graph AE and VAE to large graphs with millions of nodes and edges. Our strategy, based on an effective stochastic subgraph decoding scheme, significantly speeds up the training of graph AE and VAE while preserving or even improving performances. We demonstrate the effectiveness of FastGAE on various real-world graphs, outperforming the few existing approaches to scale graph AE and VAE by a wide margin.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001520",
    "keywords": [],
    "authors": [
      {
        "surname": "Salha",
        "given_name": "Guillaume"
      },
      {
        "surname": "Hennequin",
        "given_name": "Romain"
      },
      {
        "surname": "Remy",
        "given_name": "Jean-Baptiste"
      },
      {
        "surname": "Moussallam",
        "given_name": "Manuel"
      },
      {
        "surname": "Vazirgiannis",
        "given_name": "Michalis"
      }
    ]
  },
  {
    "title": "Self-spectral learning with GAN based spectral–spatial target detection for hyperspectral image",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.029",
    "abstract": "To alleviate the shortcomings of target detection in only one aspect and reduce redundant information among adjacent bands, we propose a spectral–spatial target detection (SSTD) framework in deep latent space based on self-spectral learning (SSL) with a spectral generative adversarial network (GAN). The concept of SSL is introduced into hyperspectral feature extraction in an unsupervised fashion with the purpose of background suppression and target saliency. In particular, a novel structure-to-structure selection rule that takes full account of the structure, contrast, and luminance similarity is established to interpret the mapping relationship between the latent spectral feature space and the original spectral band space, to generate the optimal spectral band subset without any prior knowledge. Finally, the comprehensive result is achieved by nonlinearly combining the spatial detection on the fused latent features with the spectral detection on the selected band subset and the corresponding selected target signature. This paper paves a novel self-spectral learning way for hyperspectral target detection and identifies sensitive bands for specific targets in practice. Comparative analyses demonstrate that the proposed SSTD method presents superior detection performance compared with CSCR, ACE, CEM, hCEM, and ECEM.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002252",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Feature (linguistics)",
      "Feature learning",
      "Geology",
      "Hyperspectral imaging",
      "Image (mathematics)",
      "Linguistics",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Remote sensing",
      "Similarity (geometry)",
      "Spectral bands",
      "Spectral signature"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Weiying"
      },
      {
        "surname": "Zhang",
        "given_name": "Jiaqing"
      },
      {
        "surname": "Lei",
        "given_name": "Jie"
      },
      {
        "surname": "Li",
        "given_name": "Yunsong"
      },
      {
        "surname": "Jia",
        "given_name": "Xiuping"
      }
    ]
  },
  {
    "title": "Two-timescale neurodynamic approaches to supervised feature selection based on alternative problem formulations",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.038",
    "abstract": "Feature selection is a crucial step in data processing and machine learning. While many greedy and sequential feature selection approaches are available, a holistic neurodynamics approach to supervised feature selection is recently developed via fractional programming by minimizing feature redundancy and maximizing relevance simultaneously. In view that the gradient of the fractional objective function is also fractional, alternative problem formulations are desirable to obviate the fractional complexity. In this paper, the fractional programming problem formulation is equivalently reformulated as bilevel and bilinear programming problems without using any fractional function. Two two-timescale projection neural networks are adapted for solving the reformulated problems. Experimental results on six benchmark datasets are elaborated to demonstrate the global convergence and high classification performance of the proposed neurodynamic approaches in comparison with six mainstream feature selection approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001751",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Feature (linguistics)",
      "Feature selection",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Operating system",
      "Philosophy",
      "Redundancy (engineering)",
      "Selection (genetic algorithm)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yadi"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Che",
        "given_name": "Hangjun"
      }
    ]
  },
  {
    "title": "Graph embedding clustering: Graph attention auto-encoder with cluster-specificity distribution",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.008",
    "abstract": "Towards exploring the topological structure of data, numerous graph embedding clustering methods have been developed in recent years, none of them takes into account the cluster-specificity distribution of the nodes representations, resulting in suboptimal clustering performance. Moreover, most existing graph embedding clustering methods execute the nodes representations learning and clustering in two separated steps, which increases the instability of its original performance. Additionally, rare of them simultaneously takes node attributes reconstruction and graph structure reconstruction into account, resulting in degrading the capability of graph learning. In this work, we integrate the nodes representations learning and clustering into a unified framework, and propose a new deep graph attention auto-encoder for nodes clustering that attempts to learn more favorable nodes representations by leveraging self-attention mechanism and node attributes reconstruction. Meanwhile, a cluster-specificity distribution constraint, which is measured by ℓ 1 , 2 -norm, is employed to make the nodes representations within the same cluster end up with a common distribution in the dimension space while representations with different clusters have different distributions in the intrinsic dimensions. Extensive experiment results reveal that our proposed method is superior to several state-of-the-art methods in terms of performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002008",
    "keywords": [
      "Artificial intelligence",
      "Cluster (spacecraft)",
      "Cluster analysis",
      "Clustering coefficient",
      "Combinatorics",
      "Computer science",
      "Data mining",
      "Embedding",
      "Graph",
      "Graph embedding",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Programming language",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Huiling"
      },
      {
        "surname": "Xia",
        "given_name": "Wei"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Han",
        "given_name": "Jungong"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Why grid cells function as a metric for space",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.031",
    "abstract": "The brain is able to calculate the distance and direction to the desired position based on grid cells. Extensive neurophysiological studies of rodent navigation have postulated the grid cells function as a metric for space, and have inspired many computational studies to develop innovative navigation approaches. Furthermore, grid cells may provide a general encoding scheme for high-order nonspatial information. Built upon existing neuroscience and machine learning work, this paper provides theoretical clarity on that the grid cell population codes can be taken as a metric for space. The metric is generated by a shift-invariant positive definite kernel via kernel distance method and embeds isometrically in a Euclidean space, and the inner product of the grid cell population code exponentially converges to the kernel. We also provide a method to learn the distribution of grid cell population efficiently. Grid cells, as a scalable position encoding method, can encode the spatial relationships of places and enable grid cells to outperform place cells in navigation. Further, we extend the grid cell to images encoding and find that grid cells embed images into a mental map, where geometric relationships are conceptual relationships of images. The theoretical model and analysis would contribute to establishing the grid cell code as a generic coding scheme for both spatial and conceptual spaces, and is promising for a multitude of problems across spatial cognition, machine learning and semantic cognition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001684",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Demography",
      "Geometry",
      "Grid",
      "Mathematics",
      "Population",
      "Sociology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Dang",
        "given_name": "Suogui"
      },
      {
        "surname": "Wu",
        "given_name": "Yining"
      },
      {
        "surname": "Yan",
        "given_name": "Rui"
      },
      {
        "surname": "Tang",
        "given_name": "Huajin"
      }
    ]
  },
  {
    "title": "Arguments for the unsuitability of convolutional neural networks for non-local tasks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.001",
    "abstract": "Convolutional neural networks have established themselves over the past years as the state of the art method for image classification, and for many datasets, they even surpass humans in categorizing images. Unfortunately, the same architectures perform much worse when they have to compare parts of an image to each other to correctly classify this image. Until now, no well-formed theoretical argument has been presented to explain this deficiency. In this paper, we will argue that convolutional layers are of little use for such problems, since comparison tasks are global by nature, but convolutional layers are local by design. We will use this insight to reformulate a comparison task into a sorting task and use findings on sorting networks to propose a lower bound for the number of parameters a neural network needs to solve comparison tasks in a generalizable way. We will use this lower bound to argue that attention, as well as iterative/recurrent processing, is needed to prevent a combinatorial explosion.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001775",
    "keywords": [],
    "authors": [
      {
        "surname": "Stabinger",
        "given_name": "Sebastian"
      },
      {
        "surname": "Peer",
        "given_name": "David"
      },
      {
        "surname": "Rodríguez-Sánchez",
        "given_name": "Antonio"
      }
    ]
  },
  {
    "title": "Deep ReLU neural networks in high-dimensional approximation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.027",
    "abstract": "We study the computation complexity of deep ReLU (Rectified Linear Unit) neural networks for the approximation of functions from the Hölder–Zygmund space of mixed smoothness defined on the d -dimensional unit cube when the dimension d may be very large. The approximation error is measured in the norm of isotropic Sobolev space. For every function f from the Hölder–Zygmund space of mixed smoothness, we explicitly construct a deep ReLU neural network having an output that approximates f with a prescribed accuracy ɛ , and prove tight dimension-dependent upper and lower bounds of the computation complexity of the approximation, characterized as the size and depth of this deep ReLU neural network, explicitly in d and ɛ . The proof of these results in particular, relies on the approximation by sparse-grid sampling recovery based on the Faber series.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002987",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Approximation error",
      "Artificial intelligence",
      "Artificial neural network",
      "Computation",
      "Computer science",
      "Dimension (graph theory)",
      "Discrete mathematics",
      "Function approximation",
      "Isotropy",
      "Law",
      "Mathematical analysis",
      "Mathematics",
      "Norm (philosophy)",
      "Physics",
      "Political science",
      "Pure mathematics",
      "Quantum mechanics",
      "Smoothness",
      "Sobolev space",
      "Uniform norm",
      "Unit cube"
    ],
    "authors": [
      {
        "surname": "Dũng",
        "given_name": "Dinh"
      },
      {
        "surname": "Nguyen",
        "given_name": "Van Kien"
      }
    ]
  },
  {
    "title": "Adaptive ensemble perception tracking",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.003",
    "abstract": "Recently, tracking models based on bounding box regression (such as region proposal networks), built on the Siamese network, have attracted much attention. Despite their promising performance, these trackers are less effective in perceiving the target information in the following two aspects. First, existing regression models cannot take a global view of a large-scale target since the effective receptive field of a neuron is too small to cover the target with a large scale. Second, the neurons with a fixed receptive field (RF) size in these models cannot adapt to the scale and aspect ratio changes of the target. In this paper, we propose an adaptive ensemble perception tracking framework to address these issues. Specifically, we first construct a per-pixel prediction model, which predicts the target state at each pixel of the correlated feature. On top of the per-pixel prediction model, we then develop a confidence-guided ensemble prediction mechanism. The ensemble mechanism adaptively fuses the predictions of multiple pixels with the guidance of confidence maps, which enlarges the perception range and enhances the adaptive perception ability at the object-level. In addition, we introduce a receptive field adaption model to enhance the adaptive perception ability at the neuron-level, which adjusts the RF by adaptively integrating the features with different RFs. Extensive experimental results on the VOT2018, VOT2016, UAV123, LaSOT, and TC128 datasets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods in terms of accuracy and speed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001957",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Bounding overwatch",
      "Computer science",
      "Computer vision",
      "Field (mathematics)",
      "Image (mathematics)",
      "Machine learning",
      "Mathematics",
      "Minimum bounding box",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Pedagogy",
      "Perception",
      "Physics",
      "Pixel",
      "Psychology",
      "Pure mathematics",
      "Quantum mechanics",
      "Receptive field",
      "Scale (ratio)",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Zikun"
      },
      {
        "surname": "Fan",
        "given_name": "Nana"
      },
      {
        "surname": "Yang",
        "given_name": "Kai"
      },
      {
        "surname": "Wang",
        "given_name": "Hongpeng"
      },
      {
        "surname": "He",
        "given_name": "Zhenyu"
      }
    ]
  },
  {
    "title": "Distributed-force-feedback-based reflex with online learning for adaptive quadruped motor control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.001",
    "abstract": "Biological motor control mechanisms (e.g., central pattern generators (CPGs), sensory feedback, reflexes, and motor learning) play a crucial role in the adaptive locomotion of animals. However, the interaction and integration of these mechanisms – necessary for generating the efficient, adaptive locomotion responses of legged robots to diverse terrains – have not yet been fully realized. One issue is that of achieving adaptive motor control for fast postural adaptation across various terrains. To address this issue, this study proposes a novel distributed-force-feedback-based reflex with online learning (DFRL). It integrates force-sensory feedback, reflexes, and learning to cooperate with CPGs in producing adaptive motor commands. The DFRL is based on a simple neural network that uses plastic synapses modulated online by a fast dual integral learner. Experimental results on different quadruped robots show that the DFRL can (1) automatically and rapidly adapt the CPG patterns (motor commands) of the robots, enabling them to realize appropriate body postures during locomotion and (2) enable the robots to effectively accommodate themselves to various slope terrains, including steep ones. Consequently, the DFRL-controlled robots can achieve efficient adaptive locomotion, to tackle complex terrains with diverse slopes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002331",
    "keywords": [
      "Adaptation (eye)",
      "Aesthetics",
      "Artificial intelligence",
      "Biology",
      "Central pattern generator",
      "Computer science",
      "Control engineering",
      "Ecology",
      "Engineering",
      "Motor learning",
      "Neuroscience",
      "Philosophy",
      "Psychology",
      "Reflex",
      "Rhythm",
      "Robot",
      "Sensory system",
      "Terrain"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Tao"
      },
      {
        "surname": "Dai",
        "given_name": "Zhendong"
      },
      {
        "surname": "Manoonpong",
        "given_name": "Poramate"
      }
    ]
  },
  {
    "title": "Capped L 2 , p -norm metric based robust least squares twin support vector machine for pattern classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.028",
    "abstract": "Least squares twin support vector machine (LSTSVM) is an effective and efficient learning algorithm for pattern classification. However, the distance in LSTSVM is measured by squared L 2 -norm metric that may magnify the influence of outliers. In this paper, a novel robust least squares twin support vector machine framework is proposed for binary classification, termed as C L 2 , p -LSTSVM, which utilizes capped L 2 , p -norm distance metric to reduce the influence of noise and outliers. The goal of C L 2 , p -LSTSVM is to minimize the capped L 2 , p -norm intra-class distance dispersion, and eliminate the influence of outliers during training process, where the value of the metric is controlled by the capped parameter, which can ensure better robustness. The proposed metric includes and extends the traditional metrics by setting appropriate values of p and capped parameter. This strategy not only retains the advantages of LSTSVM, but also improves the robustness in solving a binary classification problem with outliers. However, the nonconvexity of metric makes it difficult to optimize. We design an effective iterative algorithm to solve the C L 2 , p -LSTSVM. In each iteration, two systems of linear equations are solved. Simultaneously, we present some insightful analyses on the computational complexity and convergence of algorithm. Moreover, we extend the C L 2 , p -LSTSVM to nonlinear classifier and semi-supervised classification. Experiments are conducted on artificial datasets, UCI benchmark datasets, and image datasets to evaluate our method. Under different noise settings and different evaluation criteria, the experiment results show that the C L 2 , p -LSTSVM has better robustness than state-of-the-art approaches in most cases, which demonstrates the feasibility and effectiveness of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002604",
    "keywords": [
      "Algorithm",
      "Arithmetic",
      "Artificial intelligence",
      "Binary classification",
      "Binary number",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Gene",
      "Mathematics",
      "Outlier",
      "Robustness (evolution)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Yuan",
        "given_name": "Chao"
      },
      {
        "surname": "Yang",
        "given_name": "Liming"
      }
    ]
  },
  {
    "title": "Enhancing Graph Neural Networks by a High-quality Aggregation of Beneficial Information",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.025",
    "abstract": "Graph Neural Networks (GNNs), such as GCN, GraphSAGE, GAT, and SGC, have achieved state-of-the-art performance on a wide range of graph-based tasks. These models all use a technique called neighborhood aggregation, in which the embedding of each node is updated by aggregating the embeddings of its neighbors. However, not all information aggregated from neighbors is beneficial. In some cases, a portion of the neighbor information may be harmful to the downstream tasks. For the high-quality aggregation of beneficial information, we propose a flexible method EGAI (Enhancing Graph neural networks by a high-quality Aggregation of beneficial Information). The core concept of this method is to filter out the redundant and harmful information by removing specific edges during each training epoch. The practical and theoretical motivations, considerations, and strategies related to this method are discussed in detail. EGAI is a general method that can be combined with many backbone models (e.g., GCN, GraphSAGE, GAT, and SGC) to enhance their performance in the node classification task. In addition, EGAI reduces the convergence speed of over-smoothing that occurs when models are deepened. Extensive experiments on three real-world networks demonstrate that EGAI indeed improves the performance for both shallow and deep GNN models, and to some extent, mitigates over-smoothing. The code is available at https://github.com/liucoo/egai.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001623",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Data mining",
      "Embedding",
      "Engineering",
      "Graph",
      "Interpretability",
      "Machine learning",
      "Node (physics)",
      "Smoothing",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Chuang"
      },
      {
        "surname": "Wu",
        "given_name": "Jia"
      },
      {
        "surname": "Liu",
        "given_name": "Weiwei"
      },
      {
        "surname": "Hu",
        "given_name": "Wenbin"
      }
    ]
  },
  {
    "title": "A neuromimetic realization of hippocampal CA1 for theta wave generation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.002",
    "abstract": "Recent advances in neural engineering allowed the development of neuroprostheses which facilitate functionality in people with neurological problems. In this research, a real-time neuromorphic system is proposed to artificially reproduce the theta wave and firing patterns of different neuronal populations in the CA1, a sub-region of the hippocampus. The hippocampal theta oscillations (4–12 Hz) are an important electrophysiological rhythm that contributes in various cognitive functions, including navigation, memory, and novelty detection. The proposed CA1 neuromimetic circuit includes 100 linearized Pinsky–Rinzel neurons and 668 excitatory and inhibitory synapses on a field programmable gate array (FPGA). The implemented spiking neural network of the CA1 includes the main neuronal populations for the theta rhythm generation: excitatory pyramidal cells, PV+ basket cells, and Oriens Lacunosum-Moleculare (OLM) cells which are inhibitory interneurons. Moreover, the main inputs to the CA1 region from the entorhinal cortex via the perforant pathway, the CA3 via Schaffer collaterals, and the medial septum via fimbria–fornix are also implemented on the FPGA using a bursting leaky-integrate and fire (LIF) neuron model. The results of hardware realization show that the proposed CA1 neuromimetic circuit successfully reconstructs the theta oscillations and functionally illustrates the phase relations between firing responses of the different neuronal populations. It is also evaluated the impact of medial septum elimination on the firing patterns of the CA1 neuronal population and the theta wave’s characteristics. This neuromorphic system can be considered as a potential platform that opens opportunities for neuroprosthetic applications in future works.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002653",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bursting",
      "Computer hardware",
      "Computer science",
      "Entorhinal cortex",
      "Environmental health",
      "Excitatory postsynaptic potential",
      "Field-programmable gate array",
      "Fornix",
      "Hippocampal formation",
      "Hippocampus",
      "Inhibitory postsynaptic potential",
      "Local field potential",
      "Medicine",
      "Neuromorphic engineering",
      "Neuroscience",
      "Population",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Salimi-Nezhad",
        "given_name": "Nima"
      },
      {
        "surname": "Hasanlou",
        "given_name": "Mohammad"
      },
      {
        "surname": "Amiri",
        "given_name": "Mahmood"
      },
      {
        "surname": "Keliris",
        "given_name": "Georgios A."
      }
    ]
  },
  {
    "title": "Instance elimination strategy for non-convex multiple-instance learning using sparse positive bags",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.009",
    "abstract": "In some multiple instance learning (MIL) applications, positive bags are sparse (i.e. containing only a small fraction of positive instances). To deal with the imbalanced data caused by these situations, we present a novel MIL method based on a small sphere and large margin approach (SSLM-MIL). Due to the introduction of a large margin, SSLM-MIL enforces the desired constraint that for all positive bags, there is at least one positive instance in each bag. Moreover, our framework is flexible to incorporate the non-convex optimization problem. Therefore, we can solve it using the concave–convex procedure (CCCP). Still, CCCP may be computationally inefficient for the number of external iterations. Inspired by the existing safe screening rules, which can effectively reduce computational time by discarding some inactive instances. In this paper, we propose a strategy to reduce the scale of the optimization problem. Specifically, we construct a screening rule in the inner solver and another rule for propagating screened instances between iterations of CCCP. To the best of our knowledge, this is the first attempt to introduce safe instance screening to a non-convex hypersphere support vector machine. Experiments on thirty-one benchmark datasets demonstrate the safety and effectiveness of our approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002720",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Convex optimization",
      "Geodesy",
      "Geography",
      "Geometry",
      "Hypersphere",
      "Machine learning",
      "Margin (machine learning)",
      "Mathematical optimization",
      "Mathematics",
      "Regular polygon",
      "Solver",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Yuan",
        "given_name": "Min"
      },
      {
        "surname": "Xu",
        "given_name": "Yitian"
      },
      {
        "surname": "Feng",
        "given_name": "Renxiu"
      },
      {
        "surname": "Liu",
        "given_name": "Zongmin"
      }
    ]
  },
  {
    "title": "Adaptive ensemble perception tracking",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.003",
    "abstract": "Recently, tracking models based on bounding box regression (such as region proposal networks), built on the Siamese network, have attracted much attention. Despite their promising performance, these trackers are less effective in perceiving the target information in the following two aspects. First, existing regression models cannot take a global view of a large-scale target since the effective receptive field of a neuron is too small to cover the target with a large scale. Second, the neurons with a fixed receptive field (RF) size in these models cannot adapt to the scale and aspect ratio changes of the target. In this paper, we propose an adaptive ensemble perception tracking framework to address these issues. Specifically, we first construct a per-pixel prediction model, which predicts the target state at each pixel of the correlated feature. On top of the per-pixel prediction model, we then develop a confidence-guided ensemble prediction mechanism. The ensemble mechanism adaptively fuses the predictions of multiple pixels with the guidance of confidence maps, which enlarges the perception range and enhances the adaptive perception ability at the object-level. In addition, we introduce a receptive field adaption model to enhance the adaptive perception ability at the neuron-level, which adjusts the RF by adaptively integrating the features with different RFs. Extensive experimental results on the VOT2018, VOT2016, UAV123, LaSOT, and TC128 datasets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods in terms of accuracy and speed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001957",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Bounding overwatch",
      "Computer science",
      "Computer vision",
      "Field (mathematics)",
      "Image (mathematics)",
      "Machine learning",
      "Mathematics",
      "Minimum bounding box",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Pedagogy",
      "Perception",
      "Physics",
      "Pixel",
      "Psychology",
      "Pure mathematics",
      "Quantum mechanics",
      "Receptive field",
      "Scale (ratio)",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Zikun"
      },
      {
        "surname": "Fan",
        "given_name": "Nana"
      },
      {
        "surname": "Yang",
        "given_name": "Kai"
      },
      {
        "surname": "Wang",
        "given_name": "Hongpeng"
      },
      {
        "surname": "He",
        "given_name": "Zhenyu"
      }
    ]
  },
  {
    "title": "A neuromimetic realization of hippocampal CA1 for theta wave generation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.002",
    "abstract": "Recent advances in neural engineering allowed the development of neuroprostheses which facilitate functionality in people with neurological problems. In this research, a real-time neuromorphic system is proposed to artificially reproduce the theta wave and firing patterns of different neuronal populations in the CA1, a sub-region of the hippocampus. The hippocampal theta oscillations (4–12 Hz) are an important electrophysiological rhythm that contributes in various cognitive functions, including navigation, memory, and novelty detection. The proposed CA1 neuromimetic circuit includes 100 linearized Pinsky–Rinzel neurons and 668 excitatory and inhibitory synapses on a field programmable gate array (FPGA). The implemented spiking neural network of the CA1 includes the main neuronal populations for the theta rhythm generation: excitatory pyramidal cells, PV+ basket cells, and Oriens Lacunosum-Moleculare (OLM) cells which are inhibitory interneurons. Moreover, the main inputs to the CA1 region from the entorhinal cortex via the perforant pathway, the CA3 via Schaffer collaterals, and the medial septum via fimbria–fornix are also implemented on the FPGA using a bursting leaky-integrate and fire (LIF) neuron model. The results of hardware realization show that the proposed CA1 neuromimetic circuit successfully reconstructs the theta oscillations and functionally illustrates the phase relations between firing responses of the different neuronal populations. It is also evaluated the impact of medial septum elimination on the firing patterns of the CA1 neuronal population and the theta wave’s characteristics. This neuromorphic system can be considered as a potential platform that opens opportunities for neuroprosthetic applications in future works.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002653",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bursting",
      "Computer hardware",
      "Computer science",
      "Entorhinal cortex",
      "Environmental health",
      "Excitatory postsynaptic potential",
      "Field-programmable gate array",
      "Fornix",
      "Hippocampal formation",
      "Hippocampus",
      "Inhibitory postsynaptic potential",
      "Local field potential",
      "Medicine",
      "Neuromorphic engineering",
      "Neuroscience",
      "Population",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Salimi-Nezhad",
        "given_name": "Nima"
      },
      {
        "surname": "Hasanlou",
        "given_name": "Mohammad"
      },
      {
        "surname": "Amiri",
        "given_name": "Mahmood"
      },
      {
        "surname": "Keliris",
        "given_name": "Georgios A."
      }
    ]
  },
  {
    "title": "Bio-instantiated recurrent neural networks: Integrating neurobiology-based network topology in artificial networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.011",
    "abstract": "Biological neuronal networks (BNNs) are a source of inspiration and analogy making for researchers that focus on artificial neuronal networks (ANNs). Moreover, neuroscientists increasingly use ANNs as a model for the brain. Despite certain similarities between these two types of networks, important differences can be discerned. First, biological neural networks are sculpted by evolution and the constraints that it entails, whereas artificial neural networks are engineered to solve particular tasks. Second, the network topology of these systems, apart from some analogies that can be drawn, exhibits pronounced differences. Here, we examine strategies to construct recurrent neural networks (RNNs) that instantiate the network topology of brains of different species. We refer to such RNNs as bio-instantiated. We investigate the performance of bio-instantiated RNNs in terms of: (i) the prediction performance itself, that is, the capacity of the network to minimize the cost function at hand in test data, and (ii) speed of training, that is, how fast during training the network reaches its optimal performance. We examine bio-instantiated RNNs in working memory tasks where task-relevant information must be tracked as a sequence of events unfolds in time. We highlight the strategies that can be used to construct RNNs with the network topology found in BNNs, without sacrificing performance. Despite that we observe no enhancement of performance when compared to randomly wired RNNs, our approach demonstrates how empirical neural network data can be used for constructing RNNs, thus, facilitating further experimentation with biologically realistic network topologies, in contexts where such aspect is desired.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002744",
    "keywords": [
      "Analogy",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer network",
      "Computer science",
      "Construct (python library)",
      "Electrical engineering",
      "Engineering",
      "Linguistics",
      "Machine learning",
      "Nervous system network models",
      "Network topology",
      "Philosophy",
      "Recurrent neural network",
      "Topology (electrical circuits)",
      "Types of artificial neural networks"
    ],
    "authors": [
      {
        "surname": "Goulas",
        "given_name": "Alexandros"
      },
      {
        "surname": "Damicelli",
        "given_name": "Fabrizio"
      },
      {
        "surname": "Hilgetag",
        "given_name": "Claus C."
      }
    ]
  },
  {
    "title": "Exact coexistence and locally asymptotic stability of multiple equilibria for fractional-order delayed Hopfield neural networks with Gaussian activation function",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.029",
    "abstract": "This paper explores the multistability issue for fractional-order Hopfield neural networks with Gaussian activation function and multiple time delays. First, several sufficient criteria are presented for ensuring the exact coexistence of 3 n equilibria, based on the geometric characteristics of Gaussian function, the fixed point theorem and the contraction mapping principle. Then, different from the existing methods used in the multistability analysis of fractional-order neural networks without time delays, it is shown that 2 n of 3 n total equilibria are locally asymptotically stable, by applying the theory of fractional-order linear delayed system and constructing suitable Lyapunov function. The obtained results improve and extend some existing multistability works for classical integer-order neural networks and fractional-order neural networks without time delays. Finally, an illustrative example with comprehensive computer simulations is given to demonstrate the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003002",
    "keywords": [
      "Activation function",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differential equation",
      "Equilibrium point",
      "Evolutionary biology",
      "Exponential stability",
      "Function (biology)",
      "Gaussian",
      "Hopfield network",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Multistability",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Nie",
        "given_name": "Xiaobing"
      },
      {
        "surname": "Liu",
        "given_name": "Pingping"
      },
      {
        "surname": "Liang",
        "given_name": "Jinling"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Probabilistic learning vector quantization on manifold of symmetric positive definite matrices",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.024",
    "abstract": "In this paper, we develop a new classification method for manifold-valued data in the framework of probabilistic learning vector quantization. In many classification scenarios, the data can be naturally represented by symmetric positive definite matrices, which are inherently points that live on a curved Riemannian manifold. Due to the non-Euclidean geometry of Riemannian manifolds, traditional Euclidean machine learning algorithms yield poor results on such data. In this paper, we generalize the probabilistic learning vector quantization algorithm for data points living on the manifold of symmetric positive definite matrices equipped with Riemannian natural metric (affine-invariant metric). By exploiting the induced Riemannian distance, we derive the probabilistic learning Riemannian space quantization algorithm, obtaining the learning rule through Riemannian gradient descent. Empirical investigations on synthetic data, image data , and motor imagery electroencephalogram (EEG) data demonstrate the superior performance of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001611",
    "keywords": [
      "Affine transformation",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Curvature",
      "Dimensionality reduction",
      "Eigenvalues and eigenvectors",
      "Engineering",
      "Euclidean space",
      "Geometry",
      "Gradient descent",
      "Information geometry",
      "Learning vector quantization",
      "Manifold (fluid mechanics)",
      "Manifold alignment",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Pattern recognition (psychology)",
      "Physics",
      "Positive-definite matrix",
      "Probabilistic logic",
      "Pure mathematics",
      "Quantum mechanics",
      "Riemannian geometry",
      "Riemannian manifold",
      "Scalar curvature",
      "Statistical manifold",
      "Vector quantization"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Fengzhen"
      },
      {
        "surname": "Feng",
        "given_name": "Haifeng"
      },
      {
        "surname": "Tino",
        "given_name": "Peter"
      },
      {
        "surname": "Si",
        "given_name": "Bailu"
      },
      {
        "surname": "Ji",
        "given_name": "Daxiong"
      }
    ]
  },
  {
    "title": "Capturing the grouping and compactness of high-level semantic feature for saliency detection",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.028",
    "abstract": "Saliency detection is an important and challenging research topic due to the variety and complexity of the background and saliency regions. In this paper, we present a novel unsupervised saliency detection approach by exploiting the grouping and compactness characteristics of the high-level semantic features. First, for the high-level semantic feature, the elastic net based hypergraph model is adopted to discover the group structure relationships of salient regional points, and the calculation of the spatial distribution is constructed to detect the compactness of the saliency regions. Next, the grouping-based and compactness-based saliency maps are improved by a propagation algorithm. The propagation process uses an enhanced similarity matrix, which fuses the low-level deep feature and the high-level semantic feature through cross diffusion. Results on four benchmark datasets with pixel-wise accurate labeling demonstrate the effectiveness of the proposed method. Particularly, the proposed unsupervised method achieves competitive performance with deep learning-based methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001659",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Compact space",
      "Computer science",
      "Feature (linguistics)",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Linguistics",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pure mathematics",
      "Salient",
      "Similarity (geometry)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Ying Ying"
      },
      {
        "surname": "Wang",
        "given_name": "HongJuan"
      },
      {
        "surname": "Lv",
        "given_name": "XiaoDong"
      },
      {
        "surname": "Zhang",
        "given_name": "Ping"
      }
    ]
  },
  {
    "title": "Learning to reweight examples in multi-label classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.022",
    "abstract": "This paper presents a new method for reweighting examples in the multi-label classification problem. Existing weighting functions in self-paced learning simply determine the weights of examples according to their loss values given the current multi-label model, but neglect the unique properties of multi-label examples. It is inaccurate to treat two distinct examples as equal even if their loss values are the same. Therefore, we upgrade the classical weight functions by considering instance complexities, which are described by the distances between instance features and their corresponding labels. The distance metric can be easily optimized during training. Experimental results on real-world datasets demonstrate the significance of investigating both the dynamic and static complexities of multi-label examples, as well as the advantages of the proposed example reweighting algorithm in multi-label classification problems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001106",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Current (fluid)",
      "Economics",
      "Electrical engineering",
      "Engineering",
      "Machine learning",
      "Medicine",
      "Metric (unit)",
      "Operations management",
      "Pattern recognition (psychology)",
      "Radiology",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Zhong",
        "given_name": "Yongjian"
      },
      {
        "surname": "Du",
        "given_name": "Bo"
      },
      {
        "surname": "Xu",
        "given_name": "Chang"
      }
    ]
  },
  {
    "title": "Optimal attention tuning in a neuro-computational model of the visual cortex–basal ganglia–prefrontal cortex loop",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.008",
    "abstract": "Visual attention is widely considered a vital factor in the perception and analysis of a visual scene. Several studies explored the effects and mechanisms of top-down attention, but the mechanisms that determine the attentional signal are less explored. By developing a neuro-computational model of visual attention including the visual cortex–basal ganglia loop, we demonstrate how attentional alignment can evolve based on dopaminergic reward during a visual search task. Unlike most previous modeling studies of feature-based attention, we do not implement a manually predefined attention template. Dopamine-modulated covariance learning enable the basal ganglia to learn rewarded associations between the visual input and the attentional gain represented in the PFC of the model. Hence, the model shows human-like performance on a visual search task by optimally tuning the attention signal. In particular, similar as in humans, this reward-based tuning in the model leads to an attentional template that is not centered on the target feature, but a relevant feature deviating away from the target due to the presence of highly similar distractors. Further analyses of the model shows, attention is mainly guided by the signal-to-noise ratio between target and distractors.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002719",
    "keywords": [
      "Artificial intelligence",
      "Basal ganglia",
      "Central nervous system",
      "Cognition",
      "Computer science",
      "Feature (linguistics)",
      "Linguistics",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Perception",
      "Philosophy",
      "Prefrontal cortex",
      "Psychology",
      "Visual cortex",
      "Visual perception",
      "Visual search"
    ],
    "authors": [
      {
        "surname": "Maith",
        "given_name": "Oliver"
      },
      {
        "surname": "Schwarz",
        "given_name": "Alex"
      },
      {
        "surname": "Hamker",
        "given_name": "Fred H."
      }
    ]
  },
  {
    "title": "Robot navigation as hierarchical active inference",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.010",
    "abstract": "Localization and mapping has been a long standing area of research, both in neuroscience, to understand how mammals navigate their environment, as well as in robotics, to enable autonomous mobile robots. In this paper, we treat navigation as inferring actions that minimize (expected) variational free energy under a hierarchical generative model. We find that familiar concepts like perception, path integration, localization and mapping naturally emerge from this active inference formulation. Moreover, we show that this model is consistent with models of hippocampal functions, and can be implemented in silico on a real-world robot. Our experiments illustrate that a robot equipped with our hierarchical model is able to generate topologically consistent maps, and correct navigation behaviour is inferred when a goal location is provided to the system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002021",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Free energy principle",
      "Generative grammar",
      "Generative model",
      "Inference",
      "Machine learning",
      "Mobile robot",
      "Mobile robot navigation",
      "Robot",
      "Robot control",
      "Robotics"
    ],
    "authors": [
      {
        "surname": "Çatal",
        "given_name": "Ozan"
      },
      {
        "surname": "Verbelen",
        "given_name": "Tim"
      },
      {
        "surname": "Van de Maele",
        "given_name": "Toon"
      },
      {
        "surname": "Dhoedt",
        "given_name": "Bart"
      },
      {
        "surname": "Safron",
        "given_name": "Adam"
      }
    ]
  },
  {
    "title": "Spatial information transfer in hippocampal place cells depends on trial-to-trial variability, symmetry of place-field firing, and biophysical heterogeneities",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.026",
    "abstract": "The relationship between the feature-tuning curve and information transfer profile of individual neurons provides vital insights about neural encoding. However, the relationship between the spatial tuning curve and spatial information transfer of hippocampal place cells remains unexplored. Here, employing a stochastic search procedure spanning thousands of models, we arrived at 127 conductance-based place-cell models that exhibited signature electrophysiological characteristics and sharp spatial tuning, with parametric values that exhibited neither clustering nor strong pairwise correlations. We introduced trial-to-trial variability in responses and computed model tuning curves and information transfer profiles, using stimulus-specific (SSI) and mutual (MI) information metrics, across locations within the place field. We found spatial information transfer to be heterogeneous across models, but to reduce consistently with increasing levels of variability. Importantly, whereas reliable low-variability responses implied that maximal information transfer occurred at high-slope regions of the tuning curve, increase in variability resulted in maximal transfer occurring at the peak-firing location in a subset of models. Moreover, experience-dependent asymmetry in place-field firing introduced asymmetries in the information transfer computed through MI, but not SSI, and the impact of activity-dependent variability on information transfer was minimal compared to activity-independent variability. We unveiled ion-channel degeneracy in the regulation of spatial information transfer, and demonstrated critical roles for N-methyl-d-aspartate receptors, transient potassium and dendritic sodium channels in regulating information transfer. Our results demonstrate that trial-to-trial variability, tuning-curve shape and biological heterogeneities critically regulate the relationship between the spatial tuning curve and spatial information transfer in hippocampal place cells.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002975",
    "keywords": [
      "Artificial intelligence",
      "Biological system",
      "Biology",
      "Computer science",
      "Information transfer",
      "Magnetic resonance imaging",
      "Magnetization transfer",
      "Mathematics",
      "Medicine",
      "Mutual information",
      "Neuroscience",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Radiology",
      "Spatial analysis",
      "Spatial variability",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Roy",
        "given_name": "Ankit"
      },
      {
        "surname": "Narayanan",
        "given_name": "Rishikesh"
      }
    ]
  },
  {
    "title": "Self-selective attention using correlation between instances for distant supervision relation extraction",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.032",
    "abstract": "Distant supervision relation extraction methods are widely used to extract relational facts in text. The traditional selective attention model regards instances in the bag as independent of each other, which makes insufficient use of correlation information between instances and supervision information of all correctly labeled instances, affecting the performance of relation extractor. Aiming at this problem, a distant supervision relation extraction method with self-selective attention is proposed. The method uses a layer of convolution and self-attention mechanism to encode instances to learn the better semantic vector representation of instances. The correlation between instances in the bag is used to assign a higher weight to all correctly labeled instances, and the weighted summation of instances in the bag is used to obtain a bag vector representation. Experiments on the NYT dataset show that the method can make full use of the information of all correctly labeled instances in the bag. The method can achieve better results as compared with baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001696",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Convolution (computer science)",
      "Correlation",
      "Data mining",
      "ENCODE",
      "Engineering",
      "Extractor",
      "Gene",
      "Geometry",
      "Law",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Process engineering",
      "Relation (database)",
      "Relationship extraction",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Yanru"
      },
      {
        "surname": "Pan",
        "given_name": "Limin"
      },
      {
        "surname": "Bai",
        "given_name": "Chongyou"
      },
      {
        "surname": "Luo",
        "given_name": "Senlin"
      },
      {
        "surname": "Wu",
        "given_name": "Zhouting"
      }
    ]
  },
  {
    "title": "Selective ensemble-based online adaptive deep neural networks for streaming data with concept drift",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.027",
    "abstract": "Concept drift is an important issue in the field of streaming data mining. However, how to maintain real-time model convergence in a dynamic environment is an important and difficult problem. In addition, the current methods have limited ability to deal with the problem of streaming data classification for complex nonlinear problems. To solve these problems, a selective ensemble-based online adaptive deep neural network (SEOA) is proposed to address concept drift. First, the adaptive depth unit is constructed by combining shallow features with deep features and adaptively controls the information flow in the neural network according to changes in streaming data at adjacent moments, which improves the convergence of the online deep learning model. Then, the adaptive depth units of different layers are regarded as base classifiers for ensemble and weighted dynamically according to the loss of each classifier. In addition, a dynamic selection of base classifiers is adopted according to the fluctuation of the streaming data to achieve a balance between stability and adaptability. The experimental results show that the SEOA can effectively contend with different types of concept drift and has good robustness and generalization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002598",
    "keywords": [
      "Adaptability",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Classifier (UML)",
      "Computer science",
      "Concept drift",
      "Convergence (economics)",
      "Data mining",
      "Data stream",
      "Data stream mining",
      "Ecology",
      "Economic growth",
      "Economics",
      "Gene",
      "Machine learning",
      "Robustness (evolution)",
      "Stability (learning theory)",
      "Streaming data",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Husheng"
      },
      {
        "surname": "Zhang",
        "given_name": "Shuai"
      },
      {
        "surname": "Wang",
        "given_name": "Wenjian"
      }
    ]
  },
  {
    "title": "Unsupervised multi-sense language models for natural language processing tasks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.023",
    "abstract": "Existing language models (LMs) represent each word with only a single representation, which is unsuitable for processing words with multiple meanings. This issue has often been compounded by the lack of availability of large-scale data annotated with word meanings. In this paper, we propose a sense-aware framework that can process multi-sense word information without relying on annotated data. In contrast to the existing multi-sense representation models, which handle information in a restricted context, our framework provides context representations encoded without ignoring word order information or long-term dependency. The proposed framework consists of a context representation stage to encode the variable-size context, a sense-labeling stage that involves unsupervised clustering to infer a probable sense for a word in each context, and a multi-sense LM (MSLM) learning stage to learn the multi-sense representations. Particularly for the evaluation of MSLMs with different vocabulary sizes, we propose a new metric, i.e., unigram-normalized perplexity (PPLu), which is also understood as the negated mutual information between a word and its context information. Additionally, there is a theoretical verification of PPLu on the change of vocabulary size. Also, we adopt a method of estimating the number of senses, which does not require further hyperparameter search for an LM performance. For the LMs in our framework, both unidirectional and bidirectional architectures based on long short-term memory (LSTM) and Transformers are adopted. We conduct comprehensive experiments on three language modeling datasets to perform quantitative and qualitative comparisons of various LMs. Our MSLM outperforms single-sense LMs (SSLMs) with the same network architecture and parameters. It also shows better performance on several downstream natural language processing tasks in the General Language Understanding Evaluation (GLUE) and SuperGLUE benchmarks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002197",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Context model",
      "Language model",
      "Linguistics",
      "Machine learning",
      "Natural language processing",
      "Object (grammar)",
      "Paleontology",
      "Perplexity",
      "Philosophy",
      "Vocabulary",
      "Word (group theory)"
    ],
    "authors": [
      {
        "surname": "Roh",
        "given_name": "Jihyeon"
      },
      {
        "surname": "Park",
        "given_name": "Sungjin"
      },
      {
        "surname": "Kim",
        "given_name": "Bo-Kyeong"
      },
      {
        "surname": "Oh",
        "given_name": "Sang-Hoon"
      },
      {
        "surname": "Lee",
        "given_name": "Soo-Young"
      }
    ]
  },
  {
    "title": "Efficient learning with augmented spikes: A case study with image classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.002",
    "abstract": "Efficient learning of spikes plays a valuable role in training spiking neural networks (SNNs) to have desired responses to input stimuli. However, current learning rules are limited to a binary form of spikes. The seemingly ubiquitous phenomenon of burst in nervous systems suggests a new way to carry more information with spike bursts in addition to times. Based on this, we introduce an advanced form, the augmented spikes, where spike coefficients are used to carry additional information. How could neurons learn and benefit from augmented spikes remains unclear. In this paper, we propose two new efficient learning rules to process spatiotemporal patterns composed of augmented spikes. Moreover, we examine the learning abilities of our methods with a synthetic recognition task of augmented spike patterns and two practical ones for image classification. Experimental results demonstrate that our rules are capable of extracting information carried by both the timing and coefficient of spikes. Our proposed approaches achieve remarkable performance and good robustness under various noise conditions, as compared to benchmarks. The improved performance indicates the merits of augmented spikes and our learning rules, which could be beneficial and generalized to a broad range of spike-based platforms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001945",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Carry (investment)",
      "Chemistry",
      "Composite material",
      "Computer science",
      "Economics",
      "Finance",
      "Gene",
      "Image (mathematics)",
      "Machine learning",
      "Management",
      "Materials science",
      "Noise (video)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Range (aeronautics)",
      "Robustness (evolution)",
      "Software engineering",
      "Spike (software development)",
      "Spike train",
      "Spiking neural network",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Shiming"
      },
      {
        "surname": "Ma",
        "given_name": "Chenxiang"
      },
      {
        "surname": "Sun",
        "given_name": "Wei"
      },
      {
        "surname": "Xu",
        "given_name": "Junhai"
      },
      {
        "surname": "Dang",
        "given_name": "Jianwu"
      },
      {
        "surname": "Yu",
        "given_name": "Qiang"
      }
    ]
  },
  {
    "title": "An efficient encoder–decoder model for portrait depth estimation from single images trained on pixel-accurate synthetic data",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.007",
    "abstract": "Depth estimation from a single image frame is a fundamental challenge in computer vision, with many applications such as augmented reality, action recognition, image understanding, and autonomous driving. Large and diverse training sets are required for accurate depth estimation from a single image frame. Due to challenges in obtaining dense ground-truth depth, a new 3D pipeline of 100 synthetic virtual human models is presented to generate multiple 2D facial images and corresponding ground truth depth data, allowing complete control over image variations. To validate the synthetic facial depth data, we propose an evaluation of state-of-the-art depth estimation algorithms based on single image frames on the generated synthetic dataset. Furthermore, an improved encoder–decoder based neural network is presented. This network is computationally efficient and shows better performance than current state-of-the-art when tested and evaluated across 4 public datasets. Our training methodology relies on the use of synthetic data samples which provides a more reliable ground truth for depth estimation. Additionally, using a combination of appropriate loss functions leads to improved performance than the current state-of-the-art network performances. Our approach clearly outperforms competing methods across different test datasets, setting a new state-of-the-art for facial depth estimation from synthetic data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002707",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Depth map",
      "Encoder",
      "Frame (networking)",
      "Ground truth",
      "Image (mathematics)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Pipeline (software)",
      "Pixel",
      "Programming language",
      "Synthetic data",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Khan",
        "given_name": "Faisal"
      },
      {
        "surname": "Hussain",
        "given_name": "Shahid"
      },
      {
        "surname": "Basak",
        "given_name": "Shubhajit"
      },
      {
        "surname": "Lemley",
        "given_name": "Joseph"
      },
      {
        "surname": "Corcoran",
        "given_name": "Peter"
      }
    ]
  },
  {
    "title": "Event-triggered adaptive neural networks control for fractional-order nonstrict-feedback nonlinear systems with unmodeled dynamics and input saturation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.014",
    "abstract": "The event-triggered adaptive neural networks control is investigated in this paper for a class of fractional-order systems (FOSs) with unmodeled dynamics and input saturation. Firstly, in order to obtain an auxiliary signal and then avoid the state variables of unmodeled dynamics directly appearing in the designed controller, the notion of exponential input-to-state practical stability (ISpS) and some related lemmas for integer-order systems are extended to the ones for FOSs. Then, based on the traditional event-triggered mechanism, we propose a novel adaptive event-triggered mechanism (AETM) in this paper, in which the threshold parameters can be adjusted dynamically according to the tracking performance. Besides, different from the previous works where the derivative of hyperbolic tangent function tanh ( ⋅ ) needs to have positive lower bound, a new type of auxiliary signal is introduced in this paper to handle the effect of input saturation and thus this limitation is released. Finally, two numerical examples and some comparisons are provided to illustrate our proposed controllers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002100",
    "keywords": [
      "Adaptive control",
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Fractional calculus",
      "Geometry",
      "Hyperbolic function",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Tangent"
    ],
    "authors": [
      {
        "surname": "Cao",
        "given_name": "Boqiang"
      },
      {
        "surname": "Nie",
        "given_name": "Xiaobing"
      }
    ]
  },
  {
    "title": "H ∞ synchronization of delayed neural networks via event-triggered dynamic output control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.009",
    "abstract": "This paper investigates H ∞ exponential synchronization (ES) of neural networks (NNs) with delay by designing an event-triggered dynamic output feedback controller (ETDOFC). The ETDOFC is flexible in practice since it is applicable to both full order and reduced order dynamic output techniques. Moreover, the event generator reduces the computational burden for the zero-order-hold (ZOH) operator and does not induce sampling delay as many existing event generators do. To obtain less conservative results, the delay-partitioning method is utilized in the Lyapunov–Krasovskii functional (LKF). Synchronization criteria formulated by linear matrix inequalities (LMIs) are established. A simple algorithm is provided to design the control gains of the ETDOFC, which overcomes the difficulty induced by different dimensions of the system parameters. One numerical example is provided to demonstrate the merits of the theoretical analysis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100201X",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Controller (irrigation)",
      "Event (particle physics)",
      "Event generator",
      "Generator (circuit theory)",
      "Mathematics",
      "Monte Carlo method",
      "Operating system",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Scalable Vector Graphics",
      "Statistics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yachun"
      },
      {
        "surname": "Tu",
        "given_name": "Zhengwen"
      },
      {
        "surname": "Wang",
        "given_name": "Liangwei"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Shi",
        "given_name": "Lei"
      },
      {
        "surname": "Qian",
        "given_name": "Wenhua"
      }
    ]
  },
  {
    "title": "Efficient learning with augmented spikes: A case study with image classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.002",
    "abstract": "Efficient learning of spikes plays a valuable role in training spiking neural networks (SNNs) to have desired responses to input stimuli. However, current learning rules are limited to a binary form of spikes. The seemingly ubiquitous phenomenon of burst in nervous systems suggests a new way to carry more information with spike bursts in addition to times. Based on this, we introduce an advanced form, the augmented spikes, where spike coefficients are used to carry additional information. How could neurons learn and benefit from augmented spikes remains unclear. In this paper, we propose two new efficient learning rules to process spatiotemporal patterns composed of augmented spikes. Moreover, we examine the learning abilities of our methods with a synthetic recognition task of augmented spike patterns and two practical ones for image classification. Experimental results demonstrate that our rules are capable of extracting information carried by both the timing and coefficient of spikes. Our proposed approaches achieve remarkable performance and good robustness under various noise conditions, as compared to benchmarks. The improved performance indicates the merits of augmented spikes and our learning rules, which could be beneficial and generalized to a broad range of spike-based platforms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001945",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Carry (investment)",
      "Chemistry",
      "Composite material",
      "Computer science",
      "Economics",
      "Finance",
      "Gene",
      "Image (mathematics)",
      "Machine learning",
      "Management",
      "Materials science",
      "Noise (video)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Range (aeronautics)",
      "Robustness (evolution)",
      "Software engineering",
      "Spike (software development)",
      "Spike train",
      "Spiking neural network",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Shiming"
      },
      {
        "surname": "Ma",
        "given_name": "Chenxiang"
      },
      {
        "surname": "Sun",
        "given_name": "Wei"
      },
      {
        "surname": "Xu",
        "given_name": "Junhai"
      },
      {
        "surname": "Dang",
        "given_name": "Jianwu"
      },
      {
        "surname": "Yu",
        "given_name": "Qiang"
      }
    ]
  },
  {
    "title": "An efficient encoder–decoder model for portrait depth estimation from single images trained on pixel-accurate synthetic data",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.07.007",
    "abstract": "Depth estimation from a single image frame is a fundamental challenge in computer vision, with many applications such as augmented reality, action recognition, image understanding, and autonomous driving. Large and diverse training sets are required for accurate depth estimation from a single image frame. Due to challenges in obtaining dense ground-truth depth, a new 3D pipeline of 100 synthetic virtual human models is presented to generate multiple 2D facial images and corresponding ground truth depth data, allowing complete control over image variations. To validate the synthetic facial depth data, we propose an evaluation of state-of-the-art depth estimation algorithms based on single image frames on the generated synthetic dataset. Furthermore, an improved encoder–decoder based neural network is presented. This network is computationally efficient and shows better performance than current state-of-the-art when tested and evaluated across 4 public datasets. Our training methodology relies on the use of synthetic data samples which provides a more reliable ground truth for depth estimation. Additionally, using a combination of appropriate loss functions leads to improved performance than the current state-of-the-art network performances. Our approach clearly outperforms competing methods across different test datasets, setting a new state-of-the-art for facial depth estimation from synthetic data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002707",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Depth map",
      "Encoder",
      "Frame (networking)",
      "Ground truth",
      "Image (mathematics)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Pipeline (software)",
      "Pixel",
      "Programming language",
      "Synthetic data",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Khan",
        "given_name": "Faisal"
      },
      {
        "surname": "Hussain",
        "given_name": "Shahid"
      },
      {
        "surname": "Basak",
        "given_name": "Shubhajit"
      },
      {
        "surname": "Lemley",
        "given_name": "Joseph"
      },
      {
        "surname": "Corcoran",
        "given_name": "Peter"
      }
    ]
  },
  {
    "title": "Event-triggered adaptive neural networks control for fractional-order nonstrict-feedback nonlinear systems with unmodeled dynamics and input saturation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.014",
    "abstract": "The event-triggered adaptive neural networks control is investigated in this paper for a class of fractional-order systems (FOSs) with unmodeled dynamics and input saturation. Firstly, in order to obtain an auxiliary signal and then avoid the state variables of unmodeled dynamics directly appearing in the designed controller, the notion of exponential input-to-state practical stability (ISpS) and some related lemmas for integer-order systems are extended to the ones for FOSs. Then, based on the traditional event-triggered mechanism, we propose a novel adaptive event-triggered mechanism (AETM) in this paper, in which the threshold parameters can be adjusted dynamically according to the tracking performance. Besides, different from the previous works where the derivative of hyperbolic tangent function tanh ( ⋅ ) needs to have positive lower bound, a new type of auxiliary signal is introduced in this paper to handle the effect of input saturation and thus this limitation is released. Finally, two numerical examples and some comparisons are provided to illustrate our proposed controllers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002100",
    "keywords": [
      "Adaptive control",
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Fractional calculus",
      "Geometry",
      "Hyperbolic function",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Tangent"
    ],
    "authors": [
      {
        "surname": "Cao",
        "given_name": "Boqiang"
      },
      {
        "surname": "Nie",
        "given_name": "Xiaobing"
      }
    ]
  },
  {
    "title": "Generalized two-dimensional linear discriminant analysis with regularization",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.030",
    "abstract": "Recent advances show that two-dimensional linear discriminant analysis (2DLDA) is a successful matrix based dimensionality reduction method. However, 2DLDA may encounter the singularity issue theoretically, and also is sensitive to outliers. In this paper, a generalized Lp-norm 2DLDA framework with regularization for an arbitrary p > 0 is proposed, named G2DLDA. There are mainly two contributions of G2DLDA: one is G2DLDA model uses an arbitrary Lp-norm to measure the between-class and within-class scatter, and hence a proper p can be selected to achieve robustness. The other one is that the introduced regularization term makes G2DLDA enjoy better generalization performance and avoid singularity. In addition, an effective learning algorithm is designed for G2LDA, which can be solved through a series of convex problems with closed-form solutions. Its convergence can be guaranteed theoretically when 1 ≤ p ≤ 2 . Preliminary experimental results on three contaminated human face databases show the effectiveness of the proposed G2DLDA.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001672",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Covariance matrix",
      "Dimensionality reduction",
      "Discriminant",
      "Estimation of covariance matrices",
      "Gene",
      "Generalization error",
      "Geometry",
      "Law",
      "Linear discriminant analysis",
      "Mathematical analysis",
      "Mathematics",
      "Norm (philosophy)",
      "Outlier",
      "Pattern recognition (psychology)",
      "Political science",
      "Regular polygon",
      "Regularization (linguistics)",
      "Robustness (evolution)",
      "Scatter matrix",
      "Singularity"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Chun-Na"
      },
      {
        "surname": "Shao",
        "given_name": "Yuan-Hai"
      },
      {
        "surname": "Chen",
        "given_name": "Wei-Jie"
      },
      {
        "surname": "Wang",
        "given_name": "Zhen"
      },
      {
        "surname": "Deng",
        "given_name": "Nai-Yang"
      }
    ]
  },
  {
    "title": "Multiple clustering for identifying subject clusters and brain sub-networks using functional connectivity matrices without vectorization",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.016",
    "abstract": "In neuroscience, the functional magnetic resonance imaging (fMRI) is a vital tool to non-invasively access brain activity. Using fMRI, the functional connectivity (FC) between brain regions can be inferred, which has contributed to a number of findings of the fundamental properties of the brain. As an important clinical application of FC, clustering of subjects based on FC recently draws much attention, which can potentially reveal important heterogeneity in subjects such as subtypes of psychiatric disorders. In particular, a multiple clustering method is a powerful analytical tool, which identifies clustering patterns of subjects depending on their FC in specific brain areas. However, when one applies an existing multiple clustering method to fMRI data, there is a need to simplify the data structure, independently dealing with elements in a FC matrix, i.e., vectorizing a correlation matrix. Such a simplification may distort the clustering results. To overcome this problem, we propose a novel multiple clustering method based on Wishart mixture models, which preserves the correlation matrix structure without vectorization. The uniqueness of this method is that the multiple clustering of subjects is based on particular networks of nodes (or regions of interest, ROIs), optimized in a data-driven manner. Hence, it can identify multiple underlying pairs of associations between a subject cluster solution and a ROI sub-network. The key assumption of the method is independence among sub-networks, which is effectively addressed by whitening correlation matrices. We applied the proposed method to synthetic and fMRI data, demonstrating the usefulness and power of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002124",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Functional magnetic resonance imaging",
      "Neuroscience",
      "Pairwise comparison",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Vectorization (mathematics)"
    ],
    "authors": [
      {
        "surname": "Tokuda",
        "given_name": "Tomoki"
      },
      {
        "surname": "Yamashita",
        "given_name": "Okito"
      },
      {
        "surname": "Yoshimoto",
        "given_name": "Junichiro"
      }
    ]
  },
  {
    "title": "Residual wide-kernel deep convolutional auto-encoder for intelligent rotating machinery fault diagnosis with limited samples",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.003",
    "abstract": "This paper deals with the development of a novel deep learning framework to achieve highly accurate rotating machinery fault diagnosis using residual wide-kernel deep convolutional auto-encoder. Unlike most existing methods, in which the input data is processed by fast Fourier transform (FFT) and wavelet transform, this paper aims to learn important features from limited raw vibration signals. Firstly, the wide-kernel convolutional layer is introduced in the convolutional auto-encoder that can ensure the model can learn effective features from the data without any signal processing. Secondly, the residual learning block is introduced in convolutional auto-encoder that can ensure the model with sufficient depth without gradient vanishing and overfitting problems. Thirdly, convolutional auto-encoder can learn constructive features without massive data. To evaluate the performance of the proposed model, Case Western Reserve University (CWRU) bearing dataset and Southeast University (SEU) gearbox dataset are used to test. The experiment results and comparisons verify the denoising and feature extraction ability of the proposed model in the case of very few training samples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001301",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Autoencoder",
      "Combinatorics",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Kernel (algebra)",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Residual"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Daoguang"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      },
      {
        "surname": "Sun",
        "given_name": "Kangkang"
      }
    ]
  },
  {
    "title": "Residual wide-kernel deep convolutional auto-encoder for intelligent rotating machinery fault diagnosis with limited samples",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.003",
    "abstract": "This paper deals with the development of a novel deep learning framework to achieve highly accurate rotating machinery fault diagnosis using residual wide-kernel deep convolutional auto-encoder. Unlike most existing methods, in which the input data is processed by fast Fourier transform (FFT) and wavelet transform, this paper aims to learn important features from limited raw vibration signals. Firstly, the wide-kernel convolutional layer is introduced in the convolutional auto-encoder that can ensure the model can learn effective features from the data without any signal processing. Secondly, the residual learning block is introduced in convolutional auto-encoder that can ensure the model with sufficient depth without gradient vanishing and overfitting problems. Thirdly, convolutional auto-encoder can learn constructive features without massive data. To evaluate the performance of the proposed model, Case Western Reserve University (CWRU) bearing dataset and Southeast University (SEU) gearbox dataset are used to test. The experiment results and comparisons verify the denoising and feature extraction ability of the proposed model in the case of very few training samples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001301",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Autoencoder",
      "Combinatorics",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Kernel (algebra)",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Residual"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Daoguang"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      },
      {
        "surname": "Sun",
        "given_name": "Kangkang"
      }
    ]
  },
  {
    "title": "Saturated impulsive control for synchronization of coupled delayed neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.012",
    "abstract": "The paper focuses on the synchronization problem for a class of coupled neural networks with impulsive control, where the saturation structure of impulse action is fully considered. The coupled neural networks under consideration are subject to mixed delays including transmission delay and coupled delay. The sector condition in virtue of a new constraint of set inclusion is given for a addressed network, based on which a sufficient condition for exponential synchronization problem is obtained by replacing saturation nonlinearity with a dead-zone function. In the framework of saturated impulses, our results relying on the domain of attraction can still achieve the synchronization of coupled delayed neural networks. In addition, the estimating domain of attraction is proposed as large as possible by solving an optimization problem. Finally, a numerical simulation example is presented to demonstrate the effectiveness of the proposed results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001477",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Shuchen"
      },
      {
        "surname": "Li",
        "given_name": "Xiaodi"
      },
      {
        "surname": "Ding",
        "given_name": "Yanhui"
      }
    ]
  },
  {
    "title": "FastTalker: A neural text-to-speech architecture with shallow and group autoregression",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.016",
    "abstract": "Non-autoregressive architecture for neural text-to-speech (TTS) allows for parallel implementation, thus reduces inference time over its autoregressive counterpart. However, such system architecture does not explicitly model temporal dependency of acoustic signal as it generates individual acoustic frames independently. The lack of temporal modeling often adversely impacts speech continuity, thus voice quality. In this paper, we propose a novel neural TTS model that is denoted as FastTalker. We study two strategies for high-quality speech synthesis at low computational cost. First, we add a shallow autoregressive acoustic decoder on top of the non-autoregressive context decoder to retrieve the temporal information of the acoustic signal. Second, we further implement group autoregression to accelerate the inference of the autoregressive acoustic decoder. The group-based autoregression acoustic decoder generates acoustic features as a sequence of groups instead of frames, each group having multiple consecutive frames. Within a group, the acoustic features are generated in parallel. With the shallow and group autoregression, FastTalker retrieves the temporal information of the acoustic signal, while keeping the fast-decoding property. The proposed FastTalker achieves a good balance between speech quality and inference speed. Experiments show that, in terms of voice quality and naturalness, FastTalker outperforms the non-autoregressive FastSpeech baseline significantly, and is on par with the autoregressive baselines. It also shows a considerable inference speedup over Tacotron2 and Transformer TTS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001532",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Autoregressive model",
      "Computer science",
      "Decoding methods",
      "Inference",
      "Mathematics",
      "Speech recognition",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Rui"
      },
      {
        "surname": "Sisman",
        "given_name": "Berrak"
      },
      {
        "surname": "Lin",
        "given_name": "Yixing"
      },
      {
        "surname": "Li",
        "given_name": "Haizhou"
      }
    ]
  },
  {
    "title": "CutCat: An augmentation method for EEG classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.032",
    "abstract": "The non-invasive electroencephalogram (EEG) signals enable humans to communicate with devices and have control over them, this process requires precise classification and identification of those signals. The recent revolution of deep learning has empowered both feature extraction and classification in a joint manner of different data types. However, deep learning is a data learning approach that demands a large number of training samples. Whilst, the EEG research field lacks a large amount of data which restricts the use of deep learning within this field. This paper proposes a novel augmentation method for enlarging EEG datasets. Our CutCat augmentation method generates trials from inter- and intra-subjects and trials. The method relies on cutting a specific period from an EEG trial and concatenating it with a period from another trial from the same subject or different subjects. The method has been tested on shallow and deep convolutional neural networks (CNN) for the classification of motor imagery (MI) EEG data. Two input formulation types images and time-series have been used as input to the neural networks. Short-time Fourier transform (STFT) is used for generating training images from the time-series signals. The experimental results demonstrate that the proposed augmentation method is a promising strategy for handling the classification of small-scale datasets. Classification results on two EEG datasets show advancement in comparison with the results of state-of-the-art researches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002288",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Botany",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Electroencephalography",
      "Feature extraction",
      "Field (mathematics)",
      "Identification (biology)",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Psychiatry",
      "Psychology",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Al-Saegh",
        "given_name": "Ali"
      },
      {
        "surname": "Dawwd",
        "given_name": "Shefa A."
      },
      {
        "surname": "Abdul-Jabbar",
        "given_name": "Jassim M."
      }
    ]
  },
  {
    "title": "Reducing bias to source samples for unsupervised domain adaptation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.021",
    "abstract": "Unsupervised Domain Adaptation (UDA) makes predictions for the target domain data while labels are only available in the source domain. Lots of works in UDA focus on finding a common representation of the two domains via domain alignment, assuming that a classifier trained in the source domain can be generalized well to the target domain. Thus, most existing UDA methods only consider minimizing the domain discrepancy without enforcing any constraint on the classifier. However, due to the uniqueness of each domain, it is difficult to achieve a perfect common representation, especially when there is low similarity between the source domain and the target domain. As a consequence, the classifier is biased to the source domain features and makes incorrect predictions on the target domain. To address this issue, we propose a novel approach named reducing bias to source samples for unsupervised domain adaptation (RBDA) by jointly matching the distribution of the two domains and reducing the classifier’s bias to source samples. Specifically, RBDA first conditions the adversarial networks with the cross-covariance of learned features and classifier predictions to match the distribution of two domains. Then to reduce the classifier’s bias to source samples, RBDA is designed with three effective mechanisms: a mean teacher model to guide the training of the original model, a regularization term to regularize the model and an improved cross-entropy loss for better supervised information learning. Comprehensive experiments on several open benchmarks demonstrate that RBDA achieves state-of-the-art results, which show its effectiveness for unsupervised domain adaptation scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100109X",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Ye",
        "given_name": "Yalan"
      },
      {
        "surname": "Huang",
        "given_name": "Ziwei"
      },
      {
        "surname": "Pan",
        "given_name": "Tongjie"
      },
      {
        "surname": "Li",
        "given_name": "Jingjing"
      },
      {
        "surname": "Shen",
        "given_name": "Heng Tao"
      }
    ]
  },
  {
    "title": "A deep network construction that adapts to intrinsic dimensionality beyond the domain",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.06.004",
    "abstract": "We study the approximation of two-layer compositions f ( x ) = g ( ϕ ( x ) ) via deep networks with ReLU activation, where ϕ is a geometrically intuitive, dimensionality reducing feature map. We focus on two intuitive and practically relevant choices for ϕ : the projection onto a low-dimensional embedded submanifold and a distance to a collection of low-dimensional sets. We achieve near optimal approximation rates, which depend only on the complexity of the dimensionality reducing map ϕ rather than the ambient dimension. Since ϕ encapsulates all nonlinear features that are material to the function f , this suggests that deep nets are faithful to an intrinsic dimension governed by f rather than the complexity of the domain of f . In particular, the prevalent assumption of approximating functions on low-dimensional manifolds can be significantly relaxed using functions of type f ( x ) = g ( ϕ ( x ) ) with ϕ representing an orthogonal projection onto the same manifold.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002367",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Curse of dimensionality",
      "Dimension (graph theory)",
      "Dimensionality reduction",
      "Domain (mathematical analysis)",
      "Engineering",
      "Evolutionary biology",
      "Feature (linguistics)",
      "Focus (optics)",
      "Function (biology)",
      "Intrinsic dimension",
      "Linguistics",
      "Manifold (fluid mechanics)",
      "Mathematical analysis",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Optics",
      "Philosophy",
      "Physics",
      "Projection (relational algebra)",
      "Pure mathematics",
      "Submanifold",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Cloninger",
        "given_name": "Alexander"
      },
      {
        "surname": "Klock",
        "given_name": "Timo"
      }
    ]
  },
  {
    "title": "CRaDLe: Deep code retrieval based on semantic Dependency Learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.019",
    "abstract": "Code retrieval is a common practice for programmers to reuse existing code snippets in the open-source repositories. Given a user query (i.e., a natural language description), code retrieval aims at searching the most relevant ones from a set of code snippets. The main challenge of effective code retrieval lies in mitigating the semantic gap between natural language descriptions and code snippets. With the ever-increasing amount of available open-source code, recent studies resort to neural networks to learn the semantic matching relationships between the two sources. The statement-level dependency information, which highlights the dependency relations among the program statements during the execution, reflects the structural importance of one statement in the code, which is favorable for accurately capturing the code semantics but has never been explored for the code retrieval task. In this paper, we propose CRaDLe, a novel approach for Code Retrieval based on statement-level semantic Dependency Learning. Specifically, CRaDLe distills code representations through fusing both the dependency and semantic information at the statement level, and then learns a unified vector representation for each code and description pair for modeling the matching relationship. Comprehensive experiments and analysis on real-world datasets show that the proposed approach can accurately retrieve code snippets for a given query and significantly outperform the state-of-the-art approaches on the task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001568",
    "keywords": [
      "Artificial intelligence",
      "Code (set theory)",
      "Computer science",
      "Dependency (UML)",
      "Economics",
      "Information retrieval",
      "Law",
      "Management",
      "Matching (statistics)",
      "Mathematics",
      "Natural language processing",
      "Political science",
      "Programming language",
      "Semantic matching",
      "Semantics (computer science)",
      "Set (abstract data type)",
      "Source code",
      "Statement (logic)",
      "Statistics",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Gu",
        "given_name": "Wenchao"
      },
      {
        "surname": "Li",
        "given_name": "Zongjie"
      },
      {
        "surname": "Gao",
        "given_name": "Cuiyun"
      },
      {
        "surname": "Wang",
        "given_name": "Chaozheng"
      },
      {
        "surname": "Zhang",
        "given_name": "Hongyu"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      },
      {
        "surname": "Lyu",
        "given_name": "Michael R."
      }
    ]
  },
  {
    "title": "Deep ANC: A deep learning approach to active noise control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.037",
    "abstract": "Traditional active noise control (ANC) methods are based on adaptive signal processing with the least mean square algorithm as the foundation. They are linear systems and do not perform satisfactorily in the presence of nonlinear distortions. In this paper, we formulate ANC as a supervised learning problem and propose a deep learning approach, called deep ANC, to address the nonlinear ANC problem. The main idea is to employ deep learning to encode the optimal control parameters corresponding to different noises and environments. A convolutional recurrent network (CRN) is trained to estimate the real and imaginary spectrograms of the canceling signal from the reference signal so that the corresponding anti-noise can eliminate or attenuate the primary noise in the ANC system. Large-scale multi-condition training is employed to achieve good generalization and robustness against a variety of noises. The deep ANC method can be trained to achieve active noise cancellation no matter whether the reference signal is noise or noisy speech. In addition, a delay-compensated strategy is introduced to solve the potential latency problem of ANC systems. Experimental results show that deep ANC is effective for wideband noise reduction and generalizes well to untrained noises. Moreover, the proposed method can achieve ANC within a quiet zone and is robust against variations in reference signals.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001258",
    "keywords": [
      "Active noise control",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Gene",
      "Image (mathematics)",
      "Noise (video)",
      "Noise measurement",
      "Noise reduction",
      "Robustness (evolution)",
      "Spectrogram",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Hao"
      },
      {
        "surname": "Wang",
        "given_name": "DeLiang"
      }
    ]
  },
  {
    "title": "A neuralized feature engineering method for entity relation extraction",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.010",
    "abstract": "Making full use of semantic and structure information in a sentence is critical to support entity relation extraction. Neural networks use stacked neural layers to perform designated feature transformations and can automatically extract high-order abstract feature representations from raw inputs. However, because a sentence usually contains several pairs of named entities, the networks are weak when encoding semantic and structure information of a relation instance. In this paper, we propose a neuralized feature engineering approach for entity relation extraction. This approach enhances the neural network by manually designed features, which have the advantage of using prior knowledge and experience developed in feature-based models. Neuralized feature engineering encodes manually designed features into distributed representations to increase the discriminability of a neural network. Experiments show that this approach considerably improves the performance compared to that of neural networks or feature-based models alone, exceeding state-of-the-art performance by more than 8% and 16.5% in terms of F1-score on the ACE corpus and the Chinese literature text corpus, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001453",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Encoding (memory)",
      "Feature (linguistics)",
      "Feature engineering",
      "Feature extraction",
      "Linguistics",
      "Natural language processing",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Relation (database)",
      "Relationship extraction",
      "Semantic feature",
      "Sentence"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Yanping"
      },
      {
        "surname": "Yang",
        "given_name": "Weizhe"
      },
      {
        "surname": "Wang",
        "given_name": "Kai"
      },
      {
        "surname": "Qin",
        "given_name": "Yongbin"
      },
      {
        "surname": "Huang",
        "given_name": "Ruizhang"
      },
      {
        "surname": "Zheng",
        "given_name": "Qinghua"
      }
    ]
  },
  {
    "title": "Deep joint learning for language recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.026",
    "abstract": "Deep learning methods for language recognition have achieved promising performance. However, most of the studies focus on frameworks for single types of acoustic features and single tasks. In this paper, we propose the deep joint learning strategies based on the Multi-Feature (MF) and Multi-Task (MT) models. First, we investigate the efficiency of integrating multiple acoustic features and explore two kinds of training constraints, one is introducing auxiliary classification constraints with adaptive weights for loss functions in feature encoder sub-networks, and the other option is introducing the Canonical Correlation Analysis (CCA) constraint to maximize the correlation of different feature representations. Correlated speech tasks, such as phoneme recognition, are applied as auxiliary tasks in order to learn related information to enhance the performance of language recognition. We analyze phoneme-aware information from different learning strategies, like joint learning on the frame-level, adversarial learning on the segment-level, and the combination mode. In addition, we present the Language-Phoneme embedding extraction structure to learn and extract language and phoneme embedding representations simultaneously. We demonstrate the effectiveness of the proposed approaches with experiments on the Oriental Language Recognition (OLR) data sets. Experimental results indicate that joint learning on the multi-feature and multi-task models extracts instinct feature representations for language identities and improves the performance, especially in complex challenges, such as cross-channel or open-set conditions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001143",
    "keywords": [
      "Architectural engineering",
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Engineering",
      "Joint (building)",
      "Natural language processing",
      "Pattern recognition (psychology)",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Lin"
      },
      {
        "surname": "Li",
        "given_name": "Zheng"
      },
      {
        "surname": "Liu",
        "given_name": "Yan"
      },
      {
        "surname": "Hong",
        "given_name": "Qingyang"
      }
    ]
  },
  {
    "title": "Synchronization for stochastic coupled networks with Lévy noise via event-triggered control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.028",
    "abstract": "This paper addresses the realization of almost sure synchronization problem for a new array of stochastic networks associated with delay and Lévy noise via event-triggered control. The coupling structure of the network is governed by a continuous-time homogeneous Markov chain. The nodes in the networks communicate with each other and update their information only at discrete-time instants so that the network workload can be minimized. Under the framework of stochastic process including Markov chain and Lévy process, and the convergence theorem of non-negative semi-martingales, we show that the Markovian coupled networks can achieve the almost sure synchronization by event-triggered control methodology. The results are further extended to the directed topology, where the coupling structure can be asymmetric. Furthermore, we also proved that the Zeno behavior can be excluded under our proposed approach, indicating that our framework is practically feasible. Numerical simulations are provided to demonstrate the effectiveness of the obtained theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001167",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Image (mathematics)",
      "Machine learning",
      "Markov chain",
      "Markov process",
      "Mathematics",
      "Noise (video)",
      "Realization (probability)",
      "Statistics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Dong",
        "given_name": "Hailing"
      },
      {
        "surname": "Luo",
        "given_name": "Ming"
      },
      {
        "surname": "Xiao",
        "given_name": "Mingqing"
      }
    ]
  },
  {
    "title": "Modeling the grid cell activity on non-horizontal surfaces based on oscillatory interference modulated by gravity",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.009",
    "abstract": "Internal representation of the space is a fundamental and crucial function of the animal’s brain. Grid cells in the medial entorhinal cortex are thought to provide an environment-invariant metric system for the navigation of the animal. Most experimental and theoretical studies have focused on the horizontal planar codes of grid cell, while how this metric coordinate system is configured in the actual three-dimensional space remains unclear. Evidence has implied the spatial cognition may not be fully volumetric. We proposed an oscillatory interference model with a novel gravity and body plane modulation to simulate grid cell activity in complex space for rodents. The animal can perceive the rotation of its body plane along the local surface by sensing the gravity, causing the modulation to the dendritic oscillations. The results not only reproduce the firing patterns of the grid cell recorded from known experiments, but also predict the grid codes in novel environments. It further demonstrates that the gravity signal is indispensable for the animal’s navigation, and supports the hypothesis that the periodic firing of the grid cell is intrinsically not a volumetric code in three-dimensional space. This will provide new insights to understand the spatial representation of the actual world in the brain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001441",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Cognition",
      "Combinatorics",
      "Computer graphics (images)",
      "Computer science",
      "Geometry",
      "Grid",
      "Hippocampus",
      "Horizontal plane",
      "Law",
      "Mathematics",
      "Neuroscience",
      "Path integration",
      "Physics",
      "Place cell",
      "Planar",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Spatial memory",
      "Topology (electrical circuits)",
      "Working memory"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yihong"
      },
      {
        "surname": "Xu",
        "given_name": "Xuying"
      },
      {
        "surname": "Wang",
        "given_name": "Rubin"
      }
    ]
  },
  {
    "title": "Radon–Sobolev Variational Auto-Encoders",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.018",
    "abstract": "The quality of generative models (such as Generative adversarial networks and Variational Auto-Encoders) depends heavily on the choice of a good probability distance. However some popular metrics like the Wasserstein or the Sliced Wasserstein distances, the Jensen–Shannon divergence, the Kullback–Leibler divergence, lack convenient properties such as (geodesic) convexity, fast evaluation and so on. To address these shortcomings, we introduce a class of distances that have built-in convexity. We investigate the relationship with some known paradigms (sliced distances – a synonym for Radon distances – reproducing kernel Hilbert spaces, energy distances). The distances are shown to possess fast implementations and are included in an adapted Variational Auto-Encoder termed Radon–Sobolev Variational Auto-Encoder (RS-VAE) which produces high quality results on standard generative datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001556",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Computer science",
      "Convexity",
      "Divergence (linguistics)",
      "Economics",
      "Financial economics",
      "Geodesic",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Philosophy",
      "Sobolev space"
    ],
    "authors": [
      {
        "surname": "Turinici",
        "given_name": "Gabriel"
      }
    ]
  },
  {
    "title": "Combination of deep speaker embeddings for diarisation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.020",
    "abstract": "Significant progress has recently been made in speaker diarisation after the introduction of d-vectors as speaker embeddings extracted from neural network (NN) speaker classifiers for clustering speech segments. To extract better-performing and more robust speaker embeddings, this paper proposes a c-vector method by combining multiple sets of complementary d-vectors derived from systems with different NN components. Three structures are used to implement the c-vectors, namely 2D self-attentive, gated additive, and bilinear pooling structures, relying on attention mechanisms, a gating mechanism, and a low-rank bilinear pooling mechanism respectively. Furthermore, a neural-based single-pass speaker diarisation pipeline is also proposed in this paper, which uses NNs to achieve voice activity detection, speaker change point detection, and speaker embedding extraction. Experiments and detailed analyses are conducted on the challenging AMI and NIST RT05 datasets which consist of real meetings with 4–10 speakers and a wide range of acoustic conditions. For systems trained on the AMI training set, relative speaker error rate (SER) reductions of 13% and 29% are obtained by using c-vectors instead of d-vectors on the AMI dev and eval sets respectively, and a relative SER reduction of 15% in SER is observed on RT05, which shows the robustness of the proposed methods. By incorporating VoxCeleb data into the training set, the best c-vector system achieved 7%, 17% and 16% relative SER reduction compared to the d-vector on the AMI dev, eval and RT05 sets respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100157X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bilinear interpolation",
      "Biochemistry",
      "Chemistry",
      "Cluster analysis",
      "Computer science",
      "Computer vision",
      "Embedding",
      "Gene",
      "NIST",
      "Pattern recognition (psychology)",
      "Pipeline (software)",
      "Pooling",
      "Programming language",
      "Robustness (evolution)",
      "Speaker diarisation",
      "Speaker recognition",
      "Speech recognition",
      "Word error rate"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Guangzhi"
      },
      {
        "surname": "Zhang",
        "given_name": "Chao"
      },
      {
        "surname": "Woodland",
        "given_name": "Philip C."
      }
    ]
  },
  {
    "title": "Multi-periodicity of switched neural networks with time delays and periodic external inputs under stochastic disturbances",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.039",
    "abstract": "This paper presents new theoretical results on the multi-periodicity of recurrent neural networks with time delays evoked by periodic inputs under stochastic disturbances and state-dependent switching. Based on the geometric properties of activation function and switching threshold, the neuronal state space is partitioned into 5 n regions in which 3 n ones are shown to be positively invariant with probability one. Furthermore, by using Itô’s formula, Lyapunov functional method, and the contraction mapping theorem, two criteria are proposed to ascertain the existence and mean-square exponential stability of a periodic orbit in every positive invariant set. As a result, the number of mean-square exponentially stable periodic orbits increases to 3 n from 2 n in a neural network without switching. Two illustrative examples are elaborated to substantiate the efficacy and characteristics of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001271",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Contraction (grammar)",
      "Control (management)",
      "Control theory (sociology)",
      "Exponential growth",
      "Exponential stability",
      "Internal medicine",
      "Invariant (physics)",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical physics",
      "Mathematics",
      "Mean square",
      "Medicine",
      "Nonlinear system",
      "Periodic orbits",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "State space",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Zhenyuan"
      },
      {
        "surname": "Ci",
        "given_name": "Jingxuan"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "QTTNet: Quantized tensor train neural networks for 3D object and video recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.034",
    "abstract": "Relying on the rapidly increasing capacity of computing clusters and hardware, convolutional neural networks (CNNs) have been successfully applied in various fields and achieved state-of-the-art results. Despite these exciting developments, the huge memory cost is still involved in training and inferring a large-scale CNN model and makes it hard to be widely used in resource-limited portable devices. To address this problem, we establish a training framework for three-dimensional convolutional neural networks (3DCNNs) named QTTNet that combines tensor train (TT) decomposition and data quantization together for further shrinking the model size and decreasing the memory and time cost. Through this framework, we can fully explore the superiority of TT in reducing the number of trainable parameters and the advantage of quantization in decreasing the bit-width of data, particularly compressing 3DCNN model greatly with little accuracy degradation. In addition, due to the low bit quantization to all parameters during the inference process including TT-cores, activations, and batch normalizations, the proposed method naturally takes advantage in memory and time cost. Experimental results of compressing 3DCNNs for 3D object and video recognition on ModelNet40, UCF11, and UCF50 datasets verify the effectiveness of the proposed method. The best compression ratio we have obtained is up to nearly 180 × with competitive performance compared with other state-of-the-art researches. Moreover, the total bytes of our QTTNet models on ModelNet40 and UCF11 datasets can be 1000 × lower than some typical practices such as MVCNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021002306",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Byte",
      "Computer engineering",
      "Computer hardware",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Inference",
      "Pattern recognition (psychology)",
      "Quantization (signal processing)"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Donghyun"
      },
      {
        "surname": "Wang",
        "given_name": "Dingheng"
      },
      {
        "surname": "Yang",
        "given_name": "Yukuan"
      },
      {
        "surname": "Deng",
        "given_name": "Lei"
      },
      {
        "surname": "Zhao",
        "given_name": "Guangshe"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      }
    ]
  },
  {
    "title": "A neuralized feature engineering method for entity relation extraction",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.010",
    "abstract": "Making full use of semantic and structure information in a sentence is critical to support entity relation extraction. Neural networks use stacked neural layers to perform designated feature transformations and can automatically extract high-order abstract feature representations from raw inputs. However, because a sentence usually contains several pairs of named entities, the networks are weak when encoding semantic and structure information of a relation instance. In this paper, we propose a neuralized feature engineering approach for entity relation extraction. This approach enhances the neural network by manually designed features, which have the advantage of using prior knowledge and experience developed in feature-based models. Neuralized feature engineering encodes manually designed features into distributed representations to increase the discriminability of a neural network. Experiments show that this approach considerably improves the performance compared to that of neural networks or feature-based models alone, exceeding state-of-the-art performance by more than 8% and 16.5% in terms of F1-score on the ACE corpus and the Chinese literature text corpus, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001453",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Encoding (memory)",
      "Feature (linguistics)",
      "Feature engineering",
      "Feature extraction",
      "Linguistics",
      "Natural language processing",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Relation (database)",
      "Relationship extraction",
      "Semantic feature",
      "Sentence"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Yanping"
      },
      {
        "surname": "Yang",
        "given_name": "Weizhe"
      },
      {
        "surname": "Wang",
        "given_name": "Kai"
      },
      {
        "surname": "Qin",
        "given_name": "Yongbin"
      },
      {
        "surname": "Huang",
        "given_name": "Ruizhang"
      },
      {
        "surname": "Zheng",
        "given_name": "Qinghua"
      }
    ]
  },
  {
    "title": "Autoencoder networks extract latent variables and encode these variables in their connectomes",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.010",
    "abstract": "Advances in electron microscopy and data processing techniques are leading to increasingly large and complete microscale connectomes. At the same time, advances in artificial neural networks have produced model systems that perform comparably rich computations with perfectly specified connectivity. This raises an exciting scientific opportunity for the study of both biological and artificial neural networks: to infer the underlying circuit function from the structure of its connectivity. A potential roadblock, however, is that – even with well constrained neural dynamics – there are in principle many different connectomes that could support a given computation. Here, we define a tractable setting in which the problem of inferring circuit function from circuit connectivity can be analyzed in detail: the function of input compression and reconstruction, in an autoencoder network with a single hidden layer. Here, in general there is substantial ambiguity in the weights that can produce the same circuit function, because largely arbitrary changes to input weights can be undone by applying the inverse modifications to the output weights. However, we use mathematical arguments and simulations to show that adding simple, biologically motivated regularization of connectivity resolves this ambiguity in an interesting way: weights are constrained such that the latent variable structure underlying the inputs can be extracted from the weights by using nonlinear dimensionality reduction methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000903",
    "keywords": [
      "Algorithm",
      "Ambiguity",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Biology",
      "Computer science",
      "Connectome",
      "Functional connectivity",
      "Inverse problem",
      "Latent variable",
      "Mathematical analysis",
      "Mathematics",
      "Neuroscience",
      "Programming language",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Farrell",
        "given_name": "Matthew"
      },
      {
        "surname": "Recanatesi",
        "given_name": "Stefano"
      },
      {
        "surname": "Reid",
        "given_name": "R. Clay"
      },
      {
        "surname": "Mihalas",
        "given_name": "Stefan"
      },
      {
        "surname": "Shea-Brown",
        "given_name": "Eric"
      }
    ]
  },
  {
    "title": "Unsupervised foveal vision neural architecture with top-down attention",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.003",
    "abstract": "Deep learning architectures are an extremely powerful tool for recognizing and classifying images. However, they require supervised learning and normally work on vectors of the size of image pixels and produce the best results when trained on millions of object images. To help mitigate these issues, we propose an end-to-end architecture that fuses bottom-up saliency and top-down attention with an object recognition module to focus on relevant data and learn important features that can later be fine-tuned for a specific task, employing only unsupervised learning. In addition, by utilizing a virtual fovea that focuses on relevant portions of the data, the training speed can be greatly improved. We test the performance of the proposed Gamma saliency technique on the Toronto and CAT 2000 databases, and the foveated vision in the large Street View House Numbers (SVHN) database. The results with foveated vision show that Gamma saliency performs at the same level as the best alternative algorithms while being computationally faster. The results in SVHN show that our unsupervised cognitive architecture is comparable to fully supervised methods and that saliency also improves CNN performance if desired. Finally, we develop and test a top-down attention mechanism based on the Gamma saliency applied to the top layer of CNNs to facilitate scene understanding in multi-object cluttered images. We show that the extra information from top-down saliency is capable of speeding up the extraction of digits in the cluttered multidigit MNIST data set, corroborating the important role of top down attention.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000836",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Cognitive neuroscience of visual object recognition",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Economics",
      "Foveal",
      "MNIST database",
      "Management",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Pixel",
      "Programming language",
      "Retinal",
      "Set (abstract data type)",
      "Task (project management)",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Burt",
        "given_name": "Ryan"
      },
      {
        "surname": "Thigpen",
        "given_name": "Nina N."
      },
      {
        "surname": "Keil",
        "given_name": "Andreas"
      },
      {
        "surname": "Principe",
        "given_name": "Jose C."
      }
    ]
  },
  {
    "title": "Emulation of wildland fire spread simulation using deep learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.006",
    "abstract": "Numerical simulation of wildland fire spread is useful to predict the locations that are likely to burn and to support decision in an operational context, notably for crisis situations and long-term planning. For short-term, the computational time of traditional simulators is too high to be tractable over large zones like a country or part of a country, especially for fire danger mapping. This issue is tackled by emulating the area of the burned surface returned after simulation of a fire igniting anywhere in Corsica island and spreading freely during one hour, with a wide range of possible environmental input conditions. A deep neural network with a hybrid architecture is used to account for two types of inputs: the spatial fields describing the surrounding landscape and the remaining scalar inputs. After training on a large simulation dataset, the network shows a satisfactory approximation error on a complementary test dataset with a MAPE of 32.8%. The convolutional part is pre-computed and the emulator is defined as the remaining part of the network, saving significant computational time. On a 32-core machine, the emulator has a speed-up factor of several thousands compared to the simulator and the overall relationship between its inputs and output is consistent with the expected physical behavior of fire spread. This reduction in computational time allows the computation of one-hour burned area map for the whole island of Corsica in less than a minute, opening new application in short-term fire danger mapping.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001337",
    "keywords": [
      "Algorithm",
      "Archaeology",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computation",
      "Computer science",
      "Context (archaeology)",
      "Convolutional neural network",
      "Deep learning",
      "Economic growth",
      "Economics",
      "Emulation",
      "Geography",
      "Geometry",
      "Materials science",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Reduction (mathematics)",
      "Simulation",
      "Term (time)"
    ],
    "authors": [
      {
        "surname": "Allaire",
        "given_name": "Frédéric"
      },
      {
        "surname": "Mallet",
        "given_name": "Vivien"
      },
      {
        "surname": "Filippi",
        "given_name": "Jean-Baptiste"
      }
    ]
  },
  {
    "title": "Generative Adversarial Network with Multi-branch Discriminator for imbalanced cross-species image-to-image translation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.013",
    "abstract": "There has been an increased interest in high-level image-to-image translation to achieve semantic matching. Through a powerful translation model, we can efficiently synthesize high-quality images with diverse appearances while retaining semantic matching. In this paper, we address an imbalanced learning problem using a cross-species image-to-image translation. We aim to perform the data augmentation through the image translation to boost the recognition performance of imbalanced learning. It requires a strong ability of the model to perform a biomorphic transformation on a semantic level. To tackle this problem, we propose a novel, simple, and effective structure of Multi-Branch Discriminator (termed as MBD) based on Generative Adversarial Networks (GANs). We demonstrate the effectiveness of the proposed MBD through theoretical analysis as well as empirical evaluation. We provide theoretical proof of why the proposed MBD is an effective and optimal case to achieve remarkable performance. Comprehensive experiments on various cross-species image translation tasks illustrate that our MBD can dramatically promote the performance of popular GANs with state-of-the-art results in terms of both objective and subjective assessments. Extensive downstream image recognition evaluations at a few-shot setting have also been conducted to demonstrate that the proposed method can effectively boost the performance of imbalanced learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001507",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Detector",
      "Discriminator",
      "Gene",
      "Generative grammar",
      "Image (mathematics)",
      "Image translation",
      "Machine learning",
      "Matching (statistics)",
      "Mathematics",
      "Messenger RNA",
      "Pattern recognition (psychology)",
      "Statistics",
      "Telecommunications",
      "Transformation (genetics)",
      "Translation (biology)"
    ],
    "authors": [
      {
        "surname": "Zheng",
        "given_name": "Ziqiang"
      },
      {
        "surname": "Yu",
        "given_name": "Zhibin"
      },
      {
        "surname": "Wu",
        "given_name": "Yang"
      },
      {
        "surname": "Zheng",
        "given_name": "Haiyong"
      },
      {
        "surname": "Zheng",
        "given_name": "Bing"
      },
      {
        "surname": "Lee",
        "given_name": "Minho"
      }
    ]
  },
  {
    "title": "Combining a parallel 2D CNN with a self-attention Dilated Residual Network for CTC-based discrete speech emotion recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.013",
    "abstract": "A challenging issue in the field of the automatic recognition of emotion from speech is the efficient modelling of long temporal contexts. Moreover, when incorporating long-term temporal dependencies between features, recurrent neural network (RNN) architectures are typically employed by default. In this work, we aim to present an efficient deep neural network architecture incorporating Connectionist Temporal Classification (CTC) loss for discrete speech emotion recognition (SER). Moreover, we also demonstrate the existence of further opportunities to improve SER performance by exploiting the properties of convolutional neural networks (CNNs) when modelling contextual information. Our proposed model uses parallel convolutional layers (PCN) integrated with Squeeze-and-Excitation Network (SEnet), a system herein denoted as PCNSE, to extract relationships from 3D spectrograms across timesteps and frequencies; here, we use the log-Mel spectrogram with deltas and delta–deltas as input. In addition, a self-attention Residual Dilated Network (SADRN) with CTC is employed as a classification block for SER. To the best of the authors’ knowledge, this is the first time that such a hybrid architecture has been employed for discrete SER. We further demonstrate the effectiveness of our proposed approach on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) and FAU-Aibo Emotion corpus (FAU-AEC). Our experimental results reveal that the proposed method is well-suited to the task of discrete SER, achieving a weighted accuracy (WA) of 73.1% and an unweighted accuracy (UA) of 66.3% on IEMOCAP, as well as a UA of 41.1% on the FAU-AEC dataset.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000939",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Emotion recognition",
      "Pattern recognition (psychology)",
      "Residual",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Ziping"
      },
      {
        "surname": "Li",
        "given_name": "Qifei"
      },
      {
        "surname": "Zhang",
        "given_name": "Zixing"
      },
      {
        "surname": "Cummins",
        "given_name": "Nicholas"
      },
      {
        "surname": "Wang",
        "given_name": "Haishuai"
      },
      {
        "surname": "Tao",
        "given_name": "Jianhua"
      },
      {
        "surname": "W. Schuller",
        "given_name": "Björn"
      }
    ]
  },
  {
    "title": "Bifurcations in a fractional-order BAM neural network with four different delays",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.005",
    "abstract": "This paper illuminates the issue of bifurcations for a fractional-order bidirectional associative memory neural network(FOBAMNN) with four different delays. On account of the affirmatory presumption, the developed FOBAMNN is firstly transformed into the one with two nonidentical delays. Then the critical values of Hopf bifurcations with respect to disparate delays are calculated quantitatively by establishing one delay and selecting remaining delay as a bifurcation parameter in the transformed model. It detects that the stability of the developed FOBAMNN with multiple delays can be fairly preserved if selecting lesser control delays, and Hopf bifurcation emerges once the control delays outnumber their critical values. The derived bifurcation results are numerically testified via the bifurcation graphs. The feasibility of theoretical analysis is ultimately corroborated in the light of simulation experiments. The analytic results available in this paper are beneficial to give impetus to resolve the issues of bifurcations of high-order FONNs with multiple delays.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001325",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bidirectional associative memory",
      "Bifurcation",
      "Bifurcation diagram",
      "Computer science",
      "Content-addressable memory",
      "Control (management)",
      "Control theory (sociology)",
      "Economics",
      "Finance",
      "Hopf bifurcation",
      "Law",
      "Machine learning",
      "Mathematics",
      "Nonlinear system",
      "Order (exchange)",
      "Physics",
      "Political science",
      "Presumption",
      "Quantum mechanics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Chengdai"
      },
      {
        "surname": "Wang",
        "given_name": "Juan"
      },
      {
        "surname": "Chen",
        "given_name": "Xiaoping"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "A dual-stream deep attractor network with multi-domain learning for speech dereverberation and separation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.023",
    "abstract": "Deep attractor networks (DANs) perform speech separation with discriminative embeddings and speaker attractors. Compared with methods based on the permutation invariant training (PIT), DANs define a deep embedding space and deliver a more elaborate representation on each time–frequency (T–F) bin. However, it has been observed that the DANs achieve limited improvement on the signal quality if directly deployed in a reverberant environment. Following the success of time-domain separation networks on the clean mixture speech, we propose a dual-stream DAN with multi-domain learning to efficiently perform both dereverberation and separation tasks under the condition of variable numbers of speakers. The speaker encoding stream (SES) of the dual-stream DAN is trained to model the speaker information in the embedding space defined with the Fourier transform kernels. The speech decoding stream (SDS) accepts speaker attractors from the SES and learns to estimate the early component of the sound in the time domain. Meanwhile, additional clustering losses are used to bridge the gap between the oracle and the estimated attractors. Experiments were conducted on the Spatialized Multi-Speaker Wall Street Journal (SMS-WSJ) dataset. After comparing with the anechoic and reverberant signals, the early component was chosen as the learning targets. The experimental results demonstrated that the dual-stream DAN achieved scale-invariant source-to-distortion ratio (SI-SDR) improvement of 9 . 8 ∕ 7 . 5 dB on the reverberant 2-/3-speaker evaluation set, exceeding the baseline DAN and convolutional time-domain audio separation network (Conv-TasNet) by 2 . 0 ∕ 0 . 7 dB and 1 . 0 ∕ 0 . 5 dB, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100160X",
    "keywords": [
      "Acoustics",
      "Artificial intelligence",
      "Attractor",
      "Computer science",
      "Deep learning",
      "Discriminative model",
      "Embedding",
      "Hidden Markov model",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Physics",
      "Reverberation",
      "Speech recognition",
      "TIMIT"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Hangting"
      },
      {
        "surname": "Zhang",
        "given_name": "Pengyuan"
      }
    ]
  },
  {
    "title": "Exponential quasi-synchronization of coupled delayed memristive neural networks via intermittent event-triggered control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.013",
    "abstract": "Firstly, an intermittent event-triggered control (IETC), as a combination of intermittent control and event-triggered control, is proposed. Then, the quasi-synchronization problem of coupled memristive neural networks with time-varying delays (CDMNN) is discussed under this IETC. To include more of the existing work, aperiodic intermittent control and event-triggered control with combined measurement errors are adopted in the IETC. Under the IETC, it is shown that Zeno behavior cannot be exhibited for CDMNN. At the same time, two new differential inequalities are established, and some simple and practical criteria for CDMNN quasi-synchronization and synchronization are obtained by using these inequalities. In the obtained results, synchronization is a spatial case of quasi-synchronization, and the activation functions of DMNN do not need to be bounded. Finally, a numerical example and some simulations are provided to test the results in theoretical analysis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000216",
    "keywords": [
      "Agronomy",
      "Aperiodic graph",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Engineering",
      "Intermittent control",
      "Mathematical analysis",
      "Mathematics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Jiejie"
      },
      {
        "surname": "Chen",
        "given_name": "Boshan"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "PC-GAIN: Pseudo-label conditional generative adversarial imputation networks for incomplete data",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.033",
    "abstract": "Datasets with missing values are very common in real world applications. GAIN, a recently proposed deep generative model for missing data imputation, has been proved to outperform many state-of-the-art methods. But GAIN only uses a reconstruction loss in the generator to minimize the imputation error of the non-missing part, ignoring the potential category information which can reflect the relationship between samples. In this paper, we propose a novel unsupervised missing data imputation method named PC-GAIN, which utilizes potential category information to further enhance the imputation power. Specifically, we first propose a pre-training procedure to learn potential category information contained in a subset of low-missing-rate data. Then an auxiliary classifier is determined using the synthetic pseudo-labels. Further, this classifier is incorporated into the generative adversarial framework to help the generator to yield higher quality imputation results. The proposed method can improve the imputation quality of GAIN significantly. Experimental results on various benchmark datasets show that our method is also superior to other baseline approaches. Our code is available at https://github.com/WYu-Feng/pc-gain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100229X",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Generative adversarial network",
      "Generative grammar",
      "Imputation (statistics)",
      "Information gain",
      "Machine learning",
      "Missing data",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yufeng"
      },
      {
        "surname": "Li",
        "given_name": "Dan"
      },
      {
        "surname": "Li",
        "given_name": "Xiang"
      },
      {
        "surname": "Yang",
        "given_name": "Min"
      }
    ]
  },
  {
    "title": "PC-GAIN: Pseudo-label conditional generative adversarial imputation networks for incomplete data",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.05.033",
    "abstract": "Datasets with missing values are very common in real world applications. GAIN, a recently proposed deep generative model for missing data imputation, has been proved to outperform many state-of-the-art methods. But GAIN only uses a reconstruction loss in the generator to minimize the imputation error of the non-missing part, ignoring the potential category information which can reflect the relationship between samples. In this paper, we propose a novel unsupervised missing data imputation method named PC-GAIN, which utilizes potential category information to further enhance the imputation power. Specifically, we first propose a pre-training procedure to learn potential category information contained in a subset of low-missing-rate data. Then an auxiliary classifier is determined using the synthetic pseudo-labels. Further, this classifier is incorporated into the generative adversarial framework to help the generator to yield higher quality imputation results. The proposed method can improve the imputation quality of GAIN significantly. Experimental results on various benchmark datasets show that our method is also superior to other baseline approaches. Our code is available at https://github.com/WYu-Feng/pc-gain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100229X",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Generative adversarial network",
      "Generative grammar",
      "Imputation (statistics)",
      "Information gain",
      "Machine learning",
      "Missing data",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yufeng"
      },
      {
        "surname": "Li",
        "given_name": "Dan"
      },
      {
        "surname": "Li",
        "given_name": "Xiang"
      },
      {
        "surname": "Yang",
        "given_name": "Min"
      }
    ]
  },
  {
    "title": "Pinning bipartite synchronization for coupled reaction–diffusion neural networks with antagonistic interactions and switching topologies",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.007",
    "abstract": "In this paper, the bipartite synchronization issue for a class of coupled reaction–diffusion networks with antagonistic interactions and switching topologies is investigated. First of all, by virtue of Lyapunov functional method and pinning control technique, we obtain some sufficient conditions which can guarantee that networks with signed graph topologies realize bipartite synchronization under any initial conditions and arbitrary switching signals. Secondly, for the general switching signal and periodic switching signal, a pinning controller that can ensure bipartite synchronization of reaction–diffusions networks is designed based on the obtained conditions. Meanwhile, a directed relationship between coupling strength and control gains is presented. Thirdly, numerical simulation is provided to demonstrate the correctness and validity of the derived theoretical results for reaction–diffusion systems. We briefly conclude our findings and future work.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001349",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Bipartite graph",
      "Combinatorics",
      "Computer science",
      "Condensed matter physics",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Correctness",
      "Coupling strength",
      "Graph",
      "Mathematical analysis",
      "Mathematics",
      "Network topology",
      "Operating system",
      "Physics",
      "Reaction–diffusion system",
      "Synchronization (alternating current)",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Miao",
        "given_name": "Baojun"
      },
      {
        "surname": "Li",
        "given_name": "Xuechen"
      },
      {
        "surname": "Lou",
        "given_name": "Jungang"
      },
      {
        "surname": "Lu",
        "given_name": "Jianquan"
      }
    ]
  },
  {
    "title": "H ∞ estimation for stochastic semi-Markovian switching CVNNs with missing measurements and mode-dependent delays",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.022",
    "abstract": "This article is devoted to the H ∞ estimation problem for stochastic semi-Markovian switching complex-valued neural networks subject to incomplete measurement outputs, where the time-varying delay also depends on another semi-Markov process. A sequence of random variables with known statistical property is introduced to depict the missing measurement phenomenon. Based on the generalized It o ˆ ’s formula in complex form concerning with the semi-Markovian systems, complex-valued reciprocal convex inequality as well as intensive stochastic analysis method, some mode-dependent sufficient conditions are presented guaranteeing the estimation error system to be exponentially mean-square stable with a prespecified H ∞ disturbance attenuation level. In addition, the mode-dependent estimator gain matrices are appropriately designed according to the feasible solutions of certain complex matrix inequalities. In the end, one numerical example is provided to illustrate effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001593",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Biology",
      "Computer science",
      "Estimator",
      "Genetics",
      "Machine learning",
      "Markov chain",
      "Markov process",
      "Mathematics",
      "Sequence (biology)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Qiang"
      },
      {
        "surname": "Liang",
        "given_name": "Jinling"
      },
      {
        "surname": "Qu",
        "given_name": "Hong"
      }
    ]
  },
  {
    "title": "Learnable Heterogeneous Convolution: Learning both topology and strength",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.038",
    "abstract": "Existing convolution techniques in artificial neural networks suffer from huge computation complexity, while the biological neural network works in a much more powerful yet efficient way. Inspired by the biological plasticity of dendritic topology and synaptic strength, our method, Learnable Heterogeneous Convolution, realizes joint learning of kernel shape and weights, which unifies existing handcrafted convolution techniques in a data-driven way. A model based on our method can converge with structural sparse weights and then be accelerated by devices of high parallelism. In the experiments, our method either reduces VGG16/19 and ResNet34/50 computation by nearly 5 × on CIFAR10 and 2 × on ImageNet without harming the performance, where the weights are compressed by 10 × and 4 × respectively; or improves the accuracy by up to 1.0% on CIFAR10 and 0.5% on ImageNet with slightly higher efficiency. The code will be available on www.github.com/Genera1Z/LearnableHeterogeneousConvolution.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100126X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Convolution (computer science)",
      "Mathematics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Rongzhen"
      },
      {
        "surname": "Wu",
        "given_name": "Zhenzhi"
      },
      {
        "surname": "Zhang",
        "given_name": "Qikun"
      }
    ]
  },
  {
    "title": "Noise effect on the temporal patterns of neural synchrony",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.032",
    "abstract": "Neural synchrony in the brain is often present in an intermittent fashion, i.e., there are intervals of synchronized activity interspersed with intervals of desynchronized activity. A series of experimental studies showed that this kind of temporal patterning of neural synchronization may be very specific and may be correlated with behaviour (even if the average synchrony strength is not changed). Prior studies showed that a network with many short desynchronized intervals may be functionally different from a network with few long desynchronized intervals as it may be more sensitive to synchronizing input signals. In this study, we investigated the effect of channel noise on the temporal patterns of neural synchronization. We employed a small network of conductance-based model neurons that were mutually connected via excitatory synapses. The resulting dynamics of the network was studied using the same time-series analysis methods as used in prior experimental and computational studies. While it is well known that synchrony strength generally degrades with noise, we found that noise also affects the temporal patterning of synchrony. Noise, at a sufficient intensity (yet too weak to substantially affect synchrony strength), promotes dynamics with predominantly short (although potentially very numerous) desynchronizations. Thus, channel noise may be one of the mechanisms contributing to the short desynchronization dynamics observed in multiple experimental studies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001209",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biological system",
      "Biology",
      "Channel (broadcasting)",
      "Communication noise",
      "Computer science",
      "Excitatory postsynaptic potential",
      "Image (mathematics)",
      "Inhibitory postsynaptic potential",
      "Linguistics",
      "Neuroscience",
      "Noise (video)",
      "Philosophy",
      "Synchronization (alternating current)",
      "Synchronizing",
      "Telecommunications",
      "Transmission (telecommunications)"
    ],
    "authors": [
      {
        "surname": "Zirkle",
        "given_name": "Joel"
      },
      {
        "surname": "Rubchinsky",
        "given_name": "Leonid L."
      }
    ]
  },
  {
    "title": "Deep learning architectures for estimating breathing signal and respiratory parameters from speech recordings",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.029",
    "abstract": "Respiration is an essential and primary mechanism for speech production. We first inhale and then produce speech while exhaling. When we run out of breath, we stop speaking and inhale. Though this process is involuntary, speech production involves a systematic outflow of air during exhalation characterized by linguistic content and prosodic factors of the utterance. Thus speech and respiration are closely related, and modeling this relationship makes sensing respiratory dynamics directly from the speech plausible, however is not well explored. In this article, we conduct a comprehensive study to explore techniques for sensing breathing signal and breathing parameters from speech using deep learning architectures and address the challenges involved in establishing the practical purpose of this technology. Estimating the breathing pattern from the speech would give us information about the respiratory parameters, thus enabling us to understand the respiratory health using one’s speech.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001179",
    "keywords": [
      "Artificial intelligence",
      "Audiology",
      "Breathing",
      "Computer science",
      "Exhalation",
      "Medicine",
      "Phonation",
      "Programming language",
      "Psychiatry",
      "Psychology",
      "Radiology",
      "SIGNAL (programming language)",
      "Speech production",
      "Speech recognition",
      "Utterance"
    ],
    "authors": [
      {
        "surname": "Nallanthighal",
        "given_name": "Venkata Srikanth"
      },
      {
        "surname": "Mostaani",
        "given_name": "Zohreh"
      },
      {
        "surname": "Härmä",
        "given_name": "Aki"
      },
      {
        "surname": "Strik",
        "given_name": "Helmer"
      },
      {
        "surname": "Magimai-Doss",
        "given_name": "Mathew"
      }
    ]
  },
  {
    "title": "Implicit adversarial data augmentation and robustness with Noise-based Learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.008",
    "abstract": "We introduce a Noise-based Learning (NoL) approach for training neural networks that are intrinsically robust to adversarial attacks. We find that the learning of random noise introduced with the input with the same loss function used during posterior maximization, improves a model’s adversarial resistance. We show that the learnt noise performs implicit adversarial data augmentation boosting a model’s adversary generalization capability. We evaluate our approach’s efficacy and provide a simplistic visualization tool for understanding adversarial data, using Principal Component Analysis. We conduct comprehensive experiments on prevailing benchmarks such as MNIST, CIFAR10, CIFAR100, Tiny ImageNet and show that our approach performs remarkably well against a wide range of attacks. Furthermore, combining NoL with state-of-the-art defense mechanisms, such as adversarial training, consistently outperforms prior techniques in both white-box and black-box attacks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001350",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Gene",
      "Image (mathematics)",
      "Machine learning",
      "Noise (video)",
      "Noisy data",
      "Pattern recognition (psychology)",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Panda",
        "given_name": "Priyadarshini"
      },
      {
        "surname": "Roy",
        "given_name": "Kaushik"
      }
    ]
  },
  {
    "title": "Automatic, dynamic, and nearly optimal learning rate specification via local quadratic approximation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.025",
    "abstract": "In deep learning tasks, the update step size determined by the learning rate at each iteration plays a critical role in gradient-based optimization. However, determining the appropriate learning rate in practice typically relies on subjective judgment. In this work, we propose a novel optimization method based on local quadratic approximation (LQA). In each update step, we locally approximate the loss function along the gradient direction by using a standard quadratic function of the learning rate. Subsequently, we propose an approximation step to obtain a nearly optimal learning rate in a computationally efficient manner. The proposed LQA method has three important features. First, the learning rate is automatically determined in each update step. Second, it is dynamically adjusted according to the current loss function value and parameter estimates. Third, with the gradient direction fixed, the proposed method attains a nearly maximum reduction in the loss function. Extensive experiments were conducted to prove the effectiveness of the proposed LQA method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001131",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Computer science",
      "Geometry",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Quadratic equation"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Yingqiu"
      },
      {
        "surname": "Huang",
        "given_name": "Danyang"
      },
      {
        "surname": "Gao",
        "given_name": "Yuan"
      },
      {
        "surname": "Wu",
        "given_name": "Rui"
      },
      {
        "surname": "Chen",
        "given_name": "Yu"
      },
      {
        "surname": "Zhang",
        "given_name": "Bo"
      },
      {
        "surname": "Wang",
        "given_name": "Hansheng"
      }
    ]
  },
  {
    "title": "Learning emotions latent representation with CVAE for text-driven expressive audiovisual speech synthesis",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.021",
    "abstract": "Great improvement has been made in the field of expressive audiovisual Text-to-Speech synthesis (EAVTTS) thanks to deep learning techniques. However, generating realistic speech is still an open issue and researchers in this area have been focusing lately on controlling the speech variability. In this paper, we use different neural architectures to synthesize emotional speech. We study the application of unsupervised learning techniques for emotional speech modeling as well as methods for restructuring emotions representation to make it continuous and more flexible. This manipulation of the emotional representation should allow us to generate new styles of speech by mixing emotions. We first present our expressive audiovisual corpus. We validate the emotional content of this corpus with three perceptual experiments using acoustic only, visual only and audiovisual stimuli. After that, we analyze the performance of a fully connected neural network in learning characteristics specific to different emotions for the phone duration aspect and the acoustic and visual modalities. We also study the contribution of a joint and separate training of the acoustic and visual modalities in the quality of the generated synthetic speech. In the second part of this paper, we use a conditional variational auto-encoder (CVAE) architecture to learn a latent representation of emotions. We applied this method in an unsupervised manner to generate features of expressive speech. We used a probabilistic metric to compute the overlapping degree between emotions latent clusters to choose the best parameters for the CVAE. By manipulating the latent vectors, we were able to generate nuances of a given emotion and to generate new emotions that do not exist in our database. For these new emotions, we obtain a coherent articulation. We conducted four perceptual experiments to evaluate our findings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001581",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Discriminative model",
      "Economics",
      "Feature learning",
      "Hidden Markov model",
      "Latent variable",
      "Law",
      "Metric (unit)",
      "Natural language processing",
      "Operations management",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Speech recognition",
      "Speech synthesis",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Dahmani",
        "given_name": "Sara"
      },
      {
        "surname": "Colotte",
        "given_name": "Vincent"
      },
      {
        "surname": "Girard",
        "given_name": "Valérian"
      },
      {
        "surname": "Ouni",
        "given_name": "Slim"
      }
    ]
  },
  {
    "title": "SPLASH: Learnable activation functions for improving accuracy and adversarial robustness",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.023",
    "abstract": "We introduce SPLASH units, a class of learnable activation functions shown to simultaneously improve the accuracy of deep neural networks while also improving their robustness to adversarial attacks. SPLASH units have both a simple parameterization and maintain the ability to approximate a wide range of non-linear functions. SPLASH units are: (1) continuous; (2) grounded ( f ( 0 ) = 0 ); (3) use symmetric hinges; and (4) their hinges are placed at fixed locations which are derived from the data (i.e. no learning required). Compared to nine other learned and fixed activation functions, including ReLU and its variants, SPLASH units show superior performance across three datasets (MNIST, CIFAR-10, and CIFAR-100) and four architectures (LeNet5, All-CNN, ResNet-20, and Network-in-Network). Furthermore, we show that SPLASH units significantly increase the robustness of deep neural networks to adversarial attacks. Our experiments on both black-box and white-box adversarial attacks show that commonly-used architectures, namely LeNet5, All-CNN, Network-in-Network, and ResNet-20, can be up to 31% more robust to adversarial attacks by simply using SPLASH units instead of ReLUs. Finally, we show the benefits of using SPLASH activation functions in bigger architectures designed for non-trivial datasets such as ImageNet.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000733",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Engineering",
      "Gene",
      "MNIST database",
      "Mechanical engineering",
      "Robustness (evolution)",
      "Splash"
    ],
    "authors": [
      {
        "surname": "Tavakoli",
        "given_name": "Mohammadamin"
      },
      {
        "surname": "Agostinelli",
        "given_name": "Forest"
      },
      {
        "surname": "Baldi",
        "given_name": "Pierre"
      }
    ]
  },
  {
    "title": "PyDiNet: Pyramid Dilated Network for medical image segmentation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.023",
    "abstract": "Medical image segmentation is an important step in many generic applications such as population analysis and, more accessible, can be made into a crucial tool in diagnosis and treatment planning. Previous approaches are based on two main architectures: fully convolutional networks and U-Net-based architecture. These methods rely on multiple pooling and striding layers leading to the loss of important spatial information and fail to capture details in medical images. In this paper, we propose a novel neural network called PyDiNet (Pyramid Dilated Network) to capture small and complex variations in medical images while preserving spatial information. To achieve this goal, PyDiNet uses a newly proposed pyramid dilated module (PDM), which consists of multiple dilated convolutions stacked in parallel. We combine several PDM modules to form the final PyDiNet architecture. We applied the proposed PyDiNet to different medical image segmentation tasks. Experimental results show that the proposed model achieves new state-of-the-art performance on three medical image segmentation benchmarks. Furthermore, PyDiNet was very competitive on the 2020 Endoscopic Artifact Detection challenge.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001118",
    "keywords": [
      "Artifact (error)",
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Convolutional neural network",
      "Geometry",
      "Image segmentation",
      "Mathematics",
      "Medical imaging",
      "Network architecture",
      "Pattern recognition (psychology)",
      "Pooling",
      "Pyramid (geometry)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Gridach",
        "given_name": "Mourad"
      }
    ]
  },
  {
    "title": "Uncorrelated feature encoding for faster image style transfer",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.007",
    "abstract": "Recent image style transfer methods use a pre-trained convolutional neural network as their feature encoder. However, the pre-trained network is not optimal for image style transfer but rather for image classification. Furthermore, they require time-consuming feature alignment to consider the existing correlation among channels of the encoded feature map. In this paper, we propose an end-to-end learning method that optimizes both encoder and decoder networks for style transfer task and relieves the computational complexity of the existing correlation-aware feature alignment. First, we performed end-to-end learning that updates not only decoder but also encoder parameters for the task of image style transfer in the network training phase. Second, in addition to the previous style and content losses, we use uncorrelation loss, i.e., the total correlation coefficient among responses of encoder channels. Our uncorrelation loss allows the encoder network to generate a feature map of channels without correlation. Subsequently, our method results in faster forward processing with only a light-weighted transformer of correlation-unaware feature alignment. Moreover, our method drastically reduced the channel redundancy of the encoded feature during the network training process. This provides us a possibility to perform channel elimination with negligible degradation in generated style quality. Our method is applicable to multiple scaled style transfer by using the cascade network scheme and allows a user to control style strength through the usage of a content-style trade-off parameter.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000873",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Convolutional neural network",
      "Correlation",
      "Encoder",
      "Feature (linguistics)",
      "Feature extraction",
      "Geometry",
      "Linguistics",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Redundancy (engineering)"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Minseong"
      },
      {
        "surname": "Choi",
        "given_name": "Hyun-Chul"
      }
    ]
  },
  {
    "title": "Speaker recognition based on deep learning: An overview",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.004",
    "abstract": "Speaker recognition is a task of identifying persons from their voices. Recently, deep learning has dramatically revolutionized speaker recognition. However, there is lack of comprehensive reviews on the exciting progress. In this paper, we review several major subtasks of speaker recognition, including speaker verification, identification, diarization, and robust speaker recognition, with a focus on deep-learning-based methods. Because the major advantage of deep learning over conventional methods is its representation ability, which is able to produce highly abstract embedding features from utterances, we first pay close attention to deep-learning-based speaker feature extraction, including the inputs, network structures, temporal pooling strategies, and objective functions respectively, which are the fundamental components of many speaker recognition subtasks. Then, we make an overview of speaker diarization, with an emphasis of recent supervised, end-to-end, and online diarization. Finally, we survey robust speaker recognition from the perspectives of domain adaptation and speech enhancement, which are two major approaches of dealing with domain mismatch and noise problems. Popular and recently released corpora are listed at the end of the paper.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000848",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Domain (mathematical analysis)",
      "Feature engineering",
      "Feature extraction",
      "Feature learning",
      "Focus (optics)",
      "Mathematical analysis",
      "Mathematics",
      "Optics",
      "Physics",
      "Pooling",
      "Speaker diarisation",
      "Speaker recognition",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Bai",
        "given_name": "Zhongxin"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiao-Lei"
      }
    ]
  },
  {
    "title": "Improved deep CNNs based on Nonlinear Hybrid Attention Module for image classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.005",
    "abstract": "Recent years have witnessed numerous successful applications of incorporating attention module into feed-forward convolutional neural networks. Along this line of research, we design a novel lightweight general-purpose attention module by simultaneously taking channel attention and spatial attention into consideration. Specifically, inspired by the characteristics of channel attention and spatial attention, a nonlinear hybrid method is proposed to combine such two types of attention feature maps, which is highly beneficial to better network fine-tuning. Further, the parameters of each attention branch can be adjustable for the purpose of making the attention module more flexible and adaptable. From another point of view, we found that the currently popular SE, and CBAM modules are actually two particular cases of our proposed attention module. We also explore the latest attention module ADCM. To validate the module, we conduct experiments on CIFAR10, CIFAR100, Fashion MINIST datasets. Results show that, after integrating with our attention module, existing networks tend to be more efficient in training process and have better performance as compared with state-of-the-art competitors. Also, it is worthy to stress the following two points: (1) our attention module can be used in existing state-of-the-art deep architectures and get better performance at a small computational cost; (2) the module can be added to existing deep architectures in a simple way through stacking the integration of networks block and our module.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000137",
    "keywords": [
      "Artificial intelligence",
      "Block (permutation group theory)",
      "Channel (broadcasting)",
      "Computer engineering",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Feature (linguistics)",
      "Geometry",
      "Linguistics",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Point (geometry)",
      "Process (computing)",
      "Quantum mechanics",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Nan"
      },
      {
        "surname": "Gu",
        "given_name": "Ke"
      },
      {
        "surname": "Qiao",
        "given_name": "Junfei"
      },
      {
        "surname": "Bi",
        "given_name": "Jing"
      }
    ]
  },
  {
    "title": "LSTM-based approach for predicting periodic motions of an impacting system via transient dynamics",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.027",
    "abstract": "Dynamically impacting systems are characterised with inherent instability and complex non-linear phenomena which makes it practically difficult to predict the steady state response of the system at transient periods. This study investigates the ability of a data driven machine learning method using Long Short-Term Memory networks to learn the complex nonlinearity associated with co-existing impact responses from limited transient data. A one-degree-of-freedom impact oscillator has been used to represent the bit–rock interaction for percussive drilling. Simulated data results show velocity measurements to contribute most to predicting steady state responses from transient dynamics with most of the network models reaching an accuracy of over 95%. Limitations to practically measurable variables in dynamic systems warranted the development of a feature based network model for impact motion classification. Experimental data from a two-degrees-of-freedom impacting system representing percussive bit penetration has been used to demonstrate the effectiveness of this method. The study thus provides a precise and less computational means of detecting and avoiding underperforming impact modes in percussive drilling.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000770",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Electrical engineering",
      "Engineering",
      "Feature (linguistics)",
      "Instability",
      "Linguistics",
      "Mechanics",
      "Nonlinear system",
      "Operating system",
      "Philosophy",
      "Physical chemistry",
      "Physics",
      "Quantum mechanics",
      "Steady state (chemistry)",
      "Transient (computer programming)",
      "Transient response"
    ],
    "authors": [
      {
        "surname": "Afebu",
        "given_name": "Kenneth Omokhagbo"
      },
      {
        "surname": "Liu",
        "given_name": "Yang"
      },
      {
        "surname": "Papatheou",
        "given_name": "Evangelos"
      },
      {
        "surname": "Guo",
        "given_name": "Bingyong"
      }
    ]
  },
  {
    "title": "Multi-resolution modulation-filtered cochleagram feature for LSTM-based dimensional emotion recognition from speech",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.027",
    "abstract": "Continuous dimensional emotion recognition from speech helps robots or virtual agents capture the temporal dynamics of a speaker’s emotional state in natural human–robot interactions. Temporal modulation cues obtained directly from the time-domain model of auditory perception can better reflect temporal dynamics than the acoustic features usually processed in the frequency domain. Feature extraction, which can reflect temporal dynamics of emotion from temporal modulation cues, is challenging because of the complexity and diversity of the auditory perception model. A recent neuroscientific study suggests that human brains derive multi-resolution representations through temporal modulation analysis. This study investigates multi-resolution representations of an auditory perception model and proposes a novel feature called multi-resolution modulation-filtered cochleagram (MMCG) for predicting valence and arousal values of emotional primitives. The MMCG is constructed by combining four modulation-filtered cochleagrams at different resolutions to capture various temporal and contextual modulation information. In addition, to model the multi-temporal dependencies of the MMCG, we designed a parallel long short-term memory (LSTM) architecture. The results of extensive experiments on the RECOLA and SEWA datasets demonstrate that MMCG provides the best recognition performance in both datasets among all evaluated features. The results also show that the parallel LSTM can build multi-temporal dependencies from the MMCG features, and the performance on valence and arousal prediction is better than that of a plain LSTM method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001155",
    "keywords": [
      "Aesthetics",
      "Artificial intelligence",
      "Computer science",
      "Feature (linguistics)",
      "Feature extraction",
      "Linguistics",
      "Modulation (music)",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Perception",
      "Philosophy",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Speech recognition",
      "Temporal resolution"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Zhichao"
      },
      {
        "surname": "Dang",
        "given_name": "Jianwu"
      },
      {
        "surname": "Unoki",
        "given_name": "Masashi"
      },
      {
        "surname": "Akagi",
        "given_name": "Masato"
      }
    ]
  },
  {
    "title": "Understanding the message passing in graph neural networks via power iteration clustering",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.025",
    "abstract": "The mechanism of message passing in graph neural networks (GNNs) is still mysterious. Apart from convolutional neural networks, no theoretical origin for GNNs has been proposed. To our surprise, message passing can be best understood in terms of power iteration. By fully or partly removing activation functions and layer weights of GNNs, we propose subspace power iteration clustering (SPIC) models that iteratively learn with only one aggregator. Experiments show that our models extend GNNs and enhance their capability to process random featured networks. Moreover, we demonstrate the redundancy of some state-of-the-art GNNs in design and define a lower limit for model evaluation by a random aggregator of message passing. Our findings push the boundaries of the theoretical understanding of neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000757",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster analysis",
      "Computer science",
      "Distributed computing",
      "Graph",
      "Iterative method",
      "Message passing",
      "News aggregator",
      "Operating system",
      "Power iteration",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xue"
      },
      {
        "surname": "Cheng",
        "given_name": "Yuanzhi"
      }
    ]
  },
  {
    "title": "Diversity-driven knowledge distillation for financial trading using Deep Reinforcement Learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.026",
    "abstract": "Deep Reinforcement Learning (RL) is increasingly used for developing financial trading agents for a wide range of tasks. However, optimizing deep RL agents is notoriously difficult and unstable, especially in noisy financial environments, significantly hindering the performance of trading agents. In this work, we present a novel method that improves the training reliability of DRL trading agents building upon the well-known approach of neural network distillation. In the proposed approach, teacher agents are trained in different subsets of RL environment, thus diversifying the policies they learn. Then student agents are trained using distillation from the trained teachers to guide the training process, allowing for better exploring the solution space, while “mimicking” an existing policy/trading strategy provided by the teacher model. The boost in effectiveness of the proposed method comes from the use of diversified ensembles of teachers trained to perform trading for different currencies. This enables us to transfer the common view regarding the most profitable policy to the student, further improving the training stability in noisy financial environments. In the conducted experiments we find that when applying distillation, constraining the teacher models to be diversified can significantly improve their performance of the final student agents. We demonstrate this by providing an extensive evaluation on various financial trading tasks. Furthermore, we also provide additional experiments in the separate domain of control in games using the Procgen environments in order to demonstrate the generality of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000769",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Business",
      "Chemistry",
      "Computer science",
      "Distillation",
      "Finance",
      "Generality",
      "Machine learning",
      "Operating system",
      "Order (exchange)",
      "Organic chemistry",
      "Physics",
      "Power (physics)",
      "Process (computing)",
      "Psychology",
      "Psychotherapist",
      "Quantum mechanics",
      "Reinforcement learning",
      "Reliability (semiconductor)",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Tsantekidis",
        "given_name": "Avraam"
      },
      {
        "surname": "Passalis",
        "given_name": "Nikolaos"
      },
      {
        "surname": "Tefas",
        "given_name": "Anastasios"
      }
    ]
  },
  {
    "title": "Dual self-paced multi-view clustering",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.022",
    "abstract": "By utilizing the complementary information from multiple views, multi-view clustering (MVC) algorithms typically achieve much better clustering performance than conventional single-view methods. Although in this field, great progresses have been made in past few years, most existing multi-view clustering methods still suffer the following shortcomings: (1) most MVC methods are non-convex and thus are easily stuck into suboptimal local minima; (2) the effectiveness of these methods is sensitive to the existence of noises or outliers; and (3) the qualities of different features and views are usually ignored, which can also influence the clustering result. To address these issues, we propose dual self-paced multi-view clustering (DSMVC) in this paper. Specifically, DSMVC takes advantage of self-paced learning to tackle the non-convex issue. By applying a soft-weighting scheme of self-paced learning for instances, the negative impact caused by noises and outliers can be significantly reduced. Moreover, to alleviate the feature and view quality issues, we develop a novel feature selection approach in a self-paced manner and a weighting term for views. Experimental results on real-world data sets demonstrate the effectiveness of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000721",
    "keywords": [
      "Art",
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Correlation clustering",
      "Data mining",
      "Dual (grammatical number)",
      "Feature (linguistics)",
      "Field (mathematics)",
      "Linguistics",
      "Literature",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Maxima and minima",
      "Medicine",
      "Outlier",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pure mathematics",
      "Radiology",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Zongmo"
      },
      {
        "surname": "Ren",
        "given_name": "Yazhou"
      },
      {
        "surname": "Pu",
        "given_name": "Xiaorong"
      },
      {
        "surname": "Pan",
        "given_name": "Lili"
      },
      {
        "surname": "Yao",
        "given_name": "Dezhong"
      },
      {
        "surname": "Yu",
        "given_name": "Guoxian"
      }
    ]
  },
  {
    "title": "Long-term Cognitive Network-based architecture for multi-label classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.001",
    "abstract": "This paper presents a neural system to deal with multi-label classification problems that might involve sparse features. The architecture of this model involves three sequential blocks with well-defined functions. The first block consists of a multilayered feed-forward structure that extracts hidden features, thus reducing the problem dimensionality. This block is useful when dealing with sparse problems. The second block consists of a Long-term Cognitive Network-based model that operates on features extracted by the first block. The activation rule of this recurrent neural network is modified to prevent the vanishing of the input signal during the recurrent inference process. The modified activation rule combines the neurons’ state in the previous abstract layer (iteration) with the initial state. Moreover, we add a bias component to shift the transfer functions as needed to obtain good approximations. Finally, the third block consists of an output layer that adapts the second block’s outputs to the label space. We propose a backpropagation learning algorithm that uses a squared hinge loss function to maximize the margins between labels to train this network. The results show that our model outperforms the state-of-the-art algorithms in most datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000812",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Block (permutation group theory)",
      "Component (thermodynamics)",
      "Computer science",
      "Computer security",
      "Geometry",
      "Inference",
      "Mathematics",
      "Network architecture",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Term (time)",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Nápoles",
        "given_name": "Gonzalo"
      },
      {
        "surname": "Bello",
        "given_name": "Marilyn"
      },
      {
        "surname": "Salgueiro",
        "given_name": "Yamisleydi"
      }
    ]
  },
  {
    "title": "Tumor attention networks: Better feature selection, better tumor segmentation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.006",
    "abstract": "Compared with the traditional analysis of computed tomography scans, automatic liver tumor segmentation can supply precise tumor volumes and reduce the inter-observer variability in estimating the tumor size and the tumor burden, which could further assist physicians to make better therapeutic choices for hepatic diseases and monitoring treatment. Among current mainstream segmentation approaches, multi-layer and multi-kernel convolutional neural networks (CNNs) have attracted much attention in diverse biomedical/medical image segmentation tasks with remarkable performance. However, an arbitrary stacking of feature maps makes CNNs quite inconsistent in imitating the cognition and the visual attention of human beings for a specific visual task. To mitigate the lack of a reasonable feature selection mechanism in CNNs, we exploit a novel and effective network architecture, called Tumor Attention Networks (TA-Net), for mining adaptive features by embedding Tumor Attention layers with multi-functional modules to assist the liver tumor segmentation task. In particular, each tumor attention layer can adaptively highlight valuable tumor features and suppress unrelated ones among feature maps from 3D and 2D perspectives. Moreover, an analysis of visualization results illustrates the effectiveness of our tumor attention modules and the interpretability of CNNs for liver tumor segmentation. Furthermore, we explore different arrangements of skip connections in information fusion. A deep ablation study is also conducted to illustrate the effects of different attention strategies for hepatic tumors. The results of extensive experiments demonstrate that the proposed TA-Net increases the liver tumor segmentation performance with a lower computation cost and a small parameter overhead over the state-of-the-art methods, under various evaluation metrics on clinical benchmark data. In addition, two additional medical image datasets are used to evaluate generalization capability of TA-Net, including the comparison with general semantic segmentation methods and a non-tumor segmentation task. All the program codes have been released at https://github.com/shuchao1212/TA-Net.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000861",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Feature (linguistics)",
      "Feature selection",
      "Interpretability",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Pang",
        "given_name": "Shuchao"
      },
      {
        "surname": "Du",
        "given_name": "Anan"
      },
      {
        "surname": "Orgun",
        "given_name": "Mehmet A."
      },
      {
        "surname": "Wang",
        "given_name": "Yunyun"
      },
      {
        "surname": "Yu",
        "given_name": "Zhenmei"
      }
    ]
  },
  {
    "title": "Self-organized Operational Neural Networks with Generative Neurons",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.028",
    "abstract": "Operational Neural Networks (ONNs) have recently been proposed to address the well-known limitations and drawbacks of conventional Convolutional Neural Networks (CNNs) such as network homogeneity with the sole linear neuron model. ONNs are heterogeneous networks with a generalized neuron model. However the operator search method in ONNs is not only computationally demanding, but the network heterogeneity is also limited since the same set of operators will then be used for all neurons in each layer. Moreover, the performance of ONNs directly depends on the operator set library used, which introduces a certain risk of performance degradation especially when the optimal operator set required for a particular task is missing from the library. In order to address these issues and achieve an ultimate heterogeneity level to boost the network diversity along with computational efficiency, in this study we propose Self-organized ONNs (Self-ONNs) with generative neurons that can adapt (optimize) the nodal operator of each connection during the training process. Moreover, this ability voids the need of having a fixed operator set library and the prior operator search within the library in order to find the best possible set of operators. We further formulate the training method to back-propagate the error through the operational layers of Self-ONNs. Experimental results over four challenging problems demonstrate the superior learning capability and computational efficiency of Self-ONNs over conventional ONNs and CNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000782",
    "keywords": [],
    "authors": [
      {
        "surname": "Kiranyaz",
        "given_name": "Serkan"
      },
      {
        "surname": "Malik",
        "given_name": "Junaid"
      },
      {
        "surname": "Abdallah",
        "given_name": "Habib Ben"
      },
      {
        "surname": "Ince",
        "given_name": "Turker"
      },
      {
        "surname": "Iosifidis",
        "given_name": "Alexandros"
      },
      {
        "surname": "Gabbouj",
        "given_name": "Moncef"
      }
    ]
  },
  {
    "title": "Manifold adversarial training for supervised and semi-supervised learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.031",
    "abstract": "We propose a new regularization method for deep learning based on the manifold adversarial training (MAT). Unlike previous regularization and adversarial training methods, MAT further considers the local manifold of latent representations. Specifically, MAT manages to build an adversarial framework based on how the worst perturbation could affect the statistical manifold in the latent space rather than the output space. Particularly, a latent feature space with the Gaussian Mixture Model (GMM) is first derived in a deep neural network. We then define the smoothness by the largest variation of Gaussian mixtures when a local perturbation is given around the input data point. On one hand, the perturbations are added in the way that would rough the statistical manifold of the latent space the worst. On the other hand, the model is trained to promote the manifold smoothness the most in the latent space. Importantly, since the latent space is more informative than the output space, the proposed MAT can learn a more robust and compact data representation, leading to further performance improvement. The proposed MAT is important in that it can be considered as a superset of one recently-proposed discriminative feature learning approach called center loss. We conduct a series of experiments in both supervised and semi-supervised learning on four benchmark data sets, showing that the proposed MAT can achieve remarkable performance, much better than those of the state-of-the-art approaches. In addition, we present a series of visualization which could generate further understanding or explanation on adversarial examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001192",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data point",
      "Discriminative model",
      "Engineering",
      "Feature learning",
      "Feature vector",
      "Gaussian",
      "Latent variable",
      "Machine learning",
      "Manifold (fluid mechanics)",
      "Mathematics",
      "Mechanical engineering",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Regularization (linguistics)",
      "Semi-supervised learning"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Shufei"
      },
      {
        "surname": "Huang",
        "given_name": "Kaizhu"
      },
      {
        "surname": "Zhu",
        "given_name": "Jianke"
      },
      {
        "surname": "Liu",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Empirical strategy for stretching probability distribution in neural-network-based regression",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.030",
    "abstract": "In regression analysis under artificial neural networks, the prediction performance depends on determining the appropriate weights between layers. As randomly initialized weights are updated during back-propagation using the gradient descent procedure under a given loss function, the loss function structure can affect the performance significantly. In this study, we considered the distribution error, i.e., the inconsistency of two distributions (those of the predicted values and label), as the prediction error, and proposed weighted empirical stretching (WES) as a novel loss function to increase the overlap area of the two distributions. The function depends on the distribution of a given label, thus, it is applicable to any distribution shape. Moreover, it contains a scaling hyperparameter ( β ) such that the appropriate parameter value maximizes the common section of the two distributions. To test the function capability, we generated ideal distributed curves (unimodal, skewed unimodal, bimodal, and skewed bimodal) as the labels, and used the Fourier-extracted input data from the curves under a feedforward neural network. In general, WES outperformed loss functions in wide use, and the performance was robust to the various noise levels. The improved results in RMSE for the extreme domain (i.e., both tail regions of the distribution) are expected to be utilized for prediction of abnormal events in non-linear complex systems such as natural disaster and financial crisis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000800",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Error function",
      "Evolutionary biology",
      "Function (biology)",
      "Gradient descent",
      "Heavy-tailed distribution",
      "Hyperparameter",
      "Mathematics",
      "Mean squared error",
      "Probability distribution",
      "Regression",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Koo",
        "given_name": "Eunho"
      },
      {
        "surname": "Kim",
        "given_name": "Hyungjun"
      }
    ]
  },
  {
    "title": "TigeCMN: On exploration of temporal interaction graph embedding via Coupled Memory Neural Networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.016",
    "abstract": "With the increasing demand of mining rich knowledge in graph structured data, graph embedding has become one of the most popular research topics in both academic and industrial communities due to its powerful capability in learning effective representations. The majority of existing work overwhelmingly learn node embeddings in the context of static, plain or attributed, homogeneous graphs. However, many real-world applications frequently involve bipartite graphs with temporal and attributed interaction edges, named temporal interaction graphs. The temporal interactions usually imply different facets of interest and might even evolve over the time, thus putting forward huge challenges in learning effective node representations. Furthermore, most existing graph embedding models try to embed all the information of each node into a single vector representation, which is insufficient to characterize the node’s multifaceted properties. In this paper, we propose a novel framework named TigeCMN to learn node representations from a sequence of temporal interactions. Specifically, we devise two coupled memory networks to store and update node embeddings in the external matrices explicitly and dynamically, which forms deep matrix representations and thus could enhance the expressiveness of the node embeddings. Then, we generate node embedding from two parts: a static embedding that encodes its stationary properties and a dynamic embedding induced from memory matrix that models its temporal interaction patterns. We conduct extensive experiments on various real-world datasets covering the tasks of node classification, recommendation and visualization. The experimental results empirically demonstrate that TigeCMN can achieve significant gains compared with recent state-of-the-art baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000587",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Bipartite graph",
      "Computer science",
      "Context (archaeology)",
      "Embedding",
      "Engineering",
      "Graph",
      "Graph embedding",
      "Law",
      "Node (physics)",
      "Paleontology",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Structural engineering",
      "Theoretical computer science",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Zhen"
      },
      {
        "surname": "Bu",
        "given_name": "Jiajun"
      },
      {
        "surname": "Li",
        "given_name": "Zhao"
      },
      {
        "surname": "Yao",
        "given_name": "Chengwei"
      },
      {
        "surname": "Wang",
        "given_name": "Can"
      },
      {
        "surname": "Wu",
        "given_name": "Jia"
      }
    ]
  },
  {
    "title": "Self-organized Operational Neural Networks with Generative Neurons",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.028",
    "abstract": "Operational Neural Networks (ONNs) have recently been proposed to address the well-known limitations and drawbacks of conventional Convolutional Neural Networks (CNNs) such as network homogeneity with the sole linear neuron model. ONNs are heterogeneous networks with a generalized neuron model. However the operator search method in ONNs is not only computationally demanding, but the network heterogeneity is also limited since the same set of operators will then be used for all neurons in each layer. Moreover, the performance of ONNs directly depends on the operator set library used, which introduces a certain risk of performance degradation especially when the optimal operator set required for a particular task is missing from the library. In order to address these issues and achieve an ultimate heterogeneity level to boost the network diversity along with computational efficiency, in this study we propose Self-organized ONNs (Self-ONNs) with generative neurons that can adapt (optimize) the nodal operator of each connection during the training process. Moreover, this ability voids the need of having a fixed operator set library and the prior operator search within the library in order to find the best possible set of operators. We further formulate the training method to back-propagate the error through the operational layers of Self-ONNs. Experimental results over four challenging problems demonstrate the superior learning capability and computational efficiency of Self-ONNs over conventional ONNs and CNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000782",
    "keywords": [],
    "authors": [
      {
        "surname": "Kiranyaz",
        "given_name": "Serkan"
      },
      {
        "surname": "Malik",
        "given_name": "Junaid"
      },
      {
        "surname": "Abdallah",
        "given_name": "Habib Ben"
      },
      {
        "surname": "Ince",
        "given_name": "Turker"
      },
      {
        "surname": "Iosifidis",
        "given_name": "Alexandros"
      },
      {
        "surname": "Gabbouj",
        "given_name": "Moncef"
      }
    ]
  },
  {
    "title": "Cycle consistent network for end-to-end style transfer TTS training",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.005",
    "abstract": "In this paper, we propose a cycle consistent network based end-to-end TTS for speaking style transfer, including intra-speaker, inter-speaker, and unseen speaker style transfer for both parallel and unparallel transfers. The proposed approach is built upon a multi-speaker Variational Autoencoder (VAE) TTS model. The model is usually trained in a paired manner, which means the reference speech is totally paired with the output including speaker identity, text, and style. To achieve a better quality for style transfer, which for most cases is in an unpaired manner, we augment the model with an unpaired path with a separated variational style encoder. The unpaired path takes as input an unpaired reference speech and yields an unpaired output. The unpaired output, which lacks direct ground-truth target, is then successfully constrained by a delicately designed cycle consistent network. Specifically, the unpaired output of the forward transfer is fed into the model again as an unpaired reference input, and after the backward transfer yields an output expected to be the same as the original unpaired reference speech. Ablation study shows the effectiveness of the unpaired path, separated style encoders and cycle consistent network in the proposed model. The final evaluation demonstrates the proposed approach significantly outperforms the Global Style Token (GST) and VAE based systems for all the six style transfer categories, in metrics of naturalness, speech quality, similarity of speaker identity, and similarity of speaking style.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100085X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Image (mathematics)",
      "Molecule",
      "Naturalness",
      "Organic chemistry",
      "Physics",
      "Quantum mechanics",
      "Security token",
      "Similarity (geometry)",
      "Speech recognition",
      "Unpaired electron"
    ],
    "authors": [
      {
        "surname": "Xue",
        "given_name": "Liumeng"
      },
      {
        "surname": "Pan",
        "given_name": "Shifeng"
      },
      {
        "surname": "He",
        "given_name": "Lei"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      },
      {
        "surname": "Soong",
        "given_name": "Frank K."
      }
    ]
  },
  {
    "title": "Parallel orthogonal deep neural network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.002",
    "abstract": "Ensemble learning methods combine multiple models to improve performance by exploiting their diversity. The success of these approaches relies heavily on the dissimilarity of the base models forming the ensemble. This diversity can be achieved in many ways, with well-known examples including bagging and boosting. It is the diversity of the models within an ensemble that allows the ensemble to correct the errors made by its members, and consequently leads to higher classification or regression performance. A mistake made by a base model can only be rectified if other members behave differently on that particular instance, and provide the aggregator with enough information to make an informed decision. On the contrary, lack of diversity not only lowers model performance, but also wastes computational resources. Nevertheless, in the current state of the art ensemble approaches, there is no guarantee on the level of diversity achieved, and no mechanism ensuring that each member will learn a different decision boundary from the others. In this paper, we propose a parallel orthogonal deep learning architecture in which diversity is enforced by design, through imposing an orthogonality constraint. Multiple deep neural networks are created, parallel to each other. At each parallel layer, the outputs of different base models are subject to Gram–Schmidt orthogonalization. We demonstrate that this approach leads to a high level of diversity from two perspectives. First, the models make different errors on different parts of feature space, and second, they exhibit different levels of uncertainty in their decisions. Experimental results confirm the benefits of the proposed method, compared to standard deep learning models and well-known ensemble methods, in terms of diversity and, as a result, classification performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000824",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Boosting (machine learning)",
      "Computer science",
      "Constraint (computer-aided design)",
      "Ensemble forecasting",
      "Ensemble learning",
      "Feature (linguistics)",
      "Geometry",
      "Law",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Mistake",
      "Orthogonality",
      "Orthogonalization",
      "Philosophy",
      "Political science"
    ],
    "authors": [
      {
        "surname": "Mashhadi",
        "given_name": "Peyman Sheikholharam"
      },
      {
        "surname": "Nowaczyk",
        "given_name": "Sławomir"
      },
      {
        "surname": "Pashami",
        "given_name": "Sepideh"
      }
    ]
  },
  {
    "title": "Bidirectional stochastic configuration network for regression problems",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.016",
    "abstract": "To adapt to the reality of limited computing resources of various terminal devices in industrial applications, a randomized neural network called stochastic configuration network (SCN), which can conduct effective training without GPU, was proposed. SCN uses a supervisory random mechanism to assign its input weights and hidden biases, which makes it more stable than other randomized algorithms but also leads to time-consuming model training. To alleviate this problem, we propose a novel bidirectional SCN algorithm (BSCN) in this paper, which divides the way of adding hidden nodes into two modes: forward learning and backward learning. In the forward learning mode, BSCN still uses the supervisory mechanism to configure the parameters of the newly added nodes, which is the same as SCN. In the backward learning mode, BSCN calculates the parameters at one time based on the residual error feedback of the current model. The two learning modes are performed iteratively until the prediction error of the model reaches an acceptable level or the number of hidden nodes reaches its maximum value. This semi-random learning mechanism greatly speeds up the training efficiency of the BSCN model and significantly improves the quality of the hidden nodes. Extensive experiments on ten benchmark regression problems, two real-life air pollution prediction problems, and a classical image processing problem show that BSCN can achieve faster training speed, higher stability, and better generalization ability than SCN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000964",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Generalization",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Cao",
        "given_name": "Weipeng"
      },
      {
        "surname": "Xie",
        "given_name": "Zhongwu"
      },
      {
        "surname": "Li",
        "given_name": "Jianqiang"
      },
      {
        "surname": "Xu",
        "given_name": "Zhiwu"
      },
      {
        "surname": "Ming",
        "given_name": "Zhong"
      },
      {
        "surname": "Wang",
        "given_name": "Xizhao"
      }
    ]
  },
  {
    "title": "A clustering-based adaptive Neighborhood Retrieval Visualizer",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.018",
    "abstract": "We introduce a novel adaptive version of the Neighborhood Retrieval Visualizer (NeRV). We maintain the advantages of the conventional NeRV method, while proposing an improvement of the data samples’ neighborhood width calculation, in the input and output data space. In the standard NeRV, the data samples’ neighborhood widths are determined in an arbitrary manner, in this way, inhibiting the possible quality of the resulting data visualization. We propose to compute the widths adaptively, on the basis of the input data scattering. Therefore, we first perform the preliminary input data clustering, next, we calculate the values of the inner-cluster variances, which convey the information on the input data scattering, then, we assign them to each data sample, and finally, we use them as the basis for the data samples’ neighborhood widths determination. The results of the experiments conducted on the three different real datasets confirm the effectiveness and usefulness of the proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001064",
    "keywords": [
      "Artificial intelligence",
      "Basis (linear algebra)",
      "Chemistry",
      "Chromatography",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Geometry",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Sample (material)",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Olszewski",
        "given_name": "Dominik"
      }
    ]
  },
  {
    "title": "Multistability of delayed fractional-order competitive neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.036",
    "abstract": "This paper is concerned with the multistability of fractional-order competitive neural networks (FCNNs) with time-varying delays. Based on the division of state space, the equilibrium points (EPs) of FCNNs are given. Several sufficient conditions and criteria are proposed to ascertain the multiple O ( t − α ) -stability of delayed FCNNs. The O ( t − α ) -stability is the extension of Mittag-Leffler stability of fractional-order neural networks, which contains monostability and multistability. Moreover, the attraction basins of the stable EPs of FCNNs are estimated, which shows the attraction basins of the stable EPs can be larger than the divided subsets. These conditions and criteria supplement and improve the previous results. Finally, the results are illustrated by the simulation examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001246",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Attraction",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differential equation",
      "Economics",
      "Equilibrium point",
      "Finance",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Multistability",
      "Nonlinear system",
      "Order (exchange)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Fanghai"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      },
      {
        "surname": "Wu",
        "given_name": "Qiujie"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "Multistability of delayed fractional-order competitive neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.036",
    "abstract": "This paper is concerned with the multistability of fractional-order competitive neural networks (FCNNs) with time-varying delays. Based on the division of state space, the equilibrium points (EPs) of FCNNs are given. Several sufficient conditions and criteria are proposed to ascertain the multiple O ( t − α ) -stability of delayed FCNNs. The O ( t − α ) -stability is the extension of Mittag-Leffler stability of fractional-order neural networks, which contains monostability and multistability. Moreover, the attraction basins of the stable EPs of FCNNs are estimated, which shows the attraction basins of the stable EPs can be larger than the divided subsets. These conditions and criteria supplement and improve the previous results. Finally, the results are illustrated by the simulation examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001246",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Attraction",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differential equation",
      "Economics",
      "Equilibrium point",
      "Finance",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Multistability",
      "Nonlinear system",
      "Order (exchange)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Fanghai"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      },
      {
        "surname": "Wu",
        "given_name": "Qiujie"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "Smoothing inertial neurodynamic approach for sparse signal reconstruction via L p -norm minimization",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.006",
    "abstract": "In this paper, we propose a smoothing inertial neurodynamic approach (SINA) which is used to deal with L p -norm minimization problem to reconstruct sparse signals. Note that the considered optimization problem is nonsmooth, nonconvex and non-Lipschitz. First, the problem is transformed into a smooth optimization problem based on smoothing approximation method, and the Lipschitz property of gradient of the smooth objective function is discussed. Then, SINA based on Karush–Kuhn–Tucker (KKT) condition, smoothing approximation and inertial dynamical approach, is designed to handle smooth optimization problem. The existence, uniqueness, global convergence and optimality of the solution of the SINA are discussed by the Cauchy–Lipschitz–Picard theorem, energy function and KKT condition. In addition, for p = 1 , the SINA has a mean sublinear convergence rate O 1 ∕ t under some mild conditions. Finally, some numerical examples on sparse signal reconstruction and image restoration are given to illustrate the theoretical results and the efficiency of SINA.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000484",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Computer science",
      "Inertial frame of reference",
      "Karush–Kuhn–Tucker conditions",
      "Lipschitz continuity",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Physics",
      "Quantum mechanics",
      "Smoothing",
      "Statistics",
      "Sublinear function",
      "Uniqueness"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "You"
      },
      {
        "surname": "Liao",
        "given_name": "Xiaofeng"
      },
      {
        "surname": "He",
        "given_name": "Xing"
      },
      {
        "surname": "Tang",
        "given_name": "Rongqiang"
      },
      {
        "surname": "Deng",
        "given_name": "Weiwei"
      }
    ]
  },
  {
    "title": "On decision regions of narrow deep neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.024",
    "abstract": "We show that for neural network functions that have width less or equal to the input dimension all connected components of decision regions are unbounded. The result holds for continuous and strictly monotonic activation functions as well as for the ReLU activation function. This complements recent results on approximation capabilities by Hanin and Sellke (2017) and connectivity of decision regions by Nguyen et al. (2018) for such narrow neural networks. Our results are illustrated by means of numerical experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000745",
    "keywords": [],
    "authors": [
      {
        "surname": "Beise",
        "given_name": "Hans-Peter"
      },
      {
        "surname": "Dias Da Cruz",
        "given_name": "Steve"
      },
      {
        "surname": "Schröder",
        "given_name": "Udo"
      }
    ]
  },
  {
    "title": "Exploring the spatial reasoning ability of neural models in human IQ tests",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.018",
    "abstract": "Although neural models have performed impressively well on various tasks such as image recognition and question answering, their reasoning ability has been measured in only few studies. In this work, we focus on spatial reasoning and explore the spatial understanding of neural models. First, we describe the following two spatial reasoning IQ tests: rotation and shape composition. Using well-defined rules, we constructed datasets that consist of various complexity levels. We designed a variety of experiments in terms of generalization, and evaluated six different baseline models on the newly generated datasets. We provide an analysis of the results and factors that affect the generalization abilities of models. Also, we analyze how neural models solve spatial reasoning tests with visual aids. We hope that our work can encourage further research into human-level spatial reasoning and provide a new direction for future work.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100068X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognition",
      "Computer science",
      "Focus (optics)",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Mental rotation",
      "Neuroscience",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Psychology",
      "Spatial intelligence",
      "Variety (cybernetics)",
      "Visual reasoning"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Hyunjae"
      },
      {
        "surname": "Koh",
        "given_name": "Yookyung"
      },
      {
        "surname": "Baek",
        "given_name": "Jinheon"
      },
      {
        "surname": "Kang",
        "given_name": "Jaewoo"
      }
    ]
  },
  {
    "title": "A statistical framework for non-negative matrix factorization based on generalized dual divergence",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.020",
    "abstract": "A statistical framework for non-negative matrix factorization based on generalized dual Kullback–Leibler divergence, which includes members of the exponential family of models, is proposed. A family of algorithms is developed using this framework, including under sparsity constraints, and its convergence proven using the Expectation–Maximization algorithm. The framework generalizes some existing methods for different noise structures and contrasts with the recently developed quasi-likelihood approach, thus providing a useful alternative for non-negative matrix factorization. A measure to evaluate the goodness-of-fit of the resulting factorization is described. The performance of the proposed methods is evaluated extensively using real life and simulated data and their utility in unsupervised and semi-supervised learning is illustrated using an application in cancer genomics. This framework can be viewed from the perspective of reinforcement learning, and can be adapted to incorporate discriminant functions and multi-layered neural networks within a deep learning paradigm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001088",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Convergence (economics)",
      "Divergence (linguistics)",
      "Economic growth",
      "Economics",
      "Eigenvalues and eigenvectors",
      "Exponential family",
      "Factorization",
      "Kullback–Leibler divergence",
      "Linguistics",
      "Machine learning",
      "Materials science",
      "Matrix (chemical analysis)",
      "Matrix decomposition",
      "Non-negative matrix factorization",
      "Philosophy",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Devarajan",
        "given_name": "Karthik"
      }
    ]
  },
  {
    "title": "Design and independent training of composable and reusable neural modules",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.034",
    "abstract": "Monolithic neural networks and end-to-end training have become the dominating trend in the field of deep learning, but the steady increase in complexity and training costs has raised concerns about the effectiveness and efficiency of this approach. We propose modular training as an alternative strategy for building modular neural networks by composing neural modules that can be trained independently and then kept for future use. We analyse the requirements and challenges regarding modularity and compositionality and, with that information in hand, we provide a detailed design and implementation guideline. We show experimental results of applying this modular approach to a Visual Question Answering (VQA) task parting from a previously published modular network and we evaluate its impact on the final performance, with respect to a baseline trained end-to-end. We also perform compositionality tests on CLEVR.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001222",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Engineering",
      "Field (mathematics)",
      "Genetics",
      "Machine learning",
      "Mathematics",
      "Meteorology",
      "Modular design",
      "Modularity (biology)",
      "Physics",
      "Principle of compositionality",
      "Programming language",
      "Pure mathematics",
      "Systems engineering",
      "Task (project management)",
      "Training (meteorology)"
    ],
    "authors": [
      {
        "surname": "Castillo-Bolado",
        "given_name": "David"
      },
      {
        "surname": "Guerra-Artal",
        "given_name": "Cayetano"
      },
      {
        "surname": "Hernández-Tejera",
        "given_name": "Mario"
      }
    ]
  },
  {
    "title": "Biomimetic FPGA-based spatial navigation model with grid cells and place cells",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.028",
    "abstract": "The mammalian spatial navigation system is characterized by an initial divergence of internal representations, with disparate classes of neurons responding to distinct features including location, speed, borders and head direction; an ensuing convergence finally enables navigation and path integration. Here, we report the algorithmic and hardware implementation of biomimetic neural structures encompassing a feed-forward trimodular, multi-layer architecture representing grid-cell, place-cell and decoding modules for navigation. The grid-cell module comprised of neurons that fired in a grid-like pattern, and was built of distinct layers that constituted the dorsoventral span of the medial entorhinal cortex. Each layer was built as an independent continuous attractor network with distinct grid-field spatial scales. The place-cell module comprised of neurons that fired at one or few spatial locations, organized into different clusters based on convergent modular inputs from different grid-cell layers, replicating the gradient in place-field size along the hippocampal dorso-ventral axis. The decoding module, a two-layer neural network that constitutes the convergence of the divergent representations in preceding modules, received inputs from the place-cell module and provided specific coordinates of the navigating object. After vital design optimizations involving all modules, we implemented the tri-modular structure on Zynq Ultrascale+ field-programmable gate array silicon chip, and demonstrated its capacity in precisely estimating the navigational trajectory with minimal overall resource consumption involving a mere 2.92% Look Up Table utilization. Our implementation of a biomimetic, digital spatial navigation system is stable, reliable, reconfigurable, real-time with execution time of about 32 s for 100k input samples (in contrast to 40 minutes on Intel Core i7-7700 CPU with 8 cores clocking at 3.60 GHz) and thus can be deployed for autonomous-robotic navigation without requiring additional sensors.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000368",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Cognition",
      "Computer science",
      "Decoding methods",
      "Embedded system",
      "Field-programmable gate array",
      "Geometry",
      "Grid",
      "Hippocampal formation",
      "Hippocampus",
      "Mathematics",
      "Modular design",
      "Neuroscience",
      "Operating system",
      "Path integration",
      "Place cell",
      "Retrosplenial cortex",
      "Spatial memory",
      "Working memory"
    ],
    "authors": [
      {
        "surname": "Krishna",
        "given_name": "Adithya"
      },
      {
        "surname": "Mittal",
        "given_name": "Divyansh"
      },
      {
        "surname": "Virupaksha",
        "given_name": "Siri Garudanagiri"
      },
      {
        "surname": "Nair",
        "given_name": "Abhishek Ramdas"
      },
      {
        "surname": "Narayanan",
        "given_name": "Rishikesh"
      },
      {
        "surname": "Thakur",
        "given_name": "Chetan Singh"
      }
    ]
  },
  {
    "title": "Visual question answering based on local-scene-aware referring expression generation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.001",
    "abstract": "Visual question answering requires a deep understanding of both images and natural language. However, most methods mainly focus on visual concept; such as the relationships between various objects. The limited use of object categories combined with their relationships or simple question embedding is insufficient for representing complex scenes and explaining decisions. To address this limitation, we propose the use of text expressions generated for images, because such expressions have few structural constraints and can provide richer descriptions of images. The generated expressions can be incorporated with visual features and question embedding to obtain the question-relevant answer. A joint-embedding multi-head attention network is also proposed to model three different information modalities with co-attention. We quantitatively and qualitatively evaluated the proposed method on the VQA v2 dataset and compared it with state-of-the-art methods in terms of answer prediction. The quality of the generated expressions was also evaluated on the RefCOCO, RefCOCO+, and RefCOCOg datasets. Experimental results demonstrate the effectiveness of the proposed method and reveal that it outperformed all of the competing methods in terms of both quantitative and qualitative results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000435",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Embedding",
      "Epistemology",
      "Expression (computer science)",
      "Focus (optics)",
      "Machine learning",
      "Natural language processing",
      "Object (grammar)",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Programming language",
      "Question answering",
      "Simple (philosophy)"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Jung-Jun"
      },
      {
        "surname": "Lee",
        "given_name": "Dong-Gyu"
      },
      {
        "surname": "Wu",
        "given_name": "Jialin"
      },
      {
        "surname": "Jung",
        "given_name": "Hong-Gyu"
      },
      {
        "surname": "Lee",
        "given_name": "Seong-Whan"
      }
    ]
  },
  {
    "title": "Detecting slender objects with uncertainty based on keypoint-displacement representation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.024",
    "abstract": "Slender objects are long and thin objects. Existing object detection networks are not specially designed for detecting slender objects. We propose a method to detect slender objects. We represent slender objects with a keypoint-displacement pattern instead of using axis-aligned bounding boxes, avoiding problems like orientation confusion and wrong elimination. In our network, three parallel branches predict keypoint heatmaps, displacement vector field, and displacement uncertainty heatmap respectively. We add the uncertainty branch to enable our network to give uncertainty together with detection results. The predicted uncertainty provides a continuous criterion to evaluate whether detection results are reliable. In addition, the uncertainty branch can lower the weight of ambiguous training samples, leading to more accurate detection results. We employ our proposed method in two typical practical applications. Edges of electrode sheets and pins of electronic chips are correctly detected as slender objects. Manufacturing quality is evaluated through analyzing the detection results, including keypoint number, displacement property, and uncertainty value.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100112X",
    "keywords": [
      "Artificial intelligence",
      "Bounding overwatch",
      "Computer science",
      "Computer vision",
      "Displacement (psychology)",
      "Epistemology",
      "Law",
      "Mathematics",
      "Object (grammar)",
      "Object detection",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Property (philosophy)",
      "Psychology",
      "Psychotherapist",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Kong",
        "given_name": "Zelong"
      },
      {
        "surname": "Zhang",
        "given_name": "Nian"
      },
      {
        "surname": "Guan",
        "given_name": "Xinping"
      },
      {
        "surname": "Le",
        "given_name": "Xinyi"
      }
    ]
  },
  {
    "title": "End-to-end keyword search system based on attention mechanism and energy scorer for low resource languages",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.002",
    "abstract": "Keyword search (KWS) means searching for keywords given by the user from continuous speech. Conventional KWS systems are based on Automatic Speech Recognition (ASR), where the input speech has to be first processed by the ASR system before keyword searching. In the recent decade, as deep learning and deep neural networks (DNN) become increasingly popular, KWS systems can also be trained in an end-to-end (E2E) manner. The main advantage of E2E KWS is that there is no need for speech recognition, which makes the training and searching procedure much more straightforward than the traditional ones. This article proposes an E2E KWS model, which consists of four parts: speech encoder–decoder, query encoder–decoder, attention mechanism, and energy scorer. Firstly, the proposed model outperforms the baseline model. Secondly, we find that under various supervision, character or phoneme sequences, speech or query encoders can extract the corresponding information, resulting in different performances. Moreover, we introduce an attention mechanism and invent a novel energy scorer, where the former can help locate keywords. The latter can make final decisions by considering speech embeddings, query embeddings, and attention weights in parallel. We evaluate our model on low resource conditions with about 10-hour training data for four different languages. The experiment results prove that the proposed model can work well on low resource conditions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001295",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer network",
      "Computer science",
      "Encoder",
      "Energy (signal processing)",
      "Epistemology",
      "Mathematics",
      "Mechanism (biology)",
      "Operating system",
      "Philosophy",
      "Resource (disambiguation)",
      "Speech recognition",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Zeyu"
      },
      {
        "surname": "Zhang",
        "given_name": "Wei-Qiang"
      }
    ]
  },
  {
    "title": "Comparative study using inverse ontology cogency and alternatives for concept recognition in the annotated National Library of Medicine database",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.018",
    "abstract": "This paper introduces inverse ontology cogency, a concept recognition process and distance function that is biologically-inspired and competitive with alternative methods. The paper introduces inverse ontology cogency as a new alternative method. It is a novel distance measure used in selecting the optimum mapping between ontology-specified concepts and phrases in free-form text. We also apply a multi-layer perceptron and text processing method for named entity recognition as an alternative to recurrent neural network methods. Automated named entity recognition, or concept recognition, is a common task in natural language processing. Similarities between confabulation theory and existing language models are discussed. This paper provides comparisons to MetaMap from the National Library of Medicine (NLM), a popular tool used in medicine to map free-form text to concepts in a medical ontology. The NLM provides a manually annotated database from the medical literature with concepts labeled, a unique, valuable source of ground truth, permitting comparison with MetaMap performance. Comparisons for different feature set combinations are made to demonstrate the effectiveness of inverse ontology cogency for entity recognition. Results indicate that using both inverse ontology cogency and corpora cogency improved concept recognition precision 20% over the best published MetaMap results. This demonstrates a new, effective approach for identifying medical concepts in text. This is the first time cogency has been explicitly invoked for reasoning with ontologies, and the first time it has been used on medical literature where high-quality ground truth is available for quality assessment.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000265",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Epistemology",
      "Information retrieval",
      "Natural language processing",
      "Ontology",
      "Philosophy"
    ],
    "authors": [
      {
        "surname": "Shannon",
        "given_name": "George J."
      },
      {
        "surname": "Rayapati",
        "given_name": "Naga"
      },
      {
        "surname": "Corns",
        "given_name": "Steven M."
      },
      {
        "surname": "Wunsch",
        "given_name": "Donald C."
      }
    ]
  },
  {
    "title": "Keyword spotting techniques to improve the recognition accuracy of user-defined keywords",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.012",
    "abstract": "The existing keyword spotting (KWS) techniques can recognize pre-defined keywords well but have a poor recognition accuracy for user-defined keywords. In real use cases, there is a high demand for users to define their keywords for various reasons. To address the problem, in this work, three techniques have been proposed, including incremental training with revised loss function, data augmentation, and fine-grained training, to improve the accuracy for the user-defined keywords while maintaining high accuracy for pre-defined keywords. The proposed techniques are applied to a classical KWS model (cnn-trad-fpool3) and a state-of-the-art KWS model (res15) respectively. The experimental results show that the proposed techniques have better recognition accuracy than several existing methods for the recognition of use-defined keywords. With the proposed techniques, the recognition accuracy of user-defined keywords on cnn-trad-fpool3 and res15 are significantly improved by 21.78% and 24.42%, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000927",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Keyword spotting",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Spotting"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Li"
      },
      {
        "surname": "Yang",
        "given_name": "Mingxue"
      },
      {
        "surname": "Gao",
        "given_name": "Xinyi"
      },
      {
        "surname": "Liu",
        "given_name": "Qingsong"
      },
      {
        "surname": "Yuan",
        "given_name": "Zhengxi"
      },
      {
        "surname": "Zhou",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "IHG-MA: Inductive heterogeneous graph multi-agent reinforcement learning for multi-intersection traffic signal control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.015",
    "abstract": "Multi-agent deep reinforcement learning (MDRL) has been widely applied in multi-intersection traffic signal control. The MDRL algorithms produce the decentralized cooperative traffic-signal policies via specialized multi-agent settings in certain traffic networks. However, the state-of-the-art MDRL algorithms seem to have some drawbacks. (1) It is desirable that the traffic-signal policies can be smoothly transferred to diverse traffic networks, however, the adopted specialized multi-agent settings hinder the traffic-signal policies to transfer and generalize to new traffic networks. (2) Existing MDRL algorithms which are based on deep neural networks cannot flexibly tackle a time-varying number of vehicles traversing the traffic networks. (3) Existing MDRL algorithms which are based on homogeneous graph neural networks fail to capture the heterogeneous features of objects in traffic networks. Motivated by the above observations, in this paper, we propose an algorithm, referred to as Inductive Heterogeneous Graph Multi-agent Actor–critic (IHG-MA) algorithm, for multi-intersection traffic signal control. The proposed IHG-MA algorithm has two features: (1) It conducts representation learning using a proposed inductive heterogeneous graph neural network (IHG), which is an inductive algorithm. The proposed IHG algorithm can generate embeddings for previously unseen nodes (e.g., new entry vehicles) and new graphs (e.g., new traffic networks). But unlike the algorithms based on the homogeneous graph neural network, IHG algorithm not only encodes heterogeneous features of each node, but also encodes heterogeneous structural (graph) information. (2) It also conducts policy learning using a proposed multi-agent actor–critic(MA), which is a decentralized cooperative framework. The proposed MA framework employs the final embeddings to compute the Q-value and policy, and then optimizes the whole algorithm via the Q-value and policy loss. Experimental results on different traffic datasets illustrate that IHG-MA algorithm outperforms the state-of-the-art algorithms in terms of multiple traffic metrics, which seems to be a new promising algorithm for multi-intersection traffic signal control.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000952",
    "keywords": [
      "Aerospace engineering",
      "Artificial intelligence",
      "Artificial neural network",
      "Civil engineering",
      "Computer science",
      "Distributed computing",
      "Engineering",
      "Geodesy",
      "Geography",
      "Graph",
      "Heterogeneous network",
      "Intelligent transportation system",
      "Intersection (aeronautics)",
      "Machine learning",
      "Reinforcement learning",
      "Telecommunications",
      "Theoretical computer science",
      "Traverse",
      "Wireless",
      "Wireless network"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Shantian"
      },
      {
        "surname": "Yang",
        "given_name": "Bo"
      },
      {
        "surname": "Kang",
        "given_name": "Zhongfeng"
      },
      {
        "surname": "Deng",
        "given_name": "Lihui"
      }
    ]
  },
  {
    "title": "A fast saddle-point dynamical system approach to robust deep learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.021",
    "abstract": "Recent focus on robustness to adversarial attacks for deep neural networks produced a large variety of algorithms for training robust models. Most of the effective algorithms involve solving the min–max optimization problem for training robust models (min step) under worst-case attacks (max step). However, they often suffer from high computational cost from running several inner maximization iterations (to find an optimal attack) inside every outer minimization iteration. Therefore, it becomes difficult to readily apply such algorithms for moderate to large size real world data sets. To alleviate this, we explore the effectiveness of iterative descent–ascent algorithms where the maximization and minimization steps are executed in an alternate fashion to simultaneously obtain the worst-case attack and the corresponding robust model. Specifically, we propose a novel discrete-time dynamical system-based algorithm that aims to find the saddle point of a min–max optimization problem in the presence of uncertainties. Under the assumptions that the cost function is convex and uncertainties enter concavely in the robust learning problem, we analytically show that our algorithm converges asymptotically to the robust optimal solution under a general adversarial budget constraints as induced by ℓ p norm, for 1 ≤ p ≤ ∞ . Based on our proposed analysis, we devise a fast robust training algorithm for deep neural networks. Although such training involves highly non-convex robust optimization problems, empirical results show that the algorithm can achieve significant robustness compared to other state-of-the-art robust models on benchmark data sets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100071X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Dynamical systems theory",
      "Gene",
      "Geodesy",
      "Geography",
      "Geometry",
      "Gradient descent",
      "Mathematical optimization",
      "Mathematics",
      "Maximization",
      "Minification",
      "Optimization problem",
      "Physics",
      "Quantum mechanics",
      "Robust optimization",
      "Robustness (evolution)",
      "Saddle point"
    ],
    "authors": [
      {
        "surname": "Esfandiari",
        "given_name": "Yasaman"
      },
      {
        "surname": "Balu",
        "given_name": "Aditya"
      },
      {
        "surname": "Ebrahimi",
        "given_name": "Keivan"
      },
      {
        "surname": "Vaidya",
        "given_name": "Umesh"
      },
      {
        "surname": "Elia",
        "given_name": "Nicola"
      },
      {
        "surname": "Sarkar",
        "given_name": "Soumik"
      }
    ]
  },
  {
    "title": "Convergence of the RMSProp deep learning method with penalty for nonconvex optimization",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.011",
    "abstract": "A norm version of the RMSProp algorithm with penalty (termed RMSPropW) is introduced into the deep learning framework and its convergence is addressed both analytically and numerically. For rigour, we consider the general nonconvex setting and prove the boundedness and convergence of the RMSPropW method in both deterministic and stochastic cases. This equips us with strict upper bounds on both the moving average squared norm of the gradient and the norm of weight parameters throughout the learning process, owing to the penalty term within the proposed cost function. In the deterministic (batch) case, the boundedness of the moving average squared norm of the gradient is employed to prove that the gradient sequence converges to zero when using a fixed step size, while with diminishing stepsizes, the minimum of the gradient sequence converges to zero. In the stochastic case, due to the boundedness of the weight evolution sequence, it is further shown that the weight sequence converges to a stationary point with probability 1. Finally, illustrative simulations are provided to support the theoretical analysis, including a comparison with the standard RMSProp on MNIST, CIFAR-10, and IMDB datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000538",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Genetics",
      "Law",
      "MNIST database",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Norm (philosophy)",
      "Penalty method",
      "Political science",
      "Sequence (biology)",
      "Stationary point",
      "Stochastic gradient descent"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Dongpo"
      },
      {
        "surname": "Zhang",
        "given_name": "Shengdong"
      },
      {
        "surname": "Zhang",
        "given_name": "Huisheng"
      },
      {
        "surname": "Mandic",
        "given_name": "Danilo P."
      }
    ]
  },
  {
    "title": "Cross Knowledge-based Generative Zero-Shot Learning approach with Taxonomy Regularization",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.009",
    "abstract": "Although zero-shot learning (ZSL) has an inferential capability of recognizing new classes that have never been seen before, it always faces two fundamental challenges of the cross modality and cross-domain challenges. In order to alleviate these problems, we develop a generative network-based ZSL approach equipped with the proposed Cross Knowledge Learning (CKL) scheme and Taxonomy Regularization (TR). In our approach, the semantic features are taken as inputs, and the output is the synthesized visual features generated from the corresponding semantic features. CKL enables more relevant semantic features to be trained for semantic-to-visual feature embedding in ZSL, while Taxonomy Regularization (TR) significantly improves the intersections with unseen images with more generalized visual features generated from generative network. Extensive experiments on several benchmark datasets (i.e., AwA1, AwA2, CUB, NAB and aPY) show that our approach is superior to these state-of-the-art methods in terms of ZSL image classification and retrieval.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000514",
    "keywords": [],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Cheng"
      },
      {
        "surname": "Xiang",
        "given_name": "Hongxin"
      },
      {
        "surname": "Zeng",
        "given_name": "Ting"
      },
      {
        "surname": "Yang",
        "given_name": "Yun"
      },
      {
        "surname": "Yu",
        "given_name": "Beibei"
      },
      {
        "surname": "Liu",
        "given_name": "Qing"
      }
    ]
  },
  {
    "title": "CiwGAN and fiwGAN: Encoding information in acoustic data to model lexical learning with Generative Adversarial Networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.017",
    "abstract": "How can deep neural networks encode information that corresponds to words in human speech into raw acoustic data? This paper proposes two neural network architectures for modeling unsupervised lexical learning from raw acoustic inputs: ciwGAN (Categorical InfoWaveGAN) and fiwGAN (Featural InfoWaveGAN). These combine Deep Convolutional GAN architecture for audio data (WaveGAN; Donahue et al., 2019) with the information theoretic extension of GAN – InfoGAN (Chen et al., 2016) – and propose a new latent space structure that can model featural learning simultaneously with a higher level classification and allows for a very low-dimension vector representation of lexical items. In addition to the Generator and Discriminator networks, the architectures introduce a network that learns to retrieve latent codes from generated audio outputs. Lexical learning is thus modeled as emergent from an architecture that forces a deep neural network to output data such that unique information is retrievable from its acoustic outputs. The networks trained on lexical items from the TIMIT corpus learn to encode unique information corresponding to lexical items in the form of categorical variables in their latent space. By manipulating these variables, the network outputs specific lexical items. The network occasionally outputs innovative lexical items that violate training data, but are linguistically interpretable and highly informative for cognitive modeling and neural network interpretability. Innovative outputs suggest that phonetic and phonological representations learned by the network can be productively recombined and directly paralleled to productivity in human speech: a fiwGAN network trained on suit and dark outputs innovative start, even though it never saw start or even a [st] sequence in the training data. We also argue that setting latent featural codes to values well beyond training range results in almost categorical generation of prototypical lexical items and reveals underlying values of each latent code. Probing deep neural networks trained on well understood dependencies in speech bears implications for latent space interpretability and understanding how deep neural networks learn meaningful representations, as well as potential for unsupervised text-to-speech generation in the GAN framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001052",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Encoding (memory)",
      "Generative grammar",
      "Generative model",
      "Machine learning",
      "Natural language processing",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Beguš",
        "given_name": "Gašper"
      }
    ]
  },
  {
    "title": "A generative adversarial network approach to (ensemble) weather prediction",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.003",
    "abstract": "We use a conditional deep convolutional generative adversarial network to predict the geopotential height of the 500 hPa pressure level, the two-meter temperature and the total precipitation for the next 24 h over Europe. The proposed models are trained on 4 years of ERA5 reanalysis data from with the goal to predict the associated meteorological fields in 2019. The forecasts show a good qualitative and quantitative agreement with the true reanalysis data for the geopotential height and two-meter temperature, while failing for total precipitation, thus indicating that weather forecasts based on data alone may be possible for specific meteorological parameters. We further use Monte-Carlo dropout to develop an ensemble weather prediction system based purely on deep learning strategies, which is computationally cheap and further improves the skill of the forecasting model, by allowing to quantify the uncertainty in the current weather forecast as learned by the model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000459",
    "keywords": [
      "Artificial intelligence",
      "Climatology",
      "Computer science",
      "Deep learning",
      "Dropout (neural networks)",
      "Environmental science",
      "Geography",
      "Geology",
      "Geopotential",
      "Geopotential height",
      "Machine learning",
      "Meteorology",
      "Precipitation"
    ],
    "authors": [
      {
        "surname": "Bihlo",
        "given_name": "Alex"
      }
    ]
  },
  {
    "title": "Unsupervised Anomaly Detection in Stream Data with Online Evolving Spiking Neural Networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.017",
    "abstract": "Unsupervised anomaly discovery in stream data is a research topic with many practical applications. However, in many cases, it is not easy to collect enough training data with labeled anomalies for supervised learning of an anomaly detector in order to deploy it later for identification of real anomalies in streaming data. It is thus important to design anomalies detectors that can correctly detect anomalies without access to labeled training data. Our idea is to adapt the Online evolving Spiking Neural Network (OeSNN) classifier to the anomaly detection task. As a result, we offer an Online evolving Spiking Neural Network for Unsupervised Anomaly Detection algorithm (OeSNN-UAD), which, unlike OeSNN, works in an unsupervised way and does not separate output neurons into disjoint decision classes. OeSNN-UAD uses our proposed new two-step anomaly detection method. Also, we derive new theoretical properties of neuronal model and input layer encoding of OeSNN, which enable more effective and efficient detection of anomalies in our OeSNN-UAD approach. The proposed OeSNN-UAD detector was experimentally compared with state-of-the-art unsupervised and semi-supervised detectors of anomalies in stream data from the Numenta Anomaly Benchmark and Yahoo Anomaly Datasets repositories. Our approach outperforms the other solutions provided in the literature in the case of data streams from the Numenta Anomaly Benchmark repository. Also, in the case of real data files of the Yahoo Anomaly Benchmark repository, OeSNN-UAD outperforms other selected algorithms, whereas in the case of Yahoo Anomaly Benchmark synthetic data files, it provides competitive results to the results recently reported in the literature.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000599",
    "keywords": [
      "Anomaly (physics)",
      "Anomaly detection",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Condensed matter physics",
      "Data mining",
      "Data stream mining",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Physics",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Maciąg",
        "given_name": "Piotr S."
      },
      {
        "surname": "Kryszkiewicz",
        "given_name": "Marzena"
      },
      {
        "surname": "Bembenik",
        "given_name": "Robert"
      },
      {
        "surname": "L. Lobo",
        "given_name": "Jesus"
      },
      {
        "surname": "Del Ser",
        "given_name": "Javier"
      }
    ]
  },
  {
    "title": "Computational reproductions of external force field adaption without assuming desired trajectories",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.030",
    "abstract": "Optimal feedback control is an established framework that is used to characterize human movement. However, it is not fully understood how the brain computes optimal gains through interactions with the environment. In the past study, we proposed a model of motor learning that identifies a set of feedback and feedforward controllers and a state predictor of the arm musculoskeletal system to control free reaching movements. In this study, we applied the model to force field adaptation tasks where normal reaching movements are disturbed by an external force imposed on the hand. Without a priori knowledge about the arm and environment, the model was able to adapt to the force field by generating counteracting forces to overcome it in a manner similar to what is reported in the behavioral literature. The kinematics of the movements generated by our model share characteristic features of human movements observed before and after force field adaptation. In addition, we demonstrate that the structure and learning algorithm introduced in our model induced a shift in the end-point’s equilibrium position and a static force modulation, accompanied by a fast and a slow learning process. Importantly, our model does not require desired trajectories, yields movements without specifying movement duration, and predicts force generation patterns by exploring the environment. Our model demonstrates a possible mechanism through which the central nervous system may control and adapt a point-to-point reaching movement without specifying a desired trajectory by continuously updating the body’s musculoskeletal model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000381",
    "keywords": [
      "A priori and a posteriori",
      "Acoustics",
      "Adaptation (eye)",
      "Artificial intelligence",
      "Astronomy",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Economics",
      "Engineering",
      "Epistemology",
      "Feed forward",
      "Field (mathematics)",
      "Finance",
      "Force field (fiction)",
      "Geometry",
      "Kinematics",
      "Mathematics",
      "Mechanism (biology)",
      "Movement (music)",
      "Operating system",
      "Optics",
      "Philosophy",
      "Physics",
      "Point (geometry)",
      "Position (finance)",
      "Process (computing)",
      "Programming language",
      "Pure mathematics",
      "Quantum mechanics",
      "Set (abstract data type)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Kambara",
        "given_name": "Hiroyuki"
      },
      {
        "surname": "Takagi",
        "given_name": "Atsushi"
      },
      {
        "surname": "Shimizu",
        "given_name": "Haruka"
      },
      {
        "surname": "Kawase",
        "given_name": "Toshihiro"
      },
      {
        "surname": "Yoshimura",
        "given_name": "Natsue"
      },
      {
        "surname": "Schweighofer",
        "given_name": "Nicolas"
      },
      {
        "surname": "Koike",
        "given_name": "Yasuharu"
      }
    ]
  },
  {
    "title": "Dense Residual Network: Enhancing global dense feature flow for character recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.005",
    "abstract": "Deep Convolutional Neural Networks (CNNs), such as Dense Convolutional Network (DenseNet), have achieved great success for image representation learning by capturing deep hierarchical features. However, most existing network architectures of simply stacking the convolutional layers fail to enable them to fully discover local and global feature information between layers. In this paper, we mainly investigate how to enhance the local and global feature learning abilities of DenseNet by fully exploiting the hierarchical features from all convolutional layers. Technically, we propose an effective convolutional deep model termed Dense Residual Network (DRN) for the task of optical character recognition. To define DRN, we propose a refined residual dense block (r-RDB) to retain the ability of local feature fusion and local residual learning of original RDB, which can reduce the computing efforts of inner layers at the same time. After fully capturing local residual dense features, we utilize the sum operation and several r-RDBs to construct a new block termed global dense block (GDB) by imitating the construction of dense blocks to adaptively learn global dense residual features in a holistic way. Finally, we use two convolutional layers to design a down-sampling block to reduce the global feature size and extract more informative deeper features. Extensive results show that our DRN can deliver enhanced results, compared with other related deep models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000472",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Block (permutation group theory)",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Feature (linguistics)",
      "Feature learning",
      "Geometry",
      "Law",
      "Linguistics",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Residual"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Zhao"
      },
      {
        "surname": "Tang",
        "given_name": "Zemin"
      },
      {
        "surname": "Wang",
        "given_name": "Yang"
      },
      {
        "surname": "Zhang",
        "given_name": "Zheng"
      },
      {
        "surname": "Zhan",
        "given_name": "Choujun"
      },
      {
        "surname": "Zha",
        "given_name": "Zhengjun"
      },
      {
        "surname": "Wang",
        "given_name": "Meng"
      }
    ]
  },
  {
    "title": "D-MONA: A dilated mixed-order non-local attention network for speaker and language recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.014",
    "abstract": "Attention-based convolutional neural network (CNN) models are increasingly being adopted for speaker and language recognition (SR/LR) tasks. These include time, frequency, spatial and channel attention, which can focus on useful time frames, frequency bands, regions or channels while extracting features. However, these traditional attention methods lack the exploration of complex information and multi-scale long-range speech feature interactions, which can benefit SR/LR tasks. To address these issues, this paper firstly proposes mixed-order attention (MOA) for low frame-level speech features to gain the finest grain multi-order information at higher resolution. We then combine that with a non-local attention (NLA) mechanism and a dilated residual structure to balance fine grained local detail with convolution from multi-scale long-range time/frequency regions in feature space. The proposed dilated mixed-order non-local attention network (D-MONA) exploits the detail available from the first and the second-order feature attention analysis, but achieves this over a much wider context than purely local attention. Experiments are conducted on three datasets, including two SR tasks of Voxceleb and CN-celeb, and one LR task, NIST LRE 07. For SR, D-MONA improves on ResNet-34 results by at least 29% and 15% for Voxceleb1 and CN-celeb respectively. For the LR task, a large improvement is achieved over ResNet-34 of 21% for the challenging 3s utterance condition, 59% for the 10s condition and 67% for the 30s condition. It also outperforms the state-of-the-art deep bottleneck feature-DNN (DBF-DNN) x-vector system at all scales.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000940",
    "keywords": [
      "Artificial intelligence",
      "Attention network",
      "Biology",
      "Bottleneck",
      "Computer science",
      "Context (archaeology)",
      "Convolutional neural network",
      "Embedded system",
      "Feature (linguistics)",
      "Linguistics",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Miao",
        "given_name": "Xiaoxiao"
      },
      {
        "surname": "McLoughlin",
        "given_name": "Ian"
      },
      {
        "surname": "Wang",
        "given_name": "Wenchao"
      },
      {
        "surname": "Zhang",
        "given_name": "Pengyuan"
      }
    ]
  },
  {
    "title": "D-MONA: A dilated mixed-order non-local attention network for speaker and language recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.014",
    "abstract": "Attention-based convolutional neural network (CNN) models are increasingly being adopted for speaker and language recognition (SR/LR) tasks. These include time, frequency, spatial and channel attention, which can focus on useful time frames, frequency bands, regions or channels while extracting features. However, these traditional attention methods lack the exploration of complex information and multi-scale long-range speech feature interactions, which can benefit SR/LR tasks. To address these issues, this paper firstly proposes mixed-order attention (MOA) for low frame-level speech features to gain the finest grain multi-order information at higher resolution. We then combine that with a non-local attention (NLA) mechanism and a dilated residual structure to balance fine grained local detail with convolution from multi-scale long-range time/frequency regions in feature space. The proposed dilated mixed-order non-local attention network (D-MONA) exploits the detail available from the first and the second-order feature attention analysis, but achieves this over a much wider context than purely local attention. Experiments are conducted on three datasets, including two SR tasks of Voxceleb and CN-celeb, and one LR task, NIST LRE 07. For SR, D-MONA improves on ResNet-34 results by at least 29% and 15% for Voxceleb1 and CN-celeb respectively. For the LR task, a large improvement is achieved over ResNet-34 of 21% for the challenging 3s utterance condition, 59% for the 10s condition and 67% for the 30s condition. It also outperforms the state-of-the-art deep bottleneck feature-DNN (DBF-DNN) x-vector system at all scales.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000940",
    "keywords": [
      "Artificial intelligence",
      "Attention network",
      "Biology",
      "Bottleneck",
      "Computer science",
      "Context (archaeology)",
      "Convolutional neural network",
      "Embedded system",
      "Feature (linguistics)",
      "Linguistics",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Miao",
        "given_name": "Xiaoxiao"
      },
      {
        "surname": "McLoughlin",
        "given_name": "Ian"
      },
      {
        "surname": "Wang",
        "given_name": "Wenchao"
      },
      {
        "surname": "Zhang",
        "given_name": "Pengyuan"
      }
    ]
  },
  {
    "title": "Knowledge graph embedding with shared latent semantic units",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.013",
    "abstract": "Knowledge graph embedding (KGE) aims to project both entities and relations into a continuous low-dimensional space. However, for a given knowledge graph (KG), only a small number of entities and relations occur many times, while the vast majority of entities and relations occur less frequently. This data sparsity problem has largely been ignored by most of the existing KGE models. To this end, in this paper, we propose a general technique to enable knowledge transfer among semantically similar entities or relations. Specifically, we define latent semantic units (LSUs), which are the sub-components of entity and relation embeddings. Semantically similar entities or relations are supposed to share the same LSUs, and thus knowledge can be transferred among entities or relations. Finally, extensive experiments show that the proposed technique is able to enhance existing KGE models and can provide better representations of KGs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000551",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Embedding",
      "Graph",
      "Information retrieval",
      "Knowledge graph",
      "Relation (database)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Zhao"
      },
      {
        "surname": "Zhuang",
        "given_name": "Fuzhen"
      },
      {
        "surname": "Qu",
        "given_name": "Meng"
      },
      {
        "surname": "Niu",
        "given_name": "Zheng-Yu"
      },
      {
        "surname": "Xiong",
        "given_name": "Hui"
      },
      {
        "surname": "He",
        "given_name": "Qing"
      }
    ]
  },
  {
    "title": "Stochastic quasi-synchronization of heterogeneous delayed impulsive dynamical networks via single impulsive control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.011",
    "abstract": "This paper investigates the quasi-synchronization problem of the stochastic heterogeneous complex dynamical networks with impulsive couplings and multiple time-varying delays. It is shown that this kind of dynamical networks can achieve exponential quasi-synchronization by exerting impulsive control added on only one chosen pinning node. By employing the Lyapunov stability theory, some sufficient criteria on quasi-synchronization for this dynamical network are established, revealing the relationship between the quasi-synchronization performance and the stochastic perturbations as well as the frequency and strength of impulsive coupling. Finally, some numerical examples are used to illustrate the effectiveness of the main results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000915",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Complex network",
      "Computer science",
      "Condensed matter physics",
      "Control (management)",
      "Control theory (sociology)",
      "Coupling (piping)",
      "Coupling strength",
      "Dynamical systems theory",
      "Engineering",
      "Lyapunov function",
      "Lyapunov stability",
      "Machine learning",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Synchronization (alternating current)",
      "Synchronization networks",
      "Topology (electrical circuits)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Ling",
        "given_name": "Guang"
      },
      {
        "surname": "Ge",
        "given_name": "Ming-Feng"
      },
      {
        "surname": "Liu",
        "given_name": "Xinghua"
      },
      {
        "surname": "Xiao",
        "given_name": "Gaoxi"
      },
      {
        "surname": "Fan",
        "given_name": "Qingju"
      }
    ]
  },
  {
    "title": "Synchronization criteria of delayed inertial neural networks with generally Markovian jumping",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.004",
    "abstract": "In this paper, the synchronization problem of inertial neural networks with time-varying delays and generally Markovian jumping is investigated. The second order differential equations are transformed into the first-order differential equations by utilizing the variable transformation method. The Markovian process in the systems is uncertain or partially known due to the delay of data transmission channel or the loss of data information, which is more general and practicable to consider generally Markovian jumping inertial neural networks. The synchronization criteria can be obtained by using the delay-dependent Lyapunov–Krasovskii functionals and higher order polynomial based relaxed inequality (HOPRII). In addition, the desired controllers are obtained by solving a set of linear matrix inequalities. Finally, the numerical examples are provided to demonstrate the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000460",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Channel (broadcasting)",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Delay differential equation",
      "Differential equation",
      "Gene",
      "Inertial frame of reference",
      "Markov process",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Statistics",
      "Synchronization (alternating current)",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Junyi"
      },
      {
        "surname": "Wang",
        "given_name": "Zhanshan"
      },
      {
        "surname": "Chen",
        "given_name": "Xiangyong"
      },
      {
        "surname": "Qiu",
        "given_name": "Jianlong"
      }
    ]
  },
  {
    "title": "Quantifying the separability of data classes in neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.035",
    "abstract": "We introduce the Generalized Discrimination Value (GDV) that measures, in a non-invasive manner, how well different data classes separate in each given layer of an artificial neural network. It turns out that, at the end of the training period, the GDV in each given layer L attains a highly reproducible value, irrespective of the initialization of the network’s connection weights. In the case of multi-layer perceptrons trained with error backpropagation, we find that classification of highly complex data sets requires a temporal reduction of class separability, marked by a characteristic ‘energy barrier’ in the initial part of the GDV(L) curve. Even more surprisingly, for a given data set, the GDV(L) is running through a fixed ‘master curve’, independently from the total number of network layers. Finally, due to its invariance with respect to dimensionality, the GDV may serve as a useful tool to compare the internal representational dynamics of artificial neural networks with different architectures for neural architecture search or network compression; or even with brain activity in order to decide between different candidate models of brain function.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001234",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Machine learning",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Schilling",
        "given_name": "Achim"
      },
      {
        "surname": "Maier",
        "given_name": "Andreas"
      },
      {
        "surname": "Gerum",
        "given_name": "Richard"
      },
      {
        "surname": "Metzner",
        "given_name": "Claus"
      },
      {
        "surname": "Krauss",
        "given_name": "Patrick"
      }
    ]
  },
  {
    "title": "Block-cyclic stochastic coordinate descent for deep neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.04.001",
    "abstract": "We present a stochastic first-order optimization algorithm, named block-cyclic stochastic coordinate descent (BCSC), that adds a cyclic constraint to stochastic block-coordinate descent in the selection of both data and parameters. It uses different subsets of the data to update different subsets of the parameters, thus limiting the detrimental effect of outliers in the training set. Empirical tests in image classification benchmark datasets show that BCSC outperforms state-of-the-art optimization methods in generalization leading to higher accuracy within the same number of update iterations. The improvements are consistent across different architectures and datasets, and can be combined with other training techniques and regularizations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001283",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biochemistry",
      "Block (permutation group theory)",
      "Chemistry",
      "Cluster analysis",
      "Computer science",
      "Coordinate descent",
      "Gene",
      "Generalization",
      "Geodesy",
      "Geography",
      "Geometry",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Outlier",
      "Programming language",
      "Robustness (evolution)",
      "Set (abstract data type)",
      "Stochastic block model",
      "Stochastic gradient descent",
      "Stochastic optimization"
    ],
    "authors": [
      {
        "surname": "Nakamura",
        "given_name": "Kensuke"
      },
      {
        "surname": "Soatto",
        "given_name": "Stefano"
      },
      {
        "surname": "Hong",
        "given_name": "Byung-Woo"
      }
    ]
  },
  {
    "title": "A noisy label and negative sample robust loss function for DNN-based distant supervised relation extraction",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.030",
    "abstract": "As a major method for relation extraction, distantly supervised relation extraction (DSRE) suffered from the noisy label problem and class imbalance problem (these two problems are also common for many other NLP tasks, e.g., text classification). However, there seems no existing research in DSRE or other NLP tasks that can simultaneously solve both problems, which is a significant insufficiency in related researches. In this paper, we propose a loss function which is robust to noisy label and efficient for the imbalanced class dataset. More specific, first we quantify the negative impacts of the noisy label and class imbalance problems. And then we construct a loss function that can minimize these negative impacts through a linear programming method. As far as we know, this seems to be the first attempt to address the noisy label problem and class imbalance problem simultaneously. We evaluated the constructed loss function on the distantly labeled dataset, our artificially noised dataset, human-annotated dataset of Docred, as well as the artificially noised dataset of CoNLL 2003. Experimental results indicate that a DNN model adopting the constructed loss function can outperform other models that adopt the state-of-the-art noisy label robust or negative sample robust loss functions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001180",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Chemistry",
      "Chromatography",
      "Class (philosophy)",
      "Computer science",
      "Construct (python library)",
      "Data mining",
      "Evolutionary biology",
      "Function (biology)",
      "Information extraction",
      "Machine learning",
      "Noisy data",
      "Pattern recognition (psychology)",
      "Programming language",
      "Relation (database)",
      "Relationship extraction",
      "Sample (material)"
    ],
    "authors": [
      {
        "surname": "Deng",
        "given_name": "Lihui"
      },
      {
        "surname": "Yang",
        "given_name": "Bo"
      },
      {
        "surname": "Kang",
        "given_name": "Zhongfeng"
      },
      {
        "surname": "Yang",
        "given_name": "Shantian"
      },
      {
        "surname": "Wu",
        "given_name": "Shihu"
      }
    ]
  },
  {
    "title": "Residual Neural Network precisely quantifies dysarthria severity-level based on short-duration speech segments",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.008",
    "abstract": "Recently, we have witnessed Deep Learning methodologies gaining significant attention for severity-based classification of dysarthric speech. Detecting dysarthria, quantifying its severity, are of paramount importance in various real-life applications, such as the assessment of patients’ progression in treatments, which includes an adequate planning of their therapy and the improvement of speech-based interactive systems in order to handle pathologically-affected voices automatically. Notably, current speech-powered tools often deal with short-duration speech segments and, consequently, are less efficient in dealing with impaired speech, even by using Convolutional Neural Networks (CNNs). Thus, detecting dysarthria severity-level based on short speech segments might help in improving the performance and applicability of those systems. To achieve this goal, we propose a novel Residual Network (ResNet)-based technique which receives short-duration speech segments as input. Statistically meaningful objective analysis of our experiments, reported over standard Universal Access corpus, exhibits average values of 21.35% and 22.48% improvement, compared to the baseline CNN, in terms of classification accuracy and F1-score, respectively. For additional comparisons, tests with Gaussian Mixture Models and Light CNNs were also performed. Overall, the values of 98.90% and 98.00% for classification accuracy and F1-score, respectively, were obtained with the proposed ResNet approach, confirming its efficacy and reassuring its practical applicability.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000502",
    "keywords": [
      "Acoustics",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Audiology",
      "Computer science",
      "Duration (music)",
      "Dysarthria",
      "Medicine",
      "Physics",
      "Residual",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Gupta",
        "given_name": "Siddhant"
      },
      {
        "surname": "Patil",
        "given_name": "Ankur T."
      },
      {
        "surname": "Purohit",
        "given_name": "Mirali"
      },
      {
        "surname": "Parmar",
        "given_name": "Mihir"
      },
      {
        "surname": "Patel",
        "given_name": "Maitreya"
      },
      {
        "surname": "Patil",
        "given_name": "Hemant A."
      },
      {
        "surname": "Guido",
        "given_name": "Rodrigo Capobianco"
      }
    ]
  },
  {
    "title": "Synchronization in finite time for variable-order fractional complex dynamic networks with multi-weights and discontinuous nodes based on sliding mode control strategy",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.03.033",
    "abstract": "This paper is concerned with the global synchronization in finite time for variable-order fractional complex dynamic networks with multi-weights, where the dynamic nodes are modeled to be discontinuous, and subject to the local Hölder nonlinear growth in a neighborhood of continuous points. Firstly, an inequality with respect to variable-order fractional derivative for convex functions is proposed. On the basis of the proposed inequality, a global convergence principle in finite time for absolutely continuous functions is developed. Secondly, based on proposed convergence principle in finite time, a new sliding mode surface is presented, and an appropriate sliding mode control law is designed to drive the trajectory of the error system to the prescribed sliding mode surface in finite time and remain on it forever. In addition, on the basis of differential inclusions theory and Lur’e Postnikov-type convex Lyapunov function approach, the sufficient conditions with respect to the global stability in finite time are established in terms of linear matrix inequalities for the error system on designed sliding mode surface. Moreover, the upper bound of the settling time is explicitly evaluated. Finally, the effectiveness and correction of synchronization strategies are illustrated through two simulation experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021001210",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Differential inclusion",
      "Economic growth",
      "Economics",
      "Linear matrix inequality",
      "Lyapunov function",
      "Lyapunov stability",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Sliding mode control",
      "Time derivative"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xia"
      },
      {
        "surname": "Wu",
        "given_name": "Huaiqin"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "An effective SteinGLM initialization scheme for training multi-layer feedforward sigmoidal neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.014",
    "abstract": "Network initialization is the first and critical step for training neural networks. In this paper, we propose a novel network initialization scheme based on the celebrated Stein’s identity. By viewing multi-layer feedforward sigmoidal neural networks as cascades of multi-index models, the projection weights to the first hidden layer are initialized using eigenvectors of the cross-moment matrix between the input’s second-order score function and the response. The input data is then forward propagated to the next layer and such a procedure can be repeated until all the hidden layers are initialized. Finally, the weights for the output layer are initialized by generalized linear modeling. Such a proposed SteinGLM method is shown through extensive numerical results to be much faster and more accurate than other popular methods commonly used for training neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000563",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Control engineering",
      "Engineering",
      "Feed forward",
      "Feedforward neural network",
      "Initialization",
      "Layer (electronics)",
      "Organic chemistry",
      "Programming language",
      "Sigmoid function"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Zebin"
      },
      {
        "surname": "Zhang",
        "given_name": "Hengtao"
      },
      {
        "surname": "Sudjianto",
        "given_name": "Agus"
      },
      {
        "surname": "Zhang",
        "given_name": "Aijun"
      }
    ]
  },
  {
    "title": "End-to-end novel visual categories learning via auxiliary self-supervision",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.015",
    "abstract": "Semi-supervised learning has largely alleviated the strong demand for large amount of annotations in deep learning. However, most of the methods have adopted a common assumption that there is always labeled data from the same class of unlabeled data, which is impractical and restricted for real-world applications. In this research work, our focus is on semi-supervised learning when the categories of unlabeled data and labeled data are disjoint from each other. The main challenge is how to effectively leverage knowledge in labeled data to unlabeled data when they are independent from each other, and not belonging to the same categories. Previous state-of-the-art methods have proposed to construct pairwise similarity pseudo labels as supervising signals. However, two issues are commonly inherent in these methods: (1) All of previous methods are comprised of multiple training phases, which makes it difficult to train the model in an end-to-end fashion. (2) Strong dependence on the quality of pairwise similarity pseudo labels limits the performance as pseudo labels are vulnerable to noise and bias. Therefore, we propose to exploit the use of self-supervision as auxiliary task during model training such that labeled data and unlabeled data will share the same set of surrogate labels and overall supervising signals can have strong regularization. By doing so, all modules in the proposed algorithm can be trained simultaneously, which will boost the learning capability as end-to-end learning can be achieved. Moreover, we propose to utilize local structure information in feature space during pairwise pseudo label construction, as local properties are more robust to noise. Extensive experiments have been conducted on three frequently used visual datasets, i.e., CIFAR-10, CIFAR-100 and SVHN, in this paper. Experiment results have indicated the effectiveness of our proposed algorithm as we have achieved new state-of-the-art performance for novel visual categories learning for these three datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000575",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Computer security",
      "Disjoint sets",
      "Exploit",
      "Feature vector",
      "Image (mathematics)",
      "Labeled data",
      "Leverage (statistics)",
      "Machine learning",
      "Mathematics",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Semi-supervised learning",
      "Similarity (geometry)"
    ],
    "authors": [
      {
        "surname": "Qing",
        "given_name": "Yuanyuan"
      },
      {
        "surname": "Zeng",
        "given_name": "Yijie"
      },
      {
        "surname": "Cao",
        "given_name": "Qi"
      },
      {
        "surname": "Huang",
        "given_name": "Guang-Bin"
      }
    ]
  },
  {
    "title": "Synchronization of memristive neural networks with unknown parameters via event-triggered adaptive control",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.029",
    "abstract": "This paper considers the drive-response synchronization of memristive neural networks (MNNs) with unknown parameters, where the unbounded discrete and bounded distributed time-varying delays are involved. Aiming at the unknown parameters of MNNs, the updating law of weight in response system and the gain of adaptive controller are proposed to realize the synchronization of delayed MNNs. In view of the limited communication and bandwidth, the event-triggered mechanism is introduced to adaptive control, which not only decreases the times of controller update and the amount of data sending out but also enables synchronization when parameters of MNNs are unknown. In addition, a relative threshold strategy, which is relative to fixed threshold strategy, is proposed to increase the inter-execution intervals and to improve the control effect. When the parameters of MNNs are known, the algebraic criteria of synchronization are established via event-triggered state feedback control by exploiting inequality techniques and calculus theorems. Finally, one simulation is presented to validate the effectiveness of the proposed results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000794",
    "keywords": [
      "Adaptive control",
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Bandwidth (computing)",
      "Biology",
      "Bounded function",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Mathematical analysis",
      "Mathematics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Yufeng"
      },
      {
        "surname": "Zhang",
        "given_name": "Hao"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "Unsupervised cross-domain named entity recognition using entity-aware adversarial training",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.027",
    "abstract": "The success of neural network based methods in named entity recognition (NER) is heavily relied on abundant manual labeled data. However, these NER methods are unavailable when the data is fully-unlabeled in a new domain. To address the problem, we propose an unsupervised cross-domain model which leverages labeled data from source domain to predict entities in unlabeled target domain. To relieve the distribution divergence when transferring knowledge from source to target domain, we apply adversarial training. Furthermore, we design an entity-aware attention module to guide the adversarial training to reduce the discrepancy of entity features between different domains. Experimental results demonstrate that our model outperforms other methods and achieves state-of-the-art performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304524",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Divergence (linguistics)",
      "Domain (mathematical analysis)",
      "Economics",
      "Labeled data",
      "Linguistics",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Named-entity recognition",
      "Natural language processing",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Task (project management)",
      "Training set"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Qi"
      },
      {
        "surname": "Zheng",
        "given_name": "Changmeng"
      },
      {
        "surname": "Cai",
        "given_name": "Yi"
      },
      {
        "surname": "Wang",
        "given_name": "Tao"
      },
      {
        "surname": "Xie",
        "given_name": "Haoran"
      },
      {
        "surname": "Li",
        "given_name": "Qing"
      }
    ]
  },
  {
    "title": "Towards effective deep transfer via attentive feature alignment",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.022",
    "abstract": "Training a deep convolutional network from scratch requires a large amount of labeled data, which however may not be available for many practical tasks. To alleviate the data burden, a practical approach is to adapt a pre-trained model learned on the large source domain to the target domain, but the performance can be limited when the source and target domain data distributions have large differences. Some recent works attempt to alleviate this issue by imposing feature alignment over the intermediate feature maps between the source and target networks. However, for a source model, many of the channels/spatial-features for each layer can be irrelevant to the target task. Thus, directly applying feature alignment may not achieve promising performance. In this paper, we propose an Attentive Feature Alignment (AFA) method for effective domain knowledge transfer by identifying and attending on the relevant channels and spatial features between two domains. To this end, we devise two learnable attentive modules at both the channel and spatial levels. We then sequentially perform attentive spatial- and channel-level feature alignments between the source and target networks, in which the target model and attentive module are learned simultaneously. Moreover, we theoretically analyze the generalization performance of our method, which confirms its superiority to existing methods. Extensive experiments on both image classification and face recognition demonstrate the effectiveness of our method. The source code and the pre-trained models are available at https://github.com/xiezheng-cs/AFAhttps://github.com/xiezheng-cs/AFA.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000307",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Code (set theory)",
      "Computer network",
      "Computer science",
      "Convolutional neural network",
      "Domain (mathematical analysis)",
      "Economics",
      "Feature (linguistics)",
      "Feature learning",
      "Generalization",
      "Linguistics",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Set (abstract data type)",
      "Source code",
      "Task (project management)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Zheng"
      },
      {
        "surname": "Wen",
        "given_name": "Zhiquan"
      },
      {
        "surname": "Wang",
        "given_name": "Yaowei"
      },
      {
        "surname": "Wu",
        "given_name": "Qingyao"
      },
      {
        "surname": "Tan",
        "given_name": "Mingkui"
      }
    ]
  },
  {
    "title": "Self-augmentation: Generalizing deep networks to unseen classes for few-shot learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.007",
    "abstract": "Few-shot learning aims to classify unseen classes with a few training examples. While recent works have shown that standard mini-batch training with carefully designed training strategies can improve generalization ability for unseen classes, well-known problems in deep networks such as memorizing training statistics have been less explored for few-shot learning. To tackle this issue, we propose self-augmentation that consolidates self-mix and self-distillation. Specifically, we propose a regional dropout technique called self-mix, in which a patch of an image is substituted into other values in the same image. With this dropout effect, we show that the generalization ability of deep networks can be improved as it prevents us from learning specific structures of a dataset. Then, we employ a backbone network that has auxiliary branches with its own classifier to enforce knowledge sharing. This sharing of knowledge forces each branch to learn diverse optimal points during training. Additionally, we present a local representation learner to further exploit a few training examples of unseen classes by generating fake queries and novel weights. Experimental results show that the proposed method outperforms the state-of-the-art methods for prevalent few-shot benchmarks and improves the generalization ability.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000496",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Classifier (UML)",
      "Computer science",
      "Computer security",
      "Dropout (neural networks)",
      "Exploit",
      "Generalization",
      "Image (mathematics)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Shot (pellet)"
    ],
    "authors": [
      {
        "surname": "Seo",
        "given_name": "Jin-Woo"
      },
      {
        "surname": "Jung",
        "given_name": "Hong-Gyu"
      },
      {
        "surname": "Lee",
        "given_name": "Seong-Whan"
      }
    ]
  },
  {
    "title": "General stochastic separation theorems with optimal bounds",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.034",
    "abstract": "Phenomenon of stochastic separability was revealed and used in machine learning to correct errors of Artificial Intelligence (AI) systems and analyze AI instabilities. In high-dimensional datasets under broad assumptions each point can be separated from the rest of the set by simple and robust Fisher’s discriminant (is Fisher separable). Errors or clusters of errors can be separated from the rest of the data. The ability to correct an AI system also opens up the possibility of an attack on it, and the high dimensionality induces vulnerabilities caused by the same stochastic separability that holds the keys to understanding the fundamentals of robustness and adaptivity in high-dimensional data-driven AI. To manage errors and analyze vulnerabilities, the stochastic separation theorems should evaluate the probability that the dataset will be Fisher separable in given dimensionality and for a given class of distributions. Explicit and optimal estimates of these separation probabilities are required, and this problem is solved in the present work. The general stochastic separation theorems with optimal probability estimates are obtained for important classes of distributions: log-concave distribution, their convex combinations and product distributions. The standard i.i.d. assumption was significantly relaxed. These theorems and estimates can be used both for correction of high-dimensional data driven AI systems and for analysis of their vulnerabilities. The third area of application is the emergence of memories in ensembles of neurons, the phenomena of grandmother’s cells and sparse coding in the brain, and explanation of unexpected effectiveness of small neural ensembles in high-dimensional brain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000423",
    "keywords": [
      "Applied mathematics",
      "Mathematical economics",
      "Mathematical optimization",
      "Mathematics",
      "Separation (statistics)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Grechuk",
        "given_name": "Bogdan"
      },
      {
        "surname": "Gorban",
        "given_name": "Alexander N."
      },
      {
        "surname": "Tyukin",
        "given_name": "Ivan Y."
      }
    ]
  },
  {
    "title": "Fast convergence rates of deep neural networks for classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.012",
    "abstract": "We derive the fast convergence rates of a deep neural network (DNN) classifier with the rectified linear unit (ReLU) activation function learned using the hinge loss. We consider three cases for a true model: (1) a smooth decision boundary, (2) smooth conditional class probability, and (3) the margin condition (i.e., the probability of inputs near the decision boundary is small). We show that the DNN classifier learned using the hinge loss achieves fast rate convergences for all three cases provided that the architecture (i.e., the number of layers, number of nodes and sparsity) is carefully selected. An important implication is that DNN architectures are very flexible for use in various cases without much modification. In addition, we consider a DNN classifier learned by minimizing the cross-entropy, and show that the DNN classifier achieves a fast convergence rate under the conditions that the noise exponent and margin exponent are large. Even though they are strong, we explain that these two conditions are not too absurd for image classification problems. To confirm our theoretical explanation, we present the results of a small numerical study conducted to compare the hinge loss and cross-entropy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100054X",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Classifier (UML)",
      "Computer network",
      "Computer science",
      "Contextual image classification",
      "Cross entropy",
      "Decision boundary",
      "Deep neural networks",
      "Entropy (arrow of time)",
      "Hinge loss",
      "Image (mathematics)",
      "Linear classifier",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Rate of convergence",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Yongdai"
      },
      {
        "surname": "Ohn",
        "given_name": "Ilsang"
      },
      {
        "surname": "Kim",
        "given_name": "Dongha"
      }
    ]
  },
  {
    "title": "Fading memory echo state networks are universal",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.025",
    "abstract": "Echo state networks (ESNs) have been recently proved to be universal approximants for input/output systems with respect to various L p -type criteria. When 1 ≤ p < ∞ , only p -integrability hypotheses need to be imposed, while in the case p = ∞ a uniform boundedness hypotheses on the inputs is required. This note shows that, in the last case, a universal family of ESNs can be constructed that contains exclusively elements that have the echo state and the fading memory properties. This conclusion could not be drawn with the results and methods available so far in the literature.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000332",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer network",
      "Computer science",
      "Decoding methods",
      "Echo (communications protocol)",
      "Echo state network",
      "Fading",
      "Mathematics",
      "Recurrent neural network",
      "Reservoir computing",
      "Speech recognition",
      "State (computer science)"
    ],
    "authors": [
      {
        "surname": "Gonon",
        "given_name": "Lukas"
      },
      {
        "surname": "Ortega",
        "given_name": "Juan-Pablo"
      }
    ]
  },
  {
    "title": "A proximal neurodynamic model for solving inverse mixed variational inequalities",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.012",
    "abstract": "This paper proposes a proximal neurodynamic model (PNDM) for solving inverse mixed variational inequalities (IMVIs) based on the proximal operator. It is shown that the PNDM has a unique continuous solution under the condition of Lipschitz continuity (L-continuity). It is also shown that the equilibrium point of the proposed PNDM is asymptotically stable or exponentially stable under some mild conditions. Finally, three numerical examples are presented to illustrate effectiveness of the proposed PNDM.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000204",
    "keywords": [
      "Applied mathematics",
      "Biochemistry",
      "Chemistry",
      "Gene",
      "Geometry",
      "Inverse",
      "Lipschitz continuity",
      "Mathematical analysis",
      "Mathematics",
      "Operator (biology)",
      "Repressor",
      "Transcription factor",
      "Variational inequality"
    ],
    "authors": [
      {
        "surname": "Ju",
        "given_name": "Xingxing"
      },
      {
        "surname": "Li",
        "given_name": "Chuandong"
      },
      {
        "surname": "He",
        "given_name": "Xing"
      },
      {
        "surname": "Feng",
        "given_name": "Gang"
      }
    ]
  },
  {
    "title": "Explanation of emotion regulation mechanism of mindfulness using a brain function model",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.029",
    "abstract": "The emotion regulation mechanism of mindfulness plays an important role in the stress reduction effect. Many researchers in the fields of cognitive psychology and cognitive neuroscience have attempted to elucidate this mechanism by documenting the cognitive processes that occur and the neural activities that characterize each process. However, previous findings have not revealed the mechanism of information propagation in the brain that achieves emotion regulation during mindfulness. In this study, we constructed a functional brain model based on its anatomical network structure and a computational model representing the propagation of information between brain regions. We then examined the effects of mindfulness meditation on information propagation in the brain using simulations of changes in the activity of each region. These simulations of changes represent the degree of processing resource allocation to the neural activity via changes in the weights of each region’s output. As a result of the simulations, we reveal how the neural activity characteristic of emotion regulation in mindfulness, which has been reported in previous studies, is realized in the brain. Mindfulness meditation increases the weight of the output from each region of the thalamus and sensory cortex, which processes sensory stimuli from the external world. This sensory information activates the insula and anterior cingulate cortex (ACC). The orbitofrontal cortex and dorsolateral prefrontal cortex inhibit amygdala activity (i.e., top-down emotion regulation). However, when mindfulness meditation dominates bottom-up processing via sensory stimuli from the external world, amygdala activity increases through the insula and ACC activation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100037X",
    "keywords": [
      "Amygdala",
      "Anterior cingulate cortex",
      "Cognition",
      "Cognitive psychology",
      "Dorsolateral prefrontal cortex",
      "Epistemology",
      "Functional magnetic resonance imaging",
      "Insula",
      "Mechanism (biology)",
      "Meditation",
      "Mindfulness",
      "Neuroscience",
      "Orbitofrontal cortex",
      "Philosophy",
      "Prefrontal cortex",
      "Psychology",
      "Psychotherapist",
      "Sensory system",
      "Theology"
    ],
    "authors": [
      {
        "surname": "Nakamura",
        "given_name": "Haruka"
      },
      {
        "surname": "Tawatsuji",
        "given_name": "Yoshimasa"
      },
      {
        "surname": "Fang",
        "given_name": "Siyuan"
      },
      {
        "surname": "Matsui",
        "given_name": "Tatsunori"
      }
    ]
  },
  {
    "title": "Paradoxical sensory reactivity induced by functional disconnection in a robot model of neurodevelopmental disorder",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.033",
    "abstract": "Neurodevelopmental disorders are characterized by heterogeneous and non-specific nature of their clinical symptoms. In particular, hyper- and hypo-reactivity to sensory stimuli are diagnostic features of autism spectrum disorder and are reported across many neurodevelopmental disorders. However, computational mechanisms underlying the unusual paradoxical behaviors remain unclear. In this study, using a robot controlled by a hierarchical recurrent neural network model with predictive processing and learning mechanism, we simulated how functional disconnection altered the learning process and subsequent behavioral reactivity to environmental change. The results show that, through the learning process, long-range functional disconnection between distinct network levels could simultaneously lower the precision of sensory information and higher-level prediction. The alteration caused a robot to exhibit sensory-dominated and sensory-ignoring behaviors ascribed to sensory hyper- and hypo-reactivity, respectively. As long-range functional disconnection became more severe, a frequency shift from hyporeactivity to hyperreactivity was observed, paralleling an early sign of autism spectrum disorder. Furthermore, local functional disconnection at the level of sensory processing similarly induced hyporeactivity due to low sensory precision. These findings suggest a computational explanation for paradoxical sensory behaviors in neurodevelopmental disorders, such as coexisting hyper- and hypo-reactivity to sensory stimulus. A neurorobotics approach may be useful for bridging various levels of understanding in neurodevelopmental disorders and providing insights into mechanisms underlying complex clinical symptoms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000411",
    "keywords": [
      "Autism",
      "Autism spectrum disorder",
      "Cognitive psychology",
      "Developmental psychology",
      "Disconnection",
      "Law",
      "Neurodevelopmental disorder",
      "Neuroscience",
      "Political science",
      "Psychology",
      "Sensory processing",
      "Sensory system",
      "Stimulus (psychology)"
    ],
    "authors": [
      {
        "surname": "Idei",
        "given_name": "Hayato"
      },
      {
        "surname": "Murata",
        "given_name": "Shingo"
      },
      {
        "surname": "Yamashita",
        "given_name": "Yuichi"
      },
      {
        "surname": "Ogata",
        "given_name": "Tetsuya"
      }
    ]
  },
  {
    "title": "Compositional memory in attractor neural networks with one-step learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.031",
    "abstract": "Compositionality refers to the ability of an intelligent system to construct models out of reusable parts. This is critical for the productivity and generalization of human reasoning, and is considered a necessary ingredient for human-level artificial intelligence. While traditional symbolic methods have proven effective for modeling compositionality, artificial neural networks struggle to learn systematic rules for encoding generalizable structured models. We suggest that this is due in part to short-term memory that is based on persistent maintenance of activity patterns without fast weight changes. We present a recurrent neural network that encodes structured representations as systems of contextually-gated dynamical attractors called attractor graphs. This network implements a functionally compositional working memory that is manipulated using top-down gating and fast local learning. We evaluate this approach with empirical experiments on storage and retrieval of graph-based data structures, as well as an automated hierarchical planning task. Our results demonstrate that compositional structures can be stored in and retrieved from neural working memory without persistent maintenance of multiple activity patterns. Further, memory capacity is improved by the use of a fast store-erase learning rule that permits controlled erasure and mutation of previously learned associations. We conclude that the combination of top-down gating and fast associative learning provides recurrent neural networks with a robust functional mechanism for compositional working memory.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000393",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Attractor",
      "Biology",
      "Cognition",
      "Computer science",
      "Encoding (memory)",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Neuroscience",
      "Principle of compositionality",
      "Recurrent neural network",
      "Theoretical computer science",
      "Working memory"
    ],
    "authors": [
      {
        "surname": "Davis",
        "given_name": "Gregory P."
      },
      {
        "surname": "Katz",
        "given_name": "Garrett E."
      },
      {
        "surname": "Gentili",
        "given_name": "Rodolphe J."
      },
      {
        "surname": "Reggia",
        "given_name": "James A."
      }
    ]
  },
  {
    "title": "Recurrent neural network with noise rejection for cyclic motion generation of robotic manipulators",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.002",
    "abstract": "Recurrent neural network (RNN), as a kind of neural network with outstanding computing capability, improvability, and hardware realizability, has been widely used in various fields, especially in robotics. In this paper, an RNN with noise rejection is deliberately constructed to remedy the issue of joint-angle drift frequently occurring during the cyclic motion generation (CMG) of a manipulator in a noisy environment. Different from general RNNs, the proposed RNN possesses inherent noise immunity, especially for time-varying polynomial noises. Besides, proofs on the convergence of the proposed RNN in the absence and presence of noises are given. Furthermore, we carry out simulations on manipulators PUMA 560 and UR5 to demonstrate the reliability of the proposed RNN in remedying joint-angle drift, and comparison simulations under different noisy conditions further verify its superiority. In addition, experiments are conducted on manipulator FRANKA Panda to elucidate the realizability of the proposed RNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000447",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Image (mathematics)",
      "Noise (video)",
      "Realizability",
      "Recurrent neural network",
      "Robot",
      "Robot manipulator",
      "Robotics"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Mei"
      },
      {
        "surname": "He",
        "given_name": "Li"
      },
      {
        "surname": "Hu",
        "given_name": "Bin"
      },
      {
        "surname": "Li",
        "given_name": "Shuai"
      }
    ]
  },
  {
    "title": "A new recursive least squares-based learning algorithm for spiking neurons",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.016",
    "abstract": "Spiking neural networks (SNNs) are regarded as effective models for processing spatio-temporal information. However, their inherent complexity of temporal coding makes it an arduous task to put forward an effective supervised learning algorithm, which still puzzles researchers in this area. In this paper, we propose a Recursive Least Squares-Based Learning Rule (RLSBLR) for SNN to generate the desired spatio-temporal spike train. During the learning process of our method, the weight update is driven by the cost function defined by the difference between the membrane potential and the firing threshold. The amount of weight modification depends not only on the impact of the current error function, but also on the previous error functions which are evaluated by current weights. In order to improve the learning performance, we integrate a modified synaptic delay learning to the proposed RLSBLR. We conduct experiments in different settings, such as spiking lengths, number of inputs, firing rates, noises and learning parameters, to thoroughly investigate the performance of this learning algorithm. The proposed RLSBLR is compared with competitive algorithms of Perceptron-Based Spiking Neuron Learning Rule (PBSNLR) and Remote Supervised Method (ReSuMe). Experimental results demonstrate that the proposed RLSBLR can achieve higher learning accuracy, higher efficiency and better robustness against different types of noise. In addition, we apply the proposed RLSBLR to open source database TIDIGITS, and the results show that our algorithm has a good practical application performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000241",
    "keywords": [
      "Adaptive filter",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Competitive learning",
      "Computer science",
      "Gene",
      "Generalization error",
      "Learning rule",
      "Machine learning",
      "Multilayer perceptron",
      "Pattern recognition (psychology)",
      "Recursive least squares filter",
      "Robustness (evolution)",
      "Spiking neural network",
      "Supervised learning",
      "Unsupervised learning",
      "Wake-sleep algorithm"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yun"
      },
      {
        "surname": "Qu",
        "given_name": "Hong"
      },
      {
        "surname": "Luo",
        "given_name": "Xiaoling"
      },
      {
        "surname": "Chen",
        "given_name": "Yi"
      },
      {
        "surname": "Wang",
        "given_name": "Yuchen"
      },
      {
        "surname": "Zhang",
        "given_name": "Malu"
      },
      {
        "surname": "Li",
        "given_name": "Zefang"
      }
    ]
  },
  {
    "title": "SAM-GAN: Self-Attention supporting Multi-stage Generative Adversarial Networks for text-to-image synthesis",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.023",
    "abstract": "Synthesizing photo-realistic images based on text descriptions is a challenging task in the field of computer vision. Although generative adversarial networks have made significant breakthroughs in this task, they still face huge challenges in generating high-quality visually realistic images consistent with the semantics of text. Generally, existing text-to-image methods accomplish this task with two steps, that is, first generating an initial image with a rough outline and color, and then gradually yielding the image within high-resolution from the initial image. However, one drawback of these methods is that, if the quality of the initial image generation is not high, it is hard to generate a satisfactory high-resolution image. In this paper, we propose SAM-GAN, Self-Attention supporting Multi-stage Generative Adversarial Networks, for text-to-image synthesis. With the self-attention mechanism, the model can establish the multi-level dependence of the image and fuse the sentence- and word-level visual-semantic vectors, to improve the quality of the generated image. Furthermore, a multi-stage perceptual loss is introduced to enhance the semantic similarity between the synthesized image and the real image, thus enhancing the visual-semantic consistency between text and images. For the diversity of the generated images, a mode seeking regularization term is integrated into the model. The results of extensive experiments and ablation studies, which were conducted in the Caltech-UCSD Birds and Microsoft Common Objects in Context datasets, show that our model is superior to competitive models in text-to-image synthesis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000319",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Context (archaeology)",
      "Economics",
      "Generative grammar",
      "Image (mathematics)",
      "Management",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Programming language",
      "Semantics (computer science)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Dunlu"
      },
      {
        "surname": "Yang",
        "given_name": "Wuchen"
      },
      {
        "surname": "Liu",
        "given_name": "Cong"
      },
      {
        "surname": "Lü",
        "given_name": "Shuairui"
      }
    ]
  },
  {
    "title": "Small universal spiking neural P systems with dendritic/axonal delays and dendritic trunk/feedback",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.02.010",
    "abstract": "In spiking neural P (SN P) systems, neurons are interconnected by means of synapses, and they use spikes to communicate with each other. However, in biology, the complex structure of dendritic tree is also an important part in the communication scheme between neurons since these structures are linked to advanced neural process such as learning and memory formation. In this work, we present a new variant of the SN P systems inspired by diverse dendrite and axon phenomena such as dendritic feedback, dendritic trunk, dendritic delays and axonal delays, respectively. This new variant is referred to as a spiking neural P system with dendritic and axonal computation (DACSN P system). Specifically, we include experimentally proven biological features in the current SN P systems to reduce the computational complexity of the soma by providing it with stable firing patterns through dendritic delays, dendritic feedback and axonal delays. As a consequence, the proposed DACSN P systems use the minimum number of synapses and neurons with simple and homogeneous standard spiking rules. Here, we study the computational capabilities of a DACSN P system. In particular, we prove that DACSN P systems with dendritic and axonal behavior are universal as both number-accepting/generating devices. In addition, we constructed a small universal SN P system using 39 neurons with standard spiking rules to compute any Turing computable function.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000526",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Axon",
      "Biology",
      "Computer science",
      "Dendrite (mathematics)",
      "Dendritic spike",
      "Excitatory postsynaptic potential",
      "Geometry",
      "Inhibitory postsynaptic potential",
      "Mathematics",
      "Neuroscience",
      "Operating system",
      "Process (computing)",
      "Soma",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Garcia",
        "given_name": "Luis"
      },
      {
        "surname": "Sanchez",
        "given_name": "Giovanny"
      },
      {
        "surname": "Vazquez",
        "given_name": "Eduardo"
      },
      {
        "surname": "Avalos",
        "given_name": "Gerardo"
      },
      {
        "surname": "Anides",
        "given_name": "Esteban"
      },
      {
        "surname": "Nakano",
        "given_name": "Mariko"
      },
      {
        "surname": "Sanchez",
        "given_name": "Gabriel"
      },
      {
        "surname": "Perez",
        "given_name": "Hector"
      }
    ]
  },
  {
    "title": "A survey on modern trainable activation functions",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.026",
    "abstract": "In neural networks literature, there is a strong interest in identifying and defining activation functions which can improve neural network performance. In recent years there has been a renovated interest in the scientific community in investigating activation functions which can be trained during the learning process, usually referred to as trainable, learnable or adaptable activation functions. They appear to lead to better network performance. Diverse and heterogeneous models of trainable activation function have been proposed in the literature. In this paper, we present a survey of these models. Starting from a discussion on the use of the term “activation function” in literature, we propose a taxonomy of trainable activation functions, highlight common and distinctive proprieties of recent and past models, and discuss main advantages and limitations of this type of approach. We show that many of the proposed approaches are equivalent to adding neuron layers which use fixed (non-trainable) activation functions and some simple local rule that constrains the corresponding weight layers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000344",
    "keywords": [
      "Activation function",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Epistemology",
      "Evolutionary biology",
      "Function (biology)",
      "Operating system",
      "Philosophy",
      "Process (computing)",
      "Simple (philosophy)"
    ],
    "authors": [
      {
        "surname": "Apicella",
        "given_name": "Andrea"
      },
      {
        "surname": "Donnarumma",
        "given_name": "Francesco"
      },
      {
        "surname": "Isgrò",
        "given_name": "Francesco"
      },
      {
        "surname": "Prevete",
        "given_name": "Roberto"
      }
    ]
  },
  {
    "title": "Words as a window: Using word embeddings to explore the learned representations of Convolutional Neural Networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.009",
    "abstract": "As deep neural net architectures minimize loss, they accumulate information in a hierarchy of learned representations that ultimately serve the network’s final goal. Different architectures tackle this problem in slightly different ways, but all create intermediate representational spaces built to inform their final prediction. Here we show that very different neural networks trained on two very different tasks build knowledge representations that display similar underlying patterns. Namely, we show that the representational spaces of several distributional semantic models bear a remarkable resemblance to several Convolutional Neural Network (CNN) architectures (trained for image classification). We use this information to explore the network behavior of CNNs (1) in pretrained models, (2) during training, and (3) during adversarial attacks. We use these findings to motivate several applications aimed at improving future research on CNNs. Our work illustrates the power of using one model to explore another, gives new insights into the function of CNN models, and provides a framework for others to perform similar analyses when developing new architectures. We show that one neural network model can provide a window into understanding another.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304263",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Economics",
      "Hierarchy",
      "Linguistics",
      "Machine learning",
      "Market economy",
      "Natural language processing",
      "Operating system",
      "Philosophy",
      "Window (computing)",
      "Word (group theory)"
    ],
    "authors": [
      {
        "surname": "Dharmaretnam",
        "given_name": "Dhanush"
      },
      {
        "surname": "Foster",
        "given_name": "Chris"
      },
      {
        "surname": "Fyshe",
        "given_name": "Alona"
      }
    ]
  },
  {
    "title": "Robustifying models against adversarial attacks by Langevin dynamics",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.024",
    "abstract": "Adversarial attacks on deep learning models have compromised their performance considerably. As remedies, a number of defense methods were proposed, which however, have been circumvented by newer and more sophisticated attacking strategies. In the midst of this ensuing arms race, the problem of robustness against adversarial attacks still remains a challenging task. This paper proposes a novel, simple yet effective defense strategy where off-manifold adversarial samples are driven towards high density regions of the data generating distribution of the (unknown) target class by the Metropolis-adjusted Langevin algorithm (MALA) with perceptual boundary taken into account. To achieve this task, we introduce a generative model of the conditional distribution of the inputs given labels that can be learned through a supervised Denoising Autoencoder (sDAE) in alignment with a discriminative classifier. Our algorithm, called MALA for DEfense (MALADE), is equipped with significant dispersion—projection is distributed broadly. This prevents white box attacks from accurately aligning the input to create an adversarial sample effectively. MALADE is applicable to any existing classifier, providing robust defense as well as off-manifold sample detection. In our experiments, MALADE exhibited state-of-the-art performance against various elaborate attacking strategies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304494",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Autoencoder",
      "Biochemistry",
      "Chemistry",
      "Classifier (UML)",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Discriminative model",
      "Gene",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Srinivasan",
        "given_name": "Vignesh"
      },
      {
        "surname": "Rohrer",
        "given_name": "Csaba"
      },
      {
        "surname": "Marban",
        "given_name": "Arturo"
      },
      {
        "surname": "Müller",
        "given_name": "Klaus-Robert"
      },
      {
        "surname": "Samek",
        "given_name": "Wojciech"
      },
      {
        "surname": "Nakajima",
        "given_name": "Shinichi"
      }
    ]
  },
  {
    "title": "Controllable stroke-based sketch synthesis from a self-organized latent space",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.006",
    "abstract": "Learning to synthesize free-hand sketches controllably according to specified categories and sketching styles is a challenging task, due to the lack of training data with category labels and style labels. One choice to control the synthesis is by self-organizing a latent coding space to preserve the similarity of structural patterns of the observed data. A practical way is introducing a Gaussian mixture prior over the latent codes, where each Gaussian component represents a specific categorical or stylistic pattern. As a result, we can generate sketches by sampling the latent variables from the Gaussian components or continuously manipulating the latent representations by interpolation. To achieve robust controllable sketch synthesis, it is critical to determine an appropriate Gaussian number. An underestimated Gaussian number cannot fully represent all the sketch patterns, i.e., some clusters have to contain sketches with more than one pattern. An overestimated one introduces redundant components, usually representing a chaotic collection of sketches with diverse patterns featured by other components. Both cases disturb pattern clustering over the coding space and make the internal code generation difficult to control for specific patterns. However, the Gaussian number is unavailable in this unsupervised task. In this paper, we present Rival Penalized Competitive Learning pixel to sequence (RPCL-pix2seq) to automatically determine the Gaussian number. Both quantitative and qualitative experimental results show RPCL-pix2seq can partition the codes for the sketches into an approximate stable number of clusters. Hence, we are able to do synthesis reasoning over the latent space, generating novel but reasonable sketches which neither appear in the training dataset nor exist in real life.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000149",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Categorical variable",
      "Cluster analysis",
      "Computer science",
      "Gaussian",
      "Latent variable",
      "Machine learning",
      "Mixture model",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Sketch"
    ],
    "authors": [
      {
        "surname": "Zang",
        "given_name": "Sicong"
      },
      {
        "surname": "Tu",
        "given_name": "Shikui"
      },
      {
        "surname": "Xu",
        "given_name": "Lei"
      }
    ]
  },
  {
    "title": "Building an adaptive interface via unsupervised tracking of latent manifolds",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.009",
    "abstract": "In human–machine interfaces, decoder calibration is critical to enable an effective and seamless interaction with the machine. However, recalibration is often necessary as the decoder off-line predictive power does not generally imply ease-of-use, due to closed loop dynamics and user adaptation that cannot be accounted for during the calibration procedure. Here, we propose an adaptive interface that makes use of a non-linear autoencoder trained iteratively to perform online manifold identification and tracking, with the dual goal of reducing the need for interface recalibration and enhancing human–machine joint performance. Importantly, the proposed approach avoids interrupting the operation of the device and it neither relies on information about the state of the task, nor on the existence of a stable neural or movement manifold, allowing it to be applied in the earliest stages of interface operation, when the formation of new neural strategies is still on-going. In order to more directly test the performance of our algorithm, we defined the autoencoder latent space as the control space of a body–machine interface. After an initial offline parameter tuning, we evaluated the performance of the adaptive interface versus that of a static decoder in approximating the evolving low-dimensional manifold of users simultaneously learning to perform reaching movements within the latent space. Results show that the adaptive approach increased the representational efficiency of the interface decoder. Concurrently, it significantly improved users’ task-related performance, indicating that the development of a more accurate internal model is encouraged by the online co-adaptation process.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000174",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Biology",
      "Botany",
      "Bubble",
      "Computer science",
      "Economics",
      "Engineering",
      "Identification (biology)",
      "Interface (matter)",
      "Machine learning",
      "Management",
      "Manifold (fluid mechanics)",
      "Maximum bubble pressure method",
      "Mechanical engineering",
      "Operating system",
      "Optics",
      "Parallel computing",
      "Physics",
      "Process (computing)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Rizzoglio",
        "given_name": "Fabio"
      },
      {
        "surname": "Casadio",
        "given_name": "Maura"
      },
      {
        "surname": "De Santis",
        "given_name": "Dalia"
      },
      {
        "surname": "Mussa-Ivaldi",
        "given_name": "Ferdinando A."
      }
    ]
  },
  {
    "title": "Passive filter design for fractional-order quaternion-valued neural networks with neutral delays and external disturbance",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.008",
    "abstract": "The problem on passive filter design for fractional-order quaternion-valued neural networks (FOQVNNs) with neutral delays and external disturbance is considered in this paper. Without separating the FOQVNNs into two complex-valued neural networks (CVNNs) or the FOQVNNs into four real-valued neural networks (RVNNs), by constructing Lyapunov–Krasovskii functional and using inequality technique, the delay-independent and delay-dependent sufficient conditions presented as linear matrix inequality (LMI) to confirm the augmented filtering dynamic system to be stable and passive with an expected dissipation are derived. One numerical example with simulations is furnished to pledge the feasibility for the obtained theory results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000162",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Disturbance (geology)",
      "Filter (signal processing)",
      "Geometry",
      "Linear matrix inequality",
      "Mathematical optimization",
      "Mathematics",
      "Paleontology",
      "Quaternion"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Qiankun"
      },
      {
        "surname": "Chen",
        "given_name": "Sihan"
      },
      {
        "surname": "Zhao",
        "given_name": "Zhenjiang"
      },
      {
        "surname": "Liu",
        "given_name": "Yurong"
      },
      {
        "surname": "Alsaadi",
        "given_name": "Fuad E."
      }
    ]
  },
  {
    "title": "Stochastic configuration network ensembles with selective base models",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.011",
    "abstract": "Studies have demonstrated that stochastic configuration networks (SCNs) have good potential for rapid data modeling because of their sufficient adequate learning power, which is theoretically guaranteed. Empirical studies have verified that the learner models produced by SCNs can usually achieve favorable test performance in practice but more in-depth theoretical analysis of their generalization power would be useful for constructing SCN-based ensemble models with enhanced generalization capacities. In particular, given a collection of independently developed SCN-based learner models, it is useful to select certain base learners that can potentially obtain preferable test results rather than considering all of the base models together, before simply taking their average in order to build an effective ensemble model. In this study, we propose a novel framework for building SCN ensembles by exploring key factors that might potentially affect the generalization performance of the base model. Under a mild assumption, we provide a comprehensive theoretical framework for examining a learner model’s generalization error, as well as formulating a novel indicator that contains measurement information for the training errors, output weights, and a hidden layer output matrix, which can be used by our proposed algorithm to find a subset of appropriate base models from a pool of randomized learner models. A toy example of one-dimensional function approximation, a case study for developing a predictive model for forecasting student learning performance, and two large-scale data sets were used in our experiments. The experimental results indicate that our proposed method has some remarkable advantages for building ensemble models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000198",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Base (topology)",
      "Computer science",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Changqin"
      },
      {
        "surname": "Li",
        "given_name": "Ming"
      },
      {
        "surname": "Wang",
        "given_name": "Dianhui"
      }
    ]
  },
  {
    "title": "MaskLayer: Enabling scalable deep learning solutions by training embedded feature sets",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.015",
    "abstract": "Deep learning-based methods have shown to achieve excellent results in a variety of domains, however, some important assets are absent. Quality scalability is one of them. In this work, we introduce a novel and generic neural network layer, named MaskLayer. It can be integrated in any feedforward network, allowing quality scalability by design by creating embedded feature sets. These are obtained by imposing a specific structure of the feature vector during training. To further improve the performance, a masked optimizer and a balancing gradient rescaling approach are proposed. Our experiments show that the cost of introducing scalability using MaskLayer remains limited. In order to prove its generality and applicability, we integrated the proposed techniques in existing, non-scalable networks for point cloud compression and semantic hashing with excellent results. To the best of our knowledge, this is the first work presenting a generic solution able to achieve quality scalable results within the deep learning framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100023X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cloud computing",
      "Computer engineering",
      "Computer science",
      "Computer security",
      "Database",
      "Deep learning",
      "Distributed computing",
      "Epistemology",
      "Feature (linguistics)",
      "Generality",
      "Hash function",
      "Linguistics",
      "Machine learning",
      "Operating system",
      "Philosophy",
      "Psychology",
      "Psychotherapist",
      "Quality (philosophy)",
      "Scalability"
    ],
    "authors": [
      {
        "surname": "Royen",
        "given_name": "Remco"
      },
      {
        "surname": "Denis",
        "given_name": "Leon"
      },
      {
        "surname": "Bolsee",
        "given_name": "Quentin"
      },
      {
        "surname": "Hu",
        "given_name": "Pengpeng"
      },
      {
        "surname": "Munteanu",
        "given_name": "Adrian"
      }
    ]
  },
  {
    "title": "Statistical foundation of Variational Bayes neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.027",
    "abstract": "Despite the popularism of Bayesian neural networks (BNNs) in recent years, its use is somewhat limited in complex and big data situations due to the computational cost associated with full posterior evaluations. Variational Bayes (VB) provides a useful alternative to circumvent the computational cost and time complexity associated with the generation of samples from the true posterior using Markov Chain Monte Carlo (MCMC) techniques. The efficacy of the VB methods is well established in machine learning literature. However, its potential broader impact is hindered due to a lack of theoretical validity from a statistical perspective. In this paper, we establish the fundamental result of posterior consistency for the mean-field variational posterior (VP) for a feed-forward artificial neural network model. The paper underlines the conditions needed to guarantee that the VP concentrates around Hellinger neighborhoods of the true density function. Additionally, the role of the scale parameter and its influence on the convergence rates has also been discussed. The paper mainly relies on two results (1) the rate at which the true posterior grows (2) the rate at which the Kullback–Leibler (KL) distance between the posterior and variational posterior grows. The theory provides a guideline for building prior distributions for BNNs along with an assessment of accuracy of the corresponding VB implementation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000356",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bayes' theorem",
      "Bayesian probability",
      "Computer science",
      "Hellinger distance",
      "Machine learning",
      "Markov chain Monte Carlo",
      "Mathematical optimization",
      "Mathematics",
      "Parametric statistics",
      "Posterior probability",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Bhattacharya",
        "given_name": "Shrijita"
      },
      {
        "surname": "Maiti",
        "given_name": "Tapabrata"
      }
    ]
  },
  {
    "title": "Bilateral attention decoder: A lightweight decoder for real-time semantic segmentation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.021",
    "abstract": "The encoder–decoder structure has been introduced into semantic segmentation to improve the spatial accuracy of the network by fusing high- and low-level feature maps. However, recent state-of-the-art encoder–decoder-based methods can hardly attain the real-time requirement due to their complex and inefficient decoders. To address this issue, in this paper, we propose a lightweight bilateral attention decoder for real-time semantic segmentation. It consists of two blocks and can fuse different level feature maps via two steps, i.e., information refinement and information fusion. In the first step, we propose a channel attention branch to refine the high-level feature maps and a spatial attention branch for the low-level ones. The refined high-level feature maps can capture more exact semantic information and the refined low-level ones can capture more accurate spatial information, which significantly improves the information capturing ability of these feature maps. In the second step, we develop a new fusion module named pooling fusing block to fuse the refined high- and low-level feature maps. This fusion block can take full advantages of the high- and low-level feature maps, leading to high-quality fusion results. To verify the efficiency of the proposed bilateral attention decoder, we adopt a lightweight network as the backbone and compare our proposed method with other state-of-the-art real-time semantic segmentation methods on the Cityscapes and Camvid datasets. Experimental results demonstrate that our proposed method can achieve better performance with a higher inference speed. Moreover, we compare our proposed network with several state-of-the-art non-real-time semantic segmentation methods and find that our proposed network can also attain better segmentation performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000290",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Block (permutation group theory)",
      "Computer science",
      "Computer vision",
      "Decoding methods",
      "Electrical engineering",
      "Encoder",
      "Engineering",
      "Feature (linguistics)",
      "Fuse (electrical)",
      "Geometry",
      "Linguistics",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pooling",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Chengli"
      },
      {
        "surname": "Tian",
        "given_name": "Tian"
      },
      {
        "surname": "Chen",
        "given_name": "Chen"
      },
      {
        "surname": "Guo",
        "given_name": "Xiaojie"
      },
      {
        "surname": "Ma",
        "given_name": "Jiayi"
      }
    ]
  },
  {
    "title": "Extracting and inserting knowledge into stacked denoising auto-encoders",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.010",
    "abstract": "Deep neural networks (DNNs) with a complex structure and multiple nonlinear processing units have achieved great successes for feature learning in image and visualization analysis. Due to interpretability of the “black box” problem in DNNs, however, there are still many obstacles to applications of DNNs in various real-world cases. This paper proposes a new DNN model, knowledge-based deep stacked denoising auto-encoders (KBSDAE), which inserts the knowledge (i.e., confidence and classification rules) into the deep network structure. This model not only can offer a good understanding of the representations learned by the deep network but also can produce an improvement in the learning performance of stacked denoising auto-encoder (SDAE). The knowledge discovery algorithm is proposed to extract confidence rules to interpret the layerwise network (i.e., denoising auto-encoder (DAE)). The symbolic language is developed to describe the deep network and shows that it is suitable for the representation of quantitative reasoning in a deep network. The confidence rule insertion to the deep network is able to produce an improvement in feature learning of DAEs. The classification rules extracted from the data offer a novel method for knowledge insertion to the classification layer of SDAE. The testing results of KBSDAE on various benchmark data indicate that the proposed method not only effectively extracts knowledge from the deep network, but also shows better feature learning performance than that of those typical DNNs (e.g., SDAE).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000186",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Black box",
      "Computer science",
      "Computer security",
      "Data mining",
      "Deep belief network",
      "Deep learning",
      "Feature (linguistics)",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Interpretability",
      "Linguistics",
      "Machine learning",
      "Network architecture",
      "Noise reduction",
      "Pattern recognition (psychology)",
      "Philosophy"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Jianbo"
      },
      {
        "surname": "Liu",
        "given_name": "Guoliang"
      }
    ]
  },
  {
    "title": "Nonclosedness of sets of neural networks in Sobolev spaces",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.007",
    "abstract": "We examine the closedness of sets of realized neural networks of a fixed architecture in Sobolev spaces. For an exactly m -times differentiable activation function ρ , we construct a sequence of neural networks ( Φ n ) n ∈ N whose realizations converge in order- ( m − 1 ) Sobolev norm to a function that cannot be realized exactly by a neural network. Thus, sets of realized neural networks are not closed in order- ( m − 1 ) Sobolev spaces W m − 1 , p for p ∈ [ 1 , ∞ ) . We further show that these sets are not closed in W m , p under slightly stronger conditions on the m th derivative of ρ . For a real analytic activation function, we show that sets of realized neural networks are not closed in W k , p for any k ∈ N . The nonclosedness allows for approximation of non-network target functions with unbounded parameter growth. We partially characterize the rate of parameter growth for most activation functions by showing that a specific sequence of realized neural networks can approximate the activation function’s derivative with weights increasing inversely proportional to the L p approximation error. Finally, we present experimental results showing that networks are capable of closely approximating non-network target functions with increasing parameters via training.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000150",
    "keywords": [
      "Activation function",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Differentiable function",
      "Discrete mathematics",
      "Evolutionary biology",
      "Function (biology)",
      "Genetics",
      "Law",
      "Mathematics",
      "Norm (philosophy)",
      "Political science",
      "Pure mathematics",
      "Sequence (biology)",
      "Sobolev space",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Mahan",
        "given_name": "Scott"
      },
      {
        "surname": "King",
        "given_name": "Emily J."
      },
      {
        "surname": "Cloninger",
        "given_name": "Alex"
      }
    ]
  },
  {
    "title": "The exact asymptotic form of Bayesian generalization error in latent Dirichlet allocation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.024",
    "abstract": "Latent Dirichlet allocation (LDA) obtains essential information from data by using Bayesian inference. It is applied to knowledge discovery via dimension reducing and clustering in many fields. However, its generalization error had not been yet clarified since it is a singular statistical model where there is no one-to-one mapping from parameters to probability distributions. In this paper, we give the exact asymptotic form of its generalization error and marginal likelihood, by theoretical analysis of its learning coefficient using algebraic geometry. The theoretical result shows that the Bayesian generalization error in LDA is expressed in terms of that in matrix factorization and a penalty from the simplex restriction of LDA’s parameter region. A numerical experiment is consistent with the theoretical result.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000320",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Bayesian probability",
      "Boundary value problem",
      "Computer science",
      "Dirichlet distribution",
      "Generalization",
      "Latent Dirichlet allocation",
      "Marginal likelihood",
      "Mathematical analysis",
      "Mathematics",
      "Statistics",
      "Topic model"
    ],
    "authors": [
      {
        "surname": "Hayashi",
        "given_name": "Naoki"
      }
    ]
  },
  {
    "title": "The Kolmogorov–Arnold representation theorem revisited",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.020",
    "abstract": "There is a longstanding debate whether the Kolmogorov–Arnold representation theorem can explain the use of more than one hidden layer in neural networks. The Kolmogorov–Arnold representation decomposes a multivariate function into an interior and an outer function and therefore has indeed a similar structure as a neural network with two hidden layers. But there are distinctive differences. One of the main obstacles is that the outer function depends on the represented function and can be wildly varying even if the represented function is smooth. We derive modifications of the Kolmogorov–Arnold representation that transfer smoothness properties of the represented function to the outer function and can be well approximated by ReLU networks. It appears that instead of two hidden layers, a more natural interpretation of the Kolmogorov–Arnold representation is that of a deep neural network where most of the layers are required to approximate the interior function.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000289",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Differential algebraic equation",
      "Differential equation",
      "Electrical engineering",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Interpretation (philosophy)",
      "Kolmogorov complexity",
      "Kolmogorov equations (Markov jump process)",
      "Kolmogorov structure function",
      "Law",
      "Mathematical analysis",
      "Mathematics",
      "Ordinary differential equation",
      "Political science",
      "Politics",
      "Programming language",
      "Pure mathematics",
      "Representation (politics)",
      "Smoothness",
      "Transfer function"
    ],
    "authors": [
      {
        "surname": "Schmidt-Hieber",
        "given_name": "Johannes"
      }
    ]
  },
  {
    "title": "A Dual-Dimer method for training physics-constrained neural networks with minimax architecture",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.028",
    "abstract": "Data sparsity is a common issue to train machine learning tools such as neural networks for engineering and scientific applications, where experiments and simulations are expensive. Recently physics-constrained neural networks (PCNNs) were developed to reduce the required amount of training data. However, the weights of different losses from data and physical constraints are adjusted empirically in PCNNs. In this paper, a new physics-constrained neural network with the minimax architecture (PCNN-MM) is proposed so that the weights of different losses can be adjusted systematically. The training of the PCNN-MM is searching the high-order saddle points of the objective function. A novel saddle point search algorithm called Dual-Dimer method is developed. It is demonstrated that the Dual-Dimer method is computationally more efficient than the gradient descent ascent method for nonconvex–nonconcave functions and provides additional eigenvalue information to verify search results. A heat transfer example also shows that the convergence of PCNN-MMs is faster than that of traditional PCNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304536",
    "keywords": [
      "Algorithm",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Convergence (economics)",
      "Dual (grammatical number)",
      "Economic growth",
      "Economics",
      "Eigenvalues and eigenvectors",
      "Evolutionary biology",
      "Function (biology)",
      "Geometry",
      "Gradient descent",
      "Literature",
      "Mathematical optimization",
      "Mathematics",
      "Meteorology",
      "Minimax",
      "Physics",
      "Quantum mechanics",
      "Saddle point",
      "Training (meteorology)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Dehao"
      },
      {
        "surname": "Wang",
        "given_name": "Yan"
      }
    ]
  },
  {
    "title": "Low Rank Regularization: A review",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.09.021",
    "abstract": "Low Rank Regularization (LRR), in essence, involves introducing a low rank or approximately low rank assumption to target we aim to learn, which has achieved great success in many data analysis tasks. Over the last decade, much progress has been made in theories and applications. Nevertheless, the intersection between these two lines is rare. In order to construct a bridge between practical applications and theoretical studies, in this paper we provide a comprehensive survey for LRR. Specifically, we first review the recent advances in two issues that all LRR models are faced with: ( 1 ) rank-norm relaxation, which seeks to find a relaxation to replace the rank minimization problem; ( 2 ) model optimization, which seeks to use an efficient optimization algorithm to solve the relaxed LRR models. For the first issue, we provide a detailed summarization for various relaxation functions and conclude that the non-convex relaxations can alleviate the punishment bias problem compared with the convex relaxations. For the second issue, we summarize the representative optimization algorithms used in previous studies, and analyze their advantages and disadvantages. As the main goal of this paper is to promote the application of non-convex relaxations, we conduct extensive experiments to compare different relaxation functions. The experimental results demonstrate that the non-convex relaxations generally provide a large advantage over the convex relaxations. Such a result is inspiring for further improving the performance of existing LRR models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030352X",
    "keywords": [
      "Artificial intelligence",
      "Automatic summarization",
      "Combinatorics",
      "Computer science",
      "Convex optimization",
      "Eigenvalues and eigenvectors",
      "Geometry",
      "Mathematical optimization",
      "Mathematics",
      "Matrix norm",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Rank (graph theory)",
      "Regular polygon",
      "Regularization (linguistics)",
      "Relaxation (psychology)",
      "Social psychology"
    ],
    "authors": [
      {
        "surname": "Hu",
        "given_name": "Zhanxuan"
      },
      {
        "surname": "Nie",
        "given_name": "Feiping"
      },
      {
        "surname": "Wang",
        "given_name": "Rong"
      },
      {
        "surname": "Li",
        "given_name": "Xuelong"
      }
    ]
  },
  {
    "title": "Multi-scale Attention Convolutional Neural Network for time series classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.001",
    "abstract": "With the rapid increase of data availability, time series classification (TSC) has arisen in a wide range of fields and drawn great attention of researchers. Recently, hundreds of TSC approaches have been developed, which can be classified into two categories: traditional and deep learning based TSC methods. However, it remains challenging to improve accuracy and model generalization ability. Therefore, we investigate a novel end-to-end model based on deep learning named as Multi-scale Attention Convolutional Neural Network (MACNN) to solve the TSC problem. We first apply the multi-scale convolution to capture different scales of information along the time axis by generating different scales of feature maps. Then an attention mechanism is proposed to enhance useful feature maps and suppress less useful ones by learning the importance of each feature map automatically. MACNN addresses the limitation of single-scale convolution and equal weight feature maps. We conduct a comprehensive evaluation of 85 UCR standard datasets and the experimental results show that our proposed approach achieves the best performance and outperforms the other traditional and deep learning based methods by a large margin.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000010",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Deep learning",
      "Feature (linguistics)",
      "Generalization",
      "Linguistics",
      "Machine learning",
      "Margin (machine learning)",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Scale (ratio)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Wei"
      },
      {
        "surname": "Shi",
        "given_name": "Ke"
      }
    ]
  },
  {
    "title": "t-soft update of target network for deep reinforcement learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.023",
    "abstract": "This paper proposes a new robust update rule of target network for deep reinforcement learning (DRL), to replace the conventional update rule, given as an exponential moving average. The target network is for smoothly generating the reference signals for a main network in DRL, thereby reducing learning variance. The problem with its conventional update rule is the fact that all the parameters are smoothly copied with the same speed from the main network, even when some of them are trying to update toward the wrong directions. This behavior increases the risk of generating the wrong reference signals. Although slowing down the overall update speed is a naive way to mitigate wrong updates, it would decrease learning speed. To robustly update the parameters while keeping learning speed, a t-soft update method, which is inspired by Student-t distribution, is derived with reference to the analogy between the exponential moving average and the normal distribution. Through the analysis of the derived t-soft update, we show that it takes over the properties of the Student-t distribution. Specifically, with a heavy-tailed property of the Student-t distribution, the t-soft update automatically excludes extreme updates that differ from past experiences. In addition, when the updates are similar to the past experiences, it can mitigate the learning delay by increasing the amount of updates. In PyBullet robotics simulations for DRL, an online actor–critic algorithm with the t-soft update outperformed the conventional methods in terms of the obtained return and/or its variance. From the training process by the t-soft update, we found that the t-soft update is globally consistent with the standard soft update, and the update rates are locally adjusted for acceleration or suppression.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304482",
    "keywords": [
      "Accounting",
      "Analogy",
      "Artificial intelligence",
      "Artificial neural network",
      "Business",
      "Computer science",
      "Epistemology",
      "Exponential function",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Philosophy",
      "Property (philosophy)",
      "Reinforcement learning",
      "Variance (accounting)"
    ],
    "authors": [
      {
        "surname": "Kobayashi",
        "given_name": "Taisuke"
      },
      {
        "surname": "Ilboudo",
        "given_name": "Wendyam Eric Lionel"
      }
    ]
  },
  {
    "title": "Adaptive transfer learning for EEG motor imagery classification with deep Convolutional Neural Network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.013",
    "abstract": "In recent years, deep learning has emerged as a powerful tool for developing Brain–Computer Interface (BCI) systems. However, for deep learning models trained entirely on the data from a specific individual, the performance increase has only been marginal owing to the limited availability of subject-specific data. To overcome this, many transfer-based approaches have been proposed, in which deep networks are trained using pre-existing data from other subjects and evaluated on new target subjects. This mode of transfer learning however faces the challenge of substantial inter-subject variability in brain data. Addressing this, in this paper, we propose 5 schemes for adaptation of a deep convolutional neural network (CNN) based electroencephalography (EEG)-BCI system for decoding hand motor imagery (MI). Each scheme fine-tunes an extensively trained, pre-trained model and adapt it to enhance the evaluation performance on a target subject. We report the highest subject-independent performance with an average ( N = 54 ) accuracy of 84.19% ( ± 9 . 98 % ) for two-class motor imagery, while the best accuracy on this dataset is 74.15% ( ± 15 . 83 % ) in the literature. Further, we obtain a statistically significant improvement ( p = 0 . 005 ) in classification using the proposed adaptation schemes compared to the baseline subject-independent model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304305",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Artificial neural network",
      "Brain–computer interface",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Electroencephalography",
      "Machine learning",
      "Motor imagery",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychiatry",
      "Psychology",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Kaishuo"
      },
      {
        "surname": "Robinson",
        "given_name": "Neethu"
      },
      {
        "surname": "Lee",
        "given_name": "Seong-Whan"
      },
      {
        "surname": "Guan",
        "given_name": "Cuntai"
      }
    ]
  },
  {
    "title": "Quantization Friendly MobileNet (QF-MobileNet) Architecture for Vision Based Applications on Embedded Platforms",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.022",
    "abstract": "Deep Neural Networks (DNNs) have become popular for various applications in the domain of image and computer vision due to their well-established performance attributes. DNN algorithms involve powerful multilevel feature extractions resulting in an extensive range of parameters and memory footprints. However, memory bandwidth requirements, memory footprint and the associated power consumption of models are issues to be addressed to deploy DNN models on embedded platforms for real time vision-based applications. We present an optimized DNN model for memory and accuracy for vision-based applications on embedded platforms. In this paper we propose Quantization Friendly MobileNet (QF-MobileNet) architecture. The architecture is optimized for inference accuracy and reduced resource utilization. The optimization is obtained by addressing the redundancy and quantization loss of the existing baseline MobileNet architectures. We verify and validate the performance of the QF-MobileNet architecture for image classification task on the ImageNet dataset. The proposed model is tested for inference accuracy and resource utilization and compared to the baseline MobileNet architecture. The inference accuracy of the proposed QF-MobileNetV2 float model attained 73.36% and the quantized model has 69.51%. The MobileNetV3 float model attained an inference accuracy of 68.75% and the quantized model has 67.5% respectively. The proposed model saves 33% of time complexity for QF-MobileNetV2 and QF-MobileNetV3 models against the baseline models. The QF-MobileNet also showed optimized resource utilization with 32% fewer tunable parameters, 30% fewer MAC’s operations per image and reduced inference quantization loss by approximately 5% compared to the baseline models. The model is ported onto the android application using TensorFlow API. The android application performs inference on the native devices viz. smartphones, tablets and handheld devices. Future work is focused on introducing channel-wise and layer-wise quantization schemes to the proposed model. We intend to explore quantization aware training of DNN algorithms to achieve optimized resource utilization and inference accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304470",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer engineering",
      "Computer science",
      "Inference",
      "Machine learning",
      "Memory footprint",
      "Operating system",
      "Quantization (signal processing)"
    ],
    "authors": [
      {
        "surname": "Kulkarni",
        "given_name": "Uday"
      },
      {
        "surname": "S.M.",
        "given_name": "Meena"
      },
      {
        "surname": "Gurlahosur",
        "given_name": "Sunil V."
      },
      {
        "surname": "Bhogar",
        "given_name": "Gopal"
      }
    ]
  },
  {
    "title": "Supervised and semi-supervised probabilistic learning with deep neural networks for concurrent process-quality monitoring",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.006",
    "abstract": "Concurrent process-quality monitoring helps discover quality-relevant process anomalies and quality-irrelevant process anomalies. It especially works well in chemical plants with faults that cause quality problems. Traditional monitoring strategies are limitedly applied in chemical plants because quality targets in training data are insufficient. It is hard for inflexible models to fully capture the strongly nonlinear process-quality correlations. Also, deterministic models are mapped from process variables to qualities without any consideration of uncertainties. Simultaneously, a slow sampling rate for quality variables is ubiquitous in chemical plants since a product quality test is often time-consuming and expensive. Motivated by these limitations, this paper proposes a new concurrent process-quality monitoring scheme based on a probabilistic generative deep learning model developed from variational autoencoder. The supervised model is firstly developed and then the semi-supervised version is extended to solve the issue of missing targets. Especially, the semi-supervised learning algorithm is accomplished with an optimal parameter estimation in the light of maximum likelihood principle and no any hyperparameters are introduced. Two case studies validate that the proposed method effectively outperforms the other comparative methods in concurrent process-quality monitoring.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303919",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Data mining",
      "Epistemology",
      "Hyperparameter",
      "Machine learning",
      "Operating system",
      "Philosophy",
      "Probabilistic logic",
      "Process (computing)",
      "Quality (philosophy)",
      "Supervised learning"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Kai"
      },
      {
        "surname": "Yuan",
        "given_name": "Xiaofeng"
      },
      {
        "surname": "Chen",
        "given_name": "Junghui"
      },
      {
        "surname": "Wang",
        "given_name": "Yalin"
      }
    ]
  },
  {
    "title": "Stacked DeBERT: All attention in incomplete data for text classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.018",
    "abstract": "In this paper, we propose Stacked DeBERT, short for Stacked Denoising Bidirectional Encoder Representations from Transformers. This novel model improves robustness in incomplete data, when compared to existing systems, by designing a novel encoding scheme in BERT, a powerful language representation model solely based on attention mechanisms. Incomplete data in natural language processing refer to text with missing or incorrect words, and its presence can hinder the performance of current models that were not implemented to withstand such noises, but must still perform well even under duress. This is due to the fact that current approaches are built for and trained with clean and complete data, and thus are not able to extract features that can adequately represent incomplete data. Our proposed approach consists of obtaining intermediate input representations by applying an embedding layer to the input tokens followed by vanilla transformers. These intermediate features are given as input to novel denoising transformers which are responsible for obtaining richer input representations. The proposed approach takes advantage of stacks of multilayer perceptrons for the reconstruction of missing words’ embeddings by extracting more abstract and meaningful hidden feature vectors, and bidirectional transformers for improved embedding representation. We consider two datasets for training and evaluation: the Chatbot Natural Language Understanding Evaluation Corpus and Kaggle’s Twitter Sentiment Corpus. Our model shows improved F1-scores and better robustness in informal/incorrect texts present in tweets and in texts with Speech-to-Text error in the sentiment and intent classification tasks. 1 1 https://github.com/gcunhase/StackedDeBERT.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304433",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Embedding",
      "Encoder",
      "Gene",
      "Language model",
      "Machine learning",
      "Missing data",
      "Natural language",
      "Natural language processing",
      "Operating system",
      "Pattern recognition (psychology)",
      "Perceptron",
      "Physics",
      "Quantum mechanics",
      "Question answering",
      "Robustness (evolution)",
      "Speech recognition",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Cunha Sergio",
        "given_name": "Gwenaelle"
      },
      {
        "surname": "Lee",
        "given_name": "Minho"
      }
    ]
  },
  {
    "title": "A bioinspired angular velocity decoding neural network model for visually guided flights",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.008",
    "abstract": "Efficient and robust motion perception systems are important pre-requisites for achieving visually guided flights in future micro air vehicles. As a source of inspiration, the visual neural networks of flying insects such as honeybee and Drosophila provide ideal examples on which to base artificial motion perception models. In this paper, we have used this approach to develop a novel method that solves the fundamental problem of estimating angular velocity for visually guided flights. Compared with previous models, our elementary motion detector (EMD) based model uses a separate texture estimation pathway to effectively decode angular velocity, and demonstrates considerable independence from the spatial frequency and contrast of the gratings. Using the Unity development platform the model is further tested for tunnel centering and terrain following paradigms in order to reproduce the visually guided flight behaviors of honeybees. In a series of controlled trials, the virtual bee utilizes the proposed angular velocity control schemes to accurately navigate through a patterned tunnel, maintaining a suitable distance from the undulating textured terrain. The results are consistent with both neuron spike recordings and behavioral path recordings of real honeybees, thereby demonstrating the model’s potential for implementation in micro air vehicles which have only visual sensors.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304251",
    "keywords": [
      "Angular velocity",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Ecology",
      "Hyperacuity",
      "Independence (probability theory)",
      "Mathematics",
      "Motion (physics)",
      "Physics",
      "Quantum mechanics",
      "Simulation",
      "Statistics",
      "Terrain"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Huatian"
      },
      {
        "surname": "Fu",
        "given_name": "Qinbing"
      },
      {
        "surname": "Wang",
        "given_name": "Hongxin"
      },
      {
        "surname": "Baxter",
        "given_name": "Paul"
      },
      {
        "surname": "Peng",
        "given_name": "Jigen"
      },
      {
        "surname": "Yue",
        "given_name": "Shigang"
      }
    ]
  },
  {
    "title": "Steganographer detection via a similarity accumulation graph convolutional network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.026",
    "abstract": "Steganographer detection aims to identify guilty users who conceal secret information in a number of images for the purpose of covert communication in social networks. Existing steganographer detection methods focus on designing discriminative features but do not explore relationship between image features or effectively represent users based on features. In these methods, each image is recognized as an equivalent, and each user is regarded as the distribution of all images shared by the corresponding user. However, the nuances of guilty users and innocent users are difficult to recognize with this flattened method. In this paper, the steganographer detection task is formulated as a multiple-instance learning problem in which each user is considered to be a bag, and the shared images are multiple instances in the bag. Specifically, we propose a similarity accumulation graph convolutional network to represent each user as a complete weighted graph, in which each node corresponds to features extracted from an image and the weight of an edge is the similarity between each pair of images. The constructed unit in the network can take advantage of the relationships between instances so that common patterns of positive instances can be enhanced via similarity accumulations. Instead of operating on a fixed original graph, we propose a novel strategy for reconstructing and pooling graphs based on node features to iteratively operate multiple convolutions. This strategy can effectively address oversmoothing problems that render nodes indistinguishable although they share different instance-level labels. Compared with the state-of-the-art method and other representative graph-based models, the proposed framework demonstrates its effectiveness and reliability ability across image domains, even in the context of large-scale social media scenarios. Moreover, the experimental results also indicate that the proposed network can be generalized to other multiple-instance learning problems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304512",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Discriminative model",
      "Focus (optics)",
      "Graph",
      "Image (mathematics)",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Pooling",
      "Similarity (geometry)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Zhi"
      },
      {
        "surname": "Zheng",
        "given_name": "Mingjie"
      },
      {
        "surname": "Zhong",
        "given_name": "Sheng-hua"
      },
      {
        "surname": "Liu",
        "given_name": "Yan"
      }
    ]
  },
  {
    "title": "Chaos may enhance expressivity in cerebellar granular layer",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.020",
    "abstract": "Recent evidence suggests that Golgi cells in the cerebellar granular layer are densely connected to each other with massive gap junctions. Here, we propose that the massive gap junctions between the Golgi cells contribute to the representational complexity of the granular layer of the cerebellum by inducing chaotic dynamics. We construct a model of cerebellar granular layer with diffusion coupling through gap junctions between the Golgi cells, and evaluate the representational capability of the network with the reservoir computing framework. First, we show that the chaotic dynamics induced by diffusion coupling results in complex output patterns containing a wide range of frequency components. Second, the long non-recursive time series of the reservoir represents the passage of time from an external input. These properties of the reservoir enable mapping different spatial inputs into different temporal patterns.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304457",
    "keywords": [
      "Acoustics",
      "Artificial intelligence",
      "Biological system",
      "Biology",
      "Cell",
      "Cerebellum",
      "Chaotic",
      "Computer science",
      "Coupling (piping)",
      "Diffusion",
      "Dynamics (music)",
      "Genetics",
      "Golgi apparatus",
      "Granular layer",
      "Layer (electronics)",
      "Materials science",
      "Metallurgy",
      "Nanotechnology",
      "Neuroscience",
      "Physics",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Tokuda",
        "given_name": "Keita"
      },
      {
        "surname": "Fujiwara",
        "given_name": "Naoya"
      },
      {
        "surname": "Sudo",
        "given_name": "Akihito"
      },
      {
        "surname": "Katori",
        "given_name": "Yuichi"
      }
    ]
  },
  {
    "title": "A neurodynamic optimization approach to supervised feature selection via fractional programming",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.004",
    "abstract": "Feature selection is an important issue in machine learning and data mining. Most existing feature selection methods are greedy in nature thus are prone to sub-optimality. Though some global feature selection methods based on unsupervised redundancy minimization can potentiate clustering performance improvements, their efficacy for classification may be limited. In this paper, a neurodynamics-based holistic feature selection approach is proposed via feature redundancy minimization and relevance maximization. An information-theoretic similarity coefficient matrix is defined based on multi-information and entropy to measure feature redundancy with respect to class labels. Supervised feature selection is formulated as a fractional programming problem based on the similarity coefficients. A neurodynamic approach based on two one-layer recurrent neural networks is developed for solving the formulated feature selection problem. Experimental results with eight benchmark datasets are discussed to demonstrate the global convergence of the neural networks and superiority of the proposed neurodynamic approach to several existing feature selection methods in terms of classification accuracy, precision, recall, and F-measure.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000125",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Entropy (arrow of time)",
      "Feature (linguistics)",
      "Feature selection",
      "Linguistics",
      "Machine learning",
      "Minimum redundancy feature selection",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Redundancy (engineering)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yadi"
      },
      {
        "surname": "Li",
        "given_name": "Xiaoping"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Creating and concentrating quantum resource states in noisy environments using a quantum neural network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.003",
    "abstract": "Quantum information processing tasks require exotic quantum states as a prerequisite. They are usually prepared with many different methods tailored to the specific resource state. Here we provide a versatile unified state preparation scheme based on a driven quantum network composed of randomly-coupled fermionic nodes. The output of such a system is then superposed with the help of linear mixing where weights and phases are trained in order to obtain desired output quantum states. We explicitly show that our method is robust and can be utilized to create almost perfect maximally entangled, NOON, W, cluster, and discorded states. Furthermore, the treatment includes energy decay in the system as well as dephasing and depolarization. Under these noisy conditions we show that the target states are achieved with high fidelity by tuning controllable parameters and providing sufficient strength to the driving of the quantum network. Finally, in very noisy systems, where noise is comparable to the driving strength, we show how to concentrate entanglement by mixing more states in a larger network.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000034",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster state",
      "Combinatorics",
      "Computer science",
      "Fidelity",
      "Image (mathematics)",
      "Mathematics",
      "Mixing (physics)",
      "Noise (video)",
      "Physics",
      "Quantum",
      "Quantum entanglement",
      "Quantum mechanics",
      "Quantum network",
      "Quantum state",
      "Qubit",
      "Statistical physics",
      "Telecommunications",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Krisnanda",
        "given_name": "Tanjung"
      },
      {
        "surname": "Ghosh",
        "given_name": "Sanjib"
      },
      {
        "surname": "Paterek",
        "given_name": "Tomasz"
      },
      {
        "surname": "Liew",
        "given_name": "Timothy C.H."
      }
    ]
  },
  {
    "title": "Creating and concentrating quantum resource states in noisy environments using a quantum neural network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2021.01.003",
    "abstract": "Quantum information processing tasks require exotic quantum states as a prerequisite. They are usually prepared with many different methods tailored to the specific resource state. Here we provide a versatile unified state preparation scheme based on a driven quantum network composed of randomly-coupled fermionic nodes. The output of such a system is then superposed with the help of linear mixing where weights and phases are trained in order to obtain desired output quantum states. We explicitly show that our method is robust and can be utilized to create almost perfect maximally entangled, NOON, W, cluster, and discorded states. Furthermore, the treatment includes energy decay in the system as well as dephasing and depolarization. Under these noisy conditions we show that the target states are achieved with high fidelity by tuning controllable parameters and providing sufficient strength to the driving of the quantum network. Finally, in very noisy systems, where noise is comparable to the driving strength, we show how to concentrate entanglement by mixing more states in a larger network.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021000034",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster state",
      "Combinatorics",
      "Computer science",
      "Fidelity",
      "Image (mathematics)",
      "Mathematics",
      "Mixing (physics)",
      "Noise (video)",
      "Physics",
      "Quantum",
      "Quantum entanglement",
      "Quantum mechanics",
      "Quantum network",
      "Quantum state",
      "Qubit",
      "Statistical physics",
      "Telecommunications",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Krisnanda",
        "given_name": "Tanjung"
      },
      {
        "surname": "Ghosh",
        "given_name": "Sanjib"
      },
      {
        "surname": "Paterek",
        "given_name": "Tomasz"
      },
      {
        "surname": "Liew",
        "given_name": "Timothy C.H."
      }
    ]
  },
  {
    "title": "Robust facial landmark detection by cross-order cross-semantic deep network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.001",
    "abstract": "Recently, convolutional neural networks (CNNs)-based facial landmark detection methods have achieved great success. However, most of existing CNN-based facial landmark detection methods have not attempted to activate multiple correlated facial parts and learn different semantic features from them that they can not accurately model the relationships among the local details and can not fully explore more discriminative and fine semantic features, thus they suffer from partial occlusions and large pose variations. To address these problems, we propose a cross-order cross-semantic deep network (CCDN) to boost the semantic features learning for robust facial landmark detection. Specifically, a cross-order two-squeeze multi-excitation (CTM) module is proposed to introduce the cross-order channel correlations for more discriminative representations learning and multiple attention-specific part activation. Moreover, a novel cross-order cross-semantic (COCS) regularizer is designed to drive the network to learn cross-order cross-semantic features from different activation for facial landmark detection. It is interesting to show that by integrating the CTM module and COCS regularizer, the proposed CCDN can effectively activate and learn more fine and complementary cross-order cross-semantic features to improve the accuracy of facial landmark detection under extremely challenging scenarios. Experimental results on challenging benchmark datasets demonstrate the superiority of our CCDN over state-of-the-art facial landmark detection methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303828",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Convolutional neural network",
      "Discriminative model",
      "Geodesy",
      "Geography",
      "Landmark",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Wan",
        "given_name": "Jun"
      },
      {
        "surname": "Lai",
        "given_name": "Zhihui"
      },
      {
        "surname": "Shen",
        "given_name": "Linlin"
      },
      {
        "surname": "Zhou",
        "given_name": "Jie"
      },
      {
        "surname": "Gao",
        "given_name": "Can"
      },
      {
        "surname": "Xiao",
        "given_name": "Gang"
      },
      {
        "surname": "Hou",
        "given_name": "Xianxu"
      }
    ]
  },
  {
    "title": "Image manipulation with natural language using Two-sided Attentive Conditional Generative Adversarial Network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.09.002",
    "abstract": "Altering the content of an image with photo editing tools is a tedious task for an inexperienced user, especially, when modifying the visual attributes of a specific object in an image without affecting other constituents such as background etc. To simplify the process of image manipulation and to provide more control to users, it is better to utilize a simpler interface like natural language. It also enables to semantically modify parts of an image according to the given text. Therefore, in this paper, we address the challenge of manipulating images using natural language descriptions. We propose the Two-sidEd Attentive conditional Generative Adversarial Network (TEA-cGAN) to generate semantically manipulated images. TEA-cGAN’s contribution is seen as two-fold. The first contribution aims to attend locations that need to be modified during generation. It introduces two types of architectures that provide fine-grained attention both in the generator and discriminator of Generative Adversarial Network (GAN). To be specific, the first one i.e., the Single-scale architecture used in the generator focuses to modify only the text-relevant regions in an image and leaves other regions untouched. While the second one i.e., Multi-scale architecture further extended this idea by taking the different scales of image features into account. The second contribution purpose is to generate higher resolution images (e.g., 256 × 256) as they provide better quality and stability. Quantitative and qualitative experiments conducted on CUB and Oxford-102 datasets confirm that TEA-cGAN different scale architectures outperform existing methods while generating 128 × 128 resolution images including generating higher resolution image i.e., 256 × 256.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303257",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Detector",
      "Discriminator",
      "Generative grammar",
      "Generator (circuit theory)",
      "Image (mathematics)",
      "Natural language",
      "Natural language processing",
      "Pattern recognition (psychology)",
      "Physics",
      "Power (physics)",
      "Process (computing)",
      "Programming language",
      "Quantum mechanics",
      "Scale (ratio)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Dawei"
      },
      {
        "surname": "Mogadala",
        "given_name": "Aditya"
      },
      {
        "surname": "Klakow",
        "given_name": "Dietrich"
      }
    ]
  },
  {
    "title": "Smooth dendrite morphological neurons",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.021",
    "abstract": "A typical feature of hyperbox-based dendrite morphological neurons (DMN) is the generation of sharp and rough decision boundaries that inaccurately track the distribution shape of classes of patterns. This feature is because the minimum and maximum activation functions force the decision boundaries to match the faces of the hyperboxes. To improve the DMN response, we introduce a dendritic model that uses smooth maximum and minimum functions to soften the decision boundaries. The classification performance assessment is conducted on nine synthetic and 28 real-world datasets. Based on the experimental results, we demonstrate that the smooth activation functions improve the generalization capacity of DMN. The proposed approach is competitive with four machine learning techniques, namely, Multilayer Perceptron, Radial Basis Function Network, Support Vector Machine, and Nearest Neighbor algorithm. Besides, the computational complexity of DMN training is lower than MLP and SVM classifiers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304469",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Dendrite (mathematics)",
      "Evolutionary biology",
      "Feature (linguistics)",
      "Function (biology)",
      "Generalization",
      "Geometry",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Multilayer perceptron",
      "Pattern recognition (psychology)",
      "Perceptron",
      "Philosophy",
      "Support vector machine",
      "k-nearest neighbors algorithm"
    ],
    "authors": [
      {
        "surname": "Gómez-Flores",
        "given_name": "Wilfrido"
      },
      {
        "surname": "Sossa",
        "given_name": "Humberto"
      }
    ]
  },
  {
    "title": "How to teach neural networks to mesh: Application on 2-D simplicial contours",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.019",
    "abstract": "A machine learning meshing scheme for the generation of 2-D simplicial meshes is proposed based on the predictions of neural networks. The data extracted from meshed contours are utilized to train neural networks which are used to approximate the number of vertices to be inserted inside the contour cavity, their location, and connectivity. The accuracy of the scheme is evaluated by comparing the quality of the mesh generated by the neural networks with that generated by a reference mesher. Based on an element quality metric, after conducting tests on contours for a various number of edges, the results show a maximum average deviation of 15.2% on the mean quality and 27 . 3 % on the minimum quality between the elements of the meshes generated by the scheme and the ones generated from the reference mesher; the scheme is able to produce good quality meshes that are suitable for meshing purposes. The meshing scheme is also applied to generate larger scale meshes with a recursive implementation. The findings encourage the adaption of the scheme for 3-D mesh generation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304445",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer graphics (images)",
      "Computer science",
      "Economics",
      "Finite element method",
      "Mathematical analysis",
      "Mathematics",
      "Mesh generation",
      "Metric (unit)",
      "Operations management",
      "Physics",
      "Polygon mesh",
      "Scheme (mathematics)",
      "Thermodynamics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Papagiannopoulos",
        "given_name": "Alexis"
      },
      {
        "surname": "Clausen",
        "given_name": "Pascal"
      },
      {
        "surname": "Avellan",
        "given_name": "François"
      }
    ]
  },
  {
    "title": "An enhanced approach to the robust discriminant analysis and class sparsity based embedding",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.025",
    "abstract": "In recent times, feature extraction attracted much attention in machine learning and pattern recognition fields. This paper extends and improves a scheme for linear feature extraction that can be used in supervised multi-class classification problems. Inspired by recent frameworks for robust sparse LDA and Inter-class sparsity, we propose a unifying criterion able to retain the advantages of these two powerful linear discriminant methods. We introduce an iterative alternating minimization scheme in order to estimate the linear transformation and the orthogonal matrix. The linear transformation is efficiently updated via the steepest descent gradient technique. The proposed framework is generic in the sense that it allows the combination and tuning of other linear discriminant embedding methods. We used our proposed method to fine tune the linear solutions delivered by two recent linear methods: RSLDA and RDA_FSIS. Experiments have been conducted on public image datasets of different types including objects, faces, and digits. The proposed framework compared favorably with several competing methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304500",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Discriminant",
      "Embedding",
      "Feature (linguistics)",
      "Gene",
      "Gradient descent",
      "Linear discriminant analysis",
      "Linear map",
      "Linguistics",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pure mathematics",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Khoder",
        "given_name": "A."
      },
      {
        "surname": "Dornaika",
        "given_name": "F."
      }
    ]
  },
  {
    "title": "Deep multi-kernel auto-encoder network for clustering brain functional connectivity data",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.005",
    "abstract": "In this study, we propose a deep-learning network model called the deep multi-kernel auto-encoder clustering network (DMACN) for clustering functional connectivity data for brain diseases. This model is an end-to-end clustering algorithm that can learn potentially advanced features and cluster disease categories. Unlike other auto-encoders, DMACN has an added self-expression layer and standard back-propagation is used to learn the features that are beneficial for clustering brain functional connectivity data. In the self-expression layer, the kernel matrix is constructed to extract effective features and a new loss function is proposed to constrain the clustering portion, which enables the training of a deep neural learning network that tends to cluster. To test the performance of the proposed algorithm, we applied the end-to-end deep unsupervised clustering algorithm to brain connectivity data. We then conducted experiments based on four public brain functional connectivity data sets and our own functional connectivity data set. The DMACN algorithm yielded good results in various evaluations compared with the existing clustering algorithm for brain functional connectivity data, the deep auto-encoder clustering algorithm, and several other relevant clustering algorithms. The deep-learning-based clustering algorithm has great potential for use in the unsupervised recognition of brain diseases.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304226",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "CURE data clustering algorithm",
      "Canopy clustering algorithm",
      "Cluster analysis",
      "Clustering high-dimensional data",
      "Combinatorics",
      "Computer science",
      "Correlation clustering",
      "Data mining",
      "Data stream clustering",
      "Deep learning",
      "Kernel (algebra)",
      "Mathematics",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Lu",
        "given_name": "Hu"
      },
      {
        "surname": "Liu",
        "given_name": "Saixiong"
      },
      {
        "surname": "Wei",
        "given_name": "Hui"
      },
      {
        "surname": "Chen",
        "given_name": "Chao"
      },
      {
        "surname": "Geng",
        "given_name": "Xia"
      }
    ]
  },
  {
    "title": "Information Aware max-norm Dirichlet networks for predictive uncertainty estimation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.011",
    "abstract": "Precise estimation of uncertainty in predictions for AI systems is a critical factor in ensuring trust and safety. Deep neural networks trained with a conventional method are prone to over-confident predictions. In contrast to Bayesian neural networks that learn approximate distributions on weights to infer prediction confidence, we propose a novel method, Information Aware Dirichlet networks, that learn an explicit Dirichlet prior distribution on predictive distributions by minimizing a bound on the expected max norm of the prediction error and penalizing information associated with incorrect outcomes. Properties of the new cost function are derived to indicate how improved uncertainty estimation is achieved. Experiments using real datasets show that our technique outperforms, by a large margin, state-of-the-art neural networks for estimating within-distribution and out-of-distribution uncertainty, and detecting adversarial examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304287",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bayesian probability",
      "Boundary value problem",
      "Computer science",
      "Deep neural networks",
      "Dirichlet distribution",
      "Law",
      "Machine learning",
      "Margin (machine learning)",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Norm (philosophy)",
      "Political science"
    ],
    "authors": [
      {
        "surname": "Tsiligkaridis",
        "given_name": "Theodoros"
      }
    ]
  },
  {
    "title": "Deep-gKnock: Nonlinear group-feature selection with deep neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.004",
    "abstract": "Feature selection is central to contemporary high-dimensional data analysis. Group structure among features arises naturally in various scientific problems. Many methods have been proposed to incorporate the group structure information into feature selection. However, these methods are normally restricted to a linear regression setting. To relax the linear constraint, we design a new Deep Neural Network (DNN) architecture and integrating it with the recently proposed knockoff technique to perform nonlinear group-feature selection with controlled group-wise False Discovery Rate (gFDR). Experimental results on high-dimensional synthetic data demonstrate that our method achieves the highest power and accurate gFDR control compared with state-of-the-art methods. The performance of Deep-gKnock is especially superior in the following five situations: (1) nonlinearity relationship; (2) dimension p greater than sample size n ; (3) high between-group correlation; (4) high within-group correlation; (5) large number of associated groups. And Deep-gKnock is also demonstrated to be robust to the misspecification of the feature distribution and the change of network architecture. Moreover, Deep-gKnock achieves scientifically meaningful group-feature selection results for cutting-edge real world datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304214",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Feature (linguistics)",
      "Feature selection",
      "Group (periodic table)",
      "Group selection",
      "Linguistics",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Selection (genetic algorithm)"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Guangyu"
      },
      {
        "surname": "Zhao",
        "given_name": "Tingting"
      }
    ]
  },
  {
    "title": "Greedy auto-augmentation for n-shot learning using deep neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.015",
    "abstract": "The goal of n-shot learning is the classification of input data from small datasets. This type of learning is challenging in neural networks, which typically need a high number of data during the training process. Recent advancements in data augmentation allow us to produce an infinite number of target conditions from the primary condition. This process includes two main steps for finding the best augmentations and training the data with the new augmentation techniques. Optimizing these two steps for n-shot learning is still an open problem. In this paper, we propose a new method for auto-augmentation to address both of these problems. The proposed method can potentially extract many possible types of information from a small number of available data points in n-shot learning. The results of our experiments on five prominent n-shot learning datasets show the effectiveness of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304135",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Machine learning",
      "Operating system",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Shot (pellet)"
    ],
    "authors": [
      {
        "surname": "Naghizadeh",
        "given_name": "Alireza"
      },
      {
        "surname": "Metaxas",
        "given_name": "Dimitris N."
      },
      {
        "surname": "Liu",
        "given_name": "Dongfang"
      }
    ]
  },
  {
    "title": "Sparse deep dictionary learning identifies differences of time-varying functional connectivity in brain neuro-developmental study",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.007",
    "abstract": "Recently, the focus of functional connectivity analysis of human brain has shifted from merely revealing the inter-regional functional correlation over the entire scan duration to capturing the time-varying information of brain networks and characterizing time-resolved reoccurring patterns of connectivity. Much effort has been invested into developing approaches that can track changes in re-occurring patterns of functional connectivity over time. In this paper, we propose a sparse deep dictionary learning method to characterize the essential differences of reoccurring patterns of time-varying functional connectivity between different age groups. The proposed method combines both the interpretability of sparse dictionary learning and the capability of extracting sparse nonlinear higher-level features in the latent space of sparse deep autoencoder. In other words, it learns a sparse dictionary of the original data by considering the nonlinear representation of the data in the encoder layer based on a sparse deep autoencoder. In this way, the nonlinear structure and higher-level features of the data can be captured by deep dictionary learning. The proposed method is applied to the analysis of the Philadelphia Neurodevelopmental Cohort. It shows that there exist essential differences in the reoccurrence patterns of function connectivity between child and young adult groups. Specially, children have more diffusive functional connectivity patterns while young adults possess more focused functional connectivity patterns, and the brain function transits from undifferentiated systems to specialized neural networks with the growth.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030424X",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Computer science",
      "Deep learning",
      "Interpretability",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Sparse approximation"
    ],
    "authors": [
      {
        "surname": "Qiao",
        "given_name": "Chen"
      },
      {
        "surname": "Yang",
        "given_name": "Lan"
      },
      {
        "surname": "Calhoun",
        "given_name": "Vince D."
      },
      {
        "surname": "Xu",
        "given_name": "Zong-Ben"
      },
      {
        "surname": "Wang",
        "given_name": "Yu-Ping"
      }
    ]
  },
  {
    "title": "A comprehensive study of class incremental learning algorithms for visual tasks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.003",
    "abstract": "The ability of artificial agents to increment their capabilities when confronted with new data is an open challenge in artificial intelligence. The main challenge faced in such cases is catastrophic forgetting, i.e., the tendency of neural networks to underfit past data when new ones are ingested. A first group of approaches tackles forgetting by increasing deep model capacity to accommodate new knowledge. A second type of approaches fix the deep model size and introduce a mechanism whose objective is to ensure a good compromise between stability and plasticity of the model. While the first type of algorithms were compared thoroughly, this is not the case for methods which exploit a fixed size model. Here, we focus on the latter, place them in a common conceptual and experimental framework and propose the following contributions: (1) define six desirable properties of incremental learning algorithms and analyze them according to these properties, (2) introduce a unified formalization of the class-incremental learning problem, (3) propose a common evaluation framework which is more thorough than existing ones in terms of number of datasets, size of datasets, size of bounded memory and number of incremental states, (4) investigate the usefulness of herding for past exemplars selection, (5) provide experimental evidence that it is possible to obtain competitive performance without the use of knowledge distillation to tackle catastrophic forgetting and (6) facilitate reproducibility by integrating all tested methods in a common open-source repository. The main experimental finding is that none of the existing algorithms achieves the best results in all evaluated settings. Important differences arise notably if a bounded memory of past classes is allowed or not.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304202",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Computer science",
      "Computer security",
      "Exploit",
      "Focus (optics)",
      "Forgetting",
      "Linguistics",
      "Machine learning",
      "Optics",
      "Philosophy",
      "Physics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Belouadah",
        "given_name": "Eden"
      },
      {
        "surname": "Popescu",
        "given_name": "Adrian"
      },
      {
        "surname": "Kanellos",
        "given_name": "Ioannis"
      }
    ]
  },
  {
    "title": "Quantum-inspired canonical correlation analysis for exponentially large dimensional data",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.019",
    "abstract": "Canonical correlation analysis (CCA) serves to identify statistical dependencies between pairs of multivariate data. However, its application to high-dimensional data is limited due to considerable computational complexity. As an alternative to the conventional CCA approach that requires polynomial computational time, we propose an algorithm that approximates CCA using quantum-inspired computations with computational time proportional to the logarithm of the input dimensionality. The computational efficiency and performance of the proposed quantum-inspired CCA (qiCCA) algorithm are experimentally evaluated on synthetic and real datasets. Furthermore, the fast computation provided by qiCCA allows directly applying CCA even after nonlinearly mapping raw input data into high-dimensional spaces. The conducted experiments demonstrate that, as a result of mapping raw input data into the high-dimensional spaces with the use of second-order monomials, qiCCA extracts more correlations compared with the linear CCA and achieves comparable performance with state-of-the-art nonlinear variants of CCA on several datasets. These results confirm the appropriateness of the proposed qiCCA and the high potential of quantum-inspired computations in analyzing high-dimensional data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304172",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Canonical correlation",
      "Computation",
      "Computer science",
      "Curse of dimensionality",
      "Dimensionality reduction",
      "Discrete mathematics",
      "Exponential growth",
      "Kernel (algebra)",
      "Logarithm",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Quantum",
      "Quantum computer",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Koide-Majima",
        "given_name": "Naoko"
      },
      {
        "surname": "Majima",
        "given_name": "Kei"
      }
    ]
  },
  {
    "title": "Constraints on Hebbian and STDP learned weights of a spiking neuron",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.012",
    "abstract": "We analyse mathematically the constraints on weights resulting from Hebbian and STDP learning rules applied to a spiking neuron with weight normalisation. In the case of pure Hebbian learning, we find that the normalised weights equal the promotion probabilities of weights up to correction terms that depend on the learning rate and are usually small. A similar relation can be derived for STDP algorithms, where the normalised weight values reflect a difference between the promotion and demotion probabilities of the weight. These relations are practically useful in that they allow checking for convergence of Hebbian and STDP algorithms. Another application is novelty detection. We demonstrate this using the MNIST dataset.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304299",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Generalization error",
      "Hebbian theory",
      "Leabra",
      "MNIST database",
      "Mathematics",
      "Novelty",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Synaptic weight",
      "Theology",
      "Wake-sleep algorithm"
    ],
    "authors": [
      {
        "surname": "Chu",
        "given_name": "Dominique"
      },
      {
        "surname": "Le Nguyen",
        "given_name": "Huy"
      }
    ]
  },
  {
    "title": "Generative Restricted Kernel Machines: A framework for multi-view generation and disentangled feature learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.010",
    "abstract": "This paper introduces a novel framework for generative models based on Restricted Kernel Machines (RKMs) with joint multi-view generation and uncorrelated feature learning, called Gen-RKM. To enable joint multi-view generation, this mechanism uses a shared representation of data from various views. Furthermore, the model has a primal and dual formulation to incorporate both kernel-based and (deep convolutional) neural network based models within the same setting. When using neural networks as explicit feature-maps, a novel training procedure is proposed, which jointly learns the features and shared subspace representation. The latent variables are given by the eigen-decomposition of the kernel matrix, where the mutual orthogonality of eigenvectors represents the learned uncorrelated features. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of generated samples on various standard datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304275",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Convolutional neural network",
      "Feature (linguistics)",
      "Feature learning",
      "Generative grammar",
      "Generative model",
      "Geometry",
      "Kernel (algebra)",
      "Kernel method",
      "Law",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Orthogonality",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Subspace topology",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Pandey",
        "given_name": "Arun"
      },
      {
        "surname": "Schreurs",
        "given_name": "Joachim"
      },
      {
        "surname": "Suykens",
        "given_name": "Johan A.K."
      }
    ]
  },
  {
    "title": "Self-organized operational neural networks for severe image restoration problems",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.014",
    "abstract": "Discriminative learning based on convolutional neural networks (CNNs) aims to perform image restoration by learning from training examples of noisy-clean image pairs. It has become the go-to methodology for tackling image restoration and has outperformed the traditional non-local class of methods. However, the top-performing networks are generally composed of many convolutional layers and hundreds of neurons, with trainable parameters in excess of several million. We claim that this is due to the inherently linear nature of convolution-based transformation, which is inadequate for handling severe restoration problems. Recently, a non-linear generalization of CNNs, called the operational neural networks (ONN), has been shown to outperform CNN on AWGN denoising. However, its formulation is burdened by a fixed collection of well-known non-linear operators and an exhaustive search to find the best possible configuration for a given architecture, whose efficacy is further limited by a fixed output layer operator assignment. In this study, we leverage the Taylor series-based function approximation to propose a self-organizing variant of ONNs, Self-ONNs, for image restoration, which synthesizes novel nodal transformations on-the-fly as part of the learning process, thus eliminating the need for redundant training runs for operator search. In addition, it enables a finer level of operator heterogeneity by diversifying individual connections of the receptive fields and weights. We perform a series of extensive ablation experiments across three severe image restoration tasks. Even when a strict equivalence of learnable parameters is imposed, Self-ONNs surpass CNNs by a considerable margin across all problems, improving the generalization performance by up to 3 dB in terms of PSNR.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304391",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Discriminative model",
      "Gene",
      "Image (mathematics)",
      "Image processing",
      "Image restoration",
      "Leverage (statistics)",
      "Machine learning",
      "Margin (machine learning)",
      "Mathematical optimization",
      "Mathematics",
      "Operator (biology)",
      "Pattern recognition (psychology)",
      "Repressor",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Malik",
        "given_name": "Junaid"
      },
      {
        "surname": "Kiranyaz",
        "given_name": "Serkan"
      },
      {
        "surname": "Gabbouj",
        "given_name": "Moncef"
      }
    ]
  },
  {
    "title": "DAPath: Distance-aware knowledge graph reasoning based on deep reinforcement learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.012",
    "abstract": "Knowledge graph reasoning aims to find reasoning paths for relations over incomplete knowledge graphs (KG). Prior works may not take into account that the rewards for each position (vertex in the graph) may be different. We propose the distance-aware reward in the reinforcement learning framework to assign different rewards for different positions. We observe that KG embeddings are learned from independent triples and therefore cannot fully cover the information described in the local neighborhood. To this effect, we integrate a graph self-attention (GSA) mechanism to capture more comprehensive entity information from the neighboring entities and relations. To let the model remember the path, we incorporate the GSA mechanism with GRU to consider the memory of relations in the path. Our approach can train the agent in one-pass, thus eliminating the pre-training or fine-tuning process, which significantly reduces the problem complexity. Experimental results demonstrate the effectiveness of our method. We found that our model can mine more balanced paths for each relation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030410X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Knowledge graph",
      "Machine learning",
      "Path (computing)",
      "Programming language",
      "Reinforcement learning",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Tiwari",
        "given_name": "Prayag"
      },
      {
        "surname": "Zhu",
        "given_name": "Hongyin"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      }
    ]
  },
  {
    "title": "Resilient asynchronous state estimation of Markov switching neural networks: A hierarchical structure approach",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.002",
    "abstract": "This paper deals with the issue of resilient asynchronous state estimation of discrete-time Markov switching neural networks. Randomly occurring signal quantization and packet dropout are involved in the imperfect measured output. The asynchronous switching phenomena appear among Markov switching neural networks, quantizer modes and filter modes, which are modeled by a hierarchical structure approach. By resorting to the hierarchical structure approach and Lyapunov functional technique, sufficient conditions are achieved, and asynchronous resilient filters are derived such that filtering error dynamic is stochastically stable. Finally, two examples are included to verify the validity of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304196",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Asynchronous communication",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Dropout (neural networks)",
      "Filter (signal processing)",
      "Machine learning",
      "Markov chain",
      "Markov process",
      "Mathematics",
      "Network packet",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Cheng",
        "given_name": "Jun"
      },
      {
        "surname": "Wu",
        "given_name": "Yuyan"
      },
      {
        "surname": "Xiong",
        "given_name": "Lianglin"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Park",
        "given_name": "Ju H."
      }
    ]
  },
  {
    "title": "Semi-supervised disentangled framework for transferable named entity recognition",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.017",
    "abstract": "Named entity recognition (NER) for identifying proper nouns in unstructured text is one of the most important and fundamental tasks in natural language processing. However, despite the widespread use of NER models, they still require a large-scale labeled data set, which incurs a heavy burden due to manual annotation. Domain adaptation is one of the most promising solutions to this problem, where rich labeled data from the relevant source domain are utilized to strengthen the generalizability of a model based on the target domain. However, the mainstream cross-domain NER models are still affected by the following two challenges (1) Extracting domain-invariant information such as syntactic information for cross-domain transfer. (2) Integrating domain-specific information such as semantic information into the model to improve the performance of NER. In this study, we present a semi-supervised framework for transferable NER, which disentangles the domain-invariant latent variables and domain-specific latent variables. In the proposed framework, the domain-specific information is integrated with the domain-specific latent variables by using a domain predictor. The domain-specific and domain-invariant latent variables are disentangled using three mutual information regularization terms, i.e., maximizing the mutual information between the domain-specific latent variables and the original embedding, maximizing the mutual information between the domain-invariant latent variables and the original embedding, and minimizing the mutual information between the domain-specific and domain-invariant latent variables. Extensive experiments demonstrated that our model can obtain state-of-the-art performance with cross-domain and cross-lingual NER benchmark data sets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304159",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Domain (mathematical analysis)",
      "Economics",
      "Embedding",
      "Latent variable",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Mutual information",
      "Named-entity recognition",
      "Natural language processing",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Hao",
        "given_name": "Zhifeng"
      },
      {
        "surname": "Lv",
        "given_name": "Di"
      },
      {
        "surname": "Li",
        "given_name": "Zijian"
      },
      {
        "surname": "Cai",
        "given_name": "Ruichu"
      },
      {
        "surname": "Wen",
        "given_name": "Wen"
      },
      {
        "surname": "Xu",
        "given_name": "Boyan"
      }
    ]
  },
  {
    "title": "Finite-time cluster synchronization in complex-variable networks with fractional-order and nonlinear coupling",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.015",
    "abstract": "This paper is primarily concentrated on finite-time cluster synchronization of fractional-order complex-variable networks with nonlinear coupling by utilizing the non-decomposition method. Firstly, two control strategies are designed which are relevant to complex-valued sign functions. Thereafter, by employing fractional-order stability theory and complex function theory, several criteria are deduced to ensure finite-time cluster synchronization under the framework within a new norm consisting of absolute values for real and imaginary components. Furthermore, the setting time is effectively estimated based on some significant properties of fractional-order Caputo derivation and Mittag-Leffler functions. Lastly, two numerical examples are given to verify the effectiveness of theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304408",
    "keywords": [
      "Applied mathematics",
      "Biology",
      "Cluster (spacecraft)",
      "Combinatorics",
      "Complex network",
      "Computer science",
      "Coupling (piping)",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Law",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear system",
      "Norm (philosophy)",
      "Physics",
      "Political science",
      "Programming language",
      "Quantum mechanics",
      "Sign function",
      "Stability (learning theory)",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Variable (mathematics)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Shuai"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Yu",
        "given_name": "Juan"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      }
    ]
  },
  {
    "title": "Insights on the role of external globus pallidus in controlling absence seizures",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.006",
    "abstract": "Absence epilepsy, characterized by transient loss of awareness and bilaterally synchronous 2–4 Hz spike and wave discharges (SWDs) on electroencephalography (EEG) during absence seizures, is generally believed to arise from abnormal interactions between the cerebral cortex (Ctx) and thalamus. Recent animal electrophysiological studies suggested that changing the neural activation level of the external globus pallidus (GPe) neurons can remarkably modify firing rates of the thalamic reticular nucleus (TRN) neurons through the GABAergic GPe–TRN pathway. However, the existing experimental evidence does not provide a clear answer as to whether the GPe–TRN pathway contributes to regulating absence seizures. Here, using a biophysically based mean-field model of the GPe-corticothalamic (GCT) network, we found that both directly decreasing the strength of the GPe–TRN pathway and inactivating GPe neurons can effectively suppress absence seizures. Also, the pallido-cortical pathway and the recurrent connection of GPe neurons facilitate the regulation of absence seizures through the GPe–TRN pathway. Specifically, in the controllable situation, enhancing the coupling strength of either of the two pathways can successfully terminate absence seizures. Moreover, the competition between the GPe–TRN and pallido-cortical pathways may lead to the GPe bidirectionally controlling absence seizures, and this bidirectional control manner can be significantly modulated by the Ctx–TRN pathway. Importantly, when the strength of the Ctx–TRN pathway is relatively strong, the bidirectional control of absence seizures by changing GPe neural activities can be observed at both weak and strong strengths of the pallido-cortical pathway.These findings suggest that the GPe–TRN pathway may have crucial functional roles in regulating absence seizures, which may provide a testable hypothesis for further experimental studies and new perspectives on the treatment of absence epilepsy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304238",
    "keywords": [
      "Basal ganglia",
      "Biology",
      "Central nervous system",
      "Cerebral cortex",
      "Deep brain stimulation",
      "Disease",
      "Electroencephalography",
      "Electrophysiology",
      "Epilepsy",
      "GABAergic",
      "Globus pallidus",
      "Inhibitory postsynaptic potential",
      "Internal medicine",
      "Medicine",
      "Neuroscience",
      "Parkinson's disease",
      "Spike-and-wave",
      "Subthalamic nucleus",
      "Thalamic reticular nucleus",
      "Thalamus"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Mingming"
      },
      {
        "surname": "Zhu",
        "given_name": "Yajie"
      },
      {
        "surname": "Yu",
        "given_name": "Renping"
      },
      {
        "surname": "Hu",
        "given_name": "Yuxia"
      },
      {
        "surname": "Wan",
        "given_name": "Hong"
      },
      {
        "surname": "Zhang",
        "given_name": "Rui"
      },
      {
        "surname": "Yao",
        "given_name": "Dezhong"
      },
      {
        "surname": "Guo",
        "given_name": "Daqing"
      }
    ]
  },
  {
    "title": "Exploitation of image statistics with sparse coding in the case of stereo vision",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.12.016",
    "abstract": "The sparse coding algorithm has served as a model for early processing in mammalian vision. It has been assumed that the brain uses sparse coding to exploit statistical properties of the sensory stream. We hypothesize that sparse coding discovers patterns from the data set, which can be used to estimate a set of stimulus parameters by simple readout. In this study, we chose a model of stereo vision to test our hypothesis. We used the Locally Competitive Algorithm (LCA), followed by a naïve Bayes classifier, to infer stereo disparity. From the results we report three observations. First, disparity inference was successful with this naturalistic processing pipeline. Second, an expanded, highly redundant representation is required to robustly identify the input patterns. Third, the inference error can be predicted from the number of active coefficients in the LCA representation. We conclude that sparse coding can generate a suitable general representation for subsequent inference tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030441X",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Coding (social sciences)",
      "Computer science",
      "Inference",
      "Mathematics",
      "Neural coding",
      "Pattern recognition (psychology)",
      "Sparse approximation",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Ecke",
        "given_name": "Gerrit A."
      },
      {
        "surname": "Papp",
        "given_name": "Harald M."
      },
      {
        "surname": "Mallot",
        "given_name": "Hanspeter A."
      }
    ]
  },
  {
    "title": "Artificial fly visual joint perception neural network inspired by multiple-regional collision detection",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.018",
    "abstract": "The biological visual system includes multiple types of motion sensitive neurons which preferentially respond to specific perceptual regions. However, it still keeps open how to borrow such neurons to construct bio-inspired computational models for multiple-regional collision detection. To fill this gap, this work proposes a visual joint perception neural network with two subnetworks — presynaptic and postsynaptic neural networks, inspired by the preferential perception characteristics of three horizontal and vertical motion sensitive neurons. Related to the neural network and three hazard detection mechanisms, an artificial fly visual synthesized collision detection model for multiple-regional collision detection is originally developed to monitor possible danger occurrence in the case where one or more moving objects appear in the whole field of view. The experiments can clearly draw two conclusions: (i) the acquired neural network can effectively display the characteristics of visual movement, and (ii) the collision detection model, which outperforms the compared models, can effectively perform multiple-regional collision detection at a high success rate, and only takes about 0.24s to complete the process of collision detection for each virtual or actual image frame with resolution 110 × 60.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304160",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Collision",
      "Collision detection",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Frame (networking)",
      "Motion (physics)",
      "Motion perception",
      "Neuroscience",
      "On the fly",
      "Operating system",
      "Pattern recognition (psychology)",
      "Perception",
      "Process (computing)",
      "Telecommunications",
      "Visual perception"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Lun"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhuhong"
      },
      {
        "surname": "Lu",
        "given_name": "Jiaxuan"
      }
    ]
  },
  {
    "title": "Distant Supervision Relation Extraction via adaptive dependency-path and additional knowledge graph supervision",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.012",
    "abstract": "Relation Extraction systems train an extractor by aligning relation instances in Knowledge Base with a large amount of labeled corpora. Since the labeled datasets are very expensive, Distant Supervision Relation Extraction (DSRE) utilizes rough corpus annotated with Knowledge Graph to reduce the cost of acquisition. Nevertheless, the data noise problem limits the performance of the DSRE. Dependency trees can be used to filter the wrong-labeled instances in the distant supervision bag. However, existing dependency tree relation extraction strategies are all based on manually-set paths between the subject and object entities, and suffer from the problem of pruning the trees too aggressively or too insufficiently. To circumvent the shortcomings, in this paper, we propose a novel DSRE framework A 2 DSRE, based on the Adaptive dependency-path and Additional KG supervision. To obtain the dependency paths related to entity relations adaptively, we introduce an advanced graph neural network—GeniePath into DSRE, which assigns higher weights to those direct neighbor words that contribute more to relation prediction through breadth exploration, and conducts depth exploration to determine the correlation between relations and high-order neighbors. In this way, the irrelevant nodes are pruned while the relevant nodes are kept, our method can obtain more appropriate paths associated with relations. At the same time, to further reduce the noises in the data, we incorporate additional supervision information from the knowledge graph by retracting the margin between the representation of the bag and the pre-training knowledge graph embedding. Extensive numerical experiments validate the effectiveness of our new method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303671",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Dependency (UML)",
      "Embedding",
      "Graph",
      "Machine learning",
      "Margin (machine learning)",
      "Matching (statistics)",
      "Mathematics",
      "Path (computing)",
      "Pattern recognition (psychology)",
      "Programming language",
      "Relation (database)",
      "Relationship extraction",
      "Statistics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Shi",
        "given_name": "Yong"
      },
      {
        "surname": "Xiao",
        "given_name": "Yang"
      },
      {
        "surname": "Quan",
        "given_name": "Pei"
      },
      {
        "surname": "Lei",
        "given_name": "MingLong"
      },
      {
        "surname": "Niu",
        "given_name": "Lingfeng"
      }
    ]
  },
  {
    "title": "Generating photo-realistic training data to improve face recognition accuracy",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.008",
    "abstract": "Face recognition has become a widely adopted biometric in forensics, security and law enforcement thanks to the high accuracy achieved by systems based on convolutional neural networks (CNNs). However, to achieve good performance, CNNs need to be trained with very large datasets which are not always available. In this paper we investigate the feasibility of using synthetic data to augment face datasets. In particular, we propose a novel generative adversarial network (GAN) that can disentangle identity-related attributes from non-identity-related attributes. This is done by training an embedding network that maps discrete identity labels to an identity latent space that follows a simple prior distribution, and training a GAN conditioned on samples from that distribution. A main novelty of our approach is the ability to generate both synthetic images of subjects in the training set and synthetic images of new subjects not in the training set, both of which we use to augment face datasets. By using recent advances in GAN training, we show that the synthetic images generated by our model are photo-realistic, and that training with datasets augmented with those images can lead to increased recognition accuracy. Experimental results show that our method is more effective when augmenting small datasets. In particular, an absolute accuracy improvement of 8.42% was achieved when augmenting a dataset of less than 60k facial images.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303932",
    "keywords": [],
    "authors": [
      {
        "surname": "Sáez Trigueros",
        "given_name": "Daniel"
      },
      {
        "surname": "Meng",
        "given_name": "Li"
      },
      {
        "surname": "Hartnett",
        "given_name": "Margaret"
      }
    ]
  },
  {
    "title": "Efficient architecture for deep neural networks with heterogeneous sensitivity",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.017",
    "abstract": "In this study, we present a neural network that consists of nodes with heterogeneous sensitivity. Each node in a network is assigned a variable that determines the sensitivity with which it learns to perform a given task. The network is trained via a constrained optimization that maximizes the sparsity of the sensitivity variables while ensuring optimal network performance. As a result, the network learns to perform a given task using only a few sensitive nodes. Insensitive nodes, which are nodes with zero sensitivity, can be removed from a trained network to obtain a computationally efficient network. Removing zero-sensitivity nodes has no effect on the performance of the network because the network has already been trained to perform the task without them. The regularization parameter used to solve the optimization problem was simultaneously found during the training of the networks. To validate our approach, we designed networks with computationally efficient architectures for various tasks such as autoregression, object recognition, facial expression recognition, and object detection using various datasets. In our experiments, the networks designed by our proposed method provided the same or higher performances but with far less computational complexity.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303804",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer network",
      "Computer science",
      "Economics",
      "Electronic engineering",
      "Engineering",
      "Machine learning",
      "Management",
      "Network architecture",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Sensitivity (control systems)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Cho",
        "given_name": "Hyunjoong"
      },
      {
        "surname": "Jang",
        "given_name": "Jinhyeok"
      },
      {
        "surname": "Lee",
        "given_name": "Chanhyeok"
      },
      {
        "surname": "Yang",
        "given_name": "Seungjoon"
      }
    ]
  },
  {
    "title": "Modality independent adversarial network for generalized zero shot image classification",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.007",
    "abstract": "Zero Shot Learning (ZSL) aims to classify images of unseen target classes by transferring knowledge from source classes through semantic embeddings. The core of ZSL research is to embed both visual representation of object instance and semantic description of object class into a joint latent space and learn cross-modal (visual and semantic) latent representations. However, the learned representations by existing efforts often fail to fully capture the underlying cross-modal semantic consistency, and some of the representations are very similar and less discriminative. To circumvent these issues, in this paper, we propose a novel deep framework, called Modality Independent Adversarial Network (MIANet) for Generalized Zero Shot Learning (GZSL), which is an end-to-end deep architecture with three submodules. First, both visual feature and semantic description are embedded into a latent hyper-spherical space, where two orthogonal constraints are employed to ensure the learned latent representations discriminative. Second, a modality adversarial submodule is employed to make the latent representations independent of modalities to make the shared representations grab more cross-modal high-level semantic information during training. Third, a cross reconstruction submodule is proposed to reconstruct latent representations into the counterparts instead of themselves to make them capture more modality irrelevant information. Comprehensive experiments on five widely used benchmark datasets are conducted on both GZSL and standard ZSL settings, and the results show the effectiveness of our proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303920",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Chemistry",
      "Class (philosophy)",
      "Computer science",
      "Consistency (knowledge bases)",
      "Discriminative model",
      "Feature (linguistics)",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Law",
      "Linguistics",
      "Machine learning",
      "Modal",
      "Modality (human–computer interaction)",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Polymer chemistry",
      "Probabilistic latent semantic analysis",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Haofeng"
      },
      {
        "surname": "Wang",
        "given_name": "Yinduo"
      },
      {
        "surname": "Long",
        "given_name": "Yang"
      },
      {
        "surname": "Yang",
        "given_name": "Longzhi"
      },
      {
        "surname": "Shao",
        "given_name": "Ling"
      }
    ]
  },
  {
    "title": "Effect of diverse recoding of granule cells on optokinetic response in a cerebellar ring network with synaptic plasticity",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.014",
    "abstract": "We consider a cerebellar ring network for the optokinetic response (OKR), and investigate the effect of diverse recoding of granule (GR) cells on OKR by varying the connection probability p c from Golgi to GR cells. For an optimal value of p c ∗ ( = 0 . 06 ) , individual GR cells exhibit diverse spiking patterns which are in-phase, anti-phase, or complex out-of-phase with respect to their population-averaged firing activity. Then, these diversely-recoded signals via parallel fibers (PFs) from GR cells are effectively depressed by the error-teaching signals via climbing fibers from the inferior olive which are also in-phase ones. Synaptic weights at in-phase PF-Purkinje cell (PC) synapses of active GR cells are strongly depressed via strong long-term depression (LTD), while those at anti-phase and complex out-of-phase PF-PC synapses are weakly depressed through weak LTD. This kind of “effective” depression (i.e., strong/weak LTD) at the PF-PC synapses causes a big modulation in firings of PCs, which then exert effective inhibitory coordination on the vestibular nucleus (VN) neuron (which evokes OKR). For the firing of the VN neuron, the learning gain degree L g , corresponding to the modulation gain ratio, increases with increasing the learning cycle, and it saturates at about the 300th cycle. By varying p c from p c ∗ , we find that a plot of saturated learning gain degree L g ∗ versus p c forms a bell-shaped curve with a peak at p c ∗ (where the diversity degree in spiking patterns of GR cells is also maximum). Consequently, the more diverse in recoding of GR cells, the more effective in motor learning for the OKR adaptation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304123",
    "keywords": [
      "Biology",
      "Biophysics",
      "Cerebellar cortex",
      "Cerebellum",
      "Chemistry",
      "Inhibitory postsynaptic potential",
      "Neuron",
      "Neuroscience",
      "Optokinetic reflex",
      "Physics",
      "Vestibular system"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Sang-Yoon"
      },
      {
        "surname": "Lim",
        "given_name": "Woochang"
      }
    ]
  },
  {
    "title": "State bounding for fuzzy memristive neural networks with bounded input disturbances",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.016",
    "abstract": "This paper investigates the state bounding problem of fuzzy memristive neural networks (FMNNs) with bounded input disturbances. By using the characters of Metzler, Hurwitz and nonnegative matrices, this paper obtains the exact delay-independent and delay-dependent boundary ranges of the solution, which have less conservatism than the results in existing literatures. The validity of the results is verified by two numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304147",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Boundary (topology)",
      "Bounded function",
      "Bounding overwatch",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Fuzzy logic",
      "Mathematical analysis",
      "Mathematics",
      "State (computer science)"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Yu"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      },
      {
        "surname": "Yang",
        "given_name": "Chunyu"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Necessary conditions for STDP-based pattern recognition learning in a memristive spiking neural network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.005",
    "abstract": "This work is aimed to study experimental and theoretical approaches for searching effective local training rules for unsupervised pattern recognition by high-performance memristor-based Spiking Neural Networks (SNNs). First, the possibility of weight change using Spike-Timing-Dependent Plasticity (STDP) is demonstrated with a pair of hardware analog neurons connected through a (CoFeB) x (LiNbO3) 1 − x nanocomposite memristor. Next, the learning convergence to a solution of binary clusterization task is analyzed in a wide range of memristive STDP parameters for a single-layer fully connected feedforward SNN. The memristive STDP behavior supplying convergence in this simple task is shown also to provide it in the handwritten digit recognition domain by the more complex SNN architecture with a Winner-Take-All competition between neurons. To investigate basic conditions necessary for training convergence, an original probabilistic generative model of a rate-based single-layer network with independent or competing neurons is built and thoroughly analyzed. The main result is a statement of “correlation growth-anticorrelation decay” principle which prompts near-optimal policy to configure model parameters. This principle is in line with requiring the binary clusterization convergence which can be defined as the necessary condition for optimal learning and used as the simple benchmark for tuning parameters of various neural network realizations with population-rate information coding. At last, a heuristic algorithm is described to experimentally find out the convergence conditions in a memristive SNN, including robustness to a device variability. Due to the generality of the proposed approach, it can be applied to a wide range of memristors and neurons of software- or hardware-based rate-coding single-layer SNNs when searching for local rules that ensure their unsupervised learning convergence in a pattern recognition task domain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303907",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Demin",
        "given_name": "V.A."
      },
      {
        "surname": "Nekhaev",
        "given_name": "D.V."
      },
      {
        "surname": "Surazhevsky",
        "given_name": "I.A."
      },
      {
        "surname": "Nikiruy",
        "given_name": "K.E."
      },
      {
        "surname": "Emelyanov",
        "given_name": "A.V."
      },
      {
        "surname": "Nikolaev",
        "given_name": "S.N."
      },
      {
        "surname": "Rylkov",
        "given_name": "V.V."
      },
      {
        "surname": "Kovalchuk",
        "given_name": "M.V."
      }
    ]
  },
  {
    "title": "Deep-learned spike representations and sorting via an ensemble of auto-encoders",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.009",
    "abstract": "Spike sorting refers to the technique of detecting signals generated by single neurons from multi-neuron recordings and is a valuable tool for analyzing the relationships between individual neuronal activity patterns and specific behaviors. Since the precision of spike sorting affects all subsequent analyses, sorting accuracy is critical. Many semi-automatic to fully-automatic spike sorting algorithms have been developed. However, due to unsatisfactory classification accuracy, manual sorting is preferred by investigators despite the intensive time and labor costs. Thus, there still is a strong need for fully automatic spike sorting methods with high accuracy. Various machine learning algorithms have been developed for feature extraction but have yet to show sufficient accuracy for spike sorting. Here we describe a deep learning-based method for extracting features from spike signals using an ensemble of auto-encoders, each with a distinct architecture for distinguishing signals at different levels of resolution. By utilizing ensemble of auto-encoder ensemble, where shallow networks better represent overall signal structure and deep networks better represent signal details, extraction of high-dimensional representative features for improved spike sorting performance is achieved. The model was evaluated on publicly available simulated datasets and single-channel and 4-channel tetrode in vivo datasets. Our model not only classified single-channel spikes with varying degrees of feature similarities and signal to noise levels with higher accuracy, but also more precisely determined the number of source neurons compared to other machine learning methods. The model also demonstrated greater overall accuracy for spike sorting 4-channel tetrode recordings compared to single-channel recordings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303944",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Feature (linguistics)",
      "Feature extraction",
      "Image (mathematics)",
      "Linguistics",
      "Noise (video)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "SIGNAL (programming language)",
      "Software engineering",
      "Sorting",
      "Sorting algorithm",
      "Spike (software development)",
      "Spike sorting"
    ],
    "authors": [
      {
        "surname": "Eom",
        "given_name": "Junsik"
      },
      {
        "surname": "Park",
        "given_name": "In Yong"
      },
      {
        "surname": "Kim",
        "given_name": "Sewon"
      },
      {
        "surname": "Jang",
        "given_name": "Hanbyol"
      },
      {
        "surname": "Park",
        "given_name": "Sanggeon"
      },
      {
        "surname": "Huh",
        "given_name": "Yeowool"
      },
      {
        "surname": "Hwang",
        "given_name": "Dosik"
      }
    ]
  },
  {
    "title": "A brain-inspired network architecture for cost-efficient object recognition in shallow hierarchical neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.013",
    "abstract": "The brain successfully performs visual object recognition with a limited number of hierarchical networks that are much shallower than artificial deep neural networks (DNNs) that perform similar tasks. Here, we show that long-range horizontal connections (LRCs), often observed in the visual cortex of mammalian species, enable such a cost-efficient visual object recognition in shallow neural networks. Using simulations of a model hierarchical network with convergent feedforward connections and LRCs, we found that the addition of LRCs to the shallow feedforward network significantly enhances the performance of networks for image classification, to a degree that is comparable to much deeper networks. We found that a combination of sparse LRCs and dense local connections dramatically increases performance per wiring cost. From network pruning with gradient-based optimization, we also confirmed that LRCs could emerge spontaneously by minimizing the total connection length while maintaining performance. Ablation of emerged LRCs led to a significant reduction of classification performance, which implies these LRCs are crucial for performing image classification. Taken together, our findings suggest a brain-inspired strategy for constructing a cost-efficient network architecture to implement parsimonious object recognition under physical constraints such as shallow hierarchical depth.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304111",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Cognitive neuroscience of visual object recognition",
      "Computer network",
      "Computer science",
      "Contextual image classification",
      "Control engineering",
      "Engineering",
      "Feed forward",
      "Feedforward neural network",
      "Geometry",
      "Image (mathematics)",
      "Mathematics",
      "Network architecture",
      "Neuroscience",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Pruning",
      "Reduction (mathematics)",
      "Visual cortex"
    ],
    "authors": [
      {
        "surname": "Park",
        "given_name": "Youngjin"
      },
      {
        "surname": "Baek",
        "given_name": "Seungdae"
      },
      {
        "surname": "Paik",
        "given_name": "Se-Bum"
      }
    ]
  },
  {
    "title": "Learning sparse and meaningful representations through embodiment",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.004",
    "abstract": "How do humans acquire a meaningful understanding of the world with little to no supervision or semantic labels provided by the environment? Here we investigate embodiment with a closed loop between action and perception as one key component in this process. We take a close look at the representations learned by a deep reinforcement learning agent that is trained with high-dimensional visual observations collected in a 3D environment with very sparse rewards. We show that this agent learns stable representations of meaningful concepts such as doors without receiving any semantic labels. Our results show that the agent learns to represent the action relevant information, extracted from a simulated camera stream, in a wide variety of sparse activation patterns. The quality of the representations learned shows the strength of embodied learning and its advantages over fully supervised approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303890",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Component (thermodynamics)",
      "Computer science",
      "Computer security",
      "Embodied cognition",
      "Key (lock)",
      "Law",
      "Machine learning",
      "Neuroscience",
      "Operating system",
      "Perception",
      "Perspective (graphical)",
      "Physics",
      "Political science",
      "Politics",
      "Process (computing)",
      "Programming language",
      "Psychology",
      "Quantum mechanics",
      "Reinforcement learning",
      "Representation (politics)",
      "Semantics (computer science)",
      "Thermodynamics",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Clay",
        "given_name": "Viviane"
      },
      {
        "surname": "König",
        "given_name": "Peter"
      },
      {
        "surname": "Kühnberger",
        "given_name": "Kai-Uwe"
      },
      {
        "surname": "Pipa",
        "given_name": "Gordon"
      }
    ]
  },
  {
    "title": "Approximation rates for neural networks with encodable weights in smoothness spaces",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.010",
    "abstract": "We examine the necessary and sufficient complexity of neural networks to approximate functions from different smoothness spaces under the restriction of encodable network weights. Based on an entropy argument, we start by proving lower bounds for the number of nonzero encodable weights for neural network approximation in Besov spaces, Sobolev spaces and more. These results are valid for all sufficiently smooth activation functions. Afterwards, we provide a unifying framework for the construction of approximate partitions of unity by neural networks with fairly general activation functions. This allows us to approximate localized Taylor polynomials by neural networks and make use of the Bramble–Hilbert Lemma. Based on our framework, we derive almost optimal upper bounds in higher-order Sobolev norms. This work advances the theory of approximating solutions of partial differential equations by neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303956",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Discrete mathematics",
      "Ecology",
      "Entropy (arrow of time)",
      "Hilbert space",
      "Lemma (botany)",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Poaceae",
      "Pure mathematics",
      "Quantum mechanics",
      "Smoothness",
      "Sobolev space"
    ],
    "authors": [
      {
        "surname": "Gühring",
        "given_name": "Ingo"
      },
      {
        "surname": "Raslan",
        "given_name": "Mones"
      }
    ]
  },
  {
    "title": "Particle swarm optimized neural networks based local tracking control scheme of unknown nonlinear interconnected systems",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.09.020",
    "abstract": "In this paper, a local tracking control (LTC) scheme is developed via particle swarm optimized neural networks (PSONN) for unknown nonlinear interconnected systems. With the local input–output data, a local neural network identifier is constructed to approximate the local input gain matrix and the mismatched interconnection, which are utilized to derive the LTC. To solve the local Hamilton–Jacobi–Bellman equation, a local critic NN is established to estimate the proper local value function, which reflects the mismatched interconnection. The weight vector of the local critic NN is trained online by particle swarm optimization, thus the success rate of system execution is increased. The stability of the closed-loop unknown nonlinear interconnected system is guaranteed to be uniformly ultimately bounded through Lyapunov’s direct method. Simulation results of two examples demonstrate the effectiveness of the developed PSONN-based LTC scheme.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303518",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Particle swarm optimization",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Scheme (mathematics)",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Bo"
      },
      {
        "surname": "Luo",
        "given_name": "Fangchao"
      },
      {
        "surname": "Lin",
        "given_name": "Haowei"
      },
      {
        "surname": "Liu",
        "given_name": "Derong"
      }
    ]
  },
  {
    "title": "Bridging multimedia heterogeneity gap via Graph Representation Learning for cross-modal retrieval",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.011",
    "abstract": "Information retrieval among different modalities becomes a significant issue with many promising applications. However, inconsistent feature representation of various multimedia data causes the “heterogeneity gap” among various modalities, which is a challenge in cross-modal retrieval. For bridging the “heterogeneity gap,” the popular methods attempt to project the original data into a common representation space, which needs great fitting ability of the model. To address the above issue, we propose a novel Graph Representation Learning (GRL) method for bridging the heterogeneity gap, which does not project the original feature into an aligned representation space but adopts a cross-modal graph to link different modalities. The GRL approach consists of two subnetworks, Feature Transfer Learning Network (FTLN) and Graph Representation Learning Network (GRLN). Firstly, FTLN model finds a latent space for each modality, where the cosine similarity is suitable to describe their similarity. Then, we build a cross-modal graph to reconstruct the original data and their relationships. Finally, we abandon the features in the latent space and turn into embedding the graph vertexes into a common representation space directly. During the process, the proposed Graph Representation Learning method bypasses the most challenging issue by utilizing a cross-modal graph as a bridge to link the “heterogeneity gap” among different modalities. This attempt utilizes a cross-modal graph as an intermediary agent to bridge the “heterogeneity gap” in cross-modal retrieval, which is simple but effective. Extensive experiment results on six widely-used datasets indicate that the proposed GRL outperforms other state-of-the-art cross-modal retrieval methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020304093",
    "keywords": [
      "Artificial intelligence",
      "Bridging (networking)",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Feature learning",
      "Graph",
      "Information retrieval",
      "Law",
      "Modal",
      "Multimedia",
      "Political science",
      "Politics",
      "Polymer chemistry",
      "Representation (politics)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Cheng",
        "given_name": "Qingrong"
      },
      {
        "surname": "Gu",
        "given_name": "Xiaodong"
      }
    ]
  },
  {
    "title": "Episodic memory governs choices: An RNN-based reinforcement learning model for decision-making task",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.003",
    "abstract": "Typical methods to study cognitive function are to record the electrical activities of animal neurons during the training of animals performing behavioral tasks. A key problem is that they fail to record all the relevant neurons in the animal brain. To alleviate this problem, we develop an RNN-based Actor–Critic framework, which is trained through reinforcement learning (RL) to solve two tasks analogous to the monkeys’ decision-making tasks. The trained model is capable of reproducing some features of neural activities recorded from animal brain, or some behavior properties exhibited in animal experiments, suggesting that it can serve as a computational platform to explore other cognitive functions. Furthermore, we conduct behavioral experiments on our framework, trying to explore an open question in neuroscience: which episodic memory in the hippocampus should be selected to ultimately govern future decisions. We find that the retrieval of salient events sampled from episodic memories can effectively shorten deliberation time than common events in the decision-making process. The results indicate that salient events stored in the hippocampus could be prioritized to propagate reward information, and thus allow decision-makers to learn a strategy faster.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303889",
    "keywords": [
      "Animal cognition",
      "Artificial intelligence",
      "Cognition",
      "Cognitive psychology",
      "Cognitive science",
      "Computer science",
      "Deliberation",
      "Economics",
      "Episodic memory",
      "Law",
      "Machine learning",
      "Management",
      "Neuroscience",
      "Operating system",
      "Political science",
      "Politics",
      "Process (computing)",
      "Psychology",
      "Reinforcement learning",
      "Salient",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Xiaohan"
      },
      {
        "surname": "Liu",
        "given_name": "Lu"
      },
      {
        "surname": "Long",
        "given_name": "Guodong"
      },
      {
        "surname": "Jiang",
        "given_name": "Jing"
      },
      {
        "surname": "Liu",
        "given_name": "Shenquan"
      }
    ]
  },
  {
    "title": "Chapter 14 Deep learning from small labeled datasets applied to medical image analysis",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00014-0",
    "abstract": "Deep learning has been a hot topic and applied in various applications. However, a crucial requirement of deep learning in medical image applications is the ability to produce generalizable learning from small and often heterogeneous image sets. In this chapter, we will present some deep learning approaches for learning from small datasets. These approaches use the following idea: leverage information from a different related modality for learning. While approaches exist even for learning generalizable models from the same modality, we particularly focus on the problem where learning is done by using a different imaging modality such as computed tomography (CT) with MRI, T1-weighted MRI with FLAIR MRI, CT with positron emission tomography, etc. Learning using from different modalities is called cross-modality learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000140",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Focus (optics)",
      "Leverage (statistics)",
      "Machine learning",
      "Modalities",
      "Modality (human–computer interaction)",
      "Optics",
      "Physics",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Veeraraghavan",
        "given_name": "Harini"
      },
      {
        "surname": "Jiang",
        "given_name": "Jue"
      }
    ]
  },
  {
    "title": "Chapter 7 Achievements of neural network in skin lesions classification",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00007-3",
    "abstract": "The gross mismatch of skin disease cases and the specialties to manage them is the main cause of a continuously increased disease burden. The skin disease burden contributes 1.79% toward the global disease burden. To lessen this burden, automated skin lesions classification schemes that can provide multiclass classification are highly demanded. This chapter presents an investigation into an automated classification scheme to classify multiple skin lesions (acne, eczema, psoriasis; benign, and malignant) using state-of-the-art machine learning techniques. In the proposed classification scheme, convolution neural network (CNN) is utilized using the transfer learning approach, and a pretrained CNN model “AlexNet” is used to retrain the classification model on the skin lesion dataset. The proposed classification scheme outperformed over existing classification schemes and obtained an accuracy of 96.65%. The multiclass classification scheme can be very beneficial in the limited resource areas as it can assist in the early diagnosis of multiple skin lesions.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000073",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classification scheme",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Dermatology",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Medicine",
      "Multiclass classification",
      "Pattern recognition (psychology)",
      "Scheme (mathematics)",
      "Skin lesion",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Hameed",
        "given_name": "Nazia"
      },
      {
        "surname": "Shabut",
        "given_name": "Antesar"
      },
      {
        "surname": "Hameed",
        "given_name": "Fozia"
      },
      {
        "surname": "Cirstea",
        "given_name": "Silvia"
      },
      {
        "surname": "Hossain",
        "given_name": "Alamgir"
      }
    ]
  },
  {
    "title": "FPGAN: Face de-identification method with generative adversarial networks for social robots",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.09.001",
    "abstract": "In this paper, we propose a new face de-identification method based on generative adversarial network (GAN) to protect visual facial privacy, which is an end-to-end method (herein, FPGAN). First, we propose FPGAN and mathematically prove its convergence. Then, a generator with an improved U-Net is used to enhance the quality of the generated image, and two discriminators with a seven-layer network architecture are designed to strengthen the feature extraction ability of FPGAN. Subsequently, we propose the pixel loss, content loss, adversarial loss functions and optimization strategy to guarantee the performance of FPGAN. In our experiments, we applied FPGAN to face de-identification in social robots and analyzed the related conditions that could affect the model. Moreover, we proposed a new face de-identification evaluation protocol to check the performance of the model. This protocol can be used for the evaluation of face de-identification and privacy protection. Finally, we tested our model and four other methods on the CelebA, MORPH, RaFD, and FBDe datasets. The results of the experiments show that FPGAN outperforms the baseline methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303245",
    "keywords": [
      "Adversarial system",
      "Alternative medicine",
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Face (sociological concept)",
      "Facial recognition system",
      "Feature (linguistics)",
      "Feature extraction",
      "Generator (circuit theory)",
      "Identification (biology)",
      "Linguistics",
      "Machine learning",
      "Medicine",
      "Pathology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Power (physics)",
      "Protocol (science)",
      "Quantum mechanics",
      "Robot",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Lin",
        "given_name": "Jiacheng"
      },
      {
        "surname": "Li",
        "given_name": "Yang"
      },
      {
        "surname": "Yang",
        "given_name": "Guanci"
      }
    ]
  },
  {
    "title": "Chapter 2 Detection of retinal abnormalities in fundus image using CNN deep learning networks",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00002-4",
    "abstract": "The World Health Organization (WHO) estimates that 285 million people are visually impaired worldwide, with 39 million blinds. Glaucoma, cataract, age-related macular degeneration, and diabetic retinopathy are among the leading retinal diseases. Thus there is an active effort to create and develop methods to automate the screening of retinal diseases. Many computer-aided diagnosis systems for ocular diseases have been developed and are widely used. Deep learning (DL) has shown its capabilities in the field of public health including ophthalmology. In retinal disease diagnosis the approach based upon DL and convolutional neural networks (CNNs) is used to locate, identify, and quantify pathological features. The performance of this approach keeps growing. This chapter addresses an overview of the used methods based upon DL and CNNs in detection of retinal abnormalities related to the most severe ocular diseases in retinal images, where network architectures, post/preprocessing, and evaluation experiments are detailed. We also present some related work concerning the DL-based smartphone applications for earlier screening and diagnosis of retinal diseases.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000024",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Diabetes mellitus",
      "Diabetic retinopathy",
      "Endocrinology",
      "Fundus (uterus)",
      "Glaucoma",
      "Macular degeneration",
      "Medicine",
      "Ophthalmology",
      "Optometry",
      "Preprocessor",
      "Retinal",
      "Retinal Disorder"
    ],
    "authors": [
      {
        "surname": "Akil",
        "given_name": "Mohamed"
      },
      {
        "surname": "Elloumi",
        "given_name": "Yaroub"
      },
      {
        "surname": "Kachouri",
        "given_name": "Rostom"
      }
    ]
  },
  {
    "title": "PM2.5 concentration modeling and prediction by using temperature-based deep belief network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.013",
    "abstract": "Air quality prediction is a global hot issue, and PM 2.5 is an important factor affecting air quality. Due to complicated causes of formation, PM 2.5 prediction is a thorny and challenging task. In this paper, a novel deep learning model named temperature-based deep belief networks (TDBN) is proposed to predict the daily concentrations of PM 2.5 for the next day. Firstly, the location of PM 2.5 concentration prediction is Chaoyang Park in Beijing of China from January 1, 2018 to October 27, 2018. The auxiliary variables are selected as input variables of TDBN by Partial Least Square (PLS), and the corresponding data is divided into three independent sections: training samples, validating samples and testing samples. Secondly, the TDBN is composed of temperature-based restricted Boltzmann machine (RBM), where temperature is considered as an effective physical parameter in energy balance of training RBM. The structural parameters of TDBN are determined by minimizing the error in the training process, including hidden layers number, hidden neurons and value of temperature. Finally, the testing samples are used to test the performance of the proposed TDBN on PM 2.5 prediction, and the other similar models are tested by the same testing samples for convenience of comparison with TDBN. The experimental results demonstrate that TDBN performs better than its peers in root mean square error (RMSE), mean absolute error (MAE) and coefficient of determination (R2).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303683",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Beijing",
      "China",
      "Computer science",
      "Deep belief network",
      "Electrical engineering",
      "Engineering",
      "Law",
      "Machine learning",
      "Mathematics",
      "Mean absolute error",
      "Mean squared error",
      "Operating system",
      "Pattern recognition (psychology)",
      "Political science",
      "Process (computing)",
      "Restricted Boltzmann machine",
      "Root mean square",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Xing",
        "given_name": "Haixia"
      },
      {
        "surname": "Wang",
        "given_name": "Gongming"
      },
      {
        "surname": "Liu",
        "given_name": "Caixia"
      },
      {
        "surname": "Suo",
        "given_name": "Minghe"
      }
    ]
  },
  {
    "title": "Structural plasticity on an accelerated analog neuromorphic hardware system",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.09.024",
    "abstract": "In computational neuroscience, as well as in machine learning, neuromorphic devices promise an accelerated and scalable alternative to neural network simulations. Their neural connectivity and synaptic capacity depend on their specific design choices, but is always intrinsically limited. Here, we present a strategy to achieve structural plasticity that optimizes resource allocation under these constraints by constantly rewiring the pre- and postsynaptic partners while keeping the neuronal fan-in constant and the connectome sparse. In particular, we implemented this algorithm on the analog neuromorphic system BrainScaleS-2. It was executed on a custom embedded digital processor located on chip, accompanying the mixed-signal substrate of spiking neurons and synapse circuits. We evaluated our implementation in a simple supervised learning scenario, showing its ability to optimize the network topology with respect to the nature of its training data, as well as its overall computational efficiency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303555",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer architecture",
      "Computer science",
      "Connectome",
      "Database",
      "Functional connectivity",
      "Neuromorphic engineering",
      "Neuroscience",
      "Scalability",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Billaudelle",
        "given_name": "Sebastian"
      },
      {
        "surname": "Cramer",
        "given_name": "Benjamin"
      },
      {
        "surname": "Petrovici",
        "given_name": "Mihai A."
      },
      {
        "surname": "Schreiber",
        "given_name": "Korbinian"
      },
      {
        "surname": "Kappel",
        "given_name": "David"
      },
      {
        "surname": "Schemmel",
        "given_name": "Johannes"
      },
      {
        "surname": "Meier",
        "given_name": "Karlheinz"
      }
    ]
  },
  {
    "title": "Multiple graphs learning with a new weighted tensor nuclear norm",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.010",
    "abstract": "As an effective convex relaxation of the rank minimization model, the tensor nuclear norm minimization based multi-view clustering methods have been attracting more and more interest in recent years. However, most existing clustering methods regularize each singular value equally, restricting their capability and flexibility in tackling many practical problems, where the singular values should be treated differently. To address this problem, we propose a novel weighted tensor nuclear norm minimization (WTNNM) based method for multi-view spectral clustering. Specifically, we firstly calculate a set of transition probability matrices from different views, and construct a 3-order tensor whose lateral slices are composed of probability matrices. Secondly, we learn a latent high-order transition probability matrix by using our proposed weighted tensor nuclear norm, which directly considers the prior knowledge of singular values. Finally, clustering is performed on the learned transition probability matrix, which well characterizes both the complementary information and high-order information embedded in multi-view data. An efficient optimization algorithm is designed to solve the optimal solution. Extensive experiments on five benchmarks demonstrate that our method outperforms the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303658",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Eigenvalues and eigenvectors",
      "Law",
      "Mathematical optimization",
      "Mathematics",
      "Matrix norm",
      "Norm (philosophy)",
      "Physics",
      "Political science",
      "Pure mathematics",
      "Quantum mechanics",
      "Singular value",
      "Tensor (intrinsic definition)"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Deyan"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Deng",
        "given_name": "Siyang"
      },
      {
        "surname": "Yang",
        "given_name": "Xiaojun"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Chapter 1 Computer-aided detection of abnormality in mammography using deep object detectors",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00001-2",
    "abstract": "Computer-aided detection of medical abnormalities is of great importance for both doctors and patients. In this chapter, we use mammogram screening as an example and introduce two state-of-the-art deep neural networks for the detection of mass tissues. More specifically, we compare two-stage and one-stage object detectors using deep convolutional neural networks. With the limited number of training data, we use transfer learning to fine-tune the general object detectors on a publicly available mammogram dataset. Experimental results indicate that the deep learning-based approaches have great potential in mammogram screening.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000012",
    "keywords": [
      "Abnormality",
      "Artificial intelligence",
      "Artificial neural network",
      "Breast cancer",
      "Cancer",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Detector",
      "Internal medicine",
      "Mammography",
      "Medicine",
      "Object (grammar)",
      "Object detection",
      "Pattern recognition (psychology)",
      "Psychiatry",
      "Telecommunications",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Xi",
        "given_name": "Pengcheng"
      },
      {
        "surname": "Rouhafzay",
        "given_name": "Ghazal"
      },
      {
        "surname": "Guan",
        "given_name": "Haitao"
      },
      {
        "surname": "Shu",
        "given_name": "Chang"
      },
      {
        "surname": "Borgeat",
        "given_name": "Louis"
      },
      {
        "surname": "Goubran",
        "given_name": "Rafik"
      }
    ]
  },
  {
    "title": "Chapter 11 Deep learning for computer-aided diagnosis in ophthalmology: a review",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00011-5",
    "abstract": "Artificial intelligence has once again come to the fore following the tremendous success of one class of mathematical models, the artificial neural network. The newly coined approach “deep learning” has dominated modern scientific discourse, infiltrating the fields of physics, chemistry, engineering, biology, and medicine. One of the most talked-about applications of deep learning is in computer-aided diagnosis (CADx), having a profound influence in the medical branches of radiology and ophthalmology. This chapter presents and discusses some of the recent developments in CADx with applications to ophthalmology, beginning with the motivation and historical approaches to retinal image analysis, providing insight into the limitations of previous methods. This leads to a discussion about modern solutions and state-of-the-art, highlighting various caveats that may curtail clinical adoption. The chapter goes on to discuss recent developments in the field of machine learning, offering speculation about future directions for CADx in ophthalmology, and how one might address the most debated critiques of contemporary deep learning solutions.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000115",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Field (mathematics)",
      "Mathematics",
      "Medicine",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Brown",
        "given_name": "James M."
      },
      {
        "surname": "Leontidis",
        "given_name": "Georgios"
      }
    ]
  },
  {
    "title": "PM2.5 concentration modeling and prediction by using temperature-based deep belief network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.013",
    "abstract": "Air quality prediction is a global hot issue, and PM 2.5 is an important factor affecting air quality. Due to complicated causes of formation, PM 2.5 prediction is a thorny and challenging task. In this paper, a novel deep learning model named temperature-based deep belief networks (TDBN) is proposed to predict the daily concentrations of PM 2.5 for the next day. Firstly, the location of PM 2.5 concentration prediction is Chaoyang Park in Beijing of China from January 1, 2018 to October 27, 2018. The auxiliary variables are selected as input variables of TDBN by Partial Least Square (PLS), and the corresponding data is divided into three independent sections: training samples, validating samples and testing samples. Secondly, the TDBN is composed of temperature-based restricted Boltzmann machine (RBM), where temperature is considered as an effective physical parameter in energy balance of training RBM. The structural parameters of TDBN are determined by minimizing the error in the training process, including hidden layers number, hidden neurons and value of temperature. Finally, the testing samples are used to test the performance of the proposed TDBN on PM 2.5 prediction, and the other similar models are tested by the same testing samples for convenience of comparison with TDBN. The experimental results demonstrate that TDBN performs better than its peers in root mean square error (RMSE), mean absolute error (MAE) and coefficient of determination (R2).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303683",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Beijing",
      "China",
      "Computer science",
      "Deep belief network",
      "Electrical engineering",
      "Engineering",
      "Law",
      "Machine learning",
      "Mathematics",
      "Mean absolute error",
      "Mean squared error",
      "Operating system",
      "Pattern recognition (psychology)",
      "Political science",
      "Process (computing)",
      "Restricted Boltzmann machine",
      "Root mean square",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Xing",
        "given_name": "Haixia"
      },
      {
        "surname": "Wang",
        "given_name": "Gongming"
      },
      {
        "surname": "Liu",
        "given_name": "Caixia"
      },
      {
        "surname": "Suo",
        "given_name": "Minghe"
      }
    ]
  },
  {
    "title": "Unsupervised feature learning for self-tuning neural networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.011",
    "abstract": "In recent years transfer learning has attracted much attention due to its ability to adapt a well-trained model from one domain to another. Fine-tuning is one of the most widely-used methods which exploit a small set of labeled data in the target domain for adapting the network. Including a few methods using the labeled data in the source domain, most transfer learning methods require labeled datasets, and it restricts the use of transfer learning to new domains. In this paper, we propose a fully unsupervised self-tuning algorithm for learning visual features in different domains. The proposed method updates a pre-trained model by minimizing the triplet loss function using only unlabeled data in the target domain. First, we propose the relevance measure for unlabeled data by the bagged clustering method. Then triplets of the anchor, positive, and negative data points are sampled based on the ranking violations of the relevance scores and the Euclidean distances in the embedded feature space. This fully unsupervised self-tuning algorithm improves the performance of the network significantly. We extensively evaluate the proposed algorithm using various metrics, including classification accuracy, feature analysis, and clustering quality, on five benchmark datasets in different domains. Besides, we demonstrate that applying the self-tuning method on the fine-tuned network help achieve better results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030366X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Domain (mathematical analysis)",
      "Feature (linguistics)",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Law",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Ranking (information retrieval)",
      "Relevance (law)",
      "Transfer of learning",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Ryu",
        "given_name": "Jongbin"
      },
      {
        "surname": "Yang",
        "given_name": "Ming-Hsuan"
      },
      {
        "surname": "Lim",
        "given_name": "Jongwoo"
      }
    ]
  },
  {
    "title": "Title page",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00015-2",
    "abstract": "Unknown",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000152",
    "keywords": [
      "Computer science"
    ],
    "authors": []
  },
  {
    "title": "Consensus guided incomplete multi-view spectral clustering",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.014",
    "abstract": "Incomplete multi-view clustering which aims to solve the difficult clustering challenge on incomplete multi-view data collected from diverse domains with missing views has drawn considerable attention in recent years. In this paper, we propose a novel method, called consensus guided incomplete multi-view spectral clustering (CGIMVSC), to address the incomplete clustering problem. Specifically, CGIMVSC seeks to explore the local information within every single-view and the semantic consistent information shared by all views in a unified framework simultaneously, where the local structure is adaptively obtained from the incomplete data rather than pre-constructed via a k-nearest neighbor approach in the existing methods. Considering the semantic consistency of multiple views, CGIMVSC introduces a co-regularization constraint to minimize the disagreement between the common representation and the individual representations with respect to different views, such that all views will obtain a consensus clustering result. Experimental comparisons with some state-of-the-art methods on seven datasets validate the effectiveness of the proposed method on incomplete multi-view clustering.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303774",
    "keywords": [
      "Artificial intelligence",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Complete information",
      "Computer science",
      "Consensus clustering",
      "Consistency (knowledge bases)",
      "Constrained clustering",
      "Constraint (computer-aided design)",
      "Data mining",
      "Fuzzy clustering",
      "Geometry",
      "Law",
      "Machine learning",
      "Mathematical economics",
      "Mathematics",
      "Political science",
      "Politics",
      "Regularization (linguistics)",
      "Representation (politics)",
      "Spectral clustering"
    ],
    "authors": [
      {
        "surname": "Wen",
        "given_name": "Jie"
      },
      {
        "surname": "Sun",
        "given_name": "Huijie"
      },
      {
        "surname": "Fei",
        "given_name": "Lunke"
      },
      {
        "surname": "Li",
        "given_name": "Jinxing"
      },
      {
        "surname": "Zhang",
        "given_name": "Zheng"
      },
      {
        "surname": "Zhang",
        "given_name": "Bob"
      }
    ]
  },
  {
    "title": "ClsGAN: Selective Attribute Editing Model based on Classification Adversarial Network",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.019",
    "abstract": "Attribution editing has achieved remarkable progress in recent years owing to the encoder–decoder structure and generative adversarial network (GAN). However, it remains challenging to generate high-quality images with accurate attribute transformation. Attacking these problems, the work proposes a novel selective attribute editing model based on classification adversarial network (referred to as ClsGAN) that shows good balance between attribute transfer accuracy and photo-realistic images. Considering that the editing images are prone to be affected by original attribute due to skip-connection in encoder–decoder structure, an upper convolution residual network (referred to as Tr-resnet) is presented to selectively extract information from the source image and target label. In addition, to further improve the transfer accuracy of generated images, an attribute adversarial classifier (referred to as Atta-cls) is introduced to guide the generator from the perspective of attribute through learning the defects of attribute transfer images. Experimental results on CelebA demonstrate that our ClsGAN performs favorably against state-of-the-art approaches in image quality and transfer accuracy. Moreover, ablation studies are also designed to verify the great performance of Tr-resnet and Atta-cls.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030383X",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Encoder",
      "Generative adversarial network",
      "Machine learning",
      "Operating system",
      "Pattern recognition (psychology)",
      "Residual",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Ying"
      },
      {
        "surname": "Fan",
        "given_name": "Heng"
      },
      {
        "surname": "Ni",
        "given_name": "Fuchuan"
      },
      {
        "surname": "Xiang",
        "given_name": "Jinhai"
      }
    ]
  },
  {
    "title": "Title page",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00015-2",
    "abstract": "Unknown",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000152",
    "keywords": [
      "Computer science"
    ],
    "authors": []
  },
  {
    "title": "Learning interaction dynamics with an interactive LSTM for conversational sentiment analysis",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.001",
    "abstract": "Conversational sentiment analysis is an emerging, yet challenging subtask of the sentiment analysis problem. It aims to discover the affective state and sentimental change in each person in a conversation based on their opinions. There exists a wealth of interaction information that affects speaker sentiment in conversations. However, existing sentiment analysis approaches are insufficient in dealing with this subtask due to two primary reasons: the lack of benchmark conversational sentiment datasets and the inability to model interactions between individuals. To address these issues, in this paper, we first present a new conversational dataset that we created and made publicly available, named ScenarioSA, to support the development of conversational sentiment analysis models. Then, we investigate how interaction dynamics are associated with conversations and study the multidimensional nature of interactions, which is understandability, credibility and influence. Finally, we propose an interactive long short-term memory (LSTM) network for conversational sentiment analysis to model interactions between speakers in a conversation by (1) adding a confidence gate before each LSTM hidden unit to estimate the credibility of the previous speakers and (2) combining the output gate with the learned influence scores to incorporate the influences of the previous speakers. Extensive experiments are conducted on ScenarioSA and IEMOCAP, and the results show that our model outperforms a wide range of strong baselines and achieves competitive results with the state-of-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303567",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Conversation",
      "Credibility",
      "Geodesy",
      "Geography",
      "Law",
      "Linguistics",
      "Machine learning",
      "Natural language processing",
      "Philosophy",
      "Political science",
      "Sentiment analysis"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yazhou"
      },
      {
        "surname": "Tiwari",
        "given_name": "Prayag"
      },
      {
        "surname": "Song",
        "given_name": "Dawei"
      },
      {
        "surname": "Mao",
        "given_name": "Xiaoliu"
      },
      {
        "surname": "Wang",
        "given_name": "Panpan"
      },
      {
        "surname": "Li",
        "given_name": "Xiang"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      }
    ]
  },
  {
    "title": "Chapter 5 Accurate identification of renal transplant rejection: convolutional neural networks and diffusion MRI",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00005-X",
    "abstract": "For the past several years the ability of diffusion-weighted magnetic resonance imaging (DW-MRI) to provide a noninvasive assessment of renal transplant function has been investigated. The goal of this chapter is to develop a computer-aided diagnostic (CAD) system coupled with a deep convolutional neural network (DCNN) to help determine the functionality of renal transplant using diffusion MRI. This diffusion-MRI marker is derived from a 3D+ b-value DW-MRI. Our work includes kidney segmentation using a 3D DW-MRI, through a level-set approach aided by kidney/background appearance features as well as by shape. It also includes a feature extraction step in which the apparent diffusion coefficients (ADCs) of each voxel of the segmented DW-MRI at individual b-values are estimated, and lastly classification of renal transplant status. In addition, the utility of the extracted 3D ADCs for training and testing of the 3D DCNN–based classifier determines the status of the renal transplant. The results of the developed CAD system reached 94% accuracy, sensitivity, and specificity. We used the leave-one-out scenario as a cross-validation technique to determine acute-rejection versus nonrejection renal transplants. The conclusions ensure that the developed CAD system is highly reliable to diagnose the status of the renal transplant in a noninvasive way.",
    "link": "https://www.sciencedirect.com/science/article/pii/B978012819740000005X",
    "keywords": [
      "Artificial intelligence",
      "CAD",
      "Computer science",
      "Computer-aided diagnosis",
      "Convolutional neural network",
      "Diffusion MRI",
      "Engineering",
      "Engineering drawing",
      "Internal medicine",
      "Kidney transplantation",
      "Magnetic resonance imaging",
      "Medicine",
      "Pattern recognition (psychology)",
      "Radiology",
      "Renal transplant",
      "Segmentation",
      "Transplantation",
      "Voxel"
    ],
    "authors": [
      {
        "surname": "Shehata",
        "given_name": "Mohamed"
      },
      {
        "surname": "Abdeltawab",
        "given_name": "Hisham"
      },
      {
        "surname": "Ghazal",
        "given_name": "Mohammed"
      },
      {
        "surname": "Khalil",
        "given_name": "Ashraf"
      },
      {
        "surname": "Shaker",
        "given_name": "Shams"
      },
      {
        "surname": "Shalaby",
        "given_name": "Ahmed"
      },
      {
        "surname": "Mahmoud",
        "given_name": "Ali"
      },
      {
        "surname": "Abou El-Ghar",
        "given_name": "Mohamed"
      },
      {
        "surname": "Dwyer",
        "given_name": "Amy C."
      },
      {
        "surname": "El-Melegy",
        "given_name": "Moumen"
      },
      {
        "surname": "Bakr",
        "given_name": "Ashraf M."
      },
      {
        "surname": "Suri",
        "given_name": "Jasjit S."
      },
      {
        "surname": "El-Baz",
        "given_name": "Ayman S."
      }
    ]
  },
  {
    "title": "Prespecified-time synchronization of switched coupled neural networks via smooth controllers",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.007",
    "abstract": "This paper considers the prespecified-time synchronization issue of switched coupled neural networks (SCNNs) under some smooth controllers. Different from the traditional finite-time synchronization (FTS), the synchronization time obtained in this paper is independent of control gains, initial values or network topology, which can be pre-set as to the task requirements. Moreover, unlike the existing nonsmooth or even discontinuous FTS control strategies, the new proposed control protocols are fully smooth, which abandon the common fractional power feedbacks or signum functions. Finally, two illustrative examples are provided to illustrate the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303622",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Mathematics",
      "Physics",
      "Power (physics)",
      "Programming language",
      "Quantum mechanics",
      "Set (abstract data type)",
      "Synchronization (alternating current)",
      "Systems engineering",
      "Task (project management)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Shao",
        "given_name": "Shao"
      },
      {
        "surname": "Liu",
        "given_name": "Xiaoyang"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "AutoTune: Automatically Tuning Convolutional Neural Networks for Improved Transfer Learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.009",
    "abstract": "Transfer learning enables solving a specific task having limited data by using the pre-trained deep networks trained on large-scale datasets. Typically, while transferring the learned knowledge from source task to the target task, the last few layers are fine-tuned (re-trained) over the target dataset. However, these layers are originally designed for the source task that might not be suitable for the target task. In this paper, we introduce a mechanism for automatically tuning the Convolutional Neural Networks (CNN) for improved transfer learning. The pre-trained CNN layers are tuned with the knowledge from target data using Bayesian Optimization. First, we train the final layer of the base CNN model by replacing the number of neurons in the softmax layer with the number of classes involved in the target task. Next, the CNN is tuned automatically by observing the classification performance on the validation data (greedy criteria). To evaluate the performance of the proposed method, experiments are conducted on three benchmark datasets, e.g., CalTech-101, CalTech-256, and Stanford Dogs. The classification results obtained through the proposed AutoTune method outperforms the standard baseline transfer learning methods over the three datasets by achieving 95.92%, 86.54%, and 84.67% accuracy over CalTech-101, CalTech-256, and Stanford Dogs, respectively. The experimental results obtained in this study depict that tuning of the pre-trained CNN layers with the knowledge from the target dataset confesses better transfer learning ability. The source codes are available at https://github.com/JekyllAndHyde8999/AutoTune_CNN_TransferLearning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303646",
    "keywords": [
      "Artificial intelligence",
      "Bayesian optimization",
      "Benchmark (surveying)",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Economics",
      "Geodesy",
      "Geography",
      "Layer (electronics)",
      "Machine learning",
      "Management",
      "Multi-task learning",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Softmax function",
      "Task (project management)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Basha",
        "given_name": "S.H. Shabbeer"
      },
      {
        "surname": "Vinakota",
        "given_name": "Sravan Kumar"
      },
      {
        "surname": "Pulabaigari",
        "given_name": "Viswanath"
      },
      {
        "surname": "Mukherjee",
        "given_name": "Snehasis"
      },
      {
        "surname": "Dubey",
        "given_name": "Shiv Ram"
      }
    ]
  },
  {
    "title": "Reverse graph self-attention for target-directed atomic importance estimation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.09.022",
    "abstract": "Estimating the importance of each atom in a molecule is one of the most appealing and challenging problems in chemistry, physics, and materials science. The most common way to estimate the atomic importance is to compute the electronic structure using density functional theory (DFT), and then to interpret it using domain knowledge of human experts. However, this conventional approach is impractical to the large molecular database because DFT calculation requires large computation, specifically, O ( n 4 ) time complexity w.r.t. the number of electronic basis functions. Furthermore, the calculation results should be manually interpreted by human experts to estimate the atomic importance in terms of the target molecular property. To tackle this problem, we first exploit the machine learning-based approach for the atomic importance estimation based on the reverse self-attention on graph neural networks and integrating it with graph-based molecular description. Our method provides an efficiently-automated and target-directed way to estimate the atomic importance without any domain knowledge of chemistry and physics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303531",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Atom (system on chip)",
      "Chemistry",
      "Combinatorics",
      "Computation",
      "Computational chemistry",
      "Computer science",
      "Computer security",
      "Density functional theory",
      "Domain (mathematical analysis)",
      "Domain knowledge",
      "Embedded system",
      "Epistemology",
      "Exploit",
      "Graph",
      "Graph theory",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Molecular graph",
      "Philosophy",
      "Property (philosophy)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Na",
        "given_name": "Gyoung S."
      },
      {
        "surname": "Kim",
        "given_name": "Hyun Woo"
      }
    ]
  },
  {
    "title": "Chapter 4 Detection, segmentation, and numbering of teeth in dental panoramic images with mask regions with convolutional neural network features",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00004-8",
    "abstract": "Dental image analysis is important for orthodontics, forensics, and dental treatments like cavity restoration or implants. In order to build a computer-aided diagnosis system for dental analysis, localization and numbering of teeth are crucial. In this study, we propose to use a popular deep learning technique, Mask regions with convolutional neural network features (RCNN), for simultaneous detection, segmentation, and numbering of teeth in panoramic X-ray images. Multiclass labeling is performed by Mask RCNN by giving a unique class name to each tooth type. After classification, postprocessing is performed for numbering teeth according to detected labels and dental chart. The proposed method is trained on 200 images and tested on 278 panoramic dental images. The average tooth detection accuracy is 0.98, and F1 score for segmentation is 0.93.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000048",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Dentistry",
      "Medicine",
      "Numbering",
      "Orthodontics",
      "Pattern recognition (psychology)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Oktay",
        "given_name": "Ayse Betul"
      },
      {
        "surname": "Gurses",
        "given_name": "Anıl"
      }
    ]
  },
  {
    "title": "DMMAN: A two-stage audio–visual fusion framework for sound separation and event localization",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.003",
    "abstract": "Videos are used widely as the media platforms for human beings to touch the physical change of the world. However, we always receive the mixed sound from the multiple sound objects, and cannot distinguish and localize the sounds as the separate entities in videos. In order to solve this problem, a model named the Deep Multi-Modal Attention Network (DMMAN), is established to model the unconstrained video datasets for further finishing the sound source separation and event localization tasks in this paper. Based on the multi-modal separator and multi-modal matching classifier module, our model focuses on the sound separation and modal synchronization problems using two stage fusion of the sound and visual features. To link the multi-modal separator and multi-modal matching classifier modules, the regression and classification losses are employed to build the loss function of the DMMAN. The estimated spectrum masks and attention synchronization scores calculated by the DMMAN can be easily generalized to the sound source and event localization tasks. The quantitative experimental results show the DMMAN not only separates the high quality of the sound sources evaluated by Signal-to-Distortion Ratio and Signal-to-Interference Ratio metrics, but also is suitable for the mixed sound scenes that are never heard jointly. Meanwhile, DMMAN achieves better classification accuracy than other contrast baselines for the event localization tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303580",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Classifier (UML)",
      "Computer science",
      "Modal",
      "Pattern recognition (psychology)",
      "Polymer chemistry",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Hu",
        "given_name": "Ruihan"
      },
      {
        "surname": "Zhou",
        "given_name": "Songbing"
      },
      {
        "surname": "Tang",
        "given_name": "Zhi Ri"
      },
      {
        "surname": "Chang",
        "given_name": "Sheng"
      },
      {
        "surname": "Huang",
        "given_name": "Qijun"
      },
      {
        "surname": "Liu",
        "given_name": "Yisen"
      },
      {
        "surname": "Han",
        "given_name": "Wei"
      },
      {
        "surname": "Wu",
        "given_name": "Edmond Q."
      }
    ]
  },
  {
    "title": "An EEG channel selection method for motor imagery based brain–computer interface and neurofeedback using Granger causality",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.11.002",
    "abstract": "Motor imagery (MI) brain–computer interface (BCI) and neurofeedback (NF) with electroencephalogram (EEG) signals are commonly used for motor function improvement in healthy subjects and to restore neurological functions in stroke patients. Generally, in order to decrease noisy and redundant information in unrelated EEG channels, channel selection methods are used which provide feasible BCI and NF implementations with better performances. Our assumption is that there are causal interactions between the channels of EEG signal in MI tasks that are repeated in different trials of a BCI and NF experiment. Therefore, a novel method for EEG channel selection is proposed which is based on Granger causality (GC) analysis. Additionally, the machine-learning approach is used to cluster independent component analysis (ICA) components of the EEG signal into artifact and normal EEG clusters. After channel selection, using the common spatial pattern (CSP) and regularized CSP (RCSP), features are extracted and with the k-nearest neighbor (k-NN), support vector machine (SVM) and linear discriminant analysis (LDA) classifiers, MI tasks are classified into left and right hand MI. The goal of this study is to achieve a method resulting in lower EEG channels with higher classification performance in MI-based BCI and NF by causal constraint. The proposed method based on GC, with only eight selected channels, results in 93.03% accuracy, 92.93% sensitivity, and 93.12% specificity, with RCSP feature extractor and best classifier for each subject, after being applied on Physionet MI dataset, which is increased by 3.95%, 3.73%, and 4.13%, in comparison with correlation-based channel selection method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303853",
    "keywords": [
      "Artificial intelligence",
      "Brain–computer interface",
      "Computer science",
      "Electroencephalography",
      "Feature selection",
      "Granger causality",
      "Independent component analysis",
      "Linear discriminant analysis",
      "Machine learning",
      "Motor imagery",
      "Neurofeedback",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Varsehi",
        "given_name": "Hesam"
      },
      {
        "surname": "Firoozabadi",
        "given_name": "S. Mohammad P."
      }
    ]
  },
  {
    "title": "Chapter 13 Generative adversarial networks in medical imaging",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00013-9",
    "abstract": "Generative adversarial networks (GANs) are a recently introduced class of state-of-the-art generative models. GANs are characterized by a unique training process that, although unstable, enables them to accurately learn highly complex distributions. While much of the recent attention that GANs have received in the machine learning and computer vision communities is due to their ability to synthesize highly realistic images, this is but one of many potential uses for these models. In this chapter, we survey several recent applications of GANs in medical imaging, highlighting significant developments, and illustrating avenues for future work in this nascent area of research.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000139",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Data science",
      "Deep learning",
      "Generative adversarial network",
      "Generative grammar",
      "Machine learning",
      "Operating system",
      "Process (computing)",
      "State (computer science)"
    ],
    "authors": [
      {
        "surname": "Johnson",
        "given_name": "Jeremiah W."
      }
    ]
  },
  {
    "title": "Chapter 8 A computer-aided diagnosis system for breast cancer molecular subtype prediction in mammographic images",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00008-5",
    "abstract": "Several computer-aided diagnosis (CAD) systems have been developed to assist the radiologists for early breast cancer detection and treatment. These CAD systems provide statistical features of a mammogram using computer vision and image processing techniques for characterizing the morphological structure and evolution of the tumors. In this chapter a CAD system is introduced that includes three stages: tumor detection, segmentation, and tumor-shape and molecular subtypes classification based on deep learning models. The first stage is to detect the region of interest (ROI) that contains a tumor from mammographic images by using a modified Faster R-CNN (convolutional neural network) detector, which incorporates an Inception-ResNet-v2 feature extractor with a squeeze and excitation network. While the second stage employs a conditional generative adversarial network (cGAN) to segment the breast tumor from the detected ROI. For shape classification, a CNN is then developed in the third stage of the CAD system to classify the binary masks of the cGAN network into four tumor-shape classes: irregular, lobular, oval, and round. Finally, this chapter presents a study of the correlation between the tumor shapes and molecular subtypes of breast cancer. The findings of this chapter indicate that the tumor shape can be analyzed for understanding the molecular subtype of the tumor.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000085",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Breast cancer",
      "CAD",
      "Cancer",
      "Computer science",
      "Computer vision",
      "Computer-aided diagnosis",
      "Convolutional neural network",
      "Deep learning",
      "Engineering",
      "Engineering drawing",
      "Feature (linguistics)",
      "Internal medicine",
      "Linguistics",
      "Mammography",
      "Medicine",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Segmentation",
      "Stage (stratigraphy)"
    ],
    "authors": [
      {
        "surname": "Singh",
        "given_name": "Vivek Kumar"
      },
      {
        "surname": "Rashwan",
        "given_name": "Hatem A."
      },
      {
        "surname": "Abdel-Nasser",
        "given_name": "Mohamed"
      },
      {
        "surname": "Akram",
        "given_name": "Farhan"
      },
      {
        "surname": "Haffar",
        "given_name": "Rami"
      },
      {
        "surname": "Pandey",
        "given_name": "Nidhi"
      },
      {
        "surname": "Arenas",
        "given_name": "Meritxell"
      },
      {
        "surname": "Romani",
        "given_name": "Santiago"
      },
      {
        "surname": "Puig",
        "given_name": "Domenec"
      }
    ]
  },
  {
    "title": "Reverse graph self-attention for target-directed atomic importance estimation",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.09.022",
    "abstract": "Estimating the importance of each atom in a molecule is one of the most appealing and challenging problems in chemistry, physics, and materials science. The most common way to estimate the atomic importance is to compute the electronic structure using density functional theory (DFT), and then to interpret it using domain knowledge of human experts. However, this conventional approach is impractical to the large molecular database because DFT calculation requires large computation, specifically, O ( n 4 ) time complexity w.r.t. the number of electronic basis functions. Furthermore, the calculation results should be manually interpreted by human experts to estimate the atomic importance in terms of the target molecular property. To tackle this problem, we first exploit the machine learning-based approach for the atomic importance estimation based on the reverse self-attention on graph neural networks and integrating it with graph-based molecular description. Our method provides an efficiently-automated and target-directed way to estimate the atomic importance without any domain knowledge of chemistry and physics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303531",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Atom (system on chip)",
      "Chemistry",
      "Combinatorics",
      "Computation",
      "Computational chemistry",
      "Computer science",
      "Computer security",
      "Density functional theory",
      "Domain (mathematical analysis)",
      "Domain knowledge",
      "Embedded system",
      "Epistemology",
      "Exploit",
      "Graph",
      "Graph theory",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Molecular graph",
      "Philosophy",
      "Property (philosophy)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Na",
        "given_name": "Gyoung S."
      },
      {
        "surname": "Kim",
        "given_name": "Hyun Woo"
      }
    ]
  },
  {
    "title": "Chapter 4 Detection, segmentation, and numbering of teeth in dental panoramic images with mask regions with convolutional neural network features",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00004-8",
    "abstract": "Dental image analysis is important for orthodontics, forensics, and dental treatments like cavity restoration or implants. In order to build a computer-aided diagnosis system for dental analysis, localization and numbering of teeth are crucial. In this study, we propose to use a popular deep learning technique, Mask regions with convolutional neural network features (RCNN), for simultaneous detection, segmentation, and numbering of teeth in panoramic X-ray images. Multiclass labeling is performed by Mask RCNN by giving a unique class name to each tooth type. After classification, postprocessing is performed for numbering teeth according to detected labels and dental chart. The proposed method is trained on 200 images and tested on 278 panoramic dental images. The average tooth detection accuracy is 0.98, and F1 score for segmentation is 0.93.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000048",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Dentistry",
      "Medicine",
      "Numbering",
      "Orthodontics",
      "Pattern recognition (psychology)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Oktay",
        "given_name": "Ayse Betul"
      },
      {
        "surname": "Gurses",
        "given_name": "Anıl"
      }
    ]
  },
  {
    "title": "Model-free motion control of continuum robots based on a zeroing neurodynamic approach",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.005",
    "abstract": "As a result of inherent flexibility and structural compliance, continuum robots have great potential in practical applications and are attracting more and more attentions. However, these characteristics make it difficult to acquire the accurate kinematics of continuum robots due to uncertainties, deformation and external loads. This paper introduces a method based on a zeroing neurodynamic approach to solve the trajectory tracking problem of continuum robots. The proposed method can achieve the control of a bellows-driven continuum robot just relying on the actuator input and sensory output information, without knowing any information of the kinematic model. This approach reduces the computational load and can guarantee the real time control. The convergence, stability, and robustness of the proposed approach are proved by theoretical analyses. The effectiveness of the proposed method is verified by simulation studies including tracking performance, comparisons with other three methods, and robustness tests.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303609",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Gene",
      "Kinematics",
      "Physics",
      "Robot",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Tan",
        "given_name": "Ning"
      },
      {
        "surname": "Yu",
        "given_name": "Peng"
      },
      {
        "surname": "Zhang",
        "given_name": "Xinyu"
      },
      {
        "surname": "Wang",
        "given_name": "Tao"
      }
    ]
  },
  {
    "title": "Advanced deep learning methods for biomedical information analysis: An editorial",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.006",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303610",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Feature (linguistics)",
      "Linguistics",
      "Machine learning",
      "Medicine",
      "Philosophy",
      "Reinforcement learning",
      "Supervised learning",
      "Surgery",
      "Vital signs"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yu-Dong"
      },
      {
        "surname": "Morabito",
        "given_name": "Francesco Carlo"
      },
      {
        "surname": "Shen",
        "given_name": "Dinggang"
      },
      {
        "surname": "Muhammad",
        "given_name": "Khan"
      }
    ]
  },
  {
    "title": "Advanced deep learning methods for biomedical information analysis: An editorial",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.006",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303610",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Feature (linguistics)",
      "Linguistics",
      "Machine learning",
      "Medicine",
      "Philosophy",
      "Reinforcement learning",
      "Supervised learning",
      "Surgery",
      "Vital signs"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yu-Dong"
      },
      {
        "surname": "Morabito",
        "given_name": "Francesco Carlo"
      },
      {
        "surname": "Shen",
        "given_name": "Dinggang"
      },
      {
        "surname": "Muhammad",
        "given_name": "Khan"
      }
    ]
  },
  {
    "title": "Chapter 9 Computer-aided diagnosis of renal masses",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00009-7",
    "abstract": "Accurate imaging characterization of renal masses is important because not all incidentally discovered renal masses are malignant. Automated localization of kidneys and renal masses are essential steps toward the potential classification of benign versus malignant renal masses. A fully automated algorithm for this detection and localization of renal masses may also eliminate the observer variability in the clinical workflow. In recent years, researchers proposed many techniques to characterize the kidneys and renal masses in medical images from distinct imaging acquisition systems, namely ultrasound, magnetic resonance, and computed tomography. Recently, deep learning (DL)-based method was employed widely to perform these tasks. In this chapter, we review the DL-based method developed for automated delineation of kidneys and localization and evaluation of renal masses from medial images. Moreover, a brief introduction of convolutional neural network, as the main class of deep neural networks, which is most commonly applied for medical image analysis, is provided.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000097",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Database",
      "Deep learning",
      "Magnetic resonance imaging",
      "Medical imaging",
      "Medicine",
      "Radiology",
      "Workflow"
    ],
    "authors": [
      {
        "surname": "Zabihollahy",
        "given_name": "Fatemeh"
      },
      {
        "surname": "Ukwatta",
        "given_name": "Eranga"
      },
      {
        "surname": "Schieda",
        "given_name": "Nicola"
      }
    ]
  },
  {
    "title": "Model-free motion control of continuum robots based on a zeroing neurodynamic approach",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.005",
    "abstract": "As a result of inherent flexibility and structural compliance, continuum robots have great potential in practical applications and are attracting more and more attentions. However, these characteristics make it difficult to acquire the accurate kinematics of continuum robots due to uncertainties, deformation and external loads. This paper introduces a method based on a zeroing neurodynamic approach to solve the trajectory tracking problem of continuum robots. The proposed method can achieve the control of a bellows-driven continuum robot just relying on the actuator input and sensory output information, without knowing any information of the kinematic model. This approach reduces the computational load and can guarantee the real time control. The convergence, stability, and robustness of the proposed approach are proved by theoretical analyses. The effectiveness of the proposed method is verified by simulation studies including tracking performance, comparisons with other three methods, and robustness tests.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303609",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Gene",
      "Kinematics",
      "Physics",
      "Robot",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Tan",
        "given_name": "Ning"
      },
      {
        "surname": "Yu",
        "given_name": "Peng"
      },
      {
        "surname": "Zhang",
        "given_name": "Xinyu"
      },
      {
        "surname": "Wang",
        "given_name": "Tao"
      }
    ]
  },
  {
    "title": "CEGAN: Classification Enhancement Generative Adversarial Networks for unraveling data imbalance problems",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.004",
    "abstract": "The data imbalance problem in classification is a frequent but challenging task. In real-world datasets, numerous class distributions are imbalanced and the classification result under such condition reveals extreme bias in the majority data class. Recently, the potential of GAN as a data augmentation method on minority data has been studied. In this paper, we propose a classification enhancement generative adversarial networks (CEGAN) to enhance the quality of generated synthetic minority data and more importantly, to improve the prediction accuracy in data imbalanced condition. In addition, we propose an ambiguity reduction method using the generated synthetic minority data for the case of multiple similar classes that are degenerating the classification accuracy. The proposed method is demonstrated with five benchmark datasets. The results indicate that approximating the real data distribution using CEGAN improves the classification performance significantly in data imbalanced conditions compared with various standard data augmentation methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303592",
    "keywords": [
      "Adversarial system",
      "Ambiguity",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Class (philosophy)",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Economics",
      "Generative adversarial network",
      "Generative grammar",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Management",
      "Pattern recognition (psychology)",
      "Programming language",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Suh",
        "given_name": "Sungho"
      },
      {
        "surname": "Lee",
        "given_name": "Haebom"
      },
      {
        "surname": "Lukowicz",
        "given_name": "Paul"
      },
      {
        "surname": "Lee",
        "given_name": "Yong Oh"
      }
    ]
  },
  {
    "title": "Chapter 6 Applications of the ESPNet architecture in medical imaging",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00006-1",
    "abstract": "Medical imaging is a fundamental part of clinical care that creates informative, noninvasive, and visual representations of the structure and function of the interior of the body. With advancements in technology and the availability of massive amounts of imaging data, data-driven methods, such as machine learning and data mining, have become popular in medical imaging analysis. In particular, deep learning-based methods, such as convolutional neural networks, now have the requisite volume of data and computational power to be considered practical clinical tools. We describe the architecture of the ESPNet network and provide experimental results for the task of semantic segmentation on two different types of medical images: (1) tissue-level segmentation of breast biopsy whole slide images and (2) 3D tumor segmentation in brain magnetic resonance images. Our results show that the ESPNet architecture is efficient and learns meaningful representations for different types of medical images, which allows ESPNet to perform well on these images.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000061",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Engineering",
      "Image segmentation",
      "Machine learning",
      "Medical imaging",
      "Pattern recognition (psychology)",
      "Segmentation",
      "Systems engineering",
      "Task (project management)",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Mehta",
        "given_name": "Sachin"
      },
      {
        "surname": "Nuechterlein",
        "given_name": "Nicholas"
      },
      {
        "surname": "Mercan",
        "given_name": "Ezgi"
      },
      {
        "surname": "Li",
        "given_name": "Beibin"
      },
      {
        "surname": "Nofallah",
        "given_name": "Shima"
      },
      {
        "surname": "Wu",
        "given_name": "Wenjun"
      },
      {
        "surname": "Lu",
        "given_name": "Ximing"
      },
      {
        "surname": "Caspi",
        "given_name": "Anat"
      },
      {
        "surname": "Rastegari",
        "given_name": "Mohammad"
      },
      {
        "surname": "Elmore",
        "given_name": "Joann"
      },
      {
        "surname": "Hajishirzi",
        "given_name": "Hannaneh"
      },
      {
        "surname": "Shapiro",
        "given_name": "Linda"
      }
    ]
  },
  {
    "title": "Adversarial symmetric GANs: Bridging adversarial samples and adversarial networks",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.016",
    "abstract": "Generative adversarial networks have achieved remarkable performance on various tasks but suffer from training instability. Despite many training strategies proposed to improve training stability, this issue remains as a challenge. In this paper, we investigate the training instability from the perspective of adversarial samples and reveal that adversarial training on fake samples is implemented in vanilla GANs, but adversarial training on real samples has long been overlooked. Consequently, the discriminator is extremely vulnerable to adversarial perturbation and the gradient given by the discriminator contains non-informative adversarial noises, which hinders the generator from catching the pattern of real samples. Here, we develop adversarial symmetric GANs (AS-GANs) that incorporate adversarial training of the discriminator on real samples into vanilla GANs, making adversarial training symmetrical. The discriminator is therefore more robust and provides more informative gradient with less adversarial noise, thereby stabilizing training and accelerating convergence. The effectiveness of the AS-GANs is verified on image generation on CIFAR-10, CIFAR-100, CelebA, and LSUN with varied network architectures. Not only the training is more stabilized, but the FID scores of generated samples are consistently improved by a large margin compared to the baseline. Theoretical analysis is also conducted to explain why AS-GAN can improve training. The bridging of adversarial samples and adversarial networks provides a new approach to further develop adversarial networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303798",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Bridging (networking)",
      "Computer science",
      "Computer security",
      "Detector",
      "Discriminator",
      "Generator (circuit theory)",
      "Machine learning",
      "Margin (machine learning)",
      "Pattern recognition (psychology)",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Faqiang"
      },
      {
        "surname": "Xu",
        "given_name": "Mingkun"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      },
      {
        "surname": "Pei",
        "given_name": "Jing"
      },
      {
        "surname": "Shi",
        "given_name": "Luping"
      },
      {
        "surname": "Zhao",
        "given_name": "Rong"
      }
    ]
  },
  {
    "title": "Improved approach to the problem of the global Mittag-Leffler synchronization for fractional-order multidimension-valued BAM neural networks based on new inequalities",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.008",
    "abstract": "This paper studies the problem of the global Mittag-Leffler synchronization for fractional-order multidimension-valued BAM neural networks (FOMVBAMNNs) with general activation functions (AFs). First, the unified model is established for the researched systems of FOMVBAMNNs which can be turned into the corresponding multidimension-valued systems as long as the state variables, the connection weights and the AFs of the neural networks are valued to be real, complex, or quaternion. Then, without any decomposition, the criteria in unified form are derived by constructing the new Lyapunov–Krasovskii functionals (LKFs) in vector form, combining two new inequalities and considering the easy controllers. It is worth mentioning that the obtained criteria have many advantages in higher flexibility, more diversity, smaller computation, and lower conservatism. Finally, a simulation example is provided to illustrate the availability and improvements of the acquired results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303634",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Flexibility (engineering)",
      "Mathematical optimization",
      "Mathematics",
      "Statistics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Jianying"
      },
      {
        "surname": "Zhong",
        "given_name": "Shouming"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Chapter 10 Early identification of acute rejection for renal allografts: a machine learning approach",
    "journal": "State of the Art in Neural Networks and their Applications",
    "year": "2021",
    "doi": "10.1016/B978-0-12-819740-0.00010-3",
    "abstract": "The goal of this chapter is to explore the developed computer-aided diagnostic (CAD) system that helps to determine the functionality of renal transplant using diffusion-weighted magnetic resonance imaging (DW-MRI). This study is based on the integration of DW-MRI-based biomarkers with clinical-based biomarkers. The data are acquired at different durations and strengths of the magnetic field (b-values). The DW-MRI data were collected from Egypt and the United States, using different scanners such as GE and Philips. Using a level-set approach, the kidney is first segmented, then estimates the apparent diffusion coefficients (ADCs). Then serum creatinine and creatinine clearance (the clinical biomarkers that we used) are combined with the ADCs, creating new image markers known as integrated ADCs (IADCs). Finally, the IADCs make cumulative distribution functions at the different b-values. Lastly, any classifier may be used to distinguish between nonrejection and acute rejection renal transplant status. More importantly, our proposed CAD system exhibits 93% accuracy, 93% sensitivity, and 92% specificity in distinguishing between the renal transplant status. This concluded that the developed CAD system is completely independent of classifiers, geographical areas, and scanner type. These results support that the developed CAD system might be noninvasively able to assess the status of renal allograft dysfunction.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128197400000103",
    "keywords": [
      "Artificial intelligence",
      "CAD",
      "Computer science",
      "Computer-aided diagnosis",
      "Creatinine",
      "Engineering",
      "Engineering drawing",
      "Internal medicine",
      "Kidney",
      "Magnetic resonance imaging",
      "Medicine",
      "Radiology",
      "Renal function",
      "Renal transplant"
    ],
    "authors": [
      {
        "surname": "Shehata",
        "given_name": "Mohamed"
      },
      {
        "surname": "Taher",
        "given_name": "Fatma"
      },
      {
        "surname": "Ghazal",
        "given_name": "Mohammed"
      },
      {
        "surname": "Shaker",
        "given_name": "Shams"
      },
      {
        "surname": "Abou El-Ghar",
        "given_name": "Mohamed"
      },
      {
        "surname": "Badawy",
        "given_name": "Mohamed"
      },
      {
        "surname": "Shalaby",
        "given_name": "Ahmed"
      },
      {
        "surname": "El-Baz",
        "given_name": "Maryam"
      },
      {
        "surname": "Mahmoud",
        "given_name": "Ali"
      },
      {
        "surname": "Dwyer",
        "given_name": "Amy C."
      },
      {
        "surname": "Bakr",
        "given_name": "Ashraf M."
      },
      {
        "surname": "Suri",
        "given_name": "Jasjit S."
      },
      {
        "surname": "El-Baz",
        "given_name": "Ayman S."
      }
    ]
  },
  {
    "title": "FMixCutMatch for semi-supervised deep learning",
    "journal": "Neural Networks",
    "year": "2021",
    "doi": "10.1016/j.neunet.2020.10.018",
    "abstract": "Mixed sample augmentation (MSA) has witnessed great success in the research area of semi-supervised learning (SSL) and is performed by mixing two training samples as an augmentation strategy to effectively smooth the training space. Following the insights on the efficacy of cut-mix in particular, we propose FMixCut, an MSA that combines Fourier space-based data mixing (FMix) and the proposed Fourier space-based data cutting (FCut) for labeled and unlabeled data augmentation. Specifically, for the SSL task, our approach first generates soft pseudo-labels using the model’s previous predictions. The model is then trained to penalize the outputs of the FMix-generated samples so that they are consistent with their mixed soft pseudo-labels. In addition, we propose to use FCut, a new Cutout-based data augmentation strategy that adopts the two masked sample pairs from FMix for weighted cross-entropy minimization. Furthermore, by implementing two regularization techniques, namely, batch label distribution entropy maximization and sample confidence entropy minimization, we further boost the training efficiency. Finally, we introduce a dynamic labeled–unlabeled data mixing (DDM) strategy to further accelerate the convergence of the model. Combining the above process, we finally call our SSL approach as ”FMixCutMatch”, in short FMCmatch. As a result, the proposed FMCmatch achieves state-of-the-art performance on CIFAR-10/100, SVHN and Mini-Imagenet across a variety of SSL conditions with the CNN-13, WRN-28-2 and ResNet-18 networks. In particular, our method achieves a 4.54% test error on CIFAR-10 with 4K labels under the CNN-13 and a 41.25% Top-1 test error on Mini-Imagenet with 10K labels under the ResNet-18. Our codes for reproducing these results are publicly available at https://github.com/biuyq/FMixCutMatch.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303816",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Cross entropy",
      "Entropy (arrow of time)",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Maximization",
      "Minification",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Regularization (linguistics)"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Xiang"
      },
      {
        "surname": "Wei",
        "given_name": "Xiaotao"
      },
      {
        "surname": "Kong",
        "given_name": "Xiangyuan"
      },
      {
        "surname": "Lu",
        "given_name": "Siyang"
      },
      {
        "surname": "Xing",
        "given_name": "Weiwei"
      },
      {
        "surname": "Lu",
        "given_name": "Wei"
      }
    ]
  }
]