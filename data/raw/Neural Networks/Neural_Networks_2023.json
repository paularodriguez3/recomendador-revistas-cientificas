[
  {
    "title": "Unsupervised Domain Adaptation with Asymmetrical Margin Disparity loss and Outlier Sample Extraction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.045",
    "abstract": "Unsupervised domain adaptation (UDA) trains models using labeled data from a specific source domain and then transferring the knowledge to certain target domains that have few or no labels. Many prior measurement-based works achieve lots of progress, but their feature distinguishing abilities to classify target samples with similar features are not enough; they do not adequately consider the confusing samples in the target domain that are similar to the source domain; and they don't consider negative transfer of the outlier sample in source domain. We address these issues in our work and propose an UDA method with asymmetrical margin disparity loss and outlier sample extraction, called AMD-Net with OSE. We propose an Asymmetrical Margin Disparity Discrepancy (AMD) method and a training strategy based on sample selection mechanism to make the network have better feature extraction ability and the network gets rid of local optimal. Firstly, in the AMD method, we design a multi-label entropy metric to evaluate the marginal disparity loss of the confusing samples in the target domain. This asymmetric marginal disparity loss designment uses the different entropy measurement algorithms of the two domains to excavate the differences of the two domains as much as possible, so as to find the common features of the two domains. Secondly, A sample selection mechanism is designed to evaluate which part of the sample in target domain is confusable. We define the certainty of the sample in the target domain, adopt a progressive learning scheme, and adopt one-hot marginal disparity loss for most of the samples in the target domain with low uncertainty and easy to distinguish. The multi-label marginal calculation method is used only for the uncertainty samples in the target domain whose certainty is less than the threshold value, so that the network can get rid of the local optimal as much as possible. At last, we further propose an outlier sample extraction algorithm (OSE) based on weighted cosine similarity distance for source domain to reduce the negative migration effect caused by outlier samples in the source domain. Extensive experiments on four datasets Office-31, Office-Home, VisDA-2017 and DomainNet demonstrate that our method works well in various UDA settings and outperforms the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005415",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Data mining",
      "Entropy (arrow of time)",
      "Feature extraction",
      "Machine learning",
      "Margin (machine learning)",
      "Outlier",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Sample (material)",
      "Sample entropy",
      "Spurious relationship"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Chunmei"
      },
      {
        "surname": "Fan",
        "given_name": "Xianjun"
      },
      {
        "surname": "Zhou",
        "given_name": "Kang"
      },
      {
        "surname": "Ye",
        "given_name": "Zhengchun"
      }
    ]
  },
  {
    "title": "Graph structure reforming framework enhanced by commute time distance for graph classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.044",
    "abstract": "As a graph data mining task, graph classification has high academic value and wide practical application. Among them, the graph neural network-based method is one of the mainstream methods. Most graph neural networks (GNNs) follow the message passing paradigm and can be called Message Passing Neural Networks (MPNNs), achieving good results in structural data-related tasks. However, it has also been reported that these methods suffer from over-squashing and limited expressive power. In recent years, many works have proposed different solutions to these problems separately, but none has yet considered these shortcomings in a comprehensive way. After considering these several aspects comprehensively, we identify two specific defects: information loss caused by local information aggregation, and an inability to capture higher-order structures. To solve these issues, we propose a plug-and-play framework based on Commute Time Distance (CTD), in which information is propagated in commute time distance neighborhoods. By considering both local and global graph connections, the commute time distance between two nodes is evaluated with reference to the path length and the number of paths in the whole graph. Moreover, the proposed framework CTD-MPNNs ( Commute Time Distance-based Message Passing Neural Networks) can capture higher-order structural information by utilizing commute paths to enhance the expressive power of GNNs. Thus, our proposed framework can propagate and aggregate messages from defined important neighbors and model more powerful GNNs. We conduct extensive experiments using various real-world graph classification benchmarks. The experimental performance demonstrates the effectiveness of our framework. Codes are released on https://github.com/Haldate-Yu/CTD-MPNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005403",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Distributed computing",
      "Expressive power",
      "Graph",
      "Machine learning",
      "Message passing",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Wenhang"
      },
      {
        "surname": "Ma",
        "given_name": "Xueqi"
      },
      {
        "surname": "Bailey",
        "given_name": "James"
      },
      {
        "surname": "Zhan",
        "given_name": "Yibing"
      },
      {
        "surname": "Wu",
        "given_name": "Jia"
      },
      {
        "surname": "Du",
        "given_name": "Bo"
      },
      {
        "surname": "Hu",
        "given_name": "Wenbin"
      }
    ]
  },
  {
    "title": "Zero time waste in pre-trained early exit neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.10.003",
    "abstract": "The problem of reducing processing time of large deep learning models is a fundamental challenge in many real-world applications. Early exit methods strive towards this goal by attaching additional Internal Classifiers ( IC s) to intermediate layers of a neural network. IC s can quickly return predictions for easy examples and, as a result, reduce the average inference time of the whole model. However, if a particular IC does not decide to return an answer early, its predictions are discarded, with its computations effectively being wasted. To solve this issue, we introduce Zero Time Waste (ZTW), a novel approach in which each IC reuses predictions returned by its predecessors by (1) adding direct connections between IC s and (2) combining previous outputs in an ensemble-like manner. We conduct extensive experiments across various multiple modes, datasets, and architectures to demonstrate that ZTW achieves a significantly better accuracy vs. inference time trade-off than other early exit methods. On the ImageNet dataset, it obtains superior results over the best baseline method in 11 out of 16 cases, reaching up to 5 percentage points of improvement on low computational budgets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005555",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Baseline (sea)",
      "Computation",
      "Computer science",
      "Deep neural networks",
      "Geology",
      "Inference",
      "Linguistics",
      "Machine learning",
      "Oceanography",
      "Philosophy",
      "Zero (linguistics)"
    ],
    "authors": [
      {
        "surname": "Wójcik",
        "given_name": "Bartosz"
      },
      {
        "surname": "Przewiȩźlikowski",
        "given_name": "Marcin"
      },
      {
        "surname": "Szatkowski",
        "given_name": "Filip"
      },
      {
        "surname": "Wołczyk",
        "given_name": "Maciej"
      },
      {
        "surname": "Bałazy",
        "given_name": "Klaudia"
      },
      {
        "surname": "Krzepkowski",
        "given_name": "Bartłomiej"
      },
      {
        "surname": "Podolak",
        "given_name": "Igor"
      },
      {
        "surname": "Tabor",
        "given_name": "Jacek"
      },
      {
        "surname": "Śmieja",
        "given_name": "Marek"
      },
      {
        "surname": "Trzciński",
        "given_name": "Tomasz"
      }
    ]
  },
  {
    "title": "A multi-scale self-supervised hypergraph contrastive learning framework for video question answering",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.057",
    "abstract": "Video question answering (VideoQA) is a challenging video understanding task that requires a comprehensive understanding of multimodal information and accurate answers to related questions. Most existing VideoQA models use Graph Neural Networks (GNN) to capture temporal–spatial interactions between objects. Despite achieving certain success, we argue that current schemes have two limitations: (i) existing graph-based methods require stacking multi-layers of GNN to capture high-order relations between objects, which inevitably introduces irrelevant noise; (ii) neglecting the unique self-supervised signals in the high-order relational structures among multiple objects that can facilitate more accurate QA. To this end, we propose a novel Multi-scale Self-supervised Hypergraph Contrastive Learning (MSHCL) framework for VideoQA. Specifically, we first segment the video from multiple temporal dimensions to obtain multiple frame groups. For different frame groups, we design appearance and motion hyperedges based on node semantics to connect object nodes. In this way, we construct a multi-scale temporal–spatial hypergraph to directly capture high-order relations among multiple objects. Furthermore, the node features after hypergraph convolution are injected into a Transformer to capture the global information of the input sequence. Second, we design a self-supervised hypergraph contrastive learning task based on the node- and hyperedge-dropping data augmentation and an improved question-guided multimodal interaction module to enhance the accuracy and robustness of the VideoQA model. Finally, extensive experiments on three benchmark datasets demonstrate the superiority of our proposed MSHCL compared with stat-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004872",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Discrete mathematics",
      "Hypergraph",
      "Machine learning",
      "Mathematics",
      "Natural language processing",
      "Physics",
      "Quantum mechanics",
      "Question answering",
      "Scale (ratio)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Zheng"
      },
      {
        "surname": "Wu",
        "given_name": "Bin"
      },
      {
        "surname": "Ota",
        "given_name": "Kaoru"
      },
      {
        "surname": "Dong",
        "given_name": "Mianxiong"
      },
      {
        "surname": "Li",
        "given_name": "He"
      }
    ]
  },
  {
    "title": "Mean-field neural networks: Learning mappings on Wasserstein space",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.015",
    "abstract": "We study the machine learning task for models with operators mapping between the Wasserstein space of probability measures and a space of functions, like e.g. in mean-field games/control problems. Two classes of neural networks based on bin density and on cylindrical approximation, are proposed to learn these so-called mean-field functions, and are theoretically supported by universal approximation theorems. We perform several numerical experiments for training these two mean-field neural networks, and show their accuracy and efficiency in the generalization error with various test distributions. Finally, we present different algorithms relying on mean-field neural networks for solving time-dependent mean-field problems, and illustrate our results with numerical tests for the example of a semi-linear partial differential equation in the Wasserstein space of probability measures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005087",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Field (mathematics)",
      "Generalization",
      "Mathematical analysis",
      "Mathematics",
      "Mean field theory",
      "Operating system",
      "Physics",
      "Probability density function",
      "Pure mathematics",
      "Quantum mechanics",
      "Space (punctuation)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Pham",
        "given_name": "Huyên"
      },
      {
        "surname": "Warin",
        "given_name": "Xavier"
      }
    ]
  },
  {
    "title": "Adaptive control-based synchronization of discrete-time fractional-order fuzzy neural networks with time-varying delays",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.019",
    "abstract": "This paper is concerned with complete synchronization for discrete-time fractional-order fuzzy neural networks (DFFNNs) with time-varying delays. First, three original equalities and two Caputo σ -difference inequalities are established based on theory of discrete-time fractional Calculus. Next, a novel discrete-time adaptive controller with time-varying delay is designed, by virtue of 1-norm Lyapunov function and newly established lemmas herein as well as inequality techniques and contradiction method, some judgement conditions are derived to guarantee complete synchronization for the explored DFFNNs. Benefitting from discrete-time adaptive control strategy and our analysis method, the conservatism of the derived synchronization criteria is reduced. Ultimately, the effectiveness of our theoretical results and secure communication scheme are demonstrated through two numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005129",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Discrete time and continuous time",
      "Fuzzy logic",
      "Mathematics",
      "Statistics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Hong-Li"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Zhang",
        "given_name": "Long"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      }
    ]
  },
  {
    "title": "STMMOT: Advancing multi-object tracking through spatiotemporal memory networks and multi-scale attention pyramids",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.047",
    "abstract": "Multi-object Tracking (MOT) is very important in human surveillance, sports analytics, autonomous driving, and cooperative robots. Current MOT methods do not perform well in non-uniform movements, occlusion and appearance–reappearance scenarios. We introduce a comprehensive MOT method that seamlessly merges object detection and identity linkage within an end-to-end trainable framework, designed with the capability to maintain object links over a long period of time. Our proposed model, named STMMOT, is architectured around 4 key modules: (1) Candidate proposal creation network, generates object proposals via vision-Transformer encoder–decoder architecture; (2) Scale variant pyramid, progressive pyramid structure to learn the self-scale and cross-scale similarities in multi-scale feature maps; (3) Spatio-temporal memory encoder, extracting the essential information from the memory associated with each object under tracking; and (4) Spatio-temporal memory decoder, simultaneously resolving the tasks of object detection and identity association for MOT. Our system leverages a robust spatio-temporal memory module that retains extensive historical object state observations and effectively encodes them using an attention-based aggregator. The uniqueness of STMMOT resides in representing objects as dynamic query embeddings that are updated continuously, which enables the prediction of object states with an attention mechanism and eradicates the need for post-processing. Experimental results show that STMMOT archives scores of 79.8 and 78.4 for IDF1, 79.3 and 74.1 for MOTA, 73.2 and 69.0 for HOTA, 61.2 and 61.5 for AssA, and maintained an ID switch count of 1529 and 1264 on MOT17 and MOT20, respectively. When evaluated on MOT20, it scored 78.4 in IDF1, 74.1 in MOTA, 69.0 in HOTA, and 61.5 in AssA, and kept the ID switch count to 1264. Compared with the previous best TransMOT, STMMOT achieves around a 4.58% and 4.25% increase in IDF1, and ID switching reduction to 5.79% and 21.05% on MOT17 and MOT20, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005439",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Encoder",
      "Object (grammar)",
      "Operating system",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Pyramid (geometry)",
      "Video tracking"
    ],
    "authors": [
      {
        "surname": "Mukhtar",
        "given_name": "Hamza"
      },
      {
        "surname": "Khan",
        "given_name": "Muhammad Usman Ghani"
      }
    ]
  },
  {
    "title": "STTRE: A Spatio-Temporal Transformer with Relative Embeddings for multivariate time series forecasting",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.039",
    "abstract": "The prevalence of multivariate time series data across several disciplines fosters a demand and, subsequently, significant growth in the research and advancement of multivariate time series analysis. Drawing inspiration from a popular natural language processing model, the Transformer, we propose the Spatio-Temporal Transformer with Relative Embeddings (STTRE) to address multivariate time series forecasting. This work primarily focuses on developing a Transformer-based framework that can fully exploit the spatio-temporal nature of a multivariate time series by incorporating several of the Transformer’s key components, but with augmentations that allow them to excel in multivariate time series forecasting. Current Transformer-based models for multivariate time series often neglect the data’s spatial component(s) and utilize absolute position embeddings as their only means to detect the data’s temporal component(s), which we show is flawed for time series applications. The lack of emphasis on fully exploiting the spatio-temporality of the data can incur subpar results in terms of accuracy. We redesign relative position representations, which we rename to relative embeddings, to unveil a new method for detecting latent spatial, temporal, and spatio-temporal dependencies more effectively than previous Transformer-based models. We couple these relative embeddings with a restructuring of the Transformer’s primary sequence learning mechanism, multi-head attention, in a way that allows for full utilization of relative embeddings, thus achieving up to a 24% improvement in accuracy over other state-of-the-art multivariate time series models on a comprehensive selection of publicly available multivariate time series forecasting datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005361",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Electrical engineering",
      "Engineering",
      "Machine learning",
      "Multivariate statistics",
      "Time series",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Deihim",
        "given_name": "Azad"
      },
      {
        "surname": "Alonso",
        "given_name": "Eduardo"
      },
      {
        "surname": "Apostolopoulou",
        "given_name": "Dimitra"
      }
    ]
  },
  {
    "title": "Incorrect Application of Yilmaz–Poli (2022) Initialisation Method in dePater–Mitici 2023 paper entitled “A mathematical framework for improved weight initialization of neural networks using Lagrange multipliers”",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.017",
    "abstract": "In this letter to the editor we report on a methodological error made in the article entitled “A mathematical framework for improved weight initialization of neural networks using Lagrange multipliers” by dePater and Mitici recently appeared in this journal. The error relates to the incorrect application of a weight initialisation method we derived, published last year in this same journal.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005105",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Initialization",
      "Lagrange multiplier",
      "Mathematical optimization",
      "Mathematics",
      "Programming language"
    ],
    "authors": [
      {
        "surname": "Poli",
        "given_name": "Riccardo"
      },
      {
        "surname": "Yilmaz",
        "given_name": "Ahmet"
      }
    ]
  },
  {
    "title": "Exploring the role of texture features in deep convolutional neural networks: Insights from Portilla-Simoncelli statistics",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.028",
    "abstract": "It is well-understood that the performance of Deep Convolutional Neural Networks (DCNNs) in image recognition tasks is influenced not only by shape but also by texture information. Despite this, understanding the internal representations of DCNNs remains a challenging task. This study employs a simplified version of the Portilla-Simoncelli Statistics, termed “minPS,” to explore how texture information is represented in a pre-trained VGG network. Using minPS features extracted from texture images, we perform a sparse regression on the activations across various channels in VGG layers. Our findings reveal that channels in the early to middle layers of the VGG network can be effectively described by minPS features. Additionally, we observe that the explanatory power of minPS sub-groups evolves as one ascends the network hierarchy. Specifically, sub-groups termed Linear Cross Scale (LCS) and Energy Cross Scale (ECS) exhibit weak explanatory power for VGG channels. To investigate the relationship further, we compare the original texture images with their synthesized counterparts, generated using VGG, in terms of minPS features. Our results indicate that the absence of certain minPS features suggests their non-utilization in VGG’s internal representations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005245",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cartography",
      "Computer science",
      "Convolutional neural network",
      "Geography",
      "Image (mathematics)",
      "Pattern recognition (psychology)",
      "Scale (ratio)",
      "Texture (cosmology)"
    ],
    "authors": [
      {
        "surname": "Hamano",
        "given_name": "Yusuke"
      },
      {
        "surname": "Nagasaka",
        "given_name": "Shoko"
      },
      {
        "surname": "Shouno",
        "given_name": "Hayaru"
      }
    ]
  },
  {
    "title": "Adaptive neural network control for Markov jumping systems against deception attacks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.027",
    "abstract": "This paper proposes an innovative approach for mitigating the effects of deception attacks in Markov jumping systems by developing an adaptive neural network control strategy. To address the challenge of dual-mode monitoring mechanisms, two independent Markov chains are used to describe the state changes of the system and the intermittent actuator. By employing a mapping technique, these individual chains are amalgamated into a unified joint Markov chain. Additionally, to effectively approximate the unbounded false signals injected by deception attacks, an adaptive neural network technique is skillfully built. A mode monitoring scheme is implemented to design an asynchronous control law that links the mode information between the joint Markov chain and controller with fewer modes. The paper derives sufficient criteria for the mean-square bounded stability of the resulting system based on Lyapunov theories. Finally, a numerical experiment is conducted to demonstrate the effectiveness of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300518X",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Asynchronous communication",
      "Biology",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Deception",
      "Law",
      "Lyapunov function",
      "Lyapunov stability",
      "Machine learning",
      "Markov chain",
      "Nonlinear system",
      "Physics",
      "Political science",
      "Quantum mechanics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Junhui"
      },
      {
        "surname": "Qin",
        "given_name": "Gang"
      },
      {
        "surname": "Cheng",
        "given_name": "Jun"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Yan",
        "given_name": "Huaicheng"
      },
      {
        "surname": "Katib",
        "given_name": "Iyad"
      }
    ]
  },
  {
    "title": "Exploring the role of edge distribution in graph convolutional networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.048",
    "abstract": "Graph Convolutional Networks (GCNs) have shown remarkable performance in processing graph-structured data by leveraging neighborhood information for node representation learning. While most GCN models assume strong homophily within the networks they handle, some models can also handle heterophilous graphs. However, the selection of neighbors participating in the node representation learning process can significantly impact these models’ performance. To address this, we investigate the influence of neighbor selection on GCN performance, focusing on the analysis of edge distribution through theoretical and empirical approaches. Based on our findings, we propose a novel GCN model called Graph Convolution Network with Improved Edge Distribution (GCN-IED). GCN-IED incorporates both direct edges, which rely on local neighborhood similarity, and hidden edges, obtained by aggregating information from multi-hop neighbors. We extensively evaluate GCN-IED on diverse graph benchmark datasets and observe its superior performance compared to other state-of-the-art GCN methods on heterophilous datasets. Our GCN-IED model, which considers the role of neighbors and optimizes edge distribution, provides valuable insights for enhancing graph representation learning and achieving superior performance on heterophilous graphs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005440",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Convolutional neural network",
      "Enhanced Data Rates for GSM Evolution",
      "Feature learning",
      "Graph",
      "Homophily",
      "Law",
      "Machine learning",
      "Mathematics",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Liancheng"
      },
      {
        "surname": "Bai",
        "given_name": "Liang"
      },
      {
        "surname": "Yang",
        "given_name": "Xian"
      },
      {
        "surname": "Liang",
        "given_name": "Zhuomin"
      },
      {
        "surname": "Liang",
        "given_name": "Jiye"
      }
    ]
  },
  {
    "title": "An exact mapping from ReLU networks to spiking neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.011",
    "abstract": "Deep spiking neural networks (SNNs) offer the promise of low-power artificial intelligence. However, training deep SNNs from scratch or converting deep artificial neural networks to SNNs without loss of performance has been a challenge. Here we propose an exact mapping from a network with Rectified Linear Units (ReLUs) to an SNN that fires exactly one spike per neuron. For our constructive proof, we assume that an arbitrary multi-layer ReLU network with or without convolutional layers, batch normalization and max pooling layers was trained to high performance on some training set. Furthermore, we assume that we have access to a representative example of input data used during training and to the exact parameters (weights and biases) of the trained ReLU network. The mapping from deep ReLU networks to SNNs causes zero percent drop in accuracy on CIFAR10, CIFAR100 and the ImageNet-like data sets Places365 and PASS. More generally our work shows that an arbitrary deep ReLU network can be replaced by an energy-efficient single-spike neural network without any loss of performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005051",
    "keywords": [
      "Algorithm",
      "Anthropology",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Deep neural networks",
      "Normalization (sociology)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Pooling",
      "Scratch",
      "Sociology",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Stanojevic",
        "given_name": "Ana"
      },
      {
        "surname": "Woźniak",
        "given_name": "Stanisław"
      },
      {
        "surname": "Bellec",
        "given_name": "Guillaume"
      },
      {
        "surname": "Cherubini",
        "given_name": "Giovanni"
      },
      {
        "surname": "Pantazi",
        "given_name": "Angeliki"
      },
      {
        "surname": "Gerstner",
        "given_name": "Wulfram"
      }
    ]
  },
  {
    "title": "Competitive learning to generate sparse representations for associative memory",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.005",
    "abstract": "One of the most well established brain principles, Hebbian learning, has led to the theoretical concept of neural assemblies. Based on it, many interesting brain theories have spawned. Palm’s work implements this concept through multiple binary Willshaw associative memories, in a model that not only has a wide cognitive explanatory power but also makes neuroscientific predictions. Yet, Willshaw’s associative memory can only achieve top capacity when the stored vectors are extremely sparse (number of active bits can grow logarithmically with the vector’s length). This strict requirement makes it difficult to apply any model that uses this associative memory, like Palm’s, to real data. Hence the fact that most works apply the memory to optimal randomly generated codes that do not represent any information. This issue creates the need for encoders that can take real data, and produce sparse representations - a problem which is also raised following Barlow’s efficient coding principle. In this work, we propose a biologically-constrained network that encodes images into codes that are suitable for Willshaw’s associative memory. The network is organized into groups of neurons that specialize on local receptive fields, and learn through a competitive scheme. After conducting auto- and hetero-association experiments on two visual data sets, we can conclude that our network not only beats sparse coding baselines, but also that it comes close to the performance achieved using optimal random codes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005014",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Associative property",
      "Bidirectional associative memory",
      "Cognitive science",
      "Computer science",
      "Content-addressable memory",
      "Machine learning",
      "Mathematics",
      "Psychology",
      "Pure mathematics",
      "Sparse approximation"
    ],
    "authors": [
      {
        "surname": "Sacouto",
        "given_name": "Luis"
      },
      {
        "surname": "Wichert",
        "given_name": "Andreas"
      }
    ]
  },
  {
    "title": "Improved prediction of behavioral and neural similarity spaces using pruned DNNs",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.049",
    "abstract": "Deep Neural Networks (DNNs) have become an important tool for modeling brain and behavior. One key area of interest has been to apply these networks to model human similarity judgements. Several previous works have used the embeddings from the penultimate layer of vision DNNs and showed that a reweighting of these features improves the fit between human similarity judgments and DNNs. These studies underline the idea that these embeddings form a good basis set but lack the correct level of salience. Here we re-examined the grounds for this idea and on the contrary, we hypothesized that these embeddings, beyond forming a good basis set, also have the correct level of salience to account for similarity judgments. It is just that the huge dimensional embedding needs to be pruned to select those features relevant for the considered domain for which a similarity space is modeled. In Study 1 we supervised DNN pruning based on a subset of human similarity judgments. We found that pruning: i) improved out-of-sample prediction of human similarity judgments from DNN embeddings, ii) produced better alignment with WordNet hierarchy, and iii) retained much higher classification accuracy than reweighting. Study 2 showed that pruning by neurobiological data is highly effective in improving out-of-sample prediction of brain-derived representational dissimilarity matrices from DNN embeddings, at times fleshing out isomorphisms not otherwise observable. Using pruned DNNs, image-level heatmaps can be produced to identify image sections whose features load on dimensions coded by a brain area. Pruning supervised by human brain/behavior therefore effectively identifies alignable dimensions of knowledge between DNNs and humans and constitutes an effective method for understanding the organization of knowledge in neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004690",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Deep neural networks",
      "Embedding",
      "Image (mathematics)",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Programming language",
      "Pruning",
      "Salience (neuroscience)",
      "Set (abstract data type)",
      "Similarity (geometry)",
      "WordNet"
    ],
    "authors": [
      {
        "surname": "Tarigopula",
        "given_name": "Priya"
      },
      {
        "surname": "Fairhall",
        "given_name": "Scott Laurence"
      },
      {
        "surname": "Bavaresco",
        "given_name": "Anna"
      },
      {
        "surname": "Truong",
        "given_name": "Nhut"
      },
      {
        "surname": "Hasson",
        "given_name": "Uri"
      }
    ]
  },
  {
    "title": "Self-supervised depth super-resolution with contrastive multiview pre-training",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.023",
    "abstract": "Many low-level vision tasks, including guided depth super-resolution (GDSR), struggle with the issue of insufficient paired training data. Self-supervised learning is a promising solution, but it remains challenging to upsample depth maps without the explicit supervision of high-resolution target images. To alleviate this problem, we propose a self-supervised depth super-resolution method with contrastive multiview pre-training. Unlike existing contrastive learning methods for classification or segmentation tasks, our strategy can be applied to regression tasks even when trained on a small-scale dataset and can reduce information redundancy by extracting unique features from the guide. Furthermore, we propose a novel mutual modulation scheme that can effectively compute the local spatial correlation between cross-modal features. Exhaustive experiments demonstrate that our method attains superior performance with respect to state-of-the-art GDSR methods and exhibits good generalization to other modalities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005166",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Mutual information",
      "Operating system",
      "Pattern recognition (psychology)",
      "Redundancy (engineering)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Qiao",
        "given_name": "Xin"
      },
      {
        "surname": "Ge",
        "given_name": "Chenyang"
      },
      {
        "surname": "Zhao",
        "given_name": "Chaoqiang"
      },
      {
        "surname": "Tosi",
        "given_name": "Fabio"
      },
      {
        "surname": "Poggi",
        "given_name": "Matteo"
      },
      {
        "surname": "Mattoccia",
        "given_name": "Stefano"
      }
    ]
  },
  {
    "title": "A dual-branch model with inter- and intra-branch contrastive loss for long-tailed recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.022",
    "abstract": "Real-world data often exhibits a long-tailed distribution, in which head classes occupy most of the data, while tail classes only have very few samples. Models trained on long-tailed datasets have poor adaptability to tail classes and the decision boundaries are ambiguous. Therefore, in this paper, we propose a simple yet effective model, named Dual-Branch Long-Tailed Recognition (DB-LTR), which includes an imbalanced learning branch and a Contrastive Learning Branch (CoLB). The imbalanced learning branch, which consists of a shared backbone and a linear classifier, leverages common imbalanced learning approaches to tackle the data imbalance issue. In CoLB, we learn a prototype for each tail class, and calculate an inter-branch contrastive loss, an intra-branch contrastive loss and a metric loss. CoLB can improve the capability of the model in adapting to tail classes and assist the imbalanced learning branch to learn a well-represented feature space and discriminative decision boundary. Extensive experiments on three long-tailed benchmark datasets, i.e., CIFAR100-LT, ImageNet-LT and Places-LT, show that our DB-LTR is competitive and superior to the comparative methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005154",
    "keywords": [],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Qiong"
      },
      {
        "surname": "Huang",
        "given_name": "Tianlin"
      },
      {
        "surname": "Zhu",
        "given_name": "Geren"
      },
      {
        "surname": "Lin",
        "given_name": "Enlu"
      }
    ]
  },
  {
    "title": "A biologically inspired architecture with switching units can learn to generalize across backgrounds",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.014",
    "abstract": "Humans and other animals navigate different environments effortlessly, their brains rapidly and accurately generalizing across contexts. Despite recent progress in deep learning, this flexibility remains a challenge for many artificial systems. Here, we show how a bio-inspired network motif can explicitly address this issue. We do this using a dataset of MNIST digits of varying transparency, set on one of two backgrounds of different statistics that define two contexts: a pixel-wise noise or a more naturalistic background from the CIFAR-10 dataset. After learning digit classification when both contexts are shown sequentially, we find that both shallow and deep networks have sharply decreased performance when returning to the first background — an instance of the catastrophic forgetting phenomenon known from continual learning. To overcome this, we propose the bottleneck-switching network or switching network for short. This is a bio-inspired architecture analogous to a well-studied network motif in the visual cortex, with additional “switching” units that are activated in the presence of a new background, assuming a priori a contextual signal to turn these units on or off. Intriguingly, only a few of these switching units are sufficient to enable the network to learn the new context without catastrophic forgetting through inhibition of redundant background features. Further, the bottleneck-switching network can generalize to novel contexts similar to contexts it has learned. Importantly, we find that — again as in the underlying biological network motif, recurrently connecting the switching units to network layers is advantageous for context generalization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005099",
    "keywords": [
      "Archaeology",
      "Architecture",
      "Artificial intelligence",
      "Computer science",
      "Geography",
      "Machine learning"
    ],
    "authors": [
      {
        "surname": "Voina",
        "given_name": "Doris"
      },
      {
        "surname": "Shea-Brown",
        "given_name": "Eric"
      },
      {
        "surname": "Mihalas",
        "given_name": "Stefan"
      }
    ]
  },
  {
    "title": "Enhancing neurodynamic approach with physics-informed neural networks for solving non-smooth convex optimization problems",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.014",
    "abstract": "This paper proposes a deep learning approach for solving non-smooth convex optimization problems (NCOPs), which have broad applications in computer science, engineering, and physics. Our approach combines neurodynamic optimization with physics-informed neural networks (PINNs) to provide an efficient and accurate solution. We first use neurodynamic optimization to formulate an initial value problem (IVP) that involves a system of ordinary differential equations for the NCOP. We then introduce a modified PINN as an approximate state solution to the IVP. Finally, we develop a dedicated algorithm to train the model to solve the IVP and minimize the NCOP objective simultaneously. Unlike existing numerical integration methods, a key advantage of our approach is that it does not require the computation of a series of intermediate states to produce a prediction of the NCOP. Our experimental results show that this computational feature results in fewer iterations being required to produce more accurate prediction solutions. Furthermore, our approach is effective in finding feasible solutions that satisfy the NCOP constraint.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004331",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computation",
      "Computer science",
      "Computer security",
      "Constraint (computer-aided design)",
      "Convex optimization",
      "Differential equation",
      "Geometry",
      "Key (lock)",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Ordinary differential equation",
      "Regular polygon"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Dawen"
      },
      {
        "surname": "Lisser",
        "given_name": "Abdel"
      }
    ]
  },
  {
    "title": "Deep graph reconstruction for multi-view clustering",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.10.001",
    "abstract": "Graph-based multi-view clustering methods have achieved impressive success by exploring a complemental or independent graph embedding with low-dimension among multiple views. The majority of them, however, are shallow models with limited ability to learn the nonlinear information in multi-view data. To this end, we propose a novel deep graph reconstruction (DGR) framework for multi-view clustering, which contains three modules. Specifically, a Multi-graph Fusion Module (MFM) is employed to obtain the consensus graph. Then node representation is learned by the Graph Embedding Network (GEN). To assign clusters directly, the Clustering Assignment Module (CAM) is devised to obtain the final low-dimensional graph embedding, which can serve as the indicator matrix. In addition, a simple and powerful loss function is designed in the proposed DGR. Extensive experiments on seven real-world datasets have been conducted to verify the superior clustering performance and efficiency of DGR compared with the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005531",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Clustering coefficient",
      "Computer science",
      "Data mining",
      "Embedding",
      "Graph",
      "Graph embedding",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Mingyu"
      },
      {
        "surname": "Yang",
        "given_name": "Weidong"
      },
      {
        "surname": "Nie",
        "given_name": "Feiping"
      }
    ]
  },
  {
    "title": "Joint learning of feature and topology for multi-view graph convolutional network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.006",
    "abstract": "Graph convolutional network has been extensively employed in semi-supervised classification tasks. Although some studies have attempted to leverage graph convolutional networks to explore multi-view data, they mostly consider the fusion of feature and topology individually, leading to the underutilization of the consistency and complementarity of multi-view data. In this paper, we propose an end-to-end joint fusion framework that aims to simultaneously conduct a consistent feature integration and an adaptive topology adjustment. Specifically, to capture the feature consistency, we construct a deep matrix decomposition module, which maps data from different views onto a feature space obtaining a consistent feature representation. Moreover, we design a more flexible graph convolution that allows to adaptively learn a more robust topology. A dynamic topology can greatly reduce the influence of unreliable information, which acquires a more adaptive representation. As a result, our method jointly designs an effective feature fusion module and a topology adjustment module, and lets these two modules mutually enhance each other. It takes full advantage of the consistency and complementarity to better capture the more intrinsic information. The experimental results indicate that our method surpasses state-of-the-art semi-supervised classification methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004987",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Feature (linguistics)",
      "Feature learning",
      "Feature vector",
      "Graph",
      "Linguistics",
      "Mathematics",
      "Network topology",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Yuhong"
      },
      {
        "surname": "Wu",
        "given_name": "Zhihao"
      },
      {
        "surname": "Chen",
        "given_name": "Zhaoliang"
      },
      {
        "surname": "Dong",
        "given_name": "Mianxiong"
      },
      {
        "surname": "Wang",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "FOESO-Net: A specific neural network for fast sensorless robot manipulator torque estimation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.020",
    "abstract": "Contact torque sensing allows robot manipulators to cooperate with humans and detect accidental collisions in real time to ensure safety. Most sensorless torque estimation schemes, which are based on linear observer approaches, cannot compromise between non-negligible noise and high observation bandwidth. Therefore, fast time-varying nonlinear torque observation cannot be satisfied. To achieve this challenge, a customized network called FOESO-Net based on a novel fractional-order extended state observer is carefully designed in this paper. The network firstly chooses momentum as the benchmark state for torque estimation, which can avoid joint acceleration and model’s inverse inertia matrix solution. Then, a fractional-order extended state observer (FOESO) is proposed from the perspective of momentum control to better adapt to the nonlinear fast time varying torque. In addition, a fractional-order neural network and a weight update neural network parallel architecture are constructed to enable fractional-order and dynamic weight-based adaptive learning of FOESO parameters. Formal analysis and proofs are made to show that the error of FOESO-Net is convergent. Finally, the effectiveness of the proposed method is verified by numerical simulations and a real collaborative robot platform. Moreover, compared with existing methods, the FOESO-Net based torque estimation method can reduce the estimation error and response time, which illustrates the superiority of the designed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005130",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Robot",
      "Thermodynamics",
      "Torque"
    ],
    "authors": [
      {
        "surname": "Long",
        "given_name": "Shike"
      },
      {
        "surname": "Dang",
        "given_name": "Xuanju"
      },
      {
        "surname": "Huang",
        "given_name": "Jia"
      }
    ]
  },
  {
    "title": "A self-training algorithm based on the two-stage data editing method with mass-based dissimilarity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.046",
    "abstract": "A self-training algorithm is a classical semi-supervised learning algorithm that uses a small number of labeled samples and a large number of unlabeled samples to train a classifier. However, the existing self-training algorithms consider only the geometric distance between data while ignoring the data distribution when calculating the similarity between samples. In addition, misclassified samples can severely affect the performance of a self-training algorithm. To address the above two problems, this paper proposes a self-training algorithm based on data editing with mass-based dissimilarity (STDEMB). First, the mass matrix with the mass-based dissimilarity is obtained, and then the mass-based local density of each sample is determined based on its k nearest neighbors. Inspired by density peak clustering (DPC), this study designs a prototype tree based on the prototype concept. In addition, an efficient two-stage data editing algorithm is developed to edit misclassified samples and efficiently select high-confidence samples during the self-training process. The proposed STDEMB algorithm is verified by experiments using accuracy and F-score as evaluation metrics. The experimental results on 18 benchmark datasets demonstrate the effectiveness of the proposed STDEMB algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005427",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Pattern recognition (psychology)",
      "Similarity (geometry)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jikui"
      },
      {
        "surname": "Wu",
        "given_name": "Yiwen"
      },
      {
        "surname": "Li",
        "given_name": "Shaobo"
      },
      {
        "surname": "Nie",
        "given_name": "Feiping"
      }
    ]
  },
  {
    "title": "Bifurcations of a delayed fractional-order BAM neural network via new parameter perturbations",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.060",
    "abstract": "This paper makes a new breakthrough in deliberating the bifurcations of fractional-order bidirectional associative memory neural network (FOBAMNN). In the beginning, the corresponding bifurcation results are established according to self-regulating parameter, which is different from bifurcation outcomes available by using time delay as the bifurcation parameter, and greatly enriches the bifurcation results of continuous neural networks(NNs). The deived results manifest that a larger self-regulating parameter is more conducive to the stability of the system, which is consistent with the actual meaning of the self-regulating parameter representing the decay rate of activity. In addition to the innovation in the research object, this paper also has innovation in the procedure of calculating the bifurcation critical point. In the face of the quartic equation about the bifurcation parameters, this paper utilizes the methodology of implicit array to calculate the bifurcation critical point succinctly and effectively, which eschews the disadvantages of the conventional Ferrari approach, such as cumbersome formula and huge computational efforts. Our developed technique can be employed as a general method to solve the bifurcation point including the problem of dealing with the bifurcation critical point of delay. Ultimately, numerical experiments test the key theoretical fruits of this paper.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004896",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bifurcation",
      "Bifurcation diagram",
      "Bifurcation theory",
      "Biological applications of bifurcation theory",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Quartic function",
      "Saddle-node bifurcation"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Chengdai"
      },
      {
        "surname": "Wang",
        "given_name": "Huanan"
      },
      {
        "surname": "Liu",
        "given_name": "Heng"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "How to backdoor split learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.037",
    "abstract": "Split learning, a distributed learning framework, has garnered significant attention from academic and industrial communities. In contrast to federated learning, split learning offers a more flexible architecture for participants with limited computing resources. However, the security of split learning has been questioned due to the separation of data and model control rights from usage rights. Currently, most research work focuses on inference attacks in split learning. In this paper, we first reveal the vulnerability of split learning to backdoor attacks and present two backdoor attack frameworks from both the server and client perspectives. Regarding the client-side attacker, we insert backdoor samples into the training data by utilizing the client’s direct control over local data, and propose two methods for labeling backdoor samples that can be adapted to various application scenarios. Due to the server’s lack of control over the client in split learning, it is infeasible for server-side attackers to inject backdoor samples into training data. Our strategy involves leveraging the server’s control over the training process to shape the optimization direction of the client model, thereby enabling it to encode backdoor samples. Moreover, we introduce an auxiliary model into the attack framework to enhance the effectiveness of the backdoor attack. The auxiliary model can increase the distinction between backdoor samples and clean samples in the feature space to improve the sensitivity of the client model to backdoor samples. Extensive evaluations demonstrate the high attack accuracy of both proposed attack frameworks without causing any compromise to the performance of the main task. Our research uncovers the potential security risks and rings the alarm for the application of split learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005336",
    "keywords": [
      "Artificial intelligence",
      "Backdoor",
      "Computer science",
      "Computer security",
      "Machine learning",
      "Operating system",
      "Process (computing)",
      "Vulnerability (computing)"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Fangchao"
      },
      {
        "surname": "Wang",
        "given_name": "Lina"
      },
      {
        "surname": "Zeng",
        "given_name": "Bo"
      },
      {
        "surname": "Zhao",
        "given_name": "Kai"
      },
      {
        "surname": "Pang",
        "given_name": "Zhi"
      },
      {
        "surname": "Wu",
        "given_name": "Tian"
      }
    ]
  },
  {
    "title": "Lower and upper bounds for numbers of linear regions of graph convolutional networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.025",
    "abstract": "Graph neural networks (GNNs) have become a popular choice for analyzing graph data in the last few years, and characterizing their expressiveness has become an active area of research. One popular measure of expressiveness is the number of linear regions in neural networks with piecewise linear activations. In this paper, we present estimates for the number of linear regions in classic graph convolutional networks (GCNs) with one layer and multiple-layer scenarios and ReLU activation function. We derive an optimal upper bound for the maximum number of linear regions for one-layer GCNs and upper and lower bounds for multi-layer GCNs. Our simulated results suggest that the true maximum number of linear regions is likely closer to our estimated lower bound. These findings indicate that multi-layer GCNs have exponentially greater expressivity than one-layer GCNs per parameter, implying that deeper GCNs are more expressive than their shallow counterparts.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005191",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Geometry",
      "Graph",
      "Layer (electronics)",
      "Linear model",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Organic chemistry",
      "Piecewise linear function",
      "Theoretical computer science",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Hao"
      },
      {
        "surname": "Wang",
        "given_name": "Yu Guang"
      },
      {
        "surname": "Xiong",
        "given_name": "Huan"
      }
    ]
  },
  {
    "title": "Quantized minimum error entropy with fiducial points for robust regression",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.034",
    "abstract": "Minimum error entropy with fiducial points (MEEF) has received a lot of attention, due to its outstanding performance to curb the negative influence caused by non-Gaussian noises in the fields of machine learning and signal processing. However, the estimate of the information potential of MEEF involves a double summation operator based on all available error samples, which can result in large computational burden in many practical scenarios. In this paper, an efficient quantization method is therefore adopted to represent the primary set of error samples with a smaller subset, generating a quantized MEEF (QMEEF). Some basic properties of QMEEF are presented and proved from theoretical perspectives. In addition, we have applied this new criterion to train a class of linear-in-parameters models, including the commonly used linear regression model, random vector functional link network, and broad learning system as special cases. Experimental results on various datasets are reported to demonstrate the desirable performance of the proposed methods to perform regression tasks with contaminated data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005300",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Entropy (arrow of time)",
      "Fiducial marker",
      "Gaussian",
      "Linear regression",
      "Machine learning",
      "Mathematics",
      "Mutual information",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Regression",
      "Statistics",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Zheng",
        "given_name": "Yunfei"
      },
      {
        "surname": "Wang",
        "given_name": "Shiyuan"
      },
      {
        "surname": "Chen",
        "given_name": "Badong"
      }
    ]
  },
  {
    "title": "EQNAS: Evolutionary Quantum Neural Architecture Search for Image Classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.040",
    "abstract": "Quantum neural network (QNN) is a neural network model based on the principles of quantum mechanics. The advantages of faster computing speed, higher memory capacity, smaller network size and elimination of catastrophic amnesia make it a new idea to solve the problem of training massive data that is difficult for classical neural networks. However, the quantum circuit of QNN are artificially designed with high circuit complexity and low precision in classification tasks. In this paper, a neural architecture search method EQNAS is proposed to improve QNN. First, initializing the quantum population after image quantum encoding. The next step is observing the quantum population and evaluating the fitness. The last is updating the quantum population. Quantum rotation gate update, quantum circuit construction and entirety interference crossover are specific operations. The last two steps need to be carried out iteratively until a satisfactory fitness is achieved. After a lot of experiments on the searched quantum neural networks, the feasibility and effectiveness of the algorithm proposed in this paper are proved, and the searched QNN is obviously better than the original algorithm. The classification accuracy on the mnist dataset and the warship dataset not only increased by 5.31% and 4.52%, respectively, but also reduced the parameters by 21.88% and 31.25% respectively. Code will be available at https://gitee.com/Pcyslist/models/tree/master/research/cv/EQNAS, and https://github.com/Pcyslist/EQNAS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005348",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Crossover",
      "Demography",
      "Initialization",
      "MNIST database",
      "Physics",
      "Population",
      "Programming language",
      "Quantum",
      "Quantum circuit",
      "Quantum computer",
      "Quantum gate",
      "Quantum mechanics",
      "Quantum network",
      "Sociology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Yangyang"
      },
      {
        "surname": "Liu",
        "given_name": "Ruijiao"
      },
      {
        "surname": "Hao",
        "given_name": "Xiaobin"
      },
      {
        "surname": "Shang",
        "given_name": "Ronghua"
      },
      {
        "surname": "Zhao",
        "given_name": "Peixiang"
      },
      {
        "surname": "Jiao",
        "given_name": "Licheng"
      }
    ]
  },
  {
    "title": "Synergetic learning for unknown nonlinear H ∞ control using neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.029",
    "abstract": "The well-known H ∞ control design gives robustness to a controller by rejecting perturbations from the external environment, which is difficult to do for completely unknown affine nonlinear systems. Accordingly, the immediate objective of this paper is to develop an on-line real-time synergetic learning algorithm, so that a data-driven H ∞ controller can be received. By converting the H ∞ control problem into a two-player zero-sum game, a model-free Hamilton–Jacobi–Isaacs equation (MF-HJIE) is first derived using off-policy reinforcement learning, followed by a proof of equivalence between the MF-HJIE and the conventional HJIE. Next, by applying the temporal difference to the MF-HJIE, a synergetic evolutionary rule with experience replay is designed to learn the optimal value function, the optimal control, and the worst perturbation, that can be performed on-line and in real-time along the system state trajectory. It is proven that the synergistic learning system constructed by the system plant and the evolutionary rule is uniformly ultimately bounded. Finally, simulation results on an F16 aircraft system and a nonlinear system back up the tractability of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005257",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Mathematics"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Liao"
      },
      {
        "surname": "Guo",
        "given_name": "Ping"
      },
      {
        "surname": "Wei",
        "given_name": "Qinglai"
      }
    ]
  },
  {
    "title": "Reliable prediction intervals with directly optimized inductive conformal regression for deep learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.008",
    "abstract": "By generating prediction intervals (PIs) to quantify the uncertainty of each prediction in deep learning regression, the risk of wrong predictions can be effectively controlled. High-quality PIs need to be as narrow as possible, whilst covering a preset proportion of real labels. At present, many approaches to improve the quality of PIs can effectively reduce the width of PIs, but they do not ensure that enough real labels are captured. Inductive Conformal Predictor (ICP) is an algorithm that can generate effective PIs which is theoretically guaranteed to cover a preset proportion of data. However, typically ICP is not directly optimized to yield minimal PI width. In this study, we propose Directly Optimized Inductive Conformal Regression (DOICR) for neural networks that takes only the average width of PIs as the loss function and increases the quality of PIs through an optimized scheme, under the validity condition that sufficient real labels are captured in the PIs. Benchmark experiments show that DOICR outperforms current state-of-the-art algorithms for regression problems using underlying Deep Neural Network structures for both tabular and image data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004999",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Conformal map",
      "Data mining",
      "Evolutionary biology",
      "Function (biology)",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Prediction interval",
      "Regression",
      "Regression analysis",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Lei",
        "given_name": "Haocheng"
      },
      {
        "surname": "Bellotti",
        "given_name": "Anthony"
      }
    ]
  },
  {
    "title": "Divide-and-conquer the NAS puzzle in resource-constrained federated learning systems",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.10.006",
    "abstract": "Federated Learning (FL) is a privacy-preserving distributed machine learning approach geared towards applications in edge devices. However, the problem of designing custom neural architectures in federated environments is not tackled from the perspective of overall system efficiency. In this paper, we propose DC-NAS—a divide-and-conquer approach that performs supernet-based Neural Architecture Search (NAS) in a federated system by systematically sampling the search space. We propose a novel diversified sampling strategy that balances exploration and exploitation of the search space by initially maximizing the distance between the samples and progressively shrinking this distance as the training progresses. We then perform channel pruning to reduce the training complexity at the devices further. We show that our approach outperforms several sampling strategies including Hadamard sampling, where the samples are maximally separated. We evaluate our method on the CIFAR10, CIFAR100, EMNIST, and TinyImagenet benchmarks and show a comprehensive analysis of different aspects of federated learning such as scalability, and non-IID data. DC-NAS achieves near iso-accuracy as compared to full-scale federated NAS with 50% fewer resources.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005609",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer engineering",
      "Computer science",
      "Data mining",
      "Database",
      "Detector",
      "Distributed computing",
      "Divide and conquer algorithms",
      "Enhanced Data Rates for GSM Evolution",
      "Hadamard transform",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pruning",
      "Sampling (signal processing)",
      "Scalability",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Venkatesha",
        "given_name": "Yeshwanth"
      },
      {
        "surname": "Kim",
        "given_name": "Youngeun"
      },
      {
        "surname": "Park",
        "given_name": "Hyoungseob"
      },
      {
        "surname": "Panda",
        "given_name": "Priyadarshini"
      }
    ]
  },
  {
    "title": "Corrigendum to “ Domain-adaptive Message Passing Graph Neural Network” [Neural Netw. 164 (2023) 439–454]",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.026",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005233",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Distributed computing",
      "Domain (mathematical analysis)",
      "Graph",
      "Mathematical analysis",
      "Mathematics",
      "Message passing",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Xiao"
      },
      {
        "surname": "Pan",
        "given_name": "Shirui"
      },
      {
        "surname": "Choi",
        "given_name": "Kup-Sze"
      },
      {
        "surname": "Zhou",
        "given_name": "Xi"
      }
    ]
  },
  {
    "title": "Unsupervised anomaly detection by densely contrastive learning for time series data",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.038",
    "abstract": "Time series data continuously collected by different sensors play an essential role in monitoring and predicting events in many real-world applications, and anomaly detection for time series has received increasing attention during the past decades. In this paper, we propose an anomaly detection method by densely contrasting the whole time series with its sub-sequences at different timestamps in a latent space. Our approach leverages the locality property of convolutional neural networks (CNN) and integrates position embedding to effectively capture local features for sub-sequences. Simultaneously, we employ an attention mechanism to extract global features from the entire time series. By combining these local and global features, our model is trained using both instance-level contrastive learning loss and distribution-level alignment loss. Furthermore, we introduce a reconstruction loss applied to the extracted global features to prevent the potential loss of information. To validate the efficacy of our proposed technique, we conduct experiments on publicly available time-series datasets for anomaly detection. Additionally, we evaluate our method on an in-house mobile phone dataset aimed at monitoring the status of Parkinson’s disease, all within an unsupervised learning framework. Our results demonstrate the effectiveness and potential of the proposed approach in tackling anomaly detection in time series data, offering promising applications in real-world scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005385",
    "keywords": [
      "Anomaly (physics)",
      "Anomaly detection",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Condensed matter physics",
      "Convolutional neural network",
      "Data mining",
      "Deep learning",
      "Embedding",
      "Linguistics",
      "Locality",
      "Machine learning",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Real-time computing",
      "Series (stratigraphy)",
      "Time series",
      "Timestamp",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Wei"
      },
      {
        "surname": "Li",
        "given_name": "Weijian"
      },
      {
        "surname": "Dorsey",
        "given_name": "E. Ray"
      },
      {
        "surname": "Luo",
        "given_name": "Jiebo"
      }
    ]
  },
  {
    "title": "Generalized heterophily graph data augmentation for node classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.021",
    "abstract": "Graph data augmentations have demonstrated remarkable performance on homophilic graph neural networks (GNNs). Nevertheless, when transferred to a heterophilic graph, these augmentations are less effective for GNN models and lead to reduced performance. To address this issue, we propose a unified augmentation approach called GePHo, a regularization technique for heterophilic graph neural networks based on self-supervised learning, leveraging graph data augmentation to acquire extra information to guide model learning. Specifically, we propose to generate a pseudo-homophily graph that is type-agnostic, enabling us to apply GePHo to both homophilic and heterophilic graphs. Then, we regularize the neighbors with a sharpening technique for data augmentation and generate the auxiliary pseudo-labels to classify the original GNN’s output, whose operations are to constrain the local and global node representation, respectively. Extensive experiments on three homophilic graph and six heterophilic graph datasets demonstrate the competitive effectiveness of GePHo in node classification task, and the ablation experiments verify the efficacy of our GePHo in graph data augmentation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005142",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Graph",
      "Homophily",
      "Machine learning",
      "Mathematics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Bisheng"
      },
      {
        "surname": "Chen",
        "given_name": "Xiaojun"
      },
      {
        "surname": "Wang",
        "given_name": "Shaopu"
      },
      {
        "surname": "Xuan",
        "given_name": "Yuexin"
      },
      {
        "surname": "Zhao",
        "given_name": "Zhendong"
      }
    ]
  },
  {
    "title": "Sweet Gradient matters: Designing consistent and efficient estimator for Zero-shot Architecture Search",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.012",
    "abstract": "Zero-shot Neural Architecture Search has garnered attention due to its training-free nature and rapid search speed. However, existing zero-shot estimators commonly suffer from low consistency, which hampers their practicality. In this work, we theoretically analyze that network generalization and convergence are highly correlated with Sweet Gradient of Parameter, i.e., the number of parameters whose gradient absolute values are within a certain interval. Empirical results indicate that Sweet Gradient of Parameter brings a higher consistency than the overall number of parameters. Additionally, we demonstrate a positive correlation between the network depth and the proportion of parameters with sweet gradients in each layer. Based on the analysis, we propose a training-free method to find the Sweet Gradient interval and obtain an estimator, named Sweetimator. Furthermore, Sweet Gradient can be an effective and general approach to promote the consistency of zero-shot estimators. Experiments show that Sweetimator and Sweet-enhanced estimators have significant consistency improvement in multiple benchmarks. Our method achieves state-of-the-art performance with 256x speedup in NAS-Bench-201 and maintains high competitiveness in DARTS, MobileNet, and Transformer search spaces. The source code is available at https://github.com/xingxing-123/SweetGradient.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005038",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Consistency (knowledge bases)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Estimator",
      "Generalization",
      "Gradient descent",
      "Initialization",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Operating system",
      "Programming language",
      "Speedup",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Longxing"
      },
      {
        "surname": "Fu",
        "given_name": "Yanxin"
      },
      {
        "surname": "Lu",
        "given_name": "Shun"
      },
      {
        "surname": "Sun",
        "given_name": "Zihao"
      },
      {
        "surname": "Mei",
        "given_name": "Jilin"
      },
      {
        "surname": "Zhao",
        "given_name": "Wenxiao"
      },
      {
        "surname": "Hu",
        "given_name": "Yu"
      }
    ]
  },
  {
    "title": "A multidimensional feature fusion network based on MGSE and TAAC for video-based human action recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.031",
    "abstract": "With the maturity of intelligent technology such as human-computer interaction, human action recognition (HAR) technology has been widely used in virtual reality, video surveillance, and other fields. However, the current video-based HAR methods still cannot fully extract abstract action features, and there is still a lack of action collection and recognition for special personnel such as prisoners and elderly people living alone. To solve the above problems, this paper proposes a multidimensional feature fusion network, called P-MTSC3D, a parallel network based on context modeling and temporal adaptive attention module. It consists of three branches. The first branch serves as the basic network branch, which extracts basic feature information. The second branch consists of a feature pre-extraction layer and two multiscale-convolution-based global context modeling combined squeeze and excitation (MGSE) modules, which can extract spatial and channel features. The third branch consists of two temporal adaptive attention units based on convolution (TAAC) to extract temporal dimension features. In order to verify the validity of the proposed network, this paper conducts experiments on the University of Central Florida (UCF) 101 dataset and the human motion database (HMDB) 51 dataset. The recognition accuracy of the proposed P-MTSC3D network is 97.92% on the UCF101 dataset and 75.59% on the HMDB51 dataset, respectively. The FLOPs of the P-MTSC3D network is 30.85G, and the test time is 2.83 s/16 samples on the UCF101 dataset. The experimental results demonstrate that the P-MTSC3D network has better overall performance than the state-of-the-art networks. In addition, a prison action (PA) dataset is constructed in this paper to verify the application effect of the proposed network in actual scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005270",
    "keywords": [
      "Action (physics)",
      "Action recognition",
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Feature (linguistics)",
      "Fusion",
      "Linguistics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Shuang"
      },
      {
        "surname": "Xu",
        "given_name": "Hongji"
      },
      {
        "surname": "Bai",
        "given_name": "Zhiquan"
      },
      {
        "surname": "Du",
        "given_name": "Zhengfeng"
      },
      {
        "surname": "Zeng",
        "given_name": "Jiaqi"
      },
      {
        "surname": "Wang",
        "given_name": "Yang"
      },
      {
        "surname": "Wang",
        "given_name": "Yuhao"
      },
      {
        "surname": "Li",
        "given_name": "Shijie"
      },
      {
        "surname": "Wang",
        "given_name": "Mengmeng"
      },
      {
        "surname": "Li",
        "given_name": "Yiran"
      },
      {
        "surname": "Li",
        "given_name": "Jianjun"
      },
      {
        "surname": "Xu",
        "given_name": "Jie"
      }
    ]
  },
  {
    "title": "Reward prediction-errors weighted by cue salience produces addictive behaviours in simulations, with asymmetrical learning and steeper delay discounting",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.032",
    "abstract": "Dysfunction in learning and motivational systems are thought to contribute to addictive behaviours. Previous models have suggested that dopaminergic roles in learning and motivation could produce addictive behaviours through pharmacological manipulations that provide excess dopaminergic signalling towards these learning and motivational systems. Redish (2004) suggested a role based on dopaminergic signals of value prediction error, while (Zhang et al., 2009) suggested a role based on dopaminergic signals of motivation. However, both models present significant limitations. They do not explain the reduced sensitivity to drug-related costs/negative consequences, the increased impulsivity generally found in people with a substance use disorder, craving behaviours, and non-pharmacological dependence, all of which are key hallmarks of addictive behaviours. Here, we propose a novel mathematical definition of salience, that combines aspects of dopamine’s role in both learning and motivation within the reinforcement learning framework. Using a single parameter regime, we simulated addictive behaviours that the (Zhang et al., 2009; Redish, 2004) models also produce but we went further in simulating the downweighting of drug-related negative prediction-errors, steeper delay discounting of drug rewards, craving behaviours and aspects of behavioural/non-pharmacological addictions. The current salience model builds on our recently proposed conceptual theory that salience modulates internal representation updating and may contribute to addictive behaviours by producing misaligned internal representations (Kalhan et al., 2021). Critically, our current mathematical model of salience argues that the seemingly disparate learning and motivational aspects of dopaminergic functioning may interact through a salience mechanism that modulates internal representation updating.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005282",
    "keywords": [
      "Addiction",
      "Artificial intelligence",
      "Cognitive psychology",
      "Computer science",
      "Delay discounting",
      "Developmental psychology",
      "Discounting",
      "Economics",
      "Finance",
      "Impulsivity",
      "Neuroscience",
      "Psychology",
      "Salience (neuroscience)"
    ],
    "authors": [
      {
        "surname": "Kalhan",
        "given_name": "Shivam"
      },
      {
        "surname": "Garrido",
        "given_name": "Marta I."
      },
      {
        "surname": "Hester",
        "given_name": "Robert"
      },
      {
        "surname": "Redish",
        "given_name": "A. David"
      }
    ]
  },
  {
    "title": "Understanding neural network through neuron level visualization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.030",
    "abstract": "Neurons are the fundamental units of neural networks. In this paper, we propose a method for explaining neural networks by visualizing the learning process of neurons. For a trained neural network, the proposed method obtains the features learned by each neuron and displays the features in a human-understandable form. The features learned by different neurons are combined to analyze the working mechanism of different neural network models. The method is applicable to neural networks without requiring any changes to the architectures of the models. In this study, we apply the proposed method to both Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs) trained using the backpropagation learning algorithm. We conduct experiments on models for image classification tasks to demonstrate the effectiveness of the method. Through these experiments, we gain insights into the working mechanisms of various neural network architectures and evaluate neural network interpretability from diverse perspectives.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005269",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Interpretability",
      "Machine learning",
      "Nervous system network models",
      "Operating system",
      "Pattern recognition (psychology)",
      "Physical neural network",
      "Process (computing)",
      "Recurrent neural network",
      "Time delay neural network",
      "Types of artificial neural networks",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Dou",
        "given_name": "Hui"
      },
      {
        "surname": "Shen",
        "given_name": "Furao"
      },
      {
        "surname": "Zhao",
        "given_name": "Jian"
      },
      {
        "surname": "Mu",
        "given_name": "Xinyu"
      }
    ]
  },
  {
    "title": "Dynamic sparse coding-based value estimation network for deep reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.013",
    "abstract": "Deep Reinforcement Learning (DRL) is one powerful tool for varied control automation problems. Performances of DRL highly depend on the accuracy of value estimation for states from environments. However, the Value Estimation Network (VEN) in DRL can be easily influenced by the phenomenon of catastrophic interference from environments and training. In this paper, we propose a Dynamic Sparse Coding-based (DSC) VEN model to obtain precise sparse representations for accurate value prediction and sparse parameters for efficient training, which is not only applicable in Q-learning structured discrete-action DRL but also in actor–critic structured continuous-action DRL. In detail, to alleviate interference in VEN, we propose to employ DSC to learn sparse representations for accurate value estimation with dynamic gradients beyond the conventional ℓ 1 norm that provides same-value gradients. To avoid influences from redundant parameters, we employ DSC to prune weights with dynamic thresholds more efficiently than static thresholds like ℓ 1 norm. Experiments demonstrate that the proposed algorithms with dynamic sparse coding can obtain higher control performances than existing benchmark DRL algorithms in both discrete-action and continuous-action environments, e.g., over 25% increase in Puddle World and about 10% increase in Hopper. Moreover, the proposed algorithm can reach convergence efficiently with fewer episodes in different environments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005063",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Machine learning",
      "Neural coding",
      "Pattern recognition (psychology)",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Haoli"
      },
      {
        "surname": "Li",
        "given_name": "Zhenni"
      },
      {
        "surname": "Su",
        "given_name": "Wensheng"
      },
      {
        "surname": "Xie",
        "given_name": "Shengli"
      }
    ]
  },
  {
    "title": "Tell me your position: Distantly supervised biomedical entity relation extraction using entity position marker",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.043",
    "abstract": "A significant amount of textual data has been produced in the biomedical area recently as a result of the advancement of biomedical technologies. Large-scale biomedical data can be automatically obtained with the help of distant supervision. However, the noisy data brought by distant supervision methods makes relation extraction tasks more difficult. Previous work has focused more on how to restore mislabeled relationships, but little attention has been paid to the importance of labeled entity locations for relationship extraction tasks. In this paper, we present a “four-stage” model based on BioBERT and Multi-Instance Learning by using entity position markers. Firstly, the sentence is marked with position. Secondly, BioBERT, a biomedical pre-trained language model, is used in the final sentence feature vector representation not only with the global position marker but also with the start and end marker of both the head and tail entity. Thirdly, the aggregation of sentence vectors in the bag is used as the vector feature of the bag by three aggregation methods, and the performance of different sentence feature vectors combined with different bag encoding methods is discussed. At last, relation classification is performed at the bag level. According to experimental results, the presented model significantly outperforms all baseline models and contributes to noise reduction. In addition, different bag encoding methods need to match corresponding sentence encoding representation to achieve the best performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005397",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Economics",
      "Finance",
      "Information extraction",
      "Natural language processing",
      "Pattern recognition (psychology)",
      "Position (finance)",
      "Relation (database)",
      "Relationship extraction"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Jiran"
      },
      {
        "surname": "Dong",
        "given_name": "Jikun"
      },
      {
        "surname": "Du",
        "given_name": "Hongyun"
      },
      {
        "surname": "Geng",
        "given_name": "Yanfang"
      },
      {
        "surname": "Fan",
        "given_name": "Shengyu"
      },
      {
        "surname": "Yu",
        "given_name": "Hui"
      },
      {
        "surname": "Shao",
        "given_name": "Zengzhen"
      },
      {
        "surname": "Wang",
        "given_name": "Xia"
      },
      {
        "surname": "Yang",
        "given_name": "Yaping"
      },
      {
        "surname": "Xu",
        "given_name": "Weizhi"
      }
    ]
  },
  {
    "title": "CEGAT: A CNN and enhanced-GAT based on key sample selection strategy for hyperspectral image classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.059",
    "abstract": "In recent years, the application of convolutional neural networks (CNNs) and graph convolutional networks (GCNs) in hyperspectral image classification (HSIC) has achieved remarkable results. However, the limited label samples are still a major challenge when using CNN and GCN to classify hyperspectral images. In order to alleviate this problem, a double branch fusion network of CNN and enhanced graph attention network (CEGAT) based on key sample selection strategy is proposed. First, a linear discrimination of spectral inter-class slices (LD_SICS) module is designed to eliminate spectral redundancy of HSIs. Then, a spatial spectral correlation attention (SSCA) module is proposed, which can extract and assign attention weight to the spatial and spectral correlation features. On the graph attention (GAT) branch, the HSI is segmented into some super pixels as input to reduce the amount of network parameters. In addition, an enhanced graph attention (EGAT) module is constructed to enhance the relationship between nodes. Finally, a key sample selection (KSS) strategy is proposed to enable the network to achieve better classification performance with few labeled samples. Compared with other state-of-the-art methods, CEGAT has better classification performance under limited label samples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004884",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Graph",
      "Hyperspectral imaging",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Pixel",
      "Redundancy (engineering)",
      "Selection (genetic algorithm)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Shi",
        "given_name": "Cuiping"
      },
      {
        "surname": "Wu",
        "given_name": "Haiyang"
      },
      {
        "surname": "Wang",
        "given_name": "Liguo"
      }
    ]
  },
  {
    "title": "Trust-aware conditional adversarial domain adaptation with feature norm alignment",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.10.002",
    "abstract": "Adversarial learning has proven to be an effective method for capturing transferable features for unsupervised domain adaptation. However, some existing conditional adversarial domain adaptation methods assign equal importance to different samples, ignoring the fact that hard-to-transfer samples might damage the conditional adversarial adaptation procedure. Meanwhile, some methods can only roughly align marginal distributions across domains, but cannot ensure category distributions alignment, causing classifiers to make uncertain or even wrong predictions for some target data. Furthermore, we find that the feature norms of real images usually follow a complex distribution, so directly matching the mean feature norms of two domains cannot effectively reduce the statistical discrepancy of feature norms and may potentially induce feature degradation. In this paper, we develop a Trust-aware Conditional Adversarial Domain Adaptation (TCADA) method for solving the aforementioned issues. To quantify data transferability, we suggest utilizing posterior probability modeled by a Gaussian-uniform mixture, which effectively facilitates conditional domain alignment. Based on this posterior probability, a confidence-guided alignment strategy is presented to promote precise alignment of category distributions and accelerate the learning of shared features. Moreover, a novel optimal transport-based strategy is introduced to align the feature norms and facilitate shared features becoming more informative. To encourage classifiers to make more accurate predictions for target data, we also design a mixed information-guided entropy regularization term to promote deep features being away from the decision boundaries. Extensive experiments show that our method greatly improves transfer performance on various tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005543",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Bayesian probability",
      "Computer science",
      "Conditional entropy",
      "Conditional probability",
      "Conditional probability distribution",
      "Data mining",
      "Feature (linguistics)",
      "Feature vector",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Posterior probability",
      "Principle of maximum entropy",
      "Probability distribution",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Dan",
        "given_name": "Jun"
      },
      {
        "surname": "Jin",
        "given_name": "Tao"
      },
      {
        "surname": "Chi",
        "given_name": "Hao"
      },
      {
        "surname": "Dong",
        "given_name": "Shunjie"
      },
      {
        "surname": "Xie",
        "given_name": "Haoran"
      },
      {
        "surname": "Cao",
        "given_name": "Keying"
      },
      {
        "surname": "Yang",
        "given_name": "Xinjing"
      }
    ]
  },
  {
    "title": "Symmetric LINEX loss twin support vector machine for robust classification and its fast iterative algorithm",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.055",
    "abstract": "Twin support vector machine (TSVM) is a practical machine learning algorithm, whereas traditional TSVM can be limited for data with outliers or noises. To address this problem, we propose a novel TSVM with the symmetric LINEX loss function (SLTSVM) for robust classification. There are several advantages of our method: (1) The performance of the proposed SLTSVM for data with outliers or noise can be improved by using the symmetric LINEX loss function. (2) The introduction of regularization term can effectively improve the generalization ability of our model. (3) An efficient iterative algorithm is developed to solve the optimization problems of our SLTSVM. (4) The convergence and time complexity of the iterative algorithm are analyzed in detail. Furthermore, our model does not involve loss function parameter, which makes our method more competitive. Experimental results on synthetic, benchmark and image datasets with label noises and feature noises demonstrate that our proposed method slightly outperforms other state-of-the-art methods on most datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004756",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Geodesy",
      "Geography",
      "Iterative method",
      "Mathematical optimization",
      "Mathematics",
      "Outlier",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Si",
        "given_name": "Qi"
      },
      {
        "surname": "Yang",
        "given_name": "Zhixia"
      },
      {
        "surname": "Ye",
        "given_name": "Junyou"
      }
    ]
  },
  {
    "title": "Multidomain active defense: Detecting multidomain backdoor poisoned samples via ALL-to-ALL decoupling training without clean datasets",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.036",
    "abstract": "Deep learning is vulnerable to backdoor poisoning attacks in which an attacker can easily embed a hidden backdoor into a trained model by injecting poisoned samples into the training set. Many prior state-of-the-art techniques for detecting backdoor poisoning attacks are based on a potential separability assumption. However, current adaptive poisoning strategies can significantly reduce ’distinguishable behavior’, making most prior state-of-the-art techniques less effective. In addition, we note that existing detection methods are not practical for multidomain datasets and may leak user privacy because they require and collect clean samples. To address the above issues, we propose a multidomain active defense approach that does not use clean datasets. The proposed approach can generate diverse clean samples from different domains and decouple neural networks round by round using clean samples to disassociate features and labels, making backdoor poisoned samples easier to detect without fitting clean samples. We demonstrate the advantage of our approach through an extensive evaluation of CIFAR10, CelebA, MNIST & MNIST-M, MNIST & USPS & MNIST-M, MNIST & USPS & SVHN and CIFAR10 & Tiny-ImageNet.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005324",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Backdoor",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Deep neural networks",
      "MNIST database",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Training set"
    ],
    "authors": [
      {
        "surname": "Ma",
        "given_name": "Binhao"
      },
      {
        "surname": "Wang",
        "given_name": "Jiahui"
      },
      {
        "surname": "Wang",
        "given_name": "Dejun"
      },
      {
        "surname": "Meng",
        "given_name": "Bo"
      }
    ]
  },
  {
    "title": "CompNet: Complementary network for single-channel speech enhancement",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.041",
    "abstract": "Recent multi-domain processing methods have demonstrated promising performance for monaural speech enhancement tasks. However, few of them explain why they behave better over single-domain approaches. As an attempt to fill this gap, this paper presents a complementary single-channel speech enhancement network (CompNet) that demonstrates promising denoising capabilities and provides a unique perspective to understand the improvements introduced by multi-domain processing. Specifically, the noisy speech is initially enhanced through a time-domain network. However, despite the waveform can be feasibly recovered, the distribution of the time–frequency bins may still be partly different from the target spectrum when we reconsider the problem in the frequency domain. To solve this problem, we design a dedicated dual-path network as a post-processing module to independently filter the magnitude and refine the phase. This further drives the estimated spectrum to closely approximate the target spectrum in the time–frequency domain. We conduct extensive experiments with the WSJ0-SI84 and VoiceBank + Demand datasets. Objective test results show that the performance of the proposed system is highly competitive with existing systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300535X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Computer science",
      "Computer vision",
      "Domain (mathematical analysis)",
      "Filter (signal processing)",
      "Frequency domain",
      "Mathematical analysis",
      "Mathematics",
      "Monaural",
      "Noise reduction",
      "Radar",
      "Speech enhancement",
      "Speech processing",
      "Speech recognition",
      "Telecommunications",
      "Time domain",
      "Waveform"
    ],
    "authors": [
      {
        "surname": "Fan",
        "given_name": "Cunhang"
      },
      {
        "surname": "Zhang",
        "given_name": "Hongmei"
      },
      {
        "surname": "Li",
        "given_name": "Andong"
      },
      {
        "surname": "Xiang",
        "given_name": "Wang"
      },
      {
        "surname": "Zheng",
        "given_name": "Chengshi"
      },
      {
        "surname": "Lv",
        "given_name": "Zhao"
      },
      {
        "surname": "Wu",
        "given_name": "Xiaopei"
      }
    ]
  },
  {
    "title": "Learning smooth dendrite morphological neurons by stochastic gradient descent for pattern classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.033",
    "abstract": "This article presents a learning algorithm for dendrite morphological neurons (DMN) based on stochastic gradient descent (SGD). In particular, we focus on a DMN topology that comprises spherical dendrites, smooth maximum activation function nodes, and a softmax output layer, whose original learning algorithm is performed in two independent stages: (1) dendrites’ centroids are learned by k-means, and (2) softmax layer weights are adjusted by gradient descent. A drawback of this learning method is that both stages are unplugged; once dendrites’ centroids are defined, they keep static during weights learning, so no feedback is performed to correct the dendrites’ positions to improve classification performance. To overcome this issue, we derive the delta rules for adjusting the dendrites’ centroids and the output layer weights by minimizing the cross-entropy loss function under an SGD scheme. This gradient descent-based learning is feasible because the smooth maximum activation function that interfaces the dendrite units with the output layer is differentiable. The proposed DMN is compared against eight morphological neuron models with distinct topologies and learning methods and four well-established classifiers: support vector machine (SVM), multilayer perceptron (MLP), and random forest (RF), and k-nearest neighbors (k-NN). Besides, the classification performance is evaluated on 81 datasets. The experimental results show that the proposed method tends to outperform the DMN methods and is competitive or even better than SVM, MLP, RF, and k-NN. Thus, it is an alternative approach that can effectively be used for pattern classification. Moreover, SGD for DMN learning standardizes this neural model, like current artificial neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005294",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Centroid",
      "Computer science",
      "Gradient descent",
      "Mathematics",
      "Multilayer perceptron",
      "Pattern recognition (psychology)",
      "Perceptron",
      "Softmax function",
      "Stochastic gradient descent",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Gómez-Flores",
        "given_name": "Wilfrido"
      },
      {
        "surname": "Sossa",
        "given_name": "Humberto"
      }
    ]
  },
  {
    "title": "LaenNet: Learning robust GCNs by propagating labels",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.035",
    "abstract": "Graph Convolutional Networks (GCNs) can be acknowledged as one of the most significant methodologies for graph representation learning, and the family of GCNs has recently achieved great success in the community. However, in real-world scenarios, the graph data may be imperfect, e.g., with noisy and sparse features or labels, which poses a great challenge to the robustness of GCNs. To meet this challenge, we propose a simple-yet-effective LAbel-ENhanced Networks (LaenNet) architecture for GCNs, where the basic spirit is to propagate labels together with features. Specifically, we add an extra LaenNet module at one hidden layer of GCNs, which propagates labels along the graph and then integrates them with the hidden representations as the inputs to the deeper layer. The proposed LaenNet can be directly generalized to the variants of GCNs. We conduct extensive experiments to verify LaenNet on semi-supervised node classification tasks under four noisy and sparse graph data scenarios, including the graphs with noisy features, sparse features, noisy labels, and sparse labels. Empirical results indicate the superiority and robustness of LaenNet compared to the state-of-the-art baseline models. The implementation code is available to ease reproducibility 1 1 https://github.com/Zhangcx19/LAENNet. .",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005312",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Feature learning",
      "Gene",
      "Graph",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Chunxu"
      },
      {
        "surname": "Li",
        "given_name": "Ximing"
      },
      {
        "surname": "Pei",
        "given_name": "Hongbin"
      },
      {
        "surname": "Zhang",
        "given_name": "Zijian"
      },
      {
        "surname": "Liu",
        "given_name": "Bing"
      },
      {
        "surname": "Yang",
        "given_name": "Bo"
      }
    ]
  },
  {
    "title": "RepCo: Replenish sample views with better consistency for contrastive learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.004",
    "abstract": "Contrastive learning methods aim to learn shared representations by minimizing distances between positive pairs, and maximizing distances between negative pairs in the embedding space. To achieve better performance of contrastive learning, one of the key problems is to design appropriate sample pairs. In most previous works, random cropping on the input image is utilized to obtain two views as positive pairs. However, such strategies lead to suboptimal performance since the sampled crops may have inconsistent semantic information, which consequently degrades the quality of contrastive views. To address this limitation, we explore to replenish sample views with better consistency of the image and propose a novel self-supervised learning (SSL) framework RepCo. Instead of searching for semantically consistent patches between two different views, we select patches on the same image as the replenishment of positive/negative pairs, encourage patches that are similar but come from different positions as positive pairs, and force patches that are dissimilar but come from adjacent positions to have different representations, i.e. construct negative pairs to enrich the learned representations. Our method effectively generates high-quality contrastive views, explores the untapped semantic consistency on images, and provides more informative representations for downstream tasks. Experiments on adequate downstream tasks have shown that, our approach achieves ＋2.1 AP50 (COCO pre-trained) and ＋1.6 AP50 (ImageNet pre-trained) gains on Pascal VOC object detection, ＋2.3 mIoU gains on Cityscapes semantic segmentation, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004975",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Consistency (knowledge bases)",
      "Embedding",
      "Epistemology",
      "Image (mathematics)",
      "Inversion (geology)",
      "Machine learning",
      "Natural language processing",
      "Paleontology",
      "Pascal (unit)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Quality (philosophy)",
      "Sample (material)",
      "Segmentation",
      "Similarity (geometry)",
      "Structural basin"
    ],
    "authors": [
      {
        "surname": "Lei",
        "given_name": "Xinyu"
      },
      {
        "surname": "Liu",
        "given_name": "Longjun"
      },
      {
        "surname": "Zhang",
        "given_name": "Yi"
      },
      {
        "surname": "Jia",
        "given_name": "Puhang"
      },
      {
        "surname": "Zhang",
        "given_name": "Haonan"
      },
      {
        "surname": "Zheng",
        "given_name": "Nanning"
      }
    ]
  },
  {
    "title": "Single image denoising with a feature-enhanced network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.056",
    "abstract": "Recent Transformer-based networks have shown impressive performance on single image denoising tasks. While the Transformer model promotes the interaction of long-range features, it generally involves high computational complexity. In this paper, we propose a feature-enhanced denoising network (FEDNet) by combining CNN architectures with Transformers. Specifically, we propose an effective cross-channel attention to boost the interaction of channel information and enhance channel features. In order to fully exploit image features, we incorporate Transformer blocks into minimum-scale layers of the network, which can not only capture the long-distance dependency of low-resolution features but also reduce the multiplier-accumulator operations (MACs). Meanwhile, a structure-preserving block is designed to enhance the structural feature extraction. Experimental results on both synthetic and real-world datasets demonstrate that our model can achieve the state-of-the-art denoising performance with low computational costs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004859",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Electrical engineering",
      "Engineering",
      "Exploit",
      "Feature extraction",
      "Noise reduction",
      "Pattern recognition (psychology)",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Zhuge",
        "given_name": "Ruibin"
      },
      {
        "surname": "Wang",
        "given_name": "Jinghua"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      }
    ]
  },
  {
    "title": "UNIMEMnet: Learning long-term motion and appearance dynamics for video prediction with a unified memory network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.024",
    "abstract": "As a pixel-wise dense forecast task, video prediction is challenging due to its high computation complexity, dramatic future uncertainty, and extremely complicated spatial–temporal patterns. Many deep learning methods are proposed for the task, which bring up significant improvements. However, they focus on modeling short-term spatial–temporal dynamics and fail to sufficiently exploit long-term ones. As a result, the methods tend to deliver unsatisfactory performance for a long-term forecast requirement. In this article, we propose a novel unified memory network (UNIMEMnet) for long-term video prediction, which can effectively exploit long-term motion-appearance dynamics and unify the short-term spatial–temporal dynamics and long-term ones in an architecture. In the UNIMEMnet, a dual branch multi-scale memory module is carefully designed to extract and preserve long-term spatial–temporal patterns. In addition, a short-term spatial–temporal dynamics module and an alignment and fusion module are devised to capture and coordinate short-term motion-appearance dynamics with long-term ones from our designed memory module. Extensive experiments on five video prediction datasets from both synthetic and real-world scenarios are conducted, which validate the effectiveness and superiority of our proposed method UNIMEMnet over state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005178",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Dynamics (music)",
      "Long short term memory",
      "Motion (physics)",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Recurrent neural network",
      "Term (time)"
    ],
    "authors": [
      {
        "surname": "Dai",
        "given_name": "Kuai"
      },
      {
        "surname": "Li",
        "given_name": "Xutao"
      },
      {
        "surname": "Luo",
        "given_name": "Chuyao"
      },
      {
        "surname": "Chen",
        "given_name": "Wuqiao"
      },
      {
        "surname": "Ye",
        "given_name": "Yunming"
      },
      {
        "surname": "Feng",
        "given_name": "Shanshan"
      }
    ]
  },
  {
    "title": "An Adversarial Time–Frequency Reconstruction Network for Unsupervised Anomaly Detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.018",
    "abstract": "Detecting anomalies in massive volumes of multivariate time series data, particularly in the IoT domain, is critical for maintaining stable systems. Existing anomaly detection models based on reconstruction techniques face challenges in distinguishing normal and abnormal samples from unlabeled data, leading to performance degradation. Moreover, accurately reconstructing abnormal values and pinpointing anomalies remains a limitation. To address these issues, we introduce the Adversarial Time–Frequency Reconstruction Network for Unsupervised Anomaly Detection (ATF-UAD). ATF-UAD consists of a time reconstructor, a frequency reconstructor and a dual-view adversarial learning mechanism. The time reconstructor utilizes a parity sampling mechanism to weaken the dependency between neighboring points. Then attention mechanisms and graph convolutional networks (GCNs) are used to update the feature information for each point, which combines points with close feature relationships and dilutes the influence of abnormal points on normal points. The frequency reconstructor transforms the input sequence into the frequency domain using a Fourier transform and extracts the relationship between frequencies to reconstruct anomalous frequency bands. The dual-view adversarial learning mechanism aims to maximize the normal values in the reconstructed sequences and highlight anomalies and aid in their localization within the data. Through dual-view adversarial learning, ATF-UAD minimizes reconstructed value errors and maximizes the identification of residual outliers. We conducted extensive experiments on nine datasets from different domains, and ATF-UAD showed an average improvement of 6.94% in terms of F1 score compared to the state-of-the-art method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005117",
    "keywords": [
      "Algorithm",
      "Anomaly detection",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Frequency domain",
      "Outlier",
      "Pattern recognition (psychology)",
      "Residual",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Fan",
        "given_name": "Jin"
      },
      {
        "surname": "Wang",
        "given_name": "Zehao"
      },
      {
        "surname": "Wu",
        "given_name": "Huifeng"
      },
      {
        "surname": "Sun",
        "given_name": "Danfeng"
      },
      {
        "surname": "Wu",
        "given_name": "Jia"
      },
      {
        "surname": "Lu",
        "given_name": "Xin"
      }
    ]
  },
  {
    "title": "Cross-domain policy adaptation with dynamics alignment",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.025",
    "abstract": "The implementation of robotic reinforcement learning is hampered by problems such as an unspecified reward function and high training costs. Many previous works have used cross-domain policy transfer to obtain the policy of the problem domain. However, these researches require paired and aligned dynamics trajectories or other interactions with the environment. We propose a cross-domain dynamics alignment framework for the problem domain policy acquisition that can transfer the policy trained in the source domain to the problem domain. Our framework aims to learn dynamics alignment across two domains that differ in agents’ physical parameters (armature, rotation range, or torso mass) or agents’ morphologies (limbs). Most importantly, we learn dynamics alignment between two domains using unpaired and unaligned dynamics trajectories. For these two scenarios, we propose a cross-physics-domain policy adaptation algorithm (CPD) and a cross-morphology-domain policy adaptation algorithm (CMD) based on our cross-domain dynamics alignment framework. In order to improve the performance of policy in the source domain so that a better policy can be transferred to the problem domain, we propose the Boltzmann TD3 (BTD3) algorithm. We conduct diverse experiments on agent continuous control domains to demonstrate the performance of our approaches. Experimental results show that our approaches can obtain better policies and higher rewards for the agents in the problem domains even when the dataset of the problem domain is small.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004446",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Domain (mathematical analysis)",
      "Mathematical analysis",
      "Mathematics",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Gui",
        "given_name": "Haiyuan"
      },
      {
        "surname": "Pang",
        "given_name": "Shanchen"
      },
      {
        "surname": "Yu",
        "given_name": "Shihang"
      },
      {
        "surname": "Qiao",
        "given_name": "Sibo"
      },
      {
        "surname": "Qi",
        "given_name": "Yufeng"
      },
      {
        "surname": "He",
        "given_name": "Xiao"
      },
      {
        "surname": "Wang",
        "given_name": "Min"
      },
      {
        "surname": "Zhai",
        "given_name": "Xue"
      }
    ]
  },
  {
    "title": "Adversarial attacks and defenses using feature-space stochasticity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.022",
    "abstract": "Recent studies in deep neural networks have shown that injecting random noise in the input layer of the networks contributes towards ℓ p -norm-bounded adversarial perturbations. However, to defend against unrestricted adversarial examples, most of which are not ℓ p -norm-bounded in the input layer, such input-layer random noise may not be sufficient. In the first part of this study, we generated a novel class of unrestricted adversarial examples termed feature-space adversarial examples. These examples are far from the original data in the input space but adjacent to the original data in a hidden-layer feature space and far again in the output layer. In the second part of this study, we empirically showed that while injecting random noise in the input layer was unable to defend these feature-space adversarial examples, they were defended by injecting random noise in the hidden layer. These results highlight the novel benefit of stochasticity in higher layers, in that it is useful for defending against these feature-space adversarial examples, a class of unrestricted adversarial examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004422",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Bounded function",
      "Chemistry",
      "Class (philosophy)",
      "Computer science",
      "Feature (linguistics)",
      "Feature vector",
      "Image (mathematics)",
      "Law",
      "Layer (electronics)",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Noise (video)",
      "Norm (philosophy)",
      "Operating system",
      "Organic chemistry",
      "Philosophy",
      "Political science",
      "Space (punctuation)"
    ],
    "authors": [
      {
        "surname": "Ukita",
        "given_name": "Jumpei"
      },
      {
        "surname": "Ohki",
        "given_name": "Kenichi"
      }
    ]
  },
  {
    "title": "Visual question generation for explicit questioning purposes based on target objects",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.007",
    "abstract": "Visual question generation aims to focus on some target objects in an image to generate questions with certain questioning purposes. Existing studies mainly utilize an answer to extract the target object corresponding to the questioning purpose for questioning. However, answers fail to accurately and completely map to every target object, such as the objects corresponding to the answer are ambiguous or the answers are the relationship between multiple objects. To address this problem, we propose a content-controlled question generation model, which generates questions based on a given target object set specified from an image. Considering that the target objects have different contributions during the generation process, we design a recurrent generative architecture to explicitly control attention to different objects and their corresponding image information at each generative stage. Extensive experiments on the VQA v2.0 dataset and the Visual7w dataset show that the proposed model outperforms the state-of-the-art models and can controllably generate questions with specified content.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004264",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Focus (optics)",
      "Generative grammar",
      "Generative model",
      "Image (mathematics)",
      "Object (grammar)",
      "Optics",
      "Physics",
      "Process (computing)",
      "Programming language",
      "Set (abstract data type)",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Jiayuan"
      },
      {
        "surname": "Chen",
        "given_name": "Jiali"
      },
      {
        "surname": "Fang",
        "given_name": "Wenhao"
      },
      {
        "surname": "Cai",
        "given_name": "Yi"
      },
      {
        "surname": "Li",
        "given_name": "Qing"
      }
    ]
  },
  {
    "title": "Graph embedding based multi-label Zero-shot Learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.023",
    "abstract": "Multi-label Zero-shot Learning (ZSL) is more reasonable and realistic than standard single-label ZSL because several objects can co-exist in a natural image in real scenarios. Intra-class feature entanglement is a significant factor influencing the alignment of visual and semantic features, resulting in the model’s inability to recognize unseen samples comprehensively and completely. We observe that existing multi-label ZSL methods place a greater emphasis on attention-based refinement and decoupling of visual features, while ignoring the relationship between label semantics. Relying on label correlations to solve multi-label ZSL tasks has not been deeply studied. In this paper, we make full use of the co-occurrence relationship between category labels and build a directed weighted semantic graph based on statistics and prior knowledge, in which node features represent category semantics and weighted edges represent conditional probabilities of label co-occurrence. To guide the targeted extraction of visual features, node features and edge set weights are simultaneously updated and refined, and embedded into the visual feature extraction network from a global and local perspective. The proposed method’s effectiveness was demonstrated by simulation results on two challenging multi-label ZSL benchmarks: NUS-WIDE and Open Images. In comparison to state-of-the-art models, our model achieves an absolute gain of 2.4% mAP on NUS-WIDE and 2.1% mAP on Open Images respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004409",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Discrete mathematics",
      "Embedding",
      "Engineering",
      "Graph",
      "Machine learning",
      "Mathematics",
      "Node (physics)",
      "Open set",
      "Pattern recognition (psychology)",
      "Programming language",
      "Semantics (computer science)",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Haigang"
      },
      {
        "surname": "Meng",
        "given_name": "Xianglong"
      },
      {
        "surname": "Cao",
        "given_name": "Weipeng"
      },
      {
        "surname": "Liu",
        "given_name": "Ye"
      },
      {
        "surname": "Ming",
        "given_name": "Zhong"
      },
      {
        "surname": "Yang",
        "given_name": "Jinfeng"
      }
    ]
  },
  {
    "title": "A novel neural network for improved in-hospital mortality prediction with irregular and incomplete multivariate data",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.033",
    "abstract": "Accurate estimation of in-hospital mortality based on patients’ physiological time series data improves the performance of the clinical decision support systems and assists hospital providers in allocating resources. In practice, the data quality issues of missing values are ubiquitous in electronic health records (EHRs). Since the vital signs are usually observed with irregular temporal intervals and different sampling rates, it is challenging to predict clinical outcomes with sparse and incomplete multivariate time series. We propose an auto-regressive recurrent neural network (RNN) based model, dubbed the bi-directional recursive encoder–decoder network (BiRED), to jointly perform data imputation and mortality prediction. To capture complex patterns of medical time sequences, a 2D cross-regression with an RNN unit (2DCR-RNN) and an imputation block with an RNN unit (IB-RNN) are designed as the recurrent component of the encoder and decoder, respectively. Furthermore, a state initialization method is proposed to alleviate errors accumulated in the generated sequence. The experimental results on two real EHR datasets show that our proposed method can predict hospital mortality with high AUC scores.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300391X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Machine learning",
      "Multivariate analysis",
      "Multivariate statistics",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Xi"
      },
      {
        "surname": "Xiang",
        "given_name": "Wei"
      },
      {
        "surname": "Huang",
        "given_name": "Tao"
      }
    ]
  },
  {
    "title": "Novel results on asymptotic stability and synchronization of fractional-order memristive neural networks with time delays: The 0 < δ ≤ 1 case",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.007",
    "abstract": "This paper investigates the asymptotic stability and synchronization of fractional-order (FO) memristive neural networks with time delays. Based on the FO comparison principle and inverse Laplace transform method, the novel sufficient conditions for the asymptotic stability of a FO nonlinear system are given. Then, based on the above conclusions, the sufficient conditions for the asymptotic stability and synchronization of FO memristive neural networks with time delays are investigated. The results in this paper have a wider coverage of situations and are more practical than the previous related results. Finally, the validity of the results is checked by two examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005002",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Economics",
      "Exponential stability",
      "Finance",
      "Geometry",
      "Inverse",
      "Laplace transform",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Order (exchange)",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Jia-Rui"
      },
      {
        "surname": "Lu",
        "given_name": "Jun-Guo"
      },
      {
        "surname": "Jin",
        "given_name": "Xiao-Chuang"
      },
      {
        "surname": "Yang",
        "given_name": "Xing-Yu"
      }
    ]
  },
  {
    "title": "DEBI-NN: Distance-encoding biomorphic-informational neural networks for minimizing the number of trainable parameters",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.026",
    "abstract": "Modern artificial intelligence (AI) approaches mainly rely on neural network (NN) or deep NN methodologies. However, these approaches require large amounts of data to train, given, that the number of their trainable parameters has a polynomial relationship to their neuron counts. This property renders deep NNs challenging to apply in fields operating with small, albeit representative datasets such as healthcare. In this paper, we propose a novel neural network architecture which trains spatial positions of neural soma and axon pairs, where weights are calculated by axon-soma distances of connected neurons. We refer to this method as distance-encoding biomorphic-informational (DEBI) neural network. This concept significantly minimizes the number of trainable parameters compared to conventional neural networks. We demonstrate that DEBI models can yield comparable predictive performance in tabular and imaging datasets, where they require a fraction of trainable parameters compared to conventional NNs, resulting in a highly scalable solution.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300446X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Database",
      "Deep neural networks",
      "Encoding (memory)",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Scalability",
      "Soma"
    ],
    "authors": [
      {
        "surname": "Papp",
        "given_name": "Laszlo"
      },
      {
        "surname": "Haberl",
        "given_name": "David"
      },
      {
        "surname": "Ecsedi",
        "given_name": "Boglarka"
      },
      {
        "surname": "Spielvogel",
        "given_name": "Clemens P."
      },
      {
        "surname": "Krajnc",
        "given_name": "Denis"
      },
      {
        "surname": "Grahovac",
        "given_name": "Marko"
      },
      {
        "surname": "Moradi",
        "given_name": "Sasan"
      },
      {
        "surname": "Drexler",
        "given_name": "Wolfgang"
      }
    ]
  },
  {
    "title": "Event fusion photometric stereo network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.009",
    "abstract": "Photometric stereo methods typically rely on RGB cameras and are usually performed in a dark room to avoid ambient illumination. Ambient illumination poses a great challenge in photometric stereo due to the restricted dynamic range of the RGB cameras. To address this limitation, we present a novel method, namely Event Fusion Photometric Stereo Network (EFPS-Net), which estimates the surface normals of an object in an ambient light environment by utilizing a deep fusion of RGB and event cameras. The high dynamic range of event cameras provides a broader perspective of light representations that RGB cameras cannot provide. Specifically, we propose an event interpolation method to obtain ample light information, which enables precise estimation of the surface normals of an object. By using RGB-event fused observation maps, our EFPS-Net outperforms previous state-of-the-art methods that depend only on RGB frames, resulting in a 7.94% reduction in mean average error. In addition, we curate a novel photometric stereo dataset by capturing objects with RGB and event cameras under numerous ambient light environments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300429X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Event (particle physics)",
      "Image (mathematics)",
      "Perspective (graphical)",
      "Photometric stereo",
      "Physics",
      "Quantum mechanics",
      "RGB color model"
    ],
    "authors": [
      {
        "surname": "Ryoo",
        "given_name": "Wonjeong"
      },
      {
        "surname": "Nam",
        "given_name": "Giljoo"
      },
      {
        "surname": "Hyun",
        "given_name": "Jae-Sang"
      },
      {
        "surname": "Kim",
        "given_name": "Sangpil"
      }
    ]
  },
  {
    "title": "Mathematical expression recognition using a new deep neural model",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.045",
    "abstract": "In this paper, we propose a novel deep neural model for Mathematical Expression Recognition (MER). The proposed model uses encoder–decoder transformer architecture that is supported by additional pre/post-processing modules, to recognize the image of mathematical formula and convert it to a well-formed language. A novel pre-processing module based on domain prior knowledge is proposed to generate random pads around the formula’s image to create more efficient feature maps and keeps all the encoder neurons active during the training process. Also, a new post-processing module is developed which uses a sliding window to extract additional position-based information from the feature map, that is proved to be useful in the recognition process. The recurrent decoder module uses the combination of feature maps and the additional position-based information, which takes advantage of a soft attention mechanism, to extract the formula context into the LaTeX well-formed language. Finally, a novel Reinforcement Learning (RL) module processes the decoder output and tunes its results by sending proper feedbacks to the previous steps. The experimental results on im2latex-100k benchmark dataset indicate that each devised pre/post-processing as well as the RL refinement module has a positive effect on the performance of the proposed model. The results also demonstrate the higher accuracy of the proposed model compared to the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004653",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Expression (computer science)",
      "Pattern recognition (psychology)",
      "Programming language"
    ],
    "authors": [
      {
        "surname": "Mirkazemy",
        "given_name": "Abolfazl"
      },
      {
        "surname": "Adibi",
        "given_name": "Peyman"
      },
      {
        "surname": "Ehsani",
        "given_name": "Seyed Mohhamad Saied"
      },
      {
        "surname": "Darvishy",
        "given_name": "Alireza"
      },
      {
        "surname": "Hutter",
        "given_name": "Hans-Peter"
      }
    ]
  },
  {
    "title": "Information theoretic perspective on sample complexity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.032",
    "abstract": "The statistical supervised learning framework assumes an input–output set with a joint probability distribution that is reliably represented by the training dataset. The learning system is then required to output a prediction rule learned from the training dataset’s input–output pairs. In this work, we investigate the relationship between the sample complexity, the empirical risk and the generalization error based on the asymptotic equipartition property (AEP) (Shannon, 1948). We provide theoretical guarantees for reliable learning under the information-theoretic AEP, with respect to the generalization error and the sample size in different settings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004537",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Empirical risk minimization",
      "Epistemology",
      "Generalization",
      "Generalization error",
      "Joint probability distribution",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Perspective (graphical)",
      "Philosophy",
      "Programming language",
      "Property (philosophy)",
      "Sample (material)",
      "Sample complexity",
      "Sample size determination",
      "Set (abstract data type)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Pereg",
        "given_name": "Deborah"
      }
    ]
  },
  {
    "title": "Learning dynamic spatial-temporal regularized correlation filter tracking with response deviation suppression via multi-feature fusion",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.019",
    "abstract": "Visual object tracking (VOT) for intelligent video surveillance has attracted great attention in the current research community, thanks to advances in computer vision and camera technology. Meanwhile, discriminative correlation filter (DCF) trackers garnered significant interest owing to their high accuracy and low computing cost. Many researchers have introduced spatial and temporal regularization into the DCF framework to achieve a more robust appearance model and further improve tracking performance. However, these algorithms typically set fixed spatial and temporal regularization parameters, which limit flexibility and adaptability under cluttered and challenging scenarios. To overcome these problems, in this work, we propose a new dynamic spatial–temporal regularization for the DCF tracking model that emphasizes the filter to concentrate on more reliable regions during the training stage. Furthermore, we present a response deviation-suppressed regularization term for responses to encourage temporal consistency and avoid model degradation by suppressing relative response changes between two consecutive frames. Moreover, we introduce a multi-memory tracking framework to exploit various features and each memory contributes to tracking the target across all frames. Significant experiments on the OTB-2013, OTB-2015, TC-128, UAV-123, UAVDT, and DTB-70 datasets have revealed that the performance thereof outperformed many state-of-the-art trackers based on DCF and deep-based frameworks in terms of tracking accuracy and tracking success rate.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004380",
    "keywords": [
      "Artificial intelligence",
      "BitTorrent tracker",
      "Computer science",
      "Computer vision",
      "Discriminative model",
      "Eye tracking",
      "Filter (signal processing)",
      "Kalman filter",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Video tracking"
    ],
    "authors": [
      {
        "surname": "Moorthy",
        "given_name": "Sathishkumar"
      },
      {
        "surname": "Joo",
        "given_name": "Young Hoon"
      }
    ]
  },
  {
    "title": "Causal multi-label learning for image classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.052",
    "abstract": "In this paper, we investigate the problem of causal image classification with multi-label learning. As multi-label learning involves a diversity of supervision signals, it is considered a challenging issue to solve. Previous approaches have attempted to improve performance by identifying label-related image areas or exploiting the co-occurrence of labels. However, these methods are often characterized by complicated procedures, tedious computations, and a lack of intuitive interpretations. To overcome these limitations, we propose a novel approach that incorporates the concept of causal inference, which has been shown to be beneficial in other computer vision problems. Our method, called causal multi-label learning (CMLL), enables the selection of multiple objects from the original image through a multi-class attention module. These objects are then subjected to causal intervention to learn the causal relationships between different labels. Our proposed approach is both elegant and effective, with low computational cost and few parameters required for the multi-class causal intervention approach. Extensive tests and ablation studies demonstrate that the proposed method significantly improves prediction performance without a significant increase in training and inference times.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004732",
    "keywords": [
      "Artificial intelligence",
      "Causal inference",
      "Class (philosophy)",
      "Computer science",
      "Contextual image classification",
      "Econometrics",
      "Image (mathematics)",
      "Inference",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Selection (genetic algorithm)"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Yingjie"
      },
      {
        "surname": "Bai",
        "given_name": "Kunlong"
      },
      {
        "surname": "Yu",
        "given_name": "Xiaotong"
      },
      {
        "surname": "Zhu",
        "given_name": "Siyu"
      }
    ]
  },
  {
    "title": "HMM-GDAN: Hybrid multi-view and multi-scale graph duplex-attention networks for drug response prediction in cancer",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.036",
    "abstract": "Precision medicine is devoted to discovering personalized therapy for complex and difficult diseases like cancer. Many machine learning approaches have been developed for drug response prediction towards precision medicine. Notwithstanding, genetic profiles based multi-view graph learning schemes have not yet been explored for drug response prediction in previous works. Furthermore, multi-scale latent feature fusion is not considered sufficiently in the existing frameworks of graph neural networks (GNNs). Previous works on drug response prediction mainly depend on sequence data or single-view graph data. In this paper, we propose to construct multi-view graph by means of multi-omics data and STRING protein–protein association data, and develop a new architecture of GNNs for drug response prediction in cancer. Specifically, we propose hybrid multi-view and multi-scale graph duplex-attention networks (HMM-GDAN), in which both multi-view self-attention mechanism and view-level attention mechanism are devised to capture the complementary information of views and emphasize on the importance of each view collaboratively, and rich multi-scale features are constructed and integrated to further form high-level representations for better prediction. Experiments on GDSC2 dataset verify the superiority of the proposed HMM-GDAN when compared with state-of-the-art baselines. The effectiveness of multi-view and multi-scale strategies is demonstrated by the ablation study.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004562",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Data-driven",
      "Graph",
      "Hidden Markov model",
      "Machine learning",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Youfa"
      },
      {
        "surname": "Tong",
        "given_name": "Shufan"
      },
      {
        "surname": "Chen",
        "given_name": "Yongyong"
      }
    ]
  },
  {
    "title": "LJIR: Learning Joint-Action Intrinsic Reward in cooperative multi-agent reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.016",
    "abstract": "Effective exploration is the key to achieving high returns for reinforcement learning. Agents must explore jointly in multi-agent systems to find the optimal joint policy. Due to the exploration problem and the shared reward, the policy-based multi-agent reinforcement learning algorithms face policy overfitting, which may lead to the joint policy falling into a local optimum. This paper introduces a novel general framework called Learning Joint-Action Intrinsic Reward (LJIR) for improving multi-agent reinforcement learners’ joint exploration ability and performance. LJIR observes agents’ state and joint actions to learn to construct an intrinsic reward online that can guide effective joint exploration. With the novel combination of Transformer and random network distillation, LJIR selects the novel states to give more intrinsic rewards, which help agents find the best joint actions. LJIR can dynamically adjust the weight of exploration and exploitation during training and keep the policy invariance finally. To ensure LJIR seamlessly adopts existing MARL algorithms, we also provide a flexible combination method for intrinsic and external rewards. Empirical results on the SMAC benchmark show that the proposed method achieves state-of-the-art performance in challenging tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004355",
    "keywords": [
      "Architectural engineering",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Construct (python library)",
      "Engineering",
      "Geodesy",
      "Geography",
      "Joint (building)",
      "Machine learning",
      "Overfitting",
      "Programming language",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Zihan"
      },
      {
        "surname": "Luo",
        "given_name": "Biao"
      },
      {
        "surname": "Hu",
        "given_name": "Tianmeng"
      },
      {
        "surname": "Xu",
        "given_name": "Xiaodong"
      }
    ]
  },
  {
    "title": "Adaptive optimal control of affine nonlinear systems via identifier–critic neural network approximation with relaxed PE conditions",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.044",
    "abstract": "This paper considers an optimal control of an affine nonlinear system with unknown system dynamics. A new identifier–critic framework is proposed to solve the optimal control problem. Firstly, a neural network identifier is built to estimate the unknown system dynamics, and a critic NN is constructed to solve the Hamiltonian–Jacobi–Bellman equation associated with the optimal control problem. A dynamic regressor extension and mixing technique is applied to design the weight update laws with relaxed persistence of excitation conditions for the two classes of neural networks. The parameter estimation of the update laws and the stability of the closed-loop system under the adaptive optimal control are analyzed using a Lyapunov function method. Numerical simulation results are presented to demonstrate the effectiveness of the proposed IC learning based optimal control algorithm for the affine nonlinear system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004641",
    "keywords": [
      "Adaptive control",
      "Affine transformation",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Identifier",
      "Lyapunov function",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Optimal control",
      "Physics",
      "Programming language",
      "Pure mathematics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Luo",
        "given_name": "Rui"
      },
      {
        "surname": "Peng",
        "given_name": "Zhinan"
      },
      {
        "surname": "Hu",
        "given_name": "Jiangping"
      },
      {
        "surname": "Ghosh",
        "given_name": "Bijoy Kumar"
      }
    ]
  },
  {
    "title": "Active learning based on similarity level histogram and adaptive-scale sampling for very high resolution image classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.012",
    "abstract": "In remote sensing image classification, active learning aims to obtain an excellent classification model by selecting informative or representative training samples. However, due to the complexity of remote sensing images, the same class of ground objects usually have different spectral representations. The existing active learning methods may not take into account diverse representations of the same targets, which leads to a possible lack of intra-class diversity in the collected samples. To alleviate this problem, we propose an active learning method based on similarity level histogram (SLH) and adaptive-scale sampling to improve very high resolution remote sensing image classification. Specifically, we construct a SLH for each class of ground objects to effectively consider the intra-class diversity of the same target. To avoid the problem of sample imbalance caused by over-sampling or under-sampling, we design an adaptive-scale sampling strategy. Then, we utilize active learning to mine representative samples from each SLH warehouse according to adaptive-scale sampling strategies until the iteration condition is satisfied. Experiments show that the proposed algorithm can achieve better classification performance with limited training samples and is competitive with other methods based on four sets of publicly available data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004306",
    "keywords": [
      "Active learning (machine learning)",
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Computer vision",
      "Contextual image classification",
      "Data mining",
      "Filter (signal processing)",
      "Histogram",
      "Image (mathematics)",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Sampling (signal processing)",
      "Scale (ratio)",
      "Similarity (geometry)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Guangfei"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Learning domain invariant representations by joint Wasserstein distance minimization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.028",
    "abstract": "Domain shifts in the training data are common in practical applications of machine learning; they occur for instance when the data is coming from different sources. Ideally, a ML model should work well independently of these shifts, for example, by learning a domain-invariant representation. However, common ML losses do not give strong guarantees on how consistently the ML model performs for different domains, in particular, whether the model performs well on a domain at the expense of its performance on another domain. In this paper, we build new theoretical foundations for this problem, by contributing a set of mathematical relations between classical losses for supervised ML and the Wasserstein distance in joint space (i.e. representation and output space). We show that classification or regression losses, when combined with a GAN-type discriminator between domains, form an upper-bound to the true Wasserstein distance between domains. This implies a more invariant representation and also more stable prediction performance across domains. Theoretical results are corroborated empirically on several image datasets. Our proposed approach systematically produces the highest minimum classification accuracy across domains, and the most invariant representation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003866",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Detector",
      "Discriminator",
      "Domain (mathematical analysis)",
      "Feature learning",
      "Invariant (physics)",
      "Law",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematical physics",
      "Mathematics",
      "Minification",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Regression",
      "Representation (politics)",
      "Statistics",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Andéol",
        "given_name": "Léo"
      },
      {
        "surname": "Kawakami",
        "given_name": "Yusei"
      },
      {
        "surname": "Wada",
        "given_name": "Yuichiro"
      },
      {
        "surname": "Kanamori",
        "given_name": "Takafumi"
      },
      {
        "surname": "Müller",
        "given_name": "Klaus-Robert"
      },
      {
        "surname": "Montavon",
        "given_name": "Grégoire"
      }
    ]
  },
  {
    "title": "Adaptive dynamic programming-based hierarchical decision-making of non-affine systems",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.044",
    "abstract": "In this paper, the problem of multiplayer hierarchical decision-making problem for non-affine systems is solved by adaptive dynamic programming. Firstly, the control dynamics are obtained according to the theory of dynamic feedback and combined with the original system dynamics to construct the affine augmented system. Thus, the non-affine multiplayer system is transformed into a general affine form. Then, the hierarchical decision problem is modeled as a Stackelberg game. In the Stackelberg game, the leader makes a decision based on the information of all followers, whereas the followers do not know each other’s information and only obtain their optimal control strategy based on the leader’s decision. Then, the augmented system is reconstructed by a neural network (NN) using input–output data. Moreover, a single critic NN is used to approximate the value function to obtain the optimal control strategy for each player. An extra term added to the weight update law makes the initial admissible control law no longer needed. According to the Lyapunov theory, the state of the system and the error of the weights of the NN are both uniformly ultimately bounded. Finally, the feasibility and validity of the algorithm are confirmed by simulation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004021",
    "keywords": [
      "Affine transformation",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Bounded function",
      "Computer science",
      "Dynamic programming",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematical economics",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Stackelberg competition"
    ],
    "authors": [
      {
        "surname": "Lin",
        "given_name": "Danyu"
      },
      {
        "surname": "Xue",
        "given_name": "Shan"
      },
      {
        "surname": "Liu",
        "given_name": "Derong"
      },
      {
        "surname": "Liang",
        "given_name": "Mingming"
      },
      {
        "surname": "Wang",
        "given_name": "Yonghua"
      }
    ]
  },
  {
    "title": "Dichotomy value iteration with parallel learning design towards discrete-time zero-sum games",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.009",
    "abstract": "In this paper, a novel parallel learning framework is developed to solve zero-sum games for discrete-time nonlinear systems. Briefly, the purpose of this study is to determine a tentative function according to the prior knowledge of the value iteration (VI) algorithm. The learning process of the parallel controllers can be guided by the tentative function. That is to say, the neighborhood of the optimal cost function can be compressed within a small range via two typical exploration policies. Based on the parallel learning framework, a novel dichotomy VI algorithm is established to accelerate the learning speed. It is shown that the parallel controllers will converge to the optimal policy from contrary initial policies. Finally, two typical systems are used to demonstrate the learning performance of the constructed dichotomy VI algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023005026",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Biology",
      "Composite material",
      "Computer science",
      "Discrete time and continuous time",
      "Evolutionary biology",
      "Function (biology)",
      "Function approximation",
      "Linguistics",
      "Machine learning",
      "Materials science",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Philosophy",
      "Physics",
      "Process (computing)",
      "Q-learning",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Reinforcement learning",
      "Statistics",
      "Value (mathematics)",
      "Zero (linguistics)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jiangyu"
      },
      {
        "surname": "Wang",
        "given_name": "Ding"
      },
      {
        "surname": "Li",
        "given_name": "Xin"
      },
      {
        "surname": "Qiao",
        "given_name": "Junfei"
      }
    ]
  },
  {
    "title": "Sampled-data exponential consensus of multi-agent systems with Lipschitz nonlinearities",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.003",
    "abstract": "In this paper, the exponential consensus of leaderless and leader-following multi-agent systems with Lipschitz nonlinear dynamics is illustrated with aperiodic sampled-data control using a two-sided loop-based Lyapunov functional (LBLF). Firstly, applying input delay approach to reformulate the resulting sampled-data system as a continuous system with time-varying delay in the control input. A two-sided LBLF which captures the information on sampled-data pattern is constructed and the symmetry of the Laplacian matrix together with Newton–Leibniz formula have been employed to obtain reduced number of decision variables and decreased LMI dimensions for the exponential sampled-data consensus problem. Subsequently, an aperiodic sampled-data controller was designed to simplify and enhance stability conditions for computation and optimization purposes in the proposed approach. Finally, based on the controller design, simulation examples including the power system are proposed to illustrate the theoretical analysis, moreover, a larger sampled-data interval can be acquired by this method than other literature, thereby conserving bandwidth and reducing communication resources.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004951",
    "keywords": [
      "Agronomy",
      "Aperiodic graph",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Consensus",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Exponential stability",
      "Graph",
      "Laplacian matrix",
      "Lipschitz continuity",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Multi-agent system",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Wenqing"
      },
      {
        "surname": "Chen",
        "given_name": "Guoliang"
      },
      {
        "surname": "Xie",
        "given_name": "Xiangpeng"
      },
      {
        "surname": "Xia",
        "given_name": "Jianwei"
      },
      {
        "surname": "Park",
        "given_name": "Ju H."
      }
    ]
  },
  {
    "title": "LJIR: Learning Joint-Action Intrinsic Reward in cooperative multi-agent reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.016",
    "abstract": "Effective exploration is the key to achieving high returns for reinforcement learning. Agents must explore jointly in multi-agent systems to find the optimal joint policy. Due to the exploration problem and the shared reward, the policy-based multi-agent reinforcement learning algorithms face policy overfitting, which may lead to the joint policy falling into a local optimum. This paper introduces a novel general framework called Learning Joint-Action Intrinsic Reward (LJIR) for improving multi-agent reinforcement learners’ joint exploration ability and performance. LJIR observes agents’ state and joint actions to learn to construct an intrinsic reward online that can guide effective joint exploration. With the novel combination of Transformer and random network distillation, LJIR selects the novel states to give more intrinsic rewards, which help agents find the best joint actions. LJIR can dynamically adjust the weight of exploration and exploitation during training and keep the policy invariance finally. To ensure LJIR seamlessly adopts existing MARL algorithms, we also provide a flexible combination method for intrinsic and external rewards. Empirical results on the SMAC benchmark show that the proposed method achieves state-of-the-art performance in challenging tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004355",
    "keywords": [
      "Architectural engineering",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Construct (python library)",
      "Engineering",
      "Geodesy",
      "Geography",
      "Joint (building)",
      "Machine learning",
      "Overfitting",
      "Programming language",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Zihan"
      },
      {
        "surname": "Luo",
        "given_name": "Biao"
      },
      {
        "surname": "Hu",
        "given_name": "Tianmeng"
      },
      {
        "surname": "Xu",
        "given_name": "Xiaodong"
      }
    ]
  },
  {
    "title": "Metaheuristics optimization-based ensemble of deep neural networks for Mpox disease detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.035",
    "abstract": "The rising number of cases of human Mpox has emerged as a major global concern due to the daily increase of cases in several countries. The disease presents various skin symptoms in infected individuals, making it crucial to promptly identify and isolate them to prevent widespread community transmission. Rapid determination and isolation of infected individuals are therefore essential to curb the spread of the disease. Most research in the detection of Mpox disease has utilized convolutional neural network (CNN) models and ensemble methods. However, to the best of our knowledge, none have utilized a meta-heuristic-based ensemble approach. To address this gap, we propose a novel metaheuristics optimization-based weighted average ensemble model (MO-WAE) for detecting Mpox disease. We first train three transfer learning (TL)-based CNNs (DenseNet201, MobileNet, and DenseNet169) by adding additional layers to improve their classification strength. Next, we use a weighted average ensemble technique to fuse the predictions from each individual model, and the particle swarm optimization (PSO) algorithm is utilized to assign optimized weights to each model during the ensembling process. By using this approach, we obtain more accurate predictions than individual models. To gain a better understanding of the regions indicating the onset of Mpox, we performed a Gradient Class Activation Mapping (Grad-CAM) analysis to explain our model’s predictions. Our proposed MO-WAE ensemble model was evaluated on a publicly available Mpox dataset and achieved an impressive accuracy of 97.78%. This outperforms state-of-the-art (SOTA) methods on the same dataset, thereby providing further evidence of the efficacy of our proposed model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004525",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Machine learning",
      "Metaheuristic",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Asif",
        "given_name": "Sohaib"
      },
      {
        "surname": "Zhao",
        "given_name": "Ming"
      },
      {
        "surname": "Tang",
        "given_name": "Fengxiao"
      },
      {
        "surname": "Zhu",
        "given_name": "Yusen"
      },
      {
        "surname": "Zhao",
        "given_name": "Baokang"
      }
    ]
  },
  {
    "title": "Spiking neural P systems with lateral inhibition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.013",
    "abstract": "As a member of the third generation of artificial neural network models, spiking neural P systems (SN P systems) have gained a hot research spot in recent years. This work introduces the phenomenon of lateral inhibition in biological nervous systems into SN P systems, and proposes SN P systems with lateral inhibition (LISN P systems). LISN P systems add the property of synaptic length to portray the lateral distance between neurons, and adopt a new form of rules, lateral interaction rules, to describe the reception of spikes by postsynaptic neurons with different lateral distances from the presynaptic neuron. Specifically, an excited neuron produces lateral inhibition on surrounding postsynaptic neurons. Postsynaptic neurons close to the excited neuron, i.e., neurons with small lateral distances, are more susceptible to lateral inhibition and either receive a fewer number of spikes generated by the excited neuron or fail to receive spikes. As the lateral distance increases, the lateral inhibition weakens, and the number of spikes received by postsynaptic neurons increases. Based on the above mechanism, four specific LISN P systems are designed for generating arbitrary odd numbers, arbitrary even numbers, arbitrary natural numbers and arithmetic series, respectively, as examples. By designing working modules, LISN P systems provide equivalence in computational power to the universal register machines in both generating and accepting modes. This verifies the computational completeness of LISN P systems. A universal LISN P system using merely 65 neurons is devised for function computation. According to comparisons among several systems, universal LISN P systems require fewer computational resources.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300432X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Lateral inhibition",
      "Mathematics",
      "Neuron",
      "Neuroscience",
      "Physics",
      "Postsynaptic potential",
      "Receptor"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Yuping"
      },
      {
        "surname": "Zhao",
        "given_name": "Yuzhen"
      }
    ]
  },
  {
    "title": "ProxyMix: Proxy-based Mixup training with label refinery for source-free domain adaptation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.005",
    "abstract": "Due to privacy concerns and data transmission issues, Source-free Unsupervised Domain Adaptation (SFDA) has gained popularity. It exploits pre-trained source models, rather than raw source data for target learning, to transfer knowledge from a labeled source domain to an unlabeled target domain. Existing methods solve this problem typically with additional parameters or noisy pseudo labels, and we propose an effective method named Proxy-based Mixup training with label refinery (ProxyMix) to avoid these drawbacks. To avoid additional parameters and leverages information in the source model, ProxyMix defines classifier weights as class prototypes and creates a class-balanced proxy source domain using nearest neighbors of the prototypes. To improve the reliability of pseudo labels, we further propose the frequency-weighted aggregation strategy to generate soft pseudo labels for unlabeled target data. Our strategy utilizes target features’ internal structure, increases weights of low-frequency class samples, and aligns the proxy and target domains using inter- and intra-domain mixup regularization. This mitigates the negative impact of noisy labels. Experiments on three 2D image and 3D point cloud object recognition benchmarks demonstrate that ProxyMix yields state-of-the-art performance for source-free UDA tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004240",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Computer security",
      "Data mining",
      "Exploit",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Ding",
        "given_name": "Yuhe"
      },
      {
        "surname": "Sheng",
        "given_name": "Lijun"
      },
      {
        "surname": "Liang",
        "given_name": "Jian"
      },
      {
        "surname": "Zheng",
        "given_name": "Aihua"
      },
      {
        "surname": "He",
        "given_name": "Ran"
      }
    ]
  },
  {
    "title": "Subspace distillation for continual learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.047",
    "abstract": "An ultimate objective in continual learning is to preserve knowledge learned in preceding tasks while learning new tasks. To mitigate forgetting prior knowledge, we propose a novel knowledge distillation technique that takes into the account the manifold structure of the latent/output space of a neural network in learning novel tasks. To achieve this, we propose to approximate the data manifold up-to its first order, hence benefiting from linear subspaces to model the structure and maintain the knowledge of a neural network while learning novel concepts. We demonstrate that the modeling with subspaces provides several intriguing properties, including robustness to noise and therefore effective for mitigating Catastrophic Forgetting in continual learning. We also discuss and show how our proposed method can be adopted to address both classification and segmentation problems. Empirically, we observe that our proposed method outperforms various continual learning methods on several challenging datasets including Pascal VOC, and Tiny-Imagenet. Furthermore, we show how the proposed method can be seamlessly combined with existing learning approaches to improve their performances. The codes of this article will be available at https://github.com/csiro-robotics/SDCL.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004057",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Forgetting",
      "Gene",
      "Geometry",
      "Linear subspace",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Pascal (unit)",
      "Philosophy",
      "Programming language",
      "Robustness (evolution)",
      "Subspace topology"
    ],
    "authors": [
      {
        "surname": "Roy",
        "given_name": "Kaushik"
      },
      {
        "surname": "Simon",
        "given_name": "Christian"
      },
      {
        "surname": "Moghadam",
        "given_name": "Peyman"
      },
      {
        "surname": "Harandi",
        "given_name": "Mehrtash"
      }
    ]
  },
  {
    "title": "Distorted image classification using neural activation pattern matching loss",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.050",
    "abstract": "In image classification, a deep neural network (DNN) that is trained on undistorted images constitutes an effective decision boundary. Unfortunately, this boundary does not support distorted images, such as noisy or blurry ones, leading to accuracy drop-off. As a simple approach for classifying distorted images as well as undistorted ones, previous methods have optimized the trained DNN again on both kinds of images. However, in these methods, the decision boundary may become overly complicated during optimization because there is no regularization of the decision boundary. Consequently, this decision boundary limits efficient optimization. In this paper, we study a simple yet effective decision boundary for distorted image classification through the use of a novel loss, called a “neural activation pattern matching (NAPM) loss”. The NAPM loss is based on recent findings that the decision boundary is a piecewise linear function, where each linear segment is constructed from a neural activation pattern in the DNN when an image is fed to it. The NAPM loss extracts the neural activation patterns when the distorted image and its undistorted version are fed to the DNN and then matches them with each other via the sigmoid cross-entropy. Therefore, it constrains the DNN to classify the distorted image and its undistorted version by the same linear segment. As a result, our loss accelerates efficient optimization by preventing the decision boundary from becoming overly complicated. Our experiments demonstrate that our loss increases the accuracy of the previous methods in all conditions evaluated.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004185",
    "keywords": [
      "Activation function",
      "Artificial intelligence",
      "Artificial neural network",
      "Boundary (topology)",
      "Computer science",
      "Contextual image classification",
      "Decision boundary",
      "Geometry",
      "Image (mathematics)",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Piecewise linear function",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Suzuki",
        "given_name": "Satoshi"
      },
      {
        "surname": "Takeda",
        "given_name": "Shoichiro"
      },
      {
        "surname": "Tanida",
        "given_name": "Ryuichi"
      },
      {
        "surname": "Bandoh",
        "given_name": "Yukihiro"
      },
      {
        "surname": "Shouno",
        "given_name": "Hayaru"
      }
    ]
  },
  {
    "title": "Contrastive self-representation learning for data clustering",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.050",
    "abstract": "This paper is concerned with self-representation subspace learning. It is one of the most representative subspace techniques, which has attracted considerable attention for clustering due to its good performance. Among these methods, low-rank representation (LRR) has achieved impressive results for subspace clustering. However, it only considers the similarity between the data itself, while neglecting the differences with other samples. Besides, it cannot well deal with noise and portray cluster-to-cluster relationships well. To solve these problems, we propose a Contrastive Self-representation model for Clustering (CSC). CSC simultaneously takes into account the similarity/dissimilarity between positive/negative pairs when learning the self-representation coefficient matrix of data while the form of the loss function can reduce the effect of noise on the results. Moreover, We use the ℓ 1 , 2 -norm regularizer on the coefficient matrix to achieve its sparsity to better characterize the cluster structure. Thus, the learned self-representation coefficient matrix well encodes both the discriminative information and cluster structure. Extensive experiments on seven benchmark databases indicate the superiority of our proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004707",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Cluster analysis",
      "Coefficient matrix",
      "Combinatorics",
      "Computer science",
      "Discriminative model",
      "Eigenvalues and eigenvectors",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Law",
      "Mathematics",
      "Noise (video)",
      "Pattern recognition (psychology)",
      "Physics",
      "Political science",
      "Politics",
      "Quantum mechanics",
      "Rank (graph theory)",
      "Representation (politics)",
      "Similarity (geometry)",
      "Subspace topology"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Wenhui"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Mei",
        "given_name": "Shikun"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      }
    ]
  },
  {
    "title": "Dissociable default-mode subnetworks subserve childhood attention and cognitive flexibility: Evidence from deep learning and stereotactic electroencephalography",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.019",
    "abstract": "Cognitive flexibility encompasses the ability to efficiently shift focus and forms a critical component of goal-directed attention. The neural substrates of this process are incompletely understood in part due to difficulties in sampling the involved circuitry. We leverage stereotactic intracranial recordings to directly resolve local-field potentials from otherwise inaccessible structures to study moment-to-moment attentional activity in children with epilepsy performing a flexible attentional task. On an individual subject level, we employed deep learning to decode neural features predictive of task performance indexed by single-trial reaction time. These models were subsequently aggregated across participants to identify predictive brain regions based on AAL atlas and FIND functional network parcellations. Through this approach, we show that fluctuations in beta (12–30 Hz) and gamma (30–80 Hz) power reflective of increased top-down attentional control and local neuronal processing within relevant large-scale networks can accurately predict single-trial task performance. We next performed connectomic profiling of these highly predictive nodes to examine task-related engagement of distributed functional networks, revealing exclusive recruitment of the dorsal default mode network during shifts in attention. The identification of distinct substreams within the default mode system supports a key role for this network in cognitive flexibility and attention in children. Furthermore, convergence of our results onto consistent functional networks despite significant inter-subject variability in electrode implantations supports a broader role for deep learning applied to intracranial electrodes in the study of human attention.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003799",
    "keywords": [
      "Artificial intelligence",
      "Cognition",
      "Cognitive psychology",
      "Computer science",
      "Default mode network",
      "Electroencephalography",
      "Flexibility (engineering)",
      "Local field potential",
      "Machine learning",
      "Mathematics",
      "Neuroscience",
      "Psychology",
      "Statistics",
      "Task-positive network"
    ],
    "authors": [
      {
        "surname": "Warsi",
        "given_name": "Nebras M."
      },
      {
        "surname": "Wong",
        "given_name": "Simeon M."
      },
      {
        "surname": "Germann",
        "given_name": "Jürgen"
      },
      {
        "surname": "Boutet",
        "given_name": "Alexandre"
      },
      {
        "surname": "Arski",
        "given_name": "Olivia N."
      },
      {
        "surname": "Anderson",
        "given_name": "Ryan"
      },
      {
        "surname": "Erdman",
        "given_name": "Lauren"
      },
      {
        "surname": "Yan",
        "given_name": "Han"
      },
      {
        "surname": "Suresh",
        "given_name": "Hrishikesh"
      },
      {
        "surname": "Gouveia",
        "given_name": "Flavia Venetucci"
      },
      {
        "surname": "Loh",
        "given_name": "Aaron"
      },
      {
        "surname": "Elias",
        "given_name": "Gavin J.B."
      },
      {
        "surname": "Kerr",
        "given_name": "Elizabeth"
      },
      {
        "surname": "Smith",
        "given_name": "Mary Lou"
      },
      {
        "surname": "Ochi",
        "given_name": "Ayako"
      },
      {
        "surname": "Otsubo",
        "given_name": "Hiroshi"
      },
      {
        "surname": "Sharma",
        "given_name": "Roy"
      },
      {
        "surname": "Jain",
        "given_name": "Puneet"
      },
      {
        "surname": "Donner",
        "given_name": "Elizabeth"
      },
      {
        "surname": "Lozano",
        "given_name": "Andres M."
      },
      {
        "surname": "Snead",
        "given_name": "O. Carter"
      },
      {
        "surname": "Ibrahim",
        "given_name": "George M."
      }
    ]
  },
  {
    "title": "Multiple-instance ensemble for construction of deep heterogeneous committees for high-dimensional low-sample-size data",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.028",
    "abstract": "Deep ensemble learning, where we combine knowledge learned from multiple individual neural networks, has been widely adopted to improve the performance of neural networks in deep learning. This field can be encompassed by committee learning, which includes the construction of neural network cascades. This study focuses on the high-dimensional low-sample-size (HDLS) domain and introduces multiple instance ensemble (MIE) as a novel stacking method for ensembles and cascades. In this study, our proposed approach reformulates the ensemble learning process as a multiple-instance learning problem. We utilise the multiple-instance learning solution of pooling operations to associate feature representations of base neural networks into joint representations as a method of stacking. This study explores various attention mechanisms and proposes two novel committee learning strategies with MIE. In addition, we utilise the capability of MIE to generate pseudo-base neural networks to provide a proof-of-concept for a “growing” neural network cascade that is unbounded by the number of base neural networks. We have shown that our approach provides (1) a class of alternative ensemble methods that performs comparably with various stacking ensemble methods and (2) a novel method for the generation of high-performing “growing” cascades. The approach has also been verified across multiple HDLS datasets, achieving high performance for binary classification tasks in the low-sample size regime.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004483",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cascade",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Deep learning",
      "Ensemble learning",
      "Feature (linguistics)",
      "Field (mathematics)",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Philosophy",
      "Pooling",
      "Pure mathematics",
      "Sample (material)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Qinghua"
      },
      {
        "surname": "Wang",
        "given_name": "Shuihua"
      },
      {
        "surname": "Zhu",
        "given_name": "Hengde"
      },
      {
        "surname": "Zhang",
        "given_name": "Xin"
      },
      {
        "surname": "Zhang",
        "given_name": "Yudong"
      }
    ]
  },
  {
    "title": "Adv-BDPM: Adversarial attack based on Boundary Diffusion Probability Model",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.048",
    "abstract": "Deep neural networks have become increasingly significant in our daily lives due to their remarkable performance. The issue of adversarial examples, which are responsible for the vulnerability problem of deep neural networks, has attracted the attention of researchers in the study of robustness of these networks. To address the issues caused by the restricted diversity and precision of adversarial perturbations in neural networks, we introduce a novel technique called Adversarial Boundary Diffusion Probability Modeling (Adv-BDPM). This approach combines boundary analysis and diffusion probability modeling. First, we combined the denoising diffusion probability model with the boundary loss to design the boundary diffusion probability model, which can generate corresponding boundary perturbations for a specific neural network. Then, through the iterative process of boundary perturbations and its corresponding orthogonal perturbations, we proposed a decision boundary search algorithm to generate adversarial samples. The comparison experiments with black-box attacks in ImageNet demonstrate that Adv-BDPM has better attack success rate and perturbation precision. The comparison experiments with white-box attacks in CIFAR-10 and CIFAR-100 demonstrate that Adv-BDPM has better attack success rate, attack diversity for the same sample, and can effectively defend against adversarial training with shorter running time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004689",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Boundary (topology)",
      "Chemistry",
      "Classifier (UML)",
      "Computer science",
      "Decision boundary",
      "Gene",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Perturbation (astronomy)",
      "Physics",
      "Quantum mechanics",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Dian"
      },
      {
        "surname": "Dong",
        "given_name": "Yunwei"
      }
    ]
  },
  {
    "title": "Drop edges and adapt: A fairness enforcing fine-tuning for graph neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.002",
    "abstract": "The rise of graph representation learning as the primary solution for many different network science tasks led to a surge of interest in the fairness of this family of methods. Link prediction, in particular, has a substantial social impact. However, link prediction algorithms tend to increase the segregation in social networks by disfavouring the links between individuals in specific demographic groups. This paper proposes a novel way to enforce fairness on graph neural networks with a fine-tuning strategy. We Drop the unfair Edges and, simultaneously, we Adapt the model’s parameters to those modifications, DEA in short. We introduce two covariance-based constraints designed explicitly for the link prediction task. We use these constraints to guide the optimization process responsible for learning the new ‘fair’ adjacency matrix. One novelty of DEA is that we can use a discrete yet learnable adjacency matrix in our fine-tuning. We demonstrate the effectiveness of our approach on five real-world datasets and show that we can improve both the accuracy and the fairness of the link prediction tasks. In addition, we present an in-depth ablation study demonstrating that our training algorithm for the adjacency matrix can be used to improve link prediction performances during training. Finally, we compute the relevance of each component of our framework to show that the combination of both the constraints and the training of the adjacency matrix leads to optimal performances.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004215",
    "keywords": [
      "Adjacency matrix",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Graph",
      "Machine learning",
      "Novelty",
      "Philosophy",
      "Theology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Spinelli",
        "given_name": "Indro"
      },
      {
        "surname": "Bianchini",
        "given_name": "Riccardo"
      },
      {
        "surname": "Scardapane",
        "given_name": "Simone"
      }
    ]
  },
  {
    "title": "Chaos and multi-layer attractors in asymmetric neural networks coupled with discrete fractional memristor",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.041",
    "abstract": "This article introduces a novel model of asymmetric neural networks combined with fractional difference memristors, which has both theoretical and practical implications in the rapidly evolving field of computational intelligence. The proposed model includes two types of fractional difference memristor elements: one with hyperbolic tangent memductance and the other with periodic memductance and memristor state described by sine functions. The authenticity of the constructed memristor is confirmed through fingerprint verification. The research extensively investigates the dynamics of a coupled neural network model, analyzing its stability at equilibrium states, studying bifurcation diagrams, and calculating the largest Lyapunov exponents. The results suggest that when incorporating sine memristors, the model demonstrates coexisting state variables depending on the initial conditions, revealing the emergence of multi-layer attractors. The article further demonstrates how the memristor state shifts through numerical simulations with varying memductance values. Notably, the study emphasizes the crucial role of memductance (synaptic weight) in determining the complex dynamical characteristics of neural network systems. To support the analytical results and demonstrate the chaotic response of state variables, the article includes appropriate numerical simulations. These simulations effectively validate the presented findings and provide concrete evidence of the system’s chaotic behavior.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004616",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Attractor",
      "Bifurcation",
      "Chaotic",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Lyapunov exponent",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Memristor",
      "Multistability",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "State variable",
      "Statistical physics",
      "Thermodynamics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Shaobo"
      },
      {
        "surname": "Vignesh",
        "given_name": "D."
      },
      {
        "surname": "Rondoni",
        "given_name": "Lamberto"
      },
      {
        "surname": "Banerjee",
        "given_name": "Santo"
      }
    ]
  },
  {
    "title": "Switching ETM-based neural adaptive output feedback control for nonaffine stochastic MIMO nonlinear systems subject to deferred constraint",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.054",
    "abstract": "This article focuses on the neural adaptive output feedback control study related to nonaffine stochastic multiple-input, multiple-output nonlinear plants. First, a K -filter state observer based on a radial basis function neural network is designed to estimate the remaining unavailable states. Then, a novel adaptive command-filtered backstepping output feedback control framework is established, where an improved command filter with a fractional-order parameter is applied to conquer the calculation size problem. Specifically, the highlight of this work is that it designs a modified error compensation signal and incorporates the concept of deferred constraint to eradicate the negative effect caused by the filter errors. In addition, the network bandwidth resources, control impulse, and control accuracy are synthesized using an amended switching event-triggered mechanism. The theoretical analysis proved that the proposed control approach guarantees that the tracking error can converge to a preassigned region within a user-defined time while the violation of the deferred output constraint can be excluded. Two illustrative studies are provided to demonstrate the validity and superiority of the developed control method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004744",
    "keywords": [
      "Adaptive control",
      "Artificial intelligence",
      "Artificial neural network",
      "Backstepping",
      "Computer science",
      "Computer vision",
      "Constraint (computer-aided design)",
      "Control (management)",
      "Control theory (sociology)",
      "Filter (signal processing)",
      "Geometry",
      "Impulse (physics)",
      "Mathematics",
      "Nonlinear system",
      "Observer (physics)",
      "Physics",
      "Quantum mechanics",
      "Tracking error"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Xiaona"
      },
      {
        "surname": "Sun",
        "given_name": "Peng"
      },
      {
        "surname": "Ahn",
        "given_name": "Choon Ki"
      },
      {
        "surname": "Song",
        "given_name": "Shuai"
      }
    ]
  },
  {
    "title": "Word self-update contrastive adversarial networks for text-to-image synthesis",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.038",
    "abstract": "Synthesizing realistic fine-grained images from text descriptions is a significant computer vision task. Although many GANs-based methods have been proposed to solve this task, generating high-quality images consistent with text information remains a difficult problem. These existing GANs-based methods ignore important words due to the use of fixed initial word features in generator, and neglect to learn semantic consistency between images and texts for discriminators. In this article, we propose a novel attentional generation and contrastive adversarial framework for fine-grained text-to-image synthesis, termed as Word Self-Update Contrastive Adversarial Networks (WSC-GAN). Specifically, we introduce a dual attention module for modeling color details and semantic information. With a new designed word self-update module, the generator can leverage visually important words to compute attention maps in the feature synthesis module. Furthermore, we contrive multi-branch contrastive discriminators to maintain better consistency between the generated image and text description. Two novel contrastive losses are proposed for our discriminators to impose image-sentence and image-word consistency constraints. Extensive experiments on CUB and MS-COCO datasets demonstrate that our method achieves better performance compared with state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004586",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Consistency (knowledge bases)",
      "Economics",
      "Generator (circuit theory)",
      "Image (mathematics)",
      "Leverage (statistics)",
      "Linguistics",
      "Management",
      "Natural language processing",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Sentence",
      "Task (project management)",
      "Word (group theory)"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Jian"
      },
      {
        "surname": "Sun",
        "given_name": "Yiwen"
      },
      {
        "surname": "Bi",
        "given_name": "Xiaojun"
      }
    ]
  },
  {
    "title": "Conditioned Cooperative training for semi-supervised weapon detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.043",
    "abstract": "Violent assaults and homicides occur daily, and the number of victims of mass shootings increases every year. However, this number can be reduced with the help of Closed Circuit Television (CCTV) and weapon detection models, as generic object detectors have become increasingly accurate with more data for training. We present a new semi-supervised learning methodology based on conditioned cooperative student–teacher training with optimal pseudo-label generation using a novel confidence threshold search method and improving both models by conditional knowledge transfer. Furthermore, a novel firearms image dataset of 458,599 images was collected using Instagram hashtags to evaluate our approach and compare the improvements obtained using a specific unsupervised dataset instead of a general one such as ImageNet. We compared our methodology with supervised, semi-supervised and self-supervised learning techniques, outperforming approaches such as YOLOv5 m (up to ＋19.86), YOLOv5l (up to ＋6.52) Unbiased Teacher (up to ＋10.5 AP), DETReg (up to ＋2.8 AP) and UP-DETR (up to ＋1.22 AP).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004628",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Image (mathematics)",
      "Labeled data",
      "Machine learning",
      "Meteorology",
      "Object (grammar)",
      "Object detection",
      "Pattern recognition (psychology)",
      "Physics",
      "Semi-supervised learning",
      "Supervised learning",
      "Training (meteorology)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Salazar González",
        "given_name": "Jose L."
      },
      {
        "surname": "Álvarez-García",
        "given_name": "Juan A."
      },
      {
        "surname": "Rendón-Segador",
        "given_name": "Fernando J."
      },
      {
        "surname": "Carrara",
        "given_name": "Fabio"
      }
    ]
  },
  {
    "title": "An adaptive embedding procedure for time series forecasting with deep neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.051",
    "abstract": "Nowadays, solving time series prediction problems is an open and challenging task. Many solutions are based on the implementation of deep neural architectures, which are able to analyze the structure of the time series and to carry out the prediction. In this work, we present a novel deep learning scheme based on an adaptive embedding mechanism. The latter is exploited to extract a compressed representation of the input time series that is used for the subsequent forecasting. The proposed model is based on a two-layer bidirectional Long Short-Term Memory network, where the first layer performs the adaptive embedding and the second layer acts as a predictor. The performances of the proposed forecasting scheme are compared with several models in two different scenarios, considering both well-known time series and real-life application cases. The experimental results show the accuracy and the flexibility of the proposed approach, which can be used as a prediction tool for any actual application.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004719",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Economics",
      "Embedding",
      "Flexibility (engineering)",
      "Law",
      "Layer (electronics)",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Organic chemistry",
      "Paleontology",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Scheme (mathematics)",
      "Series (stratigraphy)",
      "Statistics",
      "Task (project management)",
      "Time series"
    ],
    "authors": [
      {
        "surname": "Succetti",
        "given_name": "Federico"
      },
      {
        "surname": "Rosato",
        "given_name": "Antonello"
      },
      {
        "surname": "Panella",
        "given_name": "Massimo"
      }
    ]
  },
  {
    "title": "A large-scale neurocomputational model of spatial cognition integrating memory with vision",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.034",
    "abstract": "We introduce a large-scale neurocomputational model of spatial cognition called ’Spacecog’, which integrates recent findings from mechanistic models of visual and spatial perception. As a high-level cognitive ability, spatial cognition requires the processing of behaviourally relevant features in complex environments and, importantly, the updating of this information during processes of eye and body movement. The Spacecog model achieves this by interfacing spatial memory and imagery with mechanisms of object localisation, saccade execution, and attention through coordinate transformations in parietal areas of the brain. We evaluate the model in a realistic virtual environment where our neurocognitive model steers an agent to perform complex visuospatial tasks. Our modelling approach opens up new possibilities in the assessment of neuropsychological data and human spatial cognition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004550",
    "keywords": [
      "Artificial intelligence",
      "Cognition",
      "Cognitive model",
      "Cognitive psychology",
      "Computer hardware",
      "Computer science",
      "Eye movement",
      "Geology",
      "Interfacing",
      "Neurocognitive",
      "Neuroscience",
      "Perception",
      "Psychology",
      "Remote sensing",
      "Saccade",
      "Spatial analysis",
      "Spatial cognition",
      "Spatial memory",
      "Working memory"
    ],
    "authors": [
      {
        "surname": "Burkhardt",
        "given_name": "Micha"
      },
      {
        "surname": "Bergelt",
        "given_name": "Julia"
      },
      {
        "surname": "Gönner",
        "given_name": "Lorenz"
      },
      {
        "surname": "Dinkelbach",
        "given_name": "Helge Ülo"
      },
      {
        "surname": "Beuth",
        "given_name": "Frederik"
      },
      {
        "surname": "Schwarz",
        "given_name": "Alex"
      },
      {
        "surname": "Bicanski",
        "given_name": "Andrej"
      },
      {
        "surname": "Burgess",
        "given_name": "Neil"
      },
      {
        "surname": "Hamker",
        "given_name": "Fred H."
      }
    ]
  },
  {
    "title": "PEPNet: A barotropic primitive equations-based network for wind speed prediction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.042",
    "abstract": "In wind speed prediction technologies, deep learning-based methods have achieved promising advantages. However, most existing methods focus on learning implicit knowledge in a data-driven manner but neglect some explicit knowledge from the physical theory of meteorological dynamics, failing to make stable and long-term predictions. In this paper, we explore introducing explicit physical knowledge into neural networks and propose Physical Equations Predictive Network (PEPNet) for multi-step wind speed predictions. In PEPNet, a new neural block called the Augmented Neural Barotropic Equations (ANBE) block is designed as its key component, which aims to capture the wind dynamics by combining barotropic primitive equations and deep neural networks. Specifically, the ANBE block adopts a two-branch structure to model wind dynamics, where one branch is physic-based and the other is data-driven-based. The physic-based branch constructs temporal partial derivatives of meteorological elements (including u-component wind, v-component wind, and geopotential height) in a new Neural Barotropic Equations Unit (NBEU). The NBEU is developed based on the barotropic primitive equations mode in numerical weather prediction (NWP). Besides, considering that the barotropic primitive mode is a crude assumption of atmospheric motion, another data-driven-based branch is developed in the ANBE block, which aims at capturing meteorological dynamics beyond barotropic primitive equations. Finally, the PEPNet follows a time-variant structure to enhance the model’s capability to capture wind dynamics over time. To evaluate the predictive performance of PEPNet, we have conducted several experiments on two real-world datasets. Experimental results show that the proposed method outperforms the state-of-the-art techniques and achieve optimal performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300463X",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Barotropic fluid",
      "Block (permutation group theory)",
      "Component (thermodynamics)",
      "Computer science",
      "Differential equation",
      "Geography",
      "Geometry",
      "Mathematical analysis",
      "Mathematics",
      "Mechanics",
      "Meteorology",
      "Physics",
      "Primitive equations",
      "Simultaneous equations",
      "Thermodynamics",
      "Wind speed"
    ],
    "authors": [
      {
        "surname": "Ye",
        "given_name": "Rui"
      },
      {
        "surname": "Zhang",
        "given_name": "Baoquan"
      },
      {
        "surname": "Li",
        "given_name": "Xutao"
      },
      {
        "surname": "Ye",
        "given_name": "Yunming"
      }
    ]
  },
  {
    "title": "Finite/fixed-time synchronization of inertial memristive neural networks by interval matrix method for secure communication",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.015",
    "abstract": "This paper investigates the finite/fixed-time synchronization problem of delayed inertial memristive neural networks (DIMNNs) using interval matrix-based methods within a unified control framework. By employing set-valued mapping and differential inclusion theory, two distinct methods are applied to handle the switching behavior of memristor parameters: the maximum absolute value method and the interval matrix method. Based on these different approaches, two control strategies are proposed to select appropriate control parameters, enabling the system to achieve finite and fixed-time synchronization, respectively. Additionally, the resulting theoretical criteria differ based on the chosen control strategy, with one expressed in algebraic form and the other in the form of linear matrix inequalities (LMIs). Numerical simulations demonstrate that the interval matrix method outperforms the maximum absolute value method in terms of handling memristor parameter switching, achieving faster finite/fixed-time synchronization. Furthermore, the theoretical results are extended to the field of image encryption, where the response system is utilized for decryption and expanding the keyspace.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004343",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Combinatorics",
      "Composite material",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differential inclusion",
      "Electrical engineering",
      "Engineering",
      "Inertial frame of reference",
      "Interval (graph theory)",
      "Materials science",
      "Mathematical optimization",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Memristor",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Fei"
      },
      {
        "surname": "Chen",
        "given_name": "Guici"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      },
      {
        "surname": "Gunasekaran",
        "given_name": "Nallappan"
      }
    ]
  },
  {
    "title": "On exploring node-feature and graph-structure diversities for node drop graph pooling",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.046",
    "abstract": "Graph Neural Networks (GNNs) have been successfully applied to graph-level tasks in various fields such as biology, social networks, computer vision, and natural language processing. For the graph-level representations learning of GNNs, graph pooling plays an essential role. Among many pooling techniques, node drop pooling has garnered significant attention and is considered as a leading approach. However, existing node drop pooling methods, which typically retain the top-k nodes based on their significance scores, often overlook the diversity inherent in node features and graph structures. This limitation leads to suboptimal graph-level representations. To overcome this, we introduce a groundbreaking plug-and-play score scheme, termed MID. MID comprises a Multidimensional score space and two key operations: flIpscore and Dropscore. The multidimensional score space depicts the significance of nodes by multiple criteria; the flipscore process promotes the preservation of distinct node features; the dropscore compels the model to take into account a range of graph structures rather than focusing on local structures. To evaluate the effectiveness of our proposed MID, we have conducted extensive experiments by integrating it with a broad range of recent node drop pooling methods, such as TopKPool, SAGPool, GSAPool, and ASAP. In particular, MID has proven to bring a significant average improvement of approximately 2.8% over the four aforementioned methods when tested on 17 real-world graph classification datasets. Code is available at https://github.com/whuchuang/mid.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004665",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Pooling",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Chuang"
      },
      {
        "surname": "Zhan",
        "given_name": "Yibing"
      },
      {
        "surname": "Yu",
        "given_name": "Baosheng"
      },
      {
        "surname": "Liu",
        "given_name": "Liu"
      },
      {
        "surname": "Du",
        "given_name": "Bo"
      },
      {
        "surname": "Hu",
        "given_name": "Wenbin"
      },
      {
        "surname": "Liu",
        "given_name": "Tongliang"
      }
    ]
  },
  {
    "title": "Information theory-guided heuristic progressive multi-view coding",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.027",
    "abstract": "Multi-view representation learning aims to capture comprehensive information from multiple views of a shared context. Recent works intuitively apply contrastive learning to different views in a pairwise manner, which is still scalable: view-specific noise is not filtered in learning view-shared representations; the fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; evenly measuring the similarities between terms might interfere with optimization. Importantly, few works study the theoretical framework of generalized self-supervised multi-view learning, especially for more than two views. To this end, we rethink the existing multi-view learning paradigm from the perspective of information theory and then propose a novel information theoretical framework for generalized multi-view learning. Guided by it, we build a multi-view coding method with a three-tier progressive architecture, namely Information theory-guided heuristic Progressive Multi-view Coding (IPMC). In the distribution-tier, IPMC aligns the distribution between views to reduce view-specific noise. In the set-tier, IPMC constructs self-adjusted contrasting pools, which are adaptively modified by a view filter. Lastly, in the instance-tier, we adopt a designed unified loss to learn representations and reduce the gradient interference. Theoretically and empirically, we demonstrate the superiority of IPMC over state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004471",
    "keywords": [
      "Artificial intelligence",
      "Coding (social sciences)",
      "Computer science",
      "Computer vision",
      "Database",
      "Feature learning",
      "Filter (signal processing)",
      "Heuristic",
      "Law",
      "Machine learning",
      "Mathematics",
      "Neural coding",
      "Pairwise comparison",
      "Perspective (graphical)",
      "Political science",
      "Politics",
      "Programming language",
      "Representation (politics)",
      "Scalability",
      "Set (abstract data type)",
      "Statistics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Jiangmeng"
      },
      {
        "surname": "Gao",
        "given_name": "Hang"
      },
      {
        "surname": "Qiang",
        "given_name": "Wenwen"
      },
      {
        "surname": "Zheng",
        "given_name": "Changwen"
      }
    ]
  },
  {
    "title": "Self-supervised contrastive graph representation with node and graph augmentation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.039",
    "abstract": "Graph representation is a critical technology in the field of knowledge engineering and knowledge-based applications since most knowledge bases are represented in the graph structure. Nowadays, contrastive learning has become a prominent way for graph representation by contrasting positive–positive and positive–negative node pairs between two augmentation graphs. It has achieved new state-of-the-art in the field of self-supervised graph representation. However, existing contrastive graph representation methods mainly focus on modifying (normally removing some edges/nodes) the original graph structure to generate the augmentation graph for the contrastive. It inevitably changes the original graph structures, meaning the generated augmentation graph is no longer equivalent to the original graph. This harms the performance of the representation in many structure-sensitive graphs such as protein graphs, chemical graphs, molecular graphs, etc. Moreover, there is only one positive–positive node pair but relatively massive positive–negative node pairs in the self-supervised graph contrastive learning. This can lead to the same class, or very similar samples are considered negative samples. To this end, in this work, we propose a Virtual Masking Augmentation (VMA) to generate an augmentation graph without changing any structures from the original graph. Meanwhile, a node augmentation method is proposed to augment the positive node pairs by discovering the most similar nodes in the same graph. Then, two different augmentation graphs are generated and put into a contrastive learning model to learn the graph representation. Extensive experiments on massive datasets demonstrate that our method achieves new state-of-the-art results on self-supervised graph representation. The source code of the proposed method is available at https://github.com/DuanhaoranCC/CGRA.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004598",
    "keywords": [
      "Computer science",
      "Graph",
      "Line graph",
      "Null graph",
      "Theoretical computer science",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Duan",
        "given_name": "Haoran"
      },
      {
        "surname": "Xie",
        "given_name": "Cheng"
      },
      {
        "surname": "Li",
        "given_name": "Bin"
      },
      {
        "surname": "Tang",
        "given_name": "Peng"
      }
    ]
  },
  {
    "title": "Spatial oblivion channel attention targeting intra-class diversity feature learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.032",
    "abstract": "Convolutional neural networks (CNNs) have successfully driven many visual recognition tasks including image classification. However, when dealing with classification tasks with intra-class sample style diversity, the network tends to be disturbed by more diverse features, resulting in limited feature learning. In this article, a spatial oblivion channel attention (SOCA) for intra-class diversity feature learning is proposed. Specifically, SOCA performs spatial structure oblivion in a progressive regularization for each channel after convolution, so that the network is not restricted to a limited feature learning, and pays attention to more regionally detailed features. Further, SOCA reassigns channel weights in the progressively oblivious feature space from top to bottom along the channel direction, to ensure the network learns more image details in an orderly manner while not falling into feature redundancy. Experiments are conducted on the standard classification dataset CIFAR-10/100 and two garbage datasets with intra-class diverse styles. SOCA improves SqueezeNet, MobileNet, BN-VGG-19, Inception and ResNet-50 in classification accuracy by 1.31%, 1.18%, 1.57%, 2.09% and 2.27% on average, respectively. The feasibility and effectiveness of intra-class diversity feature learning in SOCA-enhanced networks are verified. Besides, the class activation map shows that more local detail feature regions are activated by adding the SOCA module, which also demonstrates the interpretability of the method for intra-class diversity feature learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003908",
    "keywords": [
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Convolutional neural network",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature learning",
      "Interpretability",
      "Linguistics",
      "Machine learning",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Redundancy (engineering)"
    ],
    "authors": [
      {
        "surname": "Han",
        "given_name": "Honggui"
      },
      {
        "surname": "Zhang",
        "given_name": "Qiyu"
      },
      {
        "surname": "Li",
        "given_name": "Fangyu"
      },
      {
        "surname": "Du",
        "given_name": "Yongping"
      }
    ]
  },
  {
    "title": "Structure-aware deep clustering network based on contrastive learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.020",
    "abstract": "Recently, deep clustering has been extensively employed for various data mining tasks, and it can be divided into auto-encoder (AE)-based and graph neural networks (GNN)-based methods. However, existing AE-based methods fall short in effectively extracting structural information, while GNN suffer from smoothing and heterophily. Although methods that combine AE and GNN achieve impressive performance, there remains an inadequate balance between preserving the raw structure and exploring the underlying structure. Accordingly, we propose a novel network named Structure-Aware Deep Clustering network (SADC). Firstly, we compute the cumulative influence of non-adjacent nodes at multiple depths and, thus, enhance the adjacency matrix. Secondly, an enhanced graph auto-encoder is designed. Thirdly, the latent space of AE is endowed with the ability to perceive the raw structure during the learning process. Besides, we design self-supervised mechanisms to achieve co-optimization of node representation learning and topology learning. A new loss function is designed to preserve the inherent structure while also allowing for exploration of latent data structure. Extensive experiments on six benchmark datasets validate that our method outperforms state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004379",
    "keywords": [
      "Adjacency list",
      "Adjacency matrix",
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Computer vision",
      "Data mining",
      "Deep learning",
      "Feature learning",
      "Graph",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Smoothing",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Bowei"
      },
      {
        "surname": "Xu",
        "given_name": "Sen"
      },
      {
        "surname": "Xu",
        "given_name": "Heyang"
      },
      {
        "surname": "Bian",
        "given_name": "Xuesheng"
      },
      {
        "surname": "Guo",
        "given_name": "Naixuan"
      },
      {
        "surname": "Xu",
        "given_name": "Xiufang"
      },
      {
        "surname": "Hua",
        "given_name": "Xiaopeng"
      }
    ]
  },
  {
    "title": "MPCNet: Compressed multi-view video restoration via motion-parallax complementation network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.037",
    "abstract": "The performance in restoring compressed multi-view video (MVV) of the existing learning-based methods is limited because they only utilize information of temporally adjacent frames or parallax neighboring views. However, the compression artifacts caused by multi-view coding (MVC) may be related to the reference errors of intra-frame, inter-frame, and inter-view. In this paper, with delicately utilizing the stereo information from both temporal and parallax domains, a motion-parallax complementation network (MPCNet) is proposed to restore the quality of compressed MVV more efficiently. First, we introduce a motion-parallax complementation strategy consisting of a coarse stage and a fine stage. By mutually compensating the feature extracted from multiple domains, useful multi-frame information can be efficiently preserved and aggregated step by step. Second, an attention-based feature filtering and modulation module (AFFM) is proposed, which provides an efficient fusion method for two features by suppressing misleading information. By deploying it in most submodules of the proposed approach, the representational ability of MPCNet can be improved, resulting in a more substantial restoration performance. Experimental results prove the effectiveness of MPCNet by an average increase of 1.978 dB in PSNR, and 0.0282 in MS-SSIM. The BD-rate reduction can reach 47.342% on average. The subjective quality is greatly improved and lots of compression distortions are eliminated. Meanwhile, this work also benefits the accuracy improvement for high-level vision tasks, e.g., mIoU of semantic segmentation and mAP of object detection achieve 0.352 and 51.71, respectively. Quantitative and qualitative analyses demonstrate that MPCNet outperforms state-of-the-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004574",
    "keywords": [
      "Artificial intelligence",
      "Coding (social sciences)",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Feature (linguistics)",
      "Frame (networking)",
      "Linguistics",
      "Mathematics",
      "Parallax",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Segmentation",
      "Statistics",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Chang"
      },
      {
        "surname": "He",
        "given_name": "Gang"
      },
      {
        "surname": "Lai",
        "given_name": "Xinquan"
      },
      {
        "surname": "Li",
        "given_name": "Yunsong"
      }
    ]
  },
  {
    "title": "MI-DAGSC: A domain adaptation approach incorporating comprehensive information from MI-EEG signals",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.008",
    "abstract": "Non-stationarity of EEG signals leads to high variability between subjects, making it challenging to directly use data from other subjects (source domain) for the classifier in the current subject (target domain). In this study, we propose MI-DAGSC to address domain adaptation challenges in EEG-based motor imagery (MI) decoding. By combining domain-level information, class-level information, and inter-sample structure information, our model effectively aligns the feature distributions of source and target domains. This work is an extension of our previous domain adaptation work MI-DABAN (Li et al., 2023). Based on MI-DABAN, MI-DAGSC designs Sample-Feature Blocks (SFBs) and Graph Convolution Blocks (GCBs) to focus on intra-sample and inter-sample information. The synergistic integration of SFBs and GCBs enable the model to capture comprehensive information and understand the relationship between samples, thus improving representation learning. Furthermore, we introduce a triplet loss to enhance the alignment and compactness of feature representations. Extensive experiments on real EEG datasets demonstrate the effectiveness of MI-DAGSC, confirming that our method makes a valuable contribution to the MI-EEG decoding. Moreover, it holds great potential for various applications in brain–computer interface systems and neuroscience research. And the code of the proposed architecture in this study is available under https://github.com/zhangdx21/MI-DAGSC.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004276",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Electroencephalography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Dongxue"
      },
      {
        "surname": "Li",
        "given_name": "Huiying"
      },
      {
        "surname": "Xie",
        "given_name": "Jingmeng"
      },
      {
        "surname": "Li",
        "given_name": "Dajun"
      }
    ]
  },
  {
    "title": "Prediction of fluid flow in porous media by sparse observations and physics-informed PointNet",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.006",
    "abstract": "We predict steady-state Stokes flow of fluids within porous media at pore scales using sparse point observations and a novel class of physics-informed neural networks, called “physics-informed PointNet” (PIPN). Taking the advantages of PIPN into account, three new features become available compared to physics-informed convolutional neural networks for porous medium applications. First, the input of PIPN is exclusively the pore spaces of porous media (rather than both the pore and grain spaces). This feature diminishes required computer memory. Second, PIPN represents the boundary of pore spaces smoothly and realistically (rather than pixel-wise representations). Third, spatial resolution can vary over the physical domain (rather than equally spaced resolutions). This feature enables users to reach an optimal resolution with a minimum computational cost. The performance of our framework is evaluated by the study of the influence of noisy sensor data, pressure observations, and spatial correlation length.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004252",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Boundary (topology)",
      "Computer science",
      "Convolutional neural network",
      "Feature (linguistics)",
      "Flow (mathematics)",
      "Geology",
      "Geometry",
      "Geotechnical engineering",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pixel",
      "Porosity",
      "Porous medium"
    ],
    "authors": [
      {
        "surname": "Kashefi",
        "given_name": "Ali"
      },
      {
        "surname": "Mukerji",
        "given_name": "Tapan"
      }
    ]
  },
  {
    "title": "A scalable second order optimizer with an adaptive trust region for neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.010",
    "abstract": "We introduce Tadam (Trust region ADAptive Moment estimation), a new optimizer based on the trust region of the second-order approximation of the loss using the Fisher information matrix. Despite the enhanced gradient estimations offered by second-order approximations, their practical implementation requires sizable batch sizes to estimate the second-order approximation matrices and perform matrix inversions. Consequently, integrating second-order approximations entails additional memory consumption and imposes substantial computational demands due to the inversion of large matrices. In light of these challenges, we have devised a second-order approximation algorithm that mitigates these issues by judiciously approximating the pertinent large matrix, requiring only a marginal increase in memory usage while minimizing the computational burden. Tadam approximates the loss up to the second order using the Fisher information matrix. Since estimating the Fisher information matrix is expensive in both memory and time, Tadam approximates the Fisher information matrix and reduces the computational burdens to the O ( N ) level. Furthermore, Tadam employs an adaptive trust region scheme to reduce approximate errors and guarantee stability. Tadam evaluates how well it minimizes the loss function and uses this information to adjust the trust region dynamically. In addition, Tadam adjusts the learning rate internally, even if we provide the learning rate as a fixed constant. We run several experiments to measure Tadam’s performance against Adam, AMSGrad, Radam, and Nadam, which have the same space and time complexity as Tadam. The test results show that Tadam outperforms the benchmarks and finds reasonable solutions fast and stably.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300504X",
    "keywords": [
      "Algorithm",
      "Biology",
      "Composite material",
      "Computational complexity theory",
      "Computer science",
      "Database",
      "Fisher information",
      "Inversion (geology)",
      "Machine learning",
      "Materials science",
      "Mathematical optimization",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Paleontology",
      "Scalability",
      "Structural basin"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Donghee"
      },
      {
        "surname": "Cho",
        "given_name": "Junhyun"
      },
      {
        "surname": "Lee",
        "given_name": "Sungchul"
      }
    ]
  },
  {
    "title": "Efficient and accurate compound scaling for convolutional neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.053",
    "abstract": "Designing efficient and accurate network architectures to support various workloads, from servers to edge devices, is a fundamental problem as the use of Convolutional Neural Networks (ConvNets) becomes increasingly widespread. One simple yet effective method is to scale ConvNets by systematically adjusting the dimensions of the baseline network, including width, depth, and resolution, enabling it to adapt to diverse workloads by varying its computational complexity and representation ability. However, current state-of-the-art (SOTA) scaling methods for neural network architectures overlook the inter-dimensional relationships within the network and the impact of scaling on inference speed, resulting in suboptimal trade-offs between accuracy and inference speed. To overcome those limitations, we propose a scaling method for ConvNets that utilizes dimension relationship and runtime proxy constraints to improve accuracy and inference speed. Specifically, our research notes that higher input resolutions in convolutional layers lead to redundant filters (convolutional width) due to increased similarity between information in different positions, suggesting a potential benefit in reducing filters while increasing input resolution. Based on this observation, the relationship between the width and resolution is empirically quantified in our work, enabling models with higher parametric efficiency to be prioritized through our scaling strategy. Furthermore, we introduce a novel runtime prediction model that focuses on fine-grained layer tasks with different computational properties for more accurate identification of efficient network configurations. Comprehensive experiments show that our method outperforms prior works in creating a set of models with a trade-off between accuracy and inference speed on the ImageNet datasets for various ConvNets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004720",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Database",
      "Geometry",
      "Inference",
      "Machine learning",
      "Mathematics",
      "Scalability",
      "Scaling"
    ],
    "authors": [
      {
        "surname": "Lin",
        "given_name": "Chengmin"
      },
      {
        "surname": "Yang",
        "given_name": "Pengfei"
      },
      {
        "surname": "Wang",
        "given_name": "Quan"
      },
      {
        "surname": "Qiu",
        "given_name": "Zeyu"
      },
      {
        "surname": "Lv",
        "given_name": "Wenkai"
      },
      {
        "surname": "Wang",
        "given_name": "Zhenyi"
      }
    ]
  },
  {
    "title": "Sparse discriminant PCA based on contrastive learning and class-specificity distribution",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.061",
    "abstract": "Much mathematical effort has been devoted to developing Principal Component Analysis (PCA), which is the most popular feature extraction method. To suppress the negative effect of noise on PCA performance, there have been extensive studies and applications of a large number of robust PCAs achieving outstanding results. However, existing methods suffer from at least two shortcomings: (1) They expressed PCA as a reconstruction model measured by Euclidean distance, which only considers the relationship between the data and its reconstruction and ignores the differences between different data points; (2) They did not consider the class-specificity distribution information contained in the data itself, thus lacking discriminative properties. To overcome the above problems, we propose a Sparse Discriminant Principal Components Analysis (SDPCA) model based on contrastive learning and class-specificity distribution. Specifically, we use contrastive learning to measure the relationship between samples and their reconstructions, which fully takes the discriminative information between data into account in PCA. In order to make the extracted low-dimensional features profoundly reflect the class-specificity distribution of the data, we minimize the squared ℓ 1 , 2 -norm of the low-dimensional embedding. In addition, to reduce the effects of redundant features and noise and to improve the interpretability of PCA at the same time, we impose sparsity constraints on the projection matrix using the squared ℓ 1 , 2 -norm. Our experimental results on different types of benchmark databases demonstrate that our model has state-of-the-art performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004914",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Discriminant",
      "Discriminative model",
      "Euclidean distance",
      "Feature (linguistics)",
      "Interpretability",
      "Linear discriminant analysis",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Principal component analysis",
      "Sparse PCA"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Qian"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Wang",
        "given_name": "Qianqian"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "A novel feature-scrambling approach reveals the capacity of convolutional neural networks to learn spatial relations",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.021",
    "abstract": "Convolutional neural networks (CNNs) are one of the most successful computer vision systems to solve object recognition. Furthermore, CNNs have major applications in understanding the nature of visual representations in the human brain. Yet it remains poorly understood how CNNs actually make their decisions, what the nature of their internal representations is, and how their recognition strategies differ from humans. Specifically, there is a major debate about the question of whether CNNs primarily rely on surface regularities of objects, or whether they are capable of exploiting the spatial arrangement of features, similar to humans. Here, we develop a novel feature-scrambling approach to explicitly test whether CNNs use the spatial arrangement of features (i.e. object parts) to classify objects. We combine this approach with a systematic manipulation of effective receptive field sizes of CNNs as well as minimal recognizable configurations (MIRCs) analysis. In contrast to much previous literature, we provide evidence that CNNs are in fact capable of using relatively long-range spatial relationships for object classification. Moreover, the extent to which CNNs use spatial relationships depends heavily on the dataset, e.g. texture vs. sketch. In fact, CNNs even use different strategies for different classes within heterogeneous datasets (ImageNet), suggesting CNNs have a continuous spectrum of classification strategies. Finally, we show that CNNs learn the spatial arrangement of features only up to an intermediate level of granularity, which suggests that intermediate rather than global shape features provide the optimal trade-off between sensitivity and specificity in object classification. These results provide novel insights into the nature of CNN representations and the extent to which they rely on the spatial arrangement of features for object classification.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004410",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cognitive neuroscience of visual object recognition",
      "Computer science",
      "Convolutional neural network",
      "Feature (linguistics)",
      "Linguistics",
      "Mathematics",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Scrambling",
      "Spatial analysis",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Farahat",
        "given_name": "Amr"
      },
      {
        "surname": "Effenberger",
        "given_name": "Felix"
      },
      {
        "surname": "Vinck",
        "given_name": "Martin"
      }
    ]
  },
  {
    "title": "CollectiveNet-AltSpec: A collective concurrent CNN architecture of alternate specifications for EEG media perception and emotion tracing aided by multi-domain feature-augmentation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.031",
    "abstract": "Enhancing computability of cerebral recordings and connections made with human/non-human brain have been on track and are expected to propel in our current era. An effective contribution towards said ends is improving accuracy of attempts at discerning intricate phenomena taking place within human brain. Here and in two different capacities of experiments, we attempt to distinguish cerebral perceptions shaped and affective states surfaced during observation of samples of media incorporating distinct audio–visual and emotional contents, through employing electroencephalograph/EEG recorded sessions of two reputable datasets of DEAP and SEED. Here we introduce AltSpec(E3) the inceptive form of CollectiveNet intelligent computational architectures employing collective and concurrent multi-spec analysis to exploit complex patterns in complex data-structures. This processing technique uses a full array of diversification protocols with multifarious parts enabling surgical levels of optimization while integrating a holistic analysis of patterns. Data-structures designed here contain multi-electrode neuroinformatic and neurocognitive features studying emotion reactions and attentive patterns. These spatially and temporally featured 2D/3D constructs of domain-augmented data are eventually AI-processed and outputs are defragmented forming one definitive judgement. The media-perception tracing is arguably first of its kind, at least when implemented on mentioned datasets. Backed by this multi-directional approach and in subject-independent configurations for perception-tracing on 5-media-class basis, mean accuracies of 81.00% and 68.93% were obtained on DEAP and SEED, respectively. We also managed to classify emotions with accuracies of 61.59% and 66.21% in cross-dataset validation followed by 81.47% and 88.12% in cross-subject validation settings trained on DEAP and SEED, consecutively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004513",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Human–computer interaction",
      "Neuroscience",
      "Operating system",
      "Pattern recognition (psychology)",
      "Perception",
      "Psychology",
      "Tracing"
    ],
    "authors": [
      {
        "surname": "Faraji",
        "given_name": "Parham"
      },
      {
        "surname": "Khodabakhshi",
        "given_name": "Mohammad Bagher"
      }
    ]
  },
  {
    "title": "Sparse discriminant PCA based on contrastive learning and class-specificity distribution",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.061",
    "abstract": "Much mathematical effort has been devoted to developing Principal Component Analysis (PCA), which is the most popular feature extraction method. To suppress the negative effect of noise on PCA performance, there have been extensive studies and applications of a large number of robust PCAs achieving outstanding results. However, existing methods suffer from at least two shortcomings: (1) They expressed PCA as a reconstruction model measured by Euclidean distance, which only considers the relationship between the data and its reconstruction and ignores the differences between different data points; (2) They did not consider the class-specificity distribution information contained in the data itself, thus lacking discriminative properties. To overcome the above problems, we propose a Sparse Discriminant Principal Components Analysis (SDPCA) model based on contrastive learning and class-specificity distribution. Specifically, we use contrastive learning to measure the relationship between samples and their reconstructions, which fully takes the discriminative information between data into account in PCA. In order to make the extracted low-dimensional features profoundly reflect the class-specificity distribution of the data, we minimize the squared ℓ 1 , 2 -norm of the low-dimensional embedding. In addition, to reduce the effects of redundant features and noise and to improve the interpretability of PCA at the same time, we impose sparsity constraints on the projection matrix using the squared ℓ 1 , 2 -norm. Our experimental results on different types of benchmark databases demonstrate that our model has state-of-the-art performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004914",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Discriminant",
      "Discriminative model",
      "Euclidean distance",
      "Feature (linguistics)",
      "Interpretability",
      "Linear discriminant analysis",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Principal component analysis",
      "Sparse PCA"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Qian"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Wang",
        "given_name": "Qianqian"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "A multilayered bidirectional associative memory model for learning nonlinear tasks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.018",
    "abstract": "A multilayered bidirectional associative memory neural network is proposed to account for learning nonlinear types of association. The model (denoted as the MF-BAM) is composed of two modules, the Multi-Feature extracting bidirectional associative memory (MF), which contains various unsupervised network layers, and a modified Bidirectional Associative Memory (BAM), which consists of a single supervised network layer. The MF generates successive feature patterns from the original inputs. These patterns change the relationship between the inputs and targets in a way that the BAM can learn. The model was tested on different nonlinear tasks, such as the N-bit, Double Moon and its variants, and the 3-class spiral task. Behaviors were reported through learning errors, decision zones, and recall performances. Results showed that it was possible to learn all tasks consistently. By manipulating the number of units per layer and the number of unsupervised network layers in the MF, it was possible to change the level of nonlinearity observed in the decision boundaries. Furthermore, results indicated that different behaviors were achieved from the same set of inputs by using the different generated patterns. These findings are significant as they showed how a BAM-inspired model could solve nonlinear tasks in a more cognitively plausible fashion.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004392",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Associative property",
      "Bidirectional associative memory",
      "Chemistry",
      "Computer science",
      "Content-addressable memory",
      "Economics",
      "Feature (linguistics)",
      "Layer (electronics)",
      "Linguistics",
      "Management",
      "Mathematics",
      "Nonlinear system",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Programming language",
      "Pure mathematics",
      "Quantum mechanics",
      "Set (abstract data type)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Rolon-Mérette",
        "given_name": "Damiem"
      },
      {
        "surname": "Rolon-Mérette",
        "given_name": "Thaddé"
      },
      {
        "surname": "Chartier",
        "given_name": "Sylvain"
      }
    ]
  },
  {
    "title": "Boosting adversarial robustness via self-paced adversarial training",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.063",
    "abstract": "Adversarial training is considered one of the most effective methods to improve the adversarial robustness of deep neural networks. Despite the success, it still suffers from unsatisfactory performance and overfitting. Considering the intrinsic mechanism of adversarial training, recent studies adopt the idea of curriculum learning to alleviate overfitting. However, this also introduces new issues, that is, lacking the quantitative criterion for attacks’ strength and catastrophic forgetting. To mitigate such issues, we propose the self-paced adversarial training (SPAT), which explicitly builds the learning process of adversarial training based on adversarial examples of the whole dataset. Specifically, our model is first trained with “easy” adversarial examples, and then is continuously enhanced by gradually adding “complex” adversarial examples. This way strengthens the ability to fit “complex” adversarial examples while holding in mind “easy” adversarial samples. To balance adversarial examples between classes, we determine the difficulty of the adversarial examples locally in each class. Notably, this learning paradigm can also be incorporated into other advanced methods for further boosting adversarial robustness. Experimental results show the effectiveness of our proposed model against various attacks on widely-used benchmarks. Especially, on CIFAR100, SPAT provides a boost of 1.7% (relatively 5.4%) in robust accuracy on the PGD10 attack and 3.9% (relatively 7.2%) in natural accuracy for AWP.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004938",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Boosting (machine learning)",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Gene",
      "Machine learning",
      "Overfitting",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Lirong"
      },
      {
        "surname": "Ai",
        "given_name": "Qingzhong"
      },
      {
        "surname": "Yang",
        "given_name": "Xincheng"
      },
      {
        "surname": "Ren",
        "given_name": "Yazhou"
      },
      {
        "surname": "Wang",
        "given_name": "Qifan"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      }
    ]
  },
  {
    "title": "Layer adaptive node selection in Bayesian neural networks: Statistical guarantees and implementation details",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.029",
    "abstract": "Sparse deep neural networks have proven to be efficient for predictive model building in large-scale studies. Although several works have studied theoretical and numerical properties of sparse neural architectures, they have primarily focused on the edge selection. Sparsity through edge selection might be intuitively appealing; however, it does not necessarily reduce the structural complexity of a network. Instead pruning excessive nodes leads to a structurally sparse network with significant computational speedup during inference. To this end, we propose a Bayesian sparse solution using spike-and-slab Gaussian priors to allow for automatic node selection during training. The use of spike-and-slab prior alleviates the need of an ad-hoc thresholding rule for pruning. In addition, we adopt a variational Bayes approach to circumvent the computational challenges of traditional Markov Chain Monte Carlo (MCMC) implementation. In the context of node selection, we establish the fundamental result of variational posterior consistency together with the characterization of prior parameters. In contrast to the previous works, our theoretical development relaxes the assumptions of the equal number of nodes and uniform bounds on all network weights, thereby accommodating sparse networks with layer-dependent node structures or coefficient bounds. With a layer-wise characterization of prior inclusion probabilities, we discuss the optimal contraction rates of the variational posterior. We empirically demonstrate that our proposed approach outperforms the edge selection method in computational complexity with similar or better predictive performance. Our experimental evidence further substantiates that our theoretical work facilitates layer-wise optimal node recovery.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004495",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bayesian probability",
      "Biology",
      "Computational complexity theory",
      "Computer science",
      "Engineering",
      "Machine learning",
      "Markov chain Monte Carlo",
      "Mathematical optimization",
      "Mathematics",
      "Node (physics)",
      "Prior probability",
      "Pruning",
      "Structural engineering"
    ],
    "authors": [
      {
        "surname": "Jantre",
        "given_name": "Sanket"
      },
      {
        "surname": "Bhattacharya",
        "given_name": "Shrijita"
      },
      {
        "surname": "Maiti",
        "given_name": "Tapabrata"
      }
    ]
  },
  {
    "title": "Glimpse and focus: Global and local-scale graph convolution network for skeleton-based action recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.051",
    "abstract": "In the 3D skeleton-based action recognition task, learning rich spatial and temporal motion patterns from body joints are two foundational yet under-explored problems. In this paper, we propose two methods for improving these problems: (I) a novel glimpse-focus action recognition strategy that captures multi-range pose features from the whole body and key body parts jointly; (II) a powerful temporal feature extractor JD-TC that enriches trajectory features by inferring different inter-frame correlations for different joints. By coupling these two proposals, we develop a powerful skeleton-based action recognition system that extracts rich pose and trajectory features from a skeleton sequence and outperforms previous state-of-the-art methods on three large-scale datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004458",
    "keywords": [
      "Action recognition",
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Class (philosophy)",
      "Computer science",
      "Computer vision",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Engineering",
      "Extractor",
      "Feature (linguistics)",
      "Feature extraction",
      "Focus (optics)",
      "Frame (networking)",
      "Graph",
      "Linguistics",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Process engineering",
      "Programming language",
      "Quantum mechanics",
      "Scale (ratio)",
      "Skeleton (computer programming)",
      "Telecommunications",
      "Theoretical computer science",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Xuehao"
      },
      {
        "surname": "Du",
        "given_name": "Shaoyi"
      },
      {
        "surname": "Yang",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "A varying-parameter fixed-time gradient-based dynamic network for convex optimization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.047",
    "abstract": "We focus on the fixed-time convergence and robustness of gradient-based dynamic networks for solving convex optimization. Most of the existing gradient-based dynamic networks with fixed-time convergence have limited ability to resist interferences of noises. To improve the convergence of the gradient-based dynamic networks, we design a new activation function and propose a gradient-based dynamic network with fixed-time convergence. The proposed dynamic network has a smaller upper bound of the convergence time than the existing dynamic networks with fixed-time convergence. A time-varying scaling parameter is employed to speed up the convergence. Our gradient-based dynamic network is proved to be robust against bounded noises and is able to resist the interference of unbounded noises. The numerical tests illustrate the effectiveness and superiority of the proposed network.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004677",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Bounded function",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Dynamic network analysis",
      "Economic growth",
      "Economics",
      "Gene",
      "Gradient method",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Dan"
      },
      {
        "surname": "Liu",
        "given_name": "Xin-Wei"
      }
    ]
  },
  {
    "title": "ShuffleTrans: Patch-wise weight shuffle for transparent object segmentation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.011",
    "abstract": "Transparent objects widely exist in the world. The task of transparent object segmentation is challenging as the object lacks its own texture. The cue of shape information therefore gets more critical. Most existing methods, however, rely on the mechanism of simple convolution, which is good at local cues and performs weakly on global cues like shape. To solve this problem, an operation named Patch-wise Weight Shuffle is proposed to bring in the global context cue by being combined with the dynamic convolution. A network ShuffleTrans that recognizes shape better is then designed based on this operation. Besides, fitter for this task, two auxiliary modules are presented in ShuffleTrans: a Boundary and Direction Refinement Module which collects two additional information, and a Channel Attention Enhancement Module that assists the above operation. Experiments on four texture-less object segmentation datasets and two normal datasets verify the effectiveness and generality of the method. Especially, the ShuffleTrans achieved 74.93% mIoU on the Trans10k v2 test set, which is more accurate than existing methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004318",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Boundary (topology)",
      "Computer science",
      "Computer vision",
      "Context (archaeology)",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Economics",
      "Generality",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Object (grammar)",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Programming language",
      "Psychology",
      "Psychotherapist",
      "Segmentation",
      "Set (abstract data type)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Boxiang"
      },
      {
        "surname": "Wang",
        "given_name": "Zunran"
      },
      {
        "surname": "Ling",
        "given_name": "Yonggen"
      },
      {
        "surname": "Guan",
        "given_name": "Yuanyuan"
      },
      {
        "surname": "Zhang",
        "given_name": "Shenghao"
      },
      {
        "surname": "Li",
        "given_name": "Wenhui"
      },
      {
        "surname": "Wei",
        "given_name": "Lei"
      },
      {
        "surname": "Zhang",
        "given_name": "Chunxu"
      }
    ]
  },
  {
    "title": "Measuring multivariate phase synchronization with symbolization and permutation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.007",
    "abstract": "Phase synchronization is an important mechanism for the information processing of neurons in the brain. Most of the current phase synchronization measures are bivariate and focus on the synchronization between pairs of time series. However, these methods do not provide a full picture of global interactions in neural systems. Considering the prevalence and importance of multivariate neural signal analysis, there is an urgent need to quantify global phase synchronization (GPS) in neural networks. Therefore, we propose a new measure named symbolic phase difference and permutation entropy (SPDPE), which symbolizes the phase difference in multivariate neural signals and estimates GPS according to the permutation patterns of the symbolic sequences. The performance of SPDPE was evaluated using simulated data generated by Kuramoto and Rössler model. The results demonstrate that SPDPE exhibits low sensitivity to data length and outperforms existing methods in accurately characterizing GPS and effectively resisting noise. Moreover, to validate the method with real data, it was applied to classify seizures and non-seizures by calculating the GPS of stereoelectroencephalography (SEEG) data recorded from the onset zones of ten epilepsy patients. We believe that SPDPE will improve the estimation of GPS in many applications, such as EEG-based brain–computer interfaces, brain modeling, and simultaneous EEG-fMRI analysis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003659",
    "keywords": [
      "Acoustics",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bivariate analysis",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Data mining",
      "Electroencephalography",
      "Epilepsy surgery",
      "Focus (optics)",
      "Global Positioning System",
      "Image (mathematics)",
      "Machine learning",
      "Multivariate statistics",
      "Neuroscience",
      "Noise (video)",
      "Optics",
      "Pattern recognition (psychology)",
      "Permutation (music)",
      "Phase synchronization",
      "Physics",
      "Psychology",
      "Stereoelectroencephalography",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Zhaohui"
      },
      {
        "surname": "Wang",
        "given_name": "Xinyan"
      },
      {
        "surname": "Xing",
        "given_name": "Yanyu"
      },
      {
        "surname": "Zhang",
        "given_name": "Xi"
      },
      {
        "surname": "Yu",
        "given_name": "Tao"
      },
      {
        "surname": "Li",
        "given_name": "Xiaoli"
      }
    ]
  },
  {
    "title": "Hybrid learning mechanisms under a neural control network for various walking speed generation of a quadruped robot",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.030",
    "abstract": "Legged robots that can instantly change motor patterns at different walking speeds are useful and can accomplish various tasks efficiently. However, state-of-the-art control methods either are difficult to develop or require long training times. In this study, we present a comprehensible neural control framework to integrate probability-based black-box optimization ( PI BB ) and supervised learning for robot motor pattern generation at various walking speeds. The control framework structure is based on a combination of a central pattern generator (CPG), a radial basis function (RBF) -based premotor network and a hypernetwork, resulting in a so-called neural CPG-RBF-hyper control network. First, the CPG-driven RBF network, acting as a complex motor pattern generator, was trained to learn policies (multiple motor patterns) for different speeds using PI BB . We also introduce an incremental learning strategy to avoid local optima. Second, the hypernetwork, which acts as a task/behavior to control parameter mapping, was trained using supervised learning. It creates a mapping between the internal CPG frequency (reflecting the walking speed) and motor behavior. This map represents the prior knowledge of the robot, which contains the optimal motor joint patterns at various CPG frequencies. Finally, when a user-defined robot walking frequency or speed is provided, the hypernetwork generates the corresponding policy for the CPG-RBF network. The result is a versatile locomotion controller which enables a quadruped robot to perform stable and robust walking at different speeds without sensory feedback. The policy of the controller was trained in the simulation (less than 1 h ) and capable of transferring to a real robot. The generalization ability of the controller was demonstrated by testing the CPG frequencies that were not encountered during training.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004501",
    "keywords": [
      "Aesthetics",
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Central pattern generator",
      "Chip",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Digital pattern generator",
      "Philosophy",
      "Rhythm",
      "Robot",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yanbin"
      },
      {
        "surname": "Thor",
        "given_name": "Mathias"
      },
      {
        "surname": "Dilokthanakul",
        "given_name": "Nat"
      },
      {
        "surname": "Dai",
        "given_name": "Zhendong"
      },
      {
        "surname": "Manoonpong",
        "given_name": "Poramate"
      }
    ]
  },
  {
    "title": "Communication-efficient federated learning with stagewise training strategy",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.033",
    "abstract": "The efficiency of communication across workers is a significant factor that affects the performance of federated learning. Though periodic communication strategy is applied to reduce communication rounds in training, the communication cost is still high when the training data distributions are not independently and identically distributed (non-IID) which is common in federated learning. Recently, some works introduce variance reduction to eliminate the effect caused by non-IID data among workers. Nevertheless the provable optimal communication complexity O ( log ( S T ) ) and convergence rate O ( 1 / ( S T ) ) cannot be achieved simultaneously, where S denotes the number of sampled workers in each round and T is the number of iterations. To deal with this dilemma, we propose an optimization algorithm SQUARFA that adopts stagewise training framework coupling with variance reduction and uses a quick-start phase in each loop. Theoretical results show that SQUARFA achieves both optimal convergence rate and communication complexity for both strongly convex objectives and non-convex objectives under PL condition, thus fills the gap mentioned above. Then, a variant of SQUARFA yields the optimal theoretical results for general non-convex objectives. We further extend the technique in SQUARFA to the large batch setting and achieve optimal communication complexity. Experimental results demonstrate the superiority of the proposed algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004549",
    "keywords": [
      "Accounting",
      "Algorithm",
      "Artificial intelligence",
      "Binary logarithm",
      "Business",
      "Channel (broadcasting)",
      "Communication complexity",
      "Computer science",
      "Convergence (economics)",
      "Dilemma",
      "Discrete mathematics",
      "Economic growth",
      "Economics",
      "Factor (programming language)",
      "Geometry",
      "Independent and identically distributed random variables",
      "Mathematical optimization",
      "Mathematics",
      "Meteorology",
      "Physics",
      "Programming language",
      "Random variable",
      "Rate of convergence",
      "Reduction (mathematics)",
      "Regular polygon",
      "Statistics",
      "Telecommunications",
      "Training (meteorology)",
      "Variance (accounting)",
      "Variance reduction"
    ],
    "authors": [
      {
        "surname": "Cheng",
        "given_name": "Yifei"
      },
      {
        "surname": "Shen",
        "given_name": "Shuheng"
      },
      {
        "surname": "Liang",
        "given_name": "Xianfeng"
      },
      {
        "surname": "Liu",
        "given_name": "Jingchang"
      },
      {
        "surname": "Chen",
        "given_name": "Joya"
      },
      {
        "surname": "Zhang",
        "given_name": "Tie"
      },
      {
        "surname": "Chen",
        "given_name": "Enhong"
      }
    ]
  },
  {
    "title": "Bidirectionally self-normalizing neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.017",
    "abstract": "The problem of vanishing and exploding gradients has been a long-standing obstacle that hinders the effective training of neural networks. Despite various tricks and techniques that have been employed to alleviate the problem in practice, there still lacks satisfactory theories or provable solutions. In this paper, we address the problem from the perspective of high-dimensional probability theory. We provide a rigorous result that shows, under mild conditions, how the vanishing/exploding gradients problem disappears with high probability if the neural networks have sufficient width. Our main idea is to constrain both forward and backward signal propagation in a nonlinear neural network through a new class of activation functions, namely Gaussian–Poincaré normalized functions, and orthogonal weight matrices. Experiments on both synthetic and real-world data validate our theory and confirm its effectiveness on very deep neural networks when applied in practice.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004367",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Computer science",
      "Deep neural networks",
      "Gaussian",
      "Law",
      "Mathematics",
      "Nonlinear system",
      "Obstacle",
      "Perspective (graphical)",
      "Physics",
      "Political science",
      "Programming language",
      "Quantum mechanics",
      "SIGNAL (programming language)"
    ],
    "authors": [
      {
        "surname": "Lu",
        "given_name": "Yao"
      },
      {
        "surname": "Gould",
        "given_name": "Stephen"
      },
      {
        "surname": "Ajanthan",
        "given_name": "Thalaiyasingam"
      }
    ]
  },
  {
    "title": "Hierarchical Knowledge Propagation and Distillation for Few-Shot Learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.040",
    "abstract": "Recent research efforts on Few-Shot Learning (FSL) have achieved extensive progress. However, the existing efforts primarily focus on the transductive setting of FSL, which is heavily challenged by the limited quantity of the unlabeled query set. Although a few inductive-based FSL methods have been studied, most of them emphasize learning superb feature extraction networks. As a result, they may ignore the relations between sample-level and class-level representations, which are particularly crucial when labeled samples are scarce. This paper proposes an inductive FSL framework that leverages the Hierarchical Knowledge Propagation and Distillation, named HKPD. To learn more discriminative sample-level representations, HKPD first constructs a sample-level information propagation module that explores pairwise sample relations. Subsequently, a class-level information propagation module is designed to obtain and update the class-level information. Moreover, a self-distillation module is adopted to further improve the learned representations by propagating the obtained knowledge across this hierarchical architecture. Extensive experiments conducted on the commonly used few-shot benchmark datasets demonstrate the superiority of the proposed HKPD method, which outperforms the current state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004604",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Chemistry",
      "Chromatography",
      "Class (philosophy)",
      "Computer science",
      "Discriminative model",
      "Distillation",
      "Feature (linguistics)",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Organic chemistry",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Sample (material)",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Chunpeng"
      },
      {
        "surname": "Wang",
        "given_name": "Haishuai"
      },
      {
        "surname": "Zhou",
        "given_name": "Sheng"
      },
      {
        "surname": "Yu",
        "given_name": "Zhi"
      },
      {
        "surname": "Bandara",
        "given_name": "Danushka"
      },
      {
        "surname": "Bu",
        "given_name": "Jiajun"
      }
    ]
  },
  {
    "title": "A knowledge-based learning framework for self-supervised pre-training towards enhanced recognition of biomedical microscopy images",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.09.001",
    "abstract": "Self-supervised pre-training has become the priory choice to establish reliable neural networks for automated recognition of massive biomedical microscopy images, which are routinely annotation-free, without semantics, and without guarantee of quality. Note that this paradigm is still at its infancy and limited by closely related open issues: (1) how to learn robust representations in an unsupervised manner from unlabeled biomedical microscopy images of low diversity in samples? and (2) how to obtain the most significant representations demanded by a high-quality segmentation? Aiming at these issues, this study proposes a knowledge-based learning framework (TOWER) towards enhanced recognition of biomedical microscopy images, which works in three phases by synergizing contrastive learning and generative learning methods: (1) Sample Space Diversification: Reconstructive proxy tasks have been enabled to embed a priori knowledge with context highlighted to diversify the expanded sample space; (2) Enhanced Representation Learning: Informative noise-contrastive estimation loss regularizes the encoder to enhance representation learning of annotation-free images; (3) Correlated Optimization: Optimization operations in pre-training the encoder and the decoder have been correlated via image restoration from proxy tasks, targeting the need for semantic segmentation. Experiments have been conducted on public datasets of biomedical microscopy images against the state-of-the-art counterparts (e.g., SimCLR and BYOL), and results demonstrate that: TOWER statistically excels in all self-supervised methods, achieving a Dice improvement of 1.38 percentage points over SimCLR. TOWER also has potential in multi-modality medical image analysis and enables label-efficient semi-supervised learning, e.g., reducing the annotation cost by up to 99% in pathological classification.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300494X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Feature learning",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Segmentation",
      "Supervised learning"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Wei"
      },
      {
        "surname": "Li",
        "given_name": "Chen"
      },
      {
        "surname": "Chen",
        "given_name": "Dan"
      },
      {
        "surname": "Luo",
        "given_name": "Xin"
      }
    ]
  },
  {
    "title": "Block-level dependency syntax based model for end-to-end aspect-based sentiment analysis",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.008",
    "abstract": "End-to-End aspect-based sentiment analysis (E2E-ABSA) aims to jointly extract aspect terms and identify their sentiment polarities. Although previous research has demonstrated that syntax knowledge can be beneficial for E2E-ABSA, standard syntax dependency parsing struggles to capture the block-level relation between aspect and opinion terms, which hinders the role of syntax in E2E-ABSA. To address this issue, this paper proposes a block-level dependency syntax parsing (BDEP) based model to enhance the performance of E2E-ABSA. BDEP is constructed by incorporating routine dependency syntax parsing and part-of-speech tagging, which enables the capture of block-level relations. Subsequently. the BDEP-guided interactive attention module (BDEP-IAM) is used to obtain the aspect-aware representation of each word. Finally the adaptive fusion module is leveraged to combine the semantic-syntactic representation to simultaneously extract the aspect term and identify aspect-orient sentiment polarity. The model is evaluated on five benchmark datasets, including Laptop14, Rest _ALL, Restaurant14, Restaurant15, and TWITTER, with F1 scores of 62.67%, 76.53%, 75.42%, 62.21%, and 58.03%, respectively. The results show that our model outperforms the other compared state-of-the-art (SOTA) methods on all datasets. Additionally, ablation experiments confirm the efficacy of BDEP and IAM in improving aspect-level sentiment analysis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002496",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Block (permutation group theory)",
      "Computer science",
      "Dependency (UML)",
      "Dependency grammar",
      "Geodesy",
      "Geography",
      "Geometry",
      "Law",
      "Mathematics",
      "Natural language processing",
      "Parsing",
      "Political science",
      "Politics",
      "Programming language",
      "Representation (politics)",
      "Semantics (computer science)",
      "Sentiment analysis",
      "Syntax"
    ],
    "authors": [
      {
        "surname": "Xiang",
        "given_name": "Yan"
      },
      {
        "surname": "Zhang",
        "given_name": "Jiqun"
      },
      {
        "surname": "Guo",
        "given_name": "Junjun"
      }
    ]
  },
  {
    "title": "Lightweight image super-resolution based multi-order gated aggregation network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.002",
    "abstract": "Recently, Transformer-based models are taken much focus on solving the task of image super-resolution (SR) due to their ability to achieve better performance. However, these models combined huge computational cost during the computing self-attention mechanism. To solve this problem, we proposed a multi-order gated aggregation super-resolution network (MogaSRN) for low-level vision based on the concept of the MogaNet that is developed for high-level vision. The concept of the MogaSRN model is based on spatial multi-order context aggregation and adaptive channel-wise reallocation with the aid of the multi-layer perceptron (MLP). In contrast to the MogaNet model, in which the resolution of each stage decreased by a factor of 2, the resolution of the MogaSRN is stayed fixed during the deep features extraction. Moreover, the structure of the MogaSRN model is built based on balancing the performance and the model complexity. We evaluated our model based on five benchmark datasets concluding that the MogaSRN model can achieve significant improvements compared to the state-of-the-art. Moreover, our model shows the good visual quality and accuracy of the reconstruction. Finally, our model has 3.7 × faster runtime at the scale of × 4 compared to LWSwinIR with better performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003611",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Data mining",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Perceptron"
    ],
    "authors": [
      {
        "surname": "Gendy",
        "given_name": "Garas"
      },
      {
        "surname": "Sabor",
        "given_name": "Nabil"
      },
      {
        "surname": "He",
        "given_name": "Guanghui"
      }
    ]
  },
  {
    "title": "Dual memory model for experience-once task-incremental lifelong learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.009",
    "abstract": "Experience replay (ER) is a widely-adopted neuroscience-inspired method to perform lifelong learning. Nonetheless, existing ER-based approaches consider very coarse memory modules with simple memory and rehearsal mechanisms that cannot fully exploit the potential of memory replay. Evidence from neuroscience has provided fine-grained memory and rehearsal mechanisms, such as the dual-store memory system consisting of PFC-HC circuits. However, the computational abstraction of these processes is still very challenging. To address these problems, we introduce the Dual-Memory (Dual-MEM) model emulating the memorization, consolidation, and rehearsal process in the PFC-HC dual-store memory circuit. Dual-MEM maintains an incrementally updated short-term memory to benefit current-task learning. At the end of the current task, short-term memories will be consolidated into long-term ones for future rehearsal to alleviate forgetting. For the Dual-MEM optimization, we propose two learning policies that emulate different memory retrieval strategies: Direct Retrieval Learning and Mixup Retrieval Learning. Extensive evaluations on eight benchmarks demonstrate that Dual-MEM delivers compelling performance while maintaining high learning and memory utilization efficiencies under the challenging experience-once setting.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003672",
    "keywords": [
      "Art",
      "Artificial intelligence",
      "Cognitive psychology",
      "Computer hardware",
      "Computer science",
      "Dual (grammatical number)",
      "Economics",
      "Forgetting",
      "Hippocampus",
      "Literature",
      "Management",
      "Memorization",
      "Memory consolidation",
      "Memory model",
      "Neuroscience",
      "Psychology",
      "Shared memory",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Ma",
        "given_name": "Gehua"
      },
      {
        "surname": "Jiang",
        "given_name": "Runhao"
      },
      {
        "surname": "Wang",
        "given_name": "Lang"
      },
      {
        "surname": "Tang",
        "given_name": "Huajin"
      }
    ]
  },
  {
    "title": "A mathematical framework for improved weight initialization of neural networks using Lagrange multipliers",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.035",
    "abstract": "A good weight initialization is crucial to accelerate the convergence of the weights in a neural network. However, training a neural network is still time-consuming, despite recent advances in weight initialization approaches. In this paper, we propose a mathematical framework for the weight initialization in the last layer of a neural network. We first derive analytically a tight constraint on the weights that accelerates the convergence of the weights during the back-propagation algorithm. We then use linear regression and Lagrange multipliers to analytically derive the optimal initial weights and initial bias of the last layer, that minimize the initial training loss given the derived tight constraint. We also show that the restrictive assumption of traditional weight initialization algorithms that the expected value of the weights is zero is redundant for our approach. We first apply our proposed weight initialization approach to a Convolutional Neural Network that predicts the Remaining Useful Life of aircraft engines. The initial training and validation loss are relatively small, the weights do not get stuck in a local optimum, and the convergence of the weights is accelerated. We compare our approach with several benchmark strategies. Compared to the best performing state-of-the-art initialization strategy (Kaiming initialization), our approach needs 34% less epochs to reach the same validation loss. We also apply our approach to ResNets for the CIFAR-100 dataset, combined with transfer learning. Here, the initial accuracy is already at least 53%. This gives a faster weight convergence and a higher test accuracy than the benchmark strategies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003921",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Geodesy",
      "Geography",
      "Initialization",
      "Lagrange multiplier",
      "Mathematical optimization",
      "Mathematics",
      "Programming language"
    ],
    "authors": [
      {
        "surname": "de Pater",
        "given_name": "Ingeborg"
      },
      {
        "surname": "Mitici",
        "given_name": "Mihaela"
      }
    ]
  },
  {
    "title": "InfraNet: Accurate forehead temperature measurement framework for people in the wild with monocular thermal infrared camera",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.038",
    "abstract": "During an epidemic, accurate human temperature screening based on neural networks for disease surveillance is important and challenging. Existing distant human forehead temperature measuring device usually adopts a dual-camera system using paired RGB and thermal infrared images to conduct face detection and temperature measurement. Since the facial RGB image may undermine people’s privacy, we designed a monocular thermal system and proposed an effective framework called the InfraNet to measure and calibrate forehead temperature of people in the wild. To address the challenge of temperature floating, the InfraNet calibrates the subject’s temperature with one’s physical depth and horizontal offset predicted by a single infrared image. Our InfraNet framework mainly consists of three parts: face detection subnet, depth and horizontal offset estimation subnet and temperature calibration subnet. The temperature calibration performance can be improved with the help of spatial regularization term concentrating on predicting precise depth and horizontal offset of people. Besides, we collected a large-scale infrared image dataset in the both lab and wild scenarios, including 8,215 thermal infrared images. Experiments on our wild dataset demonstrated that the InfraNet achieved 91.6% high accuracy of distant multi-subject temperature measurement on average under the standard temperature threshold of strict 0.3°C.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003969",
    "keywords": [
      "Artificial intelligence",
      "Calibration",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Forehead",
      "Geology",
      "Image (mathematics)",
      "Infrared",
      "Medicine",
      "Monocular",
      "Offset (computer science)",
      "Optics",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "RGB color model",
      "Remote sensing",
      "Subnet",
      "Surgery",
      "Temperature measurement",
      "Thresholding"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Xichuan"
      },
      {
        "surname": "Lei",
        "given_name": "Dongshan"
      },
      {
        "surname": "Long",
        "given_name": "Chunqiao"
      },
      {
        "surname": "Nie",
        "given_name": "Jing"
      },
      {
        "surname": "Liu",
        "given_name": "Haijun"
      }
    ]
  },
  {
    "title": "Adaptive event-triggered extended dissipative synchronization of delayed reaction–diffusion neural networks under deception attacks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.024",
    "abstract": "Under spatially averaged measurements (SAMs) and deception attacks, this article mainly studies the problem of extended dissipativity output synchronization of delayed reaction–diffusion neural networks via an adaptive event-triggered sampled-data (AETSD) control strategy. Compared with the existing ETSD control methods with constant thresholds, our scheme can be adaptively adjusted according to the current sampling and latest transmitted signals and is realized based on limited sensors and actuators. Firstly, an AETSD control scheme is proposed to save the limited transmission channel. Secondly, some synchronization criteria under SAMs and deception attacks are established by utilizing Lyapunov–Krasovskii functional and inequality techniques. Then, by solving linear matrix inequalities (LMIs), we obtain the desired AETSD controller, which can satisfy the specified level of extended dissipativity behaviors. Lastly, one numerical example is given to demonstrate the validity of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003829",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Deception",
      "Dissipative system",
      "Law",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Political science",
      "Quantum mechanics",
      "Reaction–diffusion system",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Transmission (telecommunications)"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Feng-Liang"
      },
      {
        "surname": "Wang",
        "given_name": "Zi-Peng"
      },
      {
        "surname": "Qiao",
        "given_name": "Junfei"
      },
      {
        "surname": "Wu",
        "given_name": "Huai-Ning"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Visual information processing through the interplay between fine and coarse signal pathways",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.048",
    "abstract": "Object recognition is often viewed as a feedforward, bottom-up process in machine learning, but in real neural systems, object recognition is a complicated process which involves the interplay between two signal pathways. One is the parvocellular pathway (P-pathway), which is slow and extracts fine features of objects; the other is the magnocellular pathway (M-pathway), which is fast and extracts coarse features of objects. It has been suggested that the interplay between the two pathways endows the neural system with the capacity of processing visual information rapidly, adaptively, and robustly. However, the underlying computational mechanism remains largely unknown. In this study, we build a two-pathway model to elucidate the computational properties associated with the interactions between two visual pathways. Specifically, we model two visual pathways using two convolution neural networks: one mimics the P-pathway, referred to as FineNet, which is deep, has small-size kernels, and receives detailed visual inputs; the other mimics the M-pathway, referred to as CoarseNet, which is shallow, has large-size kernels, and receives blurred visual inputs. We show that CoarseNet can learn from FineNet through imitation to improve its performance, FineNet can benefit from the feedback of CoarseNet to improve its robustness to noise; and the two pathways interact with each other to achieve rough-to-fine information processing. Using visual backward masking as an example, we further demonstrate that our model can explain visual cognitive behaviors that involve the interplay between two pathways. We hope that this study gives us insight into understanding the interaction principles between two visual pathways.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004069",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Central nervous system",
      "Cognitive neuroscience of visual object recognition",
      "Computational model",
      "Computer science",
      "Control engineering",
      "Engineering",
      "Feed forward",
      "Gene",
      "Neuroscience",
      "Object (grammar)",
      "Parvocellular cell",
      "Perception",
      "Robustness (evolution)",
      "Visual cortex",
      "Visual processing",
      "Visual system"
    ],
    "authors": [
      {
        "surname": "Zou",
        "given_name": "Xiaolong"
      },
      {
        "surname": "Ji",
        "given_name": "Zilong"
      },
      {
        "surname": "Zhang",
        "given_name": "Tianqiu"
      },
      {
        "surname": "Huang",
        "given_name": "Tiejun"
      },
      {
        "surname": "Wu",
        "given_name": "Si"
      }
    ]
  },
  {
    "title": "Unsupervised feature selection based on variance–covariance subspace distance",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.018",
    "abstract": "Subspace distance is an invaluable tool exploited in a wide range of feature selection methods. The power of subspace distance is that it can identify a representative subspace, including a group of features that can efficiently approximate the space of original features. On the other hand, employing intrinsic statistical information of data can play a significant role in a feature selection process. Nevertheless, most of the existing feature selection methods founded on the subspace distance are limited in properly fulfilling this objective. To pursue this void, we propose a framework that takes a subspace distance into account which is called “Variance–Covariance subspace distance”. The approach gains advantages from the correlation of information included in the features of data, thus determines all the feature subsets whose corresponding Variance–Covariance matrix has the minimum norm property. Consequently, a novel, yet efficient unsupervised feature selection framework is introduced based on the Variance–Covariance distance to handle both the dimensionality reduction and subspace learning tasks. The proposed framework has the ability to exclude those features that have the least variance from the original feature set. Moreover, an efficient update algorithm is provided along with its associated convergence analysis to solve the optimization side of the proposed approach. An extensive number of experiments on nine benchmark datasets are also conducted to assess the performance of our method from which the results demonstrate its superiority over a variety of state-of-the-art unsupervised feature selection methods. The source code is available at https://github.com/SaeedKarami/VCSDFS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003295",
    "keywords": [
      "Accounting",
      "Artificial intelligence",
      "Business",
      "Computer science",
      "Covariance",
      "Feature (linguistics)",
      "Feature selection",
      "Linguistics",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Selection (genetic algorithm)",
      "Statistics",
      "Subspace topology",
      "Variance (accounting)"
    ],
    "authors": [
      {
        "surname": "Karami",
        "given_name": "Saeed"
      },
      {
        "surname": "Saberi-Movahed",
        "given_name": "Farid"
      },
      {
        "surname": "Tiwari",
        "given_name": "Prayag"
      },
      {
        "surname": "Marttinen",
        "given_name": "Pekka"
      },
      {
        "surname": "Vahdati",
        "given_name": "Sahar"
      }
    ]
  },
  {
    "title": "Solving classification tasks by a receptron based on nonlinear optical speckle fields",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.001",
    "abstract": "Among several approaches to tackle the problem of energy consumption in modern computing systems, two solutions are currently investigated: one consists of artificial neural networks (ANNs) based on photonic technologies, the other is a different paradigm compared to ANNs and it is based on random networks of non-linear nanoscale junctions resulting from the assembling of nanoparticles or nanowires as substrates for neuromorphic computing. These networks show the presence of emergent complexity and collective phenomena in analogy with biological neural networks characterized by self-organization, redundancy, and non-linearity. Starting from this background, we propose and formalize a generalization of the perceptron model to describe a classification device based on a network of interacting units where the input weights are non-linearly dependent. We show that this model, called “receptron”, provides substantial advantages compared to the perceptron as, for example, the solution of non-linearly separable Boolean functions with a single device. The receptron model is used as a starting point for the implementation of an all-optical device that exploits the non-linearity of optical speckle fields produced by a solid scatterer. By encoding these speckle fields we generated a large variety of target Boolean functions. We demonstrate that by properly setting the model parameters, different classes of functions with different multiplicity can be solved efficiently. The optical implementation of the receptron scheme opens the way for the fabrication of a completely new class of optical devices for neuromorphic data processing based on a very simple hardware.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004203",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Electronic engineering",
      "Engineering",
      "Neuromorphic engineering",
      "Nonlinear system",
      "Optical computing",
      "Perceptron",
      "Physics",
      "Quantum mechanics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Paroli",
        "given_name": "B."
      },
      {
        "surname": "Martini",
        "given_name": "G."
      },
      {
        "surname": "Potenza",
        "given_name": "M.A.C."
      },
      {
        "surname": "Siano",
        "given_name": "M."
      },
      {
        "surname": "Mirigliano",
        "given_name": "M."
      },
      {
        "surname": "Milani",
        "given_name": "P."
      }
    ]
  },
  {
    "title": "Inhibitory stabilized network behaviour in a balanced neural mass model of a cortical column",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.020",
    "abstract": "Strong inhibitory recurrent connections can reduce the tendency for a neural network to become unstable. This is known as inhibitory stabilization; networks that are unstable in the absence of strong inhibitory feedback because of their unstable excitatory recurrent connections are known as Inhibition Stabilized Networks (ISNs). One of the characteristics of ISNs is their “paradoxical response”, where perturbing the inhibitory neurons with additional excitatory input results in a decrease in their activity after a temporal delay instead of increasing their activity. Here, we develop a model of populations of neurons across different layers of cortex. Within each layer, there is one population of inhibitory neurons and one population of excitatory neurons. The connectivity weights across different populations in the model are derived from a synaptic physiology database provided by the Allen Institute. The model shows a gradient of excitation–inhibition balance across different layers in the cortex, where superficial layers are more inhibitory dominated compared to deeper layers. To investigate the presence of ISNs across different layers, we measured the membrane potentials of neural populations in the model after perturbing inhibitory populations. The results show that layer 2/3 in the model does not operate in the ISN regime but layers 4 and 5 do operate in the ISN regime. These results accord with neurophysiological findings that explored the presence of ISNs across different layers in the cortex. The results show that there may be a systematic macroscopic gradient of inhibitory stabilization across different layers in the cortex that depends on the level of excitation–inhibition balance, and that the strength of the paradoxical response increases as the model moves closer to bifurcation points.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003775",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Chemistry",
      "Computer science",
      "Cortex (anatomy)",
      "Environmental health",
      "Excitatory postsynaptic potential",
      "Inhibitory postsynaptic potential",
      "Layer (electronics)",
      "Medicine",
      "Neuroscience",
      "Organic chemistry",
      "Physics",
      "Population"
    ],
    "authors": [
      {
        "surname": "Zarei Eskikand",
        "given_name": "Parvin"
      },
      {
        "surname": "Soto-Breceda",
        "given_name": "Artemio"
      },
      {
        "surname": "Cook",
        "given_name": "Mark J."
      },
      {
        "surname": "Burkitt",
        "given_name": "Anthony N."
      },
      {
        "surname": "Grayden",
        "given_name": "David B."
      }
    ]
  },
  {
    "title": "Event-based fixed-time synchronization of neural networks under DoS attack and its applications",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.046",
    "abstract": "In this paper, the fixed-time synchronization control for neural networks with discontinuous data communication is investigated. Due to the transmission blocking caused by DoS attack, it is intractable to establish a monotonically decreasing Lyapunov function like the conventional analysis of fixed-time stability. Therefore, by virtue of recursive and reduction to absurdity approaches, novel fixed-time stability criteria where the estimated upper bound of settling-time is inherently different from existing results are presented. Then, based on the developed conditions, an event-triggered control scheme that can avoid Zeno behavior is designed to achieve synchronization of master–slave neural networks under DoS attack within a prescribed time. For comparison, the established control scheme is further discussed under the case without DoS attack, and the circumstance that there is no attack or event-triggered mechanism, respectively. Simulation results are finally provided to illustrate the significant and validity of our theoretical research. Especially, in terms of encryption and decryption keys generated from the synchronization behavior of chaotic networks, we specifically discuss the application of the proposed fixed-time synchronization scheme to image and audio encryption.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004045",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Encryption",
      "Engineering",
      "Lyapunov stability",
      "Settling time",
      "Step response",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Xing",
        "given_name": "Mengping"
      },
      {
        "surname": "Lu",
        "given_name": "Jianquan"
      },
      {
        "surname": "Lou",
        "given_name": "Jungang"
      },
      {
        "surname": "Zhang",
        "given_name": "Lingzhong"
      }
    ]
  },
  {
    "title": "Approximation of smooth functionals using deep ReLU networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.012",
    "abstract": "In recent years, deep neural networks have been employed to approximate nonlinear continuous functionals F defined on L p ( [ − 1 , 1 ] s ) for 1 ≤ p ≤ ∞ . However, the existing theoretical analysis in the literature either is unsatisfactory due to the poor approximation results, or does not apply to the rectified linear unit (ReLU) activation function. This paper aims to investigate the approximation power of functional deep ReLU networks in two settings: F is continuous with restrictions on the modulus of continuity, and F has higher order Fréchet derivatives. A novel functional network structure is proposed to extract features of higher order smoothness harbored by the target functional F . Quantitative rates of approximation in terms of the depth, width and total number of weights of neural networks are derived for both settings. We give logarithmic rates when measuring the approximation error on the unit ball of a Hölder space. In addition, we establish nearly polynomial rates (i.e., rates of the form exp − a ( log M ) b with a > 0 , 0 < b < 1 ) when measuring the approximation error on a space of analytic functions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003714",
    "keywords": [
      "Applied mathematics",
      "Approximation error",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Ecology",
      "Evolutionary biology",
      "Function (biology)",
      "Function approximation",
      "Linear approximation",
      "Logarithm",
      "Mathematical analysis",
      "Mathematics",
      "Minimax approximation algorithm",
      "Modulus of continuity",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Polynomial",
      "Quantum mechanics",
      "Smoothness",
      "Space (punctuation)",
      "Type (biology)",
      "Unit sphere"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Linhao"
      },
      {
        "surname": "Liu",
        "given_name": "Ying"
      },
      {
        "surname": "Fan",
        "given_name": "Jun"
      },
      {
        "surname": "Zhou",
        "given_name": "Ding-Xuan"
      }
    ]
  },
  {
    "title": "Long-range zero-shot generative deep network quantization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.042",
    "abstract": "Quantization approximates a deep network model with floating-point numbers by the model with low bit width numbers, thereby accelerating inference and reducing computation. Zero-shot quantization, which aims to quantize a model without access to the original data, can be achieved by fitting the real data distribution through data synthesis. However, it has been observed that zero-shot quantization leads to inferior performance compared to post-training quantization with real data for two primary reasons: 1) a normal generator has difficulty obtaining a high diversity of synthetic data since it lacks long-range information to allocate attention to global features, and 2) synthetic images aim to simulate the statistics of real data, which leads to weak intra-class heterogeneity and limited feature richness. To overcome these problems, we propose a novel deep network quantizer called long-range zero-shot generative deep network quantization (LRQ). Technically, we propose a long-range generator (LRG) to learn long-range information instead of simple local features. To incorporate more global features into the synthetic data, we use long-range attention with large-kernel convolution in the generator. In addition, we also present an adversarial margin add (AMA) module to force intra-class angular enlargement between the feature vector and class center. The AMA module forms an adversarial process that increases the convergence difficulty of the loss function, which is opposite to the training objective of the original loss function. Furthermore, to transfer knowledge from the full-precision network, we also utilize decoupled knowledge distillation. Extensive experiments demonstrate that LRQ obtains better performance than other competitors.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004008",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Inference",
      "Pattern recognition (psychology)",
      "Quantization (signal processing)"
    ],
    "authors": [
      {
        "surname": "Luo",
        "given_name": "Yan"
      },
      {
        "surname": "Gao",
        "given_name": "Yangcheng"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhao"
      },
      {
        "surname": "Fan",
        "given_name": "Jicong"
      },
      {
        "surname": "Zhang",
        "given_name": "Haijun"
      },
      {
        "surname": "Xu",
        "given_name": "Mingliang"
      }
    ]
  },
  {
    "title": "Trustworthy Medical Image Segmentation with improved performance for in-distribution samples",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.047",
    "abstract": "Despite the enormous achievements of Deep Learning (DL) based models, their non-transparent nature led to restricted applicability and distrusted predictions. Such predictions emerge from erroneous In-Distribution (ID) and Out-Of-Distribution (OOD) samples, which results in disastrous effects in the medical domain, specifically in Medical Image Segmentation (MIS). To mitigate such effects, several existing works accomplish OOD sample detection; however, the trustworthiness issues from ID samples still require thorough investigation. To this end, a novel method TrustMIS (Trustworthy Medical Image Segmentation) is proposed in this paper, which provides the trustworthiness and improved performance of ID samples for DL-based MIS models. TrustMIS works in three folds: IT (Investigating Trustworthiness), INT (Improving Non-Trustworthy prediction) and CSO (Classifier Switching Operation). Initially, the IT method investigates the trustworthiness of MIS by leveraging similar characteristics and consistency analysis of input and its variants. Subsequently, the INT method employs the IT method to improve the performance of the MIS model. It leverages the observation that an input providing erroneous segmentation can provide correct segmentation with rotated input. Eventually, the CSO method employs the INT method to scrutinise several MIS models and selects the model that delivers the most trustworthy prediction. The experiments conducted on publicly available datasets using well-known MIS models reveal that TrustMIS has successfully provided a trustworthiness measure, outperformed the existing methods, and improved the performance of state-of-the-art MIS models. Our implementation is available at https://github.com/SnehaShukla937/TrustMIS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003581",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Chromatography",
      "Classifier (UML)",
      "Computer science",
      "Computer security",
      "Consistency (knowledge bases)",
      "Data mining",
      "Image segmentation",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Sample (material)",
      "Segmentation",
      "Trustworthiness"
    ],
    "authors": [
      {
        "surname": "Shukla",
        "given_name": "Sneha"
      },
      {
        "surname": "Birla",
        "given_name": "Lokendra"
      },
      {
        "surname": "Gupta",
        "given_name": "Anup Kumar"
      },
      {
        "surname": "Gupta",
        "given_name": "Puneet"
      }
    ]
  },
  {
    "title": "CCGN: Centralized collaborative graphical transformer multi-agent reinforcement learning for multi-intersection signal free-corridor",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.027",
    "abstract": "Tackling traffic signal control through multi-agent reinforcement learning is a widely-employed approach. However, current state-of-the-art models have drawbacks: intersections optimize their own local rewards and cause traffic to waste time and fuel with a start-stop mode at each intersection. They also lack information sharing among intersections and their specialized policy hinders the ability to adapt to new traffic scenarios. To overcome these limitations, This work presents a centralized collaborative graph network (CCGN) with the core objective of a signal-free corridor once the traffic flows have waited at the entry intersection of the traffic intersection network on either side, the subsequent intersection gives the open signal as the traffic flows arrive. CCGN combines local policy networks (LPN) and global policy networks, where LPN employed at each intersection predicts actions based on Transformer and Graph Convolutional Network (GCN). In contrast, GPN is based on GCN and Q-network that receives the LPN states, traffic flow and road information to manage intersections to provide a signal-free corridor. We developed the Deep Graph Convolution Q-Network (DGCQ) by combining Deep Q-Network (DQN) and GCN to achieve a signal-free corridor. DGCQ leverages GCN’s intersection collaboration and DQN’s information aggregation for traffic control decisions Proposed CCGN model is trained on the robust synthetic traffic network and evaluated on the real-world traffic networks that outperform the other state-of-the-art models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003854",
    "keywords": [
      "Artificial intelligence",
      "Computer network",
      "Computer science",
      "Distributed computing",
      "Engineering",
      "Graph",
      "Intersection (aeronautics)",
      "Real-time computing",
      "Reinforcement learning",
      "Theoretical computer science",
      "Transport engineering"
    ],
    "authors": [
      {
        "surname": "Mukhtar",
        "given_name": "Hamza"
      },
      {
        "surname": "Afzal",
        "given_name": "Adil"
      },
      {
        "surname": "Alahmari",
        "given_name": "Sultan"
      },
      {
        "surname": "Yonbawi",
        "given_name": "Saud"
      }
    ]
  },
  {
    "title": "Node injection for class-specific network poisoning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.025",
    "abstract": "Graph Neural Networks (GNNs) are powerful in learning rich network representations that aid the performance of downstream tasks. However, recent studies showed that GNNs are vulnerable to adversarial attacks involving node injection and network perturbation. Among these, node injection attacks are more practical as they do not require manipulation in the existing network and can be performed more realistically. In this paper, we propose a novel problem statement — a class-specific poison attack on graphs in which the attacker aims to misclassify specific nodes in the target class into a different class using node injection. Additionally, nodes are injected in such a way that they camouflage as benign nodes. We propose NICKI, a novel attacking strategy that utilizes an optimization-based approach to sabotage the performance of GNN-based node classifiers. NICKI works in two phases — it first learns the node representation and then generates the features and edges of the injected nodes. Extensive experiments and ablation studies on four benchmark networks show that NICKI is consistently better than four baseline attacking strategies for misclassifying nodes in the target class. We also show that the injected nodes are properly camouflaged as benign, thus making the poisoned graph indistinguishable from its clean version w.r.t various topological properties.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003830",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Camouflage",
      "Class (philosophy)",
      "Computer network",
      "Computer science",
      "Engineering",
      "Graph",
      "Node (physics)",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Sharma",
        "given_name": "Ansh Kumar"
      },
      {
        "surname": "Kukreja",
        "given_name": "Rahul"
      },
      {
        "surname": "Kharbanda",
        "given_name": "Mayank"
      },
      {
        "surname": "Chakraborty",
        "given_name": "Tanmoy"
      }
    ]
  },
  {
    "title": "Safe screening rules for multi-view support vector machines",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.021",
    "abstract": "Multi-view learning aims to make use of the advantages of different views to complement each other and fully mines the potential information in the data. However, the complexity of multi-view learning algorithm is much higher than that of single view learning algorithm. Based on the optimality conditions of two classical multi-view models: SVM-2K and multi-view twin support vector machine (MvTwSVM), this paper analyzes the corresponding relationship between dual variables and samples, and derives their safe screening rules for the first time, termed as SSR-SVM-2K and SSR-MvTwSVM. It can assign or delete four groups of different dual variables in advance before solving the optimization problem, so as to greatly reduce the scale of the optimization problem and improve the solution speed. More importantly, the safe screening criterion is “safe”, that is, the solution of the reduced optimization problem is the same as that of the original problem before screening. In addition, we further give a sequence screening rule to speed up the parameter optimization process, and analyze its properties, including the similarities and differences of safe screening rules between multi-view SVMs and single-view SVMs, the computational complexity, and the relationship between the parameter interval and screening rate. Numerical experiments verify the effectiveness of the proposed methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003787",
    "keywords": [
      "Algorithm",
      "Art",
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Combinatorics",
      "Complement (music)",
      "Complementation",
      "Computer science",
      "Dual (grammatical number)",
      "Gene",
      "Genetics",
      "Interval (graph theory)",
      "Literature",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Operating system",
      "Optimization problem",
      "Phenotype",
      "Process (computing)",
      "Sequence (biology)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Huiru"
      },
      {
        "surname": "Zhu",
        "given_name": "Jiayi"
      },
      {
        "surname": "Zhang",
        "given_name": "Siyuan"
      }
    ]
  },
  {
    "title": "Context and detail interaction network for stereo rain streak and raindrop removal",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.013",
    "abstract": "Recently stereo image deraining has attracted lots of attention due to its superiority of abundant information from cross views. Exploring interaction information across stereo views is the key to improving the performance of stereo image deraining. In this paper, we design a general coarse-to-fine deraining framework for stereo rain streak and raindrop removal, called CDINet, comprising a stereo rain removal subnet and a stereo detail recovery subnet to restore images progressively. Two types of interaction modules are devised to explore interaction information for rain removal and detail recovery, respectively. Specifically, a global context interaction module is proposed to learn long-range dependencies of stereo images and remove rain by utilizing stereo structural information. A local detail interaction module is designed to model local contextual correlation, which aims at restoring the detail information by using neighborhood information from cross views. Extensive experiments are conducted on the two datasets including a synthetic rain streak removal dataset (RainKITTI) and a real raindrop removal dataset (Stereo Waterdrop), which demonstrates that our method sets new state-of-the-art deraining performance in terms of both quantitative and qualitative metrics with faster speed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003702",
    "keywords": [
      "Artificial intelligence",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Context (archaeology)",
      "Geology",
      "Mineralogy",
      "Paleontology",
      "Streak",
      "Subnet"
    ],
    "authors": [
      {
        "surname": "Nie",
        "given_name": "Jing"
      },
      {
        "surname": "Xie",
        "given_name": "Jin"
      },
      {
        "surname": "Cao",
        "given_name": "Jiale"
      },
      {
        "surname": "Pang",
        "given_name": "Yanwei"
      }
    ]
  },
  {
    "title": "The deep arbitrary polynomial chaos neural network or how Deep Artificial Neural Networks could benefit from data-driven homogeneous chaos theory",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.036",
    "abstract": "Artificial Intelligence and Machine learning have been widely used in various fields of mathematical computing, physical modeling, computational science, communication science, and stochastic analysis. Approaches based on Deep Artificial Neural Networks (DANN) are very popular in our days. Depending on the learning task, the exact form of DANNs is determined via their multi-layer architecture, activation functions and the so-called loss function. However, for a majority of deep learning approaches based on DANNs, the kernel structure of neural signal processing remains the same, where the node response is encoded as a linear superposition of neural activity, while the non-linearity is triggered by the activation functions. In the current paper, we suggest to analyze the neural signal processing in DANNs from the point of view of homogeneous chaos theory as known from polynomial chaos expansion (PCE). From the PCE perspective, the (linear) response on each node of a DANN could be seen as a 1st degree multi-variate polynomial of single neurons from the previous layer, i.e. linear weighted sum of monomials. From this point of view, the conventional DANN structure relies implicitly (but erroneously) on a Gaussian distribution of neural signals. Additionally, this view revels that by design DANNs do not necessarily fulfill any orthogonality or orthonormality condition for a majority of data-driven applications. Therefore, the prevailing handling of neural signals in DANNs could lead to redundant representation as any neural signal could contain some partial information from other neural signals. To tackle that challenge, we suggest to employ the data-driven generalization of PCE theory known as arbitrary polynomial chaos (aPC) to construct a corresponding multi-variate orthonormal representations on each node of a DANN. Doing so, we generalize the conventional structure of DANNs to Deep arbitrary polynomial chaos neural networks (DaPC NN). They decompose the neural signals that travel through the multi-layer structure by an adaptive construction of data-driven multi-variate orthonormal bases for each layer. Moreover, the introduced DaPC NN provides an opportunity to go beyond the linear weighted superposition of single neurons on each node. Inheriting fundamentals of PCE theory, the DaPC NN offers an additional possibility to account for high-order neural effects reflecting simultaneous interaction in multi-layer networks. Introducing the high-order weighted superposition on each node of the network mitigates the necessity to introduce non-linearity via activation functions and, hence, reduces the room for potential subjectivity in the modeling procedure. Although the current DaPC NN framework has no theoretical restrictions on the use of activation functions. The current paper also summarizes relevant properties of DaPC NNs inherited from aPC as analytical expressions for statistical quantities and sensitivity indexes on each node. We also offer an analytical form of partial derivatives that could be used in various training algorithms. Technically, DaPC NNs require similar training procedures as conventional DANNs, and all trained weights determine automatically the corresponding multi-variate data-driven orthonormal bases for all layers of DaPC NN. The paper makes use of three test cases to illustrate the performance of DaPC NN, comparing it with the performance of the conventional DANN and also with plain aPC expansion. Evidence of convergence over the training data size against validation data sets demonstrates that the DaPC NN outperforms the conventional DANN systematically. Overall, the suggested re-formulation of the kernel network structure in terms of homogeneous chaos theory is not limited to any particular architecture or any particular definition of the loss function. The DaPC NN Matlab Toolbox is available online and users are invited to adopt it for own needs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003477",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "CHAOS (operating system)",
      "Chaos theory",
      "Chaotic",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Deep neural networks",
      "Homogeneous",
      "Mathematics",
      "Monte Carlo method",
      "Physics",
      "Polynomial chaos",
      "Statistical physics",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Oladyshkin",
        "given_name": "Sergey"
      },
      {
        "surname": "Praditia",
        "given_name": "Timothy"
      },
      {
        "surname": "Kroeker",
        "given_name": "Ilja"
      },
      {
        "surname": "Mohammadi",
        "given_name": "Farid"
      },
      {
        "surname": "Nowak",
        "given_name": "Wolfgang"
      },
      {
        "surname": "Otte",
        "given_name": "Sebastian"
      }
    ]
  },
  {
    "title": "A look into feedback neural computation upon collision selectivity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.039",
    "abstract": "Physiological studies have shown that a group of locust’s lobula giant movement detectors (LGMDs) has a diversity of collision selectivity to approaching objects, relatively darker or brighter than their backgrounds in cluttered environments. Such diversity of collision selectivity can serve locusts to escape from attack by natural enemies, and migrate in swarm free of collision. For computational studies, endeavours have been made to realize the diverse selectivity which, however, is still one of the most challenging tasks especially in complex and dynamic real world scenarios. The existing models are mainly formulated as multi-layered neural networks with merely feed-forward information processing, and do not take into account the effect of re-entrant signals in feedback loop, which is an essential regulatory loop for motion perception, yet never been explored in looming perception. In this paper, we inaugurate feedback neural computation for constructing a new LGMD-based model, named F-LGMD to look into the efficacy upon implementing different collision selectivity. Accordingly, the proposed neural network model features both feed-forward processing and feedback loop. The feedback control propagates output signals of parallel ON/OFF channels back into their starting neurons, thus makes part of the feed-forward neural network, i.e. the ON/OFF channels and the feedback loop form an iterative cycle system. Moreover, the feedback control is instantaneous, which leads to the existence of a fixed point whereby the fixed point theorem is applied to rigorously derive valid range of feedback coefficients. To verify the effectiveness of the proposed method, we conduct systematic experiments covering synthetic and natural collision datasets, and also online robotic tests. The experimental results show that the F-LGMD, with a unified network, can fulfil the diverse collision selectivity revealed in physiology, which not only reduces considerably the handcrafted parameters compared to previous studies, but also offers a both efficient and robust scheme for collision perception through feedback neural computation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003519",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Collision",
      "Computation",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Control theory (sociology)",
      "Electrical engineering",
      "Engineering",
      "Feedback loop",
      "Models of neural computation",
      "Negative feedback",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Chang",
        "given_name": "Zefang"
      },
      {
        "surname": "Fu",
        "given_name": "Qinbing"
      },
      {
        "surname": "Chen",
        "given_name": "Hao"
      },
      {
        "surname": "Li",
        "given_name": "Haiyang"
      },
      {
        "surname": "Peng",
        "given_name": "Jigen"
      }
    ]
  },
  {
    "title": "Sinogram upsampling using Primal–Dual UNet for undersampled CT and radial MRI reconstruction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.004",
    "abstract": "Computed tomography (CT) and magnetic resonance imaging (MRI) are two widely used clinical imaging modalities for non-invasive diagnosis. However, both of these modalities come with certain problems. CT uses harmful ionising radiation, and MRI suffers from slow acquisition speed. Both problems can be tackled by undersampling, such as sparse sampling. However, such undersampled data leads to lower resolution and introduces artefacts. Several techniques, including deep learning based methods, have been proposed to reconstruct such data. However, the undersampled reconstruction problem for these two modalities was always considered as two different problems and tackled separately by different research works. This paper proposes a unified solution for both sparse CT and undersampled radial MRI reconstruction, achieved by applying Fourier transform-based pre-processing on the radial MRI and then finally reconstructing both modalities using sinogram upsampling combined with filtered back-projection. The Primal–Dual network is a deep learning based method for reconstructing sparsely-sampled CT data. This paper introduces Primal–Dual UNet, which improves the Primal–Dual network in terms of accuracy and reconstruction speed. The proposed method resulted in an average SSIM of 0.932±0.021 while performing sparse CT reconstruction for fan-beam geometry with a sparsity level of 16, achieving a statistically significant improvement over the previous model, which resulted in 0.919±0.016. Furthermore, the proposed model resulted in 0.903±0.019 and 0.957±0.023 average SSIM while reconstructing undersampled brain and abdominal MRI data with an acceleration factor of 16, respectively - statistically significant improvements over the original model, which resulted in 0.867±0.025 and 0.949±0.025. Finally, this paper shows that the proposed network not only improves the overall image quality, but also improves the image quality for the regions-of-interest: liver, kidneys, and spleen; as well as generalises better than the baselines in presence the of a needle.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004239",
    "keywords": [
      "Algorithm",
      "Aliasing",
      "Artificial intelligence",
      "Compressed sensing",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Image (mathematics)",
      "Iterative reconstruction",
      "Magnetic resonance imaging",
      "Medicine",
      "Projection (relational algebra)",
      "Radiology",
      "Real-time MRI",
      "Reconstruction algorithm",
      "Undersampling",
      "Upsampling"
    ],
    "authors": [
      {
        "surname": "Ernst",
        "given_name": "Philipp"
      },
      {
        "surname": "Chatterjee",
        "given_name": "Soumick"
      },
      {
        "surname": "Rose",
        "given_name": "Georg"
      },
      {
        "surname": "Speck",
        "given_name": "Oliver"
      },
      {
        "surname": "Nürnberger",
        "given_name": "Andreas"
      }
    ]
  },
  {
    "title": "Fixed-time periodic stabilization of discontinuous reaction–diffusion Cohen–Grossberg neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.017",
    "abstract": "This paper aims to study the fixed-time stabilization of a class of delayed discontinuous reaction–diffusion Cohen–Grossberg neural networks. Firstly, by providing some relaxed conditions containing indefinite functions and based on inequality techniques, a new fixed-time stability lemma is given, which can improve the traditional ones. Secondly, based on state-dependent switching laws, the periodic wave solution of the formulated networks is transformed into the periodic solution of ordinary differential system. By utilizing differential inclusions theory and coincidence theorem, the existence of periodic solutions is obtained. Thirdly, based on the new fixed-time stability lemma, the periodic solutions are stabilized at zero in a fixed-time, which is a new topic on reaction–diffusion networks. Moreover, the established criteria are all delay-dependent, which are less conservative than the previous delay-independent ones for ensuring the stabilization of delayed reaction–diffusion networks. Finally, two examples give numerical explanations of the proposed results and highlight the influence of delays.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003751",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Diffusion",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Reaction–diffusion system",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Kong",
        "given_name": "Fanchao"
      },
      {
        "surname": "Zhu",
        "given_name": "Quanxin"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      }
    ]
  },
  {
    "title": "A bio-inspired positional embedding network for transformer-based models",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.015",
    "abstract": "Owing to the progress of transformer-based networks, there have been significant improvements in the performance of vision models in recent years. However, there is further potential for improvement in positional embeddings that play a crucial role in distinguishing information across different positions. Based on the biological mechanisms of human visual pathways, we propose a positional embedding network that adaptively captures position information by modeling the dorsal pathway, which is responsible for spatial perception in human vision. Our proposed double-stream architecture leverages large zero-padding convolutions to learn local positional features and utilizes transformers to learn global features, effectively capturing the interaction between dorsal and ventral pathways. To evaluate the effectiveness of our method, we implemented experiments on various datasets, employing differentiated designs. Our statistical analysis demonstrates that the simple implementation significantly enhances image classification performance, and the observed trends demonstrate its biological plausibility.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003738",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Embedding",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Xue-song"
      },
      {
        "surname": "Hao",
        "given_name": "Kuangrong"
      },
      {
        "surname": "Wei",
        "given_name": "Hui"
      }
    ]
  },
  {
    "title": "Low-rank discrete multi-view spectral clustering",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.038",
    "abstract": "Spectral clustering has attracted intensive attention in multimedia applications due to its good performance on arbitrary shaped clusters and well-defined mathematical framework. However, most existing multi-view spectral clustering methods still have the following demerits: (1) They ignore useful complementary information embedded in indicator matrices of different views. (2) The conventional post-processing methods based on the relax and discrete strategy inevitably result in the sub-optimal discrete solution. To tackle the aforementioned drawbacks, we propose a low-rank discrete multi-view spectral clustering model. Drawing inspiration from the fact that the difference between indicator matrices of different views provides useful complementary information for clustering, our model exploits the complementary information embedded in indicator matrices with tensor Schatten p-norm constraint. Further, we integrate low-rank tensor learning and discrete label recovering into a uniform framework, which avoids the uncertainty of the relaxed and discrete strategy. Extensive experiments on benchmark datasets have demonstrated the effectiveness and superiority of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003490",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Cluster analysis",
      "Combinatorics",
      "Computer science",
      "Constraint (computer-aided design)",
      "Data mining",
      "Eigenvalues and eigenvectors",
      "Geodesy",
      "Geography",
      "Geometry",
      "Mathematics",
      "Matrix norm",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Rank (graph theory)",
      "Spectral clustering",
      "Tensor (intrinsic definition)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Yun",
        "given_name": "Yu"
      },
      {
        "surname": "Li",
        "given_name": "Jing"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Approximation of smooth functionals using deep ReLU networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.012",
    "abstract": "In recent years, deep neural networks have been employed to approximate nonlinear continuous functionals F defined on L p ( [ − 1 , 1 ] s ) for 1 ≤ p ≤ ∞ . However, the existing theoretical analysis in the literature either is unsatisfactory due to the poor approximation results, or does not apply to the rectified linear unit (ReLU) activation function. This paper aims to investigate the approximation power of functional deep ReLU networks in two settings: F is continuous with restrictions on the modulus of continuity, and F has higher order Fréchet derivatives. A novel functional network structure is proposed to extract features of higher order smoothness harbored by the target functional F . Quantitative rates of approximation in terms of the depth, width and total number of weights of neural networks are derived for both settings. We give logarithmic rates when measuring the approximation error on the unit ball of a Hölder space. In addition, we establish nearly polynomial rates (i.e., rates of the form exp − a ( log M ) b with a > 0 , 0 < b < 1 ) when measuring the approximation error on a space of analytic functions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003714",
    "keywords": [
      "Applied mathematics",
      "Approximation error",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Ecology",
      "Evolutionary biology",
      "Function (biology)",
      "Function approximation",
      "Linear approximation",
      "Logarithm",
      "Mathematical analysis",
      "Mathematics",
      "Minimax approximation algorithm",
      "Modulus of continuity",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Polynomial",
      "Quantum mechanics",
      "Smoothness",
      "Space (punctuation)",
      "Type (biology)",
      "Unit sphere"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Linhao"
      },
      {
        "surname": "Liu",
        "given_name": "Ying"
      },
      {
        "surname": "Fan",
        "given_name": "Jun"
      },
      {
        "surname": "Zhou",
        "given_name": "Ding-Xuan"
      }
    ]
  },
  {
    "title": "Long-range zero-shot generative deep network quantization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.042",
    "abstract": "Quantization approximates a deep network model with floating-point numbers by the model with low bit width numbers, thereby accelerating inference and reducing computation. Zero-shot quantization, which aims to quantize a model without access to the original data, can be achieved by fitting the real data distribution through data synthesis. However, it has been observed that zero-shot quantization leads to inferior performance compared to post-training quantization with real data for two primary reasons: 1) a normal generator has difficulty obtaining a high diversity of synthetic data since it lacks long-range information to allocate attention to global features, and 2) synthetic images aim to simulate the statistics of real data, which leads to weak intra-class heterogeneity and limited feature richness. To overcome these problems, we propose a novel deep network quantizer called long-range zero-shot generative deep network quantization (LRQ). Technically, we propose a long-range generator (LRG) to learn long-range information instead of simple local features. To incorporate more global features into the synthetic data, we use long-range attention with large-kernel convolution in the generator. In addition, we also present an adversarial margin add (AMA) module to force intra-class angular enlargement between the feature vector and class center. The AMA module forms an adversarial process that increases the convergence difficulty of the loss function, which is opposite to the training objective of the original loss function. Furthermore, to transfer knowledge from the full-precision network, we also utilize decoupled knowledge distillation. Extensive experiments demonstrate that LRQ obtains better performance than other competitors.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004008",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Inference",
      "Pattern recognition (psychology)",
      "Quantization (signal processing)"
    ],
    "authors": [
      {
        "surname": "Luo",
        "given_name": "Yan"
      },
      {
        "surname": "Gao",
        "given_name": "Yangcheng"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhao"
      },
      {
        "surname": "Fan",
        "given_name": "Jicong"
      },
      {
        "surname": "Zhang",
        "given_name": "Haijun"
      },
      {
        "surname": "Xu",
        "given_name": "Mingliang"
      }
    ]
  },
  {
    "title": "MSSPA-GC: Multi-Scale Shape Prior Adaptation with 3D Graph Convolutions for Category-Level Object Pose Estimation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.037",
    "abstract": "Category-level object pose estimation aims to predict the 6D object pose and size of arbitrary objects from known categories. It remains a challenge due to the large intra-class shape variation. Recently, the introduction of the shape prior adaptation mechanism into the normalized canonical coordinates (i.e., NOCS) reconstruction process has been shown to be effective in mitigating the intra-class shape variation. However, existing shape prior adaptation methods simply map the observed point cloud to the normalized object space, and the extracted object descriptors are not sufficient for the perception of the object pose. As a result, they fail to predict the pose of objects with complex geometric structures (e.g., cameras). To this end, this paper proposes a novel shape prior adaption method named MSSPA-GC for category-level object pose estimation. Specifically, our main network takes the observed instance point cloud converted from the RGB-D image and the prior shape point cloud pre-trained on the object CAD models as inputs. Then, a novel 3D graph convolution network and a PointNet-like MLP network are designed to extract pose-aware object features and shape-aware object features from these two inputs, respectively. After that, the two-stream object features are aggregated through a multi-scale feature propagation mechanism to generate comprehensive 3D object descriptors that maintain both pose-sensitive geometric stability and intra-class shape consistency. Finally, by leveraging object descriptors aware of both object pose and shape when reconstructing the NOCS coordinates, our approach elegantly achieves state-of-the-art performance on the widely used REAL275 and CAMERA25 datasets using only 25% of the parameters compared with existing shape prior adaptation models. Moreover, our method also exhibits decent generalization ability on the unconstrained REDWOOD75 dataset.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003957",
    "keywords": [
      "3D pose estimation",
      "Active shape model",
      "Articulated body pose estimation",
      "Artificial intelligence",
      "Cognitive neuroscience of visual object recognition",
      "Computer science",
      "Computer vision",
      "Graph",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Point cloud",
      "Pose",
      "Segmentation",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zou",
        "given_name": "Lu"
      },
      {
        "surname": "Huang",
        "given_name": "Zhangjin"
      },
      {
        "surname": "Gu",
        "given_name": "Naijie"
      },
      {
        "surname": "Wang",
        "given_name": "Guoping"
      }
    ]
  },
  {
    "title": "Content preserving image translation with texture co-occurrence and spatial self-similarity for texture debiasing and domain adaptation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.049",
    "abstract": "Models trained on datasets with texture bias usually perform poorly on out-of-distribution samples since biased representations are embedded into the model. Recently, various image translation and debiasing methods have attempted to disentangle texture biased representations for downstream tasks, but accurately discarding biased features without altering other relevant information is still challenging. In this paper, we propose a novel framework that leverages image translation to generate additional training images using the content of a source image and the texture of a target image with a different bias property to explicitly mitigate texture bias when training a model on a target task. Our model ensures texture similarity between the target and generated images via a texture co-occurrence loss while preserving content details from source images with a spatial self-similarity loss. Both the generated and original training images are combined to train improved classification or segmentation models robust to inconsistent texture bias. Evaluation on five classification- and two segmentation-datasets with known texture biases demonstrates the utility of our method, and reports significant improvements over recent state-of-the-art methods in all cases.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004070",
    "keywords": [
      "Artificial intelligence",
      "Bidirectional texture function",
      "Biochemistry",
      "Chemistry",
      "Cognitive science",
      "Computer science",
      "Computer vision",
      "Debiasing",
      "Gene",
      "Image (mathematics)",
      "Image segmentation",
      "Image texture",
      "Messenger RNA",
      "Pattern recognition (psychology)",
      "Psychology",
      "Segmentation",
      "Similarity (geometry)",
      "Texture (cosmology)",
      "Texture compression",
      "Texture filtering",
      "Translation (biology)"
    ],
    "authors": [
      {
        "surname": "Kang",
        "given_name": "Myeongkyun"
      },
      {
        "surname": "Won",
        "given_name": "Dongkyu"
      },
      {
        "surname": "Luna",
        "given_name": "Miguel"
      },
      {
        "surname": "Chikontwe",
        "given_name": "Philip"
      },
      {
        "surname": "Hong",
        "given_name": "Kyung Soo"
      },
      {
        "surname": "Ahn",
        "given_name": "June Hong"
      },
      {
        "surname": "Park",
        "given_name": "Sang Hyun"
      }
    ]
  },
  {
    "title": "Online dynamic ensemble deep random vector functional link neural network for forecasting",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.042",
    "abstract": "This paper proposes a three-stage online deep learning model for time series based on the ensemble deep random vector functional link (edRVFL). The edRVFL stacks multiple randomized layers to enhance the single-layer RVFL’s representation ability. Each hidden layer’s representation is utilized for training an output layer, and the ensemble of all output layers forms the edRVFL’s output. However, the original edRVFL is not designed for online learning, and the randomized nature of the features is harmful to extracting meaningful temporal features. In order to address the limitations and extend the edRVFL to an online learning mode, this paper proposes a dynamic edRVFL consisting of three online components, the online decomposition, the online training, and the online dynamic ensemble. First, an online decomposition is utilized as a feature engineering block for the edRVFL. Then, an online learning algorithm is designed to learn the edRVFL. Finally, an online dynamic ensemble method, which can measure the change in the distribution, is proposed for aggregating all layers’ outputs. This paper evaluates and compares the proposed model with state-of-the-art methods on sixteen time series.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003532",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer network",
      "Computer science",
      "Link (geometry)",
      "Machine learning",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Ruobin"
      },
      {
        "surname": "Li",
        "given_name": "Ruilin"
      },
      {
        "surname": "Hu",
        "given_name": "Minghui"
      },
      {
        "surname": "Suganthan",
        "given_name": "P.N."
      },
      {
        "surname": "Yuen",
        "given_name": "Kum Fai"
      }
    ]
  },
  {
    "title": "Value iteration for streaming data on a continuous space with gradient method in an RKHS",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.036",
    "abstract": "The classical theory of reinforcement learning focused on the tabular setting when states and actions are finite, or for linear representation of the value function in a finite-dimensional approximation. Establishing theory on general continuous state and action space requires a careful treatment of complexity theory of appropriately chosen function spaces and the iterative update of the value function when stochastic gradient descent (SGD) is used. For the classical prediction problem in reinforcement learning based on i.i.d. streaming data in the framework of reproducing kernel Hilbert spaces, we establish polynomial sample complexity taking into account the smoothness of the value function. In particular, we prove that the gradient descent algorithm efficiently computes the value function with appropriately chosen step sizes, with a convergence rate that can be close to 1 / N , which is the best possible rate for parametric SGD. The advantages of using the gradient descent algorithm include its computational convenience and it can naturally deal with streaming data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003945",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Discrete mathematics",
      "Evolutionary biology",
      "Function (biology)",
      "Function space",
      "Gradient descent",
      "Hilbert space",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Parametric statistics",
      "Rate of convergence",
      "Reinforcement learning",
      "Reproducing kernel Hilbert space",
      "Smoothness",
      "Statistics",
      "Stochastic gradient descent"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Jiamin"
      },
      {
        "surname": "Xu",
        "given_name": "Wangli"
      },
      {
        "surname": "Wang",
        "given_name": "Yue"
      },
      {
        "surname": "Lian",
        "given_name": "Heng"
      }
    ]
  },
  {
    "title": "Adaptive prescribed settling time periodic event-triggered control for uncertain robotic manipulators with state constraints",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.032",
    "abstract": "In this paper, an adaptive prescribed settling time periodic event-triggered control (APST-PETC) is investigated for uncertain robotic manipulators with state constraints. In order to economize network bandwidth occupancy and reduce computational burden, a periodic event-triggered control (PETC) strategy is proposed to reduce the update frequency of the control signal and avoid unnecessary continuous monitoring. Besides, considering that the maneuverable space of the actual robotic manipulators is often limited, the barrier Lyapunov function (BLF) is applied to deal with the influence of the constraint characteristics on the robotic manipulators. Further, based on the one-to-one nonlinear mapping function of the system tracking error, an adaptive prescribed settling time control (APSTC) is designed to ensure that the system tracking error reaches the predetermined precision residual set within the prescribed settling time. Finally, theoretical analysis and comparative experiments are given to verify its feasibility.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003441",
    "keywords": [
      "Adaptive control",
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Constraint (computer-aided design)",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Geometry",
      "Lyapunov function",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Residual",
      "Settling time",
      "Step response",
      "Tracking error"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Zicong"
      },
      {
        "surname": "Zhang",
        "given_name": "Hui"
      },
      {
        "surname": "Liu",
        "given_name": "Jianqi"
      },
      {
        "surname": "Wang",
        "given_name": "Qinruo"
      },
      {
        "surname": "Wang",
        "given_name": "Jianhui"
      }
    ]
  },
  {
    "title": "Discrete-time robust event-triggered actuator fault-tolerant control based on adaptive networks and reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.08.003",
    "abstract": "This paper focuses on the topic of fault-tolerant control for discrete-time systems with nonlinear uncertainties and actuator faults. It considers both passive and active faults as part of the analysis and design. The proposed adaptive controller, based on a nonlinear electronic circuit, handles offset-biasing, sensitivity variation, and dead-zone effects. An event-triggered mechanism, utilizing a sliding surface, enhances robustness and reduces data transmission. Adaptive networks called MiFRENs are employed, trained using reinforcement learning. Theoretical analysis guarantees boundedness of internal signals and tracking error. Experimental results validate the scheme, demonstrating required conditions, reduced data transmission, and robust performance. Comparative evaluations confirm its superiority",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004227",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Distributed computing",
      "Fault detection and isolation",
      "Fault tolerance",
      "Gene",
      "Nonlinear system",
      "Offset (computer science)",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Reinforcement learning",
      "Robustness (evolution)",
      "Tracking error"
    ],
    "authors": [
      {
        "surname": "Treesatayapun",
        "given_name": "C."
      }
    ]
  },
  {
    "title": "A biologically inspired auto-associative network with sparse temporal population coding",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.040",
    "abstract": "Associative system has attracted increasing attention for it can store basic information and then infer details to match perception with an efficient self-organization algorithm. However, the implementation of the associative system with the application of real-world data is relatively difficult. To address this issue, we propose a novel biologically inspired auto-associative (BIAA) network to explore the structure, encoding and formation of associative memory as well as to extend the ability to real-world application. Our network is constructed by imitating the organization of the cortical minicolumns where each minicolumn contains plenty of parallel biological spiking neurons. To allow the network to learn and predict one symbol per theta cycle, we incorporate synaptic delay and theta oscillation into the neuron dynamic process. Subsequently, we design a sparse temporal population (STP) coding scheme that allows each input symbol to be represented as stable, unique, and easily recallable sparsely distributed representations. By combining associative learning dynamics with the STP coding, our network realizes efficient storage and inference in an ordered manner. Experimental results indicate that the proposed network successfully performs sequence retrieval from partial text and sequence recovery from distorted information. BIAA network provides new insight into introducing biologically inspired mechanisms into associative system and has enormous potential for hardware and software applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003970",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Associative property",
      "Biological network",
      "Coding (social sciences)",
      "Combinatorics",
      "Computer science",
      "Content-addressable memory",
      "Demography",
      "Inference",
      "Mathematics",
      "Neural coding",
      "Population",
      "Pure mathematics",
      "Sociology",
      "Statistics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Ya"
      },
      {
        "surname": "Shi",
        "given_name": "Kexin"
      },
      {
        "surname": "Luo",
        "given_name": "Xiaoling"
      },
      {
        "surname": "Chen",
        "given_name": "Yi"
      },
      {
        "surname": "Wang",
        "given_name": "Yucheng"
      },
      {
        "surname": "Qu",
        "given_name": "Hong"
      }
    ]
  },
  {
    "title": "Sparser spiking activity can be better: Feature Refine-and-Mask spiking neural network for event-based visual recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.008",
    "abstract": "Event-based visual, a new visual paradigm with bio-inspired dynamic perception and μ s level temporal resolution, has prominent advantages in many specific visual scenarios and gained much research interest. Spiking neural network (SNN) is naturally suitable for dealing with event streams due to its temporal information processing capability and event-driven nature. However, existing works SNN neglect the fact that the input event streams are spatially sparse and temporally non-uniform, and just treat these variant inputs equally. This situation interferes with the effectiveness and efficiency of existing SNNs. In this paper, we propose the feature Refine-and-Mask SNN (RM-SNN), which has the ability of self-adaption to regulate the spiking response in a data-dependent way. We use the Refine-and-Mask (RM) module to refine all features and mask the unimportant features to optimize the membrane potential of spiking neurons, which in turn drops the spiking activity. Inspired by the fact that not all events in spatio-temporal streams are task-relevant, we execute the RM module in both temporal and channel dimensions. Extensive experiments on seven event-based benchmarks, DVS128 Gesture, DVS128 Gait, CIFAR10-DVS, N-Caltech101, DailyAction-DVS, UCF101-DVS, and HMDB51-DVS demonstrate that under the multi-scale constraints of input time window, RM-SNN can significantly reduce the network average spiking activity rate while improving the task performance. In addition, by visualizing spiking responses, we analyze why sparser spiking activity can be better. Code",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003660",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Economics",
      "Event (particle physics)",
      "Feature (linguistics)",
      "Linguistics",
      "Management",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Spiking neural network",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Yao",
        "given_name": "Man"
      },
      {
        "surname": "Zhang",
        "given_name": "Hengyu"
      },
      {
        "surname": "Zhao",
        "given_name": "Guangshe"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiyu"
      },
      {
        "surname": "Wang",
        "given_name": "Dingheng"
      },
      {
        "surname": "Cao",
        "given_name": "Gang"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      }
    ]
  },
  {
    "title": "Multi-view graph representation with similarity diffusion for general zero-shot learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.045",
    "abstract": "Zero-shot learning (ZSL) aims to predict unseen classes without using samples of these classes in model training. The ZSL has been widely used in many knowledge-based models and applications to predict various parameters, including categories, subjects, and anomalies, in different domains. Nonetheless, most existing ZSL methods require the pre-defined semantics or attributes of particular data environments. Therefore, these methods are difficult to be applied to general data environments, such as ImageNet and other real-world datasets and applications. Recent research has tried to use open knowledge to enhance the ZSL methods to adapt it to an open data environment. However, the performance of these methods is relatively low, namely the accuracy is normally below 10%, which is due to the inadequate semantics that can be used from open knowledge. Moreover, the latest methods suffer from a significant ”semantic gap” problem between the generated features of unseen classes and the real features of seen classes. To this end, this paper proposes a multi-view graph representation with a similarity diffusion model, applying the ZSL tasks to general data environments. This model applies a multi-view graph to enhance the semantics fully and proposes an innovative diffusion method to augment the graph representation. In addition, a feature diffusion method is proposed to augment the multi-view graph representation and bridge the semantic gap to realize zero-shot predicting. The results of numerous experiments in general data environments and on benchmark datasets show that the proposed method can achieve new state-of-the-art results in the field of general zero-shot learning. Furthermore, seven ablation studies analyze the effects of the settings and different modules of the proposed method on its performance in detail and prove the effectiveness of each module.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300357X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Graph",
      "Image (mathematics)",
      "Law",
      "Linguistics",
      "Mathematics",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Shot (pellet)",
      "Similarity (geometry)",
      "Theoretical computer science",
      "Zero (linguistics)"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Beibei"
      },
      {
        "surname": "Xie",
        "given_name": "Cheng"
      },
      {
        "surname": "Tang",
        "given_name": "Peng"
      },
      {
        "surname": "Duan",
        "given_name": "Haoran"
      }
    ]
  },
  {
    "title": "Quantum recurrent neural networks for sequential learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.003",
    "abstract": "Quantum neural network (QNN) is one of the promising directions where the near-term noisy intermediate-scale quantum (NISQ) devices could find advantageous applications against classical resources. Recurrent neural networks are the most fundamental networks for sequential learning, but up to now there is still a lack of canonical model of quantum recurrent neural network (QRNN), which certainly restricts the research in the field of quantum deep learning. In the present work, we propose a new kind of QRNN which would be a good candidate as the canonical QRNN model, where, the quantum recurrent blocks (QRBs) are constructed in the hardware-efficient way, and the QRNN is built by stacking the QRBs in a staggered way that can greatly reduce the algorithm’s requirement with regard to the coherent time of quantum devices. That is, our QRNN is much more accessible on NISQ devices. Furthermore, the performance of the present QRNN model is verified concretely using three different kinds of classical sequential data, i.e., meteorological indicators, stock price, and text categorization. The numerical experiments show that our QRNN achieves much better performance in prediction (classification) accuracy against the classical RNN and state-of-the-art QNN models for sequential learning, and can predict the changing details of temporal sequence data. The practical circuit structure and superior performance indicate that the present QRNN is a promising learning model to find quantum advantageous applications in the near term.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300360X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Machine learning",
      "Physics",
      "Quantum",
      "Quantum circuit",
      "Quantum computer",
      "Quantum machine learning",
      "Quantum mechanics",
      "Quantum network",
      "Recurrent neural network"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Yanan"
      },
      {
        "surname": "Wang",
        "given_name": "Zhimin"
      },
      {
        "surname": "Han",
        "given_name": "Rongbing"
      },
      {
        "surname": "Shi",
        "given_name": "Shangshang"
      },
      {
        "surname": "Li",
        "given_name": "Jiaxin"
      },
      {
        "surname": "Shang",
        "given_name": "Ruimin"
      },
      {
        "surname": "Zheng",
        "given_name": "Haiyong"
      },
      {
        "surname": "Zhong",
        "given_name": "Guoqiang"
      },
      {
        "surname": "Gu",
        "given_name": "Yongjian"
      }
    ]
  },
  {
    "title": "Adaptive pinning cluster synchronization of a stochastic reaction–diffusion complex network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.034",
    "abstract": "This work aims to achieve cluster synchronization of a complex network by some pinning control strategies. Firstly, the network not only is affected by the reaction–diffusion and the directed coupling phenomena, but also is disturbed by the stochastic noise and Markovian switching. Secondly, switched constant gain pinning, centralized and decentralized adaptive pinning are proposed respectively to realize the cluster synchronization of the considered network. In these adaptive pinning controllers, the control gain and coupling strength can been adjusted automatically while only a part of the nodes are controlled. Thirdly, the target state of cluster synchronization is taken as the average state related to the directed topology of all nodes in the same cluster, and does not need to be given separately as an isolated node. Finally, to verify the theoretical results, some simulations of directed coupled reaction–diffusion neural networks with stochastic noise and Markovian switching are given.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003933",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster (spacecraft)",
      "Combinatorics",
      "Complex network",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Coupling (piping)",
      "Diffusion",
      "Engineering",
      "Image (mathematics)",
      "Markov process",
      "Mathematics",
      "Mechanical engineering",
      "Network topology",
      "Node (physics)",
      "Noise (video)",
      "Physics",
      "Quantum mechanics",
      "State (computer science)",
      "Statistics",
      "Synchronization (alternating current)",
      "Thermodynamics",
      "Topology (electrical circuits)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Lu",
        "given_name": "Binglong"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Abdurahman",
        "given_name": "Abdujelil"
      },
      {
        "surname": "Liu",
        "given_name": "Mei"
      }
    ]
  },
  {
    "title": "A simple and reliable instance selection for fast training support vector machine: Valid Border Recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.018",
    "abstract": "Support vector machines (SVMs) are powerful statistical learning tools, but their application to large datasets can cause time-consuming training complexity. To address this issue, various instance selection (IS) approaches have been proposed, which choose a small fraction of critical instances and screen out others before training. However, existing methods have not been able to balance accuracy and efficiency well. Some methods miss critical instances, while others use complicated selection schemes that require even more execution time than training with all original instances, thus violating the initial intention of IS. In this work, we present a newly developed IS method called Valid Border Recognition (VBR). VBR selects the closest heterogeneous neighbors as valid border instances and incorporates this process into the creation of a reduced Gaussian kernel matrix, thus minimizing the execution time. To improve reliability, we propose a strengthened version of VBR (SVBR). Based on VBR, SVBR gradually adds farther heterogeneous neighbors as complements until the Lagrange multipliers of already selected instances become stable. In numerical experiments, the effectiveness of our proposed methods is verified on benchmark and synthetic datasets in terms of accuracy, execution time and inference time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003763",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Chemistry",
      "Combinatorics",
      "Computer science",
      "Data mining",
      "Epistemology",
      "Fraction (chemistry)",
      "Gaussian",
      "Gaussian process",
      "Geodesy",
      "Geography",
      "Inference",
      "Kernel (algebra)",
      "Machine learning",
      "Mathematics",
      "Operating system",
      "Organic chemistry",
      "Philosophy",
      "Physics",
      "Power (physics)",
      "Process (computing)",
      "Quantum mechanics",
      "Reliability (semiconductor)",
      "Selection (genetic algorithm)",
      "Simple (philosophy)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Long"
      },
      {
        "surname": "Tian",
        "given_name": "Yingjie"
      },
      {
        "surname": "Wang",
        "given_name": "Xiaowei"
      },
      {
        "surname": "Pardalos",
        "given_name": "Panos M."
      }
    ]
  },
  {
    "title": "End-to-end neural speaker diarization with an iterative adaptive attractor estimation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.043",
    "abstract": "End-to-end neural diarization (EEND) which has the capability to directly output speaker diarization results and handle overlapping speech has attracted more and more attention due to its promising performance. Although existing EEND-based methods often outperform clustering-based methods, they cannot generalize well to unseen test sets because fixed attractors are often utilized to estimate speech activities of each speaker. An iterative adaptive attractor estimation (IAAE) network was proposed to refine diarization results, in which the self-attentive EEND (SA-EEND) was implemented to initialize diarization results and frame-wise embeddings. There are two main parts in the proposed IAAE network: an attention-based pooling was designed to obtain a rough estimation of the attractors based on the diarization results of the previous iteration, and an adaptive attractor was then calculated by using transformer decoder blocks. A unified training framework was proposed to further improve the diarization performance, making the embeddings more discriminable based on the well separated attractors. We evaluated the proposed method on both the simulated mixtures and the real CALLHOME dataset using the diarization error rate (DER). Our proposed method provides relative reductions in DER by up to 44.8% on simulated 2-speaker mixtures and 23.6% on the CALLHOME dataset over the baseline SA-EEND at the 2nd iteration step. We also demonstrated that with an increasing number of refinement steps applied, the DER on the CALLHOME dataset could be further reduced to 7.36%, achieving the state-of-the-art diarization results when compared with other methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300401X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Attractor",
      "Cluster analysis",
      "Computer science",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Speaker diarisation",
      "Speaker recognition",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Hao",
        "given_name": "Fengyuan"
      },
      {
        "surname": "Li",
        "given_name": "Xiaodong"
      },
      {
        "surname": "Zheng",
        "given_name": "Chengshi"
      }
    ]
  },
  {
    "title": "Warming up recurrent neural networks to maximise reachable multistability greatly improves learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.023",
    "abstract": "Training recurrent neural networks is known to be difficult when time dependencies become long. In this work, we show that most standard cells only have one stable equilibrium at initialisation, and that learning on tasks with long time dependencies generally occurs once the number of network stable equilibria increases; a property known as multistability. Multistability is often not easily attained by initially monostable networks, making learning of long time dependencies between inputs and outputs difficult. This insight leads to the design of a novel way to initialise any recurrent cell connectivity through a procedure called “warmup” to improve its capability to learn arbitrarily long time dependencies. This initialisation procedure is designed to maximise network reachable multistability, i.e., the number of equilibria within the network that can be reached through relevant input trajectories, in few gradient steps. We show on several information restitution, sequence classification, and reinforcement learning benchmarks that warming up greatly improves learning speed and performance, for multiple recurrent cells, but sometimes impedes precision. We therefore introduce a double-layer architecture initialised with a partial warmup that is shown to greatly improve learning of long time dependencies while maintaining high levels of precision. This approach provides a general framework for improving learning abilities of any recurrent cell when long time dependencies are present. We also show empirically that other initialisation and pretraining procedures from the literature implicitly foster reachable multistability of recurrent cells.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003817",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Genetics",
      "Multistability",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Sequence (biology)"
    ],
    "authors": [
      {
        "surname": "Lambrechts",
        "given_name": "Gaspard"
      },
      {
        "surname": "De Geeter",
        "given_name": "Florent"
      },
      {
        "surname": "Vecoven",
        "given_name": "Nicolas"
      },
      {
        "surname": "Ernst",
        "given_name": "Damien"
      },
      {
        "surname": "Drion",
        "given_name": "Guillaume"
      }
    ]
  },
  {
    "title": "Synchronization of coupled switched neural networks subject to hybrid stochastic disturbances",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.045",
    "abstract": "In this paper, the theoretical analysis on exponential synchronization of a class of coupled switched neural networks suffering from stochastic disturbances and impulses is presented. A control law is developed and two sets of sufficient conditions are derived for the synchronization of coupled switched neural networks. First, for desynchronizing stochastic impulses, the synchronization of coupled switched neural networks is analyzed by Lyapunov function method, the comparison principle and a impulsive delay differential inequality. Then, for general stochastic impulses, by partitioning impulse interval and using the convex combination technique, a set of sufficient condition on the basis of linear matrix inequalities (LMIs) is derived for the synchronization of coupled switched neural networks. Eventually, two numerical examples and a practical application are elaborated to illustrate the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023004033",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convex combination",
      "Convex optimization",
      "Geometry",
      "Impulse (physics)",
      "Interval (graph theory)",
      "Lyapunov function",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Regular polygon",
      "Stochastic neural network",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Long",
        "given_name": "Han"
      },
      {
        "surname": "Ci",
        "given_name": "Jingxuan"
      },
      {
        "surname": "Guo",
        "given_name": "Zhenyuan"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "ATNAS: Automatic Termination for Neural Architecture Search",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.011",
    "abstract": "Neural architecture search (NAS) is a framework for automating the design process of a neural network structure. While the recent one-shot approaches have reduced the search cost, there still exists an inherent trade-off between cost and performance. It is important to appropriately stop the search and further reduce the high cost of NAS. Meanwhile, the differentiable architecture search (DARTS), a typical one-shot approach, is known to suffer from overfitting. Heuristic early-stopping strategies have been proposed to overcome such performance degradation. In this paper, we propose a more versatile and principled early-stopping criterion on the basis of the evaluation of a gap between expectation values of generalisation errors of the previous and current search steps with respect to the architecture parameters. The stopping threshold is automatically determined at each search epoch without cost. In numerical experiments, we demonstrate the effectiveness of the proposed method. We stop the one-shot NAS algorithms and evaluate the acquired architectures on the benchmark datasets: NAS-Bench-201 and NATS-Bench. Our algorithm is shown to reduce the cost of the search process while maintaining a high performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003696",
    "keywords": [
      "Algorithm",
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Beam search",
      "Benchmark (surveying)",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Early stopping",
      "Economics",
      "Geodesy",
      "Geography",
      "Heuristic",
      "Machine learning",
      "Microeconomics",
      "Network architecture",
      "Operating system",
      "Overfitting",
      "Process (computing)",
      "Search algorithm",
      "Search cost",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Sakamoto",
        "given_name": "Kotaro"
      },
      {
        "surname": "Ishibashi",
        "given_name": "Hideaki"
      },
      {
        "surname": "Sato",
        "given_name": "Rei"
      },
      {
        "surname": "Shirakawa",
        "given_name": "Shinichi"
      },
      {
        "surname": "Akimoto",
        "given_name": "Youhei"
      },
      {
        "surname": "Hino",
        "given_name": "Hideitsu"
      }
    ]
  },
  {
    "title": "A unified semi-supervised model with joint estimation of graph, soft labels and latent subspace",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.014",
    "abstract": "Since manually labeling images is expensive and labor intensive, in practice we often do not have enough labeled images to train an effective classifier for the new image classification tasks. The graph-based SSL methods have received more attention in practice due to their convexity, scalability and efficiency. In this paper, we propose a novel graph-based semi-supervised learning method that takes full advantage of a small set of labeled graphs and a large set of unlabeled graph data. First, we explain the concept of graph-based semi-supervised learning. The core idea of these models is to jointly estimate a low-rank graph with soft labels and a latent subspace. The proposed scheme leverages the synergy between the graph structure and the data representation in terms of soft labels and latent features. This improves the monitoring information and leads to better discriminative linear transformation. Several experiments were conducted on five image datasets using state-of-the-art methods. These experiments show the effectiveness of the proposed semi-supervised method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003726",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Database",
      "Discriminative model",
      "Graph",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Scalability",
      "Semi-supervised learning",
      "Subspace topology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Dornaika",
        "given_name": "Fadi"
      },
      {
        "surname": "Baradaaji",
        "given_name": "Abdullah"
      }
    ]
  },
  {
    "title": "Sparse solution of least-squares twin multi-class support vector machine using ℓ 0 and ℓ p -norm for classification and feature selection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.039",
    "abstract": "In the realm of multi-class classification, the twin K-class support vector classification (Twin-KSVC) generates ternary outputs { − 1 , 0 , + 1 } by evaluating all training data in a “1-versus-1-versus-rest” structure. Recently, inspired by the least-squares version of Twin-KSVC and Twin-KSVC, a new multi-class classifier called improvements on least-squares twin multi-class classification support vector machine (ILSTKSVC) has been proposed. In this method, the concept of structural risk minimization is achieved by incorporating a regularization term in addition to the minimization of empirical risk. Twin-KSVC and its improvements have an influence on classification accuracy. Another aspect influencing classification accuracy is feature selection, which is a critical stage in machine learning, especially when working with high-dimensional datasets. However, most prior studies have not addressed this crucial aspect. In this study, motivated by ILSTKSVC and the cardinality-constrained optimization problem, we propose ℓ p -norm least-squares twin multi-class support vector machine (PLSTKSVC) with 0 < p < 1 to perform classification and feature selection at the same time. The technique employed to solve the optimization problems associated with PLSTKSVC is user-friendly, as it involves solving systems of linear equations to obtain an approximate solution for the proposed model. Under certain assumptions, we investigate the properties of the optimum solutions to the related optimization problems. Several real-world datasets were tested using the suggested method. According to the results of our experiments, the proposed method outperforms all current strategies in most datasets in terms of classification accuracy while also reducing the number of features.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003982",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Feature selection",
      "Machine learning",
      "Minification",
      "Programming language",
      "Structural risk minimization",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Moosaei",
        "given_name": "Hossein"
      },
      {
        "surname": "Hladík",
        "given_name": "Milan"
      }
    ]
  },
  {
    "title": "A survey on neural-symbolic learning systems",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.028",
    "abstract": "In recent years, neural systems have demonstrated highly effective learning ability and superior perception intelligence. However, they have been found to lack effective reasoning and cognitive ability. On the other hand, symbolic systems exhibit exceptional cognitive intelligence but suffer from poor learning capabilities when compared to neural systems. Recognizing the advantages and disadvantages of both methodologies, an ideal solution emerges: combining neural systems and symbolic systems to create neural-symbolic learning systems that possess powerful perception and cognition. The purpose of this paper is to survey the advancements in neural-symbolic learning systems from four distinct perspectives: challenges, methods, applications, and future directions. By doing so, this research aims to propel this emerging field forward, offering researchers a comprehensive and holistic overview. This overview will not only highlight the current state-of-the-art but also identify promising avenues for future research.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003398",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognition",
      "Cognitive science",
      "Computer science",
      "Epistemology",
      "Field (mathematics)",
      "Ideal (ethics)",
      "Machine learning",
      "Mathematics",
      "Neural system",
      "Neuroscience",
      "Perception",
      "Philosophy",
      "Psychology",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Dongran"
      },
      {
        "surname": "Yang",
        "given_name": "Bo"
      },
      {
        "surname": "Liu",
        "given_name": "Dayou"
      },
      {
        "surname": "Wang",
        "given_name": "Hui"
      },
      {
        "surname": "Pan",
        "given_name": "Shirui"
      }
    ]
  },
  {
    "title": "RegraphGAN: A graph generative adversarial network model for dynamic network anomaly detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.026",
    "abstract": "Due to the wide application of dynamic graph anomaly detection in cybersecurity, social networks, e-commerce, etc., research in this area has received increasing attention. Graph generative adversarial networks can be used in dynamic graph anomaly detection due to their ability to model complex data, but the original graph generative adversarial networks do not have a method to learn reverse mapping and require an expensive process in recovering the potential representation of a given input. Therefore, this paper proposes a novel graph generative adversarial network by adding encoders to map real data to latent space to improve the training efficiency and stability of graph generative adversarial network models, which is named RegraphGAN in this paper. And this paper proposes a dynamic network anomaly edge detection method by combining RegraphGAN with spatiotemporal coding to solve the complex dynamic graph data and the problem of attribute-free node information coding challenges. Meanwhile, anomaly detection experiments are conducted on six real dynamic network datasets, and the results show that the dynamic network anomaly detection method proposed in this paper outperforms other existing methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003842",
    "keywords": [
      "Adversarial system",
      "Anomaly detection",
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Generative adversarial network",
      "Generative grammar",
      "Generative model",
      "Graph",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Dezhi"
      },
      {
        "surname": "Liu",
        "given_name": "Zhaowei"
      },
      {
        "surname": "Li",
        "given_name": "Ranran"
      }
    ]
  },
  {
    "title": "Balance guided incomplete multi-view spectral clustering",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.022",
    "abstract": "There is a large volume of incomplete multi-view data in the real-world. How to partition these incomplete multi-view data is an urgent realistic problem since almost all of the conventional multi-view clustering methods are inapplicable to cases with missing views. In this paper, a novel graph learning-based incomplete multi-view clustering (IMVC) method is proposed to address this issue. Different from existing works, our method aims at learning a common consensus graph from all incomplete views and obtaining a clustering indicator matrix in a unified framework. To achieve a stable clustering result, a relaxed spectral clustering model is introduced to obtain a probability consensus representation with all positive elements that reflect the data clustering result. Considering the different contributions of views to the clustering task, a weighted multi-view learning mechanism is introduced to automatically balance the effects of different views in model optimization. In this way, the intrinsic information of the incomplete multi-view data can be fully exploited. The experiments on several incomplete multi-view datasets show that our method outperforms the compared state-of-the-art clustering methods, which demonstrates the effectiveness of our method for IMVC.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003805",
    "keywords": [
      "Artificial intelligence",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Computer science",
      "Consensus clustering",
      "Constrained clustering",
      "Correlation clustering",
      "Data mining",
      "Data stream clustering",
      "Fuzzy clustering",
      "Graph",
      "Machine learning",
      "Spectral clustering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Lilei"
      },
      {
        "surname": "Wen",
        "given_name": "Jie"
      },
      {
        "surname": "Liu",
        "given_name": "Chengliang"
      },
      {
        "surname": "Fei",
        "given_name": "Lunke"
      },
      {
        "surname": "Li",
        "given_name": "Lusi"
      }
    ]
  },
  {
    "title": "Perceptual Contrastive Generative Adversarial Network based on image warping for unsupervised image-to-image translation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.010",
    "abstract": "This paper proposes an unsupervised image-to-image (UI2I) translation model, called Perceptual Contrastive Generative Adversarial Network (PCGAN), which can mitigate the distortion problem to enhance performance of the traditional UI2I methods. The PCGAN is designed with a two-stage UI2I model. In the first stage of the PCGAN, it leverages a novel image warping to transform shapes of objects in input (source) images. In the second stage of the PCGAN, the residual prediction is devised in refinements of the outputs of the first stage of the PCGAN. To promote performance of the image warping, a loss function, called Perceptual Patch-Wise InfoNCE, is developed in the PCGAN to effectively memorize the visual correspondences between warped images and refined images. Experimental results on quantitative evaluation and visualization comparison for UI2I benchmarks show that the PCGAN is superior to other existing methods considered here.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003684",
    "keywords": [
      "Amplifier",
      "Artificial intelligence",
      "Bandwidth (computing)",
      "Biochemistry",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Distortion (music)",
      "Gene",
      "Generative grammar",
      "Image (mathematics)",
      "Image translation",
      "Image warping",
      "Messenger RNA",
      "Pattern recognition (psychology)",
      "Translation (biology)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Lin-Chieh"
      },
      {
        "surname": "Tsai",
        "given_name": "Hung-Hsu"
      }
    ]
  },
  {
    "title": "EPC-DARTS: Efficient partial channel connection for differentiable architecture search",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.029",
    "abstract": "With weight-sharing and continuous relaxation strategies, the differentiable architecture search (DARTS) proposes a fast and effective solution to perform neural network architecture search in various deep learning tasks. However, unresolved issues, such as the inefficient memory utilization, and the poor stability of the search architecture due to channels randomly selected, which has even caused performance collapses, are still perplexing researchers and practitioners. In this paper, a novel efficient channel attention mechanism based on partial channel connection for differentiable neural architecture search, termed EPC-DARTS, is proposed to address these two issues. Specifically, we design an efficient channel attention module, which is applied to capture cross-channel interactions and assign weight based on channel importance, to dramatically improve search efficiency and reduce memory occupation. Moreover, only partial channels with higher weights in the mixed calculation of operation are used through the efficient channel attention mechanism, and thus unstable network architectures obtained by the random selection operation can also be avoided in the proposed EPC-DARTS. Experimental results show that the proposed EPC-DARTS achieves remarkably competitive performance (CIFAR-10/CIFAR-100: a test accuracy rate of 97.60%/84.02%), compared to other state-of-the-art NAS methods using only 0.2 GPU-Days.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003878",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer architecture",
      "Computer engineering",
      "Computer network",
      "Computer science",
      "Connection (principal bundle)",
      "Differentiable function",
      "Geometry",
      "Mathematical analysis",
      "Mathematics",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Cai",
        "given_name": "Zicheng"
      },
      {
        "surname": "Chen",
        "given_name": "Lei"
      },
      {
        "surname": "Liu",
        "given_name": "Hai-Lin"
      }
    ]
  },
  {
    "title": "An adaptive neurodynamic approach for solving nonsmooth N -cluster games",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.041",
    "abstract": "In this paper, N -cluster games with coupling and private constraints are studied, where each player’s cost function is nonsmooth and depends on the actions of all players. In order to seek the generalized Nash equilibrium (GNE) of the nonsmooth N -cluster games, a distributed seeking neurodynamic approach with two-time-scale structure is proposed. An adaptive leader-following consensus technique is adapted to dynamically adjust parameters according to the degree of consensus violation, so as to quickly obtain accurate estimation information of other players’ actions which facilitates the evaluation of its own cost. Benefitting from the unique structure of the approach based on primal dual and adaptive penalty methods, the players’ actions enter the constraints while completing the seeking for GNE. As a result, the neurodynamic approach is completely distributed, and prior estimation of penalty parameters is avoided. Finally, two engineering examples of power system game and company capacity allocation verify the effectiveness and feasibility of the neurodynamic approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003994",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Mengxin"
      },
      {
        "surname": "Zhu",
        "given_name": "Shihui"
      },
      {
        "surname": "Qin",
        "given_name": "Sitian"
      }
    ]
  },
  {
    "title": "Memristor-based spiking neural network with online reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.031",
    "abstract": "Neural networks implemented in memristor-based hardware can provide fast and efficient in-memory computation, but traditional learning methods such as error back-propagation are hardly feasible in it. Spiking neural networks (SNNs) are highly promising in this regard, as their weights can be changed locally in a self-organized manner without the demand for high-precision changes calculated with the use of information almost from the entire network. This problem is rather relevant for solving control tasks with neural-network reinforcement learning methods, as those are highly sensitive to any source of stochasticity in a model initialization, training, or decision-making procedure. This paper presents an online reinforcement learning algorithm in which the change of connection weights is carried out after processing each environment state during interaction-with-environment data generation. Another novel feature of the algorithm is that it is applied to SNNs with memristor-based STDP-like learning rules. The plasticity functions are obtained from real memristors based on poly-p-xylylene and CoFeB-LiNbO 3 nanocomposite, which were experimentally assembled and analyzed. The SNN is comprised of leaky integrate-and-fire neurons. Environmental states are encoded by the timings of input spikes, and the control action is decoded by the first spike. The proposed learning algorithm solves the Cart-Pole benchmark task successfully. This result could be the first step towards implementing a real-time agent learning procedure in a continuous-time environment that can be run on neuromorphic systems with memristive synapses.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003891",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Electrical engineering",
      "Engineering",
      "Geodesy",
      "Geography",
      "Initialization",
      "Machine learning",
      "Memristor",
      "Neuromorphic engineering",
      "Programming language",
      "Reinforcement learning",
      "Software engineering",
      "Spike (software development)",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Vlasov",
        "given_name": "Danila"
      },
      {
        "surname": "Minnekhanov",
        "given_name": "Anton"
      },
      {
        "surname": "Rybka",
        "given_name": "Roman"
      },
      {
        "surname": "Davydov",
        "given_name": "Yury"
      },
      {
        "surname": "Sboev",
        "given_name": "Alexander"
      },
      {
        "surname": "Serenko",
        "given_name": "Alexey"
      },
      {
        "surname": "Ilyasov",
        "given_name": "Alexander"
      },
      {
        "surname": "Demin",
        "given_name": "Vyacheslav"
      }
    ]
  },
  {
    "title": "A super-resolution network for medical imaging via transformation analysis of wavelet multi-resolution",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.005",
    "abstract": "In recent years, deep learning super-resolution models for progressive reconstruction have achieved great success. However, these models which refer to multi-resolution analysis basically ignore the information contained in the lower subspaces and do not explore the correlation between features in the wavelet and spatial domain, resulting in not fully utilizing the auxiliary information brought by multi-resolution analysis with multiple domains. Therefore, we propose a super-resolution network based on the wavelet multi-resolution framework (WMRSR) to capture the auxiliary information contained in multiple subspaces and to be aware of the interdependencies between spatial domain and wavelet domain features. Initially, the wavelet multi-resolution input (WMRI) is generated by combining wavelet sub-bands obtained from each subspace through wavelet multi-resolution analysis and the corresponding spatial domain image content, which serves as input to the network. Then, the WMRSR captures the corresponding features from the WMRI in the wavelet domain and spatial domain, respectively, and fuses them adaptively, thus learning fully explored features in multi-resolution and multi-domain. Finally, the high-resolution images are gradually reconstructed in the wavelet multi-resolution framework by our convolution-based wavelet transform module which is suitable for deep neural networks. Extensive experiments conducted on two public datasets demonstrate that our method outperforms other state-of-the-art methods in terms of objective and visual qualities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003635",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Convolution (computer science)",
      "Domain (mathematical analysis)",
      "Gene",
      "Geometry",
      "Image resolution",
      "Linear subspace",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Resolution (logic)",
      "Second-generation wavelet transform",
      "Stationary wavelet transform",
      "Subspace topology",
      "Transformation (genetics)",
      "Wavelet",
      "Wavelet packet decomposition",
      "Wavelet transform"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Yue"
      },
      {
        "surname": "She",
        "given_name": "Kun"
      },
      {
        "surname": "Liu",
        "given_name": "Jinhua"
      },
      {
        "surname": "Cai",
        "given_name": "Xiao"
      },
      {
        "surname": "Shi",
        "given_name": "Kaibo"
      },
      {
        "surname": "Kwon",
        "given_name": "O.M."
      }
    ]
  },
  {
    "title": "Tackling higher-order relations and heterogeneity: Dynamic heterogeneous hypergraph network for spatiotemporal activity prediction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.006",
    "abstract": "Spatiotemporal activity prediction aims to predict user activities at a particular time and location, which is applicable in city planning, activity recommendations, and other domains. The fundamental endeavor in spatiotemporal activity prediction is to model the intricate interaction patterns among users, locations, time, and activities, which is characterized by higher-order relations and heterogeneity. Recently, graph-based methods have gained popularity due to the advancements in graph neural networks. However, these methods encounter two significant challenges. Firstly, higher-order relations and heterogeneity are not adequately modeled. Secondly, the majority of established methods are designed around the static graph structures that rely solely on co-occurrence relations, which can be imprecise. To overcome these challenges, we propose Dy H 2 N, a dynamic heterogeneous hypergraph network for spatiotemporal activity prediction. Specifically, to enhance the capacity for modeling higher-order relations, hypergraphs are employed in lieu of graphs. Then we propose a set representation learning-inspired heterogeneous hyperedge learning module, which models higher-order relations and heterogeneity in spatiotemporal activity prediction using a non-decomposable manner. To improve the encoding of heterogeneous spatiotemporal activity hyperedges, a knowledge representation-regularized loss is introduced. Moreover, we present a hypergraph structure learning module to update the hypergraph structures dynamically. Our proposed Dy H 2 N model has been extensively tested on four real-world datasets, proving to outperform previous state-of-the-art methods by 5.98% to 27.13%. The effectiveness of all framework components is demonstrated through ablation experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003647",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Discrete mathematics",
      "Graph",
      "Heterogeneous network",
      "Hypergraph",
      "Law",
      "Machine learning",
      "Mathematics",
      "Political science",
      "Politics",
      "Popularity",
      "Programming language",
      "Psychology",
      "Representation (politics)",
      "Set (abstract data type)",
      "Social psychology",
      "Telecommunications",
      "Theoretical computer science",
      "Wireless",
      "Wireless network"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Changyuan"
      },
      {
        "surname": "Zhang",
        "given_name": "Zequn"
      },
      {
        "surname": "Yao",
        "given_name": "Fanglong"
      },
      {
        "surname": "Guo",
        "given_name": "Zhi"
      },
      {
        "surname": "Yan",
        "given_name": "Shiyao"
      },
      {
        "surname": "Sun",
        "given_name": "Xian"
      }
    ]
  },
  {
    "title": "Adaptive event-triggered synchronization of neural networks under stochastic cyber-attacks with application to Chua’s circuit",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.004",
    "abstract": "This paper focuses on the synchronization control problem for neural networks (NNs) subject to stochastic cyber-attacks. Firstly, an adaptive event-triggered scheme (AETS) is adopted to improve the utilization rate of network resources, and an output feedback controller is constructed for improving the performance of the system subject to the conventional deception attack and accumulated dynamic cyber-attack. Secondly, the synchronization problem of master–slave NNs is transformed into the stability analysis problem of the synchronization error system. Thirdly, by constructing a customized Lyapunov–Krasovskii functional (LKF), the adaptive event-triggered output feedback controller is designed to ensure the synchronization error system is asymptotically stable with a given H ∞ performance index. Lastly, in the simulation part, two examples, including Chua’s circuit, illustrate the feasibility and universality of the related technologies in this paper.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003623",
    "keywords": [
      "Adaptive control",
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Cyber-physical system",
      "Lyapunov stability",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Scheme (mathematics)",
      "Stability (learning theory)",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Yao"
      },
      {
        "surname": "Yang",
        "given_name": "Chunyu"
      },
      {
        "surname": "Zhou",
        "given_name": "Linna"
      },
      {
        "surname": "Ma",
        "given_name": "Lei"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      }
    ]
  },
  {
    "title": "Reconstructing controllable faces from brain activity with hierarchical multiview representations",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.016",
    "abstract": "Reconstructing visual experience from brain responses measured by functional magnetic resonance imaging (fMRI) is a challenging yet important research topic in brain decoding, especially it has proved more difficult to decode visually similar stimuli, such as faces. Although face attributes are known as the key to face recognition, most existing methods generally ignore how to decode facial attributes more precisely in perceived face reconstruction, which often leads to indistinguishable reconstructed faces. To solve this problem, we propose a novel neural decoding framework called VSPnet (voxel2style2pixel) by establishing hierarchical encoding and decoding networks with disentangled latent representations as media, so that to recover visual stimuli more elaborately. And we design a hierarchical visual encoder (named HVE) to pre-extract features containing both high-level semantic knowledge and low-level visual details from stimuli. The proposed VSPnet consists of two networks: Multi-branch cognitive encoder and style-based image generator. The encoder network is constructed by multiple linear regression branches to map brain signals to the latent space provided by the pre-extracted visual features and obtain representations containing hierarchical information consistent to the corresponding stimuli. We make the generator network inspired by StyleGAN to untangle the complexity of fMRI representations and generate images. And the HVE network is composed of a standard feature pyramid over a ResNet backbone. Extensive experimental results on the latest public datasets have demonstrated the reconstruction accuracy of our proposed method outperforms the state-of-the-art approaches and the identifiability of different reconstructed faces has been greatly improved. In particular, we achieve feature editing for several facial attributes in fMRI domain based on the multiview (i.e., visual stimuli and evoked fMRI) latent representations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300374X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Decoding methods",
      "Encoder",
      "Encoding (memory)",
      "Face (sociological concept)",
      "Feature (linguistics)",
      "Functional magnetic resonance imaging",
      "Geometry",
      "Linguistics",
      "Mathematics",
      "Neuroscience",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pyramid (geometry)",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Ren",
        "given_name": "Ziqi"
      },
      {
        "surname": "Li",
        "given_name": "Jie"
      },
      {
        "surname": "Xue",
        "given_name": "Xuetong"
      },
      {
        "surname": "Li",
        "given_name": "Xin"
      },
      {
        "surname": "Yang",
        "given_name": "Fan"
      },
      {
        "surname": "Jiao",
        "given_name": "Zhicheng"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "H ∞ master–slave synchronization for delayed impulsive implicit hybrid neural networks based on memory-state feedback control",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.016",
    "abstract": "This paper investigates the H ∞ master–slave synchronization problem for delayed impulsive implicit hybrid neural networks based on memory-state feedback control. By developing a more holistic stochastic impulse-time-dependent Lyapunov–Krasovskii functional and dealing with the nonlinear neuron activation function, the stochastic admissibility and prescribed H ∞ performance index for the synchronization error closed-loop system are achieved. In addition, the desired mode-dependent memory-state feedback synchronization controller is acquired in the form of linear matrix inequalities. The free-weighting matrix technique is adopted to remove the inherent limitation of time-varying delay derivative for the implicit delayed systems, and the derivative of time-varying delay is relaxed enough to be greater than 1. The simulation of genetic regulatory network in bio-economic system is given to verify validity of the derived results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003271",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Composite material",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Impulse (physics)",
      "Materials science",
      "Matrix (chemical analysis)",
      "Medicine",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Radiology",
      "State (computer science)",
      "Synchronization (alternating current)",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Zekun"
      },
      {
        "surname": "Zhuang",
        "given_name": "Guangming"
      },
      {
        "surname": "Xie",
        "given_name": "Xiangpeng"
      },
      {
        "surname": "Xia",
        "given_name": "Jianwei"
      }
    ]
  },
  {
    "title": "Adaptive neural-network-based sliding mode control of switching distributed delay systems with Markov jump parameters",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.022",
    "abstract": "This paper is devoted to the issue of observer-based adaptive sliding mode control of distributed delay systems with deterministic switching rules and stochastic jumping process, simultaneously, through a neural network approach. Firstly, relying on the designed Lebesgue observer, a sliding mode hyperplane in the integral form is put forward, on which a desired sliding mode dynamic system is derived. Secondly, in consideration of complexity of real transition rates information, a novel adaptive dynamic controller that fits to universal mode information is designed to ensure the existence of sliding motion in finite-time, especially for the case that the mode information is totally unknown. In addition, an observer-based neural compensator is developed to attenuate the effectiveness of unknown system nonlinearity. Thirdly, an average dwell-time approach is utilized to check the mean-square exponential stability of the obtained sliding mode dynamics, particularly, the proposed criteria conditions are successfully unified with the designed controller in the type of mode information. Finally, a practical example is provided to verify the validity of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003337",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Geometry",
      "Hyperplane",
      "Mathematics",
      "Mode (computer interface)",
      "Nonlinear system",
      "Observer (physics)",
      "Operating system",
      "Physics",
      "Quantum mechanics",
      "Sliding mode control",
      "State observer"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Baoping"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      },
      {
        "surname": "Zhang",
        "given_name": "Xin"
      },
      {
        "surname": "Wu",
        "given_name": "Zhengtian"
      }
    ]
  },
  {
    "title": "Approximation of classifiers by deep perceptron networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.004",
    "abstract": "We employ properties of high-dimensional geometry to obtain some insights into capabilities of deep perceptron networks to classify large data sets. We derive conditions on network depths, types of activation functions, and numbers of parameters that imply that approximation errors behave almost deterministically. We illustrate general results by concrete cases of popular activation functions: Heaviside, ramp sigmoid, rectified linear, and rectified power. Our probabilistic bounds on approximation errors are derived using concentration of measure type inequalities (method of bounded differences) and concepts from statistical learning theory.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003052",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Function approximation",
      "Generalization",
      "Heaviside step function",
      "Mathematical analysis",
      "Mathematics",
      "Measure (data warehouse)",
      "Multilayer perceptron",
      "Perceptron",
      "Probabilistic logic",
      "Sigmoid function"
    ],
    "authors": [
      {
        "surname": "Kůrková",
        "given_name": "Věra"
      },
      {
        "surname": "Sanguineti",
        "given_name": "Marcello"
      }
    ]
  },
  {
    "title": "Predictive hierarchical reinforcement learning for path-efficient mapless navigation with moving target",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.007",
    "abstract": "Deep reinforcement learning (DRL) has been proven as a powerful approach for robot navigation over the past few years. DRL-based navigation does not require the pre-construction of a map, instead, high-performance navigation skills can be learned from trial-and-error experiences. However, recent DRL-based approaches mostly focus on a fixed navigation target. It is noted that when navigating to a moving target without maps, the performance of the standard RL structure drops dramatically on both the success rate and path efficiency. To address the mapless navigation problem with moving target, the predictive hierarchical DRL (pH-DRL) framework is proposed by integrating the long-term trajectory prediction to provide a cost-effective solution. In the proposed framework, the lower-level policy of the RL agent learns robot control actions to a specified goal, and the higher-level policy learns to make long-range planning of shorter navigation routes by sufficiently exploiting the predicted trajectories. By means of making decisions over two level of policies, the pH-DRL framework is robust to the unavoidable errors in long-term predictions. With the application of deep deterministic policy gradient (DDPG) for policy optimization, the pH-DDPG algorithm is developed based on the pH-DRL structure. Finally, through comparative experiments on the Gazebo simulator with several variants of the DDPG algorithm, the results demonstrate that the pH-DDPG outperforms other algorithms and achieves a high success rate and efficiency even though the target moves fast and randomly.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300309X",
    "keywords": [
      "Aerospace engineering",
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Engineering",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Motion planning",
      "Path (computing)",
      "Physics",
      "Programming language",
      "Range (aeronautics)",
      "Reinforcement learning",
      "Robot",
      "Scheme (mathematics)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Hanxiao"
      },
      {
        "surname": "Luo",
        "given_name": "Biao"
      },
      {
        "surname": "Song",
        "given_name": "Wei"
      },
      {
        "surname": "Yang",
        "given_name": "Chunhua"
      }
    ]
  },
  {
    "title": "Analysis on the inherent noise tolerance of feedforward network and one noise-resilient structure",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.011",
    "abstract": "In the past few decades, feedforward neural networks have gained much attraction in their hardware implementations. However, when we realize a neural network in analog circuits, the circuit-based model is sensitive to hardware nonidealities. The nonidealities, such as random offset voltage drifts and thermal noise, may lead to variation in hidden neurons and further affect neural behaviors. This paper considers that time-varying noise exists at the input of hidden neurons, with zero-mean Gaussian distribution. First, we derive lower and upper bounds on the mean square error loss to estimate the inherent noise tolerance of a noise-free trained feedforward network. Then, the lower bound is extended for any non-Gaussian noise cases based on the Gaussian mixture model concept. The upper bound is generalized for any non-zero-mean noise case. As the noise could degrade the neural performance, a new network architecture is designed to suppress the noise effect. This noise-resilient design does not require any training process. We also discuss its limitation and give a closed-form expression to describe the noise tolerance when the limitation is exceeded.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003234",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Feed forward",
      "Feedforward neural network",
      "Gaussian",
      "Gaussian noise",
      "Image (mathematics)",
      "Mathematical analysis",
      "Mathematics",
      "Noise (video)",
      "Offset (computer science)",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Topology (electrical circuits)",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Lu",
        "given_name": "Wenhao"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhengyuan"
      },
      {
        "surname": "Qin",
        "given_name": "Feng"
      },
      {
        "surname": "Zhang",
        "given_name": "Wenwen"
      },
      {
        "surname": "Lu",
        "given_name": "Yuncheng"
      },
      {
        "surname": "Liu",
        "given_name": "Yue"
      },
      {
        "surname": "Zheng",
        "given_name": "Yuanjin"
      }
    ]
  },
  {
    "title": "DyVGRNN: DYnamic mixture Variational Graph Recurrent Neural Networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.048",
    "abstract": "Although graph representation learning has been studied extensively in static graph settings, dynamic graphs are less investigated in this context. This paper proposes a novel integrated variational framework called DYnamic mixture Variational Graph Recurrent Neural Networks (DyVGRNN), which consists of extra latent random variables in structural and temporal modelling. Our proposed framework comprises an integration of Variational Graph Auto-Encoder (VGAE) and Graph Recurrent Neural Network (GRNN) by exploiting a novel attention mechanism. The Gaussian Mixture Model (GMM) and the VGAE framework are combined in DyVGRNN to model the multimodal nature of data, which enhances performance. To consider the significance of time steps, our proposed method incorporates an attention-based module. The experimental results demonstrate that our method greatly outperforms state-of-the-art dynamic graph representation learning methods in terms of link prediction and clustering. 2 2 The source code is available at https://github.com/GhazalehNiknam/DyVGRNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002927",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster analysis",
      "Computer science",
      "Gaussian",
      "Graph",
      "Latent variable",
      "Mixture model",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Niknam",
        "given_name": "Ghazaleh"
      },
      {
        "surname": "Molaei",
        "given_name": "Soheila"
      },
      {
        "surname": "Zare",
        "given_name": "Hadi"
      },
      {
        "surname": "Pan",
        "given_name": "Shirui"
      },
      {
        "surname": "Jalili",
        "given_name": "Mahdi"
      },
      {
        "surname": "Zhu",
        "given_name": "Tingting"
      },
      {
        "surname": "Clifton",
        "given_name": "David"
      }
    ]
  },
  {
    "title": "Fixed-time synchronization for quaternion-valued memristor-based neural networks with mixed delays",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.045",
    "abstract": "In this paper, the fixed-time synchronization (FXTSYN) of unilateral coefficients quaternion-valued memristor-based neural networks (UCQVMNNs) with mixed delays is investigated. A direct analytical approach is suggested to obtain FXTSYN of UCQVMNNs utilizing one-norm smoothness in place of decomposition. When dealing with drive–response system discontinuity issues, use the set-valued map and the differential inclusion theorem. To accomplish the control objective, innovative nonlinear controllers and the Lyapunov functions are designed. Furthermore, some criteria of FXTSYN for UCQVMNNs are given using inequality techniques and the novel FXTSYN theory. And the accurate settling time is obtained explicitly. Finally, in order to show that the obtained theoretical results are accurate, useful, and applicable, numerical simulations are presented at the conclusion.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002897",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Differential inclusion",
      "Discontinuity (linguistics)",
      "Electrical engineering",
      "Engineering",
      "Geometry",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Memristor",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Quaternion",
      "Settling time",
      "Smoothness",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yanlin"
      },
      {
        "surname": "Yang",
        "given_name": "Liqiao"
      },
      {
        "surname": "Kou",
        "given_name": "Kit Ian"
      },
      {
        "surname": "Liu",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Enhanced covertness class discriminative universal adversarial perturbations",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.006",
    "abstract": "The main aim of class discriminative universal adversarial perturbations (CD-UAPs) is that the adversary can flexibly control the targeted class and influence remaining classes limitedly. CD-UAPs generated by the existing attack strategies suffer from a high fooling ratio of non-targeted source classes under non-targeted and targeted attacks, and face the increasing risk of discovery. In this paper, we propose a training framework for generating enhanced covertness CD-UAPs. It trains the targeted source class set and the non-targeted source classes set alternately to update the perturbation and introduces logit pairing to mitigate the influence of perturbation on the non-targeted source classes set. Further, we extend CD-UAPs on the targeted (one-targeted) attack to the multi-targeted attack, which perturbs a targeted source class to multiple targeted sink classes that seriously threaten the current scenario. It can not only provide the adversary with freedom of precise attack but reduce the risk of being detected. This attack poses a strong threat to security-sensitive applications. Extensive experiments on the CIFAR-10, CIFAR-100 and ImageNet datasets show our method can generate more deceptive perturbations and enhance the covertness of CD-UAPs. For example, our method improves the absolute fooling ratio gaps of ResNet-20 and VGG-16 by 9.46% and 6.94% compared with the baseline method, respectively. We achieve the multi-targeted attack with a high fooling ratio on the GTSRB dataset. The average absolute target fooling ratio gaps of ResNet-20 and VGG-16 are 81.89% and 76.33%, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003076",
    "keywords": [
      "Adversarial system",
      "Arithmetic",
      "Artificial intelligence",
      "Binary number",
      "Class (philosophy)",
      "Computer science",
      "Discriminative model",
      "Mathematics"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Haoran"
      },
      {
        "surname": "Zhang",
        "given_name": "Hua"
      },
      {
        "surname": "Zhang",
        "given_name": "Xin"
      },
      {
        "surname": "Li",
        "given_name": "Wenmin"
      },
      {
        "surname": "Wang",
        "given_name": "Jiahui"
      },
      {
        "surname": "Gao",
        "given_name": "Fei"
      }
    ]
  },
  {
    "title": "Two-timescale recurrent neural networks for distributed minimax optimization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.003",
    "abstract": "In this paper, we present two-timescale neurodynamic optimization approaches to distributed minimax optimization. We propose four multilayer recurrent neural networks for solving four different types of generally nonlinear convex–concave minimax problems subject to linear equality and nonlinear inequality constraints. We derive sufficient conditions to guarantee the stability and optimality of the neural networks. We demonstrate the viability and efficiency of the proposed neural networks in two specific paradigms for Nash-equilibrium seeking in a zero-sum game and distributed constrained nonlinear optimization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003040",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convex optimization",
      "Geometry",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Minimax",
      "Nash equilibrium",
      "Nonlinear system",
      "Optimization problem",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Regular polygon",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Xia",
        "given_name": "Zicong"
      },
      {
        "surname": "Liu",
        "given_name": "Yang"
      },
      {
        "surname": "Wang",
        "given_name": "Jiasen"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Dual Distillation Discriminator Networks for Domain Adaptive Few-Shot Learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.009",
    "abstract": "Domain Adaptive Few-Shot Learning (DA-FSL) aims at accomplishing few-shot classification tasks on a novel domain with the aid of a large number of source-style samples and several target-style samples. It is essential for DA-FSL to transfer task knowledge from the source domain to the target domain and overcome the asymmetry amount of labeled data in both domains. To this end, we propose Dual Distillation Discriminator Networks (D 3 Net) from the perspective of the lack of labeled target domain style samples in DA-FSL. Specifically, we employ the idea of distillation discrimination to avoid the over-fitting caused by the unequal number of samples in the target and source domains, which trains the student discriminator by the soft labels from the teacher discriminator. Meanwhile, we design the task propagation stage and the mixed domain stage respectively from the level of feature space and instances to generate more target-style samples, which apply the task distributions and the sample diversity of the source domain to enhance the target domain. Our D 3 Net realizes the distribution alignment between the source domain and the target domain and constraints the FSL task distribution by prototype distributions on the mixed domain. Extensive experiments on three DA-FSL benchmark datasets, i.e., mini-ImageNet, tiered-ImageNet, and DomainNet, demonstrate that our D 3 Net achieves competitive performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003106",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Chemistry",
      "Computer science",
      "Detector",
      "Discriminator",
      "Distillation",
      "Domain (mathematical analysis)",
      "Economics",
      "Feature (linguistics)",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Task (project management)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Xiyao"
      },
      {
        "surname": "Ji",
        "given_name": "Zhong"
      },
      {
        "surname": "Pang",
        "given_name": "Yanwei"
      },
      {
        "surname": "Han",
        "given_name": "Zhi"
      }
    ]
  },
  {
    "title": "Stabilization of reaction–diffusion fractional-order memristive neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.042",
    "abstract": "This paper investigates the stabilization control of fractional-order memristive neural networks with reaction–diffusion terms. With regard to the reaction–diffusion model, a novel processing method based on Hardy–Poincarè inequality is introduced, as a result, the diffusion terms are estimated associated with the information of the reaction–diffusion coefficients and the regional feature, which may be beneficial to obtain conditions with less conservatism. Then, based on Kakutani’s fixed point theorem of set-valued maps, new testable algebraic conclusion for ensuring the existence of the system’s equilibrium point is obtained. Subsequently, by means of Lyapunov stability theory, it is concluded that the resulting stabilization error system is global asymptotic/Mittag-Leffler stable with a prescribed controller. Finally, an illustrative example about is provided to show the effectiveness of the established results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002861",
    "keywords": [
      "Agronomy",
      "Algebraic number",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Differential equation",
      "Diffusion",
      "Economics",
      "Equilibrium point",
      "Finance",
      "Fixed-point theorem",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Order (exchange)",
      "Physics",
      "Pure mathematics",
      "Reaction–diffusion system",
      "Stability (learning theory)",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Ruoxia"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Li",
        "given_name": "Ning"
      }
    ]
  },
  {
    "title": "Task guided representation learning using compositional models for zero-shot domain adaptation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.030",
    "abstract": "Zero-shot domain adaptation (ZDA) methods aim to transfer knowledge about a task learned in a source domain to a target domain, while task-relevant data from target domain are not available. In this work, we address learning feature representations which are invariant to and shared among different domains considering task characteristics for ZDA. To this end, we propose a method for task-guided ZDA (TG-ZDA) which employs multi-branch deep neural networks to learn feature representations exploiting their domain invariance and shareability properties. The proposed TG-ZDA models can be trained end-to-end without requiring synthetic tasks and data generated from estimated representations of target domains. The proposed TG-ZDA has been examined using benchmark ZDA tasks on image classification datasets. Experimental results show that our proposed TG-ZDA outperforms state-of-the-art ZDA methods for different domains and tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002769",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Economics",
      "Feature (linguistics)",
      "Geodesy",
      "Geography",
      "Invariant (physics)",
      "Law",
      "Linguistics",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematical physics",
      "Mathematics",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Task (project management)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Shuang"
      },
      {
        "surname": "Ozay",
        "given_name": "Mete"
      }
    ]
  },
  {
    "title": "Attribute-driven streaming edge partitioning with reconciliations for distributed graph neural network training",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.026",
    "abstract": "Current distributed graph training frameworks evenly partition a large graph into small chunks to suit distributed storage, leverage a uniform interface to access neighbors, and train graph neural networks in a cluster of machines to update weights. Nevertheless, they consider a separate design of storage and training, resulting in huge communication costs for retrieving neighborhoods. During the storage phase, traditional heuristic graph partitioning not only suffers from memory overhead because of loading the full graph into the memory but also damages semantically related structures because of its neglecting meaningful node attributes. What is more, in the weight-update phase, directly averaging synchronization is difficult to tackle with heterogeneous local models where each machine’s data are loaded from different subgraphs, resulting in slow convergence. To solve these problems, we propose a novel distributed graph training approach, attribute-driven streaming edge partitioning with reconciliations (ASEPR), where the local model loads only the subgraph stored on its own machine to make fewer communications. ASEPR firstly clusters nodes with similar attributes in the same partition to maintain semantic structure and keep multihop neighbor locality. Then streaming partitioning combined with attribute clustering is applied to subgraph assignment to alleviate memory overhead. After local graph neural network training on distributed machines, we deploy cross-layer reconciliation strategies for heterogeneous local models to improve the averaged global model by knowledge distillation and contrastive learning. Extensive experiments conducted on four large graph datasets on node classification and link prediction tasks show that our model outperforms DistDGL, with fewer resource requirements and up to quadruple the convergence speed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003374",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Distributed computing",
      "Graph",
      "Graph partition",
      "Leverage (statistics)",
      "Linguistics",
      "Locality",
      "Mathematics",
      "Partition (number theory)",
      "Philosophy",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Mu",
        "given_name": "Zongshen"
      },
      {
        "surname": "Tang",
        "given_name": "Siliang"
      },
      {
        "surname": "Zhuang",
        "given_name": "Yueting"
      },
      {
        "surname": "Yu",
        "given_name": "Dianhai"
      }
    ]
  },
  {
    "title": "Collaborative neurodynamic optimization for solving nonlinear equations",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.054",
    "abstract": "A distributed optimization method for solving nonlinear equations with constraints is developed in this paper. The multiple constrained nonlinear equations are converted into an optimization problem and we solve it in a distributed manner. Due to the possible presence of nonconvexity, the converted optimization problem might be a nonconvex optimization problem. To this end, we propose a multi-agent system based on an augmented Lagrangian function and prove that it converges to a locally optimal solution to an optimization problem in the presence of nonconvexity. In addition, a collaborative neurodynamic optimization method is adopted to obtain a globally optimal solution. Three numerical examples are elaborated to illustrate the effectiveness of the main results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002988",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Augmented Lagrangian method",
      "Computer science",
      "Constrained optimization",
      "Constrained optimization problem",
      "Continuous optimization",
      "Mathematical optimization",
      "Mathematics",
      "Multi-swarm optimization",
      "Nonlinear programming",
      "Nonlinear system",
      "Optimization problem",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Guan",
        "given_name": "Huimin"
      },
      {
        "surname": "Liu",
        "given_name": "Yang"
      },
      {
        "surname": "Kou",
        "given_name": "Kit Ian"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Rutkowski",
        "given_name": "Leszek"
      }
    ]
  },
  {
    "title": "Multi-view subspace clustering via adaptive graph learning and late fusion alignment",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.019",
    "abstract": "Multi-view subspace clustering has attracted great attention due to its ability to explore data structure by utilizing complementary information from different views. Most of existing methods learn a sample representation coefficient matrix or an affinity graph for each single view, then the final clustering result is obtained from the spectral embedding of a consensus graph using certain traditional clustering techniques, such as k -means. However, clustering performance will be degenerated if the early fusion of partitions cannot fully exploit relationships between all samples. Different from existing methods, we propose a multi-view subspace clustering method via adaptive graph learning and late fusion alignment (AGLLFA). For each view, AGLLFA learns an affinity graph adaptively to capture the similarity relationship among samples. Moreover, a spectral embedding learning term is designed to exploit the latent feature space of different views. Furthermore, we design a late fusion alignment mechanism to generate an optimal clustering partition by fusing view-specific partitions obtained from multiple views. An alternate updating algorithm with validated convergence is developed to solve the resultant optimization problem. Extensive experiments on several benchmark datasets are conducted to illustrate the effectiveness of the proposed method when compared with other state-of-the-art methods. The demo code of this work is publicly available at https://github.com/tangchuan2000/AGLLFA.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002630",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Clustering coefficient",
      "Computer science",
      "Computer security",
      "Embedding",
      "Exploit",
      "Feature learning",
      "Graph",
      "Graph embedding",
      "Graph partition",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Spectral clustering",
      "Subspace topology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Chuan"
      },
      {
        "surname": "Sun",
        "given_name": "Kun"
      },
      {
        "surname": "Tang",
        "given_name": "Chang"
      },
      {
        "surname": "Zheng",
        "given_name": "Xiao"
      },
      {
        "surname": "Liu",
        "given_name": "Xinwang"
      },
      {
        "surname": "Huang",
        "given_name": "Jun-Jie"
      },
      {
        "surname": "Zhang",
        "given_name": "Wei"
      }
    ]
  },
  {
    "title": "The Deep Learning Generative Adversarial Random Neural Network in data marketplaces: The digital creative",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.028",
    "abstract": "Generative Adversarial Networks (GANs) have been proposed as a method to generate multiple replicas from an original version combining a Discriminator and a Generator. The main applications of GANs have been the casual generation of audio and video content. GANs, as a neural method that generates populations of individuals, have emulated genetic algorithms based on biologically inspired operators such as mutation, crossover and selection. This article presents the Deep Learning Generative Adversarial Random Neural Network (RNN) with the same features and functionality as a GAN. Furthermore, the presented algorithm is proposed for an application, the Digital Creative, that generates tradeable replicas in a Data Marketplace, such as 1D functions or audio, 2D and 3D images and video content. The RNN Generator creates individuals mapped from a latent space while the GAN Discriminator evaluates them based on the true data distribution. The performance of the Deep Learning Generative Adversarial RNN has been assessed against several input vectors with different dimensions, in addition to 1D functions and 2D images. The presented results are successful: the learning objective of the RNN Generator creates tradeable replicas at low error, whereas the RNN Discriminator learning target identifies unfit individuals.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002745",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Crossover",
      "Deep learning",
      "Detector",
      "Discriminator",
      "Generative grammar",
      "Generator (circuit theory)",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Recurrent neural network",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Serrano",
        "given_name": "Will"
      }
    ]
  },
  {
    "title": "Analytical interpretation of the gap of CNN’s cognition between SAR and optical target recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.037",
    "abstract": "Synthetic aperture radar (SAR) automatic target recognition (ATR) is a crucial technique utilized in various scenarios of geoscience and remote sensing. Despite the remarkable success of convolutional neural networks (CNNs) in optical vision tasks, the application of CNNs in SAR ATR is still a challenging area due to the significant differences in the imaging mechanisms of SAR and optical images. This paper analytically addresses the cognitive gap of CNNs between optical and SAR images by leveraging multi-order interactions to measure their representation capacity. Furthermore, we propose a subjective evaluation strategy to compare human interactions with those of CNNs. Our findings reveal that CNNs operate differently for optical and SAR images. Specifically, for SAR images, CNNs’ representation capacity is comparable to that of humans, as they can encode intermediate interactions better than simple and complex ones. In contrast, for optical images, CNNs excel at encoding simple and complex interactions, but not intermediate interactions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003489",
    "keywords": [
      "Artificial intelligence",
      "Automatic target recognition",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Contrast (vision)",
      "Convolutional neural network",
      "ENCODE",
      "Encoding (memory)",
      "Gene",
      "Law",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Synthetic aperture radar"
    ],
    "authors": [
      {
        "surname": "Feng",
        "given_name": "Zhenpeng"
      },
      {
        "surname": "Ji",
        "given_name": "Hongbing"
      },
      {
        "surname": "Daković",
        "given_name": "Miloš"
      },
      {
        "surname": "Zhu",
        "given_name": "Mingzhe"
      },
      {
        "surname": "Stanković",
        "given_name": "Ljubiša"
      }
    ]
  },
  {
    "title": "Variational gated autoencoder-based feature extraction model for inferring disease-miRNA associations based on multiview features",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.052",
    "abstract": "MicroRNAs (miRNA) play critical roles in diverse biological processes of diseases. Inferring potential disease-miRNA associations enable us to better understand the development and diagnosis of complex human diseases via computational algorithms. The work presents a variational gated autoencoder-based feature extraction model to extract complex contextual features for inferring potential disease-miRNA associations. Specifically, our model fuses three different similarities of miRNAs into a comprehensive miRNA network and then combines two various similarities of diseases into a comprehensive disease network, respectively. Then, a novel graph autoencoder is designed to extract multilevel representations based on variational gate mechanisms from heterogeneous networks of miRNAs and diseases. Finally, a gate-based association predictor is devised to combine multiscale representations of miRNAs and diseases via a novel contrastive cross-entropy function, and then infer disease-miRNA associations. Experimental results indicate that our proposed model achieves remarkable association prediction performance, proving the efficacy of the variational gate mechanism and contrastive cross-entropy loss for inferring disease-miRNA associations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002964",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Biochemistry",
      "Biology",
      "Complex network",
      "Computer science",
      "Entropy (arrow of time)",
      "Feature extraction",
      "Gene",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "World Wide Web",
      "microRNA"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Yanbu"
      },
      {
        "surname": "Zhou",
        "given_name": "Dongming"
      },
      {
        "surname": "Ruan",
        "given_name": "Xiaoli"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Reinforced mixture learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.018",
    "abstract": "In this article, we formulate the standard mixture learning problem as a Markov Decision Process (MDP). We theoretically show that the objective value of the MDP is equivalent to the log-likelihood of the observed data with a slightly different parameter space constrained by the policy. Different from some classic mixture learning methods such as Expectation–Maximization (EM) algorithm, the proposed reinforced algorithm requires no distribution assumptions and can handle the non-convex clustered data by constructing a model-free reward to evaluate the mixture assignment based on the spectral graph theory and Linear Discriminant Analysis (LDA). Extensive experiments on both synthetic and real examples demonstrate that the proposed method is comparable with the EM algorithm when the Gaussian mixture assumption is satisfied, and significantly outperforms it and other clustering methods in most scenarios when the model is misspecified. A Python implementation of our proposed method is available at https://github.com/leyuanheart/Reinforced-Mixture-Learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002629",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Expectation–maximization algorithm",
      "Mathematical optimization",
      "Mathematics",
      "Maximum likelihood",
      "Mixture model",
      "Operating system",
      "Pattern recognition (psychology)",
      "Python (programming language)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Le",
        "given_name": "Yuan"
      },
      {
        "surname": "Zhou",
        "given_name": "Fan"
      },
      {
        "surname": "Bai",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "High speed human action recognition using a photonic reservoir computer",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.014",
    "abstract": "The recognition of human actions in videos is one of the most active research fields in computer vision. The canonical approach consists in a more or less complex preprocessing stages of the raw video data, followed by a relatively simple classification algorithm. Here we address recognition of human actions using the reservoir computing algorithm, which allows us to focus on the classifier stage. We introduce a new training method for the reservoir computer, based on “Timesteps Of Interest”, which combines in a simple way short and long time scales. We study the performance of this algorithm using both numerical simulations and a photonic implementation based on a single non-linear node and a delay line on the well known KTH dataset. We solve the task with high accuracy and speed, to the point of allowing for processing multiple video streams in real time. The present work is thus an important step towards developing efficient dedicated hardware for video processing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003258",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Computer science",
      "Computer vision",
      "Focus (optics)",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Preprocessor",
      "Recurrent neural network",
      "Reservoir computing"
    ],
    "authors": [
      {
        "surname": "Picco",
        "given_name": "Enrico"
      },
      {
        "surname": "Antonik",
        "given_name": "Piotr"
      },
      {
        "surname": "Massar",
        "given_name": "Serge"
      }
    ]
  },
  {
    "title": "Preassigned-time projective synchronization of delayed fully quaternion-valued discontinuous neural networks with parameter uncertainties",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.017",
    "abstract": "This paper concerns with the preassigned-time projective synchronization issue for delayed fully quaternion-valued discontinuous neural networks involving parameter uncertainties through the non-separation method. Above all, based on the existing works, a new preassigned-time stability theorem is established. Subsequently, to realize the control goals, two types of novel and simple chattering-free quaternion controllers are designed, one without the power-law term and the other with a hyperbolic-tangent function. They are different from the existing common power-law controller and exponential controller. Thirdly, under the Filippov discontinuity theories and with the aid of quaternion inequality techniques, some novel succinct sufficient criteria are obtained to ensure the addressed systems to achieve the preassigned-time synchronization by using the preassigned-time stability theory. The preassigned settling time is free from any parameter and any initial value of the system, and can be preset according to the actual task demands. Particularly, unlike the existing results, the proposed control methods can effectively avoid the chattering phenomenon, and the time delay part is removed for simplicity. Additionally, the projection coefficient is generic quaternion-valued instead of real-valued or complex-valued, and some of the previous relevant results are extended. Lastly, numerical simulations are reported to substantiate the effectiveness of the control strategies, the merits of preassigned settling time, and the correctness of the acquired results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003283",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Correctness",
      "Engineering",
      "Geometry",
      "Mathematics",
      "Quaternion",
      "Settling time",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Pu",
        "given_name": "Hao"
      },
      {
        "surname": "Li",
        "given_name": "Fengjun"
      },
      {
        "surname": "Wang",
        "given_name": "Qingyun"
      },
      {
        "surname": "Li",
        "given_name": "Pengzhen"
      }
    ]
  },
  {
    "title": "SNR: Symbolic network-based rectifiable learning framework for symbolic regression",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.046",
    "abstract": "Symbolic regression (SR) can be utilized to unveil the underlying mathematical expressions that describe a given set of observed data. At present, SR can be categorized into two methods: learning-from-scratch and learning-with-experience. Compared to learning-from-scratch, learning-with-experience yields results that are comparable to those of several benchmarks and incurs significantly lower time costs for obtaining expressions. However, the learning-with-experience model performs poorly in terms of unseen data distributions and lacks a rectification tool, apart from constant optimization, which exhibits limited performance. In this study, we propose a Symbolic Network-based Rectifiable Learning Framework (SNR) that possesses the ability to correct errors. SNR adopts Symbolic Network (SymNet) to represent an expression, and the encoding of SymNet is designed to provide supervised information, with numerous self-generated expressions, to train a policy net (PolicyNet). The training of PolicyNet can offer prior knowledge to guide effective searches. Subsequently, the incorrectly predicted expressions are revised via a rectification mechanism. This rectification mechanism endows SNR with broader applicability. Experimental results demonstrate that our proposed method achieves the highest averaged coefficient of determination on self-generated datasets when compared with other state-of-the-art methods and yields more accurate results in public datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003568",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Genetic programming",
      "Machine learning",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Physics",
      "Power (physics)",
      "Programming language",
      "Quantum mechanics",
      "Rectification",
      "Regression",
      "Scratch",
      "Set (abstract data type)",
      "Statistics",
      "Symbolic regression"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Jingyi"
      },
      {
        "surname": "Li",
        "given_name": "Weijun"
      },
      {
        "surname": "Yu",
        "given_name": "Lina"
      },
      {
        "surname": "Wu",
        "given_name": "Min"
      },
      {
        "surname": "Sun",
        "given_name": "Linjun"
      },
      {
        "surname": "Li",
        "given_name": "Wenqiang"
      },
      {
        "surname": "Li",
        "given_name": "Yanjie"
      }
    ]
  },
  {
    "title": "Stable invariant models via Koopman spectra",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.040",
    "abstract": "Weight-tied models have attracted attention in the modern development of neural networks. The deep equilibrium model (DEQ) represents infinitely deep neural networks with weight-tying, and recent studies have shown the potential of this type of approach. DEQs are needed to iteratively solve root-finding problems in training and are built on the assumption that the underlying dynamics determined by the models converge to a fixed point. In this paper, we present the stable invariant model (SIM), a new class of deep models that in principle approximates DEQs under stability and extends the dynamics to more general ones converging to an invariant set (not restricted in a fixed point). The key ingredient in deriving SIMs is a representation of the dynamics with the spectra of the Koopman and Perron–Frobenius operators. This perspective approximately reveals stable dynamics with DEQs and then derives two variants of SIMs. We also propose an implementation of SIMs that can be learned in the same way as feedforward models. We illustrate the empirical performance of SIMs with experiments and demonstrate that SIMs achieve comparative or superior performance against DEQs in several learning tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002848",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Differential equation",
      "Equilibrium point",
      "Fixed point",
      "Invariant (physics)",
      "Law",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematical physics",
      "Mathematics",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Konishi",
        "given_name": "Takuya"
      },
      {
        "surname": "Kawahara",
        "given_name": "Yoshinobu"
      }
    ]
  },
  {
    "title": "A regularization perspective based theoretical analysis for adversarial robustness of deep spiking neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.038",
    "abstract": "Spiking Neural Network (SNN) has been recognized as the third generation of neural networks. Conventionally, a SNN can be converted from a pre-trained Artificial Neural Network (ANN) with less computation and memory than training from scratch. But, these converted SNNs are vulnerable to adversarial attacks. Numerical experiments demonstrate that the SNN trained by optimizing the loss function will be more adversarial robust, but the theoretical analysis for the mechanism of robustness is lacking. In this paper, we provide a theoretical explanation by analyzing the expected risk function. Starting by modeling the stochastic process introduced by the Poisson encoder, we prove that there is a positive semidefinite regularizer. Perhaps surprisingly, this regularizer can make the gradients of the output with respect to input closer to zero, thus resulting in inherent robustness against adversarial attacks. Extensive experiments on the CIFAR10 and CIFAR100 datasets support our point of view. For example, we find that the sum of squares of the gradients of the converted SNNs is 13 ∼ 160 times that of the trained SNNs. And, the smaller the sum of the squares of the gradients, the smaller the degradation of accuracy under adversarial attack.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002824",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computation",
      "Computer science",
      "Gene",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Robustness (evolution)",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Hui"
      },
      {
        "surname": "Cheng",
        "given_name": "Jian"
      },
      {
        "surname": "Zhang",
        "given_name": "Jun"
      },
      {
        "surname": "Liu",
        "given_name": "Hongyi"
      },
      {
        "surname": "Wei",
        "given_name": "Zhihui"
      }
    ]
  },
  {
    "title": "MSCDA: Multi-level semantic-guided contrast improves unsupervised domain adaptation for breast MRI segmentation in small datasets",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.014",
    "abstract": "Deep learning (DL) applied to breast tissue segmentation in magnetic resonance imaging (MRI) has received increased attention in the last decade, however, the domain shift which arises from different vendors, acquisition protocols, and biological heterogeneity, remains an important but challenging obstacle on the path towards clinical implementation. In this paper, we propose a novel Multi-level Semantic-guided Contrastive Domain Adaptation (MSCDA) framework to address this issue in an unsupervised manner. Our approach incorporates self-training with contrastive learning to align feature representations between domains. In particular, we extend the contrastive loss by incorporating pixel-to-pixel, pixel-to-centroid, and centroid-to-centroid contrasts to better exploit the underlying semantic information of the image at different levels. To resolve the data imbalance problem, we utilize a category-wise cross-domain sampling strategy to sample anchors from target images and build a hybrid memory bank to store samples from source images. We have validated MSCDA with a challenging task of cross-domain breast MRI segmentation between datasets of healthy volunteers and invasive breast cancer patients. Extensive experiments show that MSCDA effectively improves the model’s feature alignment capabilities between domains, outperforming state-of-the-art methods. Furthermore, the framework is shown to be label-efficient, achieving good performance with a smaller source dataset. The code is publicly available at https://github.com/ShengKuangCN/MSCDA.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002587",
    "keywords": [
      "Artificial intelligence",
      "Centroid",
      "Code (set theory)",
      "Computer science",
      "Computer security",
      "Domain (mathematical analysis)",
      "Exploit",
      "Feature (linguistics)",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pixel",
      "Programming language",
      "Segmentation",
      "Set (abstract data type)",
      "Source code"
    ],
    "authors": [
      {
        "surname": "Kuang",
        "given_name": "Sheng"
      },
      {
        "surname": "Woodruff",
        "given_name": "Henry C."
      },
      {
        "surname": "Granzier",
        "given_name": "Renee"
      },
      {
        "surname": "van Nijnatten",
        "given_name": "Thiemo J.A."
      },
      {
        "surname": "Lobbes",
        "given_name": "Marc B.I."
      },
      {
        "surname": "Smidt",
        "given_name": "Marjolein L."
      },
      {
        "surname": "Lambin",
        "given_name": "Philippe"
      },
      {
        "surname": "Mehrkanoon",
        "given_name": "Siamak"
      }
    ]
  },
  {
    "title": "A novel framework of prescribed time/fixed time/finite time stochastic synchronization control of neural networks and its application in image encryption",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.023",
    "abstract": "In this paper, we investigate a novel framework for achieving prescribed-time (PAT), fixed-time (FXT) and finite-time (FNT) stochastic synchronization control of semi-Markov switching quaternion-valued neural networks (SMS-QVNNs), where the setting time (ST) of PAT/FXT/FNT stochastic synchronization control is effectively preassigned beforehand and estimated. Different from the existing frameworks of PAT/FXT/FNT control and PAT/FXT control (where PAT control is deeply dependent on FXT control, meaning that if the FXT control task is removed, it is impossible to implement the PAT control task), and different from the existing frameworks of PAT control (where a time-varying control gain such as μ ( t ) = T / ( T − t ) with t ∈ [ 0 , T ) was employed, leading to an unbounded control gain as t → T − from the initial time to prescribed time T ), the investigated framework is only built on a control strategy, which can accomplish its three control tasks (PAT/FXT/FNT control), and the control gains are bounded even though time t tends to the prescribed time T . Four numerical examples and an application of image encryption/decryption are given to illustrate the feasibility of our proposed framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003349",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Encryption",
      "Image (mathematics)",
      "Mathematics",
      "Statistics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Xin"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Zhou",
        "given_name": "Xianghui"
      },
      {
        "surname": "Liu",
        "given_name": "Ying"
      },
      {
        "surname": "Yan",
        "given_name": "Yaoxi"
      },
      {
        "surname": "Wang",
        "given_name": "Jiangtao"
      }
    ]
  },
  {
    "title": "Prediction of common labels for universal domain adaptation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.057",
    "abstract": "Universal domain adaptation (UniDA) is an unsupervised domain adaptation that selectively transfers the knowledge between different domains containing different label sets. However, the existing methods do not predict the common labels of different domains and manually set a threshold to discriminate private samples, so they rely on the target domain to finely select the threshold and ignore the problem of negative transfer. In this paper, to address the above problems, we propose a novel classification model named Prediction of Common Labels (PCL) for UniDA, in which the common labels are predicted by Category Separation via Clustering (CSC). It is noted that we devise a new evaluation metric called category separation accuracy to measure the performance of category separation. To weaken negative transfer, we select source samples by the predicted common labels to fine-tune model for better domain alignment. In the test process, the target samples are discriminated by the predicted common labels and the results of clustering. Experimental results on three widely used benchmark datasets indicate the effectiveness of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003015",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Economics",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Metric (unit)",
      "Operating system",
      "Operations management",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Process (computing)",
      "Programming language",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Shan",
        "given_name": "Xinxin"
      },
      {
        "surname": "Ma",
        "given_name": "Tai"
      },
      {
        "surname": "Wen",
        "given_name": "Ying"
      }
    ]
  },
  {
    "title": "Differentiating brain states via multi-clip random fragment strategy-based interactive bidirectional recurrent neural network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.040",
    "abstract": "EEG is widely adopted to study the brain and brain computer interface (BCI) for its non-invasiveness and low costs. Specifically EEG can be applied to differentiate brain states, which is important for better understanding the working mechanisms of the brain. Recurrent neural network (RNN)-based learning strategy has been widely utilized to differentiate brain states, because its optimization architectures improve the classification performance for differentiating brain states at the group level. However, present classification performance is still far from satisfactory. We have identified two major focal points for improvements: one is about organizing the input EEG signals, and the other is related to the design of the RNN architecture. To optimize the above-mentioned issues and achieve better brain state classification performance, we propose a novel multi-clip random fragment strategy-based interactive bidirectional recurrent neural network (McRFS-IBiRNN) model in this work. This model has two advantages over previous methods. First, the McRFS component is designed to re-organize the input EEG signals to make them more suitable for the RNN architecture. Second, the IBiRNN component is an innovative design to model the RNN layers with interaction connections to enhance the fusion of bidirectional features. By adopting the proposed model, promising brain states classification performances are obtained. For example, 96.97% and 99.34% of individual and group level four-category classification accuracies are successfully obtained on the EEG motor/imagery dataset, respectively. A 99.01% accuracy can be observed for four-category classification tasks with new subjects not seen before, which demonstrates the generalization of our proposed method. Compared with existing methods, our model outperforms them with superior results. Overall, the proposed McRFS-IBiRNN model demonstrates great superiority in differentiating brain states on EEG signals",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003520",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Brain–computer interface",
      "Bubble",
      "Component (thermodynamics)",
      "Computer science",
      "Electroencephalography",
      "Interface (matter)",
      "Machine learning",
      "Maximum bubble pressure method",
      "Neuroscience",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Physics",
      "Recurrent neural network",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Shu"
      },
      {
        "surname": "Shi",
        "given_name": "Enze"
      },
      {
        "surname": "Wu",
        "given_name": "Lin"
      },
      {
        "surname": "Wang",
        "given_name": "Ruoyang"
      },
      {
        "surname": "Yu",
        "given_name": "Sigang"
      },
      {
        "surname": "Liu",
        "given_name": "Zhengliang"
      },
      {
        "surname": "Xu",
        "given_name": "Shaochen"
      },
      {
        "surname": "Liu",
        "given_name": "Tianming"
      },
      {
        "surname": "Zhao",
        "given_name": "Shijie"
      }
    ]
  },
  {
    "title": "3D graph neural network with few-shot learning for predicting drug–drug interactions in scaffold-based cold start scenario",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.039",
    "abstract": "Understanding drug–drug interactions (DDI) of new drugs is critical for minimizing unexpected adverse drug reactions. The modeling of new drugs is called a cold start scenario. In this scenario, Only a few structural information or physicochemical information about new drug is available. The 3D conformation of drug molecules usually plays a crucial role in chemical properties compared to the 2D structure. 3D graph network with few-shot learning is a promising solution. However, the 3D heterogeneity of drug molecules and the discretization of atomic distributions lead to spatial confusion in few-shot learning. Here, we propose a 3D graph neural network with few-shot learning, Meta3D-DDI, to predict DDI events in cold start scenario. The 3DGNN ensures rotation and translation invariance by calculating atomic pairwise distances, and incorporates 3D structure and distance information in the information aggregation stage. The continuous filter interaction module can continuously simulate the filter to obtain the interaction between the target atom and other atoms. Meta3D-DDI further develops a FSL strategy based on bilevel optimization to transfer meta-knowledge for DDI prediction tasks from existing drugs to new drugs. In addition, the existing cold start setting may cause the scaffold structure information in the training set to leak into the test set. We design scaffold-based cold start scenario to ensure that the drug scaffolds in the training set and test set do not overlap. The extensive experiments demonstrate that our architecture achieves the SOTA performance for DDI prediction under scaffold-based cold start scenario on two real-world datasets. The visual experiment shows that Meta3D-DDI significantly improves the learning for DDI prediction of new drugs. We also demonstrate how Meta3D-DDI can reduce the amount of data required to make meaningful DDI predictions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002836",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Database",
      "Deep learning",
      "Drug",
      "Graph",
      "Machine learning",
      "Pharmacology",
      "Scaffold",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Lv",
        "given_name": "Qiujie"
      },
      {
        "surname": "Zhou",
        "given_name": "Jun"
      },
      {
        "surname": "Yang",
        "given_name": "Ziduo"
      },
      {
        "surname": "He",
        "given_name": "Haohuai"
      },
      {
        "surname": "Chen",
        "given_name": "Calvin Yu-Chian"
      }
    ]
  },
  {
    "title": "A continuation method for image registration based on dynamic adaptive kernel",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.025",
    "abstract": "Image registration is a fundamental problem in computer vision and robotics. Recently, learning-based image registration methods have made great progress. However, these methods are sensitive to abnormal transformation and have insufficient robustness, which leads to more mismatched points in the actual environment. In this paper, we propose a new registration framework based on ensemble learning and dynamic adaptive kernel. Specifically, we first use a dynamic adaptive kernel to extract deep features at the coarse level to guide fine-level registration. Then we added an adaptive feature pyramid network based on the integrated learning principle to realize the fine-level feature extraction. Through different scale, receptive fields, not only the local geometric information of each point is considered, but also its low texture information at the pixel level is considered. According to the actual registration environment, fine features are adaptively obtained to reduce the sensitivity of the model to abnormal transformation. We use the global receptive field provided in the transformer to obtain feature descriptors based on these two levels. In addition, we use the cosine loss directly defined on the corresponding relationship to train the network and balance the samples, to achieve feature point registration based on the corresponding relationship. Extensive experiments on object-level and scene-level datasets show that the proposed method outperforms existing state-of-the-art techniques by a large margin. More critically, it has the best generalization ability in unknown scenes with different sensor modes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003362",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Feature extraction",
      "Gene",
      "Geometric transformation",
      "Image (mathematics)",
      "Image registration",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Transformation geometry"
    ],
    "authors": [
      {
        "surname": "Ma",
        "given_name": "Yuandong"
      },
      {
        "surname": "Wang",
        "given_name": "Boyuan"
      },
      {
        "surname": "Lin",
        "given_name": "Hezheng"
      },
      {
        "surname": "Liu",
        "given_name": "Chun"
      },
      {
        "surname": "Hu",
        "given_name": "Mengjie"
      },
      {
        "surname": "Song",
        "given_name": "Qing"
      }
    ]
  },
  {
    "title": "Graph convolutional network with tree-guided anisotropic message passing",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.034",
    "abstract": "Graph Convolutional Networks (GCNs) with naive message passing mechanisms have limited performance due to the isotropic aggregation strategy. To remedy this drawback, some recent works focus on how to design anisotropic aggregation strategies with tricks on feature mapping or structure mining. However, these models still suffer from the low ability of expressiveness and long-range modeling for the needs of high performance in practice. To this end, this paper proposes a tree-guided anisotropic GCN, which applies an anisotropic aggregation strategy with competitive expressiveness and a large receptive field. Specifically, the anisotropic aggregation is decoupled into two stages. The first stage is to establish the path of the message passing on a tree-like hypergraph consisting of substructures. The second one is to aggregate the messages with constrained intensities by employing an effective gating mechanism. In addition, a novel anisotropic readout mechanism is constructed to generate representative and discriminative graph-level features for downstream tasks. Our model outperforms baseline methods and recent works on several synthetic benchmarks and datasets from different real-world tasks. In addition, extensive ablation studies and theoretical analyses indicate the effectiveness of our proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003416",
    "keywords": [
      "Aggregate (composite)",
      "Algorithm",
      "Artificial intelligence",
      "Binary tree",
      "Composite material",
      "Computer science",
      "Discrete mathematics",
      "Discriminative model",
      "Distributed computing",
      "Feature (linguistics)",
      "Focus (optics)",
      "Graph",
      "Hypergraph",
      "Linguistics",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Message passing",
      "Optics",
      "Philosophy",
      "Physics",
      "Theoretical computer science",
      "Tree (set theory)",
      "Tree structure"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Ruixiang"
      },
      {
        "surname": "Wang",
        "given_name": "Yuhu"
      },
      {
        "surname": "Zhang",
        "given_name": "Chunxia"
      },
      {
        "surname": "Xiang",
        "given_name": "Shiming"
      },
      {
        "surname": "Pan",
        "given_name": "Chunhong"
      }
    ]
  },
  {
    "title": "A reliable anchor regenerative-based transformer model for x-small and dense objects recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.020",
    "abstract": "The past decade has witnessed significant progress in detecting objects by using enormous features of deep learning models. But, most of the existing models are unable to detect x-small and dense objects, due to the futility of feature extraction, and substantial misalignments between anchor boxes and axis-aligned convolution features, which leads to the discrepancy between the categorization score and positioning accuracy. This paper introduces an anchor regenerative-based transformer module in a feature refinement network to solve this problem. The anchor-regenerative module can generate anchor scales based on the semantic statistics of the objects present in the image, which avoids the inconsistency between the anchor boxes and axis-aligned convolution features. Whereas, the Multi-Head-Self-Attention (MHSA) based transformer module extracts the in-depth information from the feature maps based on the query, key, and value parameter information. This proposed model is experimentally verified on the VisDrone, VOC, and SKU-110K datasets. This model generates different anchor scales for these three datasets and achieves higher mAP, precision, and recall values on three datasets. These tested results prove that the suggested model has outstanding achievements compared with existing models in detecting x-small objects as well as dense objects. Finally, we evaluated the performance of these three datasets by using accuracy, kappa coefficient, and ROC metrics. These evaluated metrics demonstrate that our model is a good fit for VOC, and SKU-110K datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003313",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Categorization",
      "Computer science",
      "Convolution (computer science)",
      "Data mining",
      "Feature extraction",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Vasanthi",
        "given_name": "Ponduri"
      },
      {
        "surname": "Mohan",
        "given_name": "Laavanya"
      }
    ]
  },
  {
    "title": "Discriminative analysis dictionary learning with adaptively ordinal locality preserving",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.022",
    "abstract": "Dictionary learning has found broad applications in signal and image processing. By adding constraints to the traditional dictionary learning model, dictionaries with discriminative capability can be obtained which can deal with the task of image classification. The Discriminative Convolutional Analysis Dictionary Learning (DCADL) algorithm proposed recently has achieved promising results with low computational complexity. However, DCADL is still limited in classification performance because of the lack of constraints on dictionary structures. To solve this problem, this study introduces an adaptively ordinal locality preserving (AOLP) term to the original model of DCADL to further improve the classification performance. With the AOLP term, the distance ranking in the neighborhood of each atom can be preserved, which can improve the discrimination of coding coefficients. In addition, a linear classifier for the classification of coding coefficients is trained along with the dictionary. A new method is designed specifically to solve the optimization problem corresponding to the proposed model. Experiments are performed on several commonly used datasets to show the promising results of the proposed algorithm in classification performance and computational efficiency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002666",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Classifier (UML)",
      "Coding (social sciences)",
      "Computational complexity theory",
      "Computer science",
      "Contextual image classification",
      "Dictionary learning",
      "Discriminative model",
      "Image (mathematics)",
      "K-SVD",
      "Linguistics",
      "Locality",
      "Machine learning",
      "Mathematics",
      "Neural coding",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Dong",
        "given_name": "Jing"
      },
      {
        "surname": "Wu",
        "given_name": "Kai"
      },
      {
        "surname": "Liu",
        "given_name": "Chang"
      },
      {
        "surname": "Mei",
        "given_name": "Xue"
      },
      {
        "surname": "Wang",
        "given_name": "Wenwu"
      }
    ]
  },
  {
    "title": "Cross-modal hashing with missing labels",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.035",
    "abstract": "Hashing-based cross-modal retrieval methods have become increasingly popular due to their advantages in storage and speed. While current methods have demonstrated impressive results, there are still several issues that have not been addressed. Specifically, many of these approaches assume that labels are perfectly assigned, despite the fact that in real-world scenarios, labels are often incomplete or partially missing. There are two reasons for this, as manual labeling can be a complex and time-consuming task, and annotators may only be interested in certain objects. As such, cross-modal retrieval with missing labels is a significant challenge that requires further attention. Moreover, the similarity between labels is frequently ignored, which is important for exploring the high-level semantics of labels. To address these limitations, we propose a novel method called Cross-Modal Hashing with Missing Labels (CMHML). Our method consists of several key components. First, we introduce Reliable Label Learning to preserve reliable information from the observed labels. Next, to infer the uncertain part of the predicted labels, we decompose the predicted labels into latent representations of labels and samples. The representation of samples is extracted from different modalities, which assists in inferring missing labels. We also propose Label Correlation Preservation to enhance the similarity between latent representations of labels. Hash codes are then learned from the representation of samples through Global Approximation Learning. We also construct a similarity matrix according to predicted labels and embed it into hash codes learning to explore the value of labels. Finally, we train linear classifiers to map original samples to a low-dimensional Hamming space. To evaluate the efficacy of CMHML, we conduct extensive experiments on four publicly available datasets. Our method is compared to other state-of-the-art methods, and the results demonstrate that our model performs competitively even when most labels are missing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002794",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Construct (python library)",
      "Hash function",
      "Image (mathematics)",
      "Information retrieval",
      "Key (lock)",
      "Law",
      "Machine learning",
      "Missing data",
      "Modal",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Polymer chemistry",
      "Programming language",
      "Representation (politics)",
      "Semantics (computer science)",
      "Similarity (geometry)"
    ],
    "authors": [
      {
        "surname": "Ni",
        "given_name": "Haomin"
      },
      {
        "surname": "Zhang",
        "given_name": "Jianjun"
      },
      {
        "surname": "Kang",
        "given_name": "Peipei"
      },
      {
        "surname": "Fang",
        "given_name": "Xiaozhao"
      },
      {
        "surname": "Sun",
        "given_name": "Weijun"
      },
      {
        "surname": "Xie",
        "given_name": "Shengli"
      },
      {
        "surname": "Han",
        "given_name": "Na"
      }
    ]
  },
  {
    "title": "A reliable anchor regenerative-based transformer model for x-small and dense objects recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.020",
    "abstract": "The past decade has witnessed significant progress in detecting objects by using enormous features of deep learning models. But, most of the existing models are unable to detect x-small and dense objects, due to the futility of feature extraction, and substantial misalignments between anchor boxes and axis-aligned convolution features, which leads to the discrepancy between the categorization score and positioning accuracy. This paper introduces an anchor regenerative-based transformer module in a feature refinement network to solve this problem. The anchor-regenerative module can generate anchor scales based on the semantic statistics of the objects present in the image, which avoids the inconsistency between the anchor boxes and axis-aligned convolution features. Whereas, the Multi-Head-Self-Attention (MHSA) based transformer module extracts the in-depth information from the feature maps based on the query, key, and value parameter information. This proposed model is experimentally verified on the VisDrone, VOC, and SKU-110K datasets. This model generates different anchor scales for these three datasets and achieves higher mAP, precision, and recall values on three datasets. These tested results prove that the suggested model has outstanding achievements compared with existing models in detecting x-small objects as well as dense objects. Finally, we evaluated the performance of these three datasets by using accuracy, kappa coefficient, and ROC metrics. These evaluated metrics demonstrate that our model is a good fit for VOC, and SKU-110K datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003313",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Categorization",
      "Computer science",
      "Convolution (computer science)",
      "Data mining",
      "Feature extraction",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Vasanthi",
        "given_name": "Ponduri"
      },
      {
        "surname": "Mohan",
        "given_name": "Laavanya"
      }
    ]
  },
  {
    "title": "Lightweight image de-snowing: A better trade-off between network capacity and performance",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.029",
    "abstract": "The single image de-snowing task is an essential topic in computer vision, as images captured on snowy days degrade the performance of current vision-based intelligent systems. Existing methods build complex network structures with numerous parameters to pursue continuous performance improvement. Nonetheless, they generally ignore the negative impact of large memory consumption in real applications. This paper aims to address the above problem by making a trade-off between network capacity and performance. We propose two novel networks suitable for different application scenarios. For devices with small memory and requiring fast inference speed, we propose an extremely lightweight recursive network (XLRNet). XLRNet is constructed by a single recursive strategy and two novel lightweight modules. For devices with large memory and pursuing better de-snowing performance, we propose a coupled lightweight dual recursive network (CLDRNet). CLDRNet cascades two XLRNets by a novel dual recursive strategy and a novel dual coupled LSTM module (DC-LSTM). Extensive experiments demonstrate the effectiveness and superiority of our two models on three synthetic datasets and real-world datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003404",
    "keywords": [
      "Art",
      "Artificial intelligence",
      "Computer engineering",
      "Computer science",
      "Dual (grammatical number)",
      "Economics",
      "Image (mathematics)",
      "Inference",
      "Literature",
      "Machine learning",
      "Management",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Zheng"
      },
      {
        "surname": "Sun",
        "given_name": "Yiwen"
      },
      {
        "surname": "Bi",
        "given_name": "Xiaojun"
      },
      {
        "surname": "Yue",
        "given_name": "Jianyu"
      }
    ]
  },
  {
    "title": "Observer-based state estimation for discrete-time semi-Markovian jump neural networks with round-robin protocol against cyber attacks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.046",
    "abstract": "This paper investigates an observer-based state estimation issue for discrete-time semi-Markovian jump neural networks with Round-Robin protocol and cyber attacks. In order to avoid the network congestion and save the communication resources, the Round-Robin protocol is used to schedule the data transmissions over the networks. Specifically, the cyber attacks are modeled as a set of random variables satisfying the Bernoulli distribution. On the basis of the Lyapunov functional and the discrete Wirtinger-based inequality technique, some sufficient conditions are established to guarantee the dissipativity performance and mean square exponential stability of the argument system. In order to compute the estimator gain parameters, a linear matrix inequality approach is utilized. Finally, two illustrative examples are provided to demonstrate the effectiveness of the proposed state estimation algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002903",
    "keywords": [
      "Aerospace engineering",
      "Algorithm",
      "Alternative medicine",
      "Artificial intelligence",
      "Artificial neural network",
      "Bernoulli's principle",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Engineering",
      "Estimator",
      "Jump",
      "Mathematical optimization",
      "Mathematics",
      "Medicine",
      "Observer (physics)",
      "Operating system",
      "Pathology",
      "Physics",
      "Protocol (science)",
      "Quantum mechanics",
      "Schedule",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Sakthivel",
        "given_name": "Ramalingam"
      },
      {
        "surname": "Kwon",
        "given_name": "Oh-Min"
      },
      {
        "surname": "Choi",
        "given_name": "Seong-Gon"
      },
      {
        "surname": "Sakthivel",
        "given_name": "Rathinasamy"
      }
    ]
  },
  {
    "title": "Adversarial feature hybrid framework for steganography with shifted window local loss",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.053",
    "abstract": "Image steganography is a long-standing image security problem that aims at hiding information in cover images. In recent years, the application of deep learning to steganography has the tendency to outperform traditional methods. However, the vigorous development of CNN-based steganalyzers still have a serious threat to steganography methods. To address this gap, we present an end-to-end adversarial steganography framework based on CNN and Transformer learned by shifted window local loss, called StegoFormer, which contains Encoder, Decoder, and Discriminator. Encoder is a hybrid model based on U-shaped network and Transformer block, which effectively integrates high-resolution spatial features and global self-attention features. In particular, Shuffle Linear layer is suggested, which can enhance the linear layer’s competence to extract local features. Given the substantial error in the central patch of the stego image, we propose shifted window local loss learning to assist Encoder in generating accurate stego images via weighted local loss. Furthermore, Gaussian mask augmentation method is designed to augment data for Discriminator, which helps to improve the security of Encoder through adversarial training. Controlled experiments show that StegoFormer is superior to the existing advanced steganography methods in terms of anti-steganalysis ability, steganography effectiveness, and information restoration.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002976",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Computer science",
      "Embedding",
      "Feature (linguistics)",
      "Linguistics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Steganography",
      "Window (computing)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Zhengze"
      },
      {
        "surname": "Yang",
        "given_name": "Xiaoyuan"
      },
      {
        "surname": "Shen",
        "given_name": "Kangqing"
      },
      {
        "surname": "Jiang",
        "given_name": "Fazhen"
      },
      {
        "surname": "Jiang",
        "given_name": "Jin"
      },
      {
        "surname": "Ren",
        "given_name": "Huwei"
      },
      {
        "surname": "Li",
        "given_name": "Yixiao"
      }
    ]
  },
  {
    "title": "Domain-informed graph neural networks: A quantum chemistry case study",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.030",
    "abstract": "We explore different strategies to integrate prior domain knowledge into the design of graph neural networks (GNN). Our study is supported by a use-case of estimating the potential energy of chemical systems (molecules and crystals) represented as graphs. We integrate two elements of domain knowledge into the design of the GNN to constrain and regularise its learning, towards higher accuracy and generalisation. First, knowledge on the existence of different types of relations/graph edges (e.g. chemical bonds in our case study) between nodes of the graph is used to modulate their interactions. We formulate and compare two strategies, namely specialised message production and specialised update of internal states. Second, knowledge of the relevance of some physical quantities is used to constrain the learnt features towards a higher physical relevance using a simple multi-task learning (MTL) paradigm. We explore the potential of MTL to better capture the underlying mechanisms behind the studied phenomenon. We demonstrate the general applicability of our two knowledge integrations by applying them to three architectures that rely on different mechanisms to propagate information between nodes and to update node states. Our implementations are made publicly available. To support these experiments, we release three new datasets of out-of-equilibrium molecules and crystals of various complexities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003428",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Domain (mathematical analysis)",
      "Domain knowledge",
      "Graph",
      "Implementation",
      "Law",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Molecule",
      "Organic chemistry",
      "Political science",
      "Programming language",
      "Quantum chemical",
      "Relevance (law)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Morgan",
        "given_name": "Jay Paul"
      },
      {
        "surname": "Paiement",
        "given_name": "Adeline"
      },
      {
        "surname": "Klinke",
        "given_name": "Christian"
      }
    ]
  },
  {
    "title": "Contrastive encoder pre-training-based clustered federated learning for heterogeneous data",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.010",
    "abstract": "Federated learning (FL) is a promising approach that enables distributed clients to collaboratively train a global model while preserving their data privacy. However, FL often suffers from data heterogeneity problems, which can significantly affect its performance. To address this, clustered federated learning (CFL) has been proposed to construct personalized models for different client clusters. One effective client clustering strategy is to allow clients to choose their own local models from a model pool based on their performance. However, without pre-trained model parameters, such a strategy is prone to clustering failure, in which all clients choose the same model. Unfortunately, collecting a large amount of labeled data for pre-training can be costly and impractical in distributed environments. To overcome this challenge, we leverage self-supervised contrastive learning to exploit unlabeled data for the pre-training of FL systems. Together, self-supervised pre-training and client clustering can be crucial components for tackling the data heterogeneity issues of FL. Leveraging these two crucial strategies, we propose contrastive pre-training-based clustered federated learning (CP-CFL) to improve the model convergence and overall performance of FL systems. In this work, we demonstrate the effectiveness of CP-CFL through extensive experiments in heterogeneous FL settings, and present various interesting observations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003192",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Computer security",
      "Construct (python library)",
      "Data mining",
      "Encoder",
      "Exploit",
      "Federated learning",
      "Leverage (statistics)",
      "Machine learning",
      "Operating system",
      "Programming language"
    ],
    "authors": [
      {
        "surname": "Tun",
        "given_name": "Ye Lin"
      },
      {
        "surname": "Nguyen",
        "given_name": "Minh N.H."
      },
      {
        "surname": "Thwal",
        "given_name": "Chu Myaet"
      },
      {
        "surname": "Choi",
        "given_name": "Jinwoo"
      },
      {
        "surname": "Hong",
        "given_name": "Choong Seon"
      }
    ]
  },
  {
    "title": "Stereoscopic scalable quantum convolutional neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.027",
    "abstract": "As the noisy intermediate-scale quantum (NISQ) era has begun, a quantum neural network (QNN) is definitely a promising solution to many problems that classical neural networks cannot solve. In addition, a quantum convolutional neural network (QCNN) is now receiving a lot of attention because it can process high dimensional inputs comparing to QNN. However, due to the nature of quantum computing, it is difficult to scale up the QCNN to extract a sufficient number of features due to barren plateaus. This is especially challenging in classification operations with high-dimensional data input. However, due to the nature of quantum computing, it is difficult to scale up the QCNN to extract a sufficient number of features due to barren plateaus. This is especially challenging in classification operations with high dimensional data input. Motivated by this, a novel stereoscopic 3D scalable QCNN (sQCNN-3D) is proposed for point cloud data processing in classification applications. Furthermore, reverse fidelity training (RF-Train) is additionally considered on top of sQCNN-3D for diversifying features with a limited number of qubits using the fidelity of quantum computing. Our data-intensive performance evaluation verifies that the proposed algorithm achieves desired performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003386",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Database",
      "Deep learning",
      "Physics",
      "Quantum",
      "Quantum computer",
      "Quantum mechanics",
      "Qubit",
      "Scalability",
      "Scale (ratio)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Baek",
        "given_name": "Hankyul"
      },
      {
        "surname": "Yun",
        "given_name": "Won Joon"
      },
      {
        "surname": "Park",
        "given_name": "Soohyun"
      },
      {
        "surname": "Kim",
        "given_name": "Joongheon"
      }
    ]
  },
  {
    "title": "Mitigate forgetting in few-shot class-incremental learning using different image views",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.043",
    "abstract": "In the few-shot class incremental learning (FSCIL) setting, new classes with few training examples become available incrementally, and deep learning models suffer from catastrophic forgetting of the previous classes when trained on new classes. Data augmentation techniques are generally used to increase the training data and improve the model performance. In this work, we demonstrate that differently augmented views of the same image obtained by applying data augmentations may not necessarily activate the same set of neurons in the model. Therefore, the information gained by a model regarding a class, when trained using data augmentation, may not necessarily be stored in the same set of neurons in the model. Consequently, during incremental training, even if some of the model weights that store the previously seen class information for a particular view get overwritten, the information of the previous classes for the other views may still remain intact in the other model weights. Therefore, the impact of catastrophic forgetting on the model predictions is different for different data augmentations used during training. Based on this, we present an Augmentation-based Prediction Rectification (APR) approach to reduce the impact of catastrophic forgetting in the FSCIL setting. APR can also augment other FSCIL approaches and significantly improve their performance. We also propose a novel feature synthesis module (FSM) for synthesizing features relevant to the previously seen classes without requiring training data from these classes. FSM outperforms other generative approaches in this setting. We experimentally show that our approach outperforms other methods on benchmark datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003544",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Class (philosophy)",
      "Computer science",
      "Data set",
      "Feature (linguistics)",
      "Forgetting",
      "Generative grammar",
      "Generative model",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Pruning",
      "Set (abstract data type)",
      "Training set"
    ],
    "authors": [
      {
        "surname": "Mazumder",
        "given_name": "Pratik"
      },
      {
        "surname": "Singh",
        "given_name": "Pravendra"
      }
    ]
  },
  {
    "title": "TCGAN: Convolutional Generative Adversarial Network for time series classification and clustering",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.033",
    "abstract": "Recent works have demonstrated the superiority of supervised Convolutional Neural Networks (CNNs) in learning hierarchical representations from time series data for successful classification. These methods require sufficiently large labeled data for stable learning, however acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. Nonetheless, to our best knowledge, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. The above considerations inspire us to introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003453",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Cluster analysis",
      "Computer science",
      "Construct (python library)",
      "Convolutional neural network",
      "Detector",
      "Discriminator",
      "Feature learning",
      "Generative grammar",
      "Generator (circuit theory)",
      "Law",
      "Machine learning",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Physics",
      "Political science",
      "Politics",
      "Power (physics)",
      "Programming language",
      "Quantum mechanics",
      "Representation (politics)",
      "Series (stratigraphy)",
      "Supervised learning",
      "Telecommunications",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Fanling"
      },
      {
        "surname": "Deng",
        "given_name": "Yangdong"
      }
    ]
  },
  {
    "title": "Adaptive closed-loop paradigm of electrophysiology for neuron models",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.050",
    "abstract": "The traditional electrophysiological experiments based on an open-loop paradigm are relatively complicated and limited when facing an individual neuron with uncertain nonlinear factors. Emerging neural technologies enable tremendous growth in experimental data leading to the curse of high-dimensional data, which obstructs the mechanism exploration of spiking activities in the neurons. In this work, we propose an adaptive closed-loop electrophysiology simulation experimental paradigm based on a Radial Basis Function neural network and a highly nonlinear unscented Kalman filter. On account of the complex nonlinear dynamic characteristics of the real neurons, the proposed simulation experimental paradigm could fit the unknown neuron models with different channel parameters and different structures (i.e. single or multiple compartments), and further compute the injected stimulus in time according to the arbitrary desired spiking activities of the neurons. However, the hidden electrophysiological states of the neurons are difficult to be measured directly. Thus, an extra Unscented Kalman filter modular is incorporated in the closed-loop electrophysiology experimental paradigm. The numerical results and theoretical analyses demonstrate that the proposed adaptive closed-loop electrophysiology simulation experimental paradigm achieves desired spiking activities arbitrarily and the hidden dynamics of the neurons are visualized by the unscented Kalman filter modular. The proposed adaptive closed-loop simulation experimental paradigm can avoid the inefficiency of data at increasingly greater scales and enhance the scalability of electrophysiological experiments, thus speeding up the discovery cycle on neuroscience.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002940",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Electrophysiology",
      "Kalman filter",
      "Modular design",
      "Neuroscience",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Quantum mechanics",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Ming"
      },
      {
        "surname": "Wang",
        "given_name": "Jiang"
      },
      {
        "surname": "Li",
        "given_name": "Shanshan"
      },
      {
        "surname": "Wang",
        "given_name": "Kuanchuan"
      },
      {
        "surname": "Yue",
        "given_name": "Wei"
      },
      {
        "surname": "Liu",
        "given_name": "Chen"
      }
    ]
  },
  {
    "title": "Auditory perception architecture with spiking neural network and implementation on FPGA",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.026",
    "abstract": "Spike-based perception brings up a new research idea in the field of neuromorphic engineering. A high-performance biologically inspired flexible spiking neural network (SNN) architecture provides a novel method for the exploration of perception mechanisms and the development of neuromorphic computing systems . In this article, we present a biological-inspired spike-based SNN perception digital system that can realize robust perception. The system employs a fully paralleled pipeline scheme to improve the performance and accelerate the processing of feature extraction. An auditory perception system prototype is realized on ten Intel Cyclone field-programmable gate arrays, which can reach the maximum frequency of 107.28 MHz and the maximum throughput of 5364 Mbps. Our design also achieves the power of 5. 148 W/system and energy efficiency of 845.85 μ J. Our auditory perception implementation is also proved to have superior robustness compared with other SNN systems. We use TIMIT digit speech in noise in accuracy testing. Result shows that it achieves up to 85.75% speech recognition accuracy under obvious noise conditions (signal-to-noise ratio of 20 dB) and maintain small accuracy attenuation with the decline of the signal-to-noise ratio. The overall performance of our proposed system outperforms the state-of-the-art perception system on SNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300271X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer hardware",
      "Computer science",
      "Field-programmable gate array",
      "Gene",
      "Image (mathematics)",
      "Neuromorphic engineering",
      "Neuroscience",
      "Noise (video)",
      "Perception",
      "Robustness (evolution)",
      "Speech recognition",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Deng",
        "given_name": "Bin"
      },
      {
        "surname": "Fan",
        "given_name": "Yanrong"
      },
      {
        "surname": "Wang",
        "given_name": "Jiang"
      },
      {
        "surname": "Yang",
        "given_name": "Shuangming"
      }
    ]
  },
  {
    "title": "Genetic data visualization using literature text-based neural networks: Examples associated with myocardial infarction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.015",
    "abstract": "Data visualization is critical to unraveling hidden information from complex and high-dimensional data. Interpretable visualization methods are critical, especially in the biology and medical fields, however, there are limited effective visualization methods for large genetic data. Current visualization methods are limited to lower-dimensional data and their performance suffers if there is missing data. In this study, we propose a literature-based visualization method to reduce high-dimensional data without compromising the dynamics of the single nucleotide polymorphisms (SNP) and textual interpretability. Our method is innovative because it is shown to (1) preserves both global and local structures of SNP while reducing the dimension of the data using literature text representations, and (2) enables interpretable visualizations using textual information. For performance evaluations, we examined the proposed approach to classify various classification categories including race, myocardial infarction event age groups, and sex using several machine learning models on the literature-derived SNP data. We used visualization approaches to examine clustering of data as well as quantitative performance metrics for the classification of the risk factors examined above. Our method outperformed all popular dimensionality reduction and visualization methods for both classification and visualization, and it is robust against missing and higher-dimensional data. Moreover, we found it feasible to incorporate both genetic and other risk information obtained from literature with our method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002599",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster analysis",
      "Computer science",
      "Curse of dimensionality",
      "Data mining",
      "Data visualization",
      "Dimensionality reduction",
      "Interpretability",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Moon",
        "given_name": "Jihye"
      },
      {
        "surname": "Posada-Quintero",
        "given_name": "Hugo F."
      },
      {
        "surname": "Chon",
        "given_name": "Ki H."
      }
    ]
  },
  {
    "title": "Topology identification for stochastic multi-layer networks via graph-theoretic method",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.036",
    "abstract": "The topological structures of multi-layer networks have an important influence on their dynamical properties, but in most cases the topological structures of networks are unknown. Hence, this paper pays attention to investigating topology identification problems for multi-layer networks with stochastic perturbations. Both intra-layer coupling and inter-layer coupling are incorporated into the research model. Based on the graph-theoretic method and Lyapunov function, topology identification criteria for stochastic multi-layer networks are obtained by designing a suitable adaptive controller. Furthermore, to estimate the time of identification, the finite-time identification criteria are obtained by finite-time control technique. Finally, double-layer Watts–Strogatz small-world networks are presented for numerical simulations to illustrate the correctness of theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002800",
    "keywords": [
      "Algorithm",
      "Biology",
      "Botany",
      "Chemistry",
      "Combinatorics",
      "Computer science",
      "Correctness",
      "Graph theory",
      "Identification (biology)",
      "Layer (electronics)",
      "Lyapunov function",
      "Mathematics",
      "Network topology",
      "Nonlinear system",
      "Operating system",
      "Organic chemistry",
      "Physics",
      "Quantum mechanics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Chunmei"
      },
      {
        "surname": "Li",
        "given_name": "Ran"
      },
      {
        "surname": "Zhu",
        "given_name": "Quanxin"
      },
      {
        "surname": "Xu",
        "given_name": "Qin"
      }
    ]
  },
  {
    "title": "Reachable set estimation and stochastic sampled-data exponential synchronization of Markovian jump neural networks with time-varying delays",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.034",
    "abstract": "In this paper, the stochastic sampled-data exponential synchronization problem for Markovian jump neural networks (MJNNs) with time-varying delays and the reachable set estimation (RSE) problem for MJNNs subjected to external disturbances are investigated. Firstly, assuming that two sampled-data periods satisfy Bernoulli distribution, and introducing two stochastic variables to represent the unknown input delay and the sampled-data period respectively, the mode-dependent two-sided loop-based Lyapunov functional (TSLBLF) is constructed, and the conditions for the mean square exponential stability of the error system are derived. Furthermore, a mode-dependent stochastic sampled-data controller is designed. Secondly, by analyzing the unit-energy bounded disturbance of MJNNs, a sufficient condition is proved that all states of MJNNs are confined to an ellipsoid under zero initial condition. In order to make the target ellipsoid contain the reachable set of the system, a stochastic sampled-data controller with RSE is designed. Eventually, two numerical examples and an analog resistor–capacitor network circuit are provided to show that the textual approach can obtain a larger sampled-data period than the existing approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002691",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Ellipsoid",
      "Exponential stability",
      "Machine learning",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Stochastic neural network",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Linqi"
      },
      {
        "surname": "Xia",
        "given_name": "Jianwei"
      },
      {
        "surname": "Park",
        "given_name": "Ju H."
      },
      {
        "surname": "Chen",
        "given_name": "Guoliang"
      },
      {
        "surname": "Xie",
        "given_name": "Xiangpeng"
      }
    ]
  },
  {
    "title": "Towards global neural network abstractions with locally-exact reconstruction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.002",
    "abstract": "Neural networks are a powerful class of non-linear functions. However, their black-box nature makes it difficult to explain their behaviour and certify their safety. Abstraction techniques address this challenge by transforming the neural network into a simpler, over-approximated function. Unfortunately, existing abstraction techniques are slack, which limits their applicability to small local regions of the input domain. In this paper, we propose Global Interval Neural Network Abstractions with Center-Exact Reconstruction (GINNACER). Our novel abstraction technique produces sound over-approximation bounds over the whole input domain while guaranteeing exact reconstructions for any given local input. Our experiments show that GINNACER is several orders of magnitude tighter than state-of-the-art global abstraction techniques, while being competitive with local ones.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003039",
    "keywords": [
      "Abstraction",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Black box",
      "Class (philosophy)",
      "Combinatorics",
      "Computer science",
      "Deep neural networks",
      "Domain (mathematical analysis)",
      "Epistemology",
      "Evolutionary biology",
      "Function (biology)",
      "Interval (graph theory)",
      "Mathematical analysis",
      "Mathematics",
      "Philosophy",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Manino",
        "given_name": "Edoardo"
      },
      {
        "surname": "Bessa",
        "given_name": "Iury"
      },
      {
        "surname": "Cordeiro",
        "given_name": "Lucas C."
      }
    ]
  },
  {
    "title": "An insect-inspired model facilitating autonomous navigation by incorporating goal approaching and collision avoidance",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.033",
    "abstract": "Being one of the most fundamental and crucial capacity of robots and animals, autonomous navigation that consists of goal approaching and collision avoidance enables completion of various tasks while traversing different environments. In light of the impressive navigational abilities of insects despite their tiny brains compared to mammals, the idea of seeking solutions from insects for the two key problems of navigation, i.e., goal approaching and collision avoidance, has fascinated researchers and engineers for many years. However, previous bio-inspired studies have focused on merely one of these two problems at one time. Insect-inspired navigation algorithms that synthetically incorporate both goal approaching and collision avoidance, and studies that investigate the interactions of these two mechanisms in the context of sensory–motor closed-loop autonomous navigation are lacking. To fill this gap, we propose an insect-inspired autonomous navigation algorithm to integrate the goal approaching mechanism as the global working memory inspired by the sweat bee’s path integration (PI) mechanism, and the collision avoidance model as the local immediate cue built upon the locust’s lobula giant movement detector (LGMD) model. The presented algorithm is utilized to drive agents to complete navigation task in a sensory–motor closed-loop manner within a bounded static or dynamic environment. Simulation results demonstrate that the synthetic algorithm is capable of guiding the agent to complete challenging navigation tasks in a robust and efficient way. This study takes the first tentative step to integrate the insect-like navigation mechanisms with different functionalities (i.e., global goal and local interrupt) into a coordinated control system that future research avenues could build upon.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002782",
    "keywords": [
      "Artificial intelligence",
      "Autonomous agent",
      "Collision",
      "Collision avoidance",
      "Computer science",
      "Computer security",
      "Simulation"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Xuelong"
      },
      {
        "surname": "Fu",
        "given_name": "Qinbing"
      },
      {
        "surname": "Peng",
        "given_name": "Jigen"
      },
      {
        "surname": "Yue",
        "given_name": "Shigang"
      }
    ]
  },
  {
    "title": "Spatial–temporal recurrent reinforcement learning for autonomous ships",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.015",
    "abstract": "This paper proposes a spatial–temporal recurrent neural network architecture for deep Q -networks that can be used to steer an autonomous ship. The network design makes it possible to handle an arbitrary number of surrounding target ships while offering robustness to partial observability. Furthermore, a state-of-the-art collision risk metric is proposed to enable an easier assessment of different situations by the agent. The COLREG rules of maritime traffic are explicitly considered in the design of the reward function. The final policy is validated on a custom set of newly created single-ship encounters called ‘Around the Clock’ problems and the commonly used Imazu (1987) problems, which include 18 multi-ship scenarios. Performance comparisons with artificial potential field and velocity obstacle methods demonstrate the potential of the proposed approach for maritime path planning. Furthermore, the new architecture exhibits robustness when it is deployed in multi-agent scenarios and it is compatible with other deep reinforcement learning algorithms, including actor-critic frameworks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300326X",
    "keywords": [
      "Applied mathematics",
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Autonomous agent",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Distributed computing",
      "Gene",
      "Law",
      "Machine learning",
      "Mathematics",
      "Motion planning",
      "Observability",
      "Obstacle",
      "Political science",
      "Reinforcement learning",
      "Robot",
      "Robustness (evolution)",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Waltz",
        "given_name": "Martin"
      },
      {
        "surname": "Okhrin",
        "given_name": "Ostap"
      }
    ]
  },
  {
    "title": "HybridBranchNet: A novel structure for branch hybrid convolutional neural networks architecture",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.025",
    "abstract": "ConvNet deep neural networks are developed with a consistent structure. The availability of abundant resources helps these structures to be scaled and redesigned in different sizes so that they can be optimized for different applications. By increasing one or more dimensions of the network, such as depth, resolution and width, the number of trainable network parameters will increase and, as a result, the accuracy and performance It should be noted that the backtracking of the convolutional neural network will improve. However, but increasing the number of network parameters increases the complexity of the network, which is not desirable. Therefore, adjusting the structure of the network, increasing the speed, and reducing the number of network parameters along with ensuring accuracy optimization will be important. This study aims to examine a branch network structure systematically, which can lead to better performance. In this study, in order to increase the speed, to reduce the size of the convolutional network model, and to increase the accuracy optimization, a new scaling method, which optimally designs all dimensions of depth, width, and resolution, is proposed based on a branch neural network. A family of HybridBranchNet networks, which is more accurate and efficient than ConvNets, has been created along with this design. HybridBranchNet3 has a classification accuracy of 83.1%. The proposed model was compared with a family of EfficientNet convolutional networks. The comparison results revealed that the proposed network exceeded the mentioned models in terms of accuracy and speed by 1.03% and 39%, respectively. They also showed that the number of trainable parameters is 13% less than that of the EfficientNet network. The proposed method has an accuracy of 92.3% in the CIFAR-100 dataset and 98.8% in the Flowers-102 dataset. Although the architectures such as CoAtNet have slightly higher classification accuracy than the proposed method, they have a greater number of parameters that cannot be used in a conventional system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002708",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backtracking",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Geometry",
      "Machine learning",
      "Mathematics",
      "Network architecture",
      "Network structure",
      "Pattern recognition (psychology)",
      "Scaling"
    ],
    "authors": [
      {
        "surname": "Parcham",
        "given_name": "Ebrahim"
      },
      {
        "surname": "Fateh",
        "given_name": "Mansoor"
      }
    ]
  },
  {
    "title": "Modeling limit order trading with a continuous action policy for deep reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.051",
    "abstract": "Limit Orders allow buyers and sellers to set a “limit price” they are willing to accept in a trade. On the other hand, market orders allow for immediate execution at any price. Thus, market orders are susceptible to slippage, which is the additional cost incurred due to the unfavorable execution of a trade order. As a result, limit orders are often preferred, since they protect traders from excessive slippage costs due to larger than expected price fluctuations. Despite the price guarantees of limit orders, they are more complex compared to market orders. Orders with overly optimistic limit prices might never be executed, which increases the risk of employing limit orders in Machine Learning (ML)-based trading systems. Indeed, the current ML literature for trading almost exclusively relies on market orders. To overcome this limitation, a Deep Reinforcement Learning (DRL) approach is proposed to model trading agents that use limit orders. The proposed method (a) uses a framework that employs a continuous probability distribution to model limit prices, while (b) provides the ability to place market orders when the risk of no execution is more significant than the cost of slippage. Extensive experiments are conducted with multiple currency pairs, using hourly price intervals, validating the effectiveness of the proposed method and paving the way for introducing limit order modeling in DRL-based trading.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002952",
    "keywords": [
      "Algorithmic trading",
      "Artificial intelligence",
      "Computer science",
      "Econometrics",
      "Economics",
      "Finance",
      "Financial economics",
      "High-frequency trading",
      "Limit (mathematics)",
      "Limit price",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Microeconomics",
      "Monetary economics",
      "Order (exchange)",
      "Price level",
      "Reinforcement learning",
      "Slippage",
      "Trading strategy"
    ],
    "authors": [
      {
        "surname": "Tsantekidis",
        "given_name": "Avraam"
      },
      {
        "surname": "Passalis",
        "given_name": "Nikolaos"
      },
      {
        "surname": "Tefas",
        "given_name": "Anastasios"
      }
    ]
  },
  {
    "title": "An unsupervised STDP-based spiking neural network inspired by biologically plausible learning rules and connections",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.019",
    "abstract": "The backpropagation algorithm has promoted the rapid development of deep learning, but it relies on a large amount of labeled data and still has a large gap with how humans learn. The human brain can quickly learn various conceptual knowledge in a self-organized and unsupervised manner, accomplished through coordinating various learning rules and structures in the human brain. Spike-timing-dependent plasticity (STDP) is a general learning rule in the brain, but spiking neural networks (SNNs) trained with STDP alone is inefficient and perform poorly. In this paper, taking inspiration from short-term synaptic plasticity, we design an adaptive synaptic filter and introduce the adaptive spiking threshold as the neuron plasticity to enrich the representation ability of SNNs. We also introduce an adaptive lateral inhibitory connection to adjust the spikes balance dynamically to help the network learn richer features. To speed up and stabilize the training of unsupervised spiking neural networks, we design a samples temporal batch STDP (STB-STDP), which updates weights based on multiple samples and moments. By integrating the above three adaptive mechanisms and STB-STDP, our model greatly accelerates the training of unsupervised spiking neural networks and improves the performance of unsupervised SNNs on complex tasks. Our model achieves the current state-of-the-art performance of unsupervised STDP-based SNNs in the MNIST and FashionMNIST datasets. Further, we tested on the more complex CIFAR10 dataset, and the results fully illustrate the superiority of our algorithm. Our model is also the first work to apply unsupervised STDP-based SNNs to CIFAR10. At the same time, in the small-sample learning scenario, it will far exceed the supervised ANN using the same structure.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003301",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Competitive learning",
      "Computer science",
      "MNIST database",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Receptor",
      "Spike-timing-dependent plasticity",
      "Spiking neural network",
      "Synaptic plasticity",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Dong",
        "given_name": "Yiting"
      },
      {
        "surname": "Zhao",
        "given_name": "Dongcheng"
      },
      {
        "surname": "Li",
        "given_name": "Yang"
      },
      {
        "surname": "Zeng",
        "given_name": "Yi"
      }
    ]
  },
  {
    "title": "Enhanced regularization for on-chip training using analog and temporary memory weights",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.07.001",
    "abstract": "In-memory computing techniques are used to accelerate artificial neural network (ANN) training and inference tasks. Memory technology and architectural innovations allow efficient matrix–vector multiplications, gradient calculations, and updates to network weights. However, on-chip learning for edge devices is quite challenging due to the frequent updates. Here, we propose using an analog and temporary on-chip memory (ATOM) cell with controllable retention timescales for implementing the weights of an on-chip training task. Measurement results for Read–Write timescales are presented for an ATOM cell fabricated in GlobalFoundries’ 45 nm RFSOI technology. The effect of limited retention and its variability is evaluated for training a fully connected neural network with a variable number of layers for the MNIST hand-written digit recognition task. Our studies show that weight decay due to temporary memory can have benefits equivalent to regularization, achieving a ∼ 33 % reduction in the validation error (from 3 . 6 % to 2 . 4 % ). We also show that the controllability of the decay timescale can be advantageous in achieving a further ∼ 26 % reduction in the validation error. This strongly suggests the utility of temporary memory during learning before on-chip non-volatile memories can take over for the storage and inference tasks using the neural network weights. We thus propose an algorithm-circuit codesign in the form of temporary analog memory for high-performing on-chip learning of ANNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003593",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chip",
      "Computer engineering",
      "Computer hardware",
      "Computer science",
      "Economics",
      "Geometry",
      "Inference",
      "MNIST database",
      "Management",
      "Mathematics",
      "Reduction (mathematics)",
      "Semiconductor memory",
      "Task (project management)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Singhal",
        "given_name": "Raghav"
      },
      {
        "surname": "Saraswat",
        "given_name": "Vivek"
      },
      {
        "surname": "Deshmukh",
        "given_name": "Shreyas"
      },
      {
        "surname": "Subramoney",
        "given_name": "Sreenivas"
      },
      {
        "surname": "Somappa",
        "given_name": "Laxmeesha"
      },
      {
        "surname": "Baghini",
        "given_name": "Maryam Shojaei"
      },
      {
        "surname": "Ganguly",
        "given_name": "Udayan"
      }
    ]
  },
  {
    "title": "SCL: Self-supervised contrastive learning for few-shot image classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.037",
    "abstract": "Few-shot learning aims to train a model with a limited number of base class samples to classify the novel class samples. However, to attain generalization with a limited number of samples is not a trivial task. This paper proposed a novel few-shot learning approach named Self-supervised Contrastive Learning (SCL) that enriched the model representation with multiple self-supervision objectives. Given the base class samples, the model is trained with the base class loss. Subsequently, contrastive-based self-supervision is introduced to minimize the distance between each training sample with their augmented variants to improve the sample discrimination. To recognize the distant sample, rotation-based self-supervision is proposed to enable the model to learn to recognize the rotation degree of the samples for better sample diversity. The multitask environment is introduced where each training sample is assigned with two class labels: base class label and rotation class label. Complex augmentation is put forth to help the model learn a deeper understanding of the object. The image structure of the training samples are augmented independent of the base class information. The proposed SCL is trained to minimize the base class loss, contrastive distance loss, and rotation class loss simultaneously to learn the generic features and improve the novel class performance. With the multiple self-supervision objectives, the proposed SCL outperforms state-of-the-art few-shot approaches on few-shot image classification benchmark datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002812",
    "keywords": [
      "Artificial intelligence",
      "Base (topology)",
      "Benchmark (surveying)",
      "Chemistry",
      "Chromatography",
      "Class (philosophy)",
      "Computer science",
      "Economics",
      "Generalization",
      "Geodesy",
      "Geography",
      "Law",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Rotation (mathematics)",
      "Sample (material)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Lim",
        "given_name": "Jit Yan"
      },
      {
        "surname": "Lim",
        "given_name": "Kian Ming"
      },
      {
        "surname": "Lee",
        "given_name": "Chin Poo"
      },
      {
        "surname": "Tan",
        "given_name": "Yong Xuan"
      }
    ]
  },
  {
    "title": "Finite-time cluster synchronization for complex dynamical networks under FDI attack: A periodic control approach",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.013",
    "abstract": "In this paper, the finite-time cluster synchronization problem is addressed for complex dynamical networks (CDNs) with cluster characteristics under false data injection (FDI) attacks. A type of FDI attack is taken into consideration to reflect the data manipulation that controllers in CDNs may suffer. In order to improve the synchronization effect while reducing the control cost, a new periodic secure control (PSC) strategy is proposed in which the set of pinning nodes changes periodically. The aim of this paper is to derive the gains of the periodic secure controller such that the synchronization error of the CDN remains at a certain threshold in finite time with the presence of external disturbances and false control signals simultaneously. Through considering the periodic characteristics of PSC, a sufficient condition is obtained to guarantee the desired cluster synchronization performance, based on which the gains of the periodic cluster synchronization controllers are acquired by resolving an optimization problem proposed in this paper. A numerical case is carried out to validate the cluster synchronization performance of the PSC strategy under cyber attacks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001909",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Channel (broadcasting)",
      "Cluster (spacecraft)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Jun-Yi"
      },
      {
        "surname": "Huang",
        "given_name": "Yang-Cheng"
      },
      {
        "surname": "Rao",
        "given_name": "Hong-Xia"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      },
      {
        "surname": "Lu",
        "given_name": "Renquan"
      }
    ]
  },
  {
    "title": "Neurodynamic optimization approaches with finite/fixed-time convergence for absolute value equations",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.041",
    "abstract": "This paper proposes three novel accelerated inverse-free neurodynamic approaches to solve absolute value equations (AVEs). The first two are finite-time converging approaches and the third one is a fixed-time converging approach. It is shown that the proposed first two neurodynamic approaches converge to the solution of the concerned AVEs in a finite-time while, under some mild conditions, the third one converges to the solution in a fixed-time. It is also shown that the settling time for the proposed fixed-time converging approach has an uniform upper bound for all initial conditions, while the settling times for the proposed finite-time converging approaches are dependent on initial conditions. The proposed neurodynamic approaches have the advantage that they are all robust against bounded vanishing perturbations. The theoretical results are validated by means of a numerical example and an application in boundary value problems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003507",
    "keywords": [
      "Applied mathematics",
      "Boundary value problem",
      "Bounded function",
      "Computer science",
      "Control engineering",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Engineering",
      "Finite set",
      "Geometry",
      "Initial value problem",
      "Inverse",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Settling time",
      "Step response",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Ju",
        "given_name": "Xingxing"
      },
      {
        "surname": "Yang",
        "given_name": "Xinsong"
      },
      {
        "surname": "Feng",
        "given_name": "Gang"
      },
      {
        "surname": "Che",
        "given_name": "Hangjun"
      }
    ]
  },
  {
    "title": "MI-CAT: A transformer-based domain adaptation network for motor imagery classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.005",
    "abstract": "Due to its convenience and safety, electroencephalography (EEG) data is one of the most widely used signals in motor imagery (MI) brain–computer interfaces (BCIs). In recent years, methods based on deep learning have been widely applied to the field of BCIs, and some studies have gradually tried to apply Transformer to EEG signal decoding due to its superior global information focusing ability. However, EEG signals vary from subject to subject. Based on Transformer, how to effectively use data from other subjects (source domain) to improve the classification performance of a single subject (target domain) remains a challenge. To fill this gap, we propose a novel architecture called MI-CAT. The architecture innovatively utilizes Transformer’s self-attention and cross-attention mechanisms to interact features to resolve differential distribution between different domains. Specifically, we adopt a patch embedding layer for the extracted source and target features to divide the features into multiple patches. Then, we comprehensively focus on the intra-domain and inter-domain features by stacked multiple Cross-Transformer Blocks (CTBs), which can adaptively conduct bidirectional knowledge transfer and information exchange between domains. Furthermore, we also utilize two non-shared domain-based attention blocks to efficiently capture domain-dependent information, optimizing the features extracted from the source and target domains to assist in feature alignment. To evaluate our method, we conduct extensive experiments on two real public EEG datasets, Dataset IIb and Dataset IIa, achieving competitive performance with an average classification accuracy of 85.26% and 76.81%, respectively. Experimental results demonstrate that our method is a powerful model for decoding EEG signals and facilitates the development of the Transformer for brain–computer interfaces (BCIs).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003064",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Domain adaptation",
      "Electrical engineering",
      "Engineering",
      "Pattern recognition (psychology)",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Dongxue"
      },
      {
        "surname": "Li",
        "given_name": "Huiying"
      },
      {
        "surname": "Xie",
        "given_name": "Jingmeng"
      }
    ]
  },
  {
    "title": "Decentralized ADMM with compressed and event-triggered communication",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.001",
    "abstract": "This paper considers the decentralized optimization problem, where agents in a network cooperate to minimize the sum of their local objective functions by communication and local computation. We propose a decentralized second-order communication-efficient algorithm called communication-censored and communication-compressed quadratically approximated alternating direction method of multipliers (ADMM), termed as CC-DQM, by combining event-triggered communication with compressed communication. In CC-DQM, agents are allowed to transmit the compressed message only when the current primal variables have changed greatly compared to its last estimate. Moreover, to relieve the computation cost, the update of Hessian is also scheduled by the trigger condition. Theoretical analysis shows that the proposed algorithm can still maintain an exact linear convergence, despite the existence of compression error and intermittent communication, if the local objective functions are strongly convex and smooth. Finally, numerical experiments demonstrate its satisfactory communication efficiency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003027",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Communications system",
      "Compressed sensing",
      "Computation",
      "Computer science",
      "Convergence (economics)",
      "Convex function",
      "Economic growth",
      "Economics",
      "Event (particle physics)",
      "Geometry",
      "Hessian matrix",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Physics",
      "Quadratic growth",
      "Quantum mechanics",
      "Regular polygon",
      "Telecommunications",
      "Telecommunications network"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Zhen"
      },
      {
        "surname": "Yang",
        "given_name": "Shaofu"
      },
      {
        "surname": "Xu",
        "given_name": "Wenying"
      }
    ]
  },
  {
    "title": "Stochastic momentum methods for non-convex learning without bounded assumptions",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.021",
    "abstract": "Stochastic momentum methods are widely used to solve stochastic optimization problems in machine learning. However, most of the existing theoretical analyses rely on either bounded assumptions or strong stepsize conditions. In this paper, we focus on a class of non-convex objective functions satisfying the Polyak–Łojasiewicz (PL) condition and present a unified convergence rate analysis for stochastic momentum methods without any bounded assumptions, which covers stochastic heavy ball (SHB) and stochastic Nesterov accelerated gradient (SNAG). Our analysis achieves the more challenging last-iterate convergence rate of function values under the relaxed growth (RG) condition, which is a weaker assumption than those used in related work. Specifically, we attain the sub-linear rate for stochastic momentum methods with diminishing stepsizes, and the linear convergence rate for constant stepsizes if the strong growth (SG) condition holds. We also examine the iteration complexity for obtaining an ϵ -accurate solution of the last-iterate. Moreover, we provide a more flexible stepsize scheme for stochastic momentum methods in three points: ( i ) relaxing the last-iterate convergence stepsize from square summable to zero limitation; ( i i ) extending the minimum-iterate convergence rate stepsize to the non-monotonic case; ( i i i ) expanding the last-iterate convergence rate stepsize to a more general form. Finally, we conduct numerical experiments on benchmark datasets to validate our theoretical findings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003325",
    "keywords": [
      "Applied mathematics",
      "Bounded function",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Convergence (economics)",
      "Convex function",
      "Economic growth",
      "Economics",
      "Finance",
      "Geometry",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Momentum (technical analysis)",
      "Monotonic function",
      "Rate of convergence",
      "Regular polygon",
      "Stochastic optimization"
    ],
    "authors": [
      {
        "surname": "Liang",
        "given_name": "Yuqing"
      },
      {
        "surname": "Liu",
        "given_name": "Jinlan"
      },
      {
        "surname": "Xu",
        "given_name": "Dongpo"
      }
    ]
  },
  {
    "title": "Corrigendum to “Electrical coupling regulated by GABAergic nucleo-olivary afferent fibres facilitates cerebellar sensory–motor adaptation” [Neural Netw. 155 (2022) 422–438]",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.055",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300299X",
    "keywords": [
      "Adaptation (eye)",
      "Afferent",
      "Biology",
      "Cell biology",
      "Chemistry",
      "Coupling (piping)",
      "Electrical Synapses",
      "GABAergic",
      "Gap junction",
      "Inhibitory postsynaptic potential",
      "Intracellular",
      "Materials science",
      "Metallurgy",
      "Neuroscience",
      "Sensory system"
    ],
    "authors": [
      {
        "surname": "Luque",
        "given_name": "Niceto R."
      },
      {
        "surname": "Naveros",
        "given_name": "Francisco"
      },
      {
        "surname": "Abadía",
        "given_name": "Ignacio"
      },
      {
        "surname": "Ros",
        "given_name": "Eduardo"
      },
      {
        "surname": "Arleo",
        "given_name": "Angelo"
      }
    ]
  },
  {
    "title": "Strengthening transferability of adversarial examples by adaptive inertia and amplitude spectrum dropout",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.031",
    "abstract": "Deep neural networks are sensitive to adversarial examples and would produce wrong results with high confidence. However, most existing attack methods exhibit weak transferability, especially for adversarially trained models and defense models. In this paper, two methods are proposed to generate highly transferable adversarial examples, namely Adaptive Inertia Iterative Fast Gradient Sign Method (AdaI 2 -FGSM) and Amplitude Spectrum Dropout Method (ASDM). Specifically, AdaI 2 -FGSM aims to integrate adaptive inertia into the gradient-based attack, and leverage the looking ahead property to search for a flatter maximum, which is essential to strengthen the transferability of adversarial examples. By introducing a loss-preserving transformation in the frequency domain, the proposed ASDM with the dropout invariance property can craft the copies of input images to overcome the poor generalization on the surrogate models. Furthermore, AdaI 2 -FGSM and ASDM can be naturally integrated as an efficient gradient-based attack method to yield more transferable adversarial examples. Extensive experimental results on the ImageNet-compatible dataset demonstrate that higher transferability is achieved by our method than some advanced gradient-based attacks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300343X",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep neural networks",
      "Dropout (neural networks)",
      "Epistemology",
      "Generalization",
      "Initialization",
      "Logit",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Philosophy",
      "Programming language",
      "Property (philosophy)",
      "Transferability"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Huanhuan"
      },
      {
        "surname": "Yu",
        "given_name": "Wenbo"
      },
      {
        "surname": "Huang",
        "given_name": "He"
      }
    ]
  },
  {
    "title": "Motion perception based on ON/OFF channels: A survey",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.031",
    "abstract": "Motion perception is an essential ability for animals and artificially intelligent systems interacting effectively, safely with surrounding objects and environments. Biological visual systems, that have naturally evolved over hundreds-million years, are quite efficient and robust for motion perception, whereas artificial vision systems are far from such capability. This paper argues that the gap can be significantly reduced by formulation of ON/OFF channels in motion perception models encoding luminance increment (ON) and decrement (OFF) responses within receptive field, separately. Such signal-bifurcating structure has been found in neural systems of many animal species articulating early motion is split and processed in segregated pathways. However, the corresponding biological substrates, and the necessity for artificial vision systems have never been elucidated together, leaving concerns on uniqueness and advantages of ON/OFF channels upon building dynamic vision systems to address real world challenges. This paper highlights the importance of ON/OFF channels in motion perception through surveying current progress covering both neuroscience and computationally modelling works with applications. Compared to related literature, this paper for the first time provides insights into implementation of different selectivity to directional motion of looming, translating, and small-sized target movement based on ON/OFF channels in keeping with soundness and robustness of biological principles. Existing challenges and future trends of such bio-plausible computational structure for visual perception in connection with hotspots of machine learning, advanced vision sensors like event-driven camera finally are discussed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002770",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Biological motion",
      "Chemistry",
      "Cognitive psychology",
      "Computer science",
      "Computer vision",
      "Gene",
      "Looming",
      "Machine vision",
      "Motion (physics)",
      "Motion perception",
      "Neuroscience",
      "Perception",
      "Programming language",
      "Psychology",
      "Robustness (evolution)",
      "Soundness",
      "Visual perception"
    ],
    "authors": [
      {
        "surname": "Fu",
        "given_name": "Qinbing"
      }
    ]
  },
  {
    "title": "De Rham compatible Deep Neural Network FEM",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.008",
    "abstract": "On general regular simplicial partitions T of bounded polytopal domains Ω ⊂ R d , d ∈ { 2 , 3 } , we construct exact neural network (NN) emulations of all lowest order finite element spaces in the discrete de Rham complex. These include the spaces of piecewise constant functions, continuous piecewise linear (CPwL) functions, the classical “Raviart–Thomas element”, and the “Nédélec edge element”. For all but the CPwL case, our network architectures employ both ReLU (rectified linear unit) and BiSU (binary step unit) activations to capture discontinuities. In the important case of CPwL functions, we prove that it suffices to work with pure ReLU nets. Our construction and DNN architecture generalizes previous results in that no geometric restrictions on the regular simplicial partitions T of Ω are required for DNN emulation. In addition, for CPwL functions our DNN construction is valid in any dimension d ≥ 2 . Our “FE-Nets” are required in the variationally correct, structure-preserving approximation of boundary value problems of electromagnetism in nonconvex polyhedra Ω ⊂ R 3 . They are thus an essential ingredient in the application of e.g., the methodology of “physics-informed NNs” or “deep Ritz methods” to electromagnetic field simulation via deep learning techniques. We indicate generalizations of our constructions to higher-order compatible spaces and other, non-compatible classes of discretizations, in particular the “Crouzeix–Raviart” elements and Hybridized, Higher Order (HHO) methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003088",
    "keywords": [],
    "authors": [
      {
        "surname": "Longo",
        "given_name": "Marcello"
      },
      {
        "surname": "Opschoor",
        "given_name": "Joost A.A."
      },
      {
        "surname": "Disch",
        "given_name": "Nico"
      },
      {
        "surname": "Schwab",
        "given_name": "Christoph"
      },
      {
        "surname": "Zech",
        "given_name": "Jakob"
      }
    ]
  },
  {
    "title": "VLAD: Task-agnostic VAE-based lifelong anomaly detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.032",
    "abstract": "Lifelong learning represents an emerging machine learning paradigm that aims at designing new methods providing accurate analyses in complex and dynamic real-world environments. Although a significant amount of research has been conducted in image classification and reinforcement learning, very limited work has been done to solve lifelong anomaly detection problems. In this context, a successful method has to detect anomalies while adapting to changing environments and preserving knowledge to avoid catastrophic forgetting. While state-of-the-art online anomaly detection methods are able to detect anomalies and adapt to a changing environment, they are not designed to preserve past knowledge. On the other hand, while lifelong learning methods are focused on adapting to changing environments and preserving knowledge, they are not tailored for detecting anomalies, and often require task labels or task boundaries which are not available in task-agnostic lifelong anomaly detection scenarios. This paper proposes VLAD, a novel VAE-based Lifelong Anomaly Detection method addressing all these challenges simultaneously in complex task-agnostic scenarios. VLAD leverages the combination of lifelong change point detection and an effective model update strategy supported by experience replay with a hierarchical memory maintained by means of consolidation and summarization. An extensive quantitative evaluation showcases the merit of the proposed method in a variety of applied settings. VLAD outperforms state-of-the-art methods for anomaly detection, presenting increased robustness and performance in complex lifelong settings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002733",
    "keywords": [
      "Anomaly detection",
      "Artificial intelligence",
      "Automatic summarization",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Context (archaeology)",
      "Engineering",
      "Forgetting",
      "Gene",
      "Lifelong learning",
      "Linguistics",
      "Machine learning",
      "Paleontology",
      "Pedagogy",
      "Philosophy",
      "Psychology",
      "Robustness (evolution)",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Faber",
        "given_name": "Kamil"
      },
      {
        "surname": "Corizzo",
        "given_name": "Roberto"
      },
      {
        "surname": "Sniezynski",
        "given_name": "Bartlomiej"
      },
      {
        "surname": "Japkowicz",
        "given_name": "Nathalie"
      }
    ]
  },
  {
    "title": "Attention guided learnable time-domain filterbanks for speech depression detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.041",
    "abstract": "Depression, as a global mental health problem, is lacking effective screening methods that can help with early detection and treatment. This paper aims to facilitate the large-scale screening of depression by focusing on the speech depression detection (SDD) task. Currently, direct modeling on the raw signal yields a large number of parameters, and the existing deep learning-based SDD models mainly use the fixed Mel-scale spectral features as input. However, these features are not designed for depression detection, and the manual settings limit the exploration of fine-grained feature representations. In this paper, we learn the effective representations of the raw signals from an interpretable perspective. Specifically, we present a joint learning framework with attention-guided learnable time-domain filterbanks for depression classification (DALF), which collaborates with the depression filterbanks features learning (DFBL) module and multi-scale spectral attention learning (MSSA) module. DFBL is capable of producing biologically meaningful acoustic features by employing learnable time-domain filters, and MSSA is used to guide the learnable filters to better retain the useful frequency sub-bands. We collect a new dataset, the Neutral Reading-based Audio Corpus (NRAC), to facilitate the research in depression analysis, and we evaluate the performance of DALF on the NRAC and the public DAIC-woz datasets. The experimental results demonstrate that our method outperforms the state-of-the-art SDD methods with an F1 of 78.4% on the DAIC-woz dataset. In particular, DALF achieves F1 scores of 87.3% and 81.7% on two parts of the NRAC dataset. By analyzing the filter coefficients, we find that the most important frequency range identified by our method is 600–700Hz, which corresponds to the Mandarin vowels / e / and / e ˆ / and can be considered as an effective biomarker for the SDD task. Taken together, our DALF model provides a promising approach to depression detection.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300285X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Pattern recognition (psychology)",
      "Speech recognition",
      "Time domain"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Wenju"
      },
      {
        "surname": "Liu",
        "given_name": "Jiankang"
      },
      {
        "surname": "Cao",
        "given_name": "Peng"
      },
      {
        "surname": "Zhu",
        "given_name": "Rongxin"
      },
      {
        "surname": "Wang",
        "given_name": "Yang"
      },
      {
        "surname": "Liu",
        "given_name": "Jian K."
      },
      {
        "surname": "Wang",
        "given_name": "Fei"
      },
      {
        "surname": "Zhang",
        "given_name": "Xizhe"
      }
    ]
  },
  {
    "title": "A multi-modal deep neural network for multi-class liver cancer diagnosis",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.013",
    "abstract": "Liver disease is a potentially asymptomatic clinical entity that may progress to patient death. This study proposes a multi-modal deep neural network for multi-class malignant liver diagnosis. In parallel with the portal venous computed tomography (CT) scans, pathology data is utilized to prognosticate primary liver cancer variants and metastasis. The processed CT scans are fed to the deep dilated convolution neural network to explore salient features. The residual connections are further added to address vanishing gradient problems. Correspondingly, five pathological features are learned using a wide and deep network that gives a benefit of memorization with generalization. The down-scaled hierarchical features from CT scan and pathology data are concatenated to pass through fully connected layers for classification between liver cancer variants. In addition, the transfer learning of pre-trained deep dilated convolution layers assists in handling insufficient and imbalanced dataset issues. The fine-tuned network can predict three-class liver cancer variants with an average accuracy of 96.06% and an Area Under Curve (AUC) of 0.832. To the best of our knowledge, this is the first study to classify liver cancer variants by integrating pathology and image data, hence following the medical perspective of malignant liver diagnosis. The comparative analysis on the benchmark dataset shows that the proposed multi-modal neural network outperformed most of the liver diagnostic studies and is comparable to others.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003246",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Cancer",
      "Computer science",
      "Contextual image classification",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Deep learning",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Internal medicine",
      "Liver cancer",
      "Medicine",
      "Pattern recognition (psychology)",
      "Radiology"
    ],
    "authors": [
      {
        "surname": "Khan",
        "given_name": "Rayyan Azam"
      },
      {
        "surname": "Fu",
        "given_name": "Minghan"
      },
      {
        "surname": "Burbridge",
        "given_name": "Brent"
      },
      {
        "surname": "Luo",
        "given_name": "Yigang"
      },
      {
        "surname": "Wu",
        "given_name": "Fang-Xiang"
      }
    ]
  },
  {
    "title": "Distributional generative adversarial imitation learning with reproducing kernel generalization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.027",
    "abstract": "Generative adversarial imitation learning (GAIL) regards imitation learning (IL) as a distribution matching problem between the state–action distributions of the expert policy and the learned policy. In this paper, we focus on the generalization and computational properties of policy classes. We prove that the generalization can be guaranteed in GAIL when the class of policies is well controlled. With the capability of policy generalization, we introduce distributional reinforcement learning (RL) into GAIL and propose the greedy distributional soft gradient (GDSG) algorithm to solve GAIL. The main advantages of GDSG can be summarized as: (1) Q-value overestimation, a crucial factor leading to the instability of GAIL with off-policy training, can be alleviated by distributional RL. (2) By considering the maximum entropy objective, the policy can be improved in terms of performance and sample efficiency through sufficient exploration. Moreover, GDSG attains a sublinear convergence rate to a stationary solution. Comprehensive experimental verification in MuJoCo environments shows that GDSG can mimic expert demonstrations better than previous GAIL variants.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002721",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Computer science",
      "Discrete mathematics",
      "Generalization",
      "Generative grammar",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Reinforcement learning",
      "Sublinear function"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Yirui"
      },
      {
        "surname": "Lu",
        "given_name": "Mengxiao"
      },
      {
        "surname": "Liu",
        "given_name": "Xiaowei"
      },
      {
        "surname": "Che",
        "given_name": "Zhengping"
      },
      {
        "surname": "Xu",
        "given_name": "Zhiyuan"
      },
      {
        "surname": "Tang",
        "given_name": "Jian"
      },
      {
        "surname": "Zhang",
        "given_name": "Yangchun"
      },
      {
        "surname": "Peng",
        "given_name": "Yan"
      },
      {
        "surname": "Peng",
        "given_name": "Yaxin"
      }
    ]
  },
  {
    "title": "GBT: Two-stage transformer framework for non-stationary time series forecasting",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.044",
    "abstract": "This paper shows that time series forecasting Transformer (TSFT) suffers from severe over-fitting problem caused by improper initialization method of unknown decoder inputs, especially when handling non-stationary time series. Based on this observation, we propose GBT , a novel two-stage T ransformer framework with G ood B eginning. It decouples the prediction process of TSFT into two stages, including Auto-Regression stage and Self-Regression stage to tackle the problem of different statistical properties between input and prediction sequences. Prediction results of Auto-Regression stage serve as a ‘Good Beginning’, i.e., a better initialization for inputs of Self-Regression stage. We also propose the E rror S core M odification module to further enhance the forecasting capability of the Self-Regression stage in GBT. Extensive experiments on seven benchmark datasets demonstrate that GBT outperforms SOTA TSFTs (FEDformer, Pyraformer, ETSformer, etc.) and many other forecasting models (SCINet, N-HiTS, etc.) with only canonical attention and convolution while owning less time and space complexity. It is also general enough to couple with these models to strengthen their forecasting capability. The source code is available at: https://github.com/OrigamiSL/GBT",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003556",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Data mining",
      "Electrical engineering",
      "Engineering",
      "Geodesy",
      "Geography",
      "Initialization",
      "Machine learning",
      "Mathematics",
      "Operating system",
      "Paleontology",
      "Programming language",
      "Regression",
      "Regression analysis",
      "Series (stratigraphy)",
      "Source code",
      "Statistics",
      "Time series",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Li"
      },
      {
        "surname": "Wei",
        "given_name": "Yuning"
      },
      {
        "surname": "Wang",
        "given_name": "Yangzhu"
      }
    ]
  },
  {
    "title": "Novel adaptive zeroing neural dynamics schemes for temporally-varying linear equation handling applied to arm path following and target motion positioning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.056",
    "abstract": "While the handling for temporally-varying linear equation (TVLE) has received extensive attention, most methods focused on trading off the conflict between computational precision and convergence rate. Different from previous studies, this paper proposes two complete adaptive zeroing neural dynamics (ZND) schemes, including a novel adaptive continuous ZND (ACZND) model, two general variable time discretization techniques, and two resultant adaptive discrete ZND (ADZND) algorithms, to essentially eliminate the conflict. Specifically, an error-related varying-parameter ACZND model with global and exponential convergence is first designed and proposed. To further adapt to the digital hardware, two novel variable time discretization techniques are proposed to discretize the ACZND model into two ADZND algorithms. The convergence properties with respect to the convergence rate and precision of ADZND algorithms are proved via rigorous mathematical analyses. By comparing with the traditional discrete ZND (TDZND) algorithms, the superiority of ADZND algorithms in convergence rate and computational precision is shown theoretically and experimentally. Finally, simulative experiments, including numerical experiments on a specific TVLE solving as well as four application experiments on arm path following and target motion positioning are successfully conducted to substantiate the efficacy, superiority, and practicability of ADZND algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003003",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Discretization",
      "Economic growth",
      "Economics",
      "Exponential function",
      "Key (lock)",
      "Mathematical analysis",
      "Mathematics",
      "Path (computing)",
      "Programming language",
      "Rate of convergence",
      "Variable (mathematics)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Wenqi"
      },
      {
        "surname": "Zhang",
        "given_name": "Yunong"
      }
    ]
  },
  {
    "title": "Safe control of logical control networks with random impulses",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.035",
    "abstract": "Under the framework of a hybrid-index model, this paper investigates safe control problems of state-dependent random impulsive logical control networks (RILCNs) on both finite and infinite horizons, respectively. By using the ξ -domain method and the constructed transition probability matrix, the necessary and sufficient conditions for the solvability of safe control problems have been established. Further, based on the technique of state-space partition, two algorithms are proposed to design feedback controllers such that RILCNs can achieve the goal of safe control. Finally, two examples are shared to demonstrate the main results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003465",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Domain (mathematical analysis)",
      "Materials science",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Partition (number theory)",
      "State (computer science)",
      "State space",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Rongpei"
      },
      {
        "surname": "Guo",
        "given_name": "Yuqian"
      },
      {
        "surname": "Wang",
        "given_name": "Yuhao"
      },
      {
        "surname": "Sun",
        "given_name": "Zejun"
      },
      {
        "surname": "Liu",
        "given_name": "Xinzhi"
      }
    ]
  },
  {
    "title": "Retinal vessel segmentation via a Multi-resolution Contextual Network and adversarial learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.029",
    "abstract": "Timely and affordable computer-aided diagnosis of retinal diseases is pivotal in precluding blindness. Accurate retinal vessel segmentation plays an important role in disease progression and diagnosis of such vision-threatening diseases. To this end, we propose a Multi-resolution Contextual Network (MRC-Net) that addresses these issues by extracting multi-scale features to learn contextual dependencies between semantically different features and using bi-directional recurrent learning to model former-latter and latter-former dependencies. Another key idea is training in adversarial settings for foreground segmentation improvement through optimization of the region-based scores. This novel strategy boosts the performance of the segmentation network in terms of the Dice score (and correspondingly Jaccard index) while keeping the number of trainable parameters comparatively low. We have evaluated our method on three benchmark datasets, including DRIVE, STARE, and CHASE, demonstrating its superior performance as compared with competitive approaches elsewhere in the literature.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002757",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Geodesy",
      "Geography",
      "Jaccard index",
      "Key (lock)",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Khan",
        "given_name": "Tariq M."
      },
      {
        "surname": "Naqvi",
        "given_name": "Syed S."
      },
      {
        "surname": "Robles-Kelly",
        "given_name": "Antonio"
      },
      {
        "surname": "Razzak",
        "given_name": "Imran"
      }
    ]
  },
  {
    "title": "SiamDF: Tracking training data-free siamese tracker",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.012",
    "abstract": "Much progress has been made in siamese tracking, primarily benefiting from increasing huge training data. However, very little attention has been really paid to the role of huge training data in learning an effective siamese tracker. In this study, we undertake an in-depth analysis of this issue from a novel optimization perspective, and observe that training data is particularly adept at background suppression, thereby refining target representation. Inspired by this insight, we present a data-free siamese tracking algorithm named SiamDF, which requires only a pre-trained backbone and no further fine-tuning on additional training data. Particularly, to suppress background distractors, we separately improve two branches of siamese tracking by retaining the pure target region as target input with the removal of template background, and by exploring an efficient inverse transformation to maintain the constant aspect ratio of target state in search region. Besides, we further promote the center displacement prediction of the entire backbone by eliminating its spatial stride deviations caused by convolution-like quantification operations. Our experimental results on several popular benchmarks demonstrate that SiamDF, free from both offline fine-tuning and online update, achieves impressive performance compared to well-established unsupervised and supervised tracking methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003222",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Gene",
      "Machine learning",
      "Meteorology",
      "Pattern recognition (psychology)",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Tracking (education)",
      "Training (meteorology)",
      "Training set",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Cai",
        "given_name": "Huayue"
      },
      {
        "surname": "Lan",
        "given_name": "Long"
      },
      {
        "surname": "Zhang",
        "given_name": "Jing"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiang"
      },
      {
        "surname": "Luo",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "Graph structure learning layer and its graph convolution clustering application",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.06.024",
    "abstract": "To learn the embedding representation of graph structure data corrupted by noise and outliers, existing graph structure learning networks usually follow the two-step paradigm, i.e., constructing a “good” graph structure and achieving the message passing for signals supported on the learned graph. However, the data corrupted by noise may make the learned graph structure unreliable. In this paper, we propose an adaptive graph convolutional clustering network that alternatively adjusts the graph structure and node representation layer-by-layer with back-propagation. Specifically, we design a Graph Structure Learning layer before each Graph Convolutional layer to learn the sparse graph structure from the node representations, where the graph structure is implicitly determined by the solution to the optimal self-expression problem. This is one of the first works that uses an optimization process as a Graph Network layer, which is obviously different from the function operation in traditional deep learning layers. An efficient iterative optimization algorithm is given to solve the optimal self-expression problem in the Graph Structure Learning layer. Experimental results show that the proposed method can effectively defend the negative effects of inaccurate graph structures. The code is available at https://github.com/HeXiax/SSGNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023003350",
    "keywords": [
      "Algorithm",
      "Computer science",
      "Graph",
      "Graph bandwidth",
      "Line graph",
      "Null graph",
      "Strength of a graph",
      "Theoretical computer science",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Xiaxia"
      },
      {
        "surname": "Wang",
        "given_name": "Boyue"
      },
      {
        "surname": "Li",
        "given_name": "Ruikun"
      },
      {
        "surname": "Gao",
        "given_name": "Junbin"
      },
      {
        "surname": "Hu",
        "given_name": "Yongli"
      },
      {
        "surname": "Huo",
        "given_name": "Guangyu"
      },
      {
        "surname": "Yin",
        "given_name": "Baocai"
      }
    ]
  },
  {
    "title": "Epicasting: An Ensemble Wavelet Neural Network for forecasting epidemics",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.049",
    "abstract": "Infectious diseases remain among the top contributors to human illness and death worldwide, among which many diseases produce epidemic waves of infection. The lack of specific drugs and ready-to-use vaccines to prevent most of these epidemics worsens the situation. These force public health officials and policymakers to rely on early warning systems generated by accurate and reliable epidemic forecasters. Accurate forecasts of epidemics can assist stakeholders in tailoring countermeasures, such as vaccination campaigns, staff scheduling, and resource allocation, to the situation at hand, which could translate to reductions in the impact of a disease. Unfortunately, most of these past epidemics exhibit nonlinear and non-stationary characteristics due to their spreading fluctuations based on seasonal-dependent variability and the nature of these epidemics. We analyze various epidemic time series datasets using a maximal overlap discrete wavelet transform (MODWT) based autoregressive neural network and call it Ensemble Wavelet Neural Network (EWNet) model. MODWT techniques effectively characterize non-stationary behavior and seasonal dependencies in the epidemic time series and improve the nonlinear forecasting scheme of the autoregressive neural network in the proposed ensemble wavelet network framework. From a nonlinear time series viewpoint, we explore the asymptotic stationarity of the proposed EWNet model to show the asymptotic behavior of the associated Markov Chain. We also theoretically investigate the effect of learning stability and the choice of hidden neurons in the proposal. From a practical perspective, we compare our proposed EWNet framework with twenty-two statistical, machine learning, and deep learning models for fifteen real-world epidemic datasets with three test horizons using four key performance indicators. Experimental results show that the proposed EWNet is highly competitive compared to the state-of-the-art epidemic forecasting methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002939",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoregressive integrated moving average",
      "Autoregressive model",
      "Computer science",
      "Econometrics",
      "Machine learning",
      "Markov chain",
      "Mathematics",
      "Recurrent neural network",
      "Time series",
      "Wavelet"
    ],
    "authors": [
      {
        "surname": "Panja",
        "given_name": "Madhurima"
      },
      {
        "surname": "Chakraborty",
        "given_name": "Tanujit"
      },
      {
        "surname": "Kumar",
        "given_name": "Uttam"
      },
      {
        "surname": "Liu",
        "given_name": "Nan"
      }
    ]
  },
  {
    "title": "SCADA securing system using deep learning to prevent cyber infiltration",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.047",
    "abstract": "Supervisory Control and Data Acquisition (SCADA) systems are computer-based control architectures specifically engineered for the operation of industrial machinery via hardware and software models. These systems are used to project, monitor, and automate the state of the operational network through the utilization of ethernet links, which enable two-way communications. However, as a result of their constant connectivity to the internet and the lack of security frameworks within their internal architecture, they are susceptible to cyber-attacks. In light of this, we have proposed an intrusion detection algorithm, intending to alleviate this security bottleneck. The proposed algorithm, the Genetically Seeded Flora (GSF) feature optimization algorithm, is integrated with Transformer Neural Network (TNN) and functions by detecting changes in operational patterns that may be indicative of an intruder’s involvement. The proposed Genetically Seeded Flora Transformer Neural Network (GSFTNN) algorithm stands in stark contrast to the signature-based method employed by traditional intrusion detection systems. To evaluate the performance of the proposed algorithm, extensive experiments are conducted using the WUSTL-IIOT-2018 ICS SCADA cyber security dataset. The results of these experiments indicate that the proposed algorithm outperforms traditional algorithms such as Residual Neural Networks (ResNet), Recurrent Neural Networks (RNN), and Long Short-Term Memory (LSTM) in terms of accuracy and efficiency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002915",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bottleneck",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Deep learning",
      "Distributed computing",
      "Electrical engineering",
      "Embedded system",
      "Engineering",
      "Ethernet",
      "Industrial control system",
      "Intrusion detection system",
      "Machine learning",
      "Real-time computing",
      "SCADA"
    ],
    "authors": [
      {
        "surname": "Diaba",
        "given_name": "Sayawu Yakubu"
      },
      {
        "surname": "Anafo",
        "given_name": "Theophilus"
      },
      {
        "surname": "Tetteh",
        "given_name": "Lord Anertei"
      },
      {
        "surname": "Oyibo",
        "given_name": "Michael Alewo"
      },
      {
        "surname": "Alola",
        "given_name": "Andrew Adewale"
      },
      {
        "surname": "Shafie-khah",
        "given_name": "Miadreza"
      },
      {
        "surname": "Elmusrati",
        "given_name": "Mohammed"
      }
    ]
  },
  {
    "title": "BrainS: Customized multi-core embedded multiple scale neuromorphic system",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.043",
    "abstract": "Research on modeling and mechanisms of the brain remains the most urgent and challenging task. The customized embedded neuromorphic system is one of the most effective approaches for multi-scale simulations ranging from ion channel to network. This paper proposes BrainS, a scalable multi-core embedded neuromorphic system capable of accommodating massive and large-scale simulations. It is designed with rich external extension interfaces to support various types of input/output and communication requirements. The 3D mesh-based topology with an efficient memory access mechanism makes exploring the properties of neuronal networks possible. BrainS operates at 168 MHz and contains a model database ranging from ion channel to network scale within the Fundamental Computing Unit (FCU). At the ion channel scale, the Basic Community Unit (BCU) can perform real-time simulations of a Hodgkin–Huxley (HH) neuron with 16000 ion channels, using 125.54 KB of the SRAM. When the number of ion channels is within 64000, the HH neuron is simulated in real-time by 4 BCUs. At the network scale, the basal ganglia-thalamus (BG-TH) network consisting of 3200 Izhikevich neurons, providing a vital motor regulation function, is simulated in 4 BCUs with a power consumption of 364.8 mW. Overall, BrainS has an excellent performance in real-time and flexible configurability, providing an embedded application solution for multi-scale simulation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002873",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Channel (broadcasting)",
      "Chemistry",
      "Computer architecture",
      "Computer network",
      "Computer science",
      "Electrical engineering",
      "Embedded system",
      "Engineering",
      "Ion channel",
      "Neuromorphic engineering",
      "Operating system",
      "Physics",
      "Quantum mechanics",
      "Receptor",
      "Recurrent neural network",
      "Reservoir computing",
      "Scalability",
      "Scale (ratio)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Gong",
        "given_name": "Bo"
      },
      {
        "surname": "Wang",
        "given_name": "Jiang"
      },
      {
        "surname": "Lu",
        "given_name": "Meili"
      },
      {
        "surname": "Meng",
        "given_name": "Gong"
      },
      {
        "surname": "Sun",
        "given_name": "Kai"
      },
      {
        "surname": "Chang",
        "given_name": "Siyuan"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhen"
      },
      {
        "surname": "Wei",
        "given_name": "Xile"
      }
    ]
  },
  {
    "title": "Forward propagation dropout in deep neural networks using Jensen–Shannon and random forest feature importance ranking",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.044",
    "abstract": "Dropout is a mechanism to prevent deep neural networks from overfitting and improving their generalization. Random dropout is the simplest method, where nodes are randomly terminated at each step of the training phase, which may lead to network accuracy reduction. In dynamic dropout, the importance of each node and its impact on the network performance is calculated, and the important nodes do not participate in the dropout. But the problem is that the importance of the nodes is not calculated consistently. A node may be considered less important and be dropped in one training epoch and on a batch of data before entering the next epoch, in which it may be an important node. On the other hand, calculating the importance of each unit in every training step is costly. In the proposed method, using random forest and Jensen–Shannon divergence, the importance of each node is calculated once. Then, in the forward propagation steps, the importance of the nodes is propagated and used in the dropout mechanism. This method is evaluated and compared with some previously proposed dropout approaches using two different deep neural network architectures on the MNIST, NorB, CIFAR10, CIFAR100, SVHN, and ImageNet datasets. The results suggest that the proposed method has better accuracy with fewer nodes and better generalizability. Also, the evaluations show that the approach has comparable complexity with other approaches and its convergence time is low as compared with state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002885",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Dropout (neural networks)",
      "Feature (linguistics)",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Random forest",
      "Ranking (information retrieval)"
    ],
    "authors": [
      {
        "surname": "Heidari",
        "given_name": "Mohsen"
      },
      {
        "surname": "Moattar",
        "given_name": "Mohammad Hossein"
      },
      {
        "surname": "Ghaffari",
        "given_name": "Hamidreza"
      }
    ]
  },
  {
    "title": "PIPER: A logic-driven deep contrastive optimization pipeline for event temporal reasoning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.020",
    "abstract": "Event temporal relation extraction is an important task for information extraction. The existing methods usually rely on feature engineering and require post-process to achieve optimization, though inconsistent optimization may occur in the post-process module and main neural network due to their independence. Recently, a few works start to incorporate the temporal logic rules into the neural network and achieve joint optimization. However, these methods still suffer from two shortcomings: (1) Although the joint optimization is applied, the differences between rules are neglected in the unified design of rule losses and further the interpretability and flexibility of the design of model are reduced. (2) Because of lacking abundant syntactic connections between events and rule-match features, the performance of the model may be suppressed by the inefficient interaction in training between features and rules. To tackle these issues, this paper proposes PIPER, a logic-driven deep contrastive optimization pipeline for event temporal reasoning. Specifically, we apply joint optimization (including multi-stage and single-stage joint paradigms) by combining independent rule losses (i.e., flexibility) to make PIPER more interpretable. Also, by proposing a hierarchical graph distillation network to obtain more abundant syntactic information, the designed rule-match features can effectively aid in the interaction between low-level features and high-level rules during training. The final experiments on TB-Dense and MATRES demonstrate that the proposed model can achieve competitive performance compared with the recent advances.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300206X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Event (particle physics)",
      "Feature engineering",
      "Flexibility (engineering)",
      "Interpretability",
      "Machine learning",
      "Mathematics",
      "Operating system",
      "Physics",
      "Pipeline (software)",
      "Process (computing)",
      "Programming language",
      "Quantum mechanics",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Beibei"
      },
      {
        "surname": "Li",
        "given_name": "Lishuang"
      }
    ]
  },
  {
    "title": "Joint feature selection and optimal bipartite graph learning for subspace clustering",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.044",
    "abstract": "Recently, there has been tremendous interest in developing graph-based subspace clustering in high-dimensional data, which does not require a priori knowledge of the number of dimensions and subspaces. The general steps of such algorithms are dictionary representation and spectral clustering. Traditional methods use the dataset itself as a dictionary when performing dictionary representation. There are some limitations that the redundant information present in the dictionary and features may make the constructed graph structure unclear and require post-processing to obtain labels. To address these problems, we propose a novel subspace clustering model that first introduces feature selection to process the input data, randomly selects some samples to construct a dictionary to remove redundant information and learns the optimal bipartite graph with K-connected components under the constraint of the (normalized) Laplacian rank. Finally, the labels are obtained directly from the graphs. The experimental results on motion segmentation and face recognition datasets demonstrate the superior effectiveness and stability of our algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002307",
    "keywords": [
      "A priori and a posteriori",
      "Artificial intelligence",
      "Bipartite graph",
      "Cluster analysis",
      "Clustering high-dimensional data",
      "Computer science",
      "Epistemology",
      "Geometry",
      "Graph",
      "Linear subspace",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Spectral clustering",
      "Subspace topology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Mei",
        "given_name": "Shikun"
      },
      {
        "surname": "Zhao",
        "given_name": "Wenhui"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Learning defense transformations for counterattacking adversarial examples",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.008",
    "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial examples with small perturbations. Adversarial defense thus has been an important means which improves the robustness of DNNs by defending against adversarial examples. Existing defense methods focus on some specific types of adversarial examples and may fail to defend well in real-world applications. In practice, we may face many types of attacks where the exact type of adversarial examples in real-world applications can be even unknown. In this paper, motivated by that adversarial examples are more likely to appear near the classification boundary and are vulnerable to some transformations, we study adversarial examples from a new perspective that whether we can defend against adversarial examples by pulling them back to the original clean distribution. We empirically verify the existence of defense affine transformations that restore adversarial examples. Relying on this, we learn defense transformations to counterattack the adversarial examples by parameterizing the affine transformations and exploiting the boundary information of DNNs. Extensive experiments on both toy and real-world data sets demonstrate the effectiveness and generalization of our defense method. The code is avaliable at https://github.com/SCUTjinchengli/DefenseTransformer.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001259",
    "keywords": [
      "Adversarial system",
      "Affine transformation",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep neural networks",
      "Gene",
      "Generalization",
      "Mathematical analysis",
      "Mathematics",
      "Perspective (graphical)",
      "Pure mathematics",
      "Robustness (evolution)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Jincheng"
      },
      {
        "surname": "Zhang",
        "given_name": "Shuhai"
      },
      {
        "surname": "Cao",
        "given_name": "Jiezhang"
      },
      {
        "surname": "Tan",
        "given_name": "Mingkui"
      }
    ]
  },
  {
    "title": "Basis operator network: A neural network-based model for learning nonlinear operators via neural basis",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.017",
    "abstract": "It is widely acknowledged that neural networks can approximate any continuous (even measurable) functions between finite-dimensional Euclidean spaces to arbitrary accuracy. Recently, the use of neural networks has started emerging in infinite-dimensional settings. Universal approximation theorems of operators guarantee that neural networks can learn mappings between infinite-dimensional spaces. In this paper, we propose a neural network-based method (BasisONet) capable of approximating mappings between function spaces. To reduce the dimension of an infinite-dimensional space, we propose a novel function autoencoder that can compress the function data. Our model can predict the output function at any resolution using the corresponding input data at any resolution once trained. Numerical experiments demonstrate that the performance of our model is competitive with existing methods on the benchmarks, and our model can address the data on a complex geometry with high precision. We further analyze some notable characteristics of our model based on the numerical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002034",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Basis (linear algebra)",
      "Basis function",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Dimension (graph theory)",
      "Euclidean space",
      "Evolutionary biology",
      "Function (biology)",
      "Function approximation",
      "Function space",
      "Gene",
      "Geometry",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Operator (biology)",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Repressor",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Hua",
        "given_name": "Ning"
      },
      {
        "surname": "Lu",
        "given_name": "Wenlian"
      }
    ]
  },
  {
    "title": "A transformer-based deep neural network model for SSVEP classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.045",
    "abstract": "Steady-state visual evoked potential (SSVEP) is one of the most commonly used control signals in the brain–computer interface (BCI) systems. However, the conventional spatial filtering methods for SSVEP classification highly depend on the subject-specific calibration data. The need for the methods that can alleviate the demand for the calibration data becomes urgent. In recent years, developing the methods that can work in inter-subject scenario has become a promising new direction. As a popular deep learning model nowadays, Transformer has been used in EEG signal classification tasks owing to its excellent performance. Therefore, in this study, we proposed a deep learning model for SSVEP classification based on Transformer architecture in inter-subject scenario, termed as SSVEPformer, which was the first application of Transformer on the SSVEP classification. Inspired by previous studies, we adopted the complex spectrum features of SSVEP data as the model input, which could enable the model to simultaneously explore the spectral and spatial information for classification. Furthermore, to fully utilize the harmonic information, an extended SSVEPformer based on the filter bank technology (FB-SSVEPformer) was proposed to improve the classification performance. Experiments were conducted using two open datasets (Dataset 1: 10 subjects, 12 targets; Dataset 2: 35 subjects, 40 targets). The experimental results show that the proposed models could achieve better results in terms of classification accuracy and information transfer rate than other baseline methods. The proposed models validate the feasibility of deep learning models based on Transformer architecture for SSVEP data classification, and could serve as potential models to alleviate the calibration procedure in the practical application of SSVEP-based BCI systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002319",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Electrical engineering",
      "Engineering",
      "Pattern recognition (psychology)",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Jianbo"
      },
      {
        "surname": "Zhang",
        "given_name": "Yangsong"
      },
      {
        "surname": "Pan",
        "given_name": "Yudong"
      },
      {
        "surname": "Xu",
        "given_name": "Peng"
      },
      {
        "surname": "Guan",
        "given_name": "Cuntai"
      }
    ]
  },
  {
    "title": "Self-supervision assisted multimodal remote sensing image classification with coupled self-looping convolution networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.019",
    "abstract": "Recently, remote sensing community has seen a surge in the use of multimodal data for different tasks such as land cover classification, change detection and many more. However, handling multimodal data requires synergistically using the information from different sources. Currently, deep learning (DL) techniques are being religiously used in multimodal data fusion owing to their superior feature extraction capabilities. But, DL techniques have their share of challenges. Firstly, DL models are mostly constructed in the forward fashion limiting their feature extraction capability. Secondly, multimodal learning is generally addressed in a supervised setting, which leads to high labelled data requirement. Thirdly, the models generally handle each modality separately, thus preventing any cross-modal interaction. Hence, we propose a novel self-supervision oriented method of multimodal remote sensing data fusion. For effective cross-modal learning, our model solves a self-supervised auxiliary task to reconstruct input features of one modality from the extracted features of another modality, thus enabling more representative pre-fusion features. To counter the forward architecture, our model is composed of convolutions both in backward and forward directions, thus creating self-looping connections, leading to a self-correcting framework. To facilitate cross-modal communication, we have incorporated coupling across modality-specific extractors using shared parameters. We evaluate our approach on three remote sensing datasets, namely Houston 2013 and Houston 2018, which are HSI-LiDAR datasets and TU Berlin, which is an HSI-SAR dataset, where we achieve the respective accuracy of 93.08%, 84.59% and 73.21%, thus beating the state of the art by a minimum of 3.02%, 2.23% and 2.84%.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002058",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Convolution (computer science)",
      "Data mining",
      "Deep learning",
      "Economics",
      "Feature (linguistics)",
      "Feature extraction",
      "Geology",
      "Human–computer interaction",
      "Linguistics",
      "Machine learning",
      "Management",
      "Modal",
      "Modality (human–computer interaction)",
      "Mode (computer interface)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Polymer chemistry",
      "Remote sensing",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Pande",
        "given_name": "Shivam"
      },
      {
        "surname": "Banerjee",
        "given_name": "Biplab"
      }
    ]
  },
  {
    "title": "Input-to-state stability of positive delayed neural networks via impulsive control",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.011",
    "abstract": "This paper is concerned with the positivity and impulsive stabilization of equilibrium points of delayed neural networks (DNNs) subject to bounded disturbances. With the aid of the continuous dependence theorem for impulsive delay differential equations, a relaxed positivity condition is derived, which allows the neuron interconnection matrix to be Metzler if the activation functions satisfy a certain condition. The notion of input-to-state stability (ISS) is introduced to characterize internal global stability and disturbance attenuation performance for impulsively controlled DNNs. The ISS property is analyzed by employing a time-dependent max-separable Lyapunov function which is able to capture the positivity characterization and hybrid structure of the considered DNNs. A ranged dwell-time-dependent ISS condition is obtained, which allows to design an impulsive control law via partial state variables. As a byproduct, an improved global exponential stability criterion for impulse-free positive DNNs is obtained. The applicability of the achieved results is illustrated through three numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002526",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Attenuation",
      "Bounded function",
      "Clinical psychology",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Dwell time",
      "Exponential stability",
      "Impulse (physics)",
      "Interconnection",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Medicine",
      "Nonlinear system",
      "Optics",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Stability theory",
      "State (computer science)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Wu-Hua"
      },
      {
        "surname": "Li",
        "given_name": "Xiujuan"
      },
      {
        "surname": "Niu",
        "given_name": "Shuning"
      },
      {
        "surname": "Lu",
        "given_name": "Xiaomei"
      }
    ]
  },
  {
    "title": "CSAST: Content self-supervised and style contrastive learning for arbitrary style transfer",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.037",
    "abstract": "Arbitrary artistic style transfer has achieved great success with deep neural networks, but it is still difficult for existing methods to tackle the dilemma of content preservation and style translation due to the inherent content-and-style conflict. In this paper, we introduce content self-supervised learning and style contrastive learning to arbitrary style transfer for improved content preservation and style translation, respectively. The former one is based on the assumption that stylization of a geometrically transformed image is perceptually similar to applying the same transformation to the stylized result of the original image. This content self-supervised constraint noticeably improves content consistency before and after style translation, and contributes to reducing noises and artifacts as well. Furthermore, it is especially suitable to video style transfer, due to its ability to promote inter-frame continuity, which is of crucial importance to visual stability of video sequences. For the latter one, we construct a contrastive learning that pull close style representations (Gram matrices) of the same style and push away that of different styles. This brings more accurate style translation and more appealing visual effect. A large number of qualitative and quantitative experiments demonstrate superiority of our method in improving arbitrary style transfer quality, both for images and videos.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002241",
    "keywords": [
      "Archaeology",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Consistency (knowledge bases)",
      "Economics",
      "Epistemology",
      "Frame (networking)",
      "Gene",
      "Generalization",
      "History",
      "Machine learning",
      "Macroeconomics",
      "Mathematical analysis",
      "Mathematics",
      "Messenger RNA",
      "Natural language processing",
      "Philosophy",
      "Quality (philosophy)",
      "Stability (learning theory)",
      "Style (visual arts)",
      "Stylized fact",
      "Telecommunications",
      "Translation (biology)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yuqi"
      },
      {
        "surname": "Tian",
        "given_name": "Yingjie"
      },
      {
        "surname": "Hou",
        "given_name": "Junjie"
      }
    ]
  },
  {
    "title": "A novel time series prediction method based on pooling compressed sensing echo state network and its application in stock market",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.031",
    "abstract": "In the prediction of time series, the echo state network (ESN) exhibits exclusive strengths and a unique training structure. Based on ESN model, a pooling activation algorithm consisting noise value and adjusted pooling algorithm is proposed to enrich the update strategy of the reservoir layer in ESN. The algorithm optimizes the distribution of reservoir layer nodes. And the nodes set will be more matched to the characteristics of the data. In addition, we introduce a more efficient and accurate compressed sensing technique based on the existing research. The novel compressed sensing technique reduces the amount of spatial computation of methods. The ESN model based on the above two techniques overcomes the limitations in traditional prediction. In the experimental part, the model is validated with different chaotic time series as well as multiple stocks, and the method shows its efficiency and accuracy in prediction.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002174",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Chaotic",
      "Compressed sensing",
      "Computation",
      "Computer science",
      "Data mining",
      "Echo state network",
      "Machine learning",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Pooling",
      "Recurrent neural network",
      "Series (stratigraphy)",
      "Time series"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Zijian"
      },
      {
        "surname": "Zhao",
        "given_name": "Hui"
      },
      {
        "surname": "Zheng",
        "given_name": "Mingwen"
      },
      {
        "surname": "Niu",
        "given_name": "Sijie"
      },
      {
        "surname": "Gao",
        "given_name": "Xizhan"
      },
      {
        "surname": "Li",
        "given_name": "Lixiang"
      }
    ]
  },
  {
    "title": "TIToK: A solution for bi-imbalanced unsupervised domain adaptation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.027",
    "abstract": "Unsupervised domain adaptation (UDA) aims to transfer knowledge via domain alignment, and typically assumes balanced data distribution. When deployed in real tasks, however, (i) each domain usually suffers from class imbalance, and (ii) different domains may have different class imbalance ratios. In such bi-imbalanced cases with both within-domain and across-domain imbalance, source knowledge transfer may degenerate the target performance. Some recent efforts have adopted source re-weighting to this issue, in order to align label distributions across domains. However, since target label distribution is unknown, the alignment might be incorrect or even risky. In this paper, we propose an alternative solution named TIToK for bi-imbalanced UDA, by directly Transferring Imbalance-Tolerant Knowledge across domains. In TIToK, a class contrastive loss is presented for classification, in order to alleviate the sensitivity to imbalance in knowledge transfer. Meanwhile, knowledge of class correlation is transferred as a supplementary, which is commonly invariant to imbalance. Finally, discriminative feature alignment is developed for a more robust classifier boundary. Experiments over benchmark datasets show that TIToK achieves competitive performance with the state-of-the-arts, and its performance is less sensitive to imbalance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002137",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Data mining",
      "Discriminative model",
      "Domain adaptation",
      "Machine learning",
      "Medicine",
      "Pattern recognition (psychology)",
      "Radiology",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yunyun"
      },
      {
        "surname": "Chen",
        "given_name": "Quchuan"
      },
      {
        "surname": "Liu",
        "given_name": "Yao"
      },
      {
        "surname": "Li",
        "given_name": "Weikai"
      },
      {
        "surname": "Chen",
        "given_name": "Songcan"
      }
    ]
  },
  {
    "title": "Contrast sensitivity function in deep networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.032",
    "abstract": "The contrast sensitivity function (CSF) is a fundamental signature of the visual system that has been measured extensively in several species. It is defined by the visibility threshold for sinusoidal gratings at all spatial frequencies. Here, we investigated the CSF in deep neural networks using the same 2AFC contrast detection paradigm as in human psychophysics. We examined 240 networks pretrained on several tasks. To obtain their corresponding CSFs, we trained a linear classifier on top of the extracted features from frozen pretrained networks. The linear classifier is exclusively trained on a contrast discrimination task with natural images. It has to find which of the two input images has higher contrast. The network’s CSF is measured by detecting which one of two images contains a sinusoidal grating of varying orientation and spatial frequency. Our results demonstrate characteristics of the human CSF are manifested in deep networks both in the luminance channel (a band-limited inverted U-shaped function) and in the chromatic channels (two low-pass functions of similar properties). The exact shape of the networks’ CSF appears to be task-dependent. The human CSF is better captured by networks trained on low-level visual tasks such as image-denoising or autoencoding. However, human-like CSF also emerges in mid- and high-level tasks such as edge detection and object recognition. Our analysis shows that human-like CSF appears in all architectures but at different depths of processing, some at early layers, while others in intermediate and final layers. Overall, these results suggest that (i) deep networks model the human CSF faithfully, making them suitable candidates for applications of image quality and compression, (ii) efficient/purposeful processing of the natural world drives the CSF shape, and (iii) visual representation from all levels of visual hierarchy contribute to the tuning curve of the CSF, in turn implying a function which we intuitively think of as modulated by low-level visual features may arise as a consequence of pooling from a larger set of neurons at all levels of the visual system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002186",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Chromatic scale",
      "Classifier (UML)",
      "Computer science",
      "Computer vision",
      "Contrast (vision)",
      "Deep neural networks",
      "Geometry",
      "Human visual system model",
      "Image (mathematics)",
      "Luminance",
      "Mathematics",
      "Neuroscience",
      "Optics",
      "Orientation (vector space)",
      "Pattern recognition (psychology)",
      "Perception",
      "Physics",
      "Psychophysics",
      "Spatial frequency"
    ],
    "authors": [
      {
        "surname": "Akbarinia",
        "given_name": "Arash"
      },
      {
        "surname": "Morgenstern",
        "given_name": "Yaniv"
      },
      {
        "surname": "Gegenfurtner",
        "given_name": "Karl R."
      }
    ]
  },
  {
    "title": "Prospective classification of Alzheimer’s disease conversion from mild cognitive impairment",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.018",
    "abstract": "Alzheimer’s disease (AD) is emerging as a serious problem with the rapid aging of the population, but due to the unclear cause of the disease and the absence of therapy, appropriate preventive measures are the next best thing. For this reason, it is important to early detect whether the disease converts from mild cognitive impairment (MCI) which is a prodromal phase of AD. With the advance in brain imaging techniques, various machine learning algorithms have become able to predict the conversion from MCI to AD by learning brain atrophy patterns. However, at the time of diagnosis, it is difficult to distinguish between the conversion group and the non-conversion group of subjects because the difference between groups is small, but the within-group variability is large in brain images. After a certain period of time, the subjects of conversion group show significant brain atrophy, whereas subjects of non-conversion group show only subtle changes due to the normal aging effect. This difference on brain atrophy makes the brain images more discriminative for learning. Motivated by this, we propose a method to perform classification by projecting brain images into the future, namely prospective classification. The experiments on the Alzheimer’s Disease Neuroimaging Initiative dataset show that the prospective classification outperforms ordinary classification. Moreover, the features of prospective classification indicate the brain regions that significantly influence the conversion from MCI to AD.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002046",
    "keywords": [
      "Alzheimer's disease",
      "Artificial intelligence",
      "Atrophy",
      "Cognition",
      "Computer science",
      "Degenerative disease",
      "Discriminative model",
      "Disease",
      "Internal medicine",
      "Medicine",
      "Neuroimaging",
      "Neuroscience",
      "Prospective cohort study",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Park",
        "given_name": "Sunghong"
      },
      {
        "surname": "Hong",
        "given_name": "Chang Hyung"
      },
      {
        "surname": "Lee",
        "given_name": "Dong-gi"
      },
      {
        "surname": "Park",
        "given_name": "Kanghee"
      },
      {
        "surname": "Shin",
        "given_name": "Hyunjung"
      }
    ]
  },
  {
    "title": "Approximate spectral decomposition of Fisher information matrix for simple ReLU networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.017",
    "abstract": "We argue the Fisher information matrix (FIM) of one hidden layer networks with the ReLU activation function. For a network, let W denote the d × p weight matrix from the d -dimensional input to the hidden layer consisting of p neurons, and v the p -dimensional weight vector from the hidden layer to the scalar output. We focus on the FIM of v , which we denote as I . Under certain conditions, we characterize the first three clusters of eigenvalues and eigenvectors of the FIM. Specifically, we show that the following approximately holds. (1) Since I is non-negative owing to the ReLU, the first eigenvalue is the Perron–Frobenius eigenvalue. (2) For the cluster of the next maximum values, the eigenspace is spanned by the row vectors of W . (3) The direct sum of the eigenspace of the first eigenvalue and that of the third cluster is spanned by the set of all the vectors obtained as the Hadamard product of any pair of the row vectors of W . We confirmed by numerical calculation that the above is approximately correct when the number of hidden nodes is about 10000.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002617",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Biology",
      "Chemistry",
      "Chromatography",
      "Combinatorics",
      "Computer science",
      "Decomposition",
      "Eigendecomposition of a matrix",
      "Eigenvalues and eigenvectors",
      "Epistemology",
      "Evolutionary biology",
      "Fisher information",
      "Function (biology)",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Matrix decomposition",
      "Organic chemistry",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Simple (philosophy)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Takeishi",
        "given_name": "Yoshinari"
      },
      {
        "surname": "Iida",
        "given_name": "Masazumi"
      },
      {
        "surname": "Takeuchi",
        "given_name": "Jun’ichi"
      }
    ]
  },
  {
    "title": "LoyalDE: Improving the performance of Graph Neural Networks with loyal node discovery and emphasis",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.023",
    "abstract": "Recent years have witnessed an increasing focus on graph-based semi-supervised learning with Graph Neural Networks (GNNs). Despite existing GNNs having achieved remarkable accuracy, research on the quality of graph supervision information has inadvertently been ignored. In fact, there are significant differences in the quality of supervision information provided by different labeled nodes, and treating supervision information with different qualities equally may lead to sub-optimal performance of GNNs. We refer to this as the graph supervision loyalty problem, which is a new perspective for improving the performance of GNNs. In this paper, we devise FT-Score to quantify node loyalty by considering both the local feature similarity and the local topology similarity, and nodes with higher loyalty are more likely to provide higher-quality supervision. Based on this, we propose LoyalDE (Loyal Node Discovery and Emphasis), a model-agnostic hot-plugging training strategy, which can discover potential nodes with high loyalty to expand the training set, and then emphasize nodes with high loyalty during model training to improve performance. Experiments demonstrate that the graph supervision loyalty problem will fail most existing GNNs. In contrast, LoyalDE brings about at most 9.1% performance improvement to vanilla GNNs and consistently outperforms several state-of-the-art training strategies for semi-supervised node classification.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002678",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Engineering",
      "Epistemology",
      "Graph",
      "Image (mathematics)",
      "Law",
      "Loyalty",
      "Machine learning",
      "Node (physics)",
      "Philosophy",
      "Political science",
      "Programming language",
      "Quality (philosophy)",
      "Set (abstract data type)",
      "Similarity (geometry)",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Haotong"
      },
      {
        "surname": "Zhu",
        "given_name": "Yinlin"
      },
      {
        "surname": "Li",
        "given_name": "Xunkai"
      },
      {
        "surname": "Jiang",
        "given_name": "Bin"
      }
    ]
  },
  {
    "title": "A reinforcement learning algorithm acquires demonstration from the training agent by dividing the task space",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.042",
    "abstract": "Although reinforcement learning (RL) has made numerous breakthroughs in recent years, addressing reward-sparse environments remains challenging and requires further exploration. Many studies improve the performance of the agents by introducing the state-action pairs experienced by an expert. However, such kinds of strategies almost depend on the quality of the demonstration by the expert, which is rarely optimal in a real-world environment, and struggle with learning from sub-optimal demonstrations. In this paper, a self-imitation learning algorithm based on the task space division is proposed to realize an efficient high-quality demonstration acquire while the training process. To determine the quality of the trajectory, some well-designed criteria are defined in the task space for finding a better demonstration. The results show that the proposed algorithm will improve the success rate of robot control and achieve a high mean Q value per step. The algorithm framework proposed in this paper has illustrated a great potential to learn from a demonstration generated by using self-policy in sparse environments and can be used in reward-sparse environments where the task space can be divided.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002289",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Engineering",
      "Epistemology",
      "Imitation",
      "Machine learning",
      "Mathematics",
      "Operating system",
      "Philosophy",
      "Physics",
      "Process (computing)",
      "Psychology",
      "Q-learning",
      "Quality (philosophy)",
      "Quantum mechanics",
      "Reinforcement learning",
      "Robot",
      "Social psychology",
      "Space (punctuation)",
      "State space",
      "Statistics",
      "Systems engineering",
      "Task (project management)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Zu",
        "given_name": "Lipeng"
      },
      {
        "surname": "He",
        "given_name": "Xiao"
      },
      {
        "surname": "Yang",
        "given_name": "Jia"
      },
      {
        "surname": "Liu",
        "given_name": "Lianqing"
      },
      {
        "surname": "Wang",
        "given_name": "Wenxue"
      }
    ]
  },
  {
    "title": "ProductGraphSleepNet: Sleep staging using product spatio-temporal graph learning with attentive temporal aggregation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.016",
    "abstract": "The classification of sleep stages plays a crucial role in understanding and diagnosing sleep pathophysiology. Sleep stage scoring relies heavily on visual inspection by an expert, which is a time-consuming and subjective procedure. Recently, deep learning neural network approaches have been leveraged to develop a generalized automated sleep staging and account for shifts in distributions that may be caused by inherent inter/intra-subject variability, heterogeneity across datasets, and different recording environments. However, these networks (mostly) ignore the connections among brain regions and disregard modeling the connections between temporally adjacent sleep epochs. To address these issues, this work proposes an adaptive product graph learning-based graph convolutional network, named ProductGraphSleepNet, for learning joint spatio-temporal graphs along with a bidirectional gated recurrent unit and a modified graph attention network to capture the attentive dynamics of sleep stage transitions. Evaluation on two public databases: the Montreal Archive of Sleep Studies (MASS) SS3; and the SleepEDF, which contain full night polysomnography recordings of 62 and 20 healthy subjects, respectively, demonstrates performance comparable to the state-of-the-art (Accuracy: 0.867;0.838, F1-score: 0.818;0.774 and Kappa: 0.802;0.775, on each database respectively). More importantly, the proposed network makes it possible for clinicians to comprehend and interpret the learned spatial and temporal connectivity graphs for sleep stages.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002605",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Electroencephalography",
      "Graph",
      "Machine learning",
      "Neuroscience",
      "Operating system",
      "Pattern recognition (psychology)",
      "Polysomnography",
      "Psychology",
      "Sleep (system call)",
      "Sleep Stages",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Einizade",
        "given_name": "Aref"
      },
      {
        "surname": "Nasiri",
        "given_name": "Samaneh"
      },
      {
        "surname": "Sardouie",
        "given_name": "Sepideh Hajipour"
      },
      {
        "surname": "Clifford",
        "given_name": "Gari D."
      }
    ]
  },
  {
    "title": "Quasi-projective and complete synchronization of discrete-time fractional-order delayed neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.005",
    "abstract": "This paper presents new theoretical results on quasi-projective synchronization (Q-PS) and complete synchronization (CS) of one kind of discrete-time fractional-order delayed neural networks (DFDNNs). At first, three new fractional difference inequalities for exploring the upper bound of quasi-synchronization error and adaptive synchronization are established by dint of Laplace transform and properties of discrete Mittag-Leffler function, which vastly expand a number of available results. Furthermore, two controllers are designed including nonlinear controller and adaptive controller. And on the basis of Lyapunov method, the aforementioned inequalities and properties of fractional-order difference operators, some sufficient synchronization criteria of DFDNNs are derived. Because of the above controllers, synchronization criteria in this paper are less conservative. At last, numerical examples are carried out to illustrate the usefulness of theoretical upshots.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002368",
    "keywords": [
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Laplace transform",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Xiao-Li"
      },
      {
        "surname": "Li",
        "given_name": "Hong-Li"
      },
      {
        "surname": "Yu",
        "given_name": "Yongguang"
      },
      {
        "surname": "Zhang",
        "given_name": "Long"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      }
    ]
  },
  {
    "title": "Evolution-communication spiking neural P systems with energy request rules",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.007",
    "abstract": "Evolution-communication spiking neural P systems with energy request rules (ECSNP-ER systems) are proposed and developed as a new variant of evolution-communication spiking neural P systems. In ECSNP-ER systems, in addition to spike-evolution rules and spike-communication rules, neurons also have energy request rules. Energy request rules are used to obtain energy from the environment needed for spike evolution and communication in neurons. The definition, structure and operations of ECSNP-ER systems are presented in detail. ECSNP-ER systems are proved to have the same computing capabilities as Turing machines by using them as number generating/accepting devices and function computing devices. Working non-deterministically, ECSNP-ER systems are used to solve NP-complete problems, using the SAT problem as an example, in linear time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002381",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Communications system",
      "Computation",
      "Computer science",
      "Energy (signal processing)",
      "Mathematics",
      "P system",
      "Software engineering",
      "Spike (software development)",
      "Spiking neural network",
      "Statistics",
      "Telecommunications",
      "Theoretical computer science",
      "Turing machine"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Liping"
      },
      {
        "surname": "Liu",
        "given_name": "Xiyu"
      },
      {
        "surname": "Sun",
        "given_name": "Minghe"
      },
      {
        "surname": "Zhao",
        "given_name": "Yuzhen"
      }
    ]
  },
  {
    "title": "Imitating the oracle: Towards calibrated model for class incremental learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.010",
    "abstract": "Class-incremental learning (CIL) aims to recognize classes that emerged in different phases. The joint-training (JT), which trains the model jointly with all classes, is often considered as the upper bound of CIL. In this paper, we thoroughly analyze the difference between CIL and JT in feature space and weight space. Motivated by the comparative analysis, we propose two types of calibration: feature calibration and weight calibration to imitate the oracle (ItO), i.e., JT. Specifically, on the one hand, feature calibration introduces deviation compensation to maintain the class decision boundary of old classes in feature space. On the other hand, weight calibration leverages forgetting-aware weight perturbation to increase transferability and reduce forgetting in parameter space. With those two calibration strategies, the model is forced to imitate the properties of joint-training at each incremental learning stage, thus yielding better CIL performance. Our ItO is a plug-and-play method and can be implemented into existing methods easily. Extensive experiments on several benchmark datasets demonstrate that ItO can significantly and consistently improve the performance of existing state-of-the-art methods. Our code is publicly available at https://github.com/Impression2805/ItO4CIL.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001879",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Calibration",
      "Computer science",
      "Decision boundary",
      "Feature (linguistics)",
      "Feature vector",
      "Forgetting",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Oracle",
      "Philosophy",
      "Software engineering",
      "Statistics",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Fei"
      },
      {
        "surname": "Cheng",
        "given_name": "Zhen"
      },
      {
        "surname": "Zhang",
        "given_name": "Xu-Yao"
      },
      {
        "surname": "Liu",
        "given_name": "Cheng-Lin"
      }
    ]
  },
  {
    "title": "A novel sequential structure for lightweight multi-scale feature learning under limited available images",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.023",
    "abstract": "Although multi-scale feature learning can improve the performances of deep models, its parallel structure quadratically increases the model parameters and causes deep models to become larger and larger when enlarging the receptive fields (RFs). This leads to deep models easily suffering from over-fitting issue in many practical applications where the available training samples are always insufficient or limited. In addition, under this limited situation, although lightweight models (with fewer model parameters) can effectively reduce over-fitting, they may suffer from under-fitting because of insufficient training data for effective feature learning. In this work, a lightweight model called Sequential Multi-scale Feature Learning Network (SMF-Net) is proposed to alleviate these two issues simultaneously using a novel sequential structure of multi-scale feature learning. Compared to both deep and lightweight models, the proposed sequential structure in SMF-Net can easily extract features with larger RFs for multi-scale feature learning only with a few and linearly increased model parameters. The experimental results on both classification and segmentation tasks demonstrate that our SMF-Net only has 1.25M model parameters (5.3% of Res2Net50) with 0.7G FLOPS (14.6% of Res2Net50) for classification and 1.54M parameters (8.9% of UNet) with 3.35G FLOPs (10.9% of UNet) for segmentation but achieves higher accuracy than SOTA deep models and lightweight models, even when the training data is very limited available.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002095",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "FLOPS",
      "Feature (linguistics)",
      "Linguistics",
      "Machine learning",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Scale (ratio)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Peng"
      },
      {
        "surname": "Du",
        "given_name": "Jie"
      },
      {
        "surname": "Vong",
        "given_name": "Chi-Man"
      }
    ]
  },
  {
    "title": "Event-triggered fault-tolerant control for input-constrained nonlinear systems with mismatched disturbances via adaptive dynamic programming",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.001",
    "abstract": "In this paper, the issue of event-triggered optimal fault-tolerant control is investigated for input-constrained nonlinear systems with mismatched disturbances. To eliminate the effect of abrupt faults and ensure the optimal performance of general nonlinear dynamics, an adaptive dynamic programming (ADP) algorithm is employed to develop a sliding mode fault-tolerant control strategy. When the system trajectories converge to the sliding-mode surface, the equivalent sliding mode dynamics is transformed into a reformulated auxiliary system with a modified cost function. Then, a single critic neural network (NN) is adopted to solve the modified Hamilton–Jacobi–Bellman (HJB) equation. In order to overcome the difficulty that arises from the persistence of excitation (PE) condition, the experience replay technique is utilized to update the critic weights. In this study, a novel control method is proposed, which can effectively eliminate the effects of abrupt faults while achieving optimal control with the minimum cost under a single network architecture. Furthermore, the closed-loop nonlinear system is proved to be uniformly ultimate boundedness based on Lyapunov stability theory. Finally, three examples are presented to verify the validity of the control strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002320",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Distributed computing",
      "Dynamic programming",
      "Fault tolerance",
      "Hamilton–Jacobi–Bellman equation",
      "Lyapunov function",
      "Lyapunov stability",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Optimal control",
      "Physics",
      "Quantum mechanics",
      "Sliding mode control"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Heng"
      },
      {
        "surname": "Wang",
        "given_name": "Huanqing"
      },
      {
        "surname": "Niu",
        "given_name": "Ben"
      },
      {
        "surname": "Zhao",
        "given_name": "Xudong"
      },
      {
        "surname": "Alharbi",
        "given_name": "Khalid H."
      }
    ]
  },
  {
    "title": "Optimal H ∞ tracking control of nonlinear systems with zero-equilibrium-free via novel adaptive critic designs",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.021",
    "abstract": "In this paper, a novel adaptive critic control method is designed to solve an optimal H ∞ tracking control problem for continuous nonlinear systems with nonzero equilibrium based on adaptive dynamic programming (ADP). To guarantee the finiteness of a cost function, traditional methods generally assume that the controlled system has a zero equilibrium point, which is not true in practical systems. In order to overcome such obstacle and realize H ∞ optimal tracking control, this paper proposes a novel cost function design with respect to disturbance, tracking error and the derivative of tracking error. Based on the designed cost function, the H ∞ control problem is formulated as two-player zero-sum differential games, and then a policy iteration (PI) algorithm is proposed to solve the corresponding Hamilton–Jacobi–Isaacs (HJI) equation. In order to obtain the online solution to the HJI equation, a single-critic neural network structure based on PI algorithm is established to learn the optimal control policy and the worst-case disturbance law. It is worth mentioning that the proposed adaptive critic control method can simplify the controller design process when the equilibrium of the systems is not zero. Finally, simulations are conducted to evaluate the tracking performance of the proposed control methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002071",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Controller (irrigation)",
      "Differential equation",
      "Equilibrium point",
      "Evolutionary biology",
      "Function (biology)",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Optimal control",
      "Pedagogy",
      "Psychology",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Zhinan"
      },
      {
        "surname": "Ji",
        "given_name": "Hanqi"
      },
      {
        "surname": "Zou",
        "given_name": "Chaobin"
      },
      {
        "surname": "Kuang",
        "given_name": "Yiqun"
      },
      {
        "surname": "Cheng",
        "given_name": "Hong"
      },
      {
        "surname": "Shi",
        "given_name": "Kaibo"
      },
      {
        "surname": "Ghosh",
        "given_name": "Bijoy Kumar"
      }
    ]
  },
  {
    "title": "Aperiodic switching event-triggered stabilization of continuous memristive neural networks with interval delays",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.036",
    "abstract": "The stabilization problem is studied for memristive neural networks with interval delays under aperiodic switching event-triggered control. Note that, most of delayed memristive neural networks models studied are discontinuous, which are not the real memristive neural networks. First, a real model of memristive neural networks is proposed by continuous differential equations, furthermore, it is simplified to neural networks with interval matrix uncertainties. Secondly, an aperiodic switching event-trigger is given, and the considered system switches between aperiodic sampled-data system and continuous event-triggered system. Thirdly, by constructing a time-dependent piecewise-defined Lyapunov functional, the stability criterion and the feedback gain design are obtained by linear matrix inequalities. Compared with the existing results, the stability criterion is with lower conservatism. Finally, two neurons are taken as examples to ensure the feasibility of the results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002228",
    "keywords": [
      "Aperiodic graph",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Event (particle physics)",
      "Interval (graph theory)",
      "Machine learning",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Physics",
      "Piecewise",
      "Quantum mechanics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yaning"
      },
      {
        "surname": "Tuo",
        "given_name": "Huan"
      },
      {
        "surname": "Lyu",
        "given_name": "Huiping"
      },
      {
        "surname": "Cheng",
        "given_name": "Zunshui"
      },
      {
        "surname": "Xin",
        "given_name": "Youming"
      }
    ]
  },
  {
    "title": "Long short-term memory with activation on gradient",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.026",
    "abstract": "As the number of long short-term memory (LSTM) layers increases, vanishing/exploding gradient problems exacerbate and have a negative impact on the performance of the LSTM. In addition, the ill-conditioned problem occurs in the training process of LSTM and adversely affects its convergence. In this work, a simple and effective method of the gradient activation is applied to the LSTM, while empirical criteria for choosing gradient activation hyperparameters are found. Activating the gradient refers to modifying the gradient with a specific function named the gradient activation function. Moreover, different activation functions and different gradient operations are compared to prove that the gradient activation is effective on LSTM. Furthermore, comparative experiments are conducted, and their results show that the gradient activation alleviates the above problems and accelerates the convergence of the LSTM. The source code is publicly available at https://github.com/LongJin-lab/ACT-In-NLP.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002125",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Code (set theory)",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Gradient descent",
      "Gradient method",
      "Hyperparameter",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Set (abstract data type)",
      "Term (time)"
    ],
    "authors": [
      {
        "surname": "Qin",
        "given_name": "Chuan"
      },
      {
        "surname": "Chen",
        "given_name": "Liangming"
      },
      {
        "surname": "Cai",
        "given_name": "Zangtai"
      },
      {
        "surname": "Liu",
        "given_name": "Mei"
      },
      {
        "surname": "Jin",
        "given_name": "Long"
      }
    ]
  },
  {
    "title": "Explainable hybrid word representations for sentiment analysis of financial news",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.011",
    "abstract": "Due to the increasing interest of people in the stock and financial market, the sentiment analysis of news and texts related to the sector is of utmost importance. This helps the potential investors in deciding what company to invest in and what are their long-term benefits. However, it is challenging to analyze the sentiments of texts related to the financial domain, given the enormous amount of information available. The existing approaches are unable to capture complex attributes of language such as word usage, including semantics and syntax throughout the context, and polysemy in the context. Further, these approaches failed to interpret the models’ predictability, which is obscure to humans. Models’ interpretability to justify the predictions has remained largely unexplored and has become important to engender users’ trust in the predictions by providing insight into the model prediction. Accordingly, in this paper, we present an explainable hybrid word representation that first augments the data to address the class imbalance issue and then integrates three embeddings to involve polysemy in context, semantics, and syntax in a context. We then fed our proposed word representation to a convolutional neural network (CNN) with attention to capture the sentiment. The experimental results show that our model outperforms several baselines of both classic classifiers and combinations of various word embedding models in the sentiment analysis of financial news. The experimental results also show that the proposed model outperforms several baselines of word embeddings and contextual embeddings when they are separately fed to a neural network model. Further, we show the explainability of the proposed method by presenting the visualization results to explain the reason for a prediction in the sentiment analysis of financial news.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001880",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Convolutional neural network",
      "Embedding",
      "Interpretability",
      "Law",
      "Linguistics",
      "Natural language processing",
      "Paleontology",
      "Philosophy",
      "Physics",
      "Political science",
      "Politics",
      "Polysemy",
      "Predictability",
      "Programming language",
      "Quantum mechanics",
      "Representation (politics)",
      "Semantics (computer science)",
      "Sentiment analysis",
      "Syntax",
      "Word (group theory)",
      "Word embedding"
    ],
    "authors": [
      {
        "surname": "Adhikari",
        "given_name": "Surabhi"
      },
      {
        "surname": "Thapa",
        "given_name": "Surendrabikram"
      },
      {
        "surname": "Naseem",
        "given_name": "Usman"
      },
      {
        "surname": "Lu",
        "given_name": "Hai Ya"
      },
      {
        "surname": "Bharathy",
        "given_name": "Gnana"
      },
      {
        "surname": "Prasad",
        "given_name": "Mukesh"
      }
    ]
  },
  {
    "title": "Event-triggered control for robust exponential synchronization of inertial memristive neural networks under parameter disturbance",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.024",
    "abstract": "Synchronization of memristive neural networks (MNNs) by using network control scheme has been widely and deeply studied. However, these researches are usually restricted to traditional continuous-time control methods for synchronization of the first-order MNNs. In this paper, we study the robust exponential synchronization of inertial memristive neural networks (IMNNs) with time-varying delays and parameter disturbance via event-triggered control (ETC) scheme. First, the delayed IMNNs with parameter disturbance are changed into first-order MNNs with parameter disturbance by constructing proper variable substitutions. Next, a kind of state feedback controller is designed to the response IMNN with parameter disturbance. Based on feedback controller, some ETC methods are provided to largely decrease the update times of controller. Then, some sufficient conditions are provided to realize robust exponential synchronization of delayed IMNNs with parameter disturbance via ETC scheme. Moreover, the Zeno behavior will not happen in all ETC conditions shown in this paper. Finally, numerical simulations are given to verify the advantages of the obtained results such as anti-interference performance and good reliability.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002101",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Disturbance (geology)",
      "Inertial frame of reference",
      "Paleontology",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Yao",
        "given_name": "Wei"
      },
      {
        "surname": "Wang",
        "given_name": "Chunhua"
      },
      {
        "surname": "Sun",
        "given_name": "Yichuang"
      },
      {
        "surname": "Gong",
        "given_name": "Shuqing"
      },
      {
        "surname": "Lin",
        "given_name": "Hairong"
      }
    ]
  },
  {
    "title": "Stability analysis of stochastic gradient descent for homogeneous neural networks and linear classifiers",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.028",
    "abstract": "We prove new generalization bounds for stochastic gradient descent when training classifiers with invariances. Our analysis is based on the stability framework and covers both the convex case of linear classifiers and the non-convex case of homogeneous neural networks. We analyze stability with respect to the normalized version of the loss function used for training. This leads to investigating a form of angle-wise stability instead of euclidean stability in weights. For neural networks, the measure of distance we consider is invariant to rescaling the weights of each layer. Furthermore, we exploit the notion of on-average stability in order to obtain a data-dependent quantity in the bound. This data-dependent quantity is seen to be more favorable when training with larger learning rates in our numerical experiments. This might help to shed some light on why larger learning rates can lead to better generalization in some practical scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002149",
    "keywords": [
      "Activation function",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Ergodic theory",
      "Euclidean geometry",
      "Generalization",
      "Geometry",
      "Gradient descent",
      "Invariant (physics)",
      "Invariant measure",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical physics",
      "Mathematics",
      "Regular polygon",
      "Stability (learning theory)",
      "Stochastic gradient descent"
    ],
    "authors": [
      {
        "surname": "Paquin",
        "given_name": "Alexandre Lemire"
      },
      {
        "surname": "Chaib-draa",
        "given_name": "Brahim"
      },
      {
        "surname": "Giguère",
        "given_name": "Philippe"
      }
    ]
  },
  {
    "title": "Growing dendrites enhance a neuron’s computational power and memory capacity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.033",
    "abstract": "Neocortical pyramidal neurons have many dendrites, and such dendrites are capable of, in isolation of one-another, generating a neuronal spike. It is also now understood that there is a large amount of dendritic growth during the first years of a humans life, arguably a period of prodigious learning. These observations inspire the construction of a local, stochastic algorithm based on an earlier stochastic, homeostatic, Hebbian developmental theory. Here we investigate the neurocomputational advantages and limits on this novel algorithm that combines dendritogenesis with supervised adaptive synaptogenesis. Neurons created with this algorithm have enhanced memory capacity, can avoid catastrophic interference (forgetting), and have the ability to unmix mixture distributions. In particular, individual dendrites develop within each class, in an unsupervised manner, to become feature-clusters that correspond to the mixing elements of class-conditional mixture distribution. Error-free classification is demonstrated with input perturbations up to 40%. Although discriminative problems are used to understand the capabilities of the stochastic algorithm and the neuronal connectivity it produces, the algorithm is in the generative class, it thus seems ideal for decisions that require generalization, i.e., extrapolation beyond previous learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002198",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognitive psychology",
      "Computer science",
      "Discriminative model",
      "Forgetting",
      "Generalization",
      "Generative grammar",
      "Generative model",
      "Hebbian theory",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Psychology",
      "Software engineering",
      "Spike (software development)"
    ],
    "authors": [
      {
        "surname": "Levy",
        "given_name": "William B"
      },
      {
        "surname": "Baxter",
        "given_name": "Robert A."
      }
    ]
  },
  {
    "title": "Corrigendum to “Functional Connectivity Learning via Siamese-based SPD Matrix Representation of Brain Imaging Data” [Neural Networks 163 (2023) 272–285]",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.012",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002563",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Functional Brain Imaging",
      "Functional connectivity",
      "Law",
      "Matrix (chemical analysis)",
      "Neuroimaging",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Psychology",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Yunbo"
      },
      {
        "surname": "Chen",
        "given_name": "Dan"
      },
      {
        "surname": "Wu",
        "given_name": "Jia"
      },
      {
        "surname": "Tu",
        "given_name": "Weiping"
      },
      {
        "surname": "Monaghan",
        "given_name": "Jessica J.M."
      },
      {
        "surname": "Sowman",
        "given_name": "Paul"
      },
      {
        "surname": "Mcalpine",
        "given_name": "David"
      }
    ]
  },
  {
    "title": "A spectral graph convolution for signed directed graphs via magnetic Laplacian",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.009",
    "abstract": "Signed directed graphs contain both sign and direction information on their edges, providing richer information about real-world phenomena compared to unsigned or undirected graphs. However, analyzing such graphs is more challenging due to their complexity, and the limited availability of existing methods. Consequently, despite their potential uses, signed directed graphs have received less research attention. In this paper, we propose a novel spectral graph convolution model that effectively captures the underlying patterns in signed directed graphs. To this end, we introduce a complex Hermitian adjacency matrix that can represent both sign and direction of edges using complex numbers. We then define a magnetic Laplacian matrix based on the adjacency matrix, which we use to perform spectral convolution. We demonstrate that the magnetic Laplacian matrix is positive semi-definite (PSD), which guarantees its applicability to spectral methods. Compared to traditional Laplacians, the magnetic Laplacian captures additional edge information, which makes it a more informative tool for graph analysis. By leveraging the information of signed directed edges, our method generates embeddings that are more representative of the underlying graph structure. Furthermore, we showed that the proposed method has wide applicability for various graph types and is the most generalized Laplacian form. We evaluate the effectiveness of the proposed model through extensive experiments on several real-world datasets. The results demonstrate that our method outperforms state-of-the-art techniques in signed directed graph embedding.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002502",
    "keywords": [
      "Adjacency list",
      "Adjacency matrix",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Directed graph",
      "Embedding",
      "Graph",
      "Laplace operator",
      "Laplacian matrix",
      "Line graph",
      "Mathematical analysis",
      "Mathematics",
      "Signed graph",
      "Spectral graph theory",
      "Theoretical computer science",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Ko",
        "given_name": "Taewook"
      },
      {
        "surname": "Choi",
        "given_name": "Yoonhyuk"
      },
      {
        "surname": "Kim",
        "given_name": "Chong-Kwon"
      }
    ]
  },
  {
    "title": "Multi-granularity knowledge distillation and prototype consistency regularization for class-incremental learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.006",
    "abstract": "Deep neural networks (DNNs) are prone to the notorious catastrophic forgetting problem when learning new tasks incrementally. Class-incremental learning (CIL) is a promising solution to tackle the challenge and learn new classes while not forgetting old ones. Existing CIL approaches adopted stored representative exemplars or complex generative models to achieve good performance. However, storing data from previous tasks causes memory or privacy issues, and the training of generative models is unstable and inefficient. This paper proposes a method based on multi-granularity knowledge distillation and prototype consistency regularization (MDPCR) that performs well even when the previous training data is unavailable. First, we propose to design knowledge distillation losses in the deep feature space to constrain the incremental model trained on the new data. Thereby, multi-granularity is captured from three aspects: by distilling multi-scale self-attentive features, the feature similarity probability, and global features to maximize the retention of previous knowledge, effectively alleviating catastrophic forgetting. Conversely, we preserve the prototype of each old class and employ prototype consistency regularization (PCR) to ensure that the old prototypes and semantically enhanced prototypes produce consistent prediction, which excels in enhancing the robustness of old prototypes and reduces the classification bias. Extensive experiments on three CIL benchmark datasets confirm that MDPCR performs significantly better over exemplar-free methods and outperforms typical exemplar-based approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300237X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Boosting (machine learning)",
      "Chemistry",
      "Computer science",
      "Consistency (knowledge bases)",
      "Distillation",
      "Forgetting",
      "Gene",
      "Generative grammar",
      "Granularity",
      "Linguistics",
      "Machine learning",
      "Operating system",
      "Organic chemistry",
      "Philosophy",
      "Regularization (linguistics)",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Shi",
        "given_name": "Yanyan"
      },
      {
        "surname": "Shi",
        "given_name": "Dianxi"
      },
      {
        "surname": "Qiao",
        "given_name": "Ziteng"
      },
      {
        "surname": "Wang",
        "given_name": "Zhen"
      },
      {
        "surname": "Zhang",
        "given_name": "Yi"
      },
      {
        "surname": "Yang",
        "given_name": "Shaowu"
      },
      {
        "surname": "Qiu",
        "given_name": "Chunping"
      }
    ]
  },
  {
    "title": "Theoretical bounds of generalization error for generalized extreme learning machine and random vector functional link network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.014",
    "abstract": "Ensuring the prediction accuracy of a learning algorithm on a theoretical basis is crucial and necessary for building the reliability of the learning algorithm. This paper analyzes prediction error obtained through the least square estimation in the generalized extreme learning machine (GELM), which applies the limiting behavior of the Moore–Penrose generalized inverse (M–P GI) to the output matrix of ELM. ELM is the random vector functional link (RVFL) network without direct input to output links Specifically, we analyze tail probabilities associated with upper and lower bounds to the error expressed by norms. The analysis employs the concepts of the L 2 norm, the Frobenius norm, the stable rank, and the M–P GI. The coverage of theoretical analysis extends to the RVFL network. In addition, a criterion for more precise bounds of prediction errors that may give stochastically better network environments is provided. The analysis is applied to simple examples and large-size datasets to illustrate the procedure and verify the analysis and execution speed with big data. Based on this study, we can immediately obtain the upper and lower bounds of prediction errors and their associated tail probabilities through matrices calculations appearing in the GELM and RVFL. This analysis provides criteria for the reliability of the learning performance of a network in real-time and for network structure that enables obtaining better performance reliability. This analysis can be applied in various areas where the ELM and RVFL are adopted. The proposed analytical method will guide the theoretical analysis of errors occurring in DNNs, which employ a gradient descent algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002009",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer network",
      "Computer science",
      "Extreme learning machine",
      "Generalization",
      "Generalization error",
      "Link (geometry)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Multivariate random variable",
      "Pattern recognition (psychology)",
      "Random variable",
      "Statistical learning theory",
      "Statistics",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Meejoung"
      }
    ]
  },
  {
    "title": "Generating post-hoc explanations for Skip-gram-based node embeddings by identifying important nodes with bridgeness",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.029",
    "abstract": "Node representation learning in a network is an important machine learning technique for encoding relational information in a continuous vector space while preserving the inherent properties and structures of the network. Recently, unsupervised node embedding methods such as DeepWalk (Perozzi et al., 2014), LINE (Tang et al., 2015), struc2vec (Ribeiro et al., 2017), PTE (Tang et al., 2015), UserItem2vec (Wu et al., 2020), and RWJBG (Li et al., 2021) have emerged from the Skip-gram model (Mikolov et al., 2013) and perform better performance in several downstream tasks such as node classification and link prediction than the existing relational models. However, providing post-hoc explanations of unsupervised embeddings remains a challenging problem because of the lack of explanation methods and theoretical studies applicable for embeddings. In this paper, we first show that global explanations to the Skip-gram-based embeddings can be found by computing bridgeness under a spectral cluster-aware local perturbation. Moreover, a novel gradient-based explanation method, which we call GRAPH-wGD, is proposed that allows the top- q global explanations about learned graph embedding vectors more efficiently. Experiments show that the ranking of nodes by scores using GRAPH-wGD is highly correlated with true bridgeness scores. We also observe that the top- q node-level explanations selected by GRAPH-wGD have higher importance scores and produce more changes in class label prediction when perturbed, compared with the nodes selected by recent alternatives, using five real-world graphs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002150",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Embedding",
      "Engineering",
      "Graph",
      "Machine learning",
      "Node (physics)",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Park",
        "given_name": "Hogun"
      },
      {
        "surname": "Neville",
        "given_name": "Jennifer"
      }
    ]
  },
  {
    "title": "Cost-effective framework for gradual domain adaptation with multifidelity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.035",
    "abstract": "In domain adaptation, when there is a large distance between the source and target domains, the prediction performance will degrade. Gradual domain adaptation is one of the solutions to such an issue, assuming that we have access to intermediate domains, which shift gradually from the source to the target domain. In previous works, it was assumed that the number of samples in the intermediate domains was sufficiently large; hence, self-training was possible without the need for labeled data. If the number of accessible intermediate domains is restricted, the distances between domains become large, and self-training will fail. Practically, the cost of samples in intermediate domains will vary, and it is natural to consider that the closer an intermediate domain is to the target domain, the higher the cost of obtaining samples from the intermediate domain is. To solve the trade-off between cost and accuracy, we propose a framework that combines multifidelity and active domain adaptation. The effectiveness of the proposed method is evaluated by experiments with real-world datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001703",
    "keywords": [
      "Adaptation (eye)",
      "Algorithm",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Optics",
      "Physics"
    ],
    "authors": [
      {
        "surname": "Sagawa",
        "given_name": "Shogo"
      },
      {
        "surname": "Hino",
        "given_name": "Hideitsu"
      }
    ]
  },
  {
    "title": "Design of continuous-time recurrent neural networks with piecewise-linear activation function for generation of prescribed sequences of bipolar vectors",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.013",
    "abstract": "A recurrent neural network (RNN) can generate a sequence of patterns as the temporal evolution of the output vector. This paper focuses on a continuous-time RNN model with a piecewise-linear activation function that has neither external inputs nor hidden neurons, and studies the problem of finding the parameters of the model so that it generates a given sequence of bipolar vectors. First, a sufficient condition for the model to generate the desired sequence is derived, which is expressed as a system of linear inequalities in the parameters. Next, three approaches to finding solutions of the system of linear inequalities are proposed: One is formulated as a convex quadratic programming problem and others are linear programming problems. Then, two types of sequences of bipolar vectors that can be generated by the model are presented. Finally, the case where the model generates a periodic sequence of bipolar vectors is considered, and a sufficient condition for the trajectory of the state vector to converge to a limit cycle is provided.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002575",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Genetics",
      "Geometry",
      "Linear programming",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Piecewise",
      "Piecewise linear function",
      "Quadratic programming",
      "Recurrent neural network",
      "Sequence (biology)"
    ],
    "authors": [
      {
        "surname": "Takahashi",
        "given_name": "Norikazu"
      },
      {
        "surname": "Yamakawa",
        "given_name": "Tsuyoshi"
      },
      {
        "surname": "Minetoma",
        "given_name": "Yasuhiro"
      },
      {
        "surname": "Nishi",
        "given_name": "Tetsuo"
      },
      {
        "surname": "Migita",
        "given_name": "Tsuyoshi"
      }
    ]
  },
  {
    "title": "An adaptive reinforcement learning-based multimodal data fusion framework for human–robot confrontation gaming",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.043",
    "abstract": "Playing games between humans and robots have become a widespread human–robot confrontation (HRC) application. Although many approaches were proposed to enhance the tracking accuracy by combining different information, the problems of the intelligence degree of the robot and the anti-interference ability of the motion capture system still need to be solved. In this paper, we present an adaptive reinforcement learning (RL) based multimodal data fusion (AdaRL-MDF) framework teaching the robot hand to play Rock–Paper–Scissors (RPS) game with humans. It includes an adaptive learning mechanism to update the ensemble classifier, an RL model providing intellectual wisdom to the robot, and a multimodal data fusion structure offering resistance to interference. The corresponding experiments prove the mentioned functions of the AdaRL-MDF model. The comparison accuracy and computational time show the high performance of the ensemble model by combining k-nearest neighbor (k-NN) and deep convolutional neural network (DCNN). In addition, the depth vision-based k-NN classifier obtains a 100% identification accuracy so that the predicted gestures can be regarded as the real value. The demonstration illustrates the real possibility of HRC application. The theory involved in this model provides the possibility of developing HRC intelligence.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002290",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Machine learning",
      "Reinforcement learning",
      "Robot",
      "Sensor fusion"
    ],
    "authors": [
      {
        "surname": "Qi",
        "given_name": "Wen"
      },
      {
        "surname": "Fan",
        "given_name": "Haoyu"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      },
      {
        "surname": "Su",
        "given_name": "Hang"
      }
    ]
  },
  {
    "title": "B-mode ultrasound based CAD for liver cancers via multi-view privileged information learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.028",
    "abstract": "B-mode ultrasound-based computer-aided diagnosis model can help sonologists improve the diagnostic performance for liver cancers, but it generally suffers from the bottleneck due to the limited structure and internal echogenicity information in B-mode ultrasound images. Contrast-enhanced ultrasound images provide additional diagnostic information on dynamic blood perfusion of liver lesions for B-mode ultrasound images with improved diagnostic accuracy. Since transfer learning has indicated its effectiveness in promoting the performance of target computer-aided diagnosis model by transferring knowledge from related imaging modalities, a multi-view privileged information learning framework is proposed to improve the diagnostic accuracy of the single-modal B-mode ultrasound-based diagnosis for liver cancers. This framework can make full use of the shared label information between the paired B-mode ultrasound images and contrast-enhanced ultrasound images to guide knowledge transfer It consists of a novel supervised dual-view deep Boltzmann machine and a new deep multi-view SVM algorithm. The former is developed to implement knowledge transfer from the multi-phase contrast-enhanced ultrasound images to the B-mode ultrasound-based diagnosis model via a feature-level learning using privileged information paradigm, which is totally different from the existing learning using privileged information paradigm that performs knowledge transfer in the classifier. The latter further fuses and enhances feature representation learned from three pre-trained supervised dual-view deep Boltzmann machine networks for the classification task. An experiment is conducted on a bimodal ultrasound liver cancer dataset. The experimental results show that the proposed framework outperforms all the compared algorithms with the best classification accuracy of 88.91 ± 1.52%, sensitivity of 88.31 ± 2.02%, and specificity of 89.50 ± 3.12%. It suggests the effectiveness of our proposed MPIL framework for the BUS-based CAD of liver cancers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001636",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Echogenicity",
      "Feature (linguistics)",
      "Linguistics",
      "Machine learning",
      "Medicine",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Radiology",
      "Support vector machine",
      "Transfer of learning",
      "Ultrasound"
    ],
    "authors": [
      {
        "surname": "Han",
        "given_name": "Xiangmin"
      },
      {
        "surname": "Gong",
        "given_name": "Bangming"
      },
      {
        "surname": "Guo",
        "given_name": "Lehang"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Ying",
        "given_name": "Shihui"
      },
      {
        "surname": "Li",
        "given_name": "Shuo"
      },
      {
        "surname": "Shi",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "One-shot Federated Learning without server-side training",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.035",
    "abstract": "Federated Learning (FL) has recently made significant progress as a new machine learning paradigm for privacy protection. Due to the high communication cost of traditional FL, one-shot federated learning is gaining popularity as a way to reduce communication cost between clients and the server. Most of the existing one-shot FL methods are based on Knowledge Distillation; however, distillation based approach requires an extra training phase and depends on publicly available data sets or generated pseudo samples. In this work, we consider a novel and challenging cross-silo setting: performing a single round of parameter aggregation on the local models without server-side training. In this setting, we propose an effective algorithm for Model Aggregation via Exploring Common Harmonized Optima (MA-Echo), which iteratively updates the parameters of all local models to bring them close to a common low-loss area on the loss surface, without harming performance on their own data sets at the same time. Compared to the existing methods, MA-Echo can work well even in extremely non-identical data distribution settings where the support categories of each local model have no overlapped labels with those of the others. We conduct extensive experiments on two popular image classification data sets to compare the proposed method with existing methods and demonstrate the effectiveness of MA-Echo, which clearly outperforms the state-of-the-arts. The source code can be accessed in https://github.com/FudanVI/MAEcho.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002216",
    "keywords": [
      "Artificial intelligence",
      "Client-side",
      "Code (set theory)",
      "Computer network",
      "Computer science",
      "Data mining",
      "Echo (communications protocol)",
      "Machine learning",
      "Operating system",
      "Programming language",
      "Server-side",
      "Set (abstract data type)",
      "Source code",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Su",
        "given_name": "Shangchao"
      },
      {
        "surname": "Li",
        "given_name": "Bin"
      },
      {
        "surname": "Xue",
        "given_name": "Xiangyang"
      }
    ]
  },
  {
    "title": "Co-attention enabled content-based image retrieval",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.009",
    "abstract": "Content-based image retrieval (CBIR) aims to provide the most similar images to a given query. Feature extraction plays an essential role in retrieval performance within a CBIR pipeline. Current CBIR studies would either uniformly extract feature information from the input image and use it directly or employ some trainable spatial weighting module which is then used for similarity comparison between pairs of query and candidate matching images. These spatial weighting modules are normally query non-sensitive and only based on the knowledge learned during the training stage. They may focus towards incorrect regions, especially when the target image is not salient or is surrounded by distractors. This paper proposes an efficient query sensitive co-attention 1 1 “Co-attention” in this paper refers to spatial attention conditioned on the query content. mechanism for large-scale CBIR tasks. In order to reduce the extra computation cost required by the query sensitivity to the co-attention mechanism, the proposed method employs clustering of the selected local features. Experimental results indicate that the co-attention maps can provide the best retrieval results on benchmark datasets under challenging situations, such as having completely different image acquisition conditions between the query and its match image.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001867",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Cluster analysis",
      "Computer science",
      "Content-based image retrieval",
      "Data mining",
      "Feature (linguistics)",
      "Feature extraction",
      "Focus (optics)",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Image retrieval",
      "Information retrieval",
      "Linguistics",
      "Matching (statistics)",
      "Mathematics",
      "Medicine",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Pipeline (software)",
      "Programming language",
      "Query expansion",
      "Radiology",
      "Similarity (geometry)",
      "Statistics",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Hu",
        "given_name": "Zechao"
      },
      {
        "surname": "Bors",
        "given_name": "Adrian G."
      }
    ]
  },
  {
    "title": "SpikeSEE: An energy-efficient dynamic scenes processing framework for retinal prostheses",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.002",
    "abstract": "Intelligent and low-power retinal prostheses are highly demanded in this era, where wearable and implantable devices are used for numerous healthcare applications. In this paper, we propose an energy-efficient dynamic scenes processing framework (SpikeSEE) that combines a spike representation encoding technique and a bio-inspired spiking recurrent neural network (SRNN) model to achieve intelligent processing and extreme low-power computation for retinal prostheses. The spike representation encoding technique could interpret dynamic scenes with sparse spike trains, decreasing the data volume. The SRNN model, inspired by the human retina’s special structure and spike processing method, is adopted to predict the response of ganglion cells to dynamic scenes. Experimental results show that the Pearson correlation coefficient of the proposed SRNN model achieves 0.93, which outperforms the state-of-the-art processing framework for retinal prostheses. Thanks to the spike representation and SRNN processing, the model can extract visual features in a multiplication-free fashion. The framework achieves 8 times power reduction compared with the convolutional recurrent neural network (CRNN) processing-based framework. Our proposed SpikeSEE predicts the response of ganglion cells more accurately with lower energy consumption, which alleviates the precision and power issues of retinal prostheses and provides a potential solution for wearable or implantable prostheses.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002332",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Embedded system",
      "Encoding (memory)",
      "Geometry",
      "Image (mathematics)",
      "Image processing",
      "Law",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Reduction (mathematics)",
      "Representation (politics)",
      "Software engineering",
      "Spike (software development)",
      "Wearable computer"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Chuanqing"
      },
      {
        "surname": "Fang",
        "given_name": "Chaoming"
      },
      {
        "surname": "Zou",
        "given_name": "Yong"
      },
      {
        "surname": "Yang",
        "given_name": "Jie"
      },
      {
        "surname": "Sawan",
        "given_name": "Mohamad"
      }
    ]
  },
  {
    "title": "Tree-structured neural networks: Spatiotemporal dynamics and optimal control",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.039",
    "abstract": "How the network topology drives the response dynamic is a basic question that has not yet been fully answered in neural networks. Elucidating the internal relation between topological structures and dynamics is instrumental in our understanding of brain function. Recent studies have revealed that the ring structure and star structure have a great influence on the dynamical behavior of neural networks. In order to further explore the role of topological structures in the response dynamic, we construct a new tree structure that differs from the ring structure and star structure of traditional neural networks. Considering the diffusion effect, we propose a diffusion neural network model with binary tree structure and multiple delays. How to design control strategies to optimize brain function has also been an open question. Thus, we put forward a novel full-dimensional nonlinear state feedback control strategy to optimize relevant neurodynamics. Some conditions about the local stability and Hopf bifurcation are obtained, and it is proved that the Turing instability does not occur. Moreover, for the formation of the spatially homogeneous periodic solution, some diffusion conditions are also fused together. Finally, several numerical examples are carried out to illustrate the results’ correctness. Meanwhile, some comparative experiments are rendered to reveal the effectiveness of the proposed control strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300223X",
    "keywords": [
      "Acoustics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Dynamics (music)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Tree (set theory)"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Jiajin"
      },
      {
        "surname": "Xiao",
        "given_name": "Min"
      },
      {
        "surname": "Zhao",
        "given_name": "Jing"
      },
      {
        "surname": "Wang",
        "given_name": "Zhengxin"
      },
      {
        "surname": "Yao",
        "given_name": "Yi"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Domain-adaptive message passing graph neural network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.038",
    "abstract": "Cross-network node classification (CNNC), which aims to classify nodes in a label-deficient target network by transferring the knowledge from a source network with abundant labels, draws increasing attention recently. To address CNNC, we propose a domain-adaptive message passing graph neural network (DM-GNN), which integrates graph neural network (GNN) with conditional adversarial domain adaptation. DM-GNN is capable of learning informative representations for node classification that are also transferrable across networks. Firstly, a GNN encoder is constructed by dual feature extractors to separate ego-embedding learning from neighbor-embedding learning so as to jointly capture commonality and discrimination between connected nodes. Secondly, a label propagation node classifier is proposed to refine each node’s label prediction by combining its own prediction and its neighbors’ prediction. In addition, a label-aware propagation scheme is devised for the labeled source network to promote intra-class propagation while avoiding inter-class propagation, thus yielding label-discriminative source embeddings. Thirdly, conditional adversarial domain adaptation is performed to take the neighborhood-refined class-label information into account during adversarial domain adaptation, so that the class-conditional distributions across networks can be better matched. Comparisons with eleven state-of-the-art methods demonstrate the effectiveness of the proposed DM-GNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002253",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Computer science",
      "Discriminative model",
      "Embedding",
      "Engineering",
      "Graph",
      "Inference",
      "Machine learning",
      "Message passing",
      "Node (physics)",
      "Pattern recognition (psychology)",
      "Programming language",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Xiao"
      },
      {
        "surname": "Pan",
        "given_name": "Shirui"
      },
      {
        "surname": "Choi",
        "given_name": "Kup-Sze"
      },
      {
        "surname": "Zhou",
        "given_name": "Xi"
      }
    ]
  },
  {
    "title": "Automatized offline and online exploration to achieve a target dynamics in biohybrid neural circuits built with living and model neurons",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.034",
    "abstract": "Biohybrid circuits of interacting living and model neurons are an advantageous means to study neural dynamics and to assess the role of specific neuron and network properties in the nervous system. Hybrid networks are also a necessary step to build effective artificial intelligence and brain hybridization. In this work, we deal with the automatized online and offline adaptation, exploration and parameter mapping to achieve a target dynamics in hybrid circuits and, in particular, those that yield dynamical invariants between living and model neurons. We address dynamical invariants that form robust cycle-by-cycle relationships between the intervals that build neural sequences from such interaction. Our methodology first attains automated adaptation of model neurons to work in the same amplitude regime and time scale of living neurons. Then, we address the automatized exploration and mapping of the synapse parameter space that lead to a specific dynamical invariant target. Our approach uses multiple configurations and parallel computing from electrophysiological recordings of living neurons to build full mappings, and genetic algorithms to achieve an instance of the target dynamics for the hybrid circuit in a short time. We illustrate and validate such strategy in the context of the study of functional sequences in neural rhythms, which can be easily generalized for any variety of hybrid circuit configuration. This approach facilitates both the building of hybrid circuits and the accomplishment of their scientific goal.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002204",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Artificial neural network",
      "Biological neural network",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Dynamical systems theory",
      "Electronic circuit",
      "Machine learning",
      "Neuroscience",
      "Paleontology",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Reyes-Sanchez",
        "given_name": "Manuel"
      },
      {
        "surname": "Amaducci",
        "given_name": "Rodrigo"
      },
      {
        "surname": "Sanchez-Martin",
        "given_name": "Pablo"
      },
      {
        "surname": "Elices",
        "given_name": "Irene"
      },
      {
        "surname": "Rodriguez",
        "given_name": "Francisco B."
      },
      {
        "surname": "Varona",
        "given_name": "Pablo"
      }
    ]
  },
  {
    "title": "Multi-teacher knowledge distillation based on joint Guidance of Probe and Adaptive Corrector",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.015",
    "abstract": "Knowledge distillation (KD) has been widely used in model compression. But, in the current multi-teacher KD algorithms, the student can only passively acquire the knowledge of the teacher’s middle layer in a single form and all teachers use identical a guiding scheme to the student. To solve these problems, this paper proposes a multi-teacher KD based on joint Guidance of Probe and Adaptive Corrector (GPAC) method. First, GPAC proposes a teacher selection strategy guided by the Linear Classifier Probe (LCP). This strategy allows the student to select better teachers in the middle layer. Teachers are evaluated using the classification accuracy detected by LCP. Then, GPAC designs an adaptive multi-teacher instruction mechanism. The mechanism uses instructional weights to emphasize the student’s predicted direction and reduce the student’s difficulty learning from teachers. At the same time, every teacher can formulate guiding scheme according to the Kullback–Leibler divergence loss of the student and itself. Finally, GPAC develops a multi-level mechanism for adjusting spatial attention loss. this mechanism uses a piecewise function that varies with the number of epochs to adjust the spatial attention loss. This piecewise function classifies the student’ learning about spatial attention into three levels, which can efficiently use spatial attention of teachers. GPAC and the current state-of-the-art distillation methods are tested on CIFAR-10 and CIFAR-100 datasets. The experimental results demonstrate that the proposed method in this paper can obtain higher classification accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002010",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Divergence (linguistics)",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Philosophy",
      "Piecewise",
      "Scheme (mathematics)"
    ],
    "authors": [
      {
        "surname": "Shang",
        "given_name": "Ronghua"
      },
      {
        "surname": "Li",
        "given_name": "Wenzheng"
      },
      {
        "surname": "Zhu",
        "given_name": "Songling"
      },
      {
        "surname": "Jiao",
        "given_name": "Licheng"
      },
      {
        "surname": "Li",
        "given_name": "Yangyang"
      }
    ]
  },
  {
    "title": "Lifelong learning on evolving graphs under the constraints of imbalanced classes and new classes",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.022",
    "abstract": "Lifelong graph learning deals with the problem of continually adapting graph neural network (GNN) models to changes in evolving graphs. We address two critical challenges of lifelong graph learning in this work: dealing with new classes and tackling imbalanced class distributions. The combination of these two challenges is particularly relevant since newly emerging classes typically resemble only a tiny fraction of the data, adding to the already skewed class distribution. We make several contributions: First, we show that the amount of unlabeled data does not influence the results, which is an essential prerequisite for lifelong learning on a sequence of tasks. Second, we experiment with different label rates and show that our methods can perform well with only a tiny fraction of annotated nodes. Third, we propose the gDOC method to detect new classes under the constraint of having an imbalanced class distribution. The critical ingredient is a weighted binary cross-entropy loss function to account for the class imbalance. Moreover, we demonstrate combinations of gDOC with various base GNN models such as GraphSAGE, Simplified Graph Convolution, and Graph Attention Networks. Lastly, our k-neighborhood time difference measure provably normalizes the temporal changes across different graph datasets. With extensive experimentation, we find that the proposed gDOC method is consistently better than a naive adaption of DOC to graphs. Specifically, in experiments using the smallest history size, the out-of-distribution detection score of gDOC is 0.09 compared to 0.01 for DOC. Furthermore, gDOC achieves an Open-F1 score, a combined measure of in-distribution classification and out-of-distribution detection, of 0.33 compared to 0.25 of DOC (32% increase).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002083",
    "keywords": [
      "Arithmetic",
      "Artificial intelligence",
      "Binary number",
      "Computer science",
      "Graph",
      "Lifelong learning",
      "Machine learning",
      "Mathematics",
      "Pedagogy",
      "Psychology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Galke",
        "given_name": "Lukas"
      },
      {
        "surname": "Vagliano",
        "given_name": "Iacopo"
      },
      {
        "surname": "Franke",
        "given_name": "Benedikt"
      },
      {
        "surname": "Zielke",
        "given_name": "Tobias"
      },
      {
        "surname": "Hoffmann",
        "given_name": "Marcel"
      },
      {
        "surname": "Scherp",
        "given_name": "Ansgar"
      }
    ]
  },
  {
    "title": "Collaborative bi-aggregation for directed graph embedding",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.024",
    "abstract": "Directed graph is able to model asymmetric relationships between nodes and research on directed graph embedding is of great significance in downstream graph analysis and inference. Learning source and target embeddings of nodes separately to preserve edge asymmetry has become the dominant approach, but also poses challenge for learning representations of low or even zero in/out degree nodes that are ubiquitous in sparse graphs. In this paper, a collaborative bi-directional aggregation method (COBA) for directed graph embedding is proposed. Firstly, the source and target embeddings of the central node are learned by aggregating from the counterparts of the source and target neighbors, respectively; Secondly, the source/target embeddings of the zero in/out degree central nodes are enhanced by aggregating the counterparts of opposite-directional neighbors (i.e. target/source neighbors); Finally, source and target embeddings of the same node are correlated to achieve collaborative aggregation. Both the feasibility and rationality of the model are theoretically analyzed. Extensive experiments on real-world datasets demonstrate that COBA comprehensively outperforms state-of-the-art methods on multiple tasks and meanwhile validates the effectiveness of proposed aggregation strategies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300268X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Embedding",
      "Engineering",
      "Graph",
      "Graph embedding",
      "Inference",
      "Node (physics)",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Linsong"
      },
      {
        "surname": "Chen",
        "given_name": "Ke-Jia"
      },
      {
        "surname": "Liu",
        "given_name": "Zheng"
      }
    ]
  },
  {
    "title": "Distance metric learning based on the class center and nearest neighbor relationship",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.004",
    "abstract": "Distance metric learning has been a promising technology to improve the performance of algorithms related to distance metrics. The existing distance metric learning methods are either based on the class center or the nearest neighbor relationship. In this work, we propose a new distance metric learning method based on the class center and nearest neighbor relationship (DMLCN). Specifically, when centers of different classes overlap, DMLCN first splits each class into several clusters and uses one center to represent one cluster. Then, a distance metric is learned such that each example is close to the corresponding cluster center and the nearest neighbor relationship is kept for each receptive field. Therefore, while characterizing the local structure of data, the proposed method leads to intra-class compactness and inter-class dispersion simultaneously. Further, to better process complex data, we introduce multiple metrics into DMLCN (MMLCN) by learning a local metric for each center. Following that, a new classification decision rule is designed based on the proposed methods. Moreover, we develop an iterative algorithm to optimize the proposed methods. The convergence and complexity are analyzed theoretically. Experiments on different types of data sets including artificial data sets, benchmark data sets and noise data sets show the feasibility and effectiveness of the proposed methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002356",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Class (philosophy)",
      "Computer science",
      "Data mining",
      "Economics",
      "Geodesy",
      "Geography",
      "Large margin nearest neighbor",
      "Metric (unit)",
      "Nearest neighbor search",
      "Operations management",
      "Pattern recognition (psychology)",
      "k-nearest neighbors algorithm"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Yifeng"
      },
      {
        "surname": "Yang",
        "given_name": "Liming"
      }
    ]
  },
  {
    "title": "A survey of sum–product networks structural learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.010",
    "abstract": "Sum–product networks (SPNs) in deep probabilistic models have made great progress in computer vision, robotics, neuro-symbolic artificial intelligence, natural language processing, probabilistic programming languages, and other fields. Compared with probabilistic graphical models and deep probabilistic models, SPNs can balance the tractability and expressive efficiency. In addition, SPNs remain more interpretable than deep neural models. The expressiveness and complexity of SPNs depend on their own structure. Thus, how to design an effective SPN structure learning algorithm that can balance expressiveness and complexity has become a hot research topic in recent years. In this paper, we review SPN structure learning comprehensively, including the motivation of SPN structure learning, a systematic review of related theories, the proper categorization of different SPN structure learning algorithms, several evaluation approaches and some helpful online resources. Moreover, we discuss some open issues and research directions for SPN structure learning. To our knowledge, this is the first survey to focus specifically on SPN structure learning, and we hope to provide useful references for researchers in related fields.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002514",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Categorization",
      "Computer science",
      "Deep learning",
      "Focus (optics)",
      "Geometry",
      "Graphical model",
      "Machine learning",
      "Mathematics",
      "Optics",
      "Physics",
      "Probabilistic logic",
      "Product (mathematics)"
    ],
    "authors": [
      {
        "surname": "Xia",
        "given_name": "Riting"
      },
      {
        "surname": "Zhang",
        "given_name": "Yan"
      },
      {
        "surname": "Liu",
        "given_name": "Xueyan"
      },
      {
        "surname": "Yang",
        "given_name": "Bo"
      }
    ]
  },
  {
    "title": "An accelerated end-to-end method for solving routing problems",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.003",
    "abstract": "The application of neural network models to solve combinatorial optimization has recently drawn much attention and shown promising results in dealing with similar problems, like Travelling Salesman Problem. The neural network allows to learn solutions based on given problem instances, using reinforcement learning or supervised learning. In this paper, we present a novel end-to-end method to solve routing problems. In specific, we propose a gated cosine-based attention model (GCAM) to train policies, which accelerates the training process and the convergence of policy. Extensive experiments on different scale of routing problems show that the proposed method can achieve faster convergence of the training process than the state-of-the-art deep learning models while achieving solutions of the same quality.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002344",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer network",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "End-to-end principle",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Operating system",
      "Physics",
      "Process (computing)",
      "Quantum mechanics",
      "Reinforcement learning",
      "Routing (electronic design automation)",
      "Scale (ratio)",
      "Travelling salesman problem"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Tianyu"
      },
      {
        "surname": "Shi",
        "given_name": "Xinli"
      },
      {
        "surname": "Xu",
        "given_name": "Xiangping"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Continual learning with invertible generative models",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.020",
    "abstract": "Catastrophic forgetting (CF) happens whenever a neural network overwrites past knowledge while being trained on new tasks. Common techniques to handle CF include regularization of the weights (using, e.g., their importance on past tasks), and rehearsal strategies, where the network is constantly re-trained on past data. Generative models have also been applied for the latter, in order to have endless sources of data. In this paper, we propose a novel method that combines the strengths of regularization and generative-based rehearsal approaches. Our generative model consists of a normalizing flow (NF), a probabilistic and invertible neural network, trained on the internal embeddings of the network. By keeping a single NF throughout the training process, we show that our memory overhead remains constant. In addition, exploiting the invertibility of the NF, we propose a simple approach to regularize the network’s embeddings with respect to past tasks. We show that our method performs favorably with respect to state-of-the-art approaches in the literature, with bounded computational power and memory overheads.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002642",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Generative grammar",
      "Generative model",
      "Invertible matrix",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Pomponi",
        "given_name": "Jary"
      },
      {
        "surname": "Scardapane",
        "given_name": "Simone"
      },
      {
        "surname": "Uncini",
        "given_name": "Aurelio"
      }
    ]
  },
  {
    "title": "Credit assignment with predictive contribution measurement in multi-agent reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.05.021",
    "abstract": "Credit assignment is a crucial issue in multi-agent tasks employing a centralized training and decentralized execution paradigm. While value decomposition has demonstrated strong performance in Q-learning-based approaches and certain Actor–Critic variants, it remains challenging to achieve efficient credit assignment in multi-agent tasks using policy gradient methods due to decomposable value limitations. This paper introduces Predictive Contribution Measurement, an explicit credit assignment method that compares prediction errors among agents and allocates surrogate rewards based on their relevance to global state transitions, with a theoretical guarantee. With multi-agent proximal policy optimization (MAPPO) as a training backend, we propose Predictive Contribution MAPPO (PC-MAPPO). Our experiments demonstrate that PC-MAPPO, with a 10% warm-up phase, outperforms MAPPO, QMIX, and Weighted QMIX on StarCraft multi-agent challenge tasks, particularly in maps requiring heightened cooperation to defeat enemies, such as the map corridor. Employing a pre-trained predictor, PC-MAPPO achieves significantly improved performance on all tested super-hard maps. In parallel training scenarios, PC-MAPPO exhibits superior data efficiency and achieves state-of-the-art performance compared to other methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002654",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Decomposition",
      "Ecology",
      "Internal medicine",
      "Law",
      "Machine learning",
      "Medicine",
      "Political science",
      "Predictive value",
      "Reinforcement learning",
      "Relevance (law)",
      "State (computer science)",
      "Value (mathematics)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Renlong"
      },
      {
        "surname": "Tan",
        "given_name": "Ying"
      }
    ]
  },
  {
    "title": "Semi-supervised deep embedded clustering with pairwise constraints and subset allocation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.016",
    "abstract": "Semi-supervised deep clustering methods attract much attention due to their excellent performance on the end-to-end clustering task. However, it is hard to obtain satisfying clustering results since many overlapping samples in industrial text datasets strongly and incorrectly influence the learning process. Existing methods incorporate prior knowledge in the form of pairwise constraints or class labels, which not only largely ignore the correlation between these two supervision information but also cause the problem of weak-supervised constraint or incorrect strong-supervised label guidance. In order to tackle these problems, we propose a semi-supervised method based on pairwise constraints and subset allocation (PCSA-DEC). We redefine the similarity-based constraint loss by forcing the similarity of samples in the same class much higher than other samples and design a novel subset allocation loss to precisely learn strong-supervised information contained in labels which consistent with unlabeled data. Experimental results on the two industrial text datasets show that our method can yield 8.2%–8.7% improvement in accuracy and 13.4%–19.8% on normalized mutual information over the state-of-the-art method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002022",
    "keywords": [
      "Artificial intelligence",
      "Class (philosophy)",
      "Cluster analysis",
      "Computer science",
      "Constraint (computer-aided design)",
      "Data mining",
      "Economics",
      "Geometry",
      "Image (mathematics)",
      "Machine learning",
      "Management",
      "Mathematics",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Similarity (geometry)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yalin"
      },
      {
        "surname": "Zou",
        "given_name": "Jiangfeng"
      },
      {
        "surname": "Wang",
        "given_name": "Kai"
      },
      {
        "surname": "Liu",
        "given_name": "Chenliang"
      },
      {
        "surname": "Yuan",
        "given_name": "Xiaofeng"
      }
    ]
  },
  {
    "title": "A multi-view co-training network for semi-supervised medical image-based prognostic prediction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.030",
    "abstract": "Prognostic prediction has long been a hotspot in disease analysis and management, and the development of image-based prognostic prediction models has significant clinical implications for current personalized treatment strategies. The main challenge in prognostic prediction is to model a regression problem based on censored observations, and semi-supervised learning has the potential to play an important role in improving the utilization efficiency of censored data. However, there are yet few effective semi-supervised paradigms to be applied. In this paper, we propose a semi-supervised co-training deep neural network incorporating a support vector regression layer for survival time estimation (Co-DeepSVS) that improves the efficiency in utilizing censored data for prognostic prediction. First, we introduce a support vector regression layer in deep neural networks to deal with censored data and directly predict survival time, and more importantly to calculate the labeling confidence of each case. Then, we apply a semi-supervised multi-view co-training framework to achieve accurate prognostic prediction, where labeling confidence estimation with prior knowledge of pseudo time is conducted for each view. Experimental results demonstrate that the proposed Co-DeepSVS has a promising prognostic ability and surpasses most widely used methods on a multi-phase CT dataset. Besides, the introduction of SVR layer makes the model more robust in the presence of follow-up bias.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002162",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Predictive modelling",
      "Regression",
      "Regression analysis",
      "Statistics",
      "Supervised learning",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Hailin"
      },
      {
        "surname": "Wang",
        "given_name": "Siwen"
      },
      {
        "surname": "Liu",
        "given_name": "Bo"
      },
      {
        "surname": "Fang",
        "given_name": "Mengjie"
      },
      {
        "surname": "Cao",
        "given_name": "Runnan"
      },
      {
        "surname": "He",
        "given_name": "Bingxi"
      },
      {
        "surname": "Liu",
        "given_name": "Shengyuan"
      },
      {
        "surname": "Hu",
        "given_name": "Chaoen"
      },
      {
        "surname": "Dong",
        "given_name": "Di"
      },
      {
        "surname": "Wang",
        "given_name": "Ximing"
      },
      {
        "surname": "Wang",
        "given_name": "Hexiang"
      },
      {
        "surname": "Tian",
        "given_name": "Jie"
      }
    ]
  },
  {
    "title": "A direct discretization recurrent neurodynamics method for time-variant nonlinear optimization with redundant robot manipulators",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.040",
    "abstract": "Discrete time-variant nonlinear optimization (DTVNO) problems are commonly encountered in various scientific researches and engineering application fields. Nowadays, many discrete-time recurrent neurodynamics (DTRN) methods have been proposed for solving the DTVNO problems. However, these traditional DTRN methods currently employ an indirect technical route in which the discrete-time derivation process requires to interconvert with continuous-time derivation process. In order to break through this traditional research method, we develop a novel DTRN method based on the inspiring direct discrete technique for solving the DTVNO problem more concisely and efficiently. To be specific, firstly, considering that the DTVNO problem emerging in the discrete-time tracing control of robot manipulator, we further abstract and summarize the mathematical definition of DTVNO problem, and then we define the corresponding error function. Secondly, based on the second-order Taylor expansion, we can directly obtain the DTRN method for solving the DTVNO problem, which no longer requires the derivation process in the continuous-time environment. Whereafter, such a DTRN method is theoretically analyzed and its convergence is demonstrated. Furthermore, numerical experiments confirm the effectiveness and superiority of the DTRN method. In addition, the application experiments of the robot manipulators are presented to further demonstrate the superior performance of the DTRN method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002265",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Discrete time and continuous time",
      "Discretization",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Process (computing)",
      "Quantum mechanics",
      "Robot",
      "Robot manipulator",
      "Statistics",
      "Tracing"
    ],
    "authors": [
      {
        "surname": "Shi",
        "given_name": "Yang"
      },
      {
        "surname": "Sheng",
        "given_name": "Wangrong"
      },
      {
        "surname": "Li",
        "given_name": "Shuai"
      },
      {
        "surname": "Li",
        "given_name": "Bin"
      },
      {
        "surname": "Sun",
        "given_name": "Xiaobing"
      },
      {
        "surname": "Gerontitis",
        "given_name": "Dimitrios K."
      }
    ]
  },
  {
    "title": "Capsule neural tensor networks with multi-aspect information for Few-shot Knowledge Graph Completion",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.041",
    "abstract": "Few-shot Knowledge Graph Completion (FKGC) has recently attracted significant research interest due to its ability to expand few-shot relation coverage in Knowledge Graphs. Prevailing FKGC approaches focus on exploiting the one-hop neighbor information of entities to enhance few-shot relation embedding. However, these methods select one-hop neighbors randomly and neglect the rich multi-aspect information of entities. Although some methods have attempted to leverage Long Short-Term Memory (LSTM) to learn few-shot relation embedding, they are sensitive to the input order. To address these limitations, we propose the Capsule Neural Tensor Networks with Multi-Aspect Information approach (short for InforMix-FKGC). InforMix-FKGC employs a one-hop neighbor selection strategy based on how valuable they are and encodes multi-aspect information of entities, including one-hop neighbors, attributes and literal description. Then, a capsule network is responsible for integrating the support set and deriving few-shot relation embedding. Moreover, a neural tensor network is used to match the query set with the support set. In this way, InforMix-FKGC can learn few-shot relation embedding more precisely so as to enhance the accuracy of FKGC. Extensive experiments on the NELL-One and Wiki-One datasets demonstrate that InforMix-FKGC significantly outperforms ten state-of-the-art methods in terms of Mean Reciprocal Rank and Hits@K.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002277",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Graph",
      "Knowledge graph",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Qianyu"
      },
      {
        "surname": "Yao",
        "given_name": "Jiale"
      },
      {
        "surname": "Tang",
        "given_name": "Xiaoli"
      },
      {
        "surname": "Yu",
        "given_name": "Han"
      },
      {
        "surname": "Jiang",
        "given_name": "Siyu"
      },
      {
        "surname": "Yang",
        "given_name": "Haizhi"
      },
      {
        "surname": "Song",
        "given_name": "Hengjie"
      }
    ]
  },
  {
    "title": "A deep connectome learning network using graph convolution for connectome-disease association study",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.025",
    "abstract": "Multivariate analysis approaches provide insights into the identification of phenotype associations in brain connectome data. In recent years, deep learning methods including convolutional neural network (CNN) and graph neural network (GNN), have shifted the development of connectome-wide association studies (CWAS) and made breakthroughs for connectome representation learning by leveraging deep embedded features. However, most existing studies remain limited by potentially ignoring the exploration of region-specific features, which play a key role in distinguishing brain disorders with high intra-class variations, such as autism spectrum disorder (ASD), and attention deficit hyperactivity disorder (ADHD). Here, we propose a multivariate distance-based connectome network (MDCN) that addresses the local specificity problem by efficient parcellation-wise learning, as well as associating population and parcellation dependencies to map individual differences. The approach incorporating an explainable method, parcellation-wise gradient and class activation map (p-GradCAM), is feasible for identifying individual patterns of interest and pinpointing connectome associations with diseases. We demonstrate the utility of our method on two largely aggregated multicenter public datasets by distinguishing ASD and ADHD from healthy controls and assessing their associations with underlying diseases. Extensive experiments have demonstrated the superiority of MDCN in classification and interpretation, where MDCN outperformed competitive state-of-the-art methods and achieved a high proportion of overlap with previous findings. As a CWAS-guided deep learning method, our proposed MDCN framework may narrow the bridge between deep learning and CWAS approaches, and provide new insights for connectome-wide association studies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023002113",
    "keywords": [
      "Artificial intelligence",
      "Association (psychology)",
      "Computer science",
      "Connectome",
      "Connectomics",
      "Convolutional neural network",
      "Deep learning",
      "Environmental health",
      "Functional connectivity",
      "Graph",
      "Machine learning",
      "Medicine",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Population",
      "Psychology",
      "Psychotherapist",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yanwu"
      },
      {
        "surname": "Ye",
        "given_name": "Chenfei"
      },
      {
        "surname": "Ma",
        "given_name": "Ting"
      }
    ]
  },
  {
    "title": "Multi-level Feature Interaction and Efficient Non-Local Information Enhanced Channel Attention for image dehazing",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.017",
    "abstract": "Image dehazing is a challenging task in computer vision. Currently, most dehazing methods adopt the U-Net architecture that directly fuses the decoding layer with the corresponding scale encoding layer. These methods ignore the effective utilization of different encoding layer information and existing feature information dilute problems, resulting in suboptimal edge details and overall scene aspects of dehazed image restoration. In addition, Squeeze and Excitation (SE) channel attention is widely used in dehazing network. However, the two fully-connected layers of dimensionality reduction operation in SE will negatively affect the weight prediction of feature channels, thus reducing the performance of the dehazing network. To solve the above problems, we propose a Multi-level Feature Interaction and Non-local Information Enhanced Channel Attention (MFINEA) dehazing model. Specifically, a multi-level feature interaction module is proposed to enable the decoding layer to fuse shallow and deep feature information extracted from different encoding layers for better recovery of edge details and the overall scene. Furthermore, an efficient non-local information enhanced channel attention module is proposed to mine more effective feature channel information for the weight assignment of the feature maps. The experimental results on several challenging benchmark datasets show that our MFINEA outperforms the state-of-the-art dehazing methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300134X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Channel (broadcasting)",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Decoding methods",
      "Encoding (memory)",
      "Enhanced Data Rates for GSM Evolution",
      "Feature (linguistics)",
      "Geodesy",
      "Geography",
      "Layer (electronics)",
      "Linguistics",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Philosophy"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Hang"
      },
      {
        "surname": "Li",
        "given_name": "Bohui"
      },
      {
        "surname": "Dan",
        "given_name": "Zhiping"
      },
      {
        "surname": "Hu",
        "given_name": "Wei"
      },
      {
        "surname": "Du",
        "given_name": "Bo"
      },
      {
        "surname": "Yang",
        "given_name": "Wen"
      },
      {
        "surname": "Wan",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "On the value of label and semantic information in domain generalization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.023",
    "abstract": "In this work, we tackle the domain generalization (DG) problem aiming to learn a universal predictor on several source domains and deploy it on an unseen target domain. Many existing DG approaches were mainly motivated by domain adaptation techniques to align the marginal feature distribution but ignored conditional relations and labeling information in the source domains, which are critical to ensure successful knowledge transfer. Although some recent advances started to take advantage of conditional semantic distributions, theoretical justifications were still missing. To this end, we investigate the theoretical guarantee for a successful generalization process by focusing on how to control the target domain error. Our results reveal that to control the target risk, one should jointly control the source errors that are weighted according to label information and align the semantic conditional distributions between different source domains. The theoretical analysis then leads to an efficient algorithm to control the label distributions as well as match the semantic conditional distributions. To verify the effectiveness of our method, we evaluate it against recent baseline algorithms on several benchmarks. We also conducted experiments to verify the performance under label distribution shift to demonstrate the necessity of leveraging the labeling and semantic information. Empirical results show that the proposed method outperforms most of the baseline methods and shows state-of-the-art performances.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001570",
    "keywords": [
      "Artificial intelligence",
      "Baseline (sea)",
      "Computer science",
      "Conditional probability distribution",
      "Data mining",
      "Domain (mathematical analysis)",
      "Feature (linguistics)",
      "Generalization",
      "Geology",
      "Linguistics",
      "Machine learning",
      "Marginal distribution",
      "Mathematical analysis",
      "Mathematics",
      "Oceanography",
      "Operating system",
      "Philosophy",
      "Process (computing)",
      "Random variable",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Fan"
      },
      {
        "surname": "Chen",
        "given_name": "Yuyi"
      },
      {
        "surname": "Yang",
        "given_name": "Shichun"
      },
      {
        "surname": "Wang",
        "given_name": "Boyu"
      },
      {
        "surname": "Chaib-draa",
        "given_name": "Brahim"
      }
    ]
  },
  {
    "title": "An octonion-based nonlinear echo state network for speech emotion recognition in Metaverse",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.026",
    "abstract": "While the Metaverse is becoming a popular trend and drawing much attention from academia, society, and businesses, processing cores used in its infrastructures need to be improved, particularly in terms of signal processing and pattern recognition. Accordingly, the speech emotion recognition (SER) method plays a crucial role in creating the Metaverse platforms more usable​ and enjoyable for its users. However, existing SER methods continue to be plagued by two significant problems in the online environment. The shortage of adequate engagement and customization between avatars and users is recognized as the first issue and the second problem is related to the complexity of SER problems in the Metaverse as we face people and their digital twins or avatars. This is why developing efficient machine learning (ML) techniques specified for hypercomplex signal processing is essential to enhance the impressiveness and tangibility of the Metaverse platforms. As a solution, echo state networks (ESNs), which are an ML powerful tool for SER, can be an appropriate technique to enhance the Metaverse’s foundations in this area. Nevertheless, ESNs have some technical issues restricting them from a precise and reliable analysis, especially in the aspect of high-dimensional data. The most significant limitation of these networks is the high memory consumption caused by their reservoir structure in face of high-dimensional signals. To solve all problems associated with ESNs and their application in the Metaverse, we have come up with a novel structure for ESNs empowered by octonion algebra called NO2GESNet. Octonion numbers have eight dimensions, compactly display high-dimensional data, and improve the network precision and performance in comparison to conventional ESNs. The proposed network also solves the weaknesses of the ESNs in the presentation of the higher-order statistics to the output layer by equipping it with a multidimensional bilinear filter. Three comprehensive scenarios to use the proposed network in the Metaverse have been designed and analyzed, not only do they show the accuracy and performance of the proposed approach, but also the ways how SER can be employed in the Metaverse platforms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001600",
    "keywords": [
      "Algorithm",
      "Computer science",
      "Computer security",
      "Echo (communications protocol)",
      "Face (sociological concept)",
      "Human–computer interaction",
      "Linguistics",
      "Metaverse",
      "Multimedia",
      "Philosophy",
      "State (computer science)",
      "USable",
      "Virtual reality"
    ],
    "authors": [
      {
        "surname": "Daneshfar",
        "given_name": "Fatemeh"
      },
      {
        "surname": "Jamshidi",
        "given_name": "Mohammad (Behdad)"
      }
    ]
  },
  {
    "title": "Resilient fixed-time stabilization of switched neural networks subjected to impulsive deception attacks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.003",
    "abstract": "This article focuses on the resilient fixed-time stabilization of switched neural networks (SNNs) under impulsive deception attacks. A novel theorem for the fixed-time stability of impulsive systems is established by virtue of the comparison principle. Existing fixed-time stability theorems for impulsive systems assume that the impulsive strength is not greater than 1, while the proposed theorem removes this assumption. SNNs subjected to impulsive deception attacks are modeled as impulsive systems. Some sufficient criteria are derived to ensure the stabilization of SNNs in fixed time. The estimation of the upper bound for the settling time is also given. The influence of impulsive attacks on the convergence time is discussed. A numerical example and an application to Chua’s circuit system are given to demonstrate the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001806",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Deception",
      "Economic growth",
      "Economics",
      "Engineering",
      "Fixed point",
      "Law",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Political science",
      "Settling time",
      "Stability (learning theory)",
      "Step response",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Bao",
        "given_name": "Yuangui"
      },
      {
        "surname": "Zhang",
        "given_name": "Yijun"
      },
      {
        "surname": "Zhang",
        "given_name": "Baoyong"
      }
    ]
  },
  {
    "title": "Online continual learning with declarative memory",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.025",
    "abstract": "Deep neural networks are enjoying unprecedented attention and success in recent years. However, catastrophic forgetting undermines the performance of deep models when the training data are arrived sequentially in an online multi-task learning fashion. To address this issue, we propose a novel method named continual learning with declarative memory (CLDM) in this paper. Specifically, our idea is inspired by the structure of human memory. Declarative memory is a major component of long-term memory which helps human beings memorize past experiences and facts. In this paper, we propose to formulate declarative memory as task memory and instance memory in neural networks to overcome catastrophic forgetting. Intuitively, the instance memory recalls the input–output relations (fact) in previous tasks, which is implemented by jointly rehearsing previous samples and learning current tasks as replaying-based methods act. In addition, the task memory aims to capture long-term task correlation information across task sequences to regularize the learning of the current task, thus preserving task-specific weight realizations (experience) in high task-specific layers. In this work, we implement a concrete instantiation of the proposed task memory by leveraging a recurrent unit. Extensive experiments on seven continual learning benchmarks verify that our proposed method is able to outperform previous approaches with tremendous improvements by retaining the information of both samples and tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001594",
    "keywords": [
      "Artificial intelligence",
      "Cognition",
      "Cognitive psychology",
      "Cognitive science",
      "Computer science",
      "Declarative memory",
      "Machine learning",
      "Neuroscience",
      "Procedural memory",
      "Programming language",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Zhe"
      },
      {
        "surname": "Du",
        "given_name": "Zhekai"
      },
      {
        "surname": "Wang",
        "given_name": "Ruijin"
      },
      {
        "surname": "Gan",
        "given_name": "Ruimeng"
      },
      {
        "surname": "Li",
        "given_name": "Jingjing"
      }
    ]
  },
  {
    "title": "Meta attention for Off-Policy Actor-Critic",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.024",
    "abstract": "Off-Policy Actor-Critic methods can effectively exploit past experiences and thus they have achieved great success in various reinforcement learning tasks. In many image-based and multi-agent tasks, attention mechanism has been employed in Actor-Critic methods to improve their sampling efficiency. In this paper, we propose a meta attention method for state-based reinforcement learning tasks, which combines attention mechanism and meta-learning based on the Off-Policy Actor-Critic framework. Unlike previous attention-based work, our meta attention method introduces attention in the Actor and the Critic of the typical Actor-Critic framework, rather than in multiple pixels of an image or multiple information sources in specific image-based control tasks or multi-agent systems. In contrast to existing meta-learning methods, the proposed meta-attention approach is able to function in both the gradient-based training phase and the agent’s decision-making process. The experimental results demonstrate the superiority of our meta-attention method in various continuous control tasks, which are based on the Off-Policy Actor-Critic methods including DDPG and TD3.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001582",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Economics",
      "Exploit",
      "Machine learning",
      "Management",
      "Meta learning (computer science)",
      "Operating system",
      "Process (computing)",
      "Reinforcement learning",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Jiateng"
      },
      {
        "surname": "Huang",
        "given_name": "Wanrong"
      },
      {
        "surname": "Lan",
        "given_name": "Long"
      },
      {
        "surname": "Wu",
        "given_name": "Dan"
      }
    ]
  },
  {
    "title": "Incomplete multi-view clustering network via nonlinear manifold embedding and probability-induced loss",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.013",
    "abstract": "Incomplete multi-view clustering, which included missing data in different views, is more challenging than multi-view clustering. For the purpose of eliminating the negative influence of incomplete data, researchers have proposed a series of solutions. However, the present incomplete multi-view clustering methods still confront three major issues: (1) The interference of redundant features hinders these methods to learn the most discriminative features. (2) The importance role of local structure is not considered during clustering. (3) These methods fail to utilize data distribution information to guide models update to decrease the effects of outliers and noise. To address above issues, a novel deep clustering network which exerted on incomplete multi-view data was proposed in this paper. We combine multi-view autoencoders with nonlinear manifold embedding method UMAP to extract latent consistent features of incomplete multi-view data. In the clustering method, we introduce Gaussian Mixture Model (GMM) to fit the complex distribution of data and deal with the interference of outliers. In addition, we reasonably utilize the probability distribution information generated by GMM, using probability-induced loss function to integrate feature learning and clustering as a joint framework. In experiments conducted on multiple benchmark datasets, our method captures incomplete multi-view data features effectively and perform excellent.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001302",
    "keywords": [
      "Artificial intelligence",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Computer science",
      "Constrained clustering",
      "Correlation clustering",
      "Data mining",
      "Data stream clustering",
      "Dimensionality reduction",
      "Discriminative model",
      "Embedding",
      "Feature (linguistics)",
      "Joint probability distribution",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Mixture model",
      "Nonlinear dimensionality reduction",
      "Outlier",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Cheng"
      },
      {
        "surname": "Cui",
        "given_name": "Jinrong"
      },
      {
        "surname": "Fu",
        "given_name": "Yulu"
      },
      {
        "surname": "Huang",
        "given_name": "Dong"
      },
      {
        "surname": "Zhao",
        "given_name": "Min"
      },
      {
        "surname": "Li",
        "given_name": "Lusi"
      }
    ]
  },
  {
    "title": "Lifelong learning with Shared and Private Latent Representations learned through synaptic intelligence",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.005",
    "abstract": "This paper explores a novel lifelong learning method with Shared and Private Latent Representations (SPLR), which are learned through synaptic intelligence. To solve a sequence of tasks, by considering the entire parameter learning trajectory, SPLR can learn task-invariant representation which changes little, and task-specific features that change greatly along the entire parameter updating trajectory. Therefore, in the lifelong learning scenarios, our model can obtain a task-invariant structure shared by all tasks and also contain some private properties that are task-specific to each task. To reduce the parameter quantity, a ℓ 1 regularization to promote sparsity is employed in the weights. We use multiple datasets under lifelong learning scenes to verify our SPLR, on these datasets it can get comparable performance compared with existing lifelong learning approaches, and learn a sparse network which means fewer parameters while requiring less model training time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300182X",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Economics",
      "Invariant (physics)",
      "Law",
      "Lifelong learning",
      "Machine learning",
      "Management",
      "Mathematical physics",
      "Mathematics",
      "Multi-task learning",
      "Pedagogy",
      "Physics",
      "Political science",
      "Politics",
      "Psychology",
      "Regularization (linguistics)",
      "Representation (politics)",
      "Task (project management)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yang"
      },
      {
        "surname": "Huang",
        "given_name": "Jie"
      },
      {
        "surname": "Hu",
        "given_name": "Dexiu"
      }
    ]
  },
  {
    "title": "Dynamic event-triggered controller design for nonlinear systems: Reinforcement learning strategy",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.008",
    "abstract": "The current investigation aims at the optimal control problem for discrete-time nonstrict-feedback nonlinear systems by invoking the reinforcement learning-based backstepping technique and neural networks. The dynamic-event-triggered control strategy introduced in this paper can alleviate the communication frequency between the actuator and controller. Based on the reinforcement learning strategy, actor–critic neural networks are employed to implement the n-order backstepping framework. Then, a neural network weight-updated algorithm is developed to minimize the computational burden and avoid the local optimal problem. Furthermore, a novel dynamic-event-triggered strategy is introduced, which can remarkably outperform the previously studied static-event-triggered strategy. Moreover, combined with the Lyapunov stability theory, all signals in the closed-loop system are strictly proven to be semiglobal uniformly ultimately bounded. Finally, the practicality of the offered control algorithms is further elucidated by the numerical simulation examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001855",
    "keywords": [
      "Actuator",
      "Adaptive control",
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Backstepping",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Lyapunov function",
      "Lyapunov stability",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Optimal control",
      "Physics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Zichen"
      },
      {
        "surname": "Wang",
        "given_name": "Xin"
      },
      {
        "surname": "Pang",
        "given_name": "Ning"
      }
    ]
  },
  {
    "title": "Robust data hiding for JPEG images with invertible neural network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.037",
    "abstract": "JPEG compression will cause severe distortion to the shared compressed image, which brings great challenges to extracting messages correctly from the stego image. To address such challenges, we propose a novel end-to-end robust data hiding scheme for JPEG images. The embedding and extracting secret messages on the quantized discrete cosine transform (DCT) coefficients are implemented by the bi-directional process of the invertible neural network (INN), which can provide intrinsic robustness against lossy JPEG compression. We design a JPEG compression attack module to simulate the JPEG compression process, which helps the network automatically learn how to recover the secret message from JPEG compressed image. Experimental results have demonstrated that our method achieves strong robustness against lossy JPEG compression, and also significantly improves the security compared with the existing data hiding methods on the premise of ensuring image quality and high capacity. For example, the detection error of our method against XuNet has been increased by 3.45% over the existing data hiding methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001727",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Compression artifact",
      "Computer science",
      "Computer vision",
      "Data compression",
      "Discrete cosine transform",
      "Embedding",
      "Gene",
      "Image (mathematics)",
      "Image compression",
      "Image processing",
      "Information hiding",
      "JPEG",
      "Lossless JPEG",
      "Lossless compression",
      "Lossy compression",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Transform coding"
    ],
    "authors": [
      {
        "surname": "Shang",
        "given_name": "Fei"
      },
      {
        "surname": "Lan",
        "given_name": "Yuhang"
      },
      {
        "surname": "Yang",
        "given_name": "Jianhua"
      },
      {
        "surname": "Li",
        "given_name": "Enping"
      },
      {
        "surname": "Kang",
        "given_name": "Xiangui"
      }
    ]
  },
  {
    "title": "Adams-based hierarchical features fusion network for image dehazing",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.021",
    "abstract": "Recent developments in Convolutional Neural Networks (CNNs) have made them one of the most powerful image dehazing methods. In particular, the Residual Networks (ResNets), which can avoid the vanishing gradient problem effectively, are widely deployed. To understand the success of ResNets, recent mathematical analysis of ResNets reveals that a ResNet has a similar formulation as the Euler method in solving the Ordinary Differential Equations (ODE’s). Hence, image dehazing which can be formulated as an optimal control problem in dynamical systems can be solved by a single-step optimal control method, such as the Euler method. This optimal control viewpoint provides a new perspective to address the problem of image restoration. Motivated by the advantages of multi-step optimal control solvers in ODE’s, which include better stability and efficiency than single-step solvers, e.g. Euler, we propose the Adams-based Hierarchical Feature Fusion Network (AHFFN) for image dehazing with modules inspired by a multi-step optimal control method named the Adams–Bashforth method. Firstly, we extend a multi-step Adams–Bashforth method to the corresponding Adams block, which achieves a higher accuracy than that of single-step solvers because of its more effective use of intermediate results. Then, we stack multiple Adams blocks to mimic the discrete approximation process of an optimal control in a dynamical system. To improve the results, the hierarchical features from stacked Adams blocks are fully used by combining Hierarchical Feature Fusion (HFF) and Lightweight Spatial Attention (LSA) with Adams blocks to form a new Adams module. Finally, we not only use HFF and LSA to fuse features, but also highlight important spatial information in each Adams module for estimating the clear image. The experimental results using synthetic and real images demonstrate that the proposed AHFFN obtains better accuracy and visual results than that of state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001557",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Backward Euler method",
      "Block (permutation group theory)",
      "Computer science",
      "Differential equation",
      "Euler equations",
      "Euler method",
      "Euler's formula",
      "Feature (linguistics)",
      "Geometry",
      "Image (mathematics)",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Ode",
      "Ordinary differential equation",
      "Philosophy"
    ],
    "authors": [
      {
        "surname": "Yin",
        "given_name": "Shibai"
      },
      {
        "surname": "Hu",
        "given_name": "Shuhao"
      },
      {
        "surname": "Wang",
        "given_name": "Yibin"
      },
      {
        "surname": "Wang",
        "given_name": "Weixing"
      },
      {
        "surname": "Yang",
        "given_name": "Yee-Hong"
      }
    ]
  },
  {
    "title": "A novel semi-supervised meta learning method for subject-transfer brain–computer interface",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.039",
    "abstract": "The brain–computer interface (BCI) provides a direct communication pathway between the human brain and external devices. However, the models trained for existing subjects perform poorly on new subjects, which is termed the subject calibration problem. In this paper, we propose a semi-supervised meta learning (SSML) method for subject-transfer calibration. The proposed SSML learns a model-agnostic meta learner with existing subjects and then fine-tunes the meta learner in a semi-supervised learning manner, i.e. using a few labelled samples and many unlabelled samples of the target subject for calibration. It is significant for BCI applications in which labelled data are scarce or expensive while unlabelled data are readily available. Three different BCI paradigms are tested: event-related potential detection, emotion recognition and sleep staging. The SSML achieved classification accuracies of 0.95, 0.89 and 0.83 in the benchmark datasets of three paradigms. The runtime complexity of SSML grows linearly as the number of samples of target subject increases so that is possible to apply it in real-time systems. This study is the first attempt to apply semi-supervised model-agnostic meta learning methodology for subject calibration. The experimental results demonstrated the effectiveness and potential of the SSML method for subject-transfer BCI applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001740",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Brain–computer interface",
      "Bubble",
      "Calibration",
      "Computer science",
      "Economics",
      "Electroencephalography",
      "Geodesy",
      "Geography",
      "Interface (matter)",
      "Library science",
      "Machine learning",
      "Management",
      "Mathematics",
      "Maximum bubble pressure method",
      "Meta learning (computer science)",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Psychiatry",
      "Psychology",
      "Statistics",
      "Subject (documents)",
      "Task (project management)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Jingcong"
      },
      {
        "surname": "Wang",
        "given_name": "Fei"
      },
      {
        "surname": "Huang",
        "given_name": "Haiyun"
      },
      {
        "surname": "Qi",
        "given_name": "Feifei"
      },
      {
        "surname": "Pan",
        "given_name": "Jiahui"
      }
    ]
  },
  {
    "title": "Differential evolution based dual adversarial camouflage: Fooling human eyes and object detectors",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.041",
    "abstract": "Deep neural network-based object detectors are vulnerable to adversarial examples. Among existing works to fool object detectors, the camouflage-based method is more often adopted due to its adaptation to multi-view scenarios and non-planar objects. However, most of them can still be easily observed by human eyes, which limits their application in the real world. To fool human eyes and object detectors simultaneously, we propose a differential evolution based dual adversarial camouflage method. Specifically, we try to obtain the camouflage texture by the two-stage training, which can be wrapped over the surface of the object. In the first stage, we optimize the global texture to minimize the discrepancy between the rendered object and the scene background, making human eyes difficult to distinguish. In the second stage, we design three loss functions to optimize the local texture, which is selected from the global texture, making object detectors ineffective. In addition, we introduce the differential evolution algorithm to search for the near-optimal areas of the object to attack, improving the adversarial performance under certain attack area limitations. Experimental results show that our proposed method can obtain a good trade-off between fooling human eyes and object detectors under multiple specific scenes and objects.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001764",
    "keywords": [
      "Adaptation (eye)",
      "Adversarial system",
      "Artificial intelligence",
      "Camouflage",
      "Computer science",
      "Computer vision",
      "Detector",
      "Human eye",
      "Object (grammar)",
      "Object detection",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Jialiang"
      },
      {
        "surname": "Yao",
        "given_name": "Wen"
      },
      {
        "surname": "Jiang",
        "given_name": "Tingsong"
      },
      {
        "surname": "Wang",
        "given_name": "Donghua"
      },
      {
        "surname": "Chen",
        "given_name": "Xiaoqian"
      }
    ]
  },
  {
    "title": "Functional connectivity learning via Siamese-based SPD matrix representation of brain imaging data",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.004",
    "abstract": "Measurement of brain functional connectivity has become a dominant approach to explore the interaction dynamics between brain regions of subjects under examination. Conventional functional connectivity measures largely originate from deterministic models on empirical analysis, usually demanding application-specific settings (e.g., Pearson’s Correlation and Mutual Information). To bridge the technical gap, this study proposes a Siamese-based Symmetric Positive Definite (SPD) Matrix Representation framework (SiameseSPD-MR) to derive the functional connectivity of brain imaging data (BID) such as Electroencephalography (EEG), thus the alternative application-independent measure (in the form of SPD matrix) can be automatically learnt: (1) SiameseSPD-MR first exploits graph convolution to extract the representative features of BID with the adjacency matrix computed considering the anatomical structure; (2) Adaptive Gaussian kernel function then applies to obtain the functional connectivity representations from the deep features followed by SPD matrix transformation to address the intrinsic functional characteristics; and (3) Two-branch (Siamese) networks are combined via an element-wise product followed by a dense layer to derive the similarity between the pairwise inputs. Experimental results on two EEG datasets (autism spectrum disorder, emotion) indicate that (1) SiameseSPD-MR can capture more significant differences in functional connectivity between neural states than the state-of-the-art counterparts do, and these findings properly highlight the typical EEG characteristics of ASD subjects, and (2) the obtained functional connectivity representations conforming to the proposed measure can act as meaningful markers for brain network analysis and ASD discrimination.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001818",
    "keywords": [
      "Adjacency matrix",
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Data mining",
      "Electroencephalography",
      "Functional connectivity",
      "Functional data analysis",
      "Graph",
      "Kernel (algebra)",
      "Law",
      "Machine learning",
      "Mathematics",
      "Measure (data warehouse)",
      "Neuroscience",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Psychology",
      "Representation (politics)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Yunbo"
      },
      {
        "surname": "Chen",
        "given_name": "Dan"
      },
      {
        "surname": "Wu",
        "given_name": "Jia"
      },
      {
        "surname": "Tu",
        "given_name": "Weiping"
      },
      {
        "surname": "Monaghan",
        "given_name": "Jessica J.M."
      },
      {
        "surname": "Sowman",
        "given_name": "Paul"
      },
      {
        "surname": "Mcalpine",
        "given_name": "David"
      }
    ]
  },
  {
    "title": "Exploring personalization via federated representation Learning on non-IID data",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.007",
    "abstract": "Federated Learning (FL) can learn a global model across decentralized data over different clients. However, it is susceptible to statistical heterogeneity of client-specific data. Clients focus on optimizing for their individual target distributions, which would yield divergence of the global model due to inconsistent data distributions. Moreover, federated learning approaches adhere to the scheme of collaboratively learning representations and classifiers, further exacerbating such inconsistency and resulting in imbalanced features and biased classifiers. Hence, in this paper, we propose an independent two-stage personalized FL framework, i.e., Fed-RepPer, to separate representation learning from classification in federated learning. First, the client-side feature representation models are learned using supervised contrastive loss, which enables local objectives consistently, i.e., learning robust representations on distinct data distributions. Local representation models are aggregated into the common global representation model. Then, in the second stage, personalization is studied by learning different classifiers for each client based on the global representation model. The proposed two-stage learning scheme is examined in lightweight edge computing that involves devices with constrained computation resources. Experiments on various datasets (CIFAR-10/100, CINIC-10) and heterogeneous data setups show that Fed-RepPer outperforms alternatives by utilizing flexibility and personalization on non-IID data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001843",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "External Data Representation",
      "Feature (linguistics)",
      "Feature learning",
      "Flexibility (engineering)",
      "Law",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Personalization",
      "Philosophy",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Scheme (mathematics)",
      "Statistics",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Jing",
        "given_name": "Changxing"
      },
      {
        "surname": "Huang",
        "given_name": "Yan"
      },
      {
        "surname": "Zhuang",
        "given_name": "Yihong"
      },
      {
        "surname": "Sun",
        "given_name": "Liyan"
      },
      {
        "surname": "Xiao",
        "given_name": "Zhenlong"
      },
      {
        "surname": "Huang",
        "given_name": "Yue"
      },
      {
        "surname": "Ding",
        "given_name": "Xinghao"
      }
    ]
  },
  {
    "title": "Fixed-time synchronization of delayed memristive neural networks with impulsive effects via novel fixed-time stability theorem",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.036",
    "abstract": "In this study, the fixed-time synchronization (FXTS) of delayed memristive neural networks (MNNs) with hybrid impulsive effects is explored. To investigate the FXTS mechanism, we first propose a novel theorem about the fixed-time stability (FTS) of impulsive dynamical systems, where the coefficients are extended to functions and the derivatives of Lyapunov function (LF) are allowed to be indefinite. After that, we obtain some new sufficient conditions for achieving FXTS of the system within a settling-time using three different controllers. At last, to verify the correctness and effectiveness of our results, a numerical simulation was conducted. Significantly, the impulse strength studied in this paper can take different values at different points, so it can be regarded as a time-varying function, unlike those in previous studies (the impulse strength takes the same value at different points). Hence, the mechanisms in this article are of more practical applicability.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001715",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Correctness",
      "Electrical engineering",
      "Engineering",
      "Fixed point",
      "Impulse (physics)",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Memristor",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Settling time",
      "Stability (learning theory)",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Dongshu"
      },
      {
        "surname": "Li",
        "given_name": "Luke"
      }
    ]
  },
  {
    "title": "Graph contrastive learning with implicit augmentations",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.001",
    "abstract": "Existing graph contrastive learning methods rely on augmentation techniques based on random perturbations (e.g., randomly adding or dropping edges and nodes). Nevertheless, altering certain edges or nodes can unexpectedly change the graph characteristics, and choosing the optimal perturbing ratio for each dataset requires onerous manual tuning. In this paper, we introduce Implicit Graph Contrastive Learning (iGCL), which utilizes augmentations in the latent space learned from a Variational Graph Auto-Encoder by reconstructing graph topological structure. Importantly, instead of explicitly sampling augmentations from latent distributions, we further propose an upper bound for the expected contrastive loss to improve the efficiency of our learning algorithm. Thus, graph semantics can be preserved within the augmentations in an intelligent way without arbitrary manual design or prior human knowledge. Experimental results on both graph-level and node-level show that the proposed method achieves state-of-the-art accuracy on downstream classification tasks compared to other graph contrastive baselines, where ablation studies in the end demonstrate the effectiveness of modules in iGCL.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001788",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Pattern recognition (psychology)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Liang",
        "given_name": "Huidong"
      },
      {
        "surname": "Du",
        "given_name": "Xingjian"
      },
      {
        "surname": "Zhu",
        "given_name": "Bilei"
      },
      {
        "surname": "Ma",
        "given_name": "Zejun"
      },
      {
        "surname": "Chen",
        "given_name": "Ke"
      },
      {
        "surname": "Gao",
        "given_name": "Junbin"
      }
    ]
  },
  {
    "title": "Amortized Bayesian inference on generative dynamical network models of epilepsy using deep neural density estimators",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.040",
    "abstract": "Whole-brain modeling of epilepsy combines personalized anatomical data with dynamical models of abnormal activities to generate spatio-temporal seizure patterns as observed in brain imaging data. Such a parametric simulator is equipped with a stochastic generative process, which itself provides the basis for inference and prediction of the local and global brain dynamics affected by disorders. However, the calculation of likelihood function at whole-brain scale is often intractable. Thus, likelihood-free algorithms are required to efficiently estimate the parameters pertaining to the hypothetical areas, ideally including the uncertainty. In this study, we introduce the simulation-based inference for the virtual epileptic patient model (SBI-VEP), enabling us to amortize the approximate posterior of the generative process from a low-dimensional representation of whole-brain epileptic patterns. The state-of-the-art deep learning algorithms for conditional density estimation are used to readily retrieve the statistical relationships between parameters and observations through a sequence of invertible transformations. We show that the SBI-VEP is able to efficiently estimate the posterior distribution of parameters linked to the extent of the epileptogenic and propagation zones from sparse intracranial electroencephalography recordings. The presented Bayesian methodology can deal with non-linear latent dynamics and parameter degeneracy, paving the way for fast and reliable inference on brain disorders from neuroimaging modalities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001752",
    "keywords": [
      "Artificial intelligence",
      "Bayes' theorem",
      "Bayesian inference",
      "Bayesian probability",
      "Computer science",
      "Estimator",
      "Generative grammar",
      "Generative model",
      "Inference",
      "Machine learning",
      "Mathematics",
      "Parametric statistics",
      "Pattern recognition (psychology)",
      "Posterior probability",
      "Statistical inference",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Hashemi",
        "given_name": "Meysam"
      },
      {
        "surname": "Vattikonda",
        "given_name": "Anirudh N."
      },
      {
        "surname": "Jha",
        "given_name": "Jayant"
      },
      {
        "surname": "Sip",
        "given_name": "Viktor"
      },
      {
        "surname": "Woodman",
        "given_name": "Marmaduke M."
      },
      {
        "surname": "Bartolomei",
        "given_name": "Fabrice"
      },
      {
        "surname": "Jirsa",
        "given_name": "Viktor K."
      }
    ]
  },
  {
    "title": "Few-shot Molecular Property Prediction via Hierarchically Structured Learning on Relation Graphs",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.034",
    "abstract": "This paper studies few-shot molecular property prediction, which is a fundamental problem in cheminformatics and drug discovery. More recently, graph neural network based model has gradually become the theme of molecular property prediction. However, there is a natural deficiency for existing methods, that is, the scarcity of molecules with desired properties, which makes it hard to build an effective predictive model. In this paper, we propose a novel framework called Hierarchically Structured Learning on Relation Graphs (HSL-RG) for molecular property prediction, which explores the structural semantics of a molecule from both global-level and local-level granularities. Technically, we first leverage graph kernels to construct relation graphs to globally communicate molecular structural knowledge from neighboring molecules and then design self-supervised learning signals of structure optimization to locally learn transformation-invariant representations from molecules themselves. Moreover, we propose a task-adaptive meta-learning algorithm to provide meta knowledge customization for different tasks in few-shot scenarios. Experiments on multiple real-life benchmark datasets show that HSL-RG is superior to existing state-of-the-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001685",
    "keywords": [
      "Artificial intelligence",
      "Cheminformatics",
      "Chemistry",
      "Computational chemistry",
      "Computer science",
      "Data mining",
      "Epistemology",
      "Knowledge graph",
      "Leverage (statistics)",
      "Machine learning",
      "Philosophy",
      "Property (philosophy)",
      "Relation (database)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Ju",
        "given_name": "Wei"
      },
      {
        "surname": "Liu",
        "given_name": "Zequn"
      },
      {
        "surname": "Qin",
        "given_name": "Yifang"
      },
      {
        "surname": "Feng",
        "given_name": "Bin"
      },
      {
        "surname": "Wang",
        "given_name": "Chen"
      },
      {
        "surname": "Guo",
        "given_name": "Zhihui"
      },
      {
        "surname": "Luo",
        "given_name": "Xiao"
      },
      {
        "surname": "Zhang",
        "given_name": "Ming"
      }
    ]
  },
  {
    "title": "An explainable artificial intelligence approach to spatial navigation based on hippocampal circuitry",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.030",
    "abstract": "Learning to navigate a complex environment is not a difficult task for a mammal. For example, finding the correct way to exit a maze following a sequence of cues, does not need a long training session. Just a single or a few runs through a new environment is, in most cases, sufficient to learn an exit path starting from anywhere in the maze. This ability is in striking contrast with the well-known difficulty that any deep learning algorithm has in learning a trajectory through a sequence of objects. Being able to learn an arbitrarily long sequence of objects to reach a specific place could take, in general, prohibitively long training sessions. This is a clear indication that current artificial intelligence methods are essentially unable to capture the way in which a real brain implements a cognitive function. In previous work, we have proposed a proof-of-principle model demonstrating how, using hippocampal circuitry, it is possible to learn an arbitrary sequence of known objects in a single trial. We called this model SLT (Single Learning Trial). In the current work, we extend this model, which we will call e-STL, to introduce the capability of navigating a classic four-arms maze to learn, in a single trial, the correct path to reach an exit ignoring dead ends. We show the conditions under which the e-SLT network, including cells coding for places, head-direction, and objects, can robustly and efficiently implement a fundamental cognitive function. The results shed light on the possible circuit organization and operation of the hippocampus and may represent the building block of a new generation of artificial intelligence algorithms for spatial navigation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300165X",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Coding (social sciences)",
      "Computer science",
      "Genetics",
      "Mathematics",
      "Path (computing)",
      "Programming language",
      "Sequence (biology)",
      "Sequence learning",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Coppolino",
        "given_name": "Simone"
      },
      {
        "surname": "Migliore",
        "given_name": "Michele"
      }
    ]
  },
  {
    "title": "Corrigendum to “Interfering with a memory without erasing its trace” [Neural Networks 121 (2020) 339–355]",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.027",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001624",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Linguistics",
      "Philosophy",
      "TRACE (psycholinguistics)"
    ],
    "authors": [
      {
        "surname": "Lange",
        "given_name": "Gesa"
      },
      {
        "surname": "Senden",
        "given_name": "Mario"
      },
      {
        "surname": "Radermacher",
        "given_name": "Alexandra"
      },
      {
        "surname": "De Weerd",
        "given_name": "Peter"
      }
    ]
  },
  {
    "title": "Collaborative-guided spectral abundance learning with bilinear mixing model for hyperspectral subpixel target detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.002",
    "abstract": "Detecting subpixel targets is a considerably challenging issue in hyperspectral image processing and interpretation. Most of the existing hyperspectral subpixel target detection methods construct detectors based on the linear mixing model which regards a pixel as a linear combination of different spectral signatures. However, due to the multiple scattering, the linear mixing model cannot​ illustrate the multiple materials interactions that are nonlinear and widespread in real-world hyperspectral images, which could result in unsatisfactory performance in detecting subpixel targets. To alleviate this problem, this work presents a novel collaborative-guided spectral abundance learning model (denoted as CGSAL) for subpixel target detection based on the bilinear mixing model in hyperspectral images. The proposed CGSAL detects subpixel targets by learning a spectral abundance of the target signature in each pixel. In CGSAL, virtual endmembers and their abundance help to achieve good accuracy for modeling nonlinear scattering accounts for multiple materials interactions according to the bilinear mixing model. Besides, we impose a collaborative term to the spectral abundance learning model to emphasize the collaborative relationships between different endmembers, which contributes to accurate spectral abundance learning and further help to detect subpixel targets. Plentiful experiments and analyses are conducted on three real-world and one synthetic hyperspectral datasets to evaluate the effectiveness of the CGSAL in subpixel target detection. The experiment results demonstrate that the CGSAL achieves competitive performance in detecting subpixel targets and outperforms other state-of-the-art hyperspectral subpixel target detectors.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000655",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Geography",
      "Hyperspectral imaging",
      "Pattern recognition (psychology)",
      "Pixel",
      "Remote sensing",
      "Spectral signature",
      "Subpixel rendering"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Dehui"
      },
      {
        "surname": "Du",
        "given_name": "Bo"
      },
      {
        "surname": "Hu",
        "given_name": "Meiqi"
      },
      {
        "surname": "Dong",
        "given_name": "Yanni"
      },
      {
        "surname": "Zhang",
        "given_name": "Liangpei"
      }
    ]
  },
  {
    "title": "Adaptive fixed-time output synchronization for complex dynamical networks with multi-weights",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.032",
    "abstract": "This paper addresses fixed-time output synchronization problems for two types of complex dynamical networks with multi-weights (CDNMWs) by using two types of adaptive control methods. Firstly, complex dynamical networks with multiple state and output couplings are respectively presented. Secondly, several fixed-time output synchronization criteria for these two networks are formulated based on Lyapunov functional and inequality techniques. Thirdly, by employing two types of adaptive control methods, fixed-time output synchronization issues of these two networks are dealt with. At last, the analytical results are verified by two numerical simulations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001673",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Complex network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Dynamical systems theory",
      "Fixed point",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Synchronization networks",
      "Topology (electrical circuits)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Cao",
        "given_name": "Yuting"
      },
      {
        "surname": "Zhao",
        "given_name": "Linhao"
      },
      {
        "surname": "Zhong",
        "given_name": "Qishui"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Shi",
        "given_name": "Kaibo"
      },
      {
        "surname": "Xiao",
        "given_name": "Jianying"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "DropAGG: Robust Graph Neural Networks via Drop Aggregation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.022",
    "abstract": "Robust learning on graph data is an active research problem in data mining field. Graph Neural Networks (GNNs) have gained great attention in graph data representation and learning tasks. The core of GNNs is the message propagation mechanism across node’s neighbors in GNNs’ layer-wise propagation. Existing GNNs generally adopt the deterministic message propagation mechanism which may (1) perform non-robustly w.r.t structural noises and adversarial attacks and (2) lead to over-smoothing issue. To alleviate these issues, this work rethinks dropout techniques in GNNs and proposes a novel random message propagation mechanism, named Drop Aggregation (DropAGG), for GNNs learning. The core of DropAGG is to randomly select a certain rate of nodes to participate in information aggregation. The proposed DropAGG is a general scheme which can incorporate any specific GNN model to enhance its robustness and mitigate the over-smoothing issue. Using DropAGG, we then design a novel Graph Random Aggregation Network (GRANet) for graph data robust learning. Extensive experiments on several benchmark datasets demonstrate the robustness of GRANet and effectiveness of DropAGG to mitigate the issue of over-smoothing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001569",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Data mining",
      "Gene",
      "Graph",
      "Machine learning",
      "Robustness (evolution)",
      "Smoothing",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Bo"
      },
      {
        "surname": "Chen",
        "given_name": "Yong"
      },
      {
        "surname": "Wang",
        "given_name": "Beibei"
      },
      {
        "surname": "Xu",
        "given_name": "Haiyun"
      },
      {
        "surname": "Luo",
        "given_name": "Bin"
      }
    ]
  },
  {
    "title": "Few-shot human–object interaction video recognition with transformers",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.019",
    "abstract": "We propose a novel few-shot learning framework that can recognize human–object interaction (HOI) classes with a few labeled samples. We achieve this by leveraging a meta-learning paradigm where human–object interactions are embedded into compact features for similarity calculation. More specifically, spatial and temporal relationships of HOI in videos are constructed with transformers which boost the performance over the baseline significantly. First, we present a spatial encoder that extracts the spatial context and infers frame-level features of a human and objects in each frame. And then the video-level feature is obtained by encoding a series of frame-level feature vectors with a temporal encoder. Experiments on two datasets, CAD-120 and Something-Else, validate that our approach achieves 7.8% and 15.2% accuracy improvement on 1-shot task, 4.7% and 15.7% on 5-shot task, which outperforms the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000199",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Encoder",
      "Feature (linguistics)",
      "Frame (networking)",
      "Linguistics",
      "Object (grammar)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Spatial contextual awareness",
      "Telecommunications",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Qiyue"
      },
      {
        "surname": "Xie",
        "given_name": "Xuemei"
      },
      {
        "surname": "Zhang",
        "given_name": "Jin"
      },
      {
        "surname": "Shi",
        "given_name": "Guangming"
      }
    ]
  },
  {
    "title": "Generalized zero-shot domain adaptation via coupled conditional variational autoencoders",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.033",
    "abstract": "Domain adaptation aims to exploit useful information from the source domain where annotated training data are easier to obtain to address a learning problem in the target domain where only limited or even no annotated data are available. In classification problems, domain adaptation has been studied under the assumption all classes are available in the target domain regardless of the annotations. However, a common situation where only a subset of classes in the target domain are available has not attracted much attention. In this paper, we formulate this particular domain adaptation problem within a generalized zero-shot learning framework by treating the labelled source-domain samples as semantic representations for zero-shot learning. For this novel problem, neither conventional domain adaptation approaches nor zero-shot learning algorithms directly apply. To solve this problem, we present a novel Coupled Conditional Variational Autoencoder (CCVAE) which can generate synthetic target-domain image features for unseen classes from real images in the source domain. Extensive experiments have been conducted on three domain adaptation datasets including a bespoke X-ray security checkpoint dataset to simulate a real-world application in aviation security. The results demonstrate the effectiveness of our proposed approach both against established benchmarks and in terms of real-world applicability.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001697",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Classifier (UML)",
      "Computer science",
      "Computer security",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Exploit",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Qian"
      },
      {
        "surname": "Breckon",
        "given_name": "Toby P."
      }
    ]
  },
  {
    "title": "Learning long-term motor timing/patterns on an orthogonal basis in random neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.006",
    "abstract": "The ability of the brain to generate complex spatiotemporal patterns with specific timings is essential for motor learning and temporal processing. An approach that can model this function, using the spontaneous activity of a random neural network (RNN), is associated with orbital instability. We propose a simple system that learns an arbitrary time series as the linear sum of stable trajectories produced by several small network modules. New finding in computer experiments is that the trajectories of the module outputs are orthogonal to each other. They created a dynamic orthogonal basis acquiring a high representational capacity, which enabled the system to learn the timing of extremely long intervals, such as tens of seconds for a millisecond computation unit, and also the complex time series of Lorenz attractors. This self-sustained system satisfies the stability and orthogonality requirements and thus provides a new neurocomputing framework and perspective for the neural mechanisms of motor learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001831",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Attractor",
      "Basis (linear algebra)",
      "Basis function",
      "Biology",
      "Computer science",
      "Geometry",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Millisecond",
      "Orthogonality",
      "Paleontology",
      "Physics",
      "Recurrent neural network",
      "Reservoir computing",
      "Series (stratigraphy)",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Kawai",
        "given_name": "Yuji"
      },
      {
        "surname": "Park",
        "given_name": "Jihoon"
      },
      {
        "surname": "Tsuda",
        "given_name": "Ichiro"
      },
      {
        "surname": "Asada",
        "given_name": "Minoru"
      }
    ]
  },
  {
    "title": "Remix: Towards the transferability of adversarial examples",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.012",
    "abstract": "Deep neural networks (DNNs) are susceptible to adversarial examples, which are crafted by deliberately adding some human-imperceptible perturbations on original images. To explore the vulnerability of models of DNNs, transfer-based black-box attacks are attracting increasing attention of researchers credited to their high practicality. The transfer-based approaches can launch attacks against models easily in the black-box setting by resultant adversarial examples, whereas the success rates are not satisfactory. To boost the adversarial transferability, we propose a Remix method with multiple input transformations, which could achieve multiple data augmentation by utilizing gradients from previous iterations and images from other categories in the same iteration. Extensive experiments on the NeurIPS 2017 adversarial dataset and the ILSVRC 2012 validation dataset demonstrate that the proposed approach could drastically enhance the adversarial transferability and maintain similar success rates of white-box attacks on both undefended models and defended models. Furthermore, extended experiments based on LPIPS show that our method could maintain a similar perceived distance compared to other baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001892",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Black box",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Deep neural networks",
      "Logit",
      "Machine learning",
      "Transfer of learning",
      "Transferability",
      "Vulnerability (computing)"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Hongzhi"
      },
      {
        "surname": "Hao",
        "given_name": "Lingguang"
      },
      {
        "surname": "Hao",
        "given_name": "Kuangrong"
      },
      {
        "surname": "Wei",
        "given_name": "Bing"
      },
      {
        "surname": "Cai",
        "given_name": "Xin"
      }
    ]
  },
  {
    "title": "Few-shot remote sensing image scene classification based on multiscale covariance metric network (MCMNet)",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.04.002",
    "abstract": "Few-shot learning (FSL) is a paradigm that simulates the fast learning ability of human beings, which can learn the feature differences between two groups of small-scale samples with common label space, and the label space of the training set and the test set is not repeated. By this way, it can quickly identify the categories of the unseen image in the test set. This method is widely used in image scene recognition, and it is expected to overcome difficulties of scarce annotated samples in remote sensing (RS). However, among most existing FSL methods, images were embed into Euclidean space, and the similarity between features at the last layer of deep network were measured by Euclidean distance. It is difficult to measure the inter-class similarity and intra-class difference of RS images. In this paper, we propose a multi-scale covariance network (MCMNet) for the application of remote sensing scene classification (RSSC). Taking Conv64F as the backbone, we mapped the features of the 1, 2, and 4 layers of the network to the manifold space by constructing a regional covariance matrix to form a covariance network with different scales. For each layer of features, we introduce the center in manifold space as a prototype for different categories of features. We simultaneously measure the similarity of three prototypes on the manifold space with different scales to form three loss functions and optimize the whole network by episodic training strategy. We conducted comparative experiments on three public datasets. The results show that the classification accuracy (CA) of our proposed method is from 1.35 % to 2.36% higher than that of the most excellent method, which demonstrates that the performance of MCMNet outperforms other methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300179X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Covariance",
      "Covariance matrix",
      "Data mining",
      "Economics",
      "Engineering",
      "Euclidean distance",
      "Euclidean space",
      "Feature (linguistics)",
      "Feature vector",
      "Image (mathematics)",
      "Linguistics",
      "Manifold (fluid mechanics)",
      "Mathematics",
      "Measure (data warehouse)",
      "Mechanical engineering",
      "Metric (unit)",
      "Operations management",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Programming language",
      "Pure mathematics",
      "Quantum mechanics",
      "Scale (ratio)",
      "Set (abstract data type)",
      "Similarity (geometry)",
      "Statistics",
      "Test set"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Xiliang"
      },
      {
        "surname": "Zhu",
        "given_name": "Guobin"
      },
      {
        "surname": "Liu",
        "given_name": "Mingqing"
      },
      {
        "surname": "Chen",
        "given_name": "Zhaotong"
      }
    ]
  },
  {
    "title": "Robust fall detection in video surveillance based on weakly supervised learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.042",
    "abstract": "Fall event detection has been a research hotspot in recent years in the fields of medicine and health. Currently, vision-based fall detection methods have been considered the most promising methods due to their advantages of a non-contact characteristic and easy deployment. However, the existing vision-based fall detection methods mainly use supervised learning in model training and require much time and energy for data annotations. To address these limitations, this work proposes a detection method that uses a weakly supervised learning-based dual-modal network. The proposed method adopts a deep multiple instance learning framework to learn the fall events using weak labels. As a result, the proposed method does not require time-consuming fine-grained annotations. The final detection result of each video is obtained by integrating the information obtained from two streams of the dual-modal network using the proposed dual-modal fusion strategy. Experimental results on two public benchmark datasets and a proposed dataset demonstrate the superiority of the proposed method over the current state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001776",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Modal",
      "Pattern recognition (psychology)",
      "Polymer chemistry",
      "Supervised learning"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Lian"
      },
      {
        "surname": "Huang",
        "given_name": "Chao"
      },
      {
        "surname": "Zhao",
        "given_name": "Shuping"
      },
      {
        "surname": "Li",
        "given_name": "Jinkai"
      },
      {
        "surname": "Zhao",
        "given_name": "Jianchuan"
      },
      {
        "surname": "Cui",
        "given_name": "Zhongwei"
      },
      {
        "surname": "Yu",
        "given_name": "Zhen"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      },
      {
        "surname": "Zhang",
        "given_name": "Min"
      }
    ]
  },
  {
    "title": "Learning task-agnostic and interpretable subsequence-based representation of time series and its applications in fMRI analysis",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.038",
    "abstract": "The recent success of sequential learning models, such as deep recurrent neural networks, is largely due to their superior representation-learning capability for learning the informative representation of a targeted time series. The learning of these representations is generally goal-directed, resulting in their task-specific nature, giving rise to excellent performance in completing a single downstream task but hindering between-task generalisation. Meanwhile, with increasingly intricate sequential learning models, learned representation becomes abstract to human knowledge and comprehension. Hence, we propose a unified local predictive model based on the multi-task learning paradigm to learn the task-agnostic and interpretable subsequence-based time series representation, allowing versatile use of learned representations in temporal prediction, smoothing, and classification tasks. The targeted interpretable representation could convey the spectral information of the modelled time series to the level of human comprehension. Through a proof-of-concept evaluation study, we demonstrate the empirical superiority of learned task-agnostic and interpretable representation over task-specific and conventional subsequence-based representation, such as symbolic and recurrent learning-based representation, in solving temporal prediction, smoothing, and classification tasks. These learned task-agnostic representations can also reveal the ground-truth periodicity of the modelled time series. We further propose two applications of our unified local predictive model in functional magnetic resonance imaging (fMRI) analysis to reveal the spectral characterisation of cortical areas at rest and reconstruct more smoothed temporal dynamics of cortical activations in both resting-state and task-evoked fMRI data, giving rise to robust decoding.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001739",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Computer science",
      "Computer vision",
      "Economics",
      "Functional magnetic resonance imaging",
      "Law",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Smoothing",
      "Subsequence",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Bai",
        "given_name": "Wenjun"
      },
      {
        "surname": "Yamashita",
        "given_name": "Okito"
      },
      {
        "surname": "Yoshimoto",
        "given_name": "Junichiro"
      }
    ]
  },
  {
    "title": "Fixed/prescribed-time synchronization of BAM memristive neural networks with time-varying delays via convex analysis",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.031",
    "abstract": "The synchronization problem of bidirectional associative memory memristive neural networks (BAMMNNs) with time-varying delays plays an essential role in the implementation and application of neural networks. Firstly, under the framework of the Filippov’s solution, the discontinuous parameters of the state-dependent switching are transformed by convex analysis method, which is different from most previous approaches. Secondly, based on Lyapunov function and some inequality techniques, several conditions for the fixed-time synchronization (FXTS) of the drive-response systems are obtained by designing special control strategies. Moreover, the settling time (ST) is estimated by the improved fixed-time stability lemma. Thirdly, the driven-response BAMMNNs are investigated to be synchronized within a prescribed time by designing new controllers based on the FXTS results, where ST is irrelevant to the initial values of BAMMNNs and the parameters of controllers. Finally, a numerical simulation is exhibited to verify the correctness of the conclusions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001661",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bidirectional associative memory",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Content-addressable memory",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Convex combination",
      "Convex optimization",
      "Correctness",
      "Ecology",
      "Electrical engineering",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Geometry",
      "Lemma (botany)",
      "Lyapunov function",
      "Mathematics",
      "Memristor",
      "Nonlinear system",
      "Physics",
      "Poaceae",
      "Quantum mechanics",
      "Regular polygon",
      "Settling time",
      "Step response",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Jinrong"
      },
      {
        "surname": "Chen",
        "given_name": "Guici"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Hu",
        "given_name": "Junhao"
      }
    ]
  },
  {
    "title": "Bounded synchronization for uncertain master–slave neural networks: An adaptive impulsive control approach",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.002",
    "abstract": "This paper investigates the bounded synchronization of the discrete-time master–slave neural networks (MSNNs) with uncertainty. To deal with the unknown parameter in the MSNNs, a parameter adaptive law combined with the impulsive mechanism is proposed to improve the estimation efficiency. Meanwhile, the impulsive method also is applied to the controller design for saving the energy. In addition, a novel time-varying Lyapunov functional candidate is employed to depict the impulsive dynamical characteristic of the MSNNs, wherein a convex function related to the impulsive interval is used to obtain a sufficient condition for bounded synchronization of the MSNNs. Based on the above condition, the controller gain is calculated utilizing an unitary matrix. An algorithm is proposed to reduce the boundary of the synchronization error by optimizing its parameters. Finally, a numerical example is provided to illustrate the correctness and the superiority of the developed results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001193",
    "keywords": [
      "Adaptive control",
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Correctness",
      "Interval (graph theory)",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Yuru"
      },
      {
        "surname": "Liu",
        "given_name": "Chang"
      },
      {
        "surname": "Liu",
        "given_name": "Yonghua"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      },
      {
        "surname": "Lu",
        "given_name": "Renquan"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Generative negative replay for continual learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.006",
    "abstract": "Learning continually is a key aspect of intelligence and a necessary ability to solve many real-life problems. One of the most effective strategies to control catastrophic forgetting, the Achilles’ heel of continual learning, is storing part of the old data and replaying them interleaved with new experiences (also known as the replay approach). Generative replay, which is using generative models to provide replay patterns on demand, is particularly intriguing, however, it was shown to be effective mainly under simplified assumptions, such as simple scenarios and low-dimensional data. In this paper, we show that, while the generated data are usually not able to improve the classification accuracy for the old classes, they can be effective as negative examples (or antagonists) to better learn the new classes, especially when the learning experiences are small and contain examples of just one or few classes. The proposed approach is validated on complex class-incremental and data-incremental continual learning scenarios (CORe50 and ImageNet-1000) composed of high-dimensional data and a large number of training experiences: a setup where existing generative replay approaches usually fail.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001235",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Generative grammar",
      "Generative model",
      "Machine learning"
    ],
    "authors": [
      {
        "surname": "Graffieti",
        "given_name": "Gabriele"
      },
      {
        "surname": "Maltoni",
        "given_name": "Davide"
      },
      {
        "surname": "Pellegrini",
        "given_name": "Lorenzo"
      },
      {
        "surname": "Lomonaco",
        "given_name": "Vincenzo"
      }
    ]
  },
  {
    "title": "WDMNet: Modeling diverse variations of regional wind speed for multi-step predictions",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.024",
    "abstract": "Regional wind speed prediction plays an important role in the development of wind power, which is usually recorded in the form of two orthogonal components, namely U-wind and V-wind. The regional wind speed has the characteristics of diverse variations, which are reflected in three aspects: (1) The spatially diverse variations of regional wind speed indicate that wind speed has different dynamic patterns at different positions; (2) The distinct variations between U-wind and V-wind denote that U-wind and V-wind at the same position exhibit different dynamic patterns; (3) The non-stationary variations of wind speed represent that the intermittent and chaotic nature of wind speed. In this paper, we propose a novel framework named Wind Dynamics Modeling Network (WDMNet) to model the diverse variations of regional wind speed and make accurate multi-step predictions. To jointly capture the spatially diverse variations and the distinct variations between U-wind and V-wind, WDMNet leverages a new neural block called Involution Gated Recurrent Unit Partial Differential Equation (Inv-GRU-PDE) as its key component. The block adopts involution to model spatially diverse variations and separately constructs hidden driven PDEs of U-wind and V-wind. The construction of PDEs in this block is achieved by a new Involution PDE (InvPDE) layers. Besides, a deep data-driven model is also introduced in Inv-GRU-PDE block as the complement to the constructed hidden PDEs for sufficiently modeling regional wind dynamics. Finally, to effectively capture the non-stationary variations of wind speed, WDMNet follows a time-variant structure for multi-step predictions. Comprehensive experiments have been conducted on two real-world datasets. Experimental results demonstrate the effectiveness and superiority of the proposed method over state-of-the-art techniques.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000874",
    "keywords": [
      "Block (permutation group theory)",
      "Computer science",
      "Electrical engineering",
      "Engineering",
      "Geometry",
      "Mathematics",
      "Meteorology",
      "Physics",
      "Wind direction",
      "Wind power",
      "Wind speed"
    ],
    "authors": [
      {
        "surname": "Ye",
        "given_name": "Rui"
      },
      {
        "surname": "Feng",
        "given_name": "Shanshan"
      },
      {
        "surname": "Li",
        "given_name": "Xutao"
      },
      {
        "surname": "Ye",
        "given_name": "Yunming"
      },
      {
        "surname": "Zhang",
        "given_name": "Baoquan"
      },
      {
        "surname": "Zhu",
        "given_name": "Yan"
      },
      {
        "surname": "Sun",
        "given_name": "Yao"
      },
      {
        "surname": "Wang",
        "given_name": "Yaowei"
      }
    ]
  },
  {
    "title": "LCM-Captioner: A lightweight text-based image captioning method with collaborative mechanism between vision and text",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.010",
    "abstract": "Text-based image captioning (TextCap) aims to remedy the shortcomings of existing image captioning tasks that ignore text content when describing images. Instead, it requires models to recognize and describe images from both visual and textual content to achieve a deeper level of comprehension of the images. However, existing methods tend to use numerous complex network architectures to improve performance, which still fails to adequately model the relationship between vision and text on the one side, while on the other side this leads to long running times, high memory consumption, and other unfavorable deployment problems. To solve the above issues, we have developed a lightweight captioning method with a collaborative mechanism, LCM-Captioner, which balances high efficiency with high performance. First, we propose a feature-lightening transformation for the TextCap task, named TextLighT, which is able to learn rich multimodal representations while mapping features to lower dimensions, thereby reducing memory costs. Next, we present a collaborative attention module for visual and text information, VTCAM, to facilitate the semantic alignment of multimodal information to uncover important visual objects and textual content. Finally, the conducted extensive experiments on the TextCaps dataset demonstrate the effectiveness of our method. Code is available at https://github.com/DengHY258/LCM-Captioner.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001272",
    "keywords": [
      "Artificial intelligence",
      "Closed captioning",
      "Code (set theory)",
      "Comprehension",
      "Computer science",
      "Economics",
      "Epistemology",
      "Feature (linguistics)",
      "Image (mathematics)",
      "Information retrieval",
      "Linguistics",
      "Management",
      "Mechanism (biology)",
      "Natural language processing",
      "Operating system",
      "Philosophy",
      "Programming language",
      "Set (abstract data type)",
      "Software deployment",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Qi"
      },
      {
        "surname": "Deng",
        "given_name": "Hongyu"
      },
      {
        "surname": "Wu",
        "given_name": "Xue"
      },
      {
        "surname": "Yang",
        "given_name": "Zhenguo"
      },
      {
        "surname": "Liu",
        "given_name": "Yun"
      },
      {
        "surname": "Wang",
        "given_name": "Yazhou"
      },
      {
        "surname": "Hao",
        "given_name": "Gefei"
      }
    ]
  },
  {
    "title": "Decoding self-motion from visual image sequence predicts distinctive features of reflexive motor responses to visual motion",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.020",
    "abstract": "Visual motion analysis is crucial for humans to detect external moving objects and self-motion which are informative for planning and executing actions for various interactions with environments. Here we show that the image motion analysis trained to decode the self-motion during human natural movements by a convolutional neural network exhibits similar specificities with the reflexive ocular and manual responses induced by a large-field visual motion, in terms of stimulus spatiotemporal frequency tuning. The spatiotemporal frequency tuning of the decoder peaked at high-temporal and low-spatial frequencies, as observed in the reflexive ocular and manual responses, but differed significantly from the frequency power of the visual image itself and the density distribution of self-motion. Further, artificial manipulations of the learning data sets predicted great changes in the specificity of the spatiotemporal tuning. Interestingly, despite similar spatiotemporal frequency tunings in the vertical-axis rotational direction and in the transversal direction to full-field visual stimuli, the tunings for center-masked stimuli were different between those directions, and the specificity difference is qualitatively similar to the discrepancy between ocular and manual responses, respectively. In addition, the representational analysis demonstrated that head-axis rotation was decoded by relatively simple spatial accumulation over the visual field, while the transversal motion was decoded by more complex spatial interaction of visual information. These synthetic model examinations support the idea that visual motion analyses eliciting the reflexive motor responses, which are critical in interacting with the external world, are acquired for decoding self-motion.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001545",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cognitive psychology",
      "Computer science",
      "Computer vision",
      "Decoding methods",
      "Motion (physics)",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Stimulus (psychology)",
      "Visual field"
    ],
    "authors": [
      {
        "surname": "Nakamura",
        "given_name": "Daiki"
      },
      {
        "surname": "Gomi",
        "given_name": "Hiroaki"
      }
    ]
  },
  {
    "title": "Human-guided deep learning with ante-hoc explainability by convolutional network from non-image data for pregnancy prognostication",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.020",
    "abstract": "Background and Objective: Deep learning is applied in medicine mostly due to its state-of-the-art performance for diagnostic imaging. Supervisory authorities also require the model to be explainable, but most explain the model after development (post hoc) instead of incorporating explanation into the design (ante hoc). This study aimed to demonstrate a human-guided deep learning with ante-hoc explainability by convolutional network from non-image data to develop, validate, and deploy a prognostic prediction model for PROM and an estimator of time of delivery using a nationwide health insurance database. Methods: To guide modeling, we constructed and verified association diagrams respectively from literatures and electronic health records. Non-image data were transformed into meaningful images utilizing predictor-to-predictor similarities, harnessing the power of convolutional neural network mostly used for diagnostic imaging. The network architecture was also inferred from the similarities. Results: This resulted the best model for prelabor rupture of membranes ( n = 883 , 376) with the area under curves 0.73 (95% CI 0.72 to 0.75) and 0.70 (95% CI 0.69 to 0.71) respectively by internal and external validations, and outperformed previous models found by systematic review. It was explainable by knowledge-based diagrams and model representation. Conclusions: This allows prognostication with actionable insights for preventive medicine.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000837",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Machine learning"
    ],
    "authors": [
      {
        "surname": "Sufriyana",
        "given_name": "Herdiantri"
      },
      {
        "surname": "Wu",
        "given_name": "Yu-Wei"
      },
      {
        "surname": "Su",
        "given_name": "Emily Chia-Yu"
      }
    ]
  },
  {
    "title": "RAFNet: Restricted attention fusion network for sleep apnea detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.019",
    "abstract": "Sleep apnea (SA) is a common sleep-related breathing disorder, which would lead to damage of multiple systemic organs or even sudden death. In clinical practice, portable device is an important tool to monitor sleep conditions and detect SA events by using physiological signals. However, SA detection performance is still limited due to physiological signals with time-variability and complexity. In this paper, we focus on SA detection with single lead ECG signals, which can be easily collected by a portable device. Under this context, we propose a restricted attention fusion network called RAFNet for sleep apnea detection. Specifically, RR intervals (RRI) and R-peak amplitudes (Rpeak) are generated from ECG signals and divided into one-minute-long segments. To alleviate the problem of insufficient feature information of the target segment, we combine the target segment with two pre- and post-adjacent segments in sequence, (i.e. a five-minute-long segment), as the input. Meanwhile, by leveraging the target segment as the query vector, we propose a new restricted attention mechanism with cascaded morphological and temporal attentions, which can effectively learn the feature information and depress redundant feature information from the adjacent segments with adaptive assigning weight importance. To further improve the SA detection performance, the target and adjacent segment features are fused together with the channel-wise stacking scheme. Experiment results on the public Apnea-ECG dataset and the real clinical FAH-ECG dataset with sleep apnea annotations show that the RAFNet greatly improves SA detection performance and achieves competitive results, which are superior to those achieved by the state-of-the-art baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001454",
    "keywords": [
      "Anatomy",
      "Apnea",
      "Artificial intelligence",
      "Attention network",
      "Biology",
      "Breathing",
      "Cardiology",
      "Computer science",
      "Context (archaeology)",
      "Encoder",
      "Feature (linguistics)",
      "Focus (optics)",
      "Linguistics",
      "Medicine",
      "Operating system",
      "Optics",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Psychiatry",
      "Sleep apnea"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Ying"
      },
      {
        "surname": "Yue",
        "given_name": "Huijun"
      },
      {
        "surname": "Zou",
        "given_name": "Ruifeng"
      },
      {
        "surname": "Lei",
        "given_name": "Wenbin"
      },
      {
        "surname": "Ma",
        "given_name": "Wenjun"
      },
      {
        "surname": "Fan",
        "given_name": "Xiaomao"
      }
    ]
  },
  {
    "title": "CHARLES: A C++ fixed-point library for Photonic-Aware Neural Networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.007",
    "abstract": "In this paper we present CHARLES (C++ pHotonic Aware neuRaL nEtworkS), a C++ library aimed at providing a flexible tool to simulate the behavior of Photonic-Aware Neural Network (PANN). PANNs are neural network architectures aware of the constraints due to the underlying photonic hardware, mostly in terms of low equivalent precision of the computations. For this reason, CHARLES exploits fixed-point computations for inference, while it supports both floating-point and fixed-point numerical formats for training. In this way, we can compare the effects due to the quantization in the inference phase when the training phase is performed on a classical floating-point model and on a model exploiting high-precision fixed-point numbers. To validate CHARLES and identify the most suited numerical format for PANN training, we report the simulation results obtained considering three datasets: Iris, MNIST, and Fashion-MNIST. Fixed-training is shown to outperform floating-training when executing inference on bitwidths suitable for photonic implementation. Indeed, performing the training phase in the floating-point domain and then quantizing to lower bitwidths results in a very high accuracy loss. Instead, when fixed-point numbers are exploited in the training phase, the accuracy loss due to quantization to lower bitwidths is significantly reduced. In particular, we show that for Iris dataset, fixed-training achieves a performance similar to floating-training. Fixed-training allows to obtain an accuracy of 90.4% and 68.1% with the MNIST and Fashion-MNIST datasets using only 6 bits, while the floating-training reaches an accuracy of just 25.4% and 50.0% when exploiting the same bitwidths.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001247",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computation",
      "Computer science",
      "Fixed point",
      "Floating point",
      "Inference",
      "MNIST database",
      "Mathematical analysis",
      "Mathematics",
      "Optics",
      "Photonics",
      "Physics",
      "Quantization (signal processing)"
    ],
    "authors": [
      {
        "surname": "Paolini",
        "given_name": "Emilio"
      },
      {
        "surname": "De Marinis",
        "given_name": "Lorenzo"
      },
      {
        "surname": "Maggiani",
        "given_name": "Luca"
      },
      {
        "surname": "Cococcioni",
        "given_name": "Marco"
      },
      {
        "surname": "Andriolli",
        "given_name": "Nicola"
      }
    ]
  },
  {
    "title": "Global synchronization of complex-valued neural networks with unbounded time-varying delays",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.041",
    "abstract": "This paper investigates global synchronization of complex-valued neural networks (CVNNs) with unbounded time-varying delays. By applying analytical method and inequality techniques, an algebraic criterion is established to ensure global synchronization of the CVNNs via a devised feedback controller, which generalizes some existing outcomes. Finally, two numerical simulations and one application in image encryption are provided to verify the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001132",
    "keywords": [
      "Agronomy",
      "Algebraic number",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Encryption",
      "Feedback controller",
      "Image (mathematics)",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Sheng",
        "given_name": "Yin"
      },
      {
        "surname": "Gong",
        "given_name": "Haoyu"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "Generalized image outpainting with U-transformer",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.021",
    "abstract": "In this paper, we develop a novel transformer-based generative adversarial neural network called U-Transformer for generalized image outpainting problems. Different from most present image outpainting methods conducting horizontal extrapolation, our generalized image outpainting could extrapolate visual context all-side around a given image with plausible structure and details even for complicated scenery, building, and art images. Specifically, we design a generator as an encoder-to-decoder structure embedded with the popular Swin Transformer blocks. As such, our novel neural network can better cope with image long-range dependencies which are crucially important for generalized image outpainting. We propose additionally a U-shaped structure and multi-view Temporal Spatial Predictor (TSP) module to reinforce image self-reconstruction as well as unknown-part prediction smoothly and realistically. By adjusting the predicting step in the TSP module in the testing stage, we can generate arbitrary outpainting size given the input sub-image. We experimentally demonstrate that our proposed method could produce visually appealing results for generalized image outpainting against the state-of-the-art image outpainting approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000849",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Encoder",
      "Extrapolation",
      "Generative grammar",
      "Image (mathematics)",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Penglei"
      },
      {
        "surname": "Yang",
        "given_name": "Xi"
      },
      {
        "surname": "Zhang",
        "given_name": "Rui"
      },
      {
        "surname": "Goulermas",
        "given_name": "John Y."
      },
      {
        "surname": "Geng",
        "given_name": "Yujie"
      },
      {
        "surname": "Yan",
        "given_name": "Yuyao"
      },
      {
        "surname": "Huang",
        "given_name": "Kaizhu"
      }
    ]
  },
  {
    "title": "Framework for Segmented threshold ℓ 0 gradient approximation based network for sparse signal recovery",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.005",
    "abstract": "Signal reconstruction from compressed sensed data need iterative methods since the sparse measurement matrix is analytically non invertible. The iterative thresholding and ℓ 0 function minimization are of special interest as these two operations provide sparse solution. However these methods need an inverse operation corresponding to the measurement matrix for estimating the reconstruction error. The pseudo-inverse of the measurement matrix is used in general for this purpose. Here a sparse signal recovery framework using an approximate inverse matrix Q and iterative segment thresholding of ℓ 0 and ℓ 1 norm with residue addition is presented. Two recovery algorithms are developed using this framework. The ℓ 0 based method is later developed to a basis function dictionary based network for sparse signal recovery. The proposed framework enables the users experiment with different inverse matrix to achieve better efficiency in sparse signal recovery and implement the algorithm in computationally efficient way.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001223",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Composite material",
      "Compressed sensing",
      "Computer hardware",
      "Computer science",
      "Digital signal processing",
      "Geometry",
      "Image (mathematics)",
      "Inverse",
      "Inverse problem",
      "Invertible matrix",
      "Iterative method",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Minification",
      "Programming language",
      "Pure mathematics",
      "Signal processing",
      "Signal reconstruction",
      "Thresholding"
    ],
    "authors": [
      {
        "surname": "V.",
        "given_name": "Vivekanand"
      },
      {
        "surname": "Mishra",
        "given_name": "Deepak"
      }
    ]
  },
  {
    "title": "SuperstarGAN: Generative adversarial networks for image-to-image translation in large-scale domains",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.042",
    "abstract": "Image-to-image translation with generative adversarial networks (GANs) has been extensively studied in recent years. Among the models, StarGAN has achieved image-to-image translation for multiple domains with a single generator, whereas conventional models require multiple generators. However, StarGAN has several limitations, including the lack of capacity to learn mappings among large-scale domains; furthermore, StarGAN can barely express small feature changes. To address the limitations, we propose an improved StarGAN, namely SuperstarGAN. We adopted the idea, first proposed in controllable GAN (ControlGAN), of training an independent classifier with the data augmentation techniques to handle the overfitting problem in the classification of StarGAN structures. Since the generator with a well-trained classifier can express small features belonging to the target domain, SuperstarGAN achieves image-to-image translation in large-scale domains. Evaluated with a face image dataset, SuperstarGAN demonstrated improved performance in terms of Fréchet Inception distance (FID) and learned perceptual image patch similarity (LPIPS). Specifically, compared to StarGAN, SuperstarGAN exhibited decreased FID and LPIPS by 18.1% and 42.5%, respectively. Furthermore, we conducted an additional experiment with interpolated and extrapolated label values, indicating the ability of SuperstarGAN to control the degree of expression of the target domain features in generated images. Additionally, SuperstarGAN was successfully adapted to an animal face dataset and a painting dataset, where it can translate styles of animal faces (i.e., a cat to a tiger) and styles of painters (i.e., Hassam to Picasso), respectively, which explains the generality of SuperstarGAN regardless of datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001144",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Classifier (UML)",
      "Computer science",
      "Computer vision",
      "Gene",
      "Generality",
      "Generator (circuit theory)",
      "Image (mathematics)",
      "Image translation",
      "Messenger RNA",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Physics",
      "Power (physics)",
      "Psychology",
      "Psychotherapist",
      "Quantum mechanics",
      "Similarity (geometry)",
      "Translation (biology)"
    ],
    "authors": [
      {
        "surname": "Ko",
        "given_name": "Kanghyeok"
      },
      {
        "surname": "Yeom",
        "given_name": "Taesun"
      },
      {
        "surname": "Lee",
        "given_name": "Minhyeok"
      }
    ]
  },
  {
    "title": "An interpretive constrained linear model for ResNet and MgNet",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.011",
    "abstract": "We propose a constrained linear data-feature-mapping model as an interpretable mathematical model for image classification using a convolutional neural network (CNN). From this viewpoint, we establish detailed connections between the traditional iterative schemes for linear systems and the architectures of the basic blocks of ResNet- and MgNet-type models. Using these connections, we present some modified ResNet models that, compared with the original models, have fewer parameters but can produce more accurate results, thereby demonstrating the validity of this constrained learning data-feature-mapping assumption. Based on this assumption, we further propose a general data-feature iterative scheme to demonstrate the rationality of MgNet. We also provide a systematic numerical study on MgNet to show its success and advantages in image classification problems, particularly in comparison with established networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001284",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Feature (linguistics)",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Residual neural network",
      "Scheme (mathematics)"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Juncai"
      },
      {
        "surname": "Xu",
        "given_name": "Jinchao"
      },
      {
        "surname": "Zhang",
        "given_name": "Lian"
      },
      {
        "surname": "Zhu",
        "given_name": "Jianqing"
      }
    ]
  },
  {
    "title": "Episodic task agnostic contrastive training for multi-task learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.023",
    "abstract": "Learning knowledge from different tasks to improve the general learning performance is crucial for designing an efficient algorithm. In this work, we tackle the Multi-task Learning (MTL) problem, where the learner extracts the knowledge from different tasks simultaneously with limited data. Previous works have been designing the MTL models by taking advantage of the transfer learning techniques, requiring the knowledge of the task index, which is not realistic in many practical scenarios. In contrast, we consider the scenario that the task index is not explicitly known, under which the features extracted by the neural networks are task agnostic. To learn the task agnostic invariant features, we implement model agnostic meta-learning by leveraging the episodic training scheme to capture the common features across tasks. Apart from the episodic training scheme, we further implemented a contrastive learning objective to improve the feature compactness for a better prediction boundary in the embedding space. We conduct extensive experiments on several benchmarks compared with several recent strong baselines to demonstrate the effectiveness of the proposed method. The results showed that our method provides a practical solution for real-world scenarios, where the task index is agnostic to the learner and can outperform several strong baselines, achieving state-of-the-art performances.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000862",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Economics",
      "Embedding",
      "Feature learning",
      "Machine learning",
      "Management",
      "Multi-task learning",
      "Task (project management)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Fan"
      },
      {
        "surname": "Chen",
        "given_name": "Yuyi"
      },
      {
        "surname": "Wen",
        "given_name": "Jun"
      },
      {
        "surname": "Zeng",
        "given_name": "Qiuhao"
      },
      {
        "surname": "Shui",
        "given_name": "Changjian"
      },
      {
        "surname": "Ling",
        "given_name": "Charles X."
      },
      {
        "surname": "Yang",
        "given_name": "Shichun"
      },
      {
        "surname": "Wang",
        "given_name": "Boyu"
      }
    ]
  },
  {
    "title": "HARDC : A novel ECG-based heartbeat classification method to detect arrhythmia using hierarchical attention based dual structured RNN with dilated CNN",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.004",
    "abstract": "Deep learning-based models have achieved significant success in detecting cardiac arrhythmia by analyzing ECG signals to categorize patient heartbeats. To improve the performance of such models, we have developed a novel hybrid hierarchical attention-based bidirectional recurrent neural network with dilated CNN (HARDC) method for arrhythmia classification. This solves problems that arise when traditional dilated convolutional neural network (CNN) models disregard the correlation between contexts and gradient dispersion. The proposed HARDC fully exploits the dilated CNN and bidirectional recurrent neural network unit (BiGRU–BiLSTM) architecture to generate fusion features. As a result of incorporating both local and global feature information and an attention mechanism, the model’s performance for prediction is improved. By combining the fusion features with a dilated CNN and a hierarchical attention mechanism, the trained HARDC model showed significantly improved classification results and interpretability of feature extraction on the PhysioNet 2017 challenge dataset. Sequential Z-Score normalization, filtering, denoising, and segmentation are used to prepare the raw data for analysis. CGAN (Conditional Generative Adversarial Network) is then used to generate synthetic signals from the processed data. The experimental results demonstrate that the proposed HARDC model significantly outperforms other existing models, achieving an accuracy of 99.60%, F1 score of 98.21%, a precision of 97.66%, and recall of 99.60% using MIT-BIH generated ECG. In addition, this approach significantly reduces run time when using dilated CNN compared to normal convolution. Overall, this hybrid model demonstrates an innovative and cost-effective strategy for ECG signal compression and high-performance ECG recognition. Our results indicate that an automated and highly computed method to classify multiple types of arrhythmia signals holds considerable promise.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001211",
    "keywords": [
      "Anthropology",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Deep learning",
      "Feature extraction",
      "Heartbeat",
      "Interpretability",
      "Normalization (sociology)",
      "Pattern recognition (psychology)",
      "Recurrent neural network",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Islam",
        "given_name": "Md Shofiqul"
      },
      {
        "surname": "Hasan",
        "given_name": "Khondokar Fida"
      },
      {
        "surname": "Sultana",
        "given_name": "Sunjida"
      },
      {
        "surname": "Uddin",
        "given_name": "Shahadat"
      },
      {
        "surname": "Lio’",
        "given_name": "Pietro"
      },
      {
        "surname": "Quinn",
        "given_name": "Julian M.W."
      },
      {
        "surname": "Moni",
        "given_name": "Mohammad Ali"
      }
    ]
  },
  {
    "title": "Hierarchical Attention Master–Slave for heterogeneous multi-agent reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.037",
    "abstract": "Most multi-agent reinforcement learning (MARL) approaches optimize strategy by improving itself, while ignoring the limitations of homogeneous agents that may have single function. However, in reality, the complex tasks tend to coordinate various types of agents and leverage advantages from one another. Therefore, it is a vital research issue how to establish appropriate communication among them and optimize decision. To this end, we propose a Hierarchical Attention Master–Slave (HAMS) MARL, where the Hierarchical Attention balances the weight allocation within and among clusters, and the Master–Slave architecture endows agents independent reasoning and individual guidance. By the offered design, information fusion, especially among clusters, is implemented effectively, and excessive communication is avoided, moreover, selective composed action optimizes decision. We evaluate the HAMS on both small and large scale heterogeneous StarCraft II micromanagement tasks. The proposed algorithm achieves the exceptional performance with more than 80% win rates in all evaluation scenarios, which obtains an impressive win rate of over 90% in the largest map. The experiments demonstrate a maximum improvement in win rate of 47% over the best known algorithm. The results show that our proposal outperforms recent state-of-the-art approaches, which provides a novel idea for heterogeneous multi-agent policy optimization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001090",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Homogeneous",
      "Leverage (statistics)",
      "Machine learning",
      "Physics",
      "Reinforcement learning",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jiao"
      },
      {
        "surname": "Yuan",
        "given_name": "Mingrui"
      },
      {
        "surname": "Li",
        "given_name": "Yun"
      },
      {
        "surname": "Zhao",
        "given_name": "Zihui"
      }
    ]
  },
  {
    "title": "Successes and critical failures of neural networks in capturing human-like speech recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.032",
    "abstract": "Natural and artificial audition can in principle acquire different solutions to a given problem. The constraints of the task, however, can nudge the cognitive science and engineering of audition to qualitatively converge, suggesting that a closer mutual examination would potentially enrich artificial hearing systems and process models of the mind and brain. Speech recognition — an area ripe for such exploration — is inherently robust in humans to a number transformations at various spectrotemporal granularities. To what extent are these robustness profiles accounted for by high-performing neural network systems? We bring together experiments in speech recognition under a single synthesis framework to evaluate state-of-the-art neural networks as stimulus-computable, optimized observers. In a series of experiments, we (1) clarify how influential speech manipulations in the literature relate to each other and to natural speech, (2) show the granularities at which machines exhibit out-of-distribution robustness, reproducing classical perceptual phenomena in humans, (3) identify the specific conditions where model predictions of human performance differ, and (4) demonstrate a crucial failure of all artificial systems to perceptually recover where humans do, suggesting alternative directions for theory and model building. These findings encourage a tighter synergy between the cognitive science and engineering of audition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001016",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep neural networks",
      "Speech recognition",
      "Time delay neural network"
    ],
    "authors": [
      {
        "surname": "Adolfi",
        "given_name": "Federico"
      },
      {
        "surname": "Bowers",
        "given_name": "Jeffrey S."
      },
      {
        "surname": "Poeppel",
        "given_name": "David"
      }
    ]
  },
  {
    "title": "Miper-MVS: Multi-scale iterative probability estimation with refinement for efficient multi-view stereo",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.012",
    "abstract": "Multi-view stereo reconstruction aims to construct 3D scenes from multiple 2D images. In recent years, learning-based multi-view stereo methods have achieved significant results in depth estimation for multi-view stereo reconstruction. However, the current popular multi-stage processing method cannot solve the low-efficiency problem satisfactorily owing to the use of 3D convolution and still involves significant amounts of calculation. Therefore, to further balance the efficiency and generalization performance, this study proposed a multi-scale iterative probability estimation with refinement, which is a highly efficient method for multi-view stereo reconstruction. It comprises three main modules: 1) a high-precision probability estimator, dilated-LSTM that encodes the pixel probability distribution of depth in the hidden state, 2) an efficient interactive multi-scale update module that fully integrates multi-scale information and improves parallelism by interacting information between adjacent scales, and 3) a Pi-error Refinement module that converts the depth error between views into a grayscale error map and refines the edges of objects in the depth map. Simultaneously, we introduced a large amount of high-frequency information to ensure the accuracy of the refined edges. Among the most efficient methods (e.g., runtime and memory), the proposed method achieved the best generalization on the Tanks & Temples benchmarks. Additionally, the performance of the Miper-MVS was highly competitive in DTU benchmark. Our code is available at https://github.com/zhz120/Miper-MVS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001296",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Code (set theory)",
      "Computer science",
      "Computer vision",
      "Convolution (computer science)",
      "Estimator",
      "Generalization",
      "Geodesy",
      "Geography",
      "Grayscale",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Pixel",
      "Programming language",
      "Quantum mechanics",
      "Scale (ratio)",
      "Set (abstract data type)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Huizhou"
      },
      {
        "surname": "Zhao",
        "given_name": "Haoliang"
      },
      {
        "surname": "Wang",
        "given_name": "Qi"
      },
      {
        "surname": "Hao",
        "given_name": "Gefei"
      },
      {
        "surname": "Lei",
        "given_name": "Liang"
      }
    ]
  },
  {
    "title": "Revisiting the fragility of influence functions",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.029",
    "abstract": "In the last few years, many works have tried to explain the predictions of deep learning models. Few methods, however, have been proposed to verify the accuracy or faithfulness of these explanations. Recently, influence functions, which is a method that approximates the effect that leave-one-out training has on the loss function, has been shown to be fragile. The proposed reason for their fragility remains unclear. Although previous work suggests the use of regularization to increase robustness, this does not hold in all cases. In this work, we seek to investigate the experiments performed in the prior work in an effort to understand the underlying mechanisms of influence function fragility. First, we verify influence functions using procedures from the literature under conditions where the convexity assumptions of influence functions are met. Then, we relax these assumptions and study the effects of non-convexity by using deeper models and more complex datasets. Here, we analyze the key metrics and procedures that are used to validate influence functions. Our results indicate that the validation procedures may cause the observed fragility.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001648",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Convexity",
      "Econometrics",
      "Economics",
      "Evolutionary biology",
      "Financial economics",
      "Fragility",
      "Function (biology)",
      "Gene",
      "Machine learning",
      "Mathematics",
      "Physical chemistry",
      "Regularization (linguistics)",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Epifano",
        "given_name": "Jacob R."
      },
      {
        "surname": "Ramachandran",
        "given_name": "Ravi P."
      },
      {
        "surname": "Masino",
        "given_name": "Aaron J."
      },
      {
        "surname": "Rasool",
        "given_name": "Ghulam"
      }
    ]
  },
  {
    "title": "Improved disturbance observer-based fixed-time adaptive neural network consensus tracking for nonlinear multi-agent systems",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.016",
    "abstract": "This paper is concerned with the problem of fixed-time consensus tracking for a class of nonlinear multi-agent systems subject to unknown disturbances. Firstly, a modified fixed-time disturbance observer is devised to estimate the unknown mismatched disturbance. Secondly, a distributed fixed-time neural network control protocol is designed, in which neural network is employed to approximate the uncertain nonlinear function. Simultaneously, the technique of command filter is applied to fixed-time control, which circumvents the “explosion of complexity” problem. Under the proposed control strategy, all agents are enable to track the desired trajectory in fixed-time, and the consensus tracking error and disturbance estimation error converge to an arbitrarily small neighborhood of the origin, meanwhile, all signals in the closed-loop system remain bounded. Finally, a simulation example is provided to validate the effectiveness of the presented design method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001338",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Bounded function",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Filter (signal processing)",
      "Mathematical analysis",
      "Mathematics",
      "Multi-agent system",
      "Nonlinear system",
      "Observer (physics)",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Tracking (education)",
      "Tracking error",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Na"
      },
      {
        "surname": "Xia",
        "given_name": "Jianwei"
      },
      {
        "surname": "Park",
        "given_name": "Ju H."
      },
      {
        "surname": "Zhang",
        "given_name": "Jing"
      },
      {
        "surname": "Shen",
        "given_name": "Hao"
      }
    ]
  },
  {
    "title": "Nested relation extraction via self-contrastive learning guided by structure and semantic similarity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.001",
    "abstract": "The conventional Relation Extraction (RE) task involves identifying whether relations exist between two entities in a given sentence and determining their relation types. However, the complexity of practical application scenarios and the flexibility of natural language demand the ability to extract nested relations, i.e., the recognized relation triples may be components of the higher-level relations. Previous studies have highlighted several challenges that affect the nested RE task, including the lack of abundant labeled data, inappropriate neural networks, and underutilization of the nested relation structures. To address these issues, we formalize the nested RE task and propose a hierarchical neural network to iteratively identify the nested relations between entities and relation triples in a layer by layer manner. Moreover, a novel self-contrastive learning optimization strategy is presented to adapt our method to low-data settings by fully exploiting the constraints due to the nested structure and semantic similarity between paired input sentences. Our method outperformed the state-of-the-art baseline methods in extensive experiments, and ablation experiments verified the effectiveness of the proposed self-contrastive learning optimization strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001181",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Economics",
      "Flexibility (engineering)",
      "Image (mathematics)",
      "Machine learning",
      "Management",
      "Mathematics",
      "Natural language processing",
      "Pattern recognition (psychology)",
      "Relation (database)",
      "Relationship extraction",
      "Sentence",
      "Similarity (geometry)",
      "Statistics",
      "Task (project management)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Mai",
        "given_name": "Chengcheng"
      },
      {
        "surname": "Luo",
        "given_name": "Kaiwen"
      },
      {
        "surname": "Wang",
        "given_name": "Yuxiang"
      },
      {
        "surname": "Peng",
        "given_name": "Ziyan"
      },
      {
        "surname": "Chen",
        "given_name": "Yu"
      },
      {
        "surname": "Yuan",
        "given_name": "Chunfeng"
      },
      {
        "surname": "Huang",
        "given_name": "Yihua"
      }
    ]
  },
  {
    "title": "A meta-framework for multi-label active learning based on deep reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.045",
    "abstract": "Multi-label Active Learning (MLAL) is an effective method to improve the performance of the classifier on multi-label problems with less annotation effort by allowing the learning system to actively select high-quality examples (example-label pairs) for labeling. Existing MLAL algorithms mainly focus on designing reasonable algorithms to evaluate the potential values (as previously mentioned quality) of the unlabeled data. These manually designed methods may show totally different results on various types of datasets due to the defect of the methods or the particularity of the datasets. In this paper, instead of manually designing an evaluation method, we propose a deep reinforcement learning (DRL) model to explore a general evaluation method on several seen datasets and eventually apply it to unseen datasets based on a meta framework. In addition, a self-attention mechanism along with a reward function is integrated into the DRL structure to address the label correlation and data imbalanced problems in MLAL. Comprehensive experiments show that our proposed DRL-based MLAL method is able to produce comparable results as compared with other methods reported in the literature.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300117X",
    "keywords": [
      "Annotation",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Machine learning",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Shuyue"
      },
      {
        "surname": "Wang",
        "given_name": "Ran"
      },
      {
        "surname": "Lu",
        "given_name": "Jian"
      }
    ]
  },
  {
    "title": "Multi-UAV autonomous collision avoidance based on PPO-GIC algorithm with CNN–LSTM fusion network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.027",
    "abstract": "This paper is concerned with the autonomous effective collision avoidance strategy for multiple unmanned aerial vehicles (multi-UAV) in limited airspace under the framework of proximal policy optimization (PPO) algorithm. An end-to-end deep reinforcement learning (DRL) control strategy and a potential-based reward function are designed. Next, the CNN-LSTM (CL) fusion network is constructed by fusing the convolutional neural network (CNN) and the long short-term memory network (LSTM), which realizes the feature interaction among the information of multi-UAV. Then, a generalized integral compensator (GIC) is introduced into the actor-critic structure, and the CLPPO-GIC algorithm is proposed by combining CL and GIC. Finally, we validate the learned policy in various simulation environments by performance evaluation. The simulation results show that the introduction of the LSTM network and GIC can further improve the efficiency of collision avoidance, and the robustness and accuracy of the algorithm are verified in different environments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000904",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Collision",
      "Collision avoidance",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Evolutionary biology",
      "Feature (linguistics)",
      "Function (biology)",
      "Gene",
      "Linguistics",
      "Philosophy",
      "Reinforcement learning",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Liang",
        "given_name": "Chengqing"
      },
      {
        "surname": "Liu",
        "given_name": "Lei"
      },
      {
        "surname": "Liu",
        "given_name": "Chen"
      }
    ]
  },
  {
    "title": "Deep learning-accelerated computational framework based on Physics Informed Neural Network for the solution of linear elasticity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.014",
    "abstract": "The paper presents an efficient and robust data-driven deep learning (DL) computational framework developed for linear continuum elasticity problems. The methodology is based on the fundamentals of the Physics Informed Neural Networks (PINNs). For an accurate representation of the field variables, a multi-objective loss function is proposed. It consists of terms corresponding to the residual of the governing partial differential equations (PDE), constitutive relations derived from the governing physics, various boundary conditions, and data-driven physical knowledge fitting terms across randomly selected collocation points in the problem domain. To this end, multiple densely connected independent artificial neural networks (ANNs), each approximating a field variable, are trained to obtain accurate solutions. Several benchmark problems including the Airy solution to elasticity and the Kirchhoff–Love plate problem are solved. Performance in terms of accuracy and robustness illustrates the superiority of the current framework showing excellent agreement with analytical solutions. The present work combines the benefits of the classical methods depending on the physical information available in analytical relations with the superior capabilities of the DL techniques in the data-driven construction of lightweight, yet accurate and robust neural networks. The models developed herein can significantly boost computational speed using minimal network parameters with easy adaptability in different computational platforms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001314",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Composite material",
      "Computer science",
      "Elasticity (physics)",
      "Function approximation",
      "Gene",
      "Materials science",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Partial differential equation",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Roy",
        "given_name": "Arunabha M."
      },
      {
        "surname": "Bose",
        "given_name": "Rikhi"
      },
      {
        "surname": "Sundararaghavan",
        "given_name": "Veera"
      },
      {
        "surname": "Arróyave",
        "given_name": "Raymundo"
      }
    ]
  },
  {
    "title": "Restoration and enhancement on low exposure raw images by joint demosaicing and denoising",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.018",
    "abstract": "Restoring high quality images from raw data in low light is challenging due to various noises caused by limited photon count and complicated Image Signal Process (ISP). Although several restoration and enhancement approaches are proposed, they may fail in extreme conditions, such as imaging short exposure raw data. The first path-breaking attempt is to utilize the connection between a pair of short and long exposure raw data and outputs RGB images as the final results. However, the whole pipeline still suffers from some blurs and color distortion. To overcome those difficulties, we propose an end-to-end network that contains two effective subnets to joint demosaic and denoise low exposure raw images. While traditional ISP are difficult to image them in acceptable conditions, the short exposure raw images can be better restored and enhanced by our model. For denoising, the proposed Short2Long raw restoration subnet outputs pseudo long exposure raw data with little noisy points. Then for demosaicing, the proposed Color consistent RGB enhancement subnet generates corresponding RGB images with the desired attributes: sharpness, color vividness, good contrast and little noise. By training the network in an end-to-end manner, our method avoids additional tuning by experts. We conduct experiments to reveal good results on three raw data datasets. We also illustrate the effectiveness of each module and the well generalization ability of this model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001442",
    "keywords": [
      "Amplifier",
      "Artificial intelligence",
      "Bandwidth (computing)",
      "Color image",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Demosaicing",
      "Distortion (music)",
      "Image (mathematics)",
      "Image processing",
      "Image restoration",
      "Noise (video)",
      "Noise reduction",
      "Pattern recognition (psychology)",
      "Pipeline (software)",
      "Programming language",
      "RGB color model",
      "Subnet"
    ],
    "authors": [
      {
        "surname": "Ma",
        "given_name": "Jiaqi"
      },
      {
        "surname": "Wang",
        "given_name": "Guoli"
      },
      {
        "surname": "Zhang",
        "given_name": "Lefei"
      },
      {
        "surname": "Zhang",
        "given_name": "Qian"
      }
    ]
  },
  {
    "title": "Edge computing on TPU for brain implant signal analysis",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.036",
    "abstract": "The ever-increasing number of recording sites of silicon-based probes imposes a great challenge for detecting and evaluating single-unit activities in an accurate and efficient manner. Currently separate solutions are available for high precision offline evaluation and separate solutions for embedded systems where computational resources are more limited. We propose a deep learning-based spike sorting system, that utilizes both unsupervised and supervised paradigms to learn a general feature embedding space and detect neural activity in raw data as well as predict the feature vectors for sorting. The unsupervised component uses contrastive learning to extract features from individual waveforms, while the supervised component is based on the MobileNetV2 architecture. One of the key advantages of our system is that it can be trained on multiple, diverse datasets simultaneously, resulting in greater generalizability than previous deep learning-based models. We demonstrate that the proposed model does not only reaches the accuracy of current state-of-art offline spike sorting methods but has the unique potential to run on edge Tensor Processing Units (TPUs), specialized chips designed for artificial intelligence and edge computing. We compare our model performance with state of art solutions on paired datasets as well as on hybrid recordings as well. The herein demonstrated system paves the way to the integration of deep learning-based spike sorting algorithms into wearable electronic devices, which will be a crucial element of high-end brain–computer interfaces.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001089",
    "keywords": [
      "Artificial intelligence",
      "Brain implant",
      "Computer hardware",
      "Computer science",
      "Digital signal processing",
      "Enhanced Data Rates for GSM Evolution",
      "Implant",
      "Medicine",
      "Programming language",
      "SIGNAL (programming language)",
      "Signal processing",
      "Surgery"
    ],
    "authors": [
      {
        "surname": "Rokai",
        "given_name": "János"
      },
      {
        "surname": "Ulbert",
        "given_name": "István"
      },
      {
        "surname": "Márton",
        "given_name": "Gergely"
      }
    ]
  },
  {
    "title": "Toward a cerebello-thalamo-cortical computational model of spinocerebellar ataxia",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.045",
    "abstract": "Computational neural network modelling is an emerging approach for optimization of drug treatment of neurological disorders and fine-tuning of rehabilitation strategies. In the current study, we constructed a cerebello-thalamo-cortical computational neural network model to simulate a mouse model of cerebellar ataxia ( pcd 5J mice) by manipulating cerebellar bursts through reduction of GABAergic inhibitory input. Cerebellar output neurons were projected to the thalamus and bidirectionally connected with the cortical network. Our results showed that reduction of inhibitory input in the cerebellum orchestrated the cortical local field potential (LFP) dynamics to generate specific motor outputs of oscillations of the theta, alpha, and beta bands in the computational model as well as in mouse motor cortical neurons. The therapeutic potential of deep brain stimulation (DBS) was tested in the computational model by increasing the sensory input to restore cortical output. Ataxia mice showed normalization of the motor cortex LFP after cerebellum DBS. We provide a novel approach to computational modelling to investigate the effect of DBS by mimicking cerebellar ataxia involving degeneration of Purkinje cells. Simulated neural activity coincides with findings from neural recordings of ataxia mice. Our computational model could thus represent cerebellar pathologies and provide insight into how to improve disease symptoms by restoring neuronal electrophysiological properties using DBS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000564",
    "keywords": [
      "Artificial intelligence",
      "Ataxia",
      "Cerebellar ataxia",
      "Cerebellar cortex",
      "Cerebellum",
      "Computational model",
      "Computer science",
      "Inhibitory postsynaptic potential",
      "Local field potential",
      "Motor cortex",
      "Neuroscience",
      "Psychology",
      "Spinocerebellar ataxia",
      "Stimulation",
      "Thalamus"
    ],
    "authors": [
      {
        "surname": "Kumar",
        "given_name": "Gajendra"
      },
      {
        "surname": "Ma",
        "given_name": "Chi Him Eddie"
      }
    ]
  },
  {
    "title": "Deep learning-based open set multi-source domain adaptation with complementary transferability metric for mechanical fault diagnosis",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.025",
    "abstract": "Intelligent fault diagnosis aims to build robust mechanical condition recognition models with limited dataset. At this stage, fault diagnosis faces two practical challenges: (1) the variability of mechanical working conditions makes the collected data distribution inconsistent, which brings about the domain shift; (2) some unpredictable unknown fault modes that do not observe in the training dataset may occur in the testing scenario, leading to a category gap. In order to cope with these two entangled challenges, an open set multi-source domain adaptation approach is developed in this study. Specifically, a complementary transferability metric defined on multiple classifiers is introduced to quantify the similarity of each target sample to known classes to weight the adversarial mechanism. By applying an unknown mode detector, unknown faults can be automatically identified. Moreover, a multi-source mutual-supervised strategy is further adopted to mine relevant information between different sources to enhance the model performance. Extensive experiments are conducted on three rotating machinery datasets, and the results show that the proposed method is superior to traditional domain adaptation approaches in the mechanical diagnosis issues that new fault modes occur.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000886",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Data mining",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Engineering",
      "Fault (geology)",
      "Geology",
      "Image (mathematics)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Metric (unit)",
      "Operations management",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Programming language",
      "Seismology",
      "Set (abstract data type)",
      "Similarity (geometry)"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Jinghui"
      },
      {
        "surname": "Han",
        "given_name": "Dongying"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      },
      {
        "surname": "Zhang",
        "given_name": "Yu"
      },
      {
        "surname": "Shi",
        "given_name": "Peiming"
      }
    ]
  },
  {
    "title": "Lifelong Text-Audio Sentiment Analysis learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.008",
    "abstract": "Sentiment analysis refers to the mining of textual context, which is conducted with the aim of identifying and extracting subjective opinions in textual materials. However, most existing methods neglect other important modalities, e.g., the audio modality, which can provide intrinsic complementary knowledge for sentiment analysis. Furthermore, much work on sentiment analysis cannot continuously learn new sentiment analysis tasks or discover potential correlations among distinct modalities. To address these concerns, we propose a novel Lifelong Text-Audio Sentiment Analysis (LTASA) model to continuously learn text-audio sentiment analysis tasks, which effectively explores intrinsic semantic relationships from both intra-modality and inter-modality perspectives. More specifically, a modality-specific knowledge dictionary is developed for each modality to obtain shared intra-modality representations among various text-audio sentiment analysis tasks. Additionally, based on information dependence between text and audio knowledge dictionaries, a complementarity-aware subspace is developed to capture the latent nonlinear inter-modality complementary knowledge. To sequentially learn text-audio sentiment analysis tasks, a new online multi-task optimization pipeline is designed. Finally, we verify our model on three common datasets to show its superiority. Compared with some baseline representative methods, the capability of the LTASA model is significantly boosted in terms of five measurement indicators.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000710",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Modalities",
      "Modality (human–computer interaction)",
      "Natural language processing",
      "Paleontology",
      "Sentiment analysis",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Lin",
        "given_name": "Yuting"
      },
      {
        "surname": "Ji",
        "given_name": "Peng"
      },
      {
        "surname": "Chen",
        "given_name": "Xiuyi"
      },
      {
        "surname": "He",
        "given_name": "Zhongshi"
      }
    ]
  },
  {
    "title": "Effects of parity, frustration, and stochastic fluctuations on integrated conceptual information for networks with two small-sized loops",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.034",
    "abstract": "This paper presents an evaluation of the system-level integrated conceptual information of a major complex for a small-scale network containing two loops in accordance with the integrated information theory 3.0 framework. We focus on the following parameters characterizing the system model: (1) number of nodes in the loop, (2) frustration of the loop, and (3) temperature controlling the stochastic fluctuation of the state transition. Effects of these parameters on the integrated conceptual information and conditions for major complexes formed by a single loop, rather than the entire network, are investigated. Our first finding is that parity of the number of nodes forming a loop has a strong effect on the integrated conceptual information. For loops with an even number of nodes, the number of concepts tends to decrease, and the integrated conceptual information becomes smaller. Our second finding is that a major complex is more likely to be formed by a small number of nodes under small stochastic fluctuations. On the other hand, the entire network can easily become a major complex under larger stochastic fluctuations, and this tendency can be reinforced by frustration. It is also shown that, although counterintuitive, the integrated conceptual information can be maximized in the presence of stochastic fluctuations. These results suggest that even when several small subnetworks are connected by only a few connections, such as a bridge, the entire network may become a major complex by introducing some stochastic fluctuations and by frustrating loops with an even number of nodes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300103X",
    "keywords": [
      "Combinatorics",
      "Complex network",
      "Computer science",
      "Condensed matter physics",
      "Counterintuitive",
      "Frustration",
      "Loop (graph theory)",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Statistical physics",
      "Theoretical computer science",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Hosaka",
        "given_name": "Tadaaki"
      }
    ]
  },
  {
    "title": "COM: Contrastive Masked-attention model for incomplete multimodal learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.003",
    "abstract": "Most multimodal learning methods assume that all modalities are always available in data. However, in real-world applications, the assumption is often violated due to privacy protection, sensor failure etc. Previous works for incomplete multimodal learning often suffer from one of the following drawbacks: introducing noise, lacking flexibility to missing patterns and failing to capture interactions between modalities. To overcome these challenges, we propose a COntrastive Masked-attention model (COM). The framework performs cross-modal contrastive learning with GAN-based augmentation to reduce modality gap, and employs a masked-attention model to capture interactions between modalities. The augmentation adapts cross-modal contrastive learning to suit incomplete case by a two-player game, improving the effectiveness of multimodal representations. Interactions between modalities are modeled by stacking self-attention blocks, and attention masks limit them on the observed modalities to avoid extra noise. All kinds of modality combinations share a unified architecture, so the model is flexible to different missing patterns. Extensive experiments on six datasets demonstrate the effectiveness and robustness of the proposed method for incomplete multimodal learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300120X",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Flexibility (engineering)",
      "Gene",
      "Machine learning",
      "Mathematics",
      "Modalities",
      "Modality (human–computer interaction)",
      "Multimodal learning",
      "Robustness (evolution)",
      "Social science",
      "Sociology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Qian",
        "given_name": "Shuwei"
      },
      {
        "surname": "Wang",
        "given_name": "Chongjun"
      }
    ]
  },
  {
    "title": "A general framework for robust stability analysis of neural networks with discrete time delays",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.040",
    "abstract": "Robust stability of different types of dynamical neural network models including time delay parameters have been extensively studied, and many different sets of sufficient conditions ensuring robust stability of these types of dynamical neural network models have been presented in past decades. In conducting stability analysis of dynamical neural systems, some basic properties of the employed activation functions and the forms of delay terms included in the mathematical representations of dynamical neural networks are of crucial importance in obtaining global stability criteria for dynamical neural systems. Therefore, this research article will examine a class of neural networks expressed by a mathematical model that involves the discrete time delay terms, the Lipschitz activation functions and possesses the intervalized parameter uncertainties. This paper will first present a new and alternative upper bound value of the second norm of the class of interval matrices, which will have an important impact on obtaining the desired results for establishing robust stability of these neural network models. Then, by exploiting wellknown Homeomorphism mapping theory and basic Lyapunov stability theory, we will state a new general framework for determining some novel robust stability conditions for dynamical neural networks possessing discrete time delay terms. This paper will also make a comprehensive review of some previously published robust stability results and show that the existing robust stability results can be easily derived from the results given in this paper.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001120",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cellular neural network",
      "Class (philosophy)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Dynamical systems theory",
      "Lipschitz continuity",
      "Lyapunov function",
      "Machine learning",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Stability (learning theory)",
      "Statistics",
      "Stochastic neural network"
    ],
    "authors": [
      {
        "surname": "Solak",
        "given_name": "Melike"
      },
      {
        "surname": "Faydasicok",
        "given_name": "Ozlem"
      },
      {
        "surname": "Arik",
        "given_name": "Sabri"
      }
    ]
  },
  {
    "title": "A dynamical model of visual motion processing for arbitrary stimuli including type II plaids",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.039",
    "abstract": "To explore the operating principle of visual motion processing in the brain underlying perception and eye movements, we model the information processing of velocity estimate of the visual stimulus at the algorithmic level using the dynamical system approach. In this study, we formulate the model as an optimization process of an appropriately defined objective function. The model is applicable to arbitrary visual stimuli. We find that our theoretical predictions qualitatively agree with time evolution of eye movement reported by previous works across various types of stimulus. Our results suggest that the brain implements the present framework as the internal model of motion vision. We anticipate our model to be a promising building block for more profound understanding of visual motion processing as well as for the development of robotics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001107",
    "keywords": [
      "Artificial intelligence",
      "Cognitive psychology",
      "Computer science",
      "Computer vision",
      "Eye movement",
      "Motion (physics)",
      "Motion perception",
      "Neuroscience",
      "Perception",
      "Psychology",
      "Robot",
      "Robotics",
      "Stimulus (psychology)",
      "Visual perception",
      "Visual processing"
    ],
    "authors": [
      {
        "surname": "Korai",
        "given_name": "Yusuke"
      },
      {
        "surname": "Miura",
        "given_name": "Kenichiro"
      }
    ]
  },
  {
    "title": "A learnable sampling method for scalable graph neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.015",
    "abstract": "With the development of graph neural networks, how to handle large-scale graph data has become an increasingly important topic. Currently, most graph neural network models which can be extended to large-scale graphs are based on random sampling methods. However, the sampling process in these models is detached from the forward propagation of neural networks. Moreover, quite a few works design sampling based on statistical estimation methods for graph convolutional networks and the weights of message passing in GCNs nodes are fixed, making these sampling methods not scalable to message passing networks with variable weights, such as graph attention networks. Noting the end-to-end learning capability of neural networks, we propose a learnable sampling method. It solves the problem that random sampling operations cannot calculate gradients and samples nodes with an unfixed probability. In this way, the sampling process is dynamically combined with the forward propagation process of the features, allowing for better training of the networks. And it can be generalized to all message passing models. In addition, we apply the learnable sampling method to GNNs and propose two models. Our method can be flexibly combined with different graph neural network models and achieves excellent accuracy on benchmark datasets with large graphs. Meanwhile, loss function converges to smaller values at a faster rate during training than past methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001326",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Database",
      "Distributed computing",
      "Filter (signal processing)",
      "Graph",
      "Message passing",
      "Sampling (signal processing)",
      "Scalability",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Weichen"
      },
      {
        "surname": "Guo",
        "given_name": "Tiande"
      },
      {
        "surname": "Yu",
        "given_name": "Xiaoxi"
      },
      {
        "surname": "Han",
        "given_name": "Congying"
      }
    ]
  },
  {
    "title": "Genetic hyperparameter optimization with Modified Scalable-Neighbourhood Component Analysis for breast cancer prognostication",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.035",
    "abstract": "Breast cancer is common among women resulting in mortality when left untreated. Early detection is vital so that suitable treatment could assist cancer from spreading further and save people’s life. The traditional way of detection is a time-consuming process. With the evolvement of DM (Data Mining), the healthcare industry could be benefitted in predicting the disease as it permits the physicians to determine the significant attributes for diagnosis. Though, conventional techniques have used DM-based methods to identify breast cancer, they lacked in terms of prediction rate. Moreover, parametric-Softmax classifiers have been a general option by conventional works with fixed classes, particularly when huge labelled data are present during training. Nevertheless, this turns into an issue for open set cases where new classes are encountered along with few instances to learn a generalized parametric classifier. Thus, the present study aims to implement a non-parametric strategy by optimizing the embedding of a feature rather than parametric classifiers. This research utilizes Deep CNN (Deep Convolutional Neural Network) and Inception V3 for learning visual features which preserve neighbourhood outline in semantic space relying on NCA (Neighbourhood Component Analysis) criteria. Delimited by its bottleneck, the study proposes MS-NCA (Modified Scalable-Neighbourhood Component Analysis) that relies on a non-linear objective function to perform feature fusion by optimizing the distance-learning objective due to which it gains the capability of computing inner feature products without performing mapping which increases the scalability of MS-NCA. Finally, G-HPO (Genetic-Hyper-parameter Optimization) is proposed. In this case, the new stage in the algorithm simply denotes the enhancement in the length of chromosome bringing several hyperparameters into subsequent XGBoost, NB and RF models having numerous layers for identifying the normal and affected cases of breast cancer for which optimized hyper-parameter values of RF (Random Forest), NB (Naïve Bayes), and XGBoost (eXtreme Gradient Boosting) are determined. This process helps in improvising the classification rate which is confirmed through analytical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001077",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bottleneck",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Database",
      "Embedded system",
      "Hyperparameter",
      "Machine learning",
      "Mathematics",
      "Parametric statistics",
      "Pattern recognition (psychology)",
      "Scalability",
      "Softmax function",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Alsubai",
        "given_name": "Shtwai"
      },
      {
        "surname": "Alqahtani",
        "given_name": "Abdullah"
      },
      {
        "surname": "Sha",
        "given_name": "Mohemmed"
      }
    ]
  },
  {
    "title": "Disturbance rejection for multi-weighted complex dynamical networks with actuator saturation and deception attacks via hybrid-triggered mechanism",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.031",
    "abstract": "In this work, we address hybrid-driven-based robust synchronization problem for multi-weighted complex dynamical networks with actuator saturation and deception attacks. The hybrid-triggered mechanism, which combines a switch between the event-triggered scheme and the time-triggered scheme, is often used to reduce the data transmission and the alleviate network burden. Further, the equivalent-input-disturbance technique is applied to eliminate the unknown disturbance effect of the addressed system. Moreover, a memory controller is designed under actuator saturation to ensure that the resultant augmented system is asymptotically synchronized even in the presence of deception attacks. Finally, three numerical examples are given to show the validity of the obtained theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001004",
    "keywords": [
      "Actuator",
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Deception",
      "Disturbance (geology)",
      "Law",
      "Mathematical analysis",
      "Mathematics",
      "Mechanism (biology)",
      "Paleontology",
      "Physics",
      "Political science",
      "Quantum mechanics",
      "Saturation (graph theory)",
      "Scheme (mathematics)",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Sakthivel",
        "given_name": "R."
      },
      {
        "surname": "Kwon",
        "given_name": "O.M."
      },
      {
        "surname": "Park",
        "given_name": "M.J."
      },
      {
        "surname": "Lee",
        "given_name": "S.M."
      },
      {
        "surname": "Sakthivel",
        "given_name": "R."
      }
    ]
  },
  {
    "title": "ProMask: Probability mask representation for skeleton detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.033",
    "abstract": "Detecting object skeletons in natural images presents challenges due to varied object scales and complex backgrounds. The skeleton is a highly compressing shape representation, which can bring some essential advantages but cause difficulties in detection. This skeleton line occupies a small part of the image and is overly sensitive to spatial position. Inspired by these issues, we propose the ProMask, which is a novel skeleton detection model. The ProMask includes the probability mask representation and vector router. This skeleton probability mask describes the gradual formation process of skeleton points, which can achieve high detection performance and robustness. Moreover, the vector router module possesses two sets of orthogonal basis vectors in a two-dimensional space, which can dynamically adjust the predicted skeleton position. Experiments show that our approach realizes better performance, efficiency, and robustness than state-of-the-art methods. We consider that our proposed skeleton probability representation will serve as a standard configuration for future skeleton detection, since it is reasonable, simple, and very effective.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001028",
    "keywords": [
      "Active shape model",
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Gene",
      "Law",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Programming language",
      "Representation (politics)",
      "Robustness (evolution)",
      "Segmentation",
      "Skeleton (computer programming)",
      "Topological skeleton"
    ],
    "authors": [
      {
        "surname": "Bai",
        "given_name": "Xiuxiu"
      },
      {
        "surname": "Ye",
        "given_name": "Lele"
      },
      {
        "surname": "Liu",
        "given_name": "Zhe"
      },
      {
        "surname": "Liu",
        "given_name": "Bin"
      }
    ]
  },
  {
    "title": "Uncertainty maximization in partially observable domains: A cognitive perspective",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.044",
    "abstract": "Faced with an ever-increasing complexity of their domains of application, artificial learning agents are now able to scale up in their ability to process an overwhelming amount of data. However, this comes at the cost of encoding and processing an increasing amount of redundant information. This work exploits the possibility of learning systems, applied in partially observable domains, to selectively focus on the specific type of information that is more likely related to the causal interaction among transitioning states. A temporal difference displacement criterion is defined to implement adaptive masking of the observations. It can enable a significant improvement of convergence of temporal difference algorithms applied to partially observable Markov processes, as shown by experiments performed under a variety of machine learning problems, ranging from highly complex visuals as Atari games to simple textbook control problems such as CartPole. The proposed framework can be added to most RL algorithms since it only affects the observation process, selecting the parts more promising to explain the dynamics of the environment and reducing the dimension of the observation space.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001168",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Convergence (economics)",
      "Dimension (graph theory)",
      "Economic growth",
      "Economics",
      "Exploit",
      "Focus (optics)",
      "Machine learning",
      "Markov chain",
      "Markov model",
      "Mathematical optimization",
      "Mathematics",
      "Maximization",
      "Observable",
      "Operating system",
      "Optics",
      "Partially observable Markov decision process",
      "Perspective (graphical)",
      "Physics",
      "Process (computing)",
      "Pure mathematics",
      "Quantum mechanics",
      "Theoretical computer science",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Ramicic",
        "given_name": "Mirza"
      },
      {
        "surname": "Bonarini",
        "given_name": "Andrea"
      }
    ]
  },
  {
    "title": "Dual adaptive learning multi-task multi-view for graph network representation learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.026",
    "abstract": "Graph network analysis, which achieves widely application, is to explore and mine the graph structure data. However, existing graph network analysis methods with graph representation learning technique ignore the correlation between multiple graph network analysis tasks, and they need massive repeated calculation to obtain each graph network analysis results. Or they cannot adaptively balance the relative importance of multiple graph network analysis tasks, that lead to weak model fitting. Besides, most of existing methods ignore multiplex views semantic information and global graph information, which fail to learn robust node embeddings resulting in unsatisfied graph analysis results. To solve these issues, we propose a multi-task multi-view adaptive graph network representation learning model, called M 2 agl. The highlights of M 2 agl are as follows: (1) Graph convolutional network with the linear combination of the adjacency matrix and PPMI (positive point-wise mutual information) matrix is utilized as encoder to extract the local and global intra-view graph feature information of the multiplex graph network. Each intra-view graph information of the multiplex graph network can adaptively learn the parameters of graph encoder. (2) We use regularization to capture the interaction information among different graph views, and the importance of different graph views are learned by view attention mechanism for further inter-view graph network fusion. (3) The model is trained oriented by multiple graph network analysis tasks. The relative importance of multiple graph network analysis tasks are adjusted adaptively with the homoscedastic uncertainty. The regularization can be considered as an auxiliary task to further boost the performance. Experiments on real-worlds attributed multiplex graph networks demonstrate the effectiveness of M 2 agl in comparison with other competing approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000898",
    "keywords": [
      "Adjacency matrix",
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Graph property",
      "Line graph",
      "Null graph",
      "Theoretical computer science",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Han",
        "given_name": "Beibei"
      },
      {
        "surname": "Wei",
        "given_name": "Yingmei"
      },
      {
        "surname": "Wang",
        "given_name": "Qingyong"
      },
      {
        "surname": "Wan",
        "given_name": "Shanshan"
      }
    ]
  },
  {
    "title": "Traffic forecasting with graph spatial–temporal position recurrent network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.03.009",
    "abstract": "With the development of social economy and smart technology, the explosive growth of vehicles has caused traffic forecasting to become a daunting challenge, especially for smart cities. Recent methods exploit graph spatial–temporal characteristics, including constructing the shared patterns of traffic data, and modeling the topological space of traffic data. However, existing methods fail to consider the spatial position information and only utilize little spatial neighborhood information. To tackle above limitation, we design a Graph Spatial–Temporal Position Recurrent Network (GSTPRN) architecture for traffic forecasting. We first construct a position graph convolution module based on self-attention and calculate the dependence strengths among the nodes to capture the spatial dependence relationship. Next, we develop approximate personalized propagation that extends the propagation range of spatial dimension information to obtain more spatial neighborhood information. Finally, we systematically integrate the position graph convolution, approximate personalized propagation and adaptive graph learning into a recurrent network (i.e. Gated Recurrent Units). Experimental evaluation on two benchmark traffic datasets demonstrates that GSTPRN is superior to the state-of-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001260",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Convolution (computer science)",
      "Data mining",
      "Economics",
      "Exploit",
      "Finance",
      "Geography",
      "Geometry",
      "Graph",
      "Machine learning",
      "Mathematics",
      "Position (finance)",
      "Remote sensing",
      "Spatial analysis",
      "Spatial network",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Yibi"
      },
      {
        "surname": "Li",
        "given_name": "Kenli"
      },
      {
        "surname": "Yeo",
        "given_name": "Chai Kiat"
      },
      {
        "surname": "Li",
        "given_name": "Keqin"
      }
    ]
  },
  {
    "title": "Vertex points are not enough: Monocular 3D object detection via intra- and inter-plane constraints",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.038",
    "abstract": "Existed methods for 3D object detection in monocular images focus mainly on the class of rigid bodies like cars, while more challenging detection like the cyclist is less studied. Therefore, we propose a novel 3D monocular object detection method to improve the accuracy of detection objects with large differences in deformation by introducing the geometric constraints of the object 3D bounding box plane. Considering the map relationship of projection plane and the keypoint, we firstly introduce the geometric constraints of the object 3D bounding box plane, adding the intra-plane constraint while regressing the position and offset of the keypoint itself, so that the position and offset error of the keypoint are always within the error range of the projection plane. For the inter-plane geometry relationship of the 3D bounding box, the prior knowledge is incorporated to optimize the keypoint regression allowing for improved the accuracy of depth location prediction. Experimental results show that the proposed method outperforms some other state-of-the-art methods on cyclist class, and obtains competitive results in the field of real-time monocular detection.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001119",
    "keywords": [
      "Artificial intelligence",
      "Bounding overwatch",
      "Computer science",
      "Computer vision",
      "Economics",
      "Finance",
      "Geometry",
      "Graph",
      "Image (mathematics)",
      "Image plane",
      "Mathematics",
      "Minimum bounding box",
      "Monocular",
      "Object detection",
      "Offset (computer science)",
      "Pattern recognition (psychology)",
      "Plane (geometry)",
      "Position (finance)",
      "Programming language",
      "Projection plane",
      "Theoretical computer science",
      "Vertex (graph theory)"
    ],
    "authors": [
      {
        "surname": "Yao",
        "given_name": "Hongdou"
      },
      {
        "surname": "Chen",
        "given_name": "Jun"
      },
      {
        "surname": "Wang",
        "given_name": "Zheng"
      },
      {
        "surname": "Wang",
        "given_name": "Xiao"
      },
      {
        "surname": "Chai",
        "given_name": "Xiaoyu"
      },
      {
        "surname": "Qiu",
        "given_name": "Yansheng"
      },
      {
        "surname": "Han",
        "given_name": "Pengfei"
      }
    ]
  },
  {
    "title": "Mittag-Leffler stability of fractional-order quaternion-valued memristive neural networks with generalized piecewise constant argument",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.030",
    "abstract": "This paper studies the global Mittag-Leffler (M-L) stability problem for fractional-order quaternion-valued memristive neural networks (FQVMNNs) with generalized piecewise constant argument (GPCA). First, a novel lemma is established, which is used to investigate the dynamic behaviors of quaternion-valued memristive neural networks (QVMNNs). Second, by using the theories of differential inclusion, set-valued mapping, and Banach fixed point, several sufficient criteria are derived to ensure the existence and uniqueness (EU) of the solution and equilibrium point for the associated systems. Then, by constructing Lyapunov functions and employing some inequality techniques, a set of criteria are proposed to ensure the global M-L stability of the considered systems. The obtained results in this paper not only extends previous works, but also provides new algebraic criteria with a larger feasible range. Finally, two numerical examples are introduced to illustrate the effectiveness of the obtained results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000990",
    "keywords": [
      "Applied mathematics",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Constant (computer programming)",
      "Differential equation",
      "Differential inclusion",
      "Ecology",
      "Equilibrium point",
      "Geometry",
      "Lemma (botany)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Piecewise",
      "Poaceae",
      "Programming language",
      "Quaternion",
      "Stability (learning theory)",
      "Uniqueness"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jingjing"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      },
      {
        "surname": "Liu",
        "given_name": "Xiaoyang"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Mittag-Leffler stability of fractional-order quaternion-valued memristive neural networks with generalized piecewise constant argument",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.030",
    "abstract": "This paper studies the global Mittag-Leffler (M-L) stability problem for fractional-order quaternion-valued memristive neural networks (FQVMNNs) with generalized piecewise constant argument (GPCA). First, a novel lemma is established, which is used to investigate the dynamic behaviors of quaternion-valued memristive neural networks (QVMNNs). Second, by using the theories of differential inclusion, set-valued mapping, and Banach fixed point, several sufficient criteria are derived to ensure the existence and uniqueness (EU) of the solution and equilibrium point for the associated systems. Then, by constructing Lyapunov functions and employing some inequality techniques, a set of criteria are proposed to ensure the global M-L stability of the considered systems. The obtained results in this paper not only extends previous works, but also provides new algebraic criteria with a larger feasible range. Finally, two numerical examples are introduced to illustrate the effectiveness of the obtained results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000990",
    "keywords": [
      "Applied mathematics",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Constant (computer programming)",
      "Differential equation",
      "Differential inclusion",
      "Ecology",
      "Equilibrium point",
      "Geometry",
      "Lemma (botany)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Piecewise",
      "Poaceae",
      "Programming language",
      "Quaternion",
      "Stability (learning theory)",
      "Uniqueness"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jingjing"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      },
      {
        "surname": "Liu",
        "given_name": "Xiaoyang"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "An effective knowledge graph entity alignment model based on multiple information",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.029",
    "abstract": "Entity alignment refers to matching entities with the same realistic meaning in different knowledge graphs. The structure of a knowledge graph provides the global signal for entity alignment. But in the real world, a knowledge graph provides insufficient structural information in general. Moreover, the problem of knowledge graph heterogeneity is common. The semantic and string information can alleviate the problems caused by the sparse and heterogeneous nature of knowledge graphs, yet both of them have not been fully utilized by most existing work. Therefore, we propose an entity alignment model based on multiple information (EAMI), which employs structural, semantic and string information. EAMI learns the structural representation of a knowledge graph by using multi-layer graph convolutional networks. To acquire more accurate entity vector representation, we incorporate the attribute semantic representation into the structural representation. In addition, to further improve entity alignment, we study the entity name string information. There is no training required to calculate the similarity of entity names. Our model is tested on publicly available cross-lingual datasets and cross-resource datasets, and the experimental results demonstrate the effectiveness of our model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000989",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Information retrieval",
      "Knowledge graph",
      "Law",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Semantic similarity",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Beibei"
      },
      {
        "surname": "Bao",
        "given_name": "Tie"
      },
      {
        "surname": "Han",
        "given_name": "Ridong"
      },
      {
        "surname": "Cui",
        "given_name": "Hai"
      },
      {
        "surname": "Han",
        "given_name": "Jiayu"
      },
      {
        "surname": "Liu",
        "given_name": "Lu"
      },
      {
        "surname": "Peng",
        "given_name": "Tao"
      }
    ]
  },
  {
    "title": "NLS: An accurate and yet easy-to-interpret prediction method",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.043",
    "abstract": "Over the last years, the predictive power of supervised machine learning (ML) has undergone impressive advances, achieving the status of state of the art and super-human level in some applications. However, the employment rate of ML models in real-life applications is much slower than one would expect. One of the downsides of using ML solution-based technologies is the lack of user trust in the produced model, which is related to the black-box nature of these models. To leverage the application of ML models, the generated predictions should be easy to interpret while maintaining a high accuracy. In this context, we develop the Neural Local Smoother (NLS), a neural network architecture that yields accurate predictions with easy-to-obtain explanations. The key idea of NLS is to add a smooth local linear layer to a standard network. We show experiments that indicate that NLS leads to a predictive power that is comparable to state-of-the-art machine learning models, but that at the same time is easier to interpret.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023001156",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Black box",
      "Computer science",
      "Context (archaeology)",
      "Deep learning",
      "Deep neural networks",
      "Epistemology",
      "Leverage (statistics)",
      "Machine learning",
      "Paleontology",
      "Philosophy",
      "Predictive power",
      "State (computer science)"
    ],
    "authors": [
      {
        "surname": "Coscrato",
        "given_name": "Victor"
      },
      {
        "surname": "Inácio",
        "given_name": "Marco H.A."
      },
      {
        "surname": "Botari",
        "given_name": "Tiago"
      },
      {
        "surname": "Izbicki",
        "given_name": "Rafael"
      }
    ]
  },
  {
    "title": "SuperFormer: Continual learning superposition method for text classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.040",
    "abstract": "One of the biggest challenges in continual learning domains is the tendency of machine learning models to forget previously learned information over time. While overcoming this issue, the existing approaches often exploit large amounts of additional memory and apply model forgetting mitigation mechanisms which substantially prolong the training process. Therefore, we propose a novel SuperFormer method that alleviates model forgetting, while spending negligible additional memory and time. We tackle the continual learning challenges in a learning scenario, where we learn different tasks in a sequential order. We compare our method against several prominent continual learning methods, i.e., EWC, SI, MAS, GEM, PSP, etc. on a set of text classification tasks. We achieve the best average performance in terms of AUROC and AUPRC (0.7% and 0.9% gain on average, respectively) and the lowest training time among all the methods of comparison. On average, our method reduces the total training time by a factor of 5.4-8.5 in comparison to similarly performing methods. In terms of the additional memory, our method is on par with the most memory-efficient approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000527",
    "keywords": [
      "Artificial intelligence",
      "Cognitive psychology",
      "Computer science",
      "Computer security",
      "Exploit",
      "Forgetting",
      "Machine learning",
      "Operating system",
      "Process (computing)",
      "Programming language",
      "Psychology",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Zeman",
        "given_name": "Marko"
      },
      {
        "surname": "Pucer",
        "given_name": "Jana Faganeli"
      },
      {
        "surname": "Kononenko",
        "given_name": "Igor"
      },
      {
        "surname": "Bosnić",
        "given_name": "Zoran"
      }
    ]
  },
  {
    "title": "Memory-efficient Transformer-based network model for Traveling Salesman Problem",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.014",
    "abstract": "Combinatorial optimization problems such as Traveling Salesman Problem (TSP) have a wide range of real-world applications in transportation, logistics, manufacturing. It has always been a difficult problem to solve large-scale TSP problems quickly because of memory usage limitations. Recent research shows that the Transformer model is a promising approach. However, the Transformer has several severe problems that prevent it from quickly solving TSP combinatorial optimization problems, such as quadratic time complexity, especially quadratic space complexity, and the inherent limitations of the encoder and decoder itself. To address these issues, we developed a memory-efficient Transformer-based network model for TSP combinatorial optimization problems, termed Tspformer, with two distinctive characteristics: (1) a sampled scaled dot-product attention mechanism with O ( L log ( L ) ) (L is the length of input sequences) time and space complexity, which is the most different between our work and other works. (2) due to the reduced space complexity, GPU/CPU memory usage is significantly reduced. Extensive experiments demonstrate that Tspformer significantly outperforms existing methods and provides a new solution to the TSP combinatorial optimization problems. Our Pytorch code will be publicly available on GitHub https://github.com/yhnju/tspFormer.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000771",
    "keywords": [
      "Algorithm",
      "Combinatorial optimization",
      "Computer science",
      "Geometry",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Physics",
      "Quadratic assignment problem",
      "Quadratic equation",
      "Quantum mechanics",
      "Transformer",
      "Travelling salesman problem",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Hua"
      },
      {
        "surname": "Zhao",
        "given_name": "Minghao"
      },
      {
        "surname": "Yuan",
        "given_name": "Lei"
      },
      {
        "surname": "Yu",
        "given_name": "Yang"
      },
      {
        "surname": "Li",
        "given_name": "Zhenhua"
      },
      {
        "surname": "Gu",
        "given_name": "Ming"
      }
    ]
  },
  {
    "title": "Rapid learning of spatial representations for goal-directed navigation based on a novel model of hippocampal place fields",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.010",
    "abstract": "The discovery of place cells and other spatially modulated neurons in the hippocampal complex of rodents has been crucial to elucidating the neural basis of spatial cognition. More recently, the replay of neural sequences encoding previously experienced trajectories has been observed during consummatory behavior—potentially with implications for rapid learning, quick memory consolidation, and behavioral planning. Several promising models for robotic navigation and reinforcement learning have been proposed based on these and previous findings. Most of these models, however, use carefully engineered neural networks, and sometimes require long learning periods. In this paper, we present a self-organizing model incorporating place cells and replay, and demonstrate its utility for rapid one-shot learning in non-trivial environments with obstacles.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000102",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognition",
      "Cognitive map",
      "Computer science",
      "Encoding (memory)",
      "Hippocampal formation",
      "Hippocampus",
      "Machine learning",
      "Memory consolidation",
      "Neuroscience",
      "Place cell",
      "Psychology",
      "Reinforcement learning",
      "Spatial memory",
      "Working memory"
    ],
    "authors": [
      {
        "surname": "Alabi",
        "given_name": "Adedapo"
      },
      {
        "surname": "Vanderelst",
        "given_name": "Dieter"
      },
      {
        "surname": "Minai",
        "given_name": "Ali A."
      }
    ]
  },
  {
    "title": "Multi-relational graph convolutional networks: Generalization guarantees and experiments",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.044",
    "abstract": "The class of multi-relational graph convolutional networks (MRGCNs) is a recent extension of standard graph convolutional networks (GCNs) to handle heterogenous graphs with multiple types of relationships. MRGCNs have been shown to yield results superior than traditional GCNs in various machine learning tasks. The key idea is to introduce a new kind of convolution operated on tensors that can effectively exploit correlations exhibited in multiple relationships. The main objective of this paper is to analyze the algorithmic stability and generalization guarantees of MRGCNs to confirm the usefulness of MRGCNs. Our contributions are of three folds. First, we develop a matrix representation of various tensor operations underneath MRGCNs to simplify the analysis significantly. Next, we prove the uniform stability of MRGCNs and deduce the convergence of the generalization gap to support the usefulness of MRGCNs. The analysis sheds lights on the design of MRGCNs, for instance, how the data should be scaled to achieve the uniform stability of the learning process. Finally, we provide experimental results to demonstrate the stability results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000576",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Extension (predicate logic)",
      "Generalization",
      "Graph",
      "Group (periodic table)",
      "Law",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Matrix representation",
      "Organic chemistry",
      "Political science",
      "Politics",
      "Programming language",
      "Representation (politics)",
      "Stability (learning theory)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xutao"
      },
      {
        "surname": "Ng",
        "given_name": "Michael K."
      },
      {
        "surname": "Xu",
        "given_name": "Guangning"
      },
      {
        "surname": "Yip",
        "given_name": "Andy"
      }
    ]
  },
  {
    "title": "Fractional derivative based weighted skip connections for satellite image road segmentation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.031",
    "abstract": "Segmentation of a road portion from a satellite image is challenging due to its complex background, occlusion, shadows, clouds, and other optical artifacts. One must combine both local and global cues for an accurate and continuous/connected road network extraction. This paper proposes a model using fractional derivative-based weighted skip connections on a densely connected convolutional neural network for road segmentation. Weights corresponding to the skip connections are determined using Grunwald–Letnikov fractional derivative. Fractional derivatives being non-local in nature incorporates memory into the system and thereby combine both local and global features. Experiments have been performed on two open source widely used benchmark databases v i z . Massachusetts Road database (MRD) and Ottawa Road database (ORD). Both these datasets represent different road topography and network structure including varying road widths and complexities. Result reveals that the proposed system demonstrated better performance than the other state-of-the-art methods by achieving an F1-score of 0.748 and the mIoU of 0.787 at fractional order 0.4 on the MRD and a mIoU of 0.9062 at fractional order 0.5 on the ORD.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000436",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Cartography",
      "Computer science",
      "Convolutional neural network",
      "Fractional calculus",
      "Geography",
      "Image (mathematics)",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Arora",
        "given_name": "Sugandha"
      },
      {
        "surname": "Suman",
        "given_name": "Harsh Kumar"
      },
      {
        "surname": "Mathur",
        "given_name": "Trilok"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      },
      {
        "surname": "Tiwari",
        "given_name": "Kamlesh"
      }
    ]
  },
  {
    "title": "Achieving efficient interpretability of reinforcement learning via policy distillation and selective input gradient regularization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.025",
    "abstract": "Although deep Reinforcement Learning (RL) has proven successful in a wide range of tasks, one challenge it faces is interpretability when applied to real-world problems. Saliency maps are frequently used to provide interpretability for deep neural networks. However, in the RL domain, existing saliency map approaches are either computationally expensive and thus cannot satisfy the real-time requirement of real-world scenarios or cannot produce interpretable saliency maps for RL policies. In this work, we propose an approach of Distillation with selective Input Gradient Regularization (DIGR) which uses policy distillation and input gradient regularization to produce new policies that achieve both high interpretability and computation efficiency in generating saliency maps. Our approach is also found to improve the robustness of RL policies to multiple adversarial attacks. We conduct experiments on three tasks, MiniGrid (Fetch Object), Atari (Breakout) and CARLA Autonomous Driving, to demonstrate the importance and effectiveness of our approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000254",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep neural networks",
      "Distillation",
      "Gene",
      "Interpretability",
      "Machine learning",
      "Organic chemistry",
      "Regularization (linguistics)",
      "Reinforcement learning",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Xing",
        "given_name": "Jinwei"
      },
      {
        "surname": "Nagata",
        "given_name": "Takashi"
      },
      {
        "surname": "Zou",
        "given_name": "Xinyun"
      },
      {
        "surname": "Neftci",
        "given_name": "Emre"
      },
      {
        "surname": "Krichmar",
        "given_name": "Jeffrey L."
      }
    ]
  },
  {
    "title": "Leveraging joint incremental learning objective with data ensemble for class incremental learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.017",
    "abstract": "A class-incremental learning problem is characterized by training data becoming available in a phase-by-phase manner. Deep learning models suffer from catastrophic forgetting of the classes in the older phases as they get trained on the classes introduced in the new phase. In this work, we show that the change in orientation of an image has a considerable effect on the model prediction accuracy, which in turn demonstrates the different rates of catastrophic forgetting for the different orientations of the same image, which is a novel finding. Based on this, we propose a data-ensemble approach that combines the predictions for the different orientations of the image to help the model retain information regarding the previously seen classes and thereby reduce the rate of forgetting in the model predictions. However, we cannot directly use the data-ensemble approach if the model is trained using traditional techniques. Therefore, we also propose a novel training approach using a joint-incremental learning objective (JILO) that involves jointly training the network with two incremental learning objectives, i.e., the class-incremental learning objective and our proposed data-incremental learning objective. We empirically demonstrate that JILO is vital to the data-ensemble approach. We apply our proposed approach to state-of-the-art class-incremental learning methods and empirically show that our approach significantly improves the performance of these methods. Our proposed approach significantly improves the performance of the state-of-the-art method (AANets) on the CIFAR-100 dataset by absolute margins of 3.30%, 4.28%, 3.55%, 4.03%, for the number of phases P = 50, 25, 10, and 5, respectively, which establishes the efficacy of the proposed work.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000175",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Computer science",
      "Ensemble learning",
      "Forgetting",
      "Incremental learning",
      "Linguistics",
      "Machine learning",
      "Philosophy"
    ],
    "authors": [
      {
        "surname": "Mazumder",
        "given_name": "Pratik"
      },
      {
        "surname": "Karim",
        "given_name": "Mohammed Asad"
      },
      {
        "surname": "Joshi",
        "given_name": "Indu"
      },
      {
        "surname": "Singh",
        "given_name": "Pravendra"
      }
    ]
  },
  {
    "title": "Nonconvex low-rank tensor approximation with graph and consistent regularizations for multi-view subspace learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.016",
    "abstract": "Multi-view clustering is widely used to improve clustering performance. Recently, the subspace clustering tensor learning method based on Markov chain is a crucial branch of multi-view clustering. Tensor learning is commonly used to apply tensor low-rank approximation to represent the relationships between data samples. However, most of the current tensor learning methods have the following shortcomings: the information of the local graph is not taken into account, the relationships between different views are not shown, and the existing tensor low-rank representation takes a biased tensor rank function for estimation. Therefore, a nonconvex low-rank tensor approximation with graph and consistent regularizations (NLRTGC) model is proposed for multi-view subspace learning. NLRTGC retains the local manifold information through graph regularization, and adopts a consistent regularization between multi-views to keep the diagonal block structure of representation matrices. Furthermore, a nonnegative nonconvex low-rank tensor kernel function is used to replace the existing classical tensor nuclear norm via tensor-singular value decomposition (t-SVD), so as to reduce the deviation from rank. Then, an alternating direction method of multipliers (ADMM) which makes the objective function monotonically non-increasing is proposed to solve NLRTGC. Finally, the effectiveness and superiority of the NLRTGC are shown through abundant comparative experiments with various state-of-the-art algorithms on noisy datasets and real world datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000795",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Combinatorics",
      "Computer science",
      "Eigenvalues and eigenvectors",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Matrix norm",
      "Pattern recognition (psychology)",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Rank (graph theory)",
      "Subspace topology",
      "Tensor (intrinsic definition)"
    ],
    "authors": [
      {
        "surname": "Pan",
        "given_name": "Baicheng"
      },
      {
        "surname": "Li",
        "given_name": "Chuandong"
      },
      {
        "surname": "Che",
        "given_name": "Hangjun"
      }
    ]
  },
  {
    "title": "Feature relocation network for fine-grained image classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.050",
    "abstract": "In fine-grained image classification, there are only very subtle differences between classes. It is challenging to learn local discriminative features and remove distractive features in fine-grained image classification. Existing fine-grained image classification methods learn discriminative feature mainly via manual part annotation or attention mechanisms. However, due to the large intraclass variance and interclass similarity, the discriminative information and distractive information still are not distinguished effectively. To address this problem, we propose a feature relocation network (FRe-Net) which takes advantage of the different natures of features learned from different stages of the network. Our network consists of a distractive feature learning module and a relocated high-level feature learning module. In the distractive feature learning module, we propose to exploit the difference between low-level features and high-level features to design a distractive loss L d i s t r a c t i v e , which guides the attention to locate distractive regions more accurately. In the relocated high-level feature learning module, we enhance the representing capacity of the middle-level feature via the attention module and subtract the distractive feature learned from the distractive feature learning module in order to learn more local discriminative features. In end-to-end model training, the distractive feature learning module and the relocated high-level feature learning module are beneficial to each other via joint optimization. We conducted comprehensive experiments on three benchmark datasets widely used in fine-grained image classification. The experimental results show that FRe-Net achieves state-of-the-art performance, which validates the effectiveness of FRe-Net.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300062X",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Discriminative model",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Peng"
      },
      {
        "surname": "Li",
        "given_name": "Yi"
      },
      {
        "surname": "Tang",
        "given_name": "Baowei"
      },
      {
        "surname": "Liu",
        "given_name": "Huiting"
      },
      {
        "surname": "Yao",
        "given_name": "Sheng"
      }
    ]
  },
  {
    "title": "CrimeNet: Neural Structured Learning using Vision Transformer for violence detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.048",
    "abstract": "The state of the art in violence detection in videos has improved in recent years thanks to deep learning models, but it is still below 90% of average precision in the most complex datasets, which may pose a problem of frequent false alarms in video surveillance environments and may cause security guards to disable the artificial intelligence system. In this study, we propose a new neural network based on Vision Transformer (ViT) and Neural Structured Learning (NSL) with adversarial training. This network, called CrimeNet, outperforms previous works by a large margin and reduces practically to zero the false positives. Our tests on the four most challenging violence-related datasets (binary and multi-class) show the effectiveness of CrimeNet, improving the state of the art from 9.4 to 22.17 percentage points in ROC AUC depending on the dataset. In addition, we present a generalisation study on our model by training and testing it on different datasets. The obtained results show that CrimeNet improves over competing methods with a gain of between 12.39 and 25.22 percentage points, showing remarkable robustness.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000606",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Binary classification",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "False positive paradox",
      "Gene",
      "Machine learning",
      "Margin (machine learning)",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Robustness (evolution)",
      "Support vector machine",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Rendón-Segador",
        "given_name": "Fernando J."
      },
      {
        "surname": "Álvarez-García",
        "given_name": "Juan A."
      },
      {
        "surname": "Salazar-González",
        "given_name": "Jose L."
      },
      {
        "surname": "Tommasi",
        "given_name": "Tatiana"
      }
    ]
  },
  {
    "title": "Regularizing transformers with deep probabilistic layers",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.032",
    "abstract": "Language models (LM) have grown non-stop in the last decade, from sequence-to-sequence architectures to attention-based Transformers. However, regularization is not deeply studied in those structures. In this work, we use a Gaussian Mixture Variational Autoencoder (GMVAE) as a regularizer layer. We study its advantages regarding the depth where it is placed and prove its effectiveness in several scenarios. Experimental result demonstrates that the inclusion of deep generative models within Transformer-based architectures such as BERT, RoBERTa, or XLM-R can bring more versatile models, able to generalize better and achieve improved imputation score in tasks such as SST-2 and TREC or even impute missing/noisy words with richer text.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000448",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Gaussian",
      "Generative grammar",
      "Generative model",
      "Imputation (statistics)",
      "Language model",
      "Machine learning",
      "Missing data",
      "Mixture model",
      "Pattern recognition (psychology)",
      "Physics",
      "Probabilistic logic",
      "Quantum mechanics",
      "Regularization (linguistics)",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Aguilera",
        "given_name": "Aurora Cobo"
      },
      {
        "surname": "Olmos",
        "given_name": "Pablo M."
      },
      {
        "surname": "Artés-Rodríguez",
        "given_name": "Antonio"
      },
      {
        "surname": "Pérez-Cruz",
        "given_name": "Fernando"
      }
    ]
  },
  {
    "title": "IASA: An IoU-aware tracker with adaptive sample assignment",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.038",
    "abstract": "Most of existing trackers develop tracking in a tracking head network, which is composed of classification branch and regression branch. However, they lack a meaningful exploration of how to define positive and negative samples during training, which can significantly affect tracking performance. Furthermore, they cannot provide a reliable ranking by using classification scores or a combination of classification and regression scores to obtain candidate locations. To address these issues, we propose an intersection over union (IoU) aware tracker with adaptive sample assignment (IASA). The IASA introduces an IoU-aware classification score to achieve a more accurate ranking for candidate tracking locations. We also propose a new loss function, IoU-focal loss, to train the anchor-free tracker IASA to predict the classification scores and introduce a star-shaped box feature representation to refine classification features. To explore the actual content of the training samples, we develop an adaptive sample assignment (ASA) strategy to divide the positive and negative samples according to the statistical characteristics of the sample IoUs. By combining these two proposed components, the IASA tracker treats the tracking task as a classification and a regression problem. It directly finds the candidate tracking location in the classification branch and then regresses the four distances from the location to the four sides of the tracking box. Experimental results show that the proposed IASA can achieve state-of-the-art performance on seven public datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000503",
    "keywords": [
      "Artificial intelligence",
      "BitTorrent tracker",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Data mining",
      "Eye tracking",
      "Feature (linguistics)",
      "Feature extraction",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Pedagogy",
      "Philosophy",
      "Psychology",
      "Ranking (information retrieval)",
      "Regression",
      "Sample (material)",
      "Statistics",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Kai"
      },
      {
        "surname": "Zhang",
        "given_name": "Haijun"
      },
      {
        "surname": "Zhou",
        "given_name": "Dongliang"
      },
      {
        "surname": "Dong",
        "given_name": "Li"
      },
      {
        "surname": "Ma",
        "given_name": "Jianghong"
      }
    ]
  },
  {
    "title": "Approximation bounds for convolutional neural networks in operator learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.029",
    "abstract": "Recently, deep Convolutional Neural Networks (CNNs) have proven to be successful when employed in areas such as reduced order modeling of parametrized PDEs. Despite their accuracy and efficiency, the approaches available in the literature still lack a rigorous justification on their mathematical foundations. Motivated by this fact, in this paper we derive rigorous error bounds for the approximation of nonlinear operators by means of CNN models. More precisely, we address the case in which an operator maps a finite dimensional input μ ∈ R p onto a functional output u μ : [ 0 , 1 ] d → R , and a neural network model is used to approximate a discretized version of the input-to-output map. The resulting error estimates provide a clear interpretation of the hyperparameters defining the neural network architecture. All the proofs are constructive, and they ultimately reveal a deep connection between CNNs and the Fourier transform. Finally, we complement the derived error bounds by numerical experiments that illustrate their application.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000412",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Complement (music)",
      "Complementation",
      "Computer science",
      "Constructive",
      "Convolutional neural network",
      "Deep learning",
      "Discretization",
      "Gene",
      "Geometry",
      "Hyperparameter",
      "Mathematical analysis",
      "Mathematical proof",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Operator (biology)",
      "Phenotype",
      "Physics",
      "Process (computing)",
      "Quantum mechanics",
      "Repressor",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Franco",
        "given_name": "Nicola Rares"
      },
      {
        "surname": "Fresca",
        "given_name": "Stefania"
      },
      {
        "surname": "Manzoni",
        "given_name": "Andrea"
      },
      {
        "surname": "Zunino",
        "given_name": "Paolo"
      }
    ]
  },
  {
    "title": "TL-ADA: Transferable Loss-based Active Domain Adaptation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.004",
    "abstract": "The field of Active Domain Adaptation (ADA) has been investigating ways to close the performance gap between supervised and unsupervised learning settings. Previous ADA research has primarily focused on query selection, but there has been little examination of how to effectively train newly labeled target samples using both labeled source samples and unlabeled target samples. In this study, we present a novel Transferable Loss-based ADA (TL-ADA) framework. Our approach is inspired by loss-based query selection, which has shown promising results in active learning. However, directly applying loss-based query selection to the ADA scenario leads to a buildup of high-loss samples that do not contribute to the model due to transferability issues and low diversity. To address these challenges, we propose a transferable doubly nested loss, which incorporates target pseudo labels and a domain adversarial loss. Our TL-ADA framework trains the model sequentially, considering both the domain type (source/target) and the availability of labels (labeled/unlabeled). Additionally, we encourage the pseudo labels to have low self-entropy and diverse class distributions to improve their reliability. Experiments on several benchmark datasets demonstrate that our TL-ADA model outperforms previous ADA methods, and in-depth analysis supports the effectiveness of our proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000679",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Geodesy",
      "Geography",
      "Logit",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Optics",
      "Physics",
      "Selection (genetic algorithm)",
      "Transferability"
    ],
    "authors": [
      {
        "surname": "Han",
        "given_name": "Kyeongtak"
      },
      {
        "surname": "Kim",
        "given_name": "Youngeun"
      },
      {
        "surname": "Han",
        "given_name": "Dongyoon"
      },
      {
        "surname": "Lee",
        "given_name": "Hojun"
      },
      {
        "surname": "Hong",
        "given_name": "Sungeun"
      }
    ]
  },
  {
    "title": "Cooperative modular reinforcement learning for large discrete action space problem",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.046",
    "abstract": "Deep reinforcement learning (DRL) has achieved remarkable results on high-dimension state tasks. However, it suffers in hard convergence and low sample efficiency when solving large discrete action space problems. To meet these challenges, we develop a cooperative modular reinforcement learning (CMRL) method to distributedly solve the problems with a large discrete action space. A general yet effective task decomposition method is proposed to decompose the complex decision task in a large action space into multiple decision sub-tasks in small action subsets, using a rule-based action division method. The CMRL method consisting of multiple Critic networks is proposed to settle the multiple sub-tasks, where each Critic network learns a decomposed value function to obtain the local optimal action in a sub-task. The global optimal action is cooperatively chosen by all local optimal actions. Moreover, we propose a new parallel training mechanism, which trains multiple Critic networks with different models and multi-data in parallel. Mathematical properties are proposed to analyze the rationality and superiority of CMRL. Four different simulation experiments are conducted to verify the generality and effectiveness of CMRL for large action space problems. The results show that CMRL has superior performance on training efficiency compared with classical and latest DRL methods while maintaining the accuracy of the solution.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000588",
    "keywords": [
      "Action (physics)",
      "Algorithm",
      "Artificial intelligence",
      "Bellman equation",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Generality",
      "Management",
      "Mathematical optimization",
      "Mathematics",
      "Modular design",
      "Operating system",
      "Physics",
      "Psychology",
      "Psychotherapist",
      "Quantum mechanics",
      "Reinforcement learning",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Ming",
        "given_name": "Fangzhu"
      },
      {
        "surname": "Gao",
        "given_name": "Feng"
      },
      {
        "surname": "Liu",
        "given_name": "Kun"
      },
      {
        "surname": "Zhao",
        "given_name": "Chengmei"
      }
    ]
  },
  {
    "title": "Video summarization for event-centric videos",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.047",
    "abstract": "Video summarization has long been used to ease video browsing and plays a more crucial role with the explosion of online videos. In the context of event-centric videos, we aim to extract the corresponding clips of more important events in the video. To tackle the dilemma between the detection precision and the clip completeness faced by previous methods, we present an efficient Boundary-Aware framework for Summary clip Extraction (BASE) to extract summary clips with more precise boundaries while maintaining their completeness. Specifically, we propose a new distance-based importance signal to reflect the progress information in each video. The signal can not only help us to detect boundaries with higher precision, but also make it possible to preserve the clip completeness. For the feature presentation part, we also explore new information types to facilitate video summarization. Our approach outperforms current state-of-the-art video summarization models in terms of more precise clip boundaries and more complete summary clips. Note that we even yield comparable results to manual annotations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300059X",
    "keywords": [
      "Artificial intelligence",
      "Automatic summarization",
      "Biology",
      "CLIPS",
      "Completeness (order theory)",
      "Computer science",
      "Context (archaeology)",
      "Event (particle physics)",
      "Feature extraction",
      "Information retrieval",
      "Mathematical analysis",
      "Mathematics",
      "Paleontology",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Qingwen"
      },
      {
        "surname": "Chen",
        "given_name": "Jianni"
      },
      {
        "surname": "Xie",
        "given_name": "Qiqin"
      },
      {
        "surname": "Han",
        "given_name": "Xiao"
      }
    ]
  },
  {
    "title": "Eigen value based loss function for training attractors in iterated autoencoders",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.003",
    "abstract": "The way that the human brain handles the input variations has been one of the most interesting areas of research for neuroscientists. There are some evidences that the human brain acts like an attractor when trying to memorize or retrieve some information. Based on this fact, in this research, a new method is presented for creating attractors during training of an iterated autoencoder. In this method a new loss function is presented which decreases the absolute real of Eigen values while preserving the reconstruction error during training. A fully connected structure is chosen for constructing the iterated autoencoder in this research which mostly faces with local minima especially when they are deep. For getting through this issue, a layer-by-layer pre-training approach is taken to train the network. Using the evaluation on MNIST dataset, it is shown that the proposed model can retrieve 59.98% of test samples which shows a considerable improvement over Dense Associative Memory (DAM) when trained on 100 similar MNIST test samples. The performance of the proposed model is compared to overparameterized autoencoder (OAE) model which was recently presented and showed promising results in constructing associative memories. The results show that the proposed model outperforms OAE in terms of the number of attractors learned by the network in a similar number of network parameters. Finally, the performance of the proposed model is evaluated with corrupted version of training samples, revealing significant robustness when compared to the baseline autoencoder.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000667",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Attractor",
      "Autoencoder",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Gene",
      "Iterated function",
      "MNIST database",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Maxima and minima",
      "Pattern recognition (psychology)",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Nouri",
        "given_name": "Ali"
      },
      {
        "surname": "Seyyedsalehi",
        "given_name": "Seyyed Ali"
      }
    ]
  },
  {
    "title": "Domain adaptive object detection with model-agnostic knowledge transferring",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.028",
    "abstract": "The development of deep learning techniques has greatly benefited CNN-based object detectors, leading to unprecedented progress in recent years. However, the distribution variance between training and testing domains causes significant performance degradation. Labeling data for new scenarios is costly and time-consuming, so most existing domain adaptation methods perform feature alignment through adversarial training. While this can improve the accuracy of detectors in unlabeled target domains, the unconstrained domain alignment also negatively transfers the feature distribution, which compromises the recognition ability of the model. To address this problem, we propose the Knowledge Transfer Network (KTNet), which consists of object intrinsic knowledge mining and category relational knowledge constraint modules. Specifically, a binary classifier shared by the source and target domains is designed to extract common attribute knowledge of objects, which can align foreground and background features from different data domains adaptively. Then, we construct relational knowledge graphs to explicitly constrain the category correlations in the source, target, and cross-domain settings. These two modules guide the detector to learn object-related and domain-invariant representations, enabling the proposed KTNet to perform well in four commonly-used cross-domain scenarios. Furthermore, the ablation experiments show that our method is scalable to more complex backbone networks and different detection architectures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000400",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Data mining",
      "Database",
      "Domain (mathematical analysis)",
      "Domain knowledge",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Object detection",
      "Pattern recognition (psychology)",
      "Scalability"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Kun"
      },
      {
        "surname": "Zhang",
        "given_name": "Chenghao"
      },
      {
        "surname": "Wang",
        "given_name": "Ying"
      },
      {
        "surname": "Xiang",
        "given_name": "Shiming"
      }
    ]
  },
  {
    "title": "Corrigendum to “Functional connectivity inference from fMRI data using multivariate information measures” [Neural Networks 146 (2022) 85–97]",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.021",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000217",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Functional connectivity",
      "Inference",
      "Machine learning",
      "Multivariate statistics",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Qiang"
      }
    ]
  },
  {
    "title": "The role of capacity constraints in Convolutional Neural Networks for learning random versus natural data",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.011",
    "abstract": "Convolutional neural networks (CNNs) are often described as promising models of human vision, yet they show many differences from human abilities. We focus on a superhuman capacity of top-performing CNNs, namely, their ability to learn very large datasets of random patterns. We verify that human learning on such tasks is extremely limited, even with few stimuli. We argue that the performance difference is due to CNNs’ overcapacity and introduce biologically inspired mechanisms to constrain it, while retaining the good test set generalisation to structured images as characteristic of CNNs. We investigate the efficacy of adding noise to hidden units’ activations, restricting early convolutional layers with a bottleneck, and using a bounded activation function. Internal noise was the most potent intervention and the only one which, by itself, could reduce random data performance in the tested models to chance levels. We also investigated whether networks with biologically inspired capacity constraints show improved generalisation to out-of-distribution stimuli, however little benefit was observed. Our results suggest that constraining networks with biologically motivated mechanisms paves the way for closer correspondence between network and human performance, but the few manipulations we have tested are only a small step towards that goal.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000114",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Geology",
      "Machine learning",
      "Natural (archaeology)",
      "Paleontology",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Tsvetkov",
        "given_name": "Christian"
      },
      {
        "surname": "Malhotra",
        "given_name": "Gaurav"
      },
      {
        "surname": "Evans",
        "given_name": "Benjamin D."
      },
      {
        "surname": "Bowers",
        "given_name": "Jeffrey S."
      }
    ]
  },
  {
    "title": "Emphasizing unseen words: New vocabulary acquisition for end-to-end speech recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.027",
    "abstract": "Due to the dynamic nature of human language, automatic speech recognition (ASR) systems need to continuously acquire new vocabulary. Out-Of-Vocabulary (OOV) words, such as trending words and new named entities, pose problems to modern ASR systems that require long training times to adapt their large numbers of parameters. Different from most previous research focusing on language model post-processing, we tackle this problem on an earlier processing level and eliminate the bias in acoustic modeling to recognize OOV words acoustically. We propose to generate OOV words using text-to-speech systems and to rescale losses to encourage neural networks to pay more attention to OOV words. Specifically, we enlarge the classification loss used for training neural networks’ parameters of utterances containing OOV words (sentence-level), or rescale the gradient used for back-propagation for OOV words (word-level), when fine-tuning a previously trained model on synthetic audio. To overcome catastrophic forgetting, we also explore the combination of loss rescaling and model regularization, i.e. L2 regularization and elastic weight consolidation (EWC). Compared with previous methods that just fine-tune synthetic audio with EWC, the experimental results on the LibriSpeech benchmark reveal that our proposed loss rescaling approach can achieve significant improvement on the recall rate with only a slight decrease on word error rate. Moreover, word-level rescaling is more stable than utterance-level rescaling and leads to higher recall rates and precision rates on OOV word recognition. Furthermore, our proposed combined loss rescaling and weight consolidation methods can support continual learning of an ASR system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000278",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Forgetting",
      "Geometry",
      "Language model",
      "Linguistics",
      "Mathematics",
      "Natural language processing",
      "Philosophy",
      "Recall",
      "Sentence",
      "Speech recognition",
      "Utterance",
      "Vocabulary",
      "Word (group theory)",
      "Word error rate"
    ],
    "authors": [
      {
        "surname": "Qu",
        "given_name": "Leyuan"
      },
      {
        "surname": "Weber",
        "given_name": "Cornelius"
      },
      {
        "surname": "Wermter",
        "given_name": "Stefan"
      }
    ]
  },
  {
    "title": "MonkeyNet: A robust deep convolutional neural network for monkeypox disease detection and classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.022",
    "abstract": "The monkeypox virus poses a new pandemic threat while we are still recovering from COVID-19. Despite the fact that monkeypox is not as lethal and contagious as COVID-19, new patient cases are recorded every day. If preparations are not made, a global pandemic is likely. Deep learning (DL) techniques are now showing promise in medical imaging for figuring out what diseases a person has. The monkeypox virus-infected human skin and the region of the skin can be used to diagnose the monkeypox early because an image has been used to learn more about the disease. But there is still no reliable Monkeypox database that is available to the public that can be used to train and test DL models. As a result, it is essential to collect images of monkeypox patients. The “MSID” dataset, short form of “Monkeypox Skin Images Dataset”, which was developed for this research, is free to use and can be downloaded from the Mendeley Data database by anyone who wants to use it. DL models can be built and used with more confidence using the images in this dataset. These images come from a variety of open-source and online sources and can be used for research purposes without any restrictions. Furthermore, we proposed and evaluated a modified DenseNet-201 deep learning-based CNN model named MonkeyNet. Using the original and augmented datasets, this study suggested a deep convolutional neural network that was able to correctly identify monkeypox disease with an accuracy of 93.19% and 98.91% respectively. This implementation also shows the Grad-CAM which indicates the level of the model’s effectiveness and identifies the infected regions in each class image, which will help the clinicians. The proposed model will also help doctors make accurate early diagnoses of monkeypox disease and protect against the spread of the disease.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000850",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Gene",
      "Machine learning",
      "Monkeypox",
      "Pattern recognition (psychology)",
      "Recombinant DNA",
      "Vaccinia"
    ],
    "authors": [
      {
        "surname": "Bala",
        "given_name": "Diponkor"
      },
      {
        "surname": "Hossain",
        "given_name": "Md. Shamim"
      },
      {
        "surname": "Hossain",
        "given_name": "Mohammad Alamgir"
      },
      {
        "surname": "Abdullah",
        "given_name": "Md. Ibrahim"
      },
      {
        "surname": "Rahman",
        "given_name": "Md. Mizanur"
      },
      {
        "surname": "Manavalan",
        "given_name": "Balachandran"
      },
      {
        "surname": "Gu",
        "given_name": "Naijie"
      },
      {
        "surname": "Islam",
        "given_name": "Mohammad S."
      },
      {
        "surname": "Huang",
        "given_name": "Zhangjin"
      }
    ]
  },
  {
    "title": "Hierarchical neural network with efficient selection inference",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.015",
    "abstract": "The image classification precision is vastly enhanced with the growing complexity of convolutional neural network (CNN) structures. However, the uneven visual separability between categories leads to various difficulties in classification. The hierarchical structure of categories can be leveraged to deal with it, but a few CNNs pay attention to the character of data. Besides, a network model with a hierarchical structure is promising to extract more specific features from the data than current CNNs, since, for the latter, all categories have the same fixed number of layers for feed-forward computation. In this paper, we propose to use category hierarchies to integrate ResNet-style modules to form a hierarchical network model in a top-down manner. To extract abundant discriminative features and improve the computation efficiency, we adopt residual block selection based on coarse categories to allocate different computation paths. Each residual block works as a switch to determine the JUMP or JOIN mode for an individual coarse category. Interestingly, since some categories need less feed-forward computation than others by jumping layers, the average inference time cost is reduced. Extensive experiments show that our hierarchical network achieves higher prediction accuracy with similar FLOPs on CIFAR-10 and CIFAR-100, SVHM, and Tiny-ImageNet datasets compared to original residual networks and other existing selection inference methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000783",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Block (permutation group theory)",
      "Computation",
      "Computer science",
      "Convolutional neural network",
      "Discriminative model",
      "FLOPS",
      "Geometry",
      "Inference",
      "Machine learning",
      "Mathematics",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Residual",
      "Selection (genetic algorithm)"
    ],
    "authors": [
      {
        "surname": "Mi",
        "given_name": "Jian-Xun"
      },
      {
        "surname": "Li",
        "given_name": "Nuo"
      },
      {
        "surname": "Huang",
        "given_name": "Ke-Yang"
      },
      {
        "surname": "Li",
        "given_name": "Weisheng"
      },
      {
        "surname": "Zhou",
        "given_name": "Lifang"
      }
    ]
  },
  {
    "title": "Simultaneous approximation of a smooth function and its derivatives by deep neural networks with piecewise-polynomial activations",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.035",
    "abstract": "This paper investigates the approximation properties of deep neural networks with piecewise-polynomial activation functions. We derive the required depth, width, and sparsity of a deep neural network to approximate any Hölder smooth function up to a given approximation error in Hölder norms in such a way that all weights of this neural network are bounded by 1. The latter feature is essential to control generalization errors in many statistical and machine learning applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000473",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Applied mathematics",
      "Approximation error",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Computer science",
      "Deep learning",
      "Evolutionary biology",
      "Feature (linguistics)",
      "Function (biology)",
      "Function approximation",
      "Generalization",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Philosophy",
      "Piecewise",
      "Polynomial"
    ],
    "authors": [
      {
        "surname": "Belomestny",
        "given_name": "Denis"
      },
      {
        "surname": "Naumov",
        "given_name": "Alexey"
      },
      {
        "surname": "Puchkin",
        "given_name": "Nikita"
      },
      {
        "surname": "Samsonov",
        "given_name": "Sergey"
      }
    ]
  },
  {
    "title": "UDRN: Unified Dimensional Reduction Neural Network for feature selection and feature projection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.018",
    "abstract": "Dimensional reduction (DR) maps high-dimensional data into a lower dimensions latent space with minimized defined optimization objectives. The two independent branches of DR are feature selection (FS) and feature projection (FP). FS focuses on selecting a critical subset of dimensions but risks destroying the data distribution (structure). On the other hand, FP combines all the input features into lower dimensions space, aiming to maintain the data structure, but lacks interpretability and sparsity. Moreover, FS and FP are traditionally incompatible categories and have not been unified into an amicable framework. Therefore, we consider that the ideal DR approach combines both FS and FP into a unified end-to-end manifold learning framework, simultaneously performing fundamental feature discovery while maintaining the intrinsic relationships between data samples in the latent space. This paper proposes a unified framework named Unified Dimensional Reduction Network (UDRN) to integrate FS and FP in an end-to-end way. Furthermore, a novel network framework is designed to implement FS and FP tasks separately using a stacked feature selection network and feature projection network. In addition, a stronger manifold assumption and a novel loss function are proposed. Furthermore, the loss function can leverage the priors of data augmentation to enhance the generalization ability of the proposed UDRN. Finally, comprehensive experimental results on four image and four biological datasets, including very high-dimensional data, demonstrate the advantages of DRN over existing methods (FS, FP, and FS&FP pipeline), especially in downstream tasks such as classification and visualization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000813",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Bayesian probability",
      "Computer science",
      "Data mining",
      "Dimensionality reduction",
      "Feature (linguistics)",
      "Feature selection",
      "Feature vector",
      "Geometry",
      "Interpretability",
      "Leverage (statistics)",
      "Linguistics",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Prior probability",
      "Projection (relational algebra)",
      "Reduction (mathematics)"
    ],
    "authors": [
      {
        "surname": "Zang",
        "given_name": "Zelin"
      },
      {
        "surname": "Xu",
        "given_name": "Yongjie"
      },
      {
        "surname": "Lu",
        "given_name": "Linyan"
      },
      {
        "surname": "Geng",
        "given_name": "Yulan"
      },
      {
        "surname": "Yang",
        "given_name": "Senqiao"
      },
      {
        "surname": "Li",
        "given_name": "Stan Z."
      }
    ]
  },
  {
    "title": "SPIDE: A purely spike-based method for training feedback spiking neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.026",
    "abstract": "Spiking neural networks (SNNs) with event-based computation are promising brain-inspired models for energy-efficient applications on neuromorphic hardware. However, most supervised SNN training methods, such as conversion from artificial neural networks or direct training with surrogate gradients, require complex computation rather than spike-based operations of spiking neurons during training. In this paper, we study spike-based implicit differentiation on the equilibrium state (SPIDE) that extends the recently proposed training method, implicit differentiation on the equilibrium state (IDE), for supervised learning with purely spike-based computation, which demonstrates the potential for energy-efficient training of SNNs. Specifically, we introduce ternary spiking neuron couples and prove that implicit differentiation can be solved by spikes based on this design, so the whole training procedure, including both forward and backward passes, is made as event-driven spike computation, and weights are updated locally with two-stage average firing rates. Then we propose to modify the reset membrane potential to reduce the approximation error of spikes. With these key components, we can train SNNs with flexible structures in a small number of time steps and with firing sparsity during training, and the theoretical estimation of energy costs demonstrates the potential for high efficiency. Meanwhile, experiments show that even with these constraints, our trained models can still achieve competitive results on MNIST, CIFAR-10, CIFAR-100, and CIFAR10-DVS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000266",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computation",
      "Computer science",
      "MNIST database",
      "Machine learning",
      "Models of neural computation",
      "Neuromorphic engineering",
      "Software engineering",
      "Spike (software development)",
      "Spike train",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Mingqing"
      },
      {
        "surname": "Meng",
        "given_name": "Qingyan"
      },
      {
        "surname": "Zhang",
        "given_name": "Zongpeng"
      },
      {
        "surname": "Wang",
        "given_name": "Yisen"
      },
      {
        "surname": "Lin",
        "given_name": "Zhouchen"
      }
    ]
  },
  {
    "title": "Approximating Nash equilibrium for anti-UAV jamming Markov game using a novel event-triggered multi-agent reinforcement learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.022",
    "abstract": "In the downlink communication, it is currently challenging for ground users to cope with the uncertain interference from aerial intelligent jammers. The cooperation and competition between ground users and unmanned aerial vehicle (UAV) jammers leads to a Markov game problem of anti-UAV jamming. Therefore, a model-free method is adopted based on multi-agent reinforcement learning (MARL) to handle the Markov game. However, the benchmark MARL strategies suffer from dimension explosion and local optimal convergence. To solve these issues, a novel event-triggered multi-agent proximal policy optimization algorithm with Beta strategy (ETMAPPO) is proposed in this paper, which aims to reduce the dimension of information transmission and improve the efficiency of policy convergence. In this event-triggering mechanism, agents can learn to obtain appropriate observation in different moment, thereby reducing the transmission of valueless information. Beta operator is used to optimize the action search. It expands the search scope of policy space. Ablation simulations show that the proposed strategy achieves better global benefits with fewer dimension of information than benchmark algorithms. In addition, the convergence performance verifies that the well-trained ETMAPPO has the capability to achieve stable jamming strategies and stable anti-jamming strategies. This approximately constitutes the Nash equilibrium of the anti-jamming Markov game.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005226",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Convergence (economics)",
      "Dimension (graph theory)",
      "Economic growth",
      "Economics",
      "Event (particle physics)",
      "Geodesy",
      "Geography",
      "Jamming",
      "Machine learning",
      "Markov chain",
      "Markov decision process",
      "Markov process",
      "Mathematical optimization",
      "Mathematics",
      "Nash equilibrium",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Statistics",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Feng",
        "given_name": "Zikai"
      },
      {
        "surname": "Huang",
        "given_name": "Mengxing"
      },
      {
        "surname": "Wu",
        "given_name": "Yuanyuan"
      },
      {
        "surname": "Wu",
        "given_name": "Di"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Korovin",
        "given_name": "Iakov"
      },
      {
        "surname": "Gorbachev",
        "given_name": "Sergey"
      },
      {
        "surname": "Gorbacheva",
        "given_name": "Nadezhda"
      }
    ]
  },
  {
    "title": "Interpretable local flow attention for multi-step traffic flow prediction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.023",
    "abstract": "Traffic flow prediction (TFP) has attracted increasing attention with the development of smart city. In the past few years, neural network-based methods have shown impressive performance for TFP. However, most of previous studies fail to explicitly and effectively model the relationship between inflows and outflows. Consequently, these methods are usually uninterpretable and inaccurate. In this paper, we propose an interpretable local flow attention (LFA) mechanism for TFP, which yields three advantages. (1) LFA is flow-aware. Different from existing works, which blend inflows and outflows in the channel dimension, we explicitly exploit the correlations between flows with a novel attention mechanism. (2) LFA is interpretable. It is formulated by the truisms of traffic flow, and the learned attention weights can well explain the flow correlations. (3) LFA is efficient. Instead of using global spatial attention as in previous studies, LFA leverages the local mode. The attention query is only performed on the local related regions. This not only reduces computational cost but also avoids false attention. Based on LFA, we further develop a novel spatiotemporal cell, named LFA-ConvLSTM (LFA-based convolutional long short-term memory), to capture the complex dynamics in traffic data. Specifically, LFA-ConvLSTM consists of three parts. (1) A ConvLSTM module is utilized to learn flow-specific features. (2) An LFA module accounts for modeling the correlations between flows. (3) A feature aggregation module fuses the above two to obtain a comprehensive feature. Extensive experiments on two real-world datasets show that our method achieves a better prediction performance. We improve the RMSE metric by 3.2%–4.6%, and the MAPE metric by 6.2%–6.7%. Our LFA-ConvLSTM is also almost 32% faster than global self-attention ConvLSTM in terms of prediction time. Furthermore, we also present some visual results to analyze the learned flow correlations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000230",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Dimension (graph theory)",
      "Epistemology",
      "Feature (linguistics)",
      "Flow (mathematics)",
      "Flow network",
      "Geometry",
      "Linguistics",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Mechanism (biology)",
      "Philosophy",
      "Pure mathematics",
      "Traffic flow (computer networking)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Xu"
      },
      {
        "surname": "Zhang",
        "given_name": "Bowen"
      },
      {
        "surname": "Feng",
        "given_name": "Shanshan"
      },
      {
        "surname": "Ye",
        "given_name": "Yunming"
      },
      {
        "surname": "Li",
        "given_name": "Xutao"
      }
    ]
  },
  {
    "title": "Data augmentation with norm-AE and selective pseudo-labelling for unsupervised domain adaptation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.006",
    "abstract": "We address the Unsupervised Domain Adaptation (UDA) problem in image classification from a new perspective. In contrast to most existing works which either align the data distributions or learn domain-invariant features, we directly learn a unified classifier for both the source and target domains in the high-dimensional homogeneous feature space without explicit domain alignment. To this end, we employ the effective Selective Pseudo-Labelling (SPL) technique to take advantage of the unlabelled samples in the target domain. Surprisingly, data distribution discrepancy across the source and target domains can be well handled by a computationally simple classifier (e.g., a shallow Multi-Layer Perceptron) trained in the original feature space. Besides, we propose a novel generative model norm-AE to generate synthetic features for the target domain as a data augmentation strategy to enhance the classifier training. Experimental results on several benchmark datasets demonstrate the pseudo-labelling strategy itself can lead to comparable performance to many state-of-the-art methods whilst the use of norm-AE for feature augmentation can further improve the performance in most cases. As a result, our proposed methods (i.e. naive-SPL and norm-AE-SPL) can achieve comparable performance with state-of-the-art methods with the average accuracy of 93.4% and 90.4% on Office-Caltech and ImageCLEF-DA datasets, and achieve competitive performance on Digits, Office31 and Office-Home datasets with the average accuracy of 97.2%, 87.6% and 68.6% respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000692",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Computer science",
      "Domain adaptation",
      "Feature vector",
      "Law",
      "Machine learning",
      "Norm (philosophy)",
      "Pattern recognition (psychology)",
      "Perceptron",
      "Political science"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Qian"
      },
      {
        "surname": "Meng",
        "given_name": "Fanlin"
      },
      {
        "surname": "Breckon",
        "given_name": "Toby P."
      }
    ]
  },
  {
    "title": "A feedforward unitary equivariant neural network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.042",
    "abstract": "We devise a new type of feedforward neural network. It is equivariant with respect to the unitary group U ( n ) . The input and output can be vectors in ℂ n with arbitrary dimension n . No convolution layer is required in our implementation. We avoid errors due to truncated higher order terms in Fourier-like transformation. The implementation of each layer can be done efficiently using simple calculations. As a proof of concept, we have given empirical results on the prediction of the dynamics of atomic motion to demonstrate the practicality of our approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000540",
    "keywords": [
      "Algebra over a field",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Combinatorics",
      "Computer science",
      "Control engineering",
      "Convolution (computer science)",
      "Dimension (graph theory)",
      "Engineering",
      "Epistemology",
      "Equivariant map",
      "Feed forward",
      "Feedforward neural network",
      "Fourier transform",
      "Gene",
      "Law",
      "Layer (electronics)",
      "Mathematical analysis",
      "Mathematics",
      "Organic chemistry",
      "Philosophy",
      "Physics",
      "Political science",
      "Pure mathematics",
      "Quantum",
      "Quantum mechanics",
      "Simple (philosophy)",
      "Topology (electrical circuits)",
      "Transformation (genetics)",
      "Unitary state",
      "Unitary transformation"
    ],
    "authors": [
      {
        "surname": "Ma",
        "given_name": "Pui-Wai"
      },
      {
        "surname": "Chan",
        "given_name": "T.-H. Hubert"
      }
    ]
  },
  {
    "title": "MixGradient: A gradient-based re-weighting scheme with mixup for imbalanced data streams",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.017",
    "abstract": "A challenge for contemporary deep neural networks in real-world problems is learning from an imbalanced data stream, where data tends to be received chunk by chunk over time, and the prior class distribution is severely imbalanced. Although many sophisticated algorithms have been derived, most of them overlook the importance of gradient information. From this perspective, the difficulty of learning from imbalanced data streams lies in the fact that the gradient estimated on an uneven class distribution is not informative enough to reflect the critical pattern of each class. To this end, we propose to assign higher weights on the training samples whose gradients are close to the gradient of corresponding typical samples, thus highlighting the important samples in minority classes and suppressing the noisy samples in majority classes. Such an idea can be combined with Mixup, which exploits the interpolation information of data to further compensate for the information of sample space that the typical samples do not provide and expand the role of the proposed re-weighting scheme. Experiments on artificially induced long-tailed CIFAR data streams and long-tailed MiniPlaces data stream show that the resulting method, termed MixGradient, boosts the generalization performance of DNNs under different imbalance ratios and achieves up to 10% accuracy improvement.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000801",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Chromatography",
      "Class (philosophy)",
      "Computer science",
      "Concept drift",
      "Data mining",
      "Data stream",
      "Data stream mining",
      "Generalization",
      "Image (mathematics)",
      "Interpolation (computer graphics)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Medicine",
      "Operating system",
      "Pattern recognition (psychology)",
      "Perspective (graphical)",
      "Radiology",
      "Sample (material)",
      "Scheme (mathematics)",
      "Space (punctuation)",
      "Telecommunications",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Xinyu"
      },
      {
        "surname": "Wang",
        "given_name": "Fei-Yue"
      },
      {
        "surname": "Li",
        "given_name": "Li"
      }
    ]
  },
  {
    "title": "SP-GNN: Learning structure and position information from graphs",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.051",
    "abstract": "Graph neural network (GNN) is a powerful model for learning from graph data. However, existing GNNs may have limited expressive power, especially in terms of capturing adequate structural and positional information of input graphs. Structure properties and node position information are unique to graph-structured data, but few GNNs are capable of capturing them. This paper proposes Structure- and Position-aware Graph Neural Networks (SP-GNN), a new class of GNNs offering generic and expressive power of graph data. SP-GNN enhances the expressive power of GNN architectures by incorporating a near-isometric proximity-aware position encoder and a scalable structure encoder. Further, given a GNN learning task, SP-GNN can be used to analyze positional and structural awareness of GNN tasks using the corresponding embeddings computed by the encoders. The awareness scores can guide fusion strategies of the extracted positional and structural information with raw features for better performance of GNNs on downstream tasks. We conduct extensive experiments using SP-GNN on various graph datasets and observe significant improvement in classification over existing GNN models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000631",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Encoder",
      "Graph",
      "Machine learning",
      "Operating system",
      "Pattern recognition (psychology)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Yangrui"
      },
      {
        "surname": "You",
        "given_name": "Jiaxuan"
      },
      {
        "surname": "He",
        "given_name": "Jun"
      },
      {
        "surname": "Lin",
        "given_name": "Yuan"
      },
      {
        "surname": "Peng",
        "given_name": "Yanghua"
      },
      {
        "surname": "Wu",
        "given_name": "Chuan"
      },
      {
        "surname": "Zhu",
        "given_name": "Yibo"
      }
    ]
  },
  {
    "title": "Asynchronous dissipative stabilization for stochastic Markov-switching neural networks with completely- and incompletely-known transition rates",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.039",
    "abstract": "The asynchronous dissipative stabilization for stochastic Markov-switching neural networks (SMSNNs) is investigated. The aim is to design an output-feedback controller with inconsistent mode switching to ensure that the SMSNN is stochastically stable with extended dissipativity. Two situations, which involve completely- and incompletely-known transition rates (TRs), are taken into account. The situation that all TRs are exactly known is considered first. By applying a mode-dependent Lyapunov–Krasovskii functional, Dynkin’s formula, and several matrix inequalities, a criterion for the desired performance of the closed-loop SMSNN is derived and a design method for determining the asynchronous controller is developed. Then, the study is generalized to the situation where some TRs are allowed to be uncertain or even fully unknown. An inequality is established for judging the upper bound of the product of the TRs with the Lyapunov matrix by making full use of accessible information on the incompletely-known TRs. Based on the inequality, performance analysis and control synthesis are presented without imposing the zero-sum hypothesis of the uncertainties in the TR matrix. Finally, an example with numerical calculation and simulation is provided to verify the validity of the stabilizing approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000515",
    "keywords": [
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Asynchronous communication",
      "Biology",
      "Composite material",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Dissipative system",
      "Lyapunov function",
      "Machine learning",
      "Markov chain",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Statistics",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Tai",
        "given_name": "Weipeng"
      },
      {
        "surname": "Li",
        "given_name": "Xinling"
      },
      {
        "surname": "Zhou",
        "given_name": "Jianping"
      },
      {
        "surname": "Arik",
        "given_name": "Sabri"
      }
    ]
  },
  {
    "title": "Learning to Generate Tips from Song Reviews",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.049",
    "abstract": "Reviews of songs play an important role in online music service platforms. Prior research shows that users can make quicker and more informed decisions when presented with meaningful song reviews. However, reviews of songs are generally long in length and most of them are non-informative for users. It is difficult for users to efficiently grasp meaningful messages for making decisions. To solve this problem, one practical strategy is to provide tips, i.e., short, concise, empathetic, and self-contained descriptions about songs. Tips are produced from song reviews and should express non-trivial insights about the songs. To the best of our knowledge, no prior studies have explored the tip generation task in music domain. In this paper, we create a dataset named MTips for the task and propose a learning-to-generate framework named GenTMS for automatically generating tips from song reviews. The dataset involves 8,003 Chinese tips/non-tips from 128 songs which are distributed in five different song genres. Experimental results show that GenTMS achieves top-10 precision at 85.56%, outperforming the baseline models by at least 3.34%. Besides, to simulate the practical usage of our proposed framework, we also experiment with previously-unseen songs, during which GenTMS also achieves the best performance with top-10 precision at 78.89% on average. The results demonstrate the effectiveness of the proposed framework in tip generation of the music domain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000618",
    "keywords": [
      "Artificial intelligence",
      "Baseline (sea)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Economics",
      "GRASP",
      "Geology",
      "Information retrieval",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Natural language processing",
      "Oceanography",
      "Programming language",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Zang",
        "given_name": "Jingya"
      },
      {
        "surname": "Gao",
        "given_name": "Cuiyun"
      },
      {
        "surname": "Chen",
        "given_name": "Yupan"
      },
      {
        "surname": "Xu",
        "given_name": "Ruifeng"
      },
      {
        "surname": "Zhou",
        "given_name": "Lanjun"
      },
      {
        "surname": "Wang",
        "given_name": "Xuan"
      }
    ]
  },
  {
    "title": "Knowledge-Preserving continual person re-identification using Graph Attention Network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.033",
    "abstract": "Person re-identification (ReID), considered as a sub-problem of image retrieval, is critical for intelligent security. The general practice is to train a deep model on images from a particular scenario (also known as a domain) and perform retrieval tests on images from the same domain. Thus, the model has to be retrained to ensure good performance on unseen domains. Unfortunately, retraining will introduce the so called catastrophic forgetting problem existing in deep learning models. To address this problem, we propose a Continual person re-identification model via a Knowledge-Preserving (CKP) mechanism. The proposed model is able to accumulate knowledge from continuously changing scenarios. The knowledge is updated via a graph attention network from the human cognitive-inspired perspective as the scenario changes. The accumulated knowledge is used to guide the learning process of the proposed model on image samples from new-coming domains. We finally evaluate and compare CKP with fine-tuning, continual learning in image classification and person re-identification, and joint training. Experiments on representative benchmark datasets (Market1501, DukeMTMC, CUHK03, CUHK-SYSU, and MSMT17, which arrive in different orders) demonstrate the advantages of the proposed model in preventing forgetting, and experiments on other benchmark datasets (GRID, SenseReID, CUHK01, CUHK02, VIPER, iLIDS, and PRID, which are not available during training) demonstrate the generalization ability of the proposed model. The CKP outperforms the best comparative model by 0.58% and 0.65% on seen domains (datasets available during training), and by 0.95% and 1.02% on never seen domains (datasets not available during training) in terms of mAP and Rank1, respectively. Arrival order of the training datasets, guidance of accumulated knowledge for learning new knowledge and parameter settings are also discussed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300045X",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Botany",
      "Computer science",
      "Deep learning",
      "Domain knowledge",
      "Forgetting",
      "Generalization",
      "Geodesy",
      "Geography",
      "Graph",
      "Identification (biology)",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Philosophy",
      "Process (computing)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Zhaoshuo"
      },
      {
        "surname": "Feng",
        "given_name": "Chaolu"
      },
      {
        "surname": "Chen",
        "given_name": "Shuaizheng"
      },
      {
        "surname": "Hu",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Bat algorithm based control to decrease the control energy consumption and modified bat algorithm based control to increase the trajectory tracking accuracy in robots",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.010",
    "abstract": "From the control theory, the best control gain produces a balance between the trajectory tracking accuracy and control energy consumption. The random search of the bat algorithm is one alternative to find the best control gain. In this paper, (1) a bat algorithm based control is proposed to decrease the control energy consumption in robots, where a bat algorithm is used to find the best control gain; and (2) a modified bat algorithm based control is proposed to increase the trajectory tracking accuracy in robots, where a modified bat algorithm is used to find the best control gain. The comparison between the two proposed controls and the simplex based control is illustrated for the trajectory tracking accuracy and control energy consumption in two robots.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000734",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Astronomy",
      "Bat algorithm",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Electrical engineering",
      "Energy consumption",
      "Engineering",
      "Particle swarm optimization",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Robot",
      "Tracking (education)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Rubio",
        "given_name": "José de Jesús"
      }
    ]
  },
  {
    "title": "VISAL—A novel learning strategy to address class imbalance",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.015",
    "abstract": "In the imbalance data scenarios, Deep Neural Networks (DNNs) fail to generalize well on minority classes. In this letter, we propose a simple and effective learning function i.e, Visually Interpretable Space Adjustment Learning (VISAL) to handle the imbalanced data classification task. VISAL’s objective is to create more room for the generalization of minority class samples by bringing in both the angular and euclidean margins into the cross-entropy learning strategy. When evaluated on the imbalanced versions of CIFAR, Tiny ImageNet, COVIDx and IMDB reviews datasets, our proposed method outperforms the state of the art works by a significant margin.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000151",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Class (philosophy)",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Euclidean geometry",
      "Euclidean space",
      "Evolutionary biology",
      "Function (biology)",
      "Generalization",
      "Generalization error",
      "Geometry",
      "Machine learning",
      "Margin (machine learning)",
      "Mathematical analysis",
      "Mathematics",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "S.",
        "given_name": "Sree Rama Vamsidhar"
      },
      {
        "surname": "Sivapuram",
        "given_name": "Arun Kumar"
      },
      {
        "surname": "Ravi",
        "given_name": "Vaishnavi"
      },
      {
        "surname": "Senthil",
        "given_name": "Gowtham"
      },
      {
        "surname": "Gorthi",
        "given_name": "Rama Krishna"
      }
    ]
  },
  {
    "title": "MPGE and RootRank: A sufficient root cause characterization and quantification framework for industrial process faults",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.030",
    "abstract": "Root cause diagnosis can locate abnormalities of industrial processes, ensuring production safety and manufacturing efficiency. However, existing root cause diagnosis models only consider pairwise direct causality and ignore the multi-level fault propagation, which may lead to incomplete root cause descriptions and ambiguous root cause candidates. To address the above issue, a novel framework, named multi-level predictive graph extraction (MPGE) and RootRank scoring, is proposed and applied to the root cause diagnosis for industrial processes. In this framework, both direct and indirect Granger causalities are characterized by multi-level predictive relationships to provide a sufficient characterization of root cause variables. First, a predictive graph structure with a sparse constrained adjacency matrix is constructed to describe the information transmission between variables. The information of variables is deeply fused according to the adjacency matrix to consider multi-level fault propagation. Then, a hierarchical adjacency pruning (HAP) mechanism is designed to automatically capture vital predictive relationships through adjacency redistribution. In this way, the multi-level causalities between variables are extracted to fully describe both direct and indirect fault propagation and highlight the root cause. Further, a RootRank scoring algorithm is proposed to analyze the predictive graph and quantify the fault propagation contribution of each variable, thereby giving definite root cause identification results. Three examples are adopted to verify the diagnostic performance of the proposed framework, including a numerical example, the Tennessee Eastman benchmark process, and a real cut-made process of cigarette. Both theoretical analysis and experimental verification show the high interpretability and reliability of the proposed framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000424",
    "keywords": [
      "Adjacency matrix",
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Data mining",
      "Engineering",
      "Graph",
      "Interpretability",
      "Machine learning",
      "Pairwise comparison",
      "Pruning",
      "Reliability engineering",
      "Root cause",
      "Root cause analysis",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Pengyu"
      },
      {
        "surname": "Zhao",
        "given_name": "Chunhui"
      },
      {
        "surname": "Huang",
        "given_name": "Biao"
      }
    ]
  },
  {
    "title": "Neural network model for imprecise regression with interval dependent variables",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.005",
    "abstract": "This paper presents a computationally feasible method to compute rigorous bounds on the interval-generalization of regression analysis to account for epistemic uncertainty in the output variables. The new iterative method uses machine learning algorithms to fit an imprecise regression model to data that consist of intervals rather than point values. The method is based on a single-layer interval neural network which can be trained to produce an interval prediction. It seeks parameters for the optimal model that minimizes the mean squared error between the actual and predicted interval values of the dependent variable using a first-order gradient-based optimization and interval analysis computations to model the measurement imprecision of the data. An additional extension to a multi-layer neural network is also presented. We consider the explanatory variables to be precise point values, but the measured dependent values are characterized by interval bounds without any probabilistic information. The proposed iterative method estimates the lower and upper bounds of the expectation region, which is an envelope of all possible precise regression lines obtained by ordinary regression analysis based on any configuration of real-valued points from the respective y -intervals and their x -values.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000680",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Generalization",
      "Interval (graph theory)",
      "Linear regression",
      "Mathematical analysis",
      "Mathematics",
      "Polynomial regression",
      "Probabilistic logic",
      "Regression",
      "Regression analysis",
      "Segmented regression",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Tretiak",
        "given_name": "Krasymyr"
      },
      {
        "surname": "Schollmeyer",
        "given_name": "Georg"
      },
      {
        "surname": "Ferson",
        "given_name": "Scott"
      }
    ]
  },
  {
    "title": "Enhanced tensor low-rank representation learning for multi-view clustering",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.037",
    "abstract": "Multi-view subspace clustering (MSC), assuming the multi-view data are generated from a latent subspace, has attracted considerable attention in multi-view clustering. To recover the underlying subspace structure, a successful approach adopted recently is subspace clustering based on tensor nuclear norm (TNN). But there are some limitations to this approach that the existing TNN-based methods usually fail to exploit the intrinsic cluster structure and high-order correlations well, which leads to limited clustering performance. To address this problem, the main purpose of this paper is to propose a novel tensor low-rank representation (TLRR) learning method to perform multi-view clustering. First, we construct a 3rd-order tensor by organizing the features from all views, and then use the t-product in the tensor space to obtain the self-representation tensor of the tensorial data. Second, we use the ℓ 1 , 2 norm to constrain the self-representation tensor to make it capture the class-specificity distribution, that is important for depicting the intrinsic cluster structure. And simultaneously, we rotate the self-representation tensor, and use the tensor singular value decomposition-based weighted TNN as a tighter tensor rank approximation to constrain the rotated tensor. For the challenged mathematical optimization problem, we present an effective optimization algorithm with a theoretical convergence guarantee and relatively low computation complexity. The constructed convergent sequence to the Karush–Kuhn–Tucker (KKT) critical point solution is mathematically validated in detail. We perform extensive experiments on four datasets and demonstrate that TLRR outperforms state-of-the-art multi-view subspace clustering methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000497",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Combinatorics",
      "Computer science",
      "Mathematics",
      "Pure mathematics",
      "Rank (graph theory)",
      "Subspace topology",
      "Tensor (intrinsic definition)"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Deyan"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      }
    ]
  },
  {
    "title": "Hybrid distributed finite-time neurodynamic optimization of electric vehicle charging schemes management in microgrid considering time-varying factors",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.012",
    "abstract": "In this paper, two distributed finite-time neurodynamic algorithms are proposed to collaboratively manage the charging scheme of electric vehicles (EVs) in the microgrid scenario. First, the upper level model is constructed to optimize the disorderly charging problem of EV users under private charging posts , and explore the optimal charging scheme under charging constraints and time-varying conditions to ensure the benefits of users. The lower layer model explores the optimal public charging scheme under the system operation constraint and the supply–demand balance constraint with the objective of minimizing the overall microgrid operation cost. The optimal solution of the upper model, i.e., the load of EV users under the private charging post, is considered as a parameter of the lower model. In this context, two finite-time neurodynamics with fast convergence rate, executed in a distributed manner, are proposed to track the optimal solution of the problem in real time. Furthermore, the stability and convergence in finite time of the two proposed algorithms are proved using Lyapunov theorem and finite time theorem. Numerical case studies of small-scale and large-scale power systems demonstrate the effectiveness, robustness, and real-time performance of the two proposed algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000758",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Context (archaeology)",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Electric vehicle",
      "Gene",
      "Lyapunov stability",
      "Mathematical optimization",
      "Mathematics",
      "Microgrid",
      "Paleontology",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Qin",
        "given_name": "Haohao"
      },
      {
        "surname": "Zhao",
        "given_name": "Gui"
      },
      {
        "surname": "Li",
        "given_name": "Yue"
      },
      {
        "surname": "Wang",
        "given_name": "Hui"
      }
    ]
  },
  {
    "title": "CLAD: A realistic Continual Learning benchmark for Autonomous Driving",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.001",
    "abstract": "In this paper we describe the design and the ideas motivating a new Continual Learning benchmark for Autonomous Driving (CLAD), that focuses on the problems of object classification and object detection. The benchmark utilises SODA10M, a recently released large-scale dataset that concerns autonomous driving related problems. First, we review and discuss existing continual learning benchmarks, how they are related, and show that most are extreme cases of continual learning. To this end, we survey the benchmarks used in continual learning papers at three highly ranked computer vision conferences. Next, we introduce CLAD-C, an online classification benchmark realised through a chronological data stream that poses both class and domain incremental challenges; and CLAD-D, a domain incremental continual object detection benchmark. We examine the inherent difficulties and challenges posed by the benchmark, through a survey of the techniques and methods used by the top-3 participants in a CLAD-challenge workshop at ICCV 2021. We conclude with possible pathways to improve the current continual learning state of the art, and which directions we deem promising for future research.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000643",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Class (philosophy)",
      "Computer science",
      "Deep learning",
      "Domain (mathematical analysis)",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Object (grammar)",
      "Object detection",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Verwimp",
        "given_name": "Eli"
      },
      {
        "surname": "Yang",
        "given_name": "Kuo"
      },
      {
        "surname": "Parisot",
        "given_name": "Sarah"
      },
      {
        "surname": "Hong",
        "given_name": "Lanqing"
      },
      {
        "surname": "McDonagh",
        "given_name": "Steven"
      },
      {
        "surname": "Pérez-Pellitero",
        "given_name": "Eduardo"
      },
      {
        "surname": "De Lange",
        "given_name": "Matthias"
      },
      {
        "surname": "Tuytelaars",
        "given_name": "Tinne"
      }
    ]
  },
  {
    "title": "DEFAEK: Domain Effective Fast Adaptive Network for Face Anti-Spoofing",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.018",
    "abstract": "Existing deep learning based face anti-spoofing (FAS) or deepfake detection approaches usually rely on large-scale datasets and powerful networks with significant amount of parameters to achieve satisfactory performance. However, these make them resource-heavy and unsuitable for handheld devices. Moreover, they are limited by the types of spoof in the dataset they train on and require considerable training time. To produce a robust FAS model, they need large datasets covering the widest variety of predefined presentation attacks possible. Testing on new or unseen attacks or environments generally results in poor performance. Ideally, the FAS model should learn discriminative features that can generalize well even on unseen spoof types. In this paper, we propose a fast learning approach called Domain Effective Fast Adaptive nEt-worK (DEFAEK), a face anti-spoofing approach based on the optimization-based meta-learning paradigm that effectively and quickly adapts to new tasks. DEFAEK treats differences in an environment as domains and simulates multiple domain shifts during training. To further improve the effectiveness and efficiency of meta-learning, we adopt the metric learning in the inner loop update with careful sample selection. With extensive experiments on the challenging CelebA-Spoof and FaceForensics++ datasets, the evaluation results show that DEFAEK can learn cues independent of the environment with good generalization capability. In addition, the resulting model is lightweight following the design principle of modern lightweight network architecture and still generalizes well on unseen classes. In addition, we also demonstrate our model’s capabilities by comparing the numbers of parameters, FLOPS, and model performance with other state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000187",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Discriminative model",
      "Domain (mathematical analysis)",
      "Economics",
      "Face (sociological concept)",
      "Flexibility (engineering)",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Metric (unit)",
      "Operations management",
      "Social science",
      "Sociology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Lin",
        "given_name": "Jiun-Da"
      },
      {
        "surname": "Han",
        "given_name": "Yue-Hua"
      },
      {
        "surname": "Huang",
        "given_name": "Po-Han"
      },
      {
        "surname": "Tan",
        "given_name": "Julianne"
      },
      {
        "surname": "Chen",
        "given_name": "Jun-Cheng"
      },
      {
        "surname": "Tanveer",
        "given_name": "M."
      },
      {
        "surname": "Hua",
        "given_name": "Kai-Lung"
      }
    ]
  },
  {
    "title": "Learning matrix factorization with scalable distance metric and regularizer",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.034",
    "abstract": "Matrix factorization has always been an encouraging field, which attempts to extract discriminative features from high-dimensional data. However, it suffers from negative generalization ability and high computational complexity when handling large-scale data. In this paper, we propose a learnable deep matrix factorization via the projected gradient descent method, which learns multi-layer low-rank factors from scalable metric distances and flexible regularizers. Accordingly, solving a constrained matrix factorization problem is equivalently transformed into training a neural network with an appropriate activation function induced from the projection onto a feasible set. Distinct from other neural networks, the proposed method activates the connected weights not just the hidden layers. As a result, it is proved that the proposed method can learn several existing well-known matrix factorizations, including singular value decomposition, convex, nonnegative and semi-nonnegative matrix factorizations. Finally, comprehensive experiments demonstrate the superiority of the proposed method against other state-of-the-arts.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000461",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Economics",
      "Eigenvalues and eigenvectors",
      "Generalization",
      "Gradient descent",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Matrix decomposition",
      "Metric (unit)",
      "Non-negative matrix factorization",
      "Operations management",
      "Physics",
      "Quantum mechanics",
      "Rank (graph theory)",
      "Singular value decomposition"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Shiping"
      },
      {
        "surname": "Zhang",
        "given_name": "Yunhe"
      },
      {
        "surname": "Lin",
        "given_name": "Xincan"
      },
      {
        "surname": "Su",
        "given_name": "Lichao"
      },
      {
        "surname": "Xiao",
        "given_name": "Guobao"
      },
      {
        "surname": "Zhu",
        "given_name": "William"
      },
      {
        "surname": "Shi",
        "given_name": "Yiqing"
      }
    ]
  },
  {
    "title": "An effective low-rank compression with a joint rank selection followed by a compression-friendly training",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.024",
    "abstract": "Low-rank compression of a neural network is one of the popular compression techniques, where it has been known to have two main challenges. The first challenge is determining the optimal rank of all the layers and the second is training the neural network into a compression-friendly form. To overcome the two challenges, we propose BSR (Beam-search and Stable Rank), a low-rank compression algorithm that embodies an efficient rank-selection method and a unique compression-friendly training method. For the rank selection, BSR employs a modified beam search that can perform a joint optimization of the rank allocations over all the layers in contrast to the previously used heuristic methods. For the compression-friendly training, BSR adopts a regularization loss derived from a modified stable rank, which can control the rank while incurring almost no harm in performance. Experiment results confirm that BSR is effective and superior when compared to the existing low-rank compression methods. For CIFAR10 on ResNet56, BSR not only achieves compression but also provides a performance improvement over the baseline model’s performance for the compression ratio of up to 0.82. For CIFAR100 on ResNet56 and ImageNet on AlexNet, BSR outperforms the previous SOTA method, LC, by 4.7% and by 6.7% on the average, respectively. BSR is also effective for EfficientNet-B0 and MobileNetV2 that are known for their efficient design in terms of parameters and computational cost. We also show that BSR provides a competitive performance when compared with the recent pruning compression algorithms. As with pruning, BSR can be easily combined with quantization for an additional compression.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000242",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Automotive engineering",
      "Biology",
      "Combinatorics",
      "Composite material",
      "Compression (physics)",
      "Compression ratio",
      "Computer science",
      "Data compression",
      "Engineering",
      "Image (mathematics)",
      "Image compression",
      "Image processing",
      "Internal combustion engine",
      "Materials science",
      "Mathematics",
      "Pruning",
      "Rank (graph theory)"
    ],
    "authors": [
      {
        "surname": "Eo",
        "given_name": "Moonjung"
      },
      {
        "surname": "Kang",
        "given_name": "Suhyun"
      },
      {
        "surname": "Rhee",
        "given_name": "Wonjong"
      }
    ]
  },
  {
    "title": "Partial label learning: Taxonomy, analysis and outlook",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.019",
    "abstract": "Partial label learning (PLL) is an emerging framework in weakly supervised machine learning with broad application prospects. It handles the case in which each training example corresponds to a candidate label set and only one label concealed in the set is the ground-truth label. In this paper, we propose a novel taxonomy framework for PLL including four categories: disambiguation strategy, transformation strategy, theory-oriented strategy and extensions. We analyze and evaluate methods in each category and sort out synthetic and real-world PLL datasets which are all hyperlinked to the source data. Future work of PLL is profoundly discussed in this article based on the proposed taxonomy framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000825",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Botany",
      "Chemistry",
      "Computer science",
      "Gene",
      "Information retrieval",
      "Machine learning",
      "Programming language",
      "Set (abstract data type)",
      "Taxonomy (biology)",
      "Training set",
      "Transformation (genetics)",
      "sort"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Yingjie"
      },
      {
        "surname": "Yu",
        "given_name": "Xiaotong"
      },
      {
        "surname": "Fu",
        "given_name": "Saiji"
      }
    ]
  },
  {
    "title": "Enhanced robust spatial feature selection and correlation filter learning for UAV tracking",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.003",
    "abstract": "Spatial boundary effect can significantly reduce the performance of a learned discriminative correlation filter (DCF) model. A commonly used method to relieve this effect is to extract appearance features from a wider region of a target. However, this way would introduce unexpected features from background pixels and noises, which will lead to a decrease of the filter’s discrimination power. To address this shortcoming, this paper proposes an innovative method called enhanced robust spatial feature selection and correlation filter Learning (EFSCF), which performs jointly sparse feature learning to handle boundary effects effectively while suppressing the influence of background pixels and noises. Unlike the ℓ 2 -norm-based tracking approaches that are prone to non-Gaussian noises, the proposed method imposes the ℓ 2 , 1 -norm on the loss term to enhance the robustness against the training outliers. To enhance the discrimination further, a jointly sparse feature selection scheme based on the ℓ 2 , 1 -norm is designed to regularize the filter in rows and columns simultaneously. To the best of the authors’ knowledge, this has been the first work exploring the structural sparsity in rows and columns of a learned filter simultaneously. The proposed model can be efficiently solved by an alternating direction multiplier method. The proposed EFSCF is verified by experiments on four challenging unmanned aerial vehicle datasets under severe noise and appearance changes, and the results show that the proposed method can achieve better tracking performance than the state-of-the-art trackers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000035",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "BitTorrent tracker",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Discriminative model",
      "Eye tracking",
      "Feature selection",
      "Filter (signal processing)",
      "Gene",
      "Outlier",
      "Pattern recognition (psychology)",
      "Pixel",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Wen",
        "given_name": "Jiajun"
      },
      {
        "surname": "Chu",
        "given_name": "Honglin"
      },
      {
        "surname": "Lai",
        "given_name": "Zhihui"
      },
      {
        "surname": "Xu",
        "given_name": "Tianyang"
      },
      {
        "surname": "Shen",
        "given_name": "Linlin"
      }
    ]
  },
  {
    "title": "Feature Alignment by Uncertainty and Self-Training for Source-Free Unsupervised Domain Adaptation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.009",
    "abstract": "Most unsupervised domain adaptation (UDA) methods assume that labeled source images are available during model adaptation. However, this assumption is often infeasible owing to confidentiality issues or memory constraints on mobile devices. Some recently developed approaches do not require source images during adaptation, but they show limited performance on perturbed images. To address these problems, we propose a novel source-free UDA method that uses only a pre-trained source model and unlabeled target images. Our method captures the aleatoric uncertainty by incorporating data augmentation and trains the feature generator with two consistency objectives. The feature generator is encouraged to learn consistent visual features away from the decision boundaries of the head classifier. Thus, the adapted model becomes more robust to image perturbations. Inspired by self-supervised learning, our method promotes inter-space alignment between the prediction space and the feature space while incorporating intra-space consistency within the feature space to reduce the domain gap between the source and target domains. We also consider epistemic uncertainty to boost the model adaptation performance. Extensive experiments on popular UDA benchmark datasets demonstrate that the proposed source-free method is comparable or even superior to vanilla UDA methods. Moreover, the adapted models show more robust results when input images are perturbed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000722",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Consistency (knowledge bases)",
      "Domain adaptation",
      "Feature (linguistics)",
      "Feature vector",
      "Generator (circuit theory)",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Power (physics)",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "JoonHo"
      },
      {
        "surname": "Lee",
        "given_name": "Gyemin"
      }
    ]
  },
  {
    "title": "Continual Object Detection: A review of definitions, strategies, and challenges",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.041",
    "abstract": "The field of Continual Learning investigates the ability to learn consecutive tasks without losing performance on those previously learned. The efforts of researchers have been mainly focused on incremental classification tasks. Yet, we believe that continual object detection deserves even more attention due to its vast range of applications in robotics and autonomous vehicles. This scenario is also more complex than conventional classification, given the occurrence of instances of classes that are unknown at the time but can appear in subsequent tasks as a new class to be learned, resulting in missing annotations and conflicts with the background label. In this review, we analyze the current strategies proposed to tackle the problem of class-incremental object detection. Our main contributions are: (1) a short and systematic review of the methods that propose solutions to traditional incremental object detection scenarios; (2) A comprehensive evaluation of the existing approaches using a new metric to quantify the stability and plasticity of each technique in a standard way; (3) an overview of the current trends within continual object detection and a discussion of possible future research directions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000539",
    "keywords": [
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Economics",
      "Field (mathematics)",
      "Incremental learning",
      "Machine learning",
      "Mathematics",
      "Metric (unit)",
      "Object (grammar)",
      "Object detection",
      "Operations management",
      "Pattern recognition (psychology)",
      "Pure mathematics",
      "Robot",
      "Robotics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Menezes",
        "given_name": "Angelo G."
      },
      {
        "surname": "de Moura",
        "given_name": "Gustavo"
      },
      {
        "surname": "Alves",
        "given_name": "Cézanne"
      },
      {
        "surname": "de Carvalho",
        "given_name": "André C.P.L.F."
      }
    ]
  },
  {
    "title": "U-SPDNet: An SPD manifold learning-based neural network for visual classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.030",
    "abstract": "With the development of neural networking techniques, several architectures for symmetric positive definite (SPD) matrix learning have recently been put forward in the computer vision and pattern recognition (CV&PR) community for mining fine-grained geometric features. However, the degradation of structural information during multi-stage feature transformation limits their capacity. To cope with this issue, this paper develops a U-shaped neural network on the SPD manifolds (U-SPDNet) for visual classification. The designed U-SPDNet contains two subsystems, one of which is a shrinking path (encoder) making up of a prevailing SPD manifold neural network (SPDNet (Huang and Van Gool, 2017)) for capturing compact representations from the input data. Another is a constructed symmetric expanding path (decoder) to upsample the encoded features, trained by a reconstruction error term. With this design, the degradation problem will be gradually alleviated during training. To enhance the representational capacity of U-SPDNet, we also append skip connections from encoder to decoder, realized by manifold-valued geometric operations, namely Riemannian barycenter and Riemannian optimization. On the MDSD, Virus, FPHA, and UAV-Human datasets, the accuracy achieved by our method is respectively 6.92%, 8.67%, 1.57%, and 1.08% higher than SPDNet, certifying its effectiveness.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004713",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Biochemistry",
      "Chemistry",
      "Combinatorics",
      "Computer science",
      "Deep learning",
      "Dimensionality reduction",
      "Encoder",
      "Engineering",
      "Feature (linguistics)",
      "Gene",
      "Linguistics",
      "Manifold (fluid mechanics)",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Operating system",
      "Path (computing)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Pure mathematics",
      "Riemannian manifold",
      "Topology (electrical circuits)",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Rui"
      },
      {
        "surname": "Wu",
        "given_name": "Xiao-Jun"
      },
      {
        "surname": "Xu",
        "given_name": "Tianyang"
      },
      {
        "surname": "Hu",
        "given_name": "Cong"
      },
      {
        "surname": "Kittler",
        "given_name": "Josef"
      }
    ]
  },
  {
    "title": "Energy scheduling for DoS attack over multi-hop networks: Deep reinforcement learning approach",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.028",
    "abstract": "This paper studies the energy scheduling for Denial-of-Service (DoS) attack against remote state estimation over multi-hop networks. A smart sensor observes a dynamic system, and transmits its local state estimate to a remote estimator. Due to the limited communication range of the sensor, some relay nodes are employed to deliver data packets from the sensor to the remote estimator, which constitutes a multi-hop network. To maximize the estimation error covariance with energy constraint, a DoS attacker needs to determine the energy level implemented on each channel. This problem is formulated as an associated Markov decision process (MDP), and the existence of an optimal deterministic and stationary policy (DSP) is proved for the attacker. Besides, a simple threshold structure of the optimal policy is obtained, which significantly reduces the computational complexity. Furthermore, an up-to-date deep reinforcement learning (DRL) algorithm, dueling double Q -network (D3QN), is introduced to approximate the optimal policy. Finally, a simulation example illustrates the developed results and verifies the effectiveness of D3QN for optimal DoS attack energy scheduling.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000916",
    "keywords": [
      "Artificial intelligence",
      "Computer network",
      "Computer science",
      "Denial-of-service attack",
      "Distributed computing",
      "Estimator",
      "Markov decision process",
      "Markov process",
      "Mathematical optimization",
      "Mathematics",
      "Network packet",
      "Real-time computing",
      "Reinforcement learning",
      "Scheduling (production processes)",
      "Statistics",
      "The Internet",
      "Wireless sensor network",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Lixin"
      },
      {
        "surname": "Tao",
        "given_name": "Jie"
      },
      {
        "surname": "Liu",
        "given_name": "Yong-Hua"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      },
      {
        "surname": "Su",
        "given_name": "Chun-Yi"
      }
    ]
  },
  {
    "title": "Quasi-synchronization of drive–response systems with parameter mismatch via event-triggered impulsive control",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.020",
    "abstract": "In this paper, an event-triggered impulsive control method is proposed to investigate the quasi-synchronization of drive–response systems with parameter mismatch, which integrates the event-triggered control and impulsive control together. The impulsive instants are event-triggered and determined by a certain state-dependent triggering law. Sufficient conditions for achieving quasi-synchronization are achieved. The synchronization error is shown to be no more than a nonzero bound. Furthermore, Zeno-behavior of impulsive instants is excluded. Finally, a numerical example is presented to verify the validity of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000205",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Geometry",
      "Mathematics",
      "State (computer science)",
      "Synchronization (alternating current)",
      "Zeno's paradoxes"
    ],
    "authors": [
      {
        "surname": "Zheng",
        "given_name": "Huannan"
      },
      {
        "surname": "Yu",
        "given_name": "Nanxiang"
      },
      {
        "surname": "Zhu",
        "given_name": "Wei"
      }
    ]
  },
  {
    "title": "BalanceHRNet: An effective network for bottom-up human pose estimation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.036",
    "abstract": "In the study of human pose estimation, which is widely used in safety and sports scenes, the performance of deep learning methods is greatly reduced in high overlap rate and crowded scenes. Therefore, we propose a bottom-up model, called BalanceHRNet, which is based on balanced high-resolution module and a new branch attention module. BalanceHRNet draws on the multi-branch structure and fusion method of a popular model HigherHRNet. And our model overcomes the shortcoming of HigherHRNet that cannot obtain a large enough receptive field. Specifically, through the connecting structure in balanced high-resolution module, we can connect almost all convolutional layers and obtain a sufficiently large receptive field. At the same time, the multi-resolution representation can be maintained due to the use of balanced high-resolution module, which enable our model to recognize objects with richer scales and obtain more complex semantics information. And for branch fusion method, we design branch attention to obtain the importance of different branches at different stages. Finally, our model improves the accuracy while ensuring a smaller amount of computation than HigherHRNet. The CrowdPose dataset is used as test dataset, and HigherHRNet, AlphaPose, OpenPose and so on are taken as comparison models. The AP measured by BalanceHRNet is 63.0%, increased by 3.1% compared to best model — HigherHRNet. We also demonstrate the effectiveness of our network through the COCO(2017) keypoint detection dataset. Compared with HigherHRNet-w32, the AP of our model is improved by 1.6%.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000485",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computation",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Field (mathematics)",
      "Law",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Programming language",
      "Pure mathematics",
      "Representation (politics)",
      "Semantics (computer science)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Yaoping"
      },
      {
        "surname": "Jia",
        "given_name": "Shuangcheng"
      },
      {
        "surname": "Li",
        "given_name": "Qian"
      }
    ]
  },
  {
    "title": "Feature flow regularization: Improving structured sparsity in deep neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.013",
    "abstract": "Pruning is a model compression method that removes redundant parameters and accelerates the inference speed of deep neural networks (DNNs) while maintaining accuracy. Most available pruning methods impose various conditions on parameters or features directly. In this paper, we propose a simple and effective regularization strategy to improve the structured sparsity and structured pruning in DNNs from a new perspective of evolution of features. In particular, we consider the trajectories connecting features of adjacent hidden layers, namely feature flow. We propose feature flow regularization (FFR) to penalize the length and the total absolute curvature of the trajectories, which implicitly increases the structured sparsity of the parameters. The principle behind FFR is that short and straight trajectories will lead to an efficient network that avoids redundant parameters. Experiments on CIFAR-10 and ImageNet datasets show that FFR improves structured sparsity and achieves pruning results comparable to or even better than those state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300076X",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Deep neural networks",
      "FLOPS",
      "Feature (linguistics)",
      "Filter (signal processing)",
      "Linguistics",
      "Machine learning",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pruning",
      "Regularization (linguistics)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Yue"
      },
      {
        "surname": "Lan",
        "given_name": "Yuan"
      },
      {
        "surname": "Zhang",
        "given_name": "Luchan"
      },
      {
        "surname": "Xiang",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "A neurodynamic approach for nonsmooth optimal power consumption of intelligent and connected vehicles",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.011",
    "abstract": "This paper investigates a class of power consumption minimization and equalization for intelligent and connected vehicles cooperative system. Accordingly, a distributed optimization problem model related to power consumption and data rate of intelligent and connected vehicles is presented, where the power consumption cost function of each intelligent and connected vehicle may be nonsmooth, and the corresponding control variable is subject to the constraints generated by data acquisition, compression coding, transmission and reception. We propose a distributed subgradient-based neurodynamic approach with projection operator to achieve the optimal power consumption of intelligent and connected vehicles. By differential inclusion and nonsmooth analysis, it is confirmed that the state solution of neurodynamic system converges to the optimal solution of the distributed optimization problem. With the help of the algorithm, all intelligent and connected vehicles asymptotically reach a consensus on an optimal power consumption. Simulation results show that the proposed neurodynamic approach is capable of effectively solving the problem of power consumption optimal control for intelligent and connected vehicles cooperative system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000746",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Mathematical optimization",
      "Mathematics",
      "Minification",
      "Optimal control",
      "Subgradient method"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Jingxin"
      },
      {
        "surname": "Liao",
        "given_name": "Xiaofeng"
      },
      {
        "surname": "Dong",
        "given_name": "Jin-song"
      },
      {
        "surname": "Mansoori",
        "given_name": "Amin"
      }
    ]
  },
  {
    "title": "Cross-modal guiding and reweighting network for multi-modal RSVP-based target detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.009",
    "abstract": "Rapid Serial Visual Presentation (RSVP) based Brain–Computer Interface (BCI) facilities the high-throughput detection of rare target images by detecting evoked event-related potentials (ERPs). At present, the decoding accuracy of the RSVP-based BCI system limits its practical applications. This study introduces eye movements (gaze and pupil information), referred to as EYE modality, as another useful source of information to combine with EEG-based BCI and forms a novel target detection system to detect target images in RSVP tasks. We performed an RSVP experiment, recorded the EEG signals and eye movements simultaneously during a target detection task, and constructed a multi-modal dataset including 20 subjects. Also, we proposed a cross-modal guiding and fusion network to fully utilize EEG and EYE modalities and fuse them for better RSVP decoding performance. In this network, a two-branch backbone was built to extract features from these two modalities. A Cross-Modal Feature Guiding (CMFG) module was proposed to guide EYE modality features to complement the EEG modality for better feature extraction. A Multi-scale Multi-modal Reweighting (MMR) module was proposed to enhance the multi-modal features by exploring intra- and inter-modal interactions. And, a Dual Activation Fusion (DAF) was proposed to modulate the enhanced multi-modal features for effective fusion. Our proposed network achieved a balanced accuracy of 88.00% (±2.29) on the collected dataset. The ablation studies and visualizations revealed the effectiveness of the proposed modules. This work implies the effectiveness of introducing the EYE modality in RSVP tasks. And, our proposed network is a promising method for RSVP decoding and further improves the performance of RSVP-based target detection systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000096",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Modal",
      "Polymer chemistry"
    ],
    "authors": [
      {
        "surname": "Mao",
        "given_name": "Jiayu"
      },
      {
        "surname": "Qiu",
        "given_name": "Shuang"
      },
      {
        "surname": "Wei",
        "given_name": "Wei"
      },
      {
        "surname": "He",
        "given_name": "Huiguang"
      }
    ]
  },
  {
    "title": "Few-shot link prediction for temporal knowledge graphs based on time-aware translation and attention mechanism",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.043",
    "abstract": "Few-shot knowledge graph completion (KGC) is an important and common task in real applications, which aims to predict unseen facts when only few samples are available for each relation in the knowledge graph (KG). Previous methods on few-shot KGC mainly focus on static KG, however, many KG in real-world applications are dynamic and develop over time. In this work, we consider few-shot KGC in temporal knowledge graphs (TKGs), where the fact may only hold for a specific timestamp. We propose a Few-Shot Completion model in TKG (TFSC), which compare the input query to the given few-shot references to make predictions. Specifically, in order to enhance the representation of entities in the case of few samples, we use the attention mechanism to model the neighbor entities of the task entity with timestamp information, and generate expressive time-aware entity pair representations through the Transformer encoder. A comprehensive set of experiments is finally carried out to demonstrate the effectiveness a of our proposed model TFSC.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000552",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Economics",
      "Encoder",
      "Engineering",
      "Focus (optics)",
      "Graph",
      "Knowledge graph",
      "Machine learning",
      "Management",
      "Mechanical engineering",
      "Natural language processing",
      "One shot",
      "Operating system",
      "Optics",
      "Organic chemistry",
      "Physics",
      "Quantum mechanics",
      "Real-time computing",
      "Shot (pellet)",
      "Task (project management)",
      "Theoretical computer science",
      "Timestamp",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Han"
      },
      {
        "surname": "Bai",
        "given_name": "Luyi"
      }
    ]
  },
  {
    "title": "Accelerating gradient descent and Adam via fractional gradients",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.002",
    "abstract": "We propose a class of novel fractional-order optimization algorithms. We define a fractional-order gradient via the Caputo fractional derivatives that generalizes integer-order gradient. We refer it to as the Caputo fractional-based gradient, and develop an efficient implementation to compute it. A general class of fractional-order optimization methods is then obtained by replacing integer-order gradients with the Caputo fractional-based gradients. To give concrete algorithms, we consider gradient descent (GD) and Adam, and extend them to the Caputo fractional GD (CfGD) and the Caputo fractional Adam (CfAdam). We demonstrate the superiority of CfGD and CfAdam on several large scale optimization problems that arise from scientific machine learning applications, such as ill-conditioned least squares problem on real-world data and the training of neural networks involving non-convex objective functions. Numerical examples show that both CfGD and CfAdam result in acceleration over GD and Adam, respectively. We also derive error bounds of CfGD for quadratic functions, which further indicate that CfGD could mitigate the dependence on the condition number in the rate of convergence and results in significant acceleration over GD.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000023",
    "keywords": [
      "Acceleration",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Classical mechanics",
      "Computer network",
      "Computer science",
      "Convergence (economics)",
      "Convex function",
      "Economic growth",
      "Economics",
      "Finance",
      "Fractional calculus",
      "Geometry",
      "Gradient descent",
      "Integer (computer science)",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Order (exchange)",
      "Physics",
      "Programming language",
      "Rate of convergence",
      "Regular polygon"
    ],
    "authors": [
      {
        "surname": "Shin",
        "given_name": "Yeonjong"
      },
      {
        "surname": "Darbon",
        "given_name": "Jérôme"
      },
      {
        "surname": "Karniadakis",
        "given_name": "George Em"
      }
    ]
  },
  {
    "title": "Improving transparency and representational generalizability through parallel continual learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.02.007",
    "abstract": "This paper takes a parallel learning approach in continual learning scenarios. We define parallel continual learning as learning a sequence of tasks where the data for the previous tasks, whose distribution may have shifted over time, are also available while learning new tasks. We propose a parallel continual learning method by assigning subnetworks to each task, and simultaneously training only the assigned subnetworks on their corresponding tasks. In doing so, some parts of the network will be shared across multiple tasks. This is unlike the existing literature in continual learning which aims at learning incoming tasks sequentially, with the assumption that the data for the previous tasks have a fixed distribution. Our proposed method offers promises in: (1) Transparency in the network and in the relationship across tasks by enabling examination of the learned representations by independent and shared subnetworks, (2) Representation generalizability through sharing and training subnetworks on multiple tasks simultaneously. Our analysis shows that compared to many competing approaches such as continual learning, neural architecture search, and multi-task learning, parallel continual learning is capable of learning more generalizable representations. Also, (3) Parallel continual learning overcomes the common issue of catastrophic forgetting in continual learning algorithms. This is the first effort to train a neural network on multiple tasks and input domains simultaneously in a continual learning scenario. Our code is available at https://github.com/yours-anonym/PaRT.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000709",
    "keywords": [
      "Artificial intelligence",
      "Cognitive science",
      "Computer science",
      "Computer security",
      "Developmental psychology",
      "Generalizability theory",
      "Machine learning",
      "Psychology",
      "Theoretical computer science",
      "Transparency (behavior)"
    ],
    "authors": [
      {
        "surname": "Paknezhad",
        "given_name": "Mahsa"
      },
      {
        "surname": "Rengarajan",
        "given_name": "Hamsawardhini"
      },
      {
        "surname": "Yuan",
        "given_name": "Chenghao"
      },
      {
        "surname": "Suresh",
        "given_name": "Sujanya"
      },
      {
        "surname": "Gupta",
        "given_name": "Manas"
      },
      {
        "surname": "Ramasamy",
        "given_name": "Savitha"
      },
      {
        "surname": "Lee",
        "given_name": "Hwee Kuan"
      }
    ]
  },
  {
    "title": "Multi-granularity graph pooling for video-based person re-identification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.015",
    "abstract": "The video-based person re-identification (ReID) aims to identify the given pedestrian video sequence across multiple non-overlapping cameras. To aggregate the temporal and spatial features of the video samples, the graph neural networks (GNNs) are introduced. However, existing graph-based models, like STGCN, perform the mean/max pooling on node features to obtain the graph representation, which neglect the graph topology and node importance. In this paper, we propose the graph pooling network (GPNet) to learn the multi-granularity graph representation for the video retrieval, where the graph pooling layer is implemented to downsample the graph. We construct a multi-granular graph by using node features learned from backbone, then implement multiple graph convolutional layers to perform the spatial and temporal aggregation on nodes. To downsample the graph, we propose a multi-head full attention graph pooling (MHFAPool) layer, which integrates the advantages of existing node clustering and node selection pooling methods. Specifically, MHFAPool first learns a full attention matrix for each pooled node, then obtains the principal eigenvector of the attention matrix via the power iteration algorithm, finally takes the softmax of the principal eigenvector as the aggregation coefficients. Extensive experiments demonstrate that our GPNet achieves the competitive results on four widely-used datasets, i.e., MARS, DukeMTMC-VideoReID, iLIDS-VID and PRID-2011.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200507X",
    "keywords": [
      "Adjacency matrix",
      "Artificial intelligence",
      "Computer science",
      "Granularity",
      "Graph",
      "Operating system",
      "Pattern recognition (psychology)",
      "Pooling",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Pan",
        "given_name": "Honghu"
      },
      {
        "surname": "Chen",
        "given_name": "Yongyong"
      },
      {
        "surname": "He",
        "given_name": "Zhenyu"
      }
    ]
  },
  {
    "title": "A domain-agnostic approach for characterization of lifelong learning systems",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.007",
    "abstract": "Despite the advancement of machine learning techniques in recent years, state-of-the-art systems lack robustness to “real world” events, where the input distributions and tasks encountered by the deployed systems will not be limited to the original training context, and systems will instead need to adapt to novel distributions and tasks while deployed. This critical gap may be addressed through the development of “Lifelong Learning” systems that are capable of (1) Continuous Learning, (2) Transfer and Adaptation, and (3) Scalability. Unfortunately, efforts to improve these capabilities are typically treated as distinct areas of research that are assessed independently, without regard to the impact of each separate capability on other aspects of the system. We instead propose a holistic approach, using a suite of metrics and an evaluation framework to assess Lifelong Learning in a principled way that is agnostic to specific domains or system techniques. Through five case studies, we show that this suite of metrics can inform the development of varied and complex Lifelong Learning systems. We highlight how the proposed suite of metrics quantifies performance trade-offs present during Lifelong Learning system development — both the widely discussed Stability-Plasticity dilemma and the newly proposed relationship between Sample Efficient and Robust Learning. Further, we make recommendations for the formulation and use of metrics to guide the continuing development of Lifelong Learning systems and assess their progress in the future.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000072",
    "keywords": [
      "Artificial intelligence",
      "Characterization (materials science)",
      "Cognitive science",
      "Computer science",
      "Domain (mathematical analysis)",
      "Lifelong learning",
      "Machine learning",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Nanotechnology",
      "Pedagogy",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Baker",
        "given_name": "Megan M."
      },
      {
        "surname": "New",
        "given_name": "Alexander"
      },
      {
        "surname": "Aguilar-Simon",
        "given_name": "Mario"
      },
      {
        "surname": "Al-Halah",
        "given_name": "Ziad"
      },
      {
        "surname": "Arnold",
        "given_name": "Sébastien M.R."
      },
      {
        "surname": "Ben-Iwhiwhu",
        "given_name": "Ese"
      },
      {
        "surname": "Brna",
        "given_name": "Andrew P."
      },
      {
        "surname": "Brooks",
        "given_name": "Ethan"
      },
      {
        "surname": "Brown",
        "given_name": "Ryan C."
      },
      {
        "surname": "Daniels",
        "given_name": "Zachary"
      },
      {
        "surname": "Daram",
        "given_name": "Anurag"
      },
      {
        "surname": "Delattre",
        "given_name": "Fabien"
      },
      {
        "surname": "Dellana",
        "given_name": "Ryan"
      },
      {
        "surname": "Eaton",
        "given_name": "Eric"
      },
      {
        "surname": "Fu",
        "given_name": "Haotian"
      },
      {
        "surname": "Grauman",
        "given_name": "Kristen"
      },
      {
        "surname": "Hostetler",
        "given_name": "Jesse"
      },
      {
        "surname": "Iqbal",
        "given_name": "Shariq"
      },
      {
        "surname": "Kent",
        "given_name": "Cassandra"
      },
      {
        "surname": "Ketz",
        "given_name": "Nicholas"
      },
      {
        "surname": "Kolouri",
        "given_name": "Soheil"
      },
      {
        "surname": "Konidaris",
        "given_name": "George"
      },
      {
        "surname": "Kudithipudi",
        "given_name": "Dhireesha"
      },
      {
        "surname": "Learned-Miller",
        "given_name": "Erik"
      },
      {
        "surname": "Lee",
        "given_name": "Seungwon"
      },
      {
        "surname": "Littman",
        "given_name": "Michael L."
      },
      {
        "surname": "Madireddy",
        "given_name": "Sandeep"
      },
      {
        "surname": "Mendez",
        "given_name": "Jorge A."
      },
      {
        "surname": "Nguyen",
        "given_name": "Eric Q."
      },
      {
        "surname": "Piatko",
        "given_name": "Christine"
      },
      {
        "surname": "Pilly",
        "given_name": "Praveen K."
      },
      {
        "surname": "Raghavan",
        "given_name": "Aswin"
      },
      {
        "surname": "Rahman",
        "given_name": "Abrar"
      },
      {
        "surname": "Ramakrishnan",
        "given_name": "Santhosh Kumar"
      },
      {
        "surname": "Ratzlaff",
        "given_name": "Neale"
      },
      {
        "surname": "Soltoggio",
        "given_name": "Andrea"
      },
      {
        "surname": "Stone",
        "given_name": "Peter"
      },
      {
        "surname": "Sur",
        "given_name": "Indranil"
      },
      {
        "surname": "Tang",
        "given_name": "Zhipeng"
      },
      {
        "surname": "Tiwari",
        "given_name": "Saket"
      },
      {
        "surname": "Vedder",
        "given_name": "Kyle"
      },
      {
        "surname": "Wang",
        "given_name": "Felix"
      },
      {
        "surname": "Xu",
        "given_name": "Zifan"
      },
      {
        "surname": "Yanguas-Gil",
        "given_name": "Angel"
      },
      {
        "surname": "Yedidsion",
        "given_name": "Harel"
      },
      {
        "surname": "Yu",
        "given_name": "Shangqun"
      },
      {
        "surname": "Vallabha",
        "given_name": "Gautam K."
      }
    ]
  },
  {
    "title": "A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.014",
    "abstract": "Current deep learning methods are regarded as favorable if they empirically perform well on dedicated test sets. This mentality is seamlessly reflected in the resurfacing area of continual learning, where consecutively arriving data is investigated. The core challenge is framed as protecting previously acquired representations from being catastrophically forgotten. However, comparison of individual methods is nevertheless performed in isolation from the real world by monitoring accumulated benchmark test set performance. The closed world assumption remains predominant, i.e. models are evaluated on data that is guaranteed to originate from the same distribution as used for training. This poses a massive challenge as neural networks are well known to provide overconfident false predictions on unknown and corrupted instances. In this work we critically survey the literature and argue that notable lessons from open set recognition, identifying unknown examples outside of the observed set, and the adjacent field of active learning, querying data to maximize the expected performance gain, are frequently overlooked in the deep learning era. Hence, we propose a consolidated view to bridge continual learning, active learning and open set recognition in deep neural networks. Finally, the established synergies are supported empirically, showing joint improvement in alleviating catastrophic forgetting, querying data, selecting task orders, while exhibiting robust open world application.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802300014X",
    "keywords": [
      "Active learning (machine learning)",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biology",
      "Bridge (graph theory)",
      "Cognitive psychology",
      "Computer science",
      "Deep learning",
      "Forgetting",
      "Geodesy",
      "Geography",
      "Internal medicine",
      "Isolation (microbiology)",
      "Machine learning",
      "Medicine",
      "Microbiology",
      "Programming language",
      "Psychology",
      "Set (abstract data type)",
      "Test set"
    ],
    "authors": [
      {
        "surname": "Mundt",
        "given_name": "Martin"
      },
      {
        "surname": "Hong",
        "given_name": "Yongwon"
      },
      {
        "surname": "Pliushch",
        "given_name": "Iuliia"
      },
      {
        "surname": "Ramesh",
        "given_name": "Visvanathan"
      }
    ]
  },
  {
    "title": "DF-UDetector: An effective method towards robust deepfake detection via feature restoration",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.001",
    "abstract": "The abuse of deepfakes, a rising face swap technique, causes severe concerns about the authenticity of visual content and the dissemination of misinformation. To alleviate the threats imposed by deepfakes, a vast body of data-centric detectors has been deployed. However, the performance of these methods can be easily defected by degradations on deepfakes. To improve the performance of degradation deepfake detection, we creatively explore the recovery method in the feature space to preserve the artifacts for detection instead of directly in the image domain. In this paper, we propose a method, namely DF-UDetector, against degradation deepfakes by modeling the degraded images and transforming the extracted features to a high-quality level. To be specific, the whole model consists of three key components: an image feature extractor to capture image features, a feature transforming module to map the degradation features into a higher quality, and a discriminator to determine whether the feature map is of high quality enough. Extensive experiments on multiple video datasets show that our proposed model performs comparably or even better than state-of-the-art counterparts. Moreover, DF-UDetector outperforms by a small margin when detecting deepfakes in the wild.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000011",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Detector",
      "Discriminator",
      "Engineering",
      "Extractor",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature vector",
      "Linguistics",
      "Machine learning",
      "Margin (machine learning)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Process engineering",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Ke",
        "given_name": "Jianpeng"
      },
      {
        "surname": "Wang",
        "given_name": "Lina"
      }
    ]
  },
  {
    "title": "Tucker network: Expressive power and comparison",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.016",
    "abstract": "Deep neural networks have achieved great success in solving many machine learning and computer vision problems. In this paper, we propose a deep neural network called the Tucker network derived from the Tucker format and analyze its expressive power. The results demonstrate that the Tucker network has exponentially higher expressive power than the shallow network. In other words, a shallow network with an exponential width is required to realize the same score function as that computed by the Tucker network. Moreover, we discuss the expressive power between the hierarchical Tucker tensor network (HT network) and the proposed Tucker network. To generalize the Tucker network into a deep version, we combine the hierarchical Tucker format and Tucker format to propose a deep Tucker tensor decomposition. Its corresponding deep Tucker network is presented. Experiments are conducted on three datasets: MNIST, CIFAR-10 and CIFAR-100. The results experimentally validate the theoretical results and show that the Tucker network and deep Tucker network have better performance than the shallow network and HT network.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005081",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer network",
      "Computer science",
      "Decomposition",
      "Deep belief network",
      "Deep learning",
      "Ecology",
      "MNIST database",
      "Mathematics",
      "Network architecture",
      "Physics",
      "Power (physics)",
      "Pure mathematics",
      "Quantum mechanics",
      "Tensor (intrinsic definition)",
      "Tensor decomposition",
      "Tucker decomposition"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Ye"
      },
      {
        "surname": "Pan",
        "given_name": "Junjun"
      },
      {
        "surname": "Ng",
        "given_name": "Michael K."
      }
    ]
  },
  {
    "title": "Model-free forecasting of partially observable spatiotemporally chaotic systems",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.013",
    "abstract": "Reservoir computing is a powerful tool for forecasting turbulence because its simple architecture has the computational efficiency to handle high-dimensional systems. Its implementation, however, often requires full state-vector measurements and knowledge of the system nonlinearities. We use nonlinear projector functions to expand the system measurements to a high dimensional space and then feed them to a reservoir to obtain forecasts. We demonstrate the application of such reservoir computing networks on spatiotemporally chaotic systems, which model several features of turbulence. We show that using radial basis functions as nonlinear projectors enables complex system nonlinearities to be captured robustly even with only partial observations and without knowing the governing equations. Finally, we show that when measurements are sparse or incomplete and noisy, such that even the governing equations become inaccurate, our networks can still produce reasonably accurate forecasts, thus paving the way towards model-free forecasting of practical turbulent systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000138",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chaotic",
      "Computer science",
      "Epistemology",
      "Mathematics",
      "Nonlinear system",
      "Observable",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Reservoir computing",
      "Simple (philosophy)",
      "State space",
      "Statistics",
      "Thermodynamics",
      "Turbulence"
    ],
    "authors": [
      {
        "surname": "Gupta",
        "given_name": "Vikrant"
      },
      {
        "surname": "Li",
        "given_name": "Larry K.B."
      },
      {
        "surname": "Chen",
        "given_name": "Shiyi"
      },
      {
        "surname": "Wan",
        "given_name": "Minping"
      }
    ]
  },
  {
    "title": "Adversarial Lagrangian integrated contrastive embedding for limited size datasets",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.023",
    "abstract": "Certain datasets contain a limited number of samples with highly various styles and complex structures. This study presents a novel adversarial Lagrangian integrated contrastive embedding (ALICE) method for small-sized datasets. First, the accuracy improvement and training convergence of the proposed pre-trained adversarial transfer are shown on various subsets of datasets with few samples. Second, a novel adversarial integrated contrastive model using various augmentation techniques is investigated. The proposed structure considers the input samples with different appearances and generates a superior representation with adversarial transfer contrastive training. Finally, multi-objective augmented Lagrangian multipliers encourage the low-rank and sparsity of the presented adversarial contrastive embedding to adaptively estimate the coefficients of the regularizers automatically to the optimum weights. The sparsity constraint suppresses less representative elements in the feature space. The low-rank constraint eliminates trivial and redundant components and enables superior generalization. The performance of the proposed model is verified by conducting ablation studies by using benchmark datasets for scenarios with small data samples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005238",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Augmented Lagrangian method",
      "Benchmark (surveying)",
      "Combinatorics",
      "Computer science",
      "Constraint (computer-aided design)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Embedding",
      "Feature (linguistics)",
      "Generalization",
      "Geodesy",
      "Geography",
      "Geometry",
      "Law",
      "Linguistics",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Rank (graph theory)",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Jalali",
        "given_name": "Amin"
      },
      {
        "surname": "Lee",
        "given_name": "Minho"
      }
    ]
  },
  {
    "title": "2DHeadPose: A simple and effective annotation method for the head pose in RGB images and its dataset",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.021",
    "abstract": "Head pose estimation is one of the essential tasks in computer vision, which predicts the Euler angles of the head in an image. In recent years, CNN-based methods for head pose estimation have achieved excellent performance. Their training relies on RGB images providing facial landmarks or depth images from RGBD cameras. However, labeling facial landmarks is complex for large angular head poses in RGB images, and RGBD cameras are unsuitable for outdoor scenes. We propose a simple and effective annotation method for the head pose in RGB images. The novelty method uses a 3D virtual human head to simulate the head pose in the RGB image. The Euler angle can be calculated from the change in coordinates of the 3D virtual head. We then create a dataset using our annotation method: 2DHeadPose dataset, which contains a rich set of attributes, dimensions, and angles. Finally, we propose Gaussian label smoothing to suppress annotation noises and reflect inter-class relationships. A baseline approach is established using Gaussian label smoothing. Experiments demonstrate that our annotation method, datasets, and Gaussian label smoothing are very effective. Our baseline approach surpasses most current state-of-the-art methods. The annotation tool, dataset, and source code are publicly available at https://github.com/youngnuaa/2DHeadPose.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005214",
    "keywords": [
      "Annotation",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Gaussian",
      "Geology",
      "Geomorphology",
      "Head (geology)",
      "Pattern recognition (psychology)",
      "Physics",
      "Pose",
      "Quantum mechanics",
      "RGB color model",
      "Smoothing"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yang"
      },
      {
        "surname": "Zhou",
        "given_name": "Wanlin"
      },
      {
        "surname": "Zhou",
        "given_name": "Jiakai"
      }
    ]
  },
  {
    "title": "STACoRe: Spatio-temporal and action-based contrastive representations for reinforcement learning in Atari",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.018",
    "abstract": "With the development of deep learning technology, deep reinforcement learning (DRL) has successfully built intelligent agents in sequential decision-making problems through interaction with image-based environments. However, learning from unlimited interaction is impractical and sample inefficient because training an agent requires many trial and error and numerous samples. One response to this problem is sample-efficient DRL, a research area that encourages learning effective state representations in limited interactions with image-based environments. Previous methods could effectively surpass human performance by training an RL agent using self-supervised learning and data augmentation to learn good state representations from a given interaction. However, most of the existing methods only consider similarity of image observations so that they are hard to capture semantic representations. To address these challenges, we propose spatio-temporal and action-based contrastive representation (STACoRe) learning for sample-efficient DRL. STACoRe performs two contrastive learning to learn proper state representations. One uses the agent’s actions as pseudo labels, and the other uses spatio-temporal information. In particular, when performing the action-based contrastive learning, we propose a method that automatically selects data augmentation techniques suitable for each environment for stable model training. We train the model by simultaneously optimizing an action-based contrastive loss function and spatio-temporal contrastive loss functions in an end-to-end manner. This leads to improving sample efficiency for DRL. We use 26 benchmark games in Atari 2600 whose environment interaction is limited to only 100k steps. The experimental results confirm that our method is more sample efficient than existing methods. The code is available at https://github.com/dudwojae/STACoRe.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200510X",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Contrast (vision)",
      "Geodesy",
      "Geography",
      "Law",
      "Machine learning",
      "Physics",
      "Political science",
      "Politics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Representation (politics)",
      "Sample (material)"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Young Jae"
      },
      {
        "surname": "Kim",
        "given_name": "Jaehoon"
      },
      {
        "surname": "Kwak",
        "given_name": "Mingu"
      },
      {
        "surname": "Park",
        "given_name": "Young Joon"
      },
      {
        "surname": "Kim",
        "given_name": "Seoung Bum"
      }
    ]
  },
  {
    "title": "A subgradient-based neurodynamic algorithm to constrained nonsmooth nonconvex interval-valued optimization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.012",
    "abstract": "In this paper, a subgradient-based neurodynamic algorithm is presented to solve the nonsmooth nonconvex interval-valued optimization problem with both partial order and linear equality constraints, where the interval-valued objective function is nonconvex, and interval-valued partial order constraint functions are convex. The designed neurodynamic system is constructed by a differential inclusion with upper semicontinuous right-hand side, whose calculation load is reduced by relieving penalty parameters estimation and complex matrix inversion. Based on nonsmooth analysis and the extension theorem of the solution of differential inclusion, it is obtained that the global existence and boundedness of state solution of neurodynamic system, as well as the asymptotic convergence of state solution to the feasible region and the set of L U -critical points of interval-valued nonconvex optimization problem. Several numerical experiments and the applications to emergency supplies distribution and nondeterministic fractional continuous static games are solved to illustrate the applicability of the proposed neurodynamic algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000126",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Combinatorics",
      "Convex function",
      "Convex optimization",
      "Differential inclusion",
      "Feasible region",
      "Geometry",
      "Interval (graph theory)",
      "Mathematical optimization",
      "Mathematics",
      "Nondeterministic algorithm",
      "Optimization problem",
      "Regular polygon",
      "Subgradient method"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Jingxin"
      },
      {
        "surname": "Liao",
        "given_name": "Xiaofeng"
      },
      {
        "surname": "Dong",
        "given_name": "Jin-song"
      },
      {
        "surname": "Mansoori",
        "given_name": "Amin"
      }
    ]
  },
  {
    "title": "Deep learning in random neural fields: Numerical experiments via neural tangent kernel",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.020",
    "abstract": "A biological neural network in the cortex forms a neural field. Neurons in the field have their own receptive fields, and connection weights between two neurons are random but highly correlated when they are in close proximity in receptive fields. In this paper, we investigate such neural fields in a multilayer architecture to investigate the supervised learning of the fields. We empirically compare the performances of our field model with those of randomly connected deep networks. The behavior of a randomly connected network is investigated on the basis of the key idea of the neural tangent kernel regime, a recent development in the machine learning theory of over-parameterized networks; for most randomly connected neural networks, it is shown that global minima always exist in their small neighborhoods. We numerically show that this claim also holds for our neural fields. In more detail, our model has two structures: (i) each neuron in a field has a continuously distributed receptive field, and (ii) the initial connection weights are random but not independent, having correlations when the positions of neurons are close in each layer. We show that such a multilayer neural field is more robust than conventional models when input patterns are deformed by noise disturbances. Moreover, its generalization ability can be slightly superior to that of conventional models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005123",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Connection (principal bundle)",
      "Discrete mathematics",
      "Field (mathematics)",
      "Generalization",
      "Geometry",
      "Kernel (algebra)",
      "Mathematical analysis",
      "Mathematics",
      "Maxima and minima",
      "Pure mathematics",
      "Receptive field",
      "Recurrent neural network",
      "Stochastic neural network",
      "Tangent",
      "Topology (electrical circuits)",
      "Types of artificial neural networks"
    ],
    "authors": [
      {
        "surname": "Watanabe",
        "given_name": "Kaito"
      },
      {
        "surname": "Sakamoto",
        "given_name": "Kotaro"
      },
      {
        "surname": "Karakida",
        "given_name": "Ryo"
      },
      {
        "surname": "Sonoda",
        "given_name": "Sho"
      },
      {
        "surname": "Amari",
        "given_name": "Shun-ichi"
      }
    ]
  },
  {
    "title": "Adaptive pseudo-Siamese policy network for temporal knowledge prediction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.004",
    "abstract": "Temporal knowledge prediction is a crucial task for early event warning, which has gained increasing attention recently. It aims to predict future facts based on relevant historical facts using temporal knowledge graphs. There are two main difficulties associated with the prediction task: from the perspective of historical facts, modeling the evolutionary patterns of facts to accurately predict the query and from the query perspective, handling the two cases where the query contains seen and unseen entities in a unified framework. Driven by these two problems, we propose a novel adaptive pseudo-Siamese policy network for temporal knowledge prediction based on reinforcement learning. Specifically, we design the policy network in our model as a pseudo-Siamese network consisting of two sub-policy networks. In the sub-policy network I, the agent searches for the answer to the query along the entity-relation paths to capture static evolutionary patterns. In sub-policy network II, the agent searches for the answer to the query along relation-time paths to deal with unseen entities. Moreover, we develop a temporal relation encoder to capture the temporal evolutionary patterns. Finally, we design a gating mechanism to adaptively integrate the results of the two sub-policy networks to help the agent focus on the destination answer. To assess the performance of our model, we conduct link prediction on four benchmark datasets, and extensive experimental results demonstrate that our method achieves considerable performance compared with existing methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000047",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Data mining",
      "Economics",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Management",
      "Perspective (graphical)",
      "Reinforcement learning",
      "Relation (database)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Shao",
        "given_name": "Pengpeng"
      },
      {
        "surname": "Liu",
        "given_name": "Tong"
      },
      {
        "surname": "Che",
        "given_name": "Feihu"
      },
      {
        "surname": "Zhang",
        "given_name": "Dawei"
      },
      {
        "surname": "Tao",
        "given_name": "Jianhua"
      }
    ]
  },
  {
    "title": "Predefined-time synchronization of coupled neural networks with switching parameters and disturbed by Brownian motion",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.024",
    "abstract": "This article focuses on predefined time synchronization problem for a class of signal switching neural networks with time-varying delays. In the network models, we not only consider the coupling characteristics in the following networks, but also consider the disturbance with standard Brownian motion. In the design of the controller, the control gain is designed as 1 ɛ + T p − t ( t ∈ [ T 0 , T p ) , ɛ is an optional smaller positive number), which avoids the infinite gain (the control gain is designed as 1 T p − t in other reference). In order to get the predefined time control law, a power function is multiplied to the Lyapunov functional, from which it can get an exponential upper bound function via the derivative and mathematical expectation operation. Utilizing the martingale theory and the method of Laplace matrix, some novel predefined time synchronization criteria are obtained for the leader-following neural networks, meanwhile the following networks can maintain the leader network after achieved synchronization. Based on the special network of the main system, five corollaries separately develop the predefined time synchronization results from different perspectives. An example with some simulation figures and computing results fully exhibits the effectiveness of the achieved synchronization scheme. In this case, although the error signal is disturbed by Brownian motion, the trace signal can still stably converge to zero by this control scheme, meanwhile the predefined-time control effect is achieved.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200524X",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Brownian motion",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Laplace transform",
      "Mathematical analysis",
      "Mathematics",
      "Statistics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Xianghui"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Wang",
        "given_name": "Xin"
      }
    ]
  },
  {
    "title": "Robust exponential stability of discrete-time uncertain impulsive stochastic neural networks with delayed impulses",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.016",
    "abstract": "This paper is devoted to the study of the robust exponential stability (RES) of discrete-time uncertain impulsive stochastic neural networks (DTUISNNs) with delayed impulses. Using Lyapunov function methods and Razumikhin techniques, a number of sufficient conditions for mean square (RES-ms) robust exponential stability are derived. The obtained results show that the hybrid dynamic is RES-ms with regard to lower boundary of impulse interval if the discrete-time stochastic neural networks (DTSNNs) is RES-ms and that the impulsive effects are instable. Conversely, if DTSNNs is not RES-ms, impulsive effects can induce unstable neural networks (NNs) to stabilize again concerning an upper bound of the impulsive interval. The results obtained in this study have a broader scope of application than some previously existing findings. Two numerical examples were presented to verify the availability and advantages of the results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000163",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Exponential function",
      "Exponential stability",
      "Impulse (physics)",
      "Interval (graph theory)",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Stability (learning theory)",
      "Statistics",
      "Stochastic neural network",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Cai",
        "given_name": "Ting"
      },
      {
        "surname": "Cheng",
        "given_name": "Pei"
      },
      {
        "surname": "Yao",
        "given_name": "Fengqi"
      },
      {
        "surname": "Hua",
        "given_name": "Mingang"
      }
    ]
  },
  {
    "title": "Fixed-time and prescribed-time synchronization of quaternion-valued neural networks: A control strategy involving Lyapunov functions",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.014",
    "abstract": "A control strategy containing Lyapunov functions is proposed in this paper. Based on this strategy, the fixed-time synchronization of a time-delay quaternion-valued neural network (QVNN) is analyzed. This strategy is extended to the prescribed-time synchronization of the QVNN. Furthermore, an improved two-step switching control strategy is also proposed based on this flexible control strategy. Compared with some existing methods, the main method of this paper is a non-decomposition one, does not contain a sign function in the controller, and has better synchronization accuracy. Two numerical examples verify the above advantages.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005068",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Geometry",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Quaternion",
      "Sign (mathematics)",
      "Sign function",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Tao"
      },
      {
        "surname": "Wu",
        "given_name": "Yanqiu"
      },
      {
        "surname": "Tu",
        "given_name": "Zhengwen"
      },
      {
        "surname": "Alofi",
        "given_name": "A.S."
      },
      {
        "surname": "Lu",
        "given_name": "Jianquan"
      }
    ]
  },
  {
    "title": "Multiclass skin lesion localization and classification using deep learning based features fusion and selection framework for smart healthcare",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.022",
    "abstract": "Background: The idea of smart healthcare has gradually gained attention as a result of the information technology industry’s rapid development. Smart healthcare uses next-generation technologies i.e., artificial intelligence (AI) and Internet of Things (IoT), to intelligently transform current medical methods to make them more efficient, dependable and individualized. One of the most prominent uses of telemedicine and e-health in medical image analysis is teledermatology. Telecommunications technologies are used in this industry to send medical information to professionals. Teledermatology is a useful method for the identification of skin lesions, particularly in rural locations, because the skin is visually perceptible. One of the most recent tools for diagnosing skin cancer is dermoscopy. To classify skin malignancies, numerous computational approaches have been proposed in the literature. However, difficulties still exist i.e., lesions with low contrast, imbalanced datasets, high level of memory complexity, and the extraction of redundant features. Methods: In this work, a unified CAD model is proposed based on a deep learning framework for skin lesion segmentation and classification. In the proposed approach, the source dermoscopic images are initially pre-processed using a contrast enhancement based modified bio-inspired multiple exposure fusion approach. In the second stage, a custom 26-layered convolutional neural network (CNN) architecture is designed to segment the skin lesion regions. In the third stage, four pre-trained CNN models (Xception, ResNet-50, ResNet-101 and VGG16) are modified and trained using transfer learning on the segmented lesion images. In the fourth stage, the deep features vectors are extracted from all the CNN models and fused using the convolutional sparse image decomposition fusion approach. In the fifth stage, the univariate measurement and Poisson distribution feature selection approach is used for the best features selection for classification. Finally, the selected features are fed to the multi-class support vector machine (MC-SVM) for the final classification. Results: The proposed approach employed to the HAM10000, ISIC2018, ISIC2019, and PH2 datasets and achieved an accuracy of 98.57%, 98.62%, 93.47%, and 98.98% respectively which are better than previous works. Conclusion: When compared to renowned state-of-the-art methods, experimental results show that the proposed skin lesion detection and classification approach achieved higher performance in terms of both visually and enhanced quantitative evaluation with enhanced accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000229",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Dermatology",
      "Economic growth",
      "Economics",
      "Health care",
      "Machine learning",
      "Medicine",
      "Multiclass classification",
      "Pattern recognition (psychology)",
      "Segmentation",
      "Skin lesion",
      "Support vector machine",
      "Teledermatology",
      "Telemedicine"
    ],
    "authors": [
      {
        "surname": "Maqsood",
        "given_name": "Sarmad"
      },
      {
        "surname": "Damaševičius",
        "given_name": "Robertas"
      }
    ]
  },
  {
    "title": "Origin of the efficiency of spike timing-based neural computation for processing temporal information",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.017",
    "abstract": "Although the advantage of spike timing-based over rate-based network computation has been recognized, the underlying mechanism remains unclear. Using Tempotron and Perceptron as elementary neural models, we examined the intrinsic difference between spike timing-based and rate-based computations. For more direct comparison, we modified Tempotron computation into rate-based computation with the retention of some temporal information. Previous studies have shown that spike timing-based computation are computationally more powerful than rate-based computation in terms of the number of computational units required and the capability in classifying random patterns. Our study showed that spike timing-based and rate-based Tempotron computations provided similar capability in classifying random spike patterns, as well as in text sentiment classification and spam text detection. However, spike timing-based computation is superior in performing a task involving discriminating forward vs. reverse sequence of events, i.e., information mainly temporal in nature. Further studies revealed that this superiority required the asymmetry in the profile of the postsynaptic potential (PSP), and that temporal sequence information was converted to biased spatial distribution of synaptic weight modifications during learning. Thus, the intrinsic PSP asymmetry is a mechanistic basis for the high efficiency of spike timing-based computation for processing temporal information.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005093",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computation",
      "Computer science",
      "Models of neural computation",
      "Pattern recognition (psychology)",
      "Software engineering",
      "Spike (software development)"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Zhiwei"
      },
      {
        "surname": "Xu",
        "given_name": "Jiaming"
      },
      {
        "surname": "Zhang",
        "given_name": "Tielin"
      },
      {
        "surname": "Poo",
        "given_name": "Mu-ming"
      },
      {
        "surname": "Xu",
        "given_name": "Bo"
      }
    ]
  },
  {
    "title": "Self-attention learning network for face super-resolution",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.006",
    "abstract": "Existing face super-resolution methods depend on deep convolutional networks (DCN) to recover high-quality reconstructed images. They either acquire information in a single space by designing complex models for direct reconstruction, or employ additional networks to extract multiple prior information to enhance the representation of features. However, existing methods are still challenging to perform well due to the inability to learn complete and uniform representations. To this end, we propose a self-attention learning network (SLNet) for three-stage face super-resolution, which fully explores the interdependence of low- and high-level spaces to achieve compensation of the information used for reconstruction. Firstly, SLNet uses a hierarchical feature learning framework to obtain shallow information in the low-level space. Then, the shallow information with cumulative errors due to DCN is improved under high-resolution (HR) supervision, while bringing an intermediate reconstruction result and a powerful intermediate benchmark. Finally, the improved feature representation is further enhanced in high-level space by a multi-scale context-aware encoder–decoder for facial reconstruction. The features in both spaces are explored progressively from coarse to fine reconstruction information. The experimental results show that SLNet has a competitive performance compared to the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000060",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Computer vision",
      "Context (archaeology)",
      "Convolutional neural network",
      "Deep learning",
      "Encoder",
      "Face (sociological concept)",
      "Facial recognition system",
      "Feature (linguistics)",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Law",
      "Linguistics",
      "Machine learning",
      "Operating system",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Zeng",
        "given_name": "Kangli"
      },
      {
        "surname": "Wang",
        "given_name": "Zhongyuan"
      },
      {
        "surname": "Lu",
        "given_name": "Tao"
      },
      {
        "surname": "Chen",
        "given_name": "Jianyu"
      },
      {
        "surname": "Wang",
        "given_name": "Jiaming"
      },
      {
        "surname": "Xiong",
        "given_name": "Zixiang"
      }
    ]
  },
  {
    "title": "Coexistence and local stability of multiple equilibrium points for fractional-order state-dependent switched competitive neural networks with time-varying delays",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.013",
    "abstract": "This paper investigates the coexistence and local stability of multiple equilibrium points for a class of competitive neural networks with sigmoidal activation functions and time-varying delays, in which fractional-order derivative and state-dependent switching are involved at the same time. Some novel criteria are established to ensure that such n -neuron neural networks can have 5 m 1 ⋅ 3 m 2 total equilibrium points and 3 m 1 ⋅ 2 m 2 locally stable equilibrium points with m 1 + m 2 = n , based on the fixed-point theorem, the definition of equilibrium point in the sense of Filippov, the theory of fractional-order differential equation and Lyapunov function method. The investigation implies that the competitive neural networks with switching can possess greater storage capacity than the ones without switching. Moreover, the obtained results include the multistability results of both fractional-order switched Hopfield neural networks and integer-order switched Hopfield neural networks as special cases, thus generalizing and improving some existing works. Finally, four numerical examples are presented to substantiate the effectiveness of the theoretical analysis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005056",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Differential equation",
      "Economics",
      "Equilibrium point",
      "Evolutionary biology",
      "Finance",
      "Fixed point",
      "Fixed-point theorem",
      "Function (biology)",
      "Hopfield network",
      "Integer (computer science)",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Multistability",
      "Nonlinear system",
      "Order (exchange)",
      "Ordinary differential equation",
      "Physics",
      "Programming language",
      "Pure mathematics",
      "Quantum mechanics",
      "Sigmoid function",
      "Stability (learning theory)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Zhongwen"
      },
      {
        "surname": "Nie",
        "given_name": "Xiaobing"
      },
      {
        "surname": "Cao",
        "given_name": "Boqiang"
      }
    ]
  },
  {
    "title": "Performance estimation for the memristor-based computing-in-memory implementation of extremely factorized network for real-time and low-power semantic segmentation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.008",
    "abstract": "Nowadays many semantic segmentation algorithms have achieved satisfactory accuracy on von Neumann platforms (e.g., GPU), but the speed and energy consumption have not meet the high requirements of certain edge applications like autonomous driving. To tackle this issue, it is of necessity to design an efficient lightweight semantic segmentation algorithm and then implement it on emerging hardware platforms with high speed and energy efficiency. Here, we first propose an extremely factorized network (EFNet) which can learn multi-scale context information while preserving rich spatial information with reduced model complexity. Experimental results on the Cityscapes dataset show that EFNet achieves an accuracy of 68.0% mean intersection over union (mIoU) with only 0.18M parameters, at a speed of 99 frames per second (FPS) on a single RTX 3090 GPU. Then, to further improve the speed and energy efficiency, we design a memristor-based computing-in-memory (CIM) accelerator for the hardware implementation of EFNet. It is shown by the simulation in DNN+NeuroSim V2.0 that the memristor-based CIM accelerator is ∼ 63 × ( ∼ 4.6 × ) smaller in area, at most ∼ 9.2 × ( ∼ 1000 × ) faster, and ∼ 470 × ( ∼ 2400 × ) more energy-efficient than the RTX 3090 GPU (the Jetson Nano embedded development board), although its accuracy slightly decreases by 1.7% mIoU. Therefore, the memristor-based CIM accelerator has great potential to be deployed at the edge to implement lightweight semantic segmentation models like EFNet. This study showcases an algorithm-hardware co-design to realize real-time and low-power semantic segmentation at the edge.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000084",
    "keywords": [
      "Aerospace engineering",
      "Artificial intelligence",
      "Biology",
      "Computer engineering",
      "Computer hardware",
      "Computer science",
      "Context (archaeology)",
      "Efficient energy use",
      "Electrical engineering",
      "Electronic engineering",
      "Energy (signal processing)",
      "Energy consumption",
      "Engineering",
      "Enhanced Data Rates for GSM Evolution",
      "Frame rate",
      "Intersection (aeronautics)",
      "Mathematics",
      "Memristor",
      "Operating system",
      "Paleontology",
      "Segmentation",
      "Statistics",
      "Von Neumann architecture"
    ],
    "authors": [
      {
        "surname": "Dong",
        "given_name": "Shuai"
      },
      {
        "surname": "Fan",
        "given_name": "Zhen"
      },
      {
        "surname": "Chen",
        "given_name": "Yihong"
      },
      {
        "surname": "Chen",
        "given_name": "Kaihui"
      },
      {
        "surname": "Qin",
        "given_name": "Minghui"
      },
      {
        "surname": "Zeng",
        "given_name": "Min"
      },
      {
        "surname": "Lu",
        "given_name": "Xubing"
      },
      {
        "surname": "Zhou",
        "given_name": "Guofu"
      },
      {
        "surname": "Gao",
        "given_name": "Xingsen"
      },
      {
        "surname": "Liu",
        "given_name": "Jun-Ming"
      }
    ]
  },
  {
    "title": "Topological biclustering ARTMAP for identifying within bicluster relationships",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.010",
    "abstract": "Biclustering is a powerful tool for exploratory data analysis in domains such as social networking, data reduction, and differential gene expression studies. Topological learning identifies connected regions that are difficult to find using other traditional clustering methods and produces a graphical representation. Therefore, to improve the quality of biclustering and module extraction, this work combines the adaptive resonance theory (ART)-based methods of biclustering ARTMAP (BARTMAP) and topological ART (TopoART), to produce TopoBARTMAP. The latter inherits the ability to detect topological associations while performing data reduction. The capabilities of TopoBARTMAP were benchmarked using 35 real world cancer datasets and contrasted with other (bi)clustering methods, where it showed a statistically significant improvement over the other assessed methods on ordered and shuffled data experiments. In experiments with 12 synthetic datasets, the method was observed to perform better at identifying constant, scale, shift, and shift scale type biclusters. The produced graphical representation was refined to represent gene bicluster associations and was assessed on the NCBI GSE89116 dataset containing expression levels of 39,326 probes sampled over 38 observations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005020",
    "keywords": [
      "Adaptive resonance theory",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biclustering",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Computer science",
      "Correlation clustering",
      "Data mining",
      "Law",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Physics",
      "Political science",
      "Politics",
      "Quantum mechanics",
      "Representation (politics)",
      "Scale (ratio)",
      "Topological data analysis"
    ],
    "authors": [
      {
        "surname": "Yelugam",
        "given_name": "Raghu"
      },
      {
        "surname": "Brito da Silva",
        "given_name": "Leonardo Enzo"
      },
      {
        "surname": "Wunsch II",
        "given_name": "Donald C."
      }
    ]
  },
  {
    "title": "Deterministic learning-based neural network control with adaptive phase compensation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2023.01.005",
    "abstract": "Under the persistent excitation (PE) condition, the real dynamics of the nonlinear system can be obtained through the deterministic learning-based radial basis function neural network (RBFNN) control. However, in this scheme, the learning speed and accuracy are limited by the tradeoff between the PE levels and the approximation capabilities of the neural network (NN). Inspired by the frequency domain phase compensation of linear time-invariant (LTI) systems, this paper presents an adaptive phase compensator employing the pure time delay to improve the performance of the deterministic learning-based adaptive feedforward control with the reference input known a priori. When the adaptive phase compensation is applied to the hidden layer of the RBFNN, the nonlinear approximation capability of the RBFNN is effectively improved such that both the learning performance (learning speed and accuracy) and the control performance of the deterministic learning-based control scheme are improved. Theoretical analysis is conducted to prove the stability of the proposed learning control scheme for a class of systems which are affine in the control. Simulation studies demonstrate the effectiveness of the proposed phase compensation method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608023000059",
    "keywords": [
      "A priori and a posteriori",
      "Adaptive control",
      "Adaptive learning",
      "Artificial intelligence",
      "Artificial neural network",
      "Compensation (psychology)",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Epistemology",
      "Feed forward",
      "Feedforward neural network",
      "Machine learning",
      "Nonlinear system",
      "Philosophy",
      "Physics",
      "Psychoanalysis",
      "Psychology",
      "Quantum mechanics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Fei",
        "given_name": "Yiming"
      },
      {
        "surname": "Li",
        "given_name": "Dongyu"
      },
      {
        "surname": "Li",
        "given_name": "Yanan"
      },
      {
        "surname": "Li",
        "given_name": "Jiangang"
      }
    ]
  },
  {
    "title": "On joint parameterizations of linear and nonlinear functionals in neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.019",
    "abstract": "The paper proposes a new class of nonlinear operators and a dual learning paradigm where optimization jointly concerns both linear convolutional weights and the parameters of these nonlinear operators. The nonlinear class proposed to perform a rich functional representation is composed by functions called rectified parametric sigmoid units. This class is constructed to benefit from the advantages of both sigmoid and rectified linear unit functions, while rejecting their respective drawbacks. Moreover, the analytic form of this new neural class involves scale, shift and shape parameters to obtain a wide range of activation shapes, including the standard rectified linear unit as a limit case. Parameters of this neural transfer class are considered as learnable for the sake of discovering the complex shapes that can contribute to solving machine learning issues. Performance achieved by the joint learning of convolutional and rectified parametric sigmoid learnable parameters are shown to be outstanding in both shallow and deep learning frameworks. This class opens new prospects with respect to machine learning in the sense that main learnable parameters are attached not only to linear transformations, but also to a wide range of nonlinear operators.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005111",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Composite material",
      "Computer science",
      "Convolutional neural network",
      "Law",
      "Materials science",
      "Mathematics",
      "Nonlinear system",
      "Parametric statistics",
      "Physics",
      "Political science",
      "Politics",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Representation (politics)",
      "Sigmoid function",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Atto",
        "given_name": "Abdourrahmane Mahamane"
      },
      {
        "surname": "Galichet",
        "given_name": "Sylvie"
      },
      {
        "surname": "Pastor",
        "given_name": "Dominique"
      },
      {
        "surname": "Méger",
        "given_name": "Nicolas"
      }
    ]
  },
  {
    "title": "Monte Carlo Ensemble Neural Network for the diagnosis of Alzheimer’s disease",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.032",
    "abstract": "Convolutional neural networks (CNNs) have been increasingly used in the computer-aided diagnosis of Alzheimer’s Disease (AD). This study takes the advantage of the 2D-slice CNN fast computation and ensemble approaches to develop a Monte Carlo Ensemble Neural Network (MCENN) by introducing Monte Carlo sampling and an ensemble neural network in the integration with ResNet50. Our goals are to improve the 2D-slice CNN performance and to design the MCENN model insensitive to image resolution. Unlike traditional ensemble approaches with multiple base learners, our MCENN model incorporates one neural network learner and generates a large number of possible classification decisions via Monte Carlo sampling of feature importance within the combined slices. This can overcome the main weakness of the lack of 3D brain anatomical information in 2D-slice CNNs and develop a neural network to learn the 3D relevance of the features across multiple slices. Brain images from Alzheimer’s Disease Neuroimaging Initiative (ADNI, 7199 scans), the Open Access Series of Imaging Studies-3 (OASIS-3, 1992 scans), and a clinical sample (239 scans) are used to evaluate the performance of the MCENN model for the classification of cognitively normal (CN), patients with mild cognitive impairment (MCI) and AD. Our MCENN with a small number of slices and minimal image processing (rigid transformation, intensity normalization, skull stripping) achieves the AD classification accuracy of 90%, better than existing 2D-slice CNNs (accuracy: 63 % ∼ 84 % ) and 3D CNNs (accuracy: 74 % ∼ 88 % ). Furthermore, the MCENN is robust to be trained in the ADNI dataset and applied to the OASIS-3 dataset and the clinical sample. Our experiments show that the AD classification accuracy of the MCENN model is comparable when using high- and low-resolution brain images, suggesting the insensitivity of the MCENN to image resolution. Hence, the MCENN does not require high-resolution 3D brain structural images and comprehensive image processing, which supports its potential use in a clinical setting.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004282",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Machine learning",
      "Mathematics",
      "Monte Carlo method",
      "Neuroimaging",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Chaoqiang"
      },
      {
        "surname": "Huang",
        "given_name": "Fei"
      },
      {
        "surname": "Qiu",
        "given_name": "Anqi"
      }
    ]
  },
  {
    "title": "SGORNN: Combining scalar gates and orthogonal constraints in recurrent networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.028",
    "abstract": "Recurrent Neural Network (RNN) models have been applied in different domains, producing high accuracies on time-dependent data. However, RNNs have long suffered from exploding gradients during training, mainly due to their recurrent process. In this context, we propose a variant of the scalar gated FastRNN architecture, called Scalar Gated Orthogonal Recurrent Neural Networks (SGORNN). SGORNN utilizes orthogonal matrices at the recurrent step. Our experiments evaluate SGORNN using two recently proposed orthogonal parametrizations for the recurrent weights of an RNN. We present a constraint on the scalar gates of SGORNN, which is easily enforced at training time to provide a probabilistic generalization gap which grows linearly with the length of sequences processed. Next, we provide bounds on the gradients of SGORNN to show the impossibility of exponentially exploding gradients through time. Our experimental results on the addition problem confirm that our combination of orthogonal and scalar gated RNNs are able to outperform other orthogonal RNNs and LSTM on long sequences. We further evaluate SGORNN on the HAR-2 classification task, where it improves upon the accuracy of several models using far fewer parameters than standard RNNs. Finally, we evaluate SGORNN on the Penn Treebank word-level language modeling task, where it again outperforms its related architectures and shows comparable performance to LSTM using far less parameters. Overall, SGORNN shows higher representation capacity than the other orthogonal RNNs tested, suffers from less overfitting than other models in our experiments, benefits from a decrease in parameter count, and alleviates exploding gradients during backpropagation through time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004695",
    "keywords": [
      "Algorithm",
      "Annotation",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Deep learning",
      "Geometry",
      "Mathematics",
      "Overfitting",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Probabilistic logic",
      "Recurrent neural network",
      "Scalar (mathematics)",
      "Treebank"
    ],
    "authors": [
      {
        "surname": "Taylor-Melanson",
        "given_name": "Will"
      },
      {
        "surname": "Ferreira",
        "given_name": "Martha Dais"
      },
      {
        "surname": "Matwin",
        "given_name": "Stan"
      }
    ]
  },
  {
    "title": "Improving fine-tuning of self-supervised models with Contrastive Initialization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.012",
    "abstract": "Self-supervised learning (SSL) has achieved remarkable performance in pre-training the models that can be further used in downstream tasks via fine-tuning. However, these self-supervised models may not capture meaningful semantic information since the images belonging to the same class are often regarded as negative pairs in the contrastive loss. Consequently, the images of the same class are often located far away from each other in the learned feature space, which would inevitably hamper the fine-tuning process. To address this issue, we seek to explicitly enhance the semantic relation among instances on the targeted downstream task and provide a better initialization for the subsequent fine-tuning. To this end, we propose a Contrastive Initialization (COIN) method that breaks the standard fine-tuning pipeline by introducing an extra class-aware initialization stage before fine-tuning. Specifically, we exploit a supervised contrastive loss to increase inter-class discrepancy and intra-class compactness of features on the target dataset. In this way, self-supervised models can be easily trained to discriminate instances of different classes during the final fine-tuning stage. Extensive experiments show that, with the enriched semantics, our COIN significantly outperforms existing methods without introducing extra training cost and sets new state-of-the-arts on multiple downstream tasks. For example, compared with the baseline method, our COIN improves the accuracy by 5% on ImageNet-20 and 2.57% on CIFAR100, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005044",
    "keywords": [
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Economics",
      "Feature (linguistics)",
      "Initialization",
      "Linguistics",
      "Machine learning",
      "Management",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pipeline (software)",
      "Process (computing)",
      "Programming language",
      "Semantics (computer science)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Pan",
        "given_name": "Haolin"
      },
      {
        "surname": "Guo",
        "given_name": "Yong"
      },
      {
        "surname": "Deng",
        "given_name": "Qinyi"
      },
      {
        "surname": "Yang",
        "given_name": "Haomin"
      },
      {
        "surname": "Chen",
        "given_name": "Jian"
      },
      {
        "surname": "Chen",
        "given_name": "Yiqun"
      }
    ]
  },
  {
    "title": "DroneAttention: Sparse weighted temporal attention for drone-camera based activity recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.005",
    "abstract": "Human activity recognition (HAR) using drone-mounted cameras has attracted considerable interest from the computer vision research community in recent years. A robust and efficient HAR system has a pivotal role in fields like video surveillance, crowd behavior analysis, sports analysis, and human–computer interaction. What makes it challenging are the complex poses, understanding different viewpoints, and the environmental scenarios where the action is taking place. To address such complexities, in this paper, we propose a novel Sparse Weighted Temporal Attention (SWTA) module to utilize sparsely sampled video frames for obtaining global weighted temporal attention. The proposed SWTA is comprised of two parts. First, temporal segment network that sparsely samples a given set of frames. Second, weighted temporal attention, which incorporates a fusion of attention maps derived from optical flow, with raw RGB images. This is followed by a basenet network, which comprises a convolutional neural network (CNN) module along with fully connected layers that provide us with activity recognition. The SWTA network can be used as a plug-in module to the existing deep CNN architectures, for optimizing them to learn temporal information by eliminating the need for a separate temporal stream. It has been evaluated on three publicly available benchmark datasets, namely Okutama, MOD20, and Drone-Action. The proposed model has received an accuracy of 72.76%, 92.56%, and 78.86% on the respective datasets thereby surpassing the previous state-of-the-art performances by a margin of 25.26%, 18.56%, and 2.94%, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200497X",
    "keywords": [
      "Action recognition",
      "Activity recognition",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Class (philosophy)",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Drone",
      "Genetics",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Machine learning",
      "Margin (machine learning)",
      "Optical flow",
      "Pattern recognition (psychology)",
      "Programming language",
      "RGB color model",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Yadav",
        "given_name": "Santosh Kumar"
      },
      {
        "surname": "Luthra",
        "given_name": "Achleshwar"
      },
      {
        "surname": "Pahwa",
        "given_name": "Esha"
      },
      {
        "surname": "Tiwari",
        "given_name": "Kamlesh"
      },
      {
        "surname": "Rathore",
        "given_name": "Heena"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      },
      {
        "surname": "Corcoran",
        "given_name": "Peter"
      }
    ]
  },
  {
    "title": "Observer-based dynamical pattern recognition via deterministic learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.004",
    "abstract": "In this paper, based on the sampled-data observer and the deterministic learning theory, a rapid dynamical pattern recognition approach is proposed for univariate time series composed of the output signals of the dynamical systems. Specifically, locally-accurate identification of inherent dynamics of univariate time series is first achieved by using the sampled-data observer and the radial basis function (RBF) networks. The dynamical estimators embedded with the learned knowledge are then designed by resorting to the sampled-data observer. It is proved that generated estimator residuals can reflect the difference between the system dynamics of the training and test univariate time series. Finally, a recognition decision-making scheme is proposed based on the residual norms of the dynamical estimators. Through rigorous analysis, recognition conditions are given to guarantee the accurate recognition of the dynamical pattern of the test univariate time series. The significance of this paper lies in that the difficult problems of dynamical modeling and rapid recognition for univariate time series are solved by incorporating the sampled-data observer design and the deterministic learning theory. The effectiveness of the proposed approach is confirmed by a numerical example and compressor stall warning experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004968",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Dynamical system (definition)",
      "Dynamical systems theory",
      "Estimator",
      "Linear dynamical system",
      "Machine learning",
      "Mathematics",
      "Multivariate statistics",
      "Observer (physics)",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Residual",
      "Series (stratigraphy)",
      "Statistics",
      "Time series",
      "Univariate"
    ],
    "authors": [
      {
        "surname": "Hu",
        "given_name": "Jingtao"
      },
      {
        "surname": "Wu",
        "given_name": "Weiming"
      },
      {
        "surname": "Zhang",
        "given_name": "Fukai"
      },
      {
        "surname": "Chen",
        "given_name": "Tianrui"
      },
      {
        "surname": "Wang",
        "given_name": "Cong"
      }
    ]
  },
  {
    "title": "Accuracy of a Deep Learning Method for Heart Sound Analysis is Unrealistic",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.006",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004981",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "ENCODE",
      "Embedding",
      "Gene",
      "Graph",
      "Graph embedding",
      "Machine learning",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Gharehbaghi",
        "given_name": "Arash"
      },
      {
        "surname": "Partovi",
        "given_name": "Elaheh"
      }
    ]
  },
  {
    "title": "Efficient Perturbation Inference and Expandable Network for continual learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.030",
    "abstract": "Although humans are capable of learning new tasks without forgetting previous ones, most neural networks fail to do so because learning new tasks could override the knowledge acquired from previous data. In this work, we alleviate this issue by proposing a novel Efficient Perturbation Inference and Expandable Network (EPIE-Net), which dynamically expands lightweight task-specific decoders for new classes and utilizes a mixed-label uncertainty strategy to improve the robustness. Moreover, we calculate the average probability of perturbed samples at inference, which can generally improve the performance of the model. Experimental results show that our method consistently outperforms other methods with fewer parameters in class incremental learning benchmarks. For example, on the CIFAR-100 10 steps setup, our method achieves an average accuracy of 76.33% and the last accuracy of 65.93% within only 3.46M average parameters.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004269",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Forgetting",
      "Gene",
      "Inference",
      "Linguistics",
      "Machine learning",
      "Philosophy",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Du",
        "given_name": "Fei"
      },
      {
        "surname": "Yang",
        "given_name": "Yun"
      },
      {
        "surname": "Zhao",
        "given_name": "Ziyuan"
      },
      {
        "surname": "Zeng",
        "given_name": "Zeng"
      }
    ]
  },
  {
    "title": "An explainable autoencoder with multi-paradigm fMRI fusion for identifying differences in dynamic functional connectivity during brain development",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.007",
    "abstract": "Multi-paradigm deep learning models show great potential for dynamic functional connectivity (dFC) analysis by integrating complementary information. However, many of them cannot use information from different paradigms effectively and have poor explainability, that is, the ability to identify significant features that contribute to decision making. In this paper, we propose a multi-paradigm fusion-based explainable deep sparse autoencoder (MF-EDSAE) to address these issues. Considering explainability, the MF-EDSAE is constructed based on a deep sparse autoencoder (DSAE). For integrating information effectively, the MF-EDASE contains the nonlinear fusion layer and multi-paradigm hypergraph regularization. We apply the model to the Philadelphia Neurodevelopmental Cohort and demonstrate it achieves better performance in detecting dynamic FC (dFC) that differ significantly during brain development than the single-paradigm DSAE. The experimental results show that children have more dispersive dFC patterns than adults. The function of the brain transits from undifferentiated systems to specialized networks during brain development. Meanwhile, adults have stronger connectivities between task-related functional networks for a given task than children. As the brain develops, the patterns of the global dFC change more quickly when stimulated by a task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004993",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Computer science",
      "Deep learning",
      "Economics",
      "Functional connectivity",
      "Machine learning",
      "Management",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Regularization (linguistics)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Faming"
      },
      {
        "surname": "Qiao",
        "given_name": "Chen"
      },
      {
        "surname": "Zhou",
        "given_name": "Huiyu"
      },
      {
        "surname": "Calhoun",
        "given_name": "Vince D."
      },
      {
        "surname": "Stephen",
        "given_name": "Julia M."
      },
      {
        "surname": "Wilson",
        "given_name": "Tony W."
      },
      {
        "surname": "Wang",
        "given_name": "Yuping"
      }
    ]
  },
  {
    "title": "Proposed algorithm for smart grid DDoS detection based on deep learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.011",
    "abstract": "The Smart Grid’s objective is to increase the electric grid’s dependability, security, and efficiency through extensive digital information and control technology deployment. As a result, it is necessary to apply real-time analysis and state estimation-based techniques to ensure efficient controls are implemented correctly. These systems are vulnerable to cyber-attacks, posing significant risks to the Smart Grid’s overall availability due to their reliance on communication technology. Therefore, effective intrusion detection algorithms are required to mitigate such attacks. In dealing with these uncertainties, we propose a hybrid deep learning algorithm that focuses on Distributed Denial of Service attacks on the communication infrastructure of the Smart Grid. The proposed algorithm is hybridized by the Convolutional Neural Network and the Gated Recurrent Unit algorithms. Simulations are done using a benchmark cyber security dataset of the Canadian Institute of Cybersecurity Intrusion Detection System. According to the simulation results, the proposed algorithm outperforms the current intrusion detection algorithms, with an overall accuracy rate of 99.7%.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005032",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Denial-of-service attack",
      "Machine learning",
      "Pattern recognition (psychology)",
      "The Internet",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Diaba",
        "given_name": "Sayawu Yakubu"
      },
      {
        "surname": "Elmusrati",
        "given_name": "Mohammed"
      }
    ]
  },
  {
    "title": "Representation learning for continuous action spaces is beneficial for efficient policy learning",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.009",
    "abstract": "Deep reinforcement learning (DRL) breaks through the bottlenecks of traditional reinforcement learning (RL) with the help of the perception capability of deep learning and has been widely applied in real-world problems. While model-free RL, as a class of efficient DRL methods, performs the learning of state representations simultaneously with policy learning in an end-to-end manner when facing large-scale continuous state and action spaces. However, training such a large policy model requires a large number of trajectory samples and training time. On the other hand, the learned policy often fails to generalize to large-scale action spaces, especially for the continuous action spaces. To address this issue, in this paper we propose an efficient policy learning method in latent state and action spaces. More specifically, we extend the idea of state representations to action representations for better policy generalization capability. Meanwhile, we divide the whole learning task into learning with the large-scale representation models in an unsupervised manner and learning with the small-scale policy model in the RL manner. The small policy model facilitates policy learning, while not sacrificing generalization and expressiveness via the large representation model. Finally, the effectiveness of the proposed method is demonstrated by MountainCar, CarRacing and Cheetah experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005019",
    "keywords": [
      "Action (physics)",
      "Action learning",
      "Active learning (machine learning)",
      "Artificial intelligence",
      "Computer science",
      "Cooperative learning",
      "Feature learning",
      "Generalization",
      "Law",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Mathematics education",
      "Physics",
      "Policy learning",
      "Political science",
      "Politics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Representation (politics)",
      "Teaching method"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Tingting"
      },
      {
        "surname": "Wang",
        "given_name": "Ying"
      },
      {
        "surname": "Sun",
        "given_name": "Wei"
      },
      {
        "surname": "Chen",
        "given_name": "Yarui"
      },
      {
        "surname": "Niu",
        "given_name": "Gang"
      },
      {
        "surname": "Sugiyama",
        "given_name": "Masashi"
      }
    ]
  },
  {
    "title": "Variable three-term conjugate gradient method for training artificial neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.001",
    "abstract": "Artificial neural networks (ANNs) have been widely adopted as general computational tools both in computer science as well as many other engineering fields. Stochastic gradient descent (SGD) and adaptive methods such as Adam are popular as robust optimization algorithms used to train the ANNs. However, the effectiveness of these algorithms is limited because they calculate a search direction based on a first-order gradient. Although higher-order gradient methods such as Newton’s method have been proposed, they require the Hessian matrix to be semi-definite, and its inversion incurs a high computational cost. Therefore, in this paper, we propose a variable three-term conjugate gradient (VTTCG) method that approximates the Hessian matrix to enhance search direction and uses a variable step size to achieve improved convergence stability. To evaluate the performance of the VTTCG method, we train different ANNs on benchmark image classification and generation datasets. We also conduct a similar experiment in which a grasp generation and selection convolutional neural network (GGS-CNN) is trained to perform intelligent robotic grasping. After considering a simulated environment, we also test the GGS-CNN with a physical grasping robot. The experimental results show that the performance of the VTTCG method is superior to that of four conventional methods, including SGD, Adam, AMSGrad, and AdaBelief.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004932",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Conjugate gradient method",
      "Convolutional neural network",
      "Geodesy",
      "Geography",
      "Gradient descent",
      "Gradient method",
      "Hessian matrix",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear conjugate gradient method",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Stochastic gradient descent",
      "Term (time)",
      "Variable (mathematics)"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Hansu"
      },
      {
        "surname": "Wang",
        "given_name": "Chuxuan"
      },
      {
        "surname": "Byun",
        "given_name": "Hyoseok"
      },
      {
        "surname": "Hu",
        "given_name": "Weifei"
      },
      {
        "surname": "Kim",
        "given_name": "Sanghyuk"
      },
      {
        "surname": "Jiao",
        "given_name": "Qing"
      },
      {
        "surname": "Lee",
        "given_name": "Tae Hee"
      }
    ]
  },
  {
    "title": "Graph Spring Network and Informative Anchor Selection for session-based recommendation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.003",
    "abstract": "Session-based recommendation (SBR) aims at predicting the next item for an ongoing anonymous session. The major challenge of SBR is how to capture richer relations in between items and learn ID-based item embeddings to capture such relations. Recent studies propose to first construct an item graph from sessions and employ a Graph Neural Network (GNN) to encode item embedding from the graph. Although such graph-based approaches have achieved performance improvements, their GNNs are not suitable for ID-based embedding learning for the SBR task. In this paper, we argue that the objective of such ID-based embedding learning is to capture a kind of neighborhood affinity in that the embedding of a node is similar to that of its neighbors’ in the embedding space. We propose a new graph neural network, called Graph Spring Network (GSN), for learning ID-based item embedding on an item graph to optimize neighborhood affinity in the embedding space. Furthermore, we argue that even stacking multiple GNN layers may not be enough to encode potential relations for two item nodes far-apart in a graph. In this paper, we propose a strategy that first selects some informative item anchors and then encode items’ potential relations to such anchors. In summary, we propose a GSN-IAS model (Graph Spring Network and Informative Anchor Selection) for the SBR task. We first construct an item graph to describe items’ co-occurrences in all sessions. We design the GSN for ID-based item embedding learning and propose an item entropy measure to select informative anchors. We then design an unsupervised learning mechanism to encode items’ relations to anchors. We next employ a shared gated recurrent unit (GRU) network to learn two session representations and make two next item predictions. Finally, we design an adaptive decision fusion strategy to fuse two predictions to make the final recommendation. Extensive experiments on three public datasets demonstrate the superiority of our GSN-IAS model over the state-of-the-art models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004956",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "ENCODE",
      "Embedding",
      "Gene",
      "Graph",
      "Graph embedding",
      "Machine learning",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Zizhuo"
      },
      {
        "surname": "Wang",
        "given_name": "Bang"
      }
    ]
  },
  {
    "title": "Path reliability-based graph attention networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.021",
    "abstract": "Self-attention mechanism has been successfully introduced in Graph Neural Networks (GNNs) for graph representation learning and achieved state-of-the-art performances in tasks such as node classification and node attacks. In most existing attention-based GNNs, attention score is only computed between two directly connected nodes with their representation at a single layer. However, this attention score computation method cannot account for its multi-hop neighbors, which supply graph structure information and have influence on many tasks such as link prediction, knowledge graph completion, and adversarial attack as well. In order to address this problem, in this paper, we propose Path Reliability-based Graph Attention Networks (PRGATs), a novel method to incorporate multi-hop neighboring context into attention score computation, enabling to capture longer-range dependencies and large-scale structural information within a single layer. Moreover, path reliability-based attention layer, a core layer of PRGATs, uses a resource-constrain allocation algorithm to compute the reliable path and its attention scores from neighboring nodes to non-neighboring nodes, increasing the receptive field for every message-passing layer. Experimental results on real-world datasets show that, as compared with baselines, our model outperforms existing methods up to 3% on standard node classification and 12% on graph universal adversarial attack.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004622",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Attention network",
      "Computation",
      "Computer science",
      "Graph",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Yayang"
      },
      {
        "surname": "Liang",
        "given_name": "Shuqing"
      },
      {
        "surname": "Jiang",
        "given_name": "Yuncheng"
      }
    ]
  },
  {
    "title": "Non-fragile output-feedback synchronization for delayed discrete-time complex-valued neural networks with randomly occurring uncertainties",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.002",
    "abstract": "This paper is step forward to establish an exponential synchronization criterion for discrete-time complex-valued neural networks (CVNNs) having time-varying delays subject to randomly occurring uncertain weighting parameters, in order to overcome the fluctuation when the output-feedback controller imposes on its dynamics. To achieve this, Jensen’s weighted summation inequalities (WSIs) and an extended reciprocal convex matrix inequality (ERCMI) are extended into the domain of complex field. By introducing some augmented vectors, a Lyapunov–Krasovskii functional (LKF) is constructed to attain an improved delay-dependent linear matrix inequalities (LMIs) constraint for the exponential synchronization phenomenon of the desired master–slave neuronal system model. For instance, the upper bound of the quadratic summation terms occurred in the finite difference of the LKF have been obtained from its linearization that has been made by the developed complex-valued WSIs and complex-valued ERCMI. The proposed results are less restrictive with the minimum number of decision variables than those obtained using existing inequalities. The designed output-feedback control gain has been determined by solving a set of complex-valued LMIs and it has been enforced with a prescribed exponential decay rate. Finally, in sight of MATLAB software, the established results have been examined via a numerical example supported by the simulation results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004944",
    "keywords": [
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Machine learning",
      "Mathematics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Soundararajan",
        "given_name": "G."
      },
      {
        "surname": "Nagamani",
        "given_name": "G."
      }
    ]
  },
  {
    "title": "Factorizing time-heterogeneous Markov transition for temporal recommendation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.032",
    "abstract": "Temporal recommendation which recommends items to users with consideration of time information has been of wide interest in recent years. But huge event space, highly sparse user activities and time-heterogeneous dependency of temporal behaviors make it really challenging to learn the temporal patterns for high-quality recommendation. In this paper, aiming to handle these challenges, especially the time-heterogeneous characteristic of user’s temporal behaviors, we proposed the Neural-based Time-heterogenous Markov Transition (NeuralTMT) model. Firstly, users’ temporal behaviors are mathematically simplified as the third-order Markov transition tensors. And then a linear co-factorization model which learns the time-evolving user/item factors from these tensors is proposed. Furthermore, the model is extended to the neural-based learning framework (NeuralTMT), which is more flexible and able to capture time-heterogeneous temporal patterns via nonlinear neural network mappings and attention techniques. Extensive experiments on four datasets demonstrate that NeuralTMT performs significantly better than the state-of-the-art baselines. And the proposed method is fundamentally inspired by factorization techniques, which may also provide some interesting ideas on the connection of tensor factorization and neural-based sequential recommendation methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004737",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Dependency (UML)",
      "Eigenvalues and eigenvectors",
      "Event (particle physics)",
      "Factorization",
      "Machine learning",
      "Markov chain",
      "Markov model",
      "Markov process",
      "Mathematics",
      "Matrix decomposition",
      "Physics",
      "Quantum mechanics",
      "Recommender system",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Wen",
        "given_name": "Wen"
      },
      {
        "surname": "Wang",
        "given_name": "Wencui"
      },
      {
        "surname": "Hao",
        "given_name": "Zhifeng"
      },
      {
        "surname": "Cai",
        "given_name": "Ruichu"
      }
    ]
  },
  {
    "title": "Early stopping by correlating online indicators in neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.035",
    "abstract": "In order to minimize the generalization error in neural networks, a novel technique to identify overfitting phenomena when training the learner is formally introduced. This enables support of a reliable and trustworthy early stopping condition, thus improving the predictive power of that type of modeling. Our proposal exploits the correlation over time in a collection of online indicators, namely characteristic functions for indicating if a set of hypotheses are met, associated with a range of independent stopping conditions built from a canary judgment to evaluate the presence of overfitting. That way, we provide a formal basis for decision making in terms of interrupting the learning process. As opposed to previous approaches focused on a single criterion, we take advantage of subsidiarities between independent assessments, thus seeking both a wider operating range and greater diagnostic reliability. With a view to illustrating the effectiveness of the halting condition described, we choose to work in the sphere of natural language processing, an operational continuum increasingly based on machine learning. As a case study, we focus on parser generation, one of the most demanding and complex tasks in the domain. The selection of cross-validation as a canary function enables an actual comparison with the most representative early stopping conditions based on overfitting identification, pointing to a promising start toward an optimal bias and variance control.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004920",
    "keywords": [
      "Accounting",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Botany",
      "Business",
      "Composite material",
      "Computer science",
      "Computer security",
      "Decision boundary",
      "Early stopping",
      "Exploit",
      "Generalization",
      "Identification (biology)",
      "Machine learning",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Overfitting",
      "Physics",
      "Power (physics)",
      "Process (computing)",
      "Programming language",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Reliability (semiconductor)",
      "Set (abstract data type)",
      "Support vector machine",
      "Variance (accounting)"
    ],
    "authors": [
      {
        "surname": "Vilares Ferro",
        "given_name": "Manuel"
      },
      {
        "surname": "Doval Mosquera",
        "given_name": "Yerai"
      },
      {
        "surname": "Ribadas Pena",
        "given_name": "Francisco J."
      },
      {
        "surname": "Darriba Bilbao",
        "given_name": "Víctor M."
      }
    ]
  },
  {
    "title": "S 3 NN: Time step reduction of spiking surrogate gradients for training energy efficient single-step spiking neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.12.008",
    "abstract": "As the scales of neural networks increase, techniques that enable them to run with low computational cost and energy efficiency are required. From such demands, various efficient neural network paradigms, such as spiking neural networks (SNNs) or binary neural networks (BNNs), have been proposed. However, they have sticky drawbacks, such as degraded inference accuracy and latency. To solve these problems, we propose a single-step spiking neural network (S 3 NN), an energy-efficient neural network with low computational cost and high precision. The proposed S 3 NN processes the information between hidden layers by spikes as SNNs. Nevertheless, it has no temporal dimension so that there is no latency within training and inference phases as BNNs. Thus, the proposed S 3 NN has a lower computational cost than SNNs that require time-series processing. However, S 3 NN cannot adopt naïve backpropagation algorithms due to the non-differentiability nature of spikes. We deduce a suitable neuron model by reducing the surrogate gradient for multi-time step SNNs to a single-time step. We experimentally demonstrated that the obtained surrogate gradient allows S 3 NN to be trained appropriately. We also showed that the proposed S 3 NN could achieve comparable accuracy to full-precision networks while being highly energy-efficient.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022005007",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Computer science",
      "Inference",
      "Latency (audio)",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Spiking neural network",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Suetake",
        "given_name": "Kazuma"
      },
      {
        "surname": "Ikegawa",
        "given_name": "Shin-ichi"
      },
      {
        "surname": "Saiin",
        "given_name": "Ryuji"
      },
      {
        "surname": "Sawada",
        "given_name": "Yoshihide"
      }
    ]
  },
  {
    "title": "Synchronization of hybrid switching diffusions delayed networks via stochastic event-triggered control",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.034",
    "abstract": "In this paper, the synchronization problem of stochastic complex networks with time delays and hybrid switching diffusions (SCNTH) is concerned based on event-triggered control. Therein, a new class of event-triggered function is proposed for the control design. Particularly, different from the existing work, the triggered instant generated by event-triggered control in this paper is a stochastic sequence instead of a number sequence to be more realistic for stochastic systems, which is a breakthrough. Furthermore, some sufficient conditions are derived to guarantee asymptotical synchronization in mean square, exponential synchronization in mean square and almost surely exponential synchronization of SCNTH based on sampled-data control, event-driven control theory and stability analysis. Meanwhile, the Zeno phenomenon can be avoided. Then, the synchronization of single-link robot arms is investigated in detail as a practical application of the obtained results. Ultimately, a numerical example is given for demonstration.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004919",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Event (particle physics)",
      "Exponential stability",
      "Genetics",
      "Geometry",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Sequence (biology)",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Zeno's paradoxes"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Hui"
      },
      {
        "surname": "Li",
        "given_name": "Shufan"
      },
      {
        "surname": "Zhang",
        "given_name": "Chunmei"
      }
    ]
  },
  {
    "title": "Representation based regression for object distance estimation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.011",
    "abstract": "In this study, we propose a novel approach to predict the distances of the detected objects in an observed scene. The proposed approach modifies the recently proposed Convolutional Support Estimator Networks (CSENs). CSENs are designed to compute a direct mapping for the Support Estimation (SE) task in a representation-based classification problem. We further propose and demonstrate that representation-based methods (sparse or collaborative representation) can be used in well-designed regression problems especially over scarce data. To the best of our knowledge, this is the first representation-based method proposed for performing a regression task by utilizing the modified CSENs; and hence, we name this novel approach as Representation-based Regression (RbR). The initial version of CSENs has a proxy mapping stage (i.e., a coarse estimation for the support set) that is required for the input. In this study, we improve the CSEN model by proposing Compressive Learning CSEN (CL-CSEN) that has the ability to jointly optimize the so-called proxy mapping stage along with convolutional layers. The experimental evaluations using the KITTI 3D Object Detection distance estimation dataset show that the proposed method can achieve a significantly improved distance estimation performance over all competing methods. Finally, the software implementations of the methods are publicly shared at https://github.com/meteahishali/CSENDistance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200452X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Economics",
      "Estimator",
      "Law",
      "Machine learning",
      "Management",
      "Mathematics",
      "Multi-task learning",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Programming language",
      "Regression",
      "Representation (politics)",
      "Set (abstract data type)",
      "Sparse approximation",
      "Statistics",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Ahishali",
        "given_name": "Mete"
      },
      {
        "surname": "Yamac",
        "given_name": "Mehmet"
      },
      {
        "surname": "Kiranyaz",
        "given_name": "Serkan"
      },
      {
        "surname": "Gabbouj",
        "given_name": "Moncef"
      }
    ]
  },
  {
    "title": "Guest editorial: Special issue on advances in deep learning based speech processing",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.033",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004750",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Event (particle physics)",
      "Exponential function",
      "Exponential stability",
      "Genetics",
      "Geometry",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Sequence (biology)",
      "Stability (learning theory)",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Zeno's paradoxes"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Xiao-Lei"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      },
      {
        "surname": "Fosler-Lussier",
        "given_name": "Eric"
      },
      {
        "surname": "Vincent",
        "given_name": "Emmanuel"
      }
    ]
  },
  {
    "title": "Discriminative and Geometry-Preserving Adaptive Graph Embedding for dimensionality reduction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.024",
    "abstract": "Learning graph embeddings for high-dimensional data is an important technology for dimensionality reduction. The learning process is expected to preserve the discriminative and geometric information of high-dimensional data in a new low-dimensional subspace via either manual or automatic graph construction. Although both manual and automatic graph constructions can capture the geometry and discrimination of data to a certain degree, they working alone cannot fully explore the underlying data structure. To learn and preserve more discriminative and geometric information of the high-dimensional data in the low-dimensional subspace as much as possible, we develop a novel Discriminative and Geometry-Preserving Adaptive Graph Embedding (DGPAGE). It systematically integrates manual and adaptive graph constructions in one unified graph embedding framework, which is able to effectively inject the essential information of data involved in predefined graphs into the learning of an adaptive graph, in order to achieve both adaptability and specificity of data. Learning the adaptive graph jointly with the optimized projections, DGPAGE can generate an embedded subspace that has better pattern discrimination for image classification. Results derived from extensive experiments on image data sets have shown that DGPAGE outperforms the state-of-the-art graph-based dimensionality reduction methods. The ablation studies show that it is beneficial to have an integrated framework, like DGPAGE, that brings together the advantages of manual/adaptive graph construction.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004208",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Dimensionality reduction",
      "Discriminative model",
      "Embedding",
      "Graph",
      "Graph embedding",
      "Pattern recognition (psychology)",
      "Subspace topology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Gou",
        "given_name": "Jianping"
      },
      {
        "surname": "Yuan",
        "given_name": "Xia"
      },
      {
        "surname": "Xue",
        "given_name": "Ya"
      },
      {
        "surname": "Du",
        "given_name": "Lan"
      },
      {
        "surname": "Yu",
        "given_name": "Jiali"
      },
      {
        "surname": "Xia",
        "given_name": "Shuyin"
      },
      {
        "surname": "Zhang",
        "given_name": "Yi"
      }
    ]
  },
  {
    "title": "An architecture entropy regularizer for differentiable neural architecture search",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.015",
    "abstract": "Differentiable architecture search (DARTS) is one of the prevailing paradigms of neural architecture search (NAS) due to allowing efficient gradient-based optimization during the search phase. However, its poor stability and generalizability are intolerable. We argue that the crux is the locally optimal architecture parameter caused by a dilemma, which is that the solutions to the Matthew effect and discretization discrepancy are inconsistent. To escape from the dilemma, we propose an architecture entropy to measure the discrepancy of the architecture parameters of different candidate operations and use it as a regularizer to control the learning of architecture parameters. Extensive experiments show that an architecture entropy regularizer with a negative or positive coefficient can effectively solve one side of the contradiction respectively, and the regularizer with a variable coefficient can relieve DARTS from the dilemma. Experimental results demonstrate that our architecture entropy regularizer can significantly improve different differentiable NAS algorithms on different datasets and different search spaces. Furthermore, we also achieve more accurate and more robust results on CIFAR-10 and ImageNet. The code is publicly available at https://github.com/kunjing96/DARTS-AER.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004567",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Computer science",
      "Differentiable function",
      "Discretization",
      "Entropy (arrow of time)",
      "Generalizability theory",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Statistics",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Jing",
        "given_name": "Kun"
      },
      {
        "surname": "Chen",
        "given_name": "Luoyu"
      },
      {
        "surname": "Xu",
        "given_name": "Jungang"
      }
    ]
  },
  {
    "title": "Finite-time consensus control for multi-agent systems with full-state constraints and actuator failures",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.028",
    "abstract": "Aiming at a class of uncertain nonlinear multi-agent systems (MASs) with full-state constraints and actuator failures, a finite-time consensus control method is developed. Full-state constraints and actuator failures are ubiquitous in practical engineering applications. Violation of constraints would drastically affect the performance of MASs, even arise security problems. It is challenging to guarantee the performance of the MASs when undergoing actuator failures. To tackle these problems, an adaptive consensus control method is established by applying the Backstepping technique and Barrier Lyapunov functions (BLFs) to ensure the performance of the MASs with full-state constraints no matter actuator failures occur. Simultaneously, for the uncertain nonlinear MASs, a finite-time neural network (NN) consensus control scheme is established to ensure system’s signals are synchronized in finite time. Moreover, an event-triggered control strategy is constructed to relieve the communication pressure of each agent. Finally, numerical and practical examples are employed to verify the effectiveness of the proposed control strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004245",
    "keywords": [
      "Actuator",
      "Adaptive control",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backstepping",
      "Computer science",
      "Consensus",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Lyapunov function",
      "Multi-agent system",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "State (computer science)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jianhui"
      },
      {
        "surname": "Yan",
        "given_name": "Yancheng"
      },
      {
        "surname": "Liu",
        "given_name": "Zhi"
      },
      {
        "surname": "Chen",
        "given_name": "C.L. Philip"
      },
      {
        "surname": "Zhang",
        "given_name": "Chunliang"
      },
      {
        "surname": "Chen",
        "given_name": "Kairui"
      }
    ]
  },
  {
    "title": "18 A Lagrangian framework for learning in graph neural networks",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00015-4",
    "abstract": "Neural network models are based on a distributed computational scheme in which signals are propagated among neurons through weighted connections. The network topology defines the overall computation, which is local to each neuron but follows a precise flow driven by the neural network architecture, in the forward and error backpropagation phases. This chapter proposes a completely local alternative view on the neural network computational scheme, devised as the satisfaction of architectural constraints solved in the Lagrangian framework. The proposed local propagation algorithm casts learning in neural networks as the search for saddle points in the adjoint space composed of weights, neurons’ outputs, and Lagrange multipliers. In particular, the case of graph neural networks is considered, for which the computationally expensive iterative learning procedure can be avoided by joint optimization of the node states and transition functions, in which the state computation on the input graph is expressed by a constraint satisfaction mechanism.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000154",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Combinatorics",
      "Computation",
      "Computer science",
      "Constraint satisfaction",
      "Constraint satisfaction problem",
      "Graph",
      "Lagrange multiplier",
      "Mathematical optimization",
      "Mathematics",
      "Probabilistic logic",
      "Recurrent neural network",
      "Stochastic neural network",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Maggini",
        "given_name": "Marco"
      },
      {
        "surname": "Tiezzi",
        "given_name": "Matteo"
      },
      {
        "surname": "Gori",
        "given_name": "Marco"
      }
    ]
  },
  {
    "title": "Finite-time consensus control for multi-agent systems with full-state constraints and actuator failures",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.028",
    "abstract": "Aiming at a class of uncertain nonlinear multi-agent systems (MASs) with full-state constraints and actuator failures, a finite-time consensus control method is developed. Full-state constraints and actuator failures are ubiquitous in practical engineering applications. Violation of constraints would drastically affect the performance of MASs, even arise security problems. It is challenging to guarantee the performance of the MASs when undergoing actuator failures. To tackle these problems, an adaptive consensus control method is established by applying the Backstepping technique and Barrier Lyapunov functions (BLFs) to ensure the performance of the MASs with full-state constraints no matter actuator failures occur. Simultaneously, for the uncertain nonlinear MASs, a finite-time neural network (NN) consensus control scheme is established to ensure system’s signals are synchronized in finite time. Moreover, an event-triggered control strategy is constructed to relieve the communication pressure of each agent. Finally, numerical and practical examples are employed to verify the effectiveness of the proposed control strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004245",
    "keywords": [
      "Actuator",
      "Adaptive control",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backstepping",
      "Computer science",
      "Consensus",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Lyapunov function",
      "Multi-agent system",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "State (computer science)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jianhui"
      },
      {
        "surname": "Yan",
        "given_name": "Yancheng"
      },
      {
        "surname": "Liu",
        "given_name": "Zhi"
      },
      {
        "surname": "Chen",
        "given_name": "C.L. Philip"
      },
      {
        "surname": "Zhang",
        "given_name": "Chunliang"
      },
      {
        "surname": "Chen",
        "given_name": "Kairui"
      }
    ]
  },
  {
    "title": "16 Multiview learning in biomedical applications",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00010-5",
    "abstract": "Motivation: In the era of big data, the richness and variety of available datasets have opened new horizons for investigators in the biomedical field. The ultimate challenge consists in building an integrated base of knowledge derived from heterogeneous sources. Multiview learning is the branch of machine learning concerned with the analysis of multimodal data, i.e., patterns represented by different sets of features extracted from multiple data sources. In recent years, multiview learning methodologies have become increasingly popular, and a high number of biomedical applications based on multiview data have been recorded in the literature. For example, in bioinformatics, analyses can be based on multiple experiments investigating different facets of the same phenomena, such as gene expression, microRNA expression, protein-protein interactions, genome-wide association, and so on, to capture information regarding different aspects of biological systems. In the same way, neuroscience data analysis can benefit from different imaging modalities that allow to study different features of the nervous system (e.g., structural vs functional organization). Compared to the limited perspective offered by single-view analyses, the integration of multiple views can provide a deeper understanding of the underlying principles governing complex systems. Results: In this work, we review the existing multiview methodologies to discuss their operation modes and principles, with the goal of increasing their further development in the biomedical field. We organized the described methods in three categories, according to the type of data, the statistical problem, and the type of integration. This discussion, which highlights the advantages and disadvantages of different schools of thought, is intended to be a reference for those who want to start working with the integration of biomedical data. We selected a number of representative examples in bioinformatics and neuroinformatics to show the potential of multiview learning applications for cutting-edge research problems. First, we explain how multiview clustering can be used to perform patient subtyping to identify groups of patients that share similar molecular characteristics and possibly similar reactions to treatment. Then, the drug-repositioning problem is introduced and a discussion of the multiview classification methods used in the literature is provided. We then describe an example of how both clustering and classification can be combined in a multiview setting for the automated diagnosis of neurodegenerative disorders and we explain how multiple noninvasive imaging modalities can be exploited together to obtain more accurate brain parcellations. We additionally introduce the emerging fields of single-cell multiomics data analysis and brain imaging genomics. Finally, we discuss how deep learning techniques, which are getting more and more recognition in various fields, can be applied to multimodal data to learn complex representations, and we present a few examples of application.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000105",
    "keywords": [
      "Artificial intelligence",
      "Big data",
      "Computer science",
      "Data mining",
      "Data science",
      "Data type",
      "Field (mathematics)",
      "Machine learning",
      "Mathematics",
      "Modalities",
      "Perspective (graphical)",
      "Programming language",
      "Pure mathematics",
      "Social science",
      "Sociology",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Serra",
        "given_name": "Angela"
      },
      {
        "surname": "Galdi",
        "given_name": "Paola"
      },
      {
        "surname": "Tagliaferri",
        "given_name": "Roberto"
      }
    ]
  },
  {
    "title": "BASeg: Boundary aware semantic segmentation for autonomous driving",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.034",
    "abstract": "Semantic segmentation is a critical component for street understanding task in autonomous driving field. Existing various methods either focus on constructing the object’s inner consistency by aggregating global or multi-scale context information, or simply combine semantic features with boundary features to refine object details. Despite impressive, most of them neglect the long-range dependences between the inner objects and boundaries. To this end, we present a Boundary Aware Network (BASeg) for semantic segmentation by exploiting boundary information as a significant cue to guide context aggregation. Specifically, a Boundary Refined Module (BRM) is proposed in the BASeg to refine coarse low-level boundary features from a Canny detector by high-level multi-scale semantic features from the backbone, and based on which, the Context Aggregation Module (CAM) is further proposed to capture long-range dependences between the boundary regions and the object inner pixels, achieving mutual gains and enhancing the intra-class consistency. Moreover, our method can be plugged into other CNN backbones for higher performance with a minor computation budget, and obtains 45.72%, 81.2%, and 77.3% of mIoU on the datasets ADE20K, Cityscapes, and CamVid, respectively. Compared with some state-of-the-art ResNet101-based segmentation methods, extensive experiments demonstrate the effectiveness of our method. Our code is available at https://github.com/Lature-Yang/BASeg.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004294",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Boundary (topology)",
      "Computer science",
      "Computer vision",
      "Consistency (knowledge bases)",
      "Context (archaeology)",
      "Focus (optics)",
      "Mathematical analysis",
      "Mathematics",
      "Object (grammar)",
      "Optics",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Physics",
      "Pixel",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Xiaoyang"
      },
      {
        "surname": "Zhao",
        "given_name": "Yuqian"
      },
      {
        "surname": "Zhang",
        "given_name": "Fan"
      },
      {
        "surname": "Luo",
        "given_name": "Biao"
      },
      {
        "surname": "Yu",
        "given_name": "Lingli"
      },
      {
        "surname": "Chen",
        "given_name": "Baifan"
      },
      {
        "surname": "Yang",
        "given_name": "Chunhua"
      }
    ]
  },
  {
    "title": "Tropical support vector machines: Evaluations and extension to function spaces",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.002",
    "abstract": "Support Vector Machines (SVMs) are one of the most popular supervised learning models to classify using a hyperplane in an Euclidean space. Similar to SVMs, tropical SVMs classify data points using a tropical hyperplane under the tropical metric with the max-plus algebra. In this paper, first we show generalization error bounds of tropical SVMs over the tropical projective torus. While the generalization error bounds attained via Vapnik–Chervonenkis (VC) dimensions in a distribution-free manner still depend on the dimension, we also show numerically and theoretically by extreme value statistics that the tropical SVMs for classifying data points from two Gaussian distributions as well as empirical data sets of different neuron types are fairly robust against the curse of dimensionality. Extreme value statistics also underlie the anomalous scaling behaviors of the tropical distance between random vectors with additional noise dimensions. Finally, we define tropical SVMs over a function space with the tropical metric.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003860",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Curse of dimensionality",
      "Extreme value theory",
      "Hyperplane",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Statistics",
      "Support vector machine",
      "Tropical geometry"
    ],
    "authors": [
      {
        "surname": "Yoshida",
        "given_name": "Ruriko"
      },
      {
        "surname": "Takamori",
        "given_name": "Misaki"
      },
      {
        "surname": "Matsumoto",
        "given_name": "Hideyuki"
      },
      {
        "surname": "Miura",
        "given_name": "Keiji"
      }
    ]
  },
  {
    "title": "Characterizing functional brain networks via Spatio-Temporal Attention 4D Convolutional Neural Networks (STA-4DCNNs)",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.004",
    "abstract": "Characterizing individualized spatio-temporal patterns of functional brain networks (FBNs) via functional magnetic resonance imaging (fMRI) provides a foundation for understanding complex brain function. Although previous studies have achieved promising performances based on either shallow or deep learning models, there is still much space to improve the accuracy of spatio-temporal pattern characterization of FBNs by optimally integrating the four-dimensional (4D) features of fMRI. In this study, we introduce a novel Spatio-Temporal Attention 4D Convolutional Neural Network (STA-4DCNN) model to characterize individualized spatio-temporal patterns of FBNs. Particularly, STA-4DCNN is composed of two subnetworks, in which the first Spatial Attention 4D CNN (SA-4DCNN) models the spatio-temporal features of 4D fMRI data and then characterizes the spatial pattern of FBNs, and the second Temporal Guided Attention Network (T-GANet) further characterizes the temporal pattern of FBNs under the guidance of the spatial pattern together with 4D fMRI data. We evaluate the proposed STA-4DCNN on seven different task fMRI and one resting state fMRI datasets from the publicly released Human Connectome Project. The experimental results demonstrate that STA-4DCNN has superior ability and generalizability in characterizing individualized spatio-temporal patterns of FBNs when compared to other state-of-the-art models. We further apply STA-4DCNN on another independent ABIDE I resting state fMRI dataset including both autism spectrum disorder (ASD) and typical developing (TD) subjects, and successfully identify abnormal spatio-temporal patterns of FBNs in ASD compared to TD. In general, STA-4DCNN provides a powerful tool for FBN characterization and for clinical applications on brain disease characterization at the individual level.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004440",
    "keywords": [
      "Artificial intelligence",
      "Brain activity and meditation",
      "Computer science",
      "Connectome",
      "Convolutional neural network",
      "Developmental psychology",
      "Electroencephalography",
      "Functional connectivity",
      "Functional magnetic resonance imaging",
      "Generalizability theory",
      "Human Connectome Project",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Resting state fMRI"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Xi"
      },
      {
        "surname": "Yan",
        "given_name": "Jiadong"
      },
      {
        "surname": "Zhao",
        "given_name": "Yu"
      },
      {
        "surname": "Jiang",
        "given_name": "Mingxin"
      },
      {
        "surname": "Chen",
        "given_name": "Yuzhong"
      },
      {
        "surname": "Zhou",
        "given_name": "Jingchao"
      },
      {
        "surname": "Xiao",
        "given_name": "Zhenxiang"
      },
      {
        "surname": "Wang",
        "given_name": "Zifan"
      },
      {
        "surname": "Zhang",
        "given_name": "Rong"
      },
      {
        "surname": "Becker",
        "given_name": "Benjamin"
      },
      {
        "surname": "Zhu",
        "given_name": "Dajiang"
      },
      {
        "surname": "Kendrick",
        "given_name": "Keith M."
      },
      {
        "surname": "Liu",
        "given_name": "Tianming"
      }
    ]
  },
  {
    "title": "Reinforcement learning for robust stabilization of nonlinear systems with asymmetric saturating actuators",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.012",
    "abstract": "We study the robust stabilization problem of a class of nonlinear systems with asymmetric saturating actuators and mismatched disturbances. Initially, we convert such a robust stabilization problem into a nonlinear-constrained optimal control problem by constructing a discounted cost function for the auxiliary system. Then, for the purpose of solving the nonlinear-constrained optimal control problem, we develop a simultaneous policy iteration (PI) in the reinforcement learning framework. The implementation of the simultaneous PI relies on an actor–critic architecture, which employs actor and critic neural networks (NNs) to separately approximate the control policy and the value function. To determine the actor and critic NNs’ weights, we use the approach of weighted residuals together with the typical Monte-Carlo integration technique. Finally, we perform simulations of two nonlinear plants to validate the established theoretical claims.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004531",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Evolutionary biology",
      "Function (biology)",
      "Mathematical optimization",
      "Mathematics",
      "Monte Carlo method",
      "Nonlinear system",
      "Optimal control",
      "Physics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Robust control",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Xiong"
      },
      {
        "surname": "Zhou",
        "given_name": "Yingjiang"
      },
      {
        "surname": "Gao",
        "given_name": "Zhongke"
      }
    ]
  },
  {
    "title": "Stacked attention hourglass network based robust facial landmark detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.021",
    "abstract": "Deep learning based facial landmark detection (FLD) has made rapid progress. However, the accuracy and robustness of FLD algorithms are degraded heavily when the face is subject to diverse expressions, posture deflection, partial occlusion and other uncertain circumstances. To learn more discriminative representations and reduce the negative effect caused by outliers, a stacked attention hourglass network (SAHN) is proposed for FLD, where new attention mechanism is introduced. Basically, in the design of SAHN, a spatial attention residual (SAR) unit is constructed such that relevant areas of facial landmarks are specially emphasized and essential features of different scales can be well extracted, and a channel attention branch (CAB) is introduced to better guide the next-level hourglass network for feature extraction. Due to the introduction of SAR and CAB, only two hourglass networks are stacked as the proposed SAHN with fewer parameters, which is different from traditional SHNs stacked by four hourglass networks. Furthermore, a variable robustness (VR) loss function is introduced for the training of SAHN. The robustness of the proposed model for FLD is guaranteed with the help of the VR loss by adaptively adjusting a continuous parameter. Extensive experimental results on three public datasets including 300W, WFLW and COFW confirm that our method is superior to some previous ones.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004178",
    "keywords": [
      "Algorithm",
      "Archaeology",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Discriminative model",
      "Feature extraction",
      "Gene",
      "History",
      "Hourglass",
      "Landmark",
      "Mechatronics",
      "Outlier",
      "Pattern recognition (psychology)",
      "Residual",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Ying"
      },
      {
        "surname": "Huang",
        "given_name": "He"
      }
    ]
  },
  {
    "title": "SSA-ICL: Multi-domain adaptive attention with intra-dataset continual learning for Facial expression recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.025",
    "abstract": "Facial expression recognition (FER) is a kind of affective computing that identifies the emotional state represented in facial photographs. Various methods have been developed for completing this critical task. In spite of this progress, three significant obstacles, the interaction between spatial action units, the inadequacy of semantic information about spectral expressions and the unbalanced data distribution, are not well addressed. In this work, we propose SSA-ICL, a novel approach for FER, and solve these three difficulties inside a coherent framework. To address the first two challenges, we develop a Spectral and Spatial Attention (SSA) module that integrates spectral semantics with spatial locations to improve the performance of the model. We provide an Intra-dataset Continual Learning (ICL) module to combat the issue of long-tail distribution in FER datasets. By subdividing a single long-tail dataset into multiple sub-datasets, ICL repeatedly trains well-balanced representations from each subset and finally develop a independent classifier. We performed extensive experiments on two publicly available datasets, AffectNet and RAFDB. In comparison to existing attention modules, our SSA achieves an accuracy improvement of 3 . 8 % ∼ 6 . 7 % , as evidenced by testing results. In the meanwhile, our proposed SSA-ICL can achieve superior or comparable performance to state-of-the-art FER methods (65.78% on AffectNet and 89.44% on RAFDB).",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200466X",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Economics",
      "Facial expression",
      "Facial expression recognition",
      "Facial recognition system",
      "Labeled data",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Hongxiang"
      },
      {
        "surname": "Wu",
        "given_name": "Min"
      },
      {
        "surname": "Chen",
        "given_name": "Zhenghua"
      },
      {
        "surname": "Li",
        "given_name": "Yuwen"
      },
      {
        "surname": "Wang",
        "given_name": "Xingyao"
      },
      {
        "surname": "An",
        "given_name": "Shan"
      },
      {
        "surname": "Li",
        "given_name": "Jianqing"
      },
      {
        "surname": "Liu",
        "given_name": "Chengyu"
      }
    ]
  },
  {
    "title": "16 Multiview learning in biomedical applications",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00010-5",
    "abstract": "Motivation: In the era of big data, the richness and variety of available datasets have opened new horizons for investigators in the biomedical field. The ultimate challenge consists in building an integrated base of knowledge derived from heterogeneous sources. Multiview learning is the branch of machine learning concerned with the analysis of multimodal data, i.e., patterns represented by different sets of features extracted from multiple data sources. In recent years, multiview learning methodologies have become increasingly popular, and a high number of biomedical applications based on multiview data have been recorded in the literature. For example, in bioinformatics, analyses can be based on multiple experiments investigating different facets of the same phenomena, such as gene expression, microRNA expression, protein-protein interactions, genome-wide association, and so on, to capture information regarding different aspects of biological systems. In the same way, neuroscience data analysis can benefit from different imaging modalities that allow to study different features of the nervous system (e.g., structural vs functional organization). Compared to the limited perspective offered by single-view analyses, the integration of multiple views can provide a deeper understanding of the underlying principles governing complex systems. Results: In this work, we review the existing multiview methodologies to discuss their operation modes and principles, with the goal of increasing their further development in the biomedical field. We organized the described methods in three categories, according to the type of data, the statistical problem, and the type of integration. This discussion, which highlights the advantages and disadvantages of different schools of thought, is intended to be a reference for those who want to start working with the integration of biomedical data. We selected a number of representative examples in bioinformatics and neuroinformatics to show the potential of multiview learning applications for cutting-edge research problems. First, we explain how multiview clustering can be used to perform patient subtyping to identify groups of patients that share similar molecular characteristics and possibly similar reactions to treatment. Then, the drug-repositioning problem is introduced and a discussion of the multiview classification methods used in the literature is provided. We then describe an example of how both clustering and classification can be combined in a multiview setting for the automated diagnosis of neurodegenerative disorders and we explain how multiple noninvasive imaging modalities can be exploited together to obtain more accurate brain parcellations. We additionally introduce the emerging fields of single-cell multiomics data analysis and brain imaging genomics. Finally, we discuss how deep learning techniques, which are getting more and more recognition in various fields, can be applied to multimodal data to learn complex representations, and we present a few examples of application.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000105",
    "keywords": [
      "Artificial intelligence",
      "Big data",
      "Computer science",
      "Data mining",
      "Data science",
      "Data type",
      "Field (mathematics)",
      "Machine learning",
      "Mathematics",
      "Modalities",
      "Perspective (graphical)",
      "Programming language",
      "Pure mathematics",
      "Social science",
      "Sociology",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Serra",
        "given_name": "Angela"
      },
      {
        "surname": "Galdi",
        "given_name": "Paola"
      },
      {
        "surname": "Tagliaferri",
        "given_name": "Roberto"
      }
    ]
  },
  {
    "title": "6 The new AI: Basic concepts, and urgent risks and opportunities in the internet of things",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00006-3",
    "abstract": "For many decades, mainstream artificial intelligence (AI) refused to believe that deep learning with neural networks and backpropagation offer true brain-like general intelligence, despite numerous successes on tough engineering problems and mathematical advances. The tide changed in 2009 due to a $2 million NSF grant to Ng and LeCun which I signed off on, despite fierce objections which in today's US government environment would have prevented the action. Empirical success on well-known challenge problems led to follow-ons by DARPA, then by Google, and then a flood of interest by competitors trying to keep up. There are huge investments pursuing new applications of methods known and proven before 1990, but also a huge reservoir of more powerful methods proven out in engineering which have yet to be exploited in computer science, including mathematical principles which (along with related physics) begin to give us a real functional understanding of how the human brain and mind achieve their intelligence. The “Terminator” risk with AI is very serious, but as the Internet of Things (IoT) takes over the world, the risks of artificial stupidity (AS) are just as serious. There is an urgent need for us to develop new interfaces and integrated platforms, using more powerful AI in a human-friendly way along with more advanced unbreakable operating systems, quantum technology, and systems to fully support the deepest human potential. If we do not move quickly and effectively enough to develop more benign possibilities, the survival of humanity is at stake (see www.werbos.com/IT_big_picture.pdf).",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000063",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Data science",
      "Engineering",
      "Government (linguistics)",
      "Humanity",
      "Law",
      "Linguistics",
      "Mainstream",
      "Philosophy",
      "Political science",
      "Stupidity"
    ],
    "authors": [
      {
        "surname": "Werbos",
        "given_name": "Paul J."
      }
    ]
  },
  {
    "title": "Neural speech enhancement with unsupervised pre-training and mixture training",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.013",
    "abstract": "Supervised neural speech enhancement methods always require a large scale of paired noisy and clean speech data. Since collecting adequate paired data from real-world applications is infeasible, simulated data is always adopted in supervised learning methods. However, the mismatch between the simulated data and in-the-wild data always causes performance inconsistency when the system is deployed in real-world applications. Unsupervised speech enhancement methods are studied to address the mismatch problem by directly using the in-the-wild noisy data without access to the corresponding clean speech. Therefore, the simulated paired data is not necessary. However, the performance of the unsupervised speech enhancement method is not on par with the supervised learning method. To address the aforementioned problems, this work proposes an unsupervised pre-training and mixture training algorithm by leveraging the advantages of supervised and unsupervised learning methods. Specifically, the proposed speech enhancement approach employs large volumes of unpaired noisy and clean speech to conduct unsupervised pre-training. The noisy data and a small amount of simulated paired data are then used for mixture training to optimize the pre-trained model. Experimental results show that the proposed method achieves better performances than other state-of-the-art supervised and unsupervised learning methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004543",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Labeled data",
      "Machine learning",
      "Noise reduction",
      "Pattern recognition (psychology)",
      "Semi-supervised learning",
      "Speech enhancement",
      "Speech recognition",
      "Supervised learning",
      "Training set",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Hao",
        "given_name": "Xiang"
      },
      {
        "surname": "Xu",
        "given_name": "Chenglin"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      }
    ]
  },
  {
    "title": "Inferring the location of neurons within an artificial network from their activity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.012",
    "abstract": "Inferring the connectivity of biological neural networks from neural activation data is an open problem. We propose that the analogous problem in artificial neural networks is more amenable to study and may illuminate the biological case. Here, we study the specific problem of assigning artificial neurons to locations in a network of known architecture, specifically the LeNet image classifier. We evaluate a supervised learning approach based on features derived from the eigenvectors of the activation correlation matrix. Experiments highlighted that for an image dataset to be effective for accurate localisation, it should fully activate the network and contain minimal confounding correlations. No single image dataset was found that resulted in perfect assignment, however perfect assignment was achieved using a concatenation of features from multiple image datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004063",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Combinatorics",
      "Computer science",
      "Concatenation (mathematics)",
      "Convolutional neural network",
      "Image (mathematics)",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Dyer",
        "given_name": "Alexander J."
      },
      {
        "surname": "Griffin",
        "given_name": "Lewis D."
      }
    ]
  },
  {
    "title": "15 Evolving GAN formulations for higher-quality image synthesis",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00014-2",
    "abstract": "Generative adversarial networks (GANs) have extended deep learning to complex generation and translation tasks across different data modalities. However, GANs are notoriously difficult to train: Mode collapse and other instabilities in the training process often degrade the quality of the generated results, such as images. This chapter presents a new technique called TaylorGAN for improving GANs by discovering customized loss functions for each of its two networks. The loss functions are parameterized as Taylor expansions and optimized through multiobjective evolution. On an image-to-image translation benchmark task, this approach qualitatively improves generated image quality and quantitatively improves two independent GAN performance metrics. It therefore forms a promising approach for applying GANs to more challenging tasks in the future.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000142",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biochemistry",
      "Chemistry",
      "Computer engineering",
      "Computer science",
      "Engineering",
      "Epistemology",
      "Gene",
      "Generative adversarial network",
      "Generative grammar",
      "Geodesy",
      "Geography",
      "Human–computer interaction",
      "Image (mathematics)",
      "Image quality",
      "Image synthesis",
      "Image translation",
      "Machine learning",
      "Messenger RNA",
      "Mode (computer interface)",
      "Operating system",
      "Parameterized complexity",
      "Philosophy",
      "Process (computing)",
      "Quality (philosophy)",
      "Systems engineering",
      "Task (project management)",
      "Translation (biology)"
    ],
    "authors": [
      {
        "surname": "Gonzalez",
        "given_name": "Santiago"
      },
      {
        "surname": "Kant",
        "given_name": "Mohak"
      },
      {
        "surname": "Miikkulainen",
        "given_name": "Risto"
      }
    ]
  },
  {
    "title": "DANet: Semi-supervised differentiated auxiliaries guided network for video action recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.009",
    "abstract": "Video Action Recognition (ViAR) aims to identify the category of the human action observed in a given video. With the advent of Deep Learning (DL) techniques, noticeable performance breakthroughs have been achieved in this study. However, the success of most existing DL-based ViAR methods heavily relies on the existence of a large amount of annotated data, i.e., videos with corresponding action categories. In practice, obtaining such a desired number of annotations is often difficult due to expensive labeling costs, which may lead to significant performance degradation for these methods. To address this issue, we propose an end-to-end semi-supervised Differentiated Auxiliary guided Network (DANet) to best use a few annotated videos. Except for the common supervised learning on a few annotated videos, the DANet also involves the knowledge of multiple pre-trained auxiliary networks to optimize the ViAR network in a self-supervised way on the unannotated data by removing the annotations. Considering the tight connection between video action recognition and classical static image-based visual tasks, the abundant knowledge from the pre-trained static image-based models can be used for training the ViAR model. Specifically, the DANet is a two-branch architecture, which includes a target branch of the ViAR network, and an auxiliary branch of multiple auxiliary networks (i.e., referring to diverse off-the-shelf models of relevant image tasks). Given a limited number of annotated videos, we train the target ViAR network end-to-end in a semi-supervised way, namely, with both the supervised cross-entropy loss on annotated videos, and the per-auxiliary weighted self-supervised contrastive losses on the same videos but without using annotations. Besides, we further explore different weighted guidance of the auxiliary networks to the ViAR network to better reflect different relationships between the image-based models and the ViAR model. Finally, we conduct extensive experiments on several popular action recognition benchmarks in comparison with existing state-of-the-art methods, and the experimental results demonstrate the superiority of DANet over most of the compared methods. In particular, the DANet obviously suppresses state-of-the-art ViAR methods even with very fewer annotated videos.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004506",
    "keywords": [
      "Action recognition",
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Computer science",
      "Computer security",
      "Cross entropy",
      "Machine learning",
      "Network architecture",
      "Pattern recognition (psychology)",
      "Supervised learning"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Guangyu"
      },
      {
        "surname": "Liu",
        "given_name": "Ziming"
      },
      {
        "surname": "Zhang",
        "given_name": "Guangjun"
      },
      {
        "surname": "Li",
        "given_name": "Jinyang"
      },
      {
        "surname": "Qin",
        "given_name": "A.K."
      }
    ]
  },
  {
    "title": "A class of doubly stochastic shift operators for random graph signals and their boundedness",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.035",
    "abstract": "A class of doubly stochastic graph shift operators (GSO) is proposed, which is shown to exhibit: (i) lower and upper L 2 -boundedness for locally stationary random graph signals, (ii) L 2 -isometry for i.i.d. random graph signals with the asymptotic increase in the incoming neighbourhood size of vertices, and (iii) preservation of the mean of any graph signal – all prerequisites for reliable graph neural networks. These properties are obtained through a statistical consistency analysis of the proposed graph shift operator, and by exploiting the dual role of the doubly stochastic GSO as a Markov (diffusion) matrix and as an unbiased expectation operator. For generality, we consider directed graphs which exhibit asymmetric connectivity matrices. The proposed approach is validated through an example on the estimation of a vector field.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004312",
    "keywords": [
      "Combinatorics",
      "Discrete mathematics",
      "Exponential random graph models",
      "Graph",
      "Mathematical analysis",
      "Mathematics",
      "Neighbourhood (mathematics)",
      "Random graph"
    ],
    "authors": [
      {
        "surname": "Scalzo",
        "given_name": "Bruno"
      },
      {
        "surname": "Stanković",
        "given_name": "Ljubiša"
      },
      {
        "surname": "Daković",
        "given_name": "Miloš"
      },
      {
        "surname": "Constantinides",
        "given_name": "Anthony G."
      },
      {
        "surname": "Mandic",
        "given_name": "Danilo P."
      }
    ]
  },
  {
    "title": "13 Computational intelligence in cyber-physical systems and the Internet of Things",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00001-4",
    "abstract": "The emergence of nontrivial embedded sensor units and cyber-physical systems and the Internet of Things has made possible the design and implementation of sophisticated applications where large amounts of real-time data are collected, possibly to constitute a big data picture as time passes. Within this framework, intelligence mechanisms based on machine learning, neural networks, and brain computing approaches play a key role to provide systems with advanced functionalities. Intelligent mechanisms are needed to guarantee appropriate performances within an evolving, time-variant environment, optimally harvest the available and manage the residual energy, reduce the energy consumption of the whole system, identify and mitigate the occurrence of faults, and provide shields against cyber-attacks. The chapter introduces the above aspects of intelligence, whose functionalities are needed to boost the next generation of cyber-physical and Internet of Things applications, a smart world generation whose footprint is already around us.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000014",
    "keywords": [
      "Artificial intelligence",
      "Big data",
      "Computer science",
      "Computer security",
      "Cyber-physical system",
      "Data mining",
      "Data science",
      "Internet of Things",
      "Key (lock)",
      "Operating system",
      "The Internet",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Alippi",
        "given_name": "Cesare"
      },
      {
        "surname": "Ozawa",
        "given_name": "Seiichi"
      }
    ]
  },
  {
    "title": "Neurodynamics-driven holistic approaches to semi-supervised feature selection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.029",
    "abstract": "Feature selection is a crucial part of machine learning and pattern recognition, which aims at selecting a subset of informative features from the original dataset. Because of label information, supervised feature selection performs better than unsupervised feature selection without label information. However, in the presence of a small number of labeled data and a large number of unlabeled data, it is challenging for supervised feature selection methods to select relevant features. In this paper, we propose three neurodynamics-driven holistic approaches to semi-supervised feature selection via semi-supervised feature redundancy minimization and semi-supervised feature relevancy maximization. We first define information-theoretic semi-supervised similarity coefficient matrix and semi-supervised feature relevancy vector based on multi-information, unsupervised symmetric uncertainty, and entropy to measure feature redundancy and relevancy. We then formulate a fractional programming problem and an iteratively weighted quadratic programming problem based on the semi-supervised similarity coefficient matrix and semi-supervised feature relevancy vector for semi-supervised feature selection. To solve the formulated problems, we delineate three neurodynamic optimization approaches based on two projection neural networks. We elaborate on the experimental results on six benchmark datasets to demonstrate the superior classification performance of the proposed neurodynamic approaches against six existing supervised and semi-supervised feature selection methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004257",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Entropy (arrow of time)",
      "Feature (linguistics)",
      "Feature selection",
      "Feature vector",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Semi-supervised learning",
      "Supervised learning"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yadi"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Reinforcement learning for robust stabilization of nonlinear systems with asymmetric saturating actuators",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.012",
    "abstract": "We study the robust stabilization problem of a class of nonlinear systems with asymmetric saturating actuators and mismatched disturbances. Initially, we convert such a robust stabilization problem into a nonlinear-constrained optimal control problem by constructing a discounted cost function for the auxiliary system. Then, for the purpose of solving the nonlinear-constrained optimal control problem, we develop a simultaneous policy iteration (PI) in the reinforcement learning framework. The implementation of the simultaneous PI relies on an actor–critic architecture, which employs actor and critic neural networks (NNs) to separately approximate the control policy and the value function. To determine the actor and critic NNs’ weights, we use the approach of weighted residuals together with the typical Monte-Carlo integration technique. Finally, we perform simulations of two nonlinear plants to validate the established theoretical claims.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004531",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Evolutionary biology",
      "Function (biology)",
      "Mathematical optimization",
      "Mathematics",
      "Monte Carlo method",
      "Nonlinear system",
      "Optimal control",
      "Physics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Robust control",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Xiong"
      },
      {
        "surname": "Zhou",
        "given_name": "Yingjiang"
      },
      {
        "surname": "Gao",
        "given_name": "Zhongke"
      }
    ]
  },
  {
    "title": "Stacked attention hourglass network based robust facial landmark detection",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.021",
    "abstract": "Deep learning based facial landmark detection (FLD) has made rapid progress. However, the accuracy and robustness of FLD algorithms are degraded heavily when the face is subject to diverse expressions, posture deflection, partial occlusion and other uncertain circumstances. To learn more discriminative representations and reduce the negative effect caused by outliers, a stacked attention hourglass network (SAHN) is proposed for FLD, where new attention mechanism is introduced. Basically, in the design of SAHN, a spatial attention residual (SAR) unit is constructed such that relevant areas of facial landmarks are specially emphasized and essential features of different scales can be well extracted, and a channel attention branch (CAB) is introduced to better guide the next-level hourglass network for feature extraction. Due to the introduction of SAR and CAB, only two hourglass networks are stacked as the proposed SAHN with fewer parameters, which is different from traditional SHNs stacked by four hourglass networks. Furthermore, a variable robustness (VR) loss function is introduced for the training of SAHN. The robustness of the proposed model for FLD is guaranteed with the help of the VR loss by adaptively adjusting a continuous parameter. Extensive experimental results on three public datasets including 300W, WFLW and COFW confirm that our method is superior to some previous ones.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004178",
    "keywords": [
      "Algorithm",
      "Archaeology",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Discriminative model",
      "Feature extraction",
      "Gene",
      "History",
      "Hourglass",
      "Landmark",
      "Mechatronics",
      "Outlier",
      "Pattern recognition (psychology)",
      "Residual",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Ying"
      },
      {
        "surname": "Huang",
        "given_name": "He"
      }
    ]
  },
  {
    "title": "SSA-ICL: Multi-domain adaptive attention with intra-dataset continual learning for Facial expression recognition",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.025",
    "abstract": "Facial expression recognition (FER) is a kind of affective computing that identifies the emotional state represented in facial photographs. Various methods have been developed for completing this critical task. In spite of this progress, three significant obstacles, the interaction between spatial action units, the inadequacy of semantic information about spectral expressions and the unbalanced data distribution, are not well addressed. In this work, we propose SSA-ICL, a novel approach for FER, and solve these three difficulties inside a coherent framework. To address the first two challenges, we develop a Spectral and Spatial Attention (SSA) module that integrates spectral semantics with spatial locations to improve the performance of the model. We provide an Intra-dataset Continual Learning (ICL) module to combat the issue of long-tail distribution in FER datasets. By subdividing a single long-tail dataset into multiple sub-datasets, ICL repeatedly trains well-balanced representations from each subset and finally develop a independent classifier. We performed extensive experiments on two publicly available datasets, AffectNet and RAFDB. In comparison to existing attention modules, our SSA achieves an accuracy improvement of 3 . 8 % ∼ 6 . 7 % , as evidenced by testing results. In the meanwhile, our proposed SSA-ICL can achieve superior or comparable performance to state-of-the-art FER methods (65.78% on AffectNet and 89.44% on RAFDB).",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200466X",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Economics",
      "Facial expression",
      "Facial expression recognition",
      "Facial recognition system",
      "Labeled data",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Hongxiang"
      },
      {
        "surname": "Wu",
        "given_name": "Min"
      },
      {
        "surname": "Chen",
        "given_name": "Zhenghua"
      },
      {
        "surname": "Li",
        "given_name": "Yuwen"
      },
      {
        "surname": "Wang",
        "given_name": "Xingyao"
      },
      {
        "surname": "An",
        "given_name": "Shan"
      },
      {
        "surname": "Li",
        "given_name": "Jianqing"
      },
      {
        "surname": "Liu",
        "given_name": "Chengyu"
      }
    ]
  },
  {
    "title": "Adversarial style discrepancy minimization for unsupervised domain adaptation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.015",
    "abstract": "Mainstream unsupervised domain adaptation (UDA) methods align feature distributions across different domains via adversarial learning. However, most of them focus on global distribution alignment, ignoring the fine-grained domain discrepancy. Besides, they generally require auxiliary models, bringing extra computation costs. To tackle these issues, this study proposes an UDA method that differentiates individual samples without the help of extra models. To this end, we introduce a novel discrepancy metric, termed style discrepancy, to distinguish different target samples. We also propose a paradigm for adversarial style discrepancy minimization (ASDM). Specifically, we fix the parameters of the feature extractor and maximize style discrepancy to update the classifier, which helps detect more hard samples. Adversely, we fix the parameters of the classifier and minimize the style discrepancy to update the feature extractor, pushing those hard samples near the support of the source distribution. Such adversary helps to progressively detect and adapt more hard samples, leading to fine-grained domain adaptation. Experiments on different UDA tasks validate the effectiveness of ASDM. Overall, without any extra models, ASDM reaches a 46.9% mIoU in the GTA5 to Cityscapes benchmark and an 84.7% accuracy in the VisDA-2017 benchmark, outperforming many existing adversarial-learning-based methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004099",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Domain adaptation",
      "Economics",
      "Feature (linguistics)",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Metric (unit)",
      "Minification",
      "Operations management",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language"
    ],
    "authors": [
      {
        "surname": "Luo",
        "given_name": "Xin"
      },
      {
        "surname": "Chen",
        "given_name": "Wei"
      },
      {
        "surname": "Liang",
        "given_name": "Zhengfa"
      },
      {
        "surname": "Li",
        "given_name": "Chen"
      },
      {
        "surname": "Tan",
        "given_name": "Yusong"
      }
    ]
  },
  {
    "title": "Image-based time series forecasting: A deep convolutional neural network approach",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.006",
    "abstract": "Inspired by the successful use of deep learning in computer vision, in this paper we introduce ForCNN, a novel deep learning method for univariate time series forecasting that mixes convolutional and dense layers in a single neural network. Instead of using conventional, numeric representations of time series data as input to the network, the proposed method considers visual representations of it in the form of images to directly produce point forecasts. Three variants of deep convolutional neural networks are examined to process the images, the first based on VGG-19, the second on ResNet-50, while the third on a self-designed architecture. The performance of the proposed approach is evaluated using time series of the M3 and M4 forecasting competitions. Our results suggest that image-based time series forecasting methods can outperform both standard and state-of-the-art forecasting models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003902",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Deep learning",
      "Image (mathematics)",
      "Machine learning",
      "Multivariate statistics",
      "Operating system",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Series (stratigraphy)",
      "Time series",
      "Univariate"
    ],
    "authors": [
      {
        "surname": "Semenoglou",
        "given_name": "Artemios-Anargyros"
      },
      {
        "surname": "Spiliotis",
        "given_name": "Evangelos"
      },
      {
        "surname": "Assimakopoulos",
        "given_name": "Vassilios"
      }
    ]
  },
  {
    "title": "Revisiting graph neural networks from hybrid regularized graph signal reconstruction",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.003",
    "abstract": "Graph neural networks (GNNs) have shown strong graph-structured data processing capabilities. However, most of them are generated based on the message-passing mechanism and lack of the systematic approach to guide their developments. Meanwhile, a unified point of view is hard to explain the design concepts of different GNN models. This paper presents a unified optimization framework from hybrid regularized graph signal reconstruction to establish the connection between the aggregation operations of different GNNs, showing that exploring the optimal solution is the process of GNN information aggregation. We use this new framework to mathematically explain several classic GNN models and summarizes their commonalities and differences from a macro perspective. The proposed framework not only provides convenience to understand GNNs, but also has a guiding significance for the proposal of new GNNs. Moreover, we design a model-driven fixed-point iteration method and a data-driven dictionary learning network according to the corresponding optimization objective and sparse representation. Then the new model, GNN based on model-driven and data-driven (GNN-MD), is established by using alternating iteration methods. We also theoretically analyze its convergence. Numerous node classification experiments on multiple datasets illustrate that the proposed GNN-MD has excellent performance and outperforms all baselines on high-feature-dimension datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004439",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convergence (economics)",
      "Data mining",
      "Economic growth",
      "Economics",
      "Graph",
      "Machine learning",
      "Macro",
      "Programming language",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Miao",
        "given_name": "Jiaxing"
      },
      {
        "surname": "Cao",
        "given_name": "Feilong"
      },
      {
        "surname": "Ye",
        "given_name": "Hailiang"
      },
      {
        "surname": "Li",
        "given_name": "Ming"
      },
      {
        "surname": "Yang",
        "given_name": "Bing"
      }
    ]
  },
  {
    "title": "Neural speech enhancement with unsupervised pre-training and mixture training",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.013",
    "abstract": "Supervised neural speech enhancement methods always require a large scale of paired noisy and clean speech data. Since collecting adequate paired data from real-world applications is infeasible, simulated data is always adopted in supervised learning methods. However, the mismatch between the simulated data and in-the-wild data always causes performance inconsistency when the system is deployed in real-world applications. Unsupervised speech enhancement methods are studied to address the mismatch problem by directly using the in-the-wild noisy data without access to the corresponding clean speech. Therefore, the simulated paired data is not necessary. However, the performance of the unsupervised speech enhancement method is not on par with the supervised learning method. To address the aforementioned problems, this work proposes an unsupervised pre-training and mixture training algorithm by leveraging the advantages of supervised and unsupervised learning methods. Specifically, the proposed speech enhancement approach employs large volumes of unpaired noisy and clean speech to conduct unsupervised pre-training. The noisy data and a small amount of simulated paired data are then used for mixture training to optimize the pre-trained model. Experimental results show that the proposed method achieves better performances than other state-of-the-art supervised and unsupervised learning methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004543",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Labeled data",
      "Machine learning",
      "Noise reduction",
      "Pattern recognition (psychology)",
      "Semi-supervised learning",
      "Speech enhancement",
      "Speech recognition",
      "Supervised learning",
      "Training set",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Hao",
        "given_name": "Xiang"
      },
      {
        "surname": "Xu",
        "given_name": "Chenglin"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      }
    ]
  },
  {
    "title": "Inferring the location of neurons within an artificial network from their activity",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.012",
    "abstract": "Inferring the connectivity of biological neural networks from neural activation data is an open problem. We propose that the analogous problem in artificial neural networks is more amenable to study and may illuminate the biological case. Here, we study the specific problem of assigning artificial neurons to locations in a network of known architecture, specifically the LeNet image classifier. We evaluate a supervised learning approach based on features derived from the eigenvectors of the activation correlation matrix. Experiments highlighted that for an image dataset to be effective for accurate localisation, it should fully activate the network and contain minimal confounding correlations. No single image dataset was found that resulted in perfect assignment, however perfect assignment was achieved using a concatenation of features from multiple image datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004063",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Combinatorics",
      "Computer science",
      "Concatenation (mathematics)",
      "Convolutional neural network",
      "Image (mathematics)",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Dyer",
        "given_name": "Alexander J."
      },
      {
        "surname": "Griffin",
        "given_name": "Lewis D."
      }
    ]
  },
  {
    "title": "11 From synapses to ephapsis: Embodied cognition and wearable personal assistants",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00005-1",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000051",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Cognition",
      "Cognitive science",
      "Computer science",
      "Embedded system",
      "Embodied cognition",
      "Human–computer interaction",
      "Neuroscience",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Wearable computer"
    ],
    "authors": [
      {
        "surname": "Ormandy",
        "given_name": "Roman"
      }
    ]
  },
  {
    "title": "Achieving small-batch accuracy with large-batch scalability via Hessian-aware learning rate adjustment",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.007",
    "abstract": "We consider synchronous data-parallel neural network training with a fixed large batch size. While the large batch size provides a high degree of parallelism, it degrades the generalization performance due to the low gradient noise scale. We propose a general learning rate adjustment framework and three critical heuristics that tackle the poor generalization issue. The key idea is to adjust the learning rate based on geometric information of loss landscape and encourage the model to converge into a flat minimum that is known to better generalize to the unknown data. Our empirical study demonstrates that the Hessian-aware learning rate schedule remarkably improves the generalization performance in large-batch training. For CIFAR-10 classification with ResNet20, our method achieves 92.31% accuracy using 16,384 batch size, which is close to 92.83% achieved using 128 batch size, at a negligible extra computational cost.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004488",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Computer security",
      "Database",
      "Generalization",
      "Geodesy",
      "Geography",
      "Hessian matrix",
      "Heuristics",
      "Key (lock)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Scalability",
      "Schedule"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Sunwoo"
      },
      {
        "surname": "He",
        "given_name": "Chaoyang"
      },
      {
        "surname": "Avestimehr",
        "given_name": "Salman"
      }
    ]
  },
  {
    "title": "Tropical support vector machines: Evaluations and extension to function spaces",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.002",
    "abstract": "Support Vector Machines (SVMs) are one of the most popular supervised learning models to classify using a hyperplane in an Euclidean space. Similar to SVMs, tropical SVMs classify data points using a tropical hyperplane under the tropical metric with the max-plus algebra. In this paper, first we show generalization error bounds of tropical SVMs over the tropical projective torus. While the generalization error bounds attained via Vapnik–Chervonenkis (VC) dimensions in a distribution-free manner still depend on the dimension, we also show numerically and theoretically by extreme value statistics that the tropical SVMs for classifying data points from two Gaussian distributions as well as empirical data sets of different neuron types are fairly robust against the curse of dimensionality. Extreme value statistics also underlie the anomalous scaling behaviors of the tropical distance between random vectors with additional noise dimensions. Finally, we define tropical SVMs over a function space with the tropical metric.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003860",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Curse of dimensionality",
      "Extreme value theory",
      "Hyperplane",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Statistics",
      "Support vector machine",
      "Tropical geometry"
    ],
    "authors": [
      {
        "surname": "Yoshida",
        "given_name": "Ruriko"
      },
      {
        "surname": "Takamori",
        "given_name": "Misaki"
      },
      {
        "surname": "Matsumoto",
        "given_name": "Hideyuki"
      },
      {
        "surname": "Miura",
        "given_name": "Keiji"
      }
    ]
  },
  {
    "title": "BASeg: Boundary aware semantic segmentation for autonomous driving",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.034",
    "abstract": "Semantic segmentation is a critical component for street understanding task in autonomous driving field. Existing various methods either focus on constructing the object’s inner consistency by aggregating global or multi-scale context information, or simply combine semantic features with boundary features to refine object details. Despite impressive, most of them neglect the long-range dependences between the inner objects and boundaries. To this end, we present a Boundary Aware Network (BASeg) for semantic segmentation by exploiting boundary information as a significant cue to guide context aggregation. Specifically, a Boundary Refined Module (BRM) is proposed in the BASeg to refine coarse low-level boundary features from a Canny detector by high-level multi-scale semantic features from the backbone, and based on which, the Context Aggregation Module (CAM) is further proposed to capture long-range dependences between the boundary regions and the object inner pixels, achieving mutual gains and enhancing the intra-class consistency. Moreover, our method can be plugged into other CNN backbones for higher performance with a minor computation budget, and obtains 45.72%, 81.2%, and 77.3% of mIoU on the datasets ADE20K, Cityscapes, and CamVid, respectively. Compared with some state-of-the-art ResNet101-based segmentation methods, extensive experiments demonstrate the effectiveness of our method. Our code is available at https://github.com/Lature-Yang/BASeg.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004294",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Boundary (topology)",
      "Computer science",
      "Computer vision",
      "Consistency (knowledge bases)",
      "Context (archaeology)",
      "Focus (optics)",
      "Mathematical analysis",
      "Mathematics",
      "Object (grammar)",
      "Optics",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Physics",
      "Pixel",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Xiaoyang"
      },
      {
        "surname": "Zhao",
        "given_name": "Yuqian"
      },
      {
        "surname": "Zhang",
        "given_name": "Fan"
      },
      {
        "surname": "Luo",
        "given_name": "Biao"
      },
      {
        "surname": "Yu",
        "given_name": "Lingli"
      },
      {
        "surname": "Chen",
        "given_name": "Baifan"
      },
      {
        "surname": "Yang",
        "given_name": "Chunhua"
      }
    ]
  },
  {
    "title": "Characterizing functional brain networks via Spatio-Temporal Attention 4D Convolutional Neural Networks (STA-4DCNNs)",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.004",
    "abstract": "Characterizing individualized spatio-temporal patterns of functional brain networks (FBNs) via functional magnetic resonance imaging (fMRI) provides a foundation for understanding complex brain function. Although previous studies have achieved promising performances based on either shallow or deep learning models, there is still much space to improve the accuracy of spatio-temporal pattern characterization of FBNs by optimally integrating the four-dimensional (4D) features of fMRI. In this study, we introduce a novel Spatio-Temporal Attention 4D Convolutional Neural Network (STA-4DCNN) model to characterize individualized spatio-temporal patterns of FBNs. Particularly, STA-4DCNN is composed of two subnetworks, in which the first Spatial Attention 4D CNN (SA-4DCNN) models the spatio-temporal features of 4D fMRI data and then characterizes the spatial pattern of FBNs, and the second Temporal Guided Attention Network (T-GANet) further characterizes the temporal pattern of FBNs under the guidance of the spatial pattern together with 4D fMRI data. We evaluate the proposed STA-4DCNN on seven different task fMRI and one resting state fMRI datasets from the publicly released Human Connectome Project. The experimental results demonstrate that STA-4DCNN has superior ability and generalizability in characterizing individualized spatio-temporal patterns of FBNs when compared to other state-of-the-art models. We further apply STA-4DCNN on another independent ABIDE I resting state fMRI dataset including both autism spectrum disorder (ASD) and typical developing (TD) subjects, and successfully identify abnormal spatio-temporal patterns of FBNs in ASD compared to TD. In general, STA-4DCNN provides a powerful tool for FBN characterization and for clinical applications on brain disease characterization at the individual level.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004440",
    "keywords": [
      "Artificial intelligence",
      "Brain activity and meditation",
      "Computer science",
      "Connectome",
      "Convolutional neural network",
      "Developmental psychology",
      "Electroencephalography",
      "Functional connectivity",
      "Functional magnetic resonance imaging",
      "Generalizability theory",
      "Human Connectome Project",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Resting state fMRI"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Xi"
      },
      {
        "surname": "Yan",
        "given_name": "Jiadong"
      },
      {
        "surname": "Zhao",
        "given_name": "Yu"
      },
      {
        "surname": "Jiang",
        "given_name": "Mingxin"
      },
      {
        "surname": "Chen",
        "given_name": "Yuzhong"
      },
      {
        "surname": "Zhou",
        "given_name": "Jingchao"
      },
      {
        "surname": "Xiao",
        "given_name": "Zhenxiang"
      },
      {
        "surname": "Wang",
        "given_name": "Zifan"
      },
      {
        "surname": "Zhang",
        "given_name": "Rong"
      },
      {
        "surname": "Becker",
        "given_name": "Benjamin"
      },
      {
        "surname": "Zhu",
        "given_name": "Dajiang"
      },
      {
        "surname": "Kendrick",
        "given_name": "Keith M."
      },
      {
        "surname": "Liu",
        "given_name": "Tianming"
      }
    ]
  },
  {
    "title": "IA-FaceS: A bidirectional method for semantic face editing",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.016",
    "abstract": "Semantic face editing has achieved substantial progress in recent years. However, existing face editing methods, which often encode the entire image into a single code, still have difficulty in enabling flexible editing while keeping high-fidelity reconstruction. The one-code scheme also brings entangled face manipulations and limited flexibility in editing face components. In this paper, we present IA-FaceS, a bidirectional method for disentangled face attribute manipulation as well as flexible, controllable component editing. We propose to embed images onto two branches: one branch computes high-dimensional component-invariant content embedding for capturing face details, and the other provides low-dimensional component-specific embeddings for component manipulations. The two-branch scheme naturally enables high-quality facial component-level editing while keeping faithful reconstruction with details. Moreover, we devise a component adaptive modulation (CAM) module, which integrates component-specific guidance into the decoder and successfully disentangles highly-correlated face components. The single-eye editing is developed for the first time without editing face masks or sketches. According to the experimental results, IA-FaceS establishes a good balance between maintaining image details and performing flexible face manipulation. Both quantitative and qualitative results indicate that the proposed method outperforms the existing methods in reconstruction, face attribute manipulation, and component transfer. We release the code and weights at: https://github.com/CMACH508/IA-FaceS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004579",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Code (set theory)",
      "Component (thermodynamics)",
      "Computer science",
      "Computer vision",
      "ENCODE",
      "Electrical engineering",
      "Embedding",
      "Engineering",
      "Face (sociological concept)",
      "Fidelity",
      "Flexibility (engineering)",
      "Gene",
      "High fidelity",
      "Image (mathematics)",
      "Image editing",
      "Mathematics",
      "Physics",
      "Programming language",
      "Set (abstract data type)",
      "Social science",
      "Sociology",
      "Statistics",
      "Telecommunications",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Wenjing"
      },
      {
        "surname": "Tu",
        "given_name": "Shikui"
      },
      {
        "surname": "Xu",
        "given_name": "Lei"
      }
    ]
  },
  {
    "title": "IA-FaceS: A bidirectional method for semantic face editing",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.016",
    "abstract": "Semantic face editing has achieved substantial progress in recent years. However, existing face editing methods, which often encode the entire image into a single code, still have difficulty in enabling flexible editing while keeping high-fidelity reconstruction. The one-code scheme also brings entangled face manipulations and limited flexibility in editing face components. In this paper, we present IA-FaceS, a bidirectional method for disentangled face attribute manipulation as well as flexible, controllable component editing. We propose to embed images onto two branches: one branch computes high-dimensional component-invariant content embedding for capturing face details, and the other provides low-dimensional component-specific embeddings for component manipulations. The two-branch scheme naturally enables high-quality facial component-level editing while keeping faithful reconstruction with details. Moreover, we devise a component adaptive modulation (CAM) module, which integrates component-specific guidance into the decoder and successfully disentangles highly-correlated face components. The single-eye editing is developed for the first time without editing face masks or sketches. According to the experimental results, IA-FaceS establishes a good balance between maintaining image details and performing flexible face manipulation. Both quantitative and qualitative results indicate that the proposed method outperforms the existing methods in reconstruction, face attribute manipulation, and component transfer. We release the code and weights at: https://github.com/CMACH508/IA-FaceS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004579",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Code (set theory)",
      "Component (thermodynamics)",
      "Computer science",
      "Computer vision",
      "ENCODE",
      "Electrical engineering",
      "Embedding",
      "Engineering",
      "Face (sociological concept)",
      "Fidelity",
      "Flexibility (engineering)",
      "Gene",
      "High fidelity",
      "Image (mathematics)",
      "Image editing",
      "Mathematics",
      "Physics",
      "Programming language",
      "Set (abstract data type)",
      "Social science",
      "Sociology",
      "Statistics",
      "Telecommunications",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Wenjing"
      },
      {
        "surname": "Tu",
        "given_name": "Shikui"
      },
      {
        "surname": "Xu",
        "given_name": "Lei"
      }
    ]
  },
  {
    "title": "Forgetting memristor based STDP learning circuit for neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.023",
    "abstract": "The circuit implementation of STDP based on memristor is of great significance for the application of neural network. However, recent research shows that the research on the pure circuit implementation of forgetting memristor and STDP is still rare. This paper proposes a new STDP learning rule implementation circuit based on the forgetting memristor. This kind of forgetting memory resistance synapse makes the neural network have the function of time-division multiplexing, but the instability of short-term memory will affect the learning ability of the neural network. This paper analyzes and discusses the influence of synapses with long-term and short-term memory on the learning characteristics of neural network STDP, which lays a foundation for the construction of time-division multiplexing neural network with long-term and short-term memory synapses. Through this circuit, it is found that the volatile memristor has different behaviors to the stimulus signal in different initial states, and the resulting LTP phenomenon is more in line with the forgetting effect in biology. This circuit has multiple adjustable parameters, which can fit the STDP learning rules under different conditions. The application of neural network proves the availability of this circuit.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004646",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognitive psychology",
      "Computer science",
      "Electronic engineering",
      "Engineering",
      "Forgetting",
      "Memristor",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Wenhao"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Liu",
        "given_name": "Yi"
      },
      {
        "surname": "Liu",
        "given_name": "Lu"
      },
      {
        "surname": "Liu",
        "given_name": "Xin"
      },
      {
        "surname": "Chen",
        "given_name": "Ling"
      }
    ]
  },
  {
    "title": "8 Brain-inspired evolving and spiking connectionist systems",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00007-5",
    "abstract": "Artificial neural networks, also known as connectionist systems, have now a long history as major techniques in computational intelligence with a wide range of application for learning from data and for artificial intelligence (AI). The main focus of the chapter is a class of ANN, called evolving connectionist systems (ECOS) that evolve their structure and functionality through incremental and life-long learning from data. Methods, systems and a wide range of applications of ECOS are presented and referenced. ECOS principles are further used for the development of brain-inspired evolving spiking neural network architectures (BI-eSNN). An example is the NeuCube architecture, which is illustrated with deep learning algorithms and with two areas of applications for life-long learning of brain data and predictive modeling of seismic data. The chapter concludes that the BI-eSNN architectures are good candidates for the future development of life-long learning and open AI systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000075",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Connectionism",
      "Deep learning",
      "Machine learning"
    ],
    "authors": [
      {
        "surname": "Kasabov",
        "given_name": "Nikola Kirilov"
      }
    ]
  },
  {
    "title": "LSTMED: An uneven dynamic process monitoring method based on LSTM and Autoencoder neural network",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.001",
    "abstract": "Due to the complicated production mechanism in multivariate industrial processes, different dynamic features of variables raise challenges to traditional data-driven process monitoring methods which assume the process data is static or dynamically consistent. To tackle this issue, this paper proposes a novel process monitoring method based on the long short-term memory (LSTM) and Autoencoder neural network (called LSTMED) for multivariate process monitoring with uneven dynamic features. First, the LSTM units are arranged in the encoder–decoder form to construct an end-to-end model. Then, the constructed model is trained in an unsupervised manner to capture long-term time dependency within variables and dominant representation of high dimensional process data. Afterward, the kernel density estimation (KDE) method is performed to determine the control limit only based on the reconstruction error from historical normal data. Finally, effective online monitoring for uneven dynamic process can be achieved. The performance and advantage of the process monitoring method proposed are explained through typical cases, including the numerical simulation and Tennessee Eastman (TE) benchmark process, and comparative experimental analysis with state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004415",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Machine learning",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)"
    ],
    "authors": [
      {
        "surname": "Deng",
        "given_name": "Wenfeng"
      },
      {
        "surname": "Li",
        "given_name": "Yuxuan"
      },
      {
        "surname": "Huang",
        "given_name": "Keke"
      },
      {
        "surname": "Wu",
        "given_name": "Dehao"
      },
      {
        "surname": "Yang",
        "given_name": "Chunhua"
      },
      {
        "surname": "Gui",
        "given_name": "Weihua"
      }
    ]
  },
  {
    "title": "Rutting prediction and analysis of influence factors based on multivariate transfer entropy and graph neural networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.08.030",
    "abstract": "The Rutting prediction model is an essential element of efficient pavement management systems. Accuracy of commonly used predictive model necessitates knowledge of the input parameters that was incorporated and local calibration of the model coefficients. In this paper, a novel rutting prediction model based on multivariate transfer entropy and graph neural networks is proposed for incorporating a limited number of observable inputs, which can accommodate with sufficient prediction performance and generalization to a variety of complex pavement design structure data. The multivariate transfer entropy based graph representation is able to find the significant causality between variables and rutting. The influence factor analysis results confirm the high influence of temperature and vehicle axle load. Several experiments are set up on the Research Institute of Highway Ministry of Transport track (RIOHTrack) dataset for the comparison between the proposed model and the state-of-art prediction models. The result demonstrates that the proposed model is more accurate and robust compared to existing methods on the rutting prediction task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003306",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Asphalt",
      "Cartography",
      "Computer science",
      "Data mining",
      "Entropy (arrow of time)",
      "Generalization",
      "Geography",
      "Graph",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Multivariate statistics",
      "Physics",
      "Predictive modelling",
      "Principal component analysis",
      "Principle of maximum entropy",
      "Quantum mechanics",
      "Rut",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Jinren"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Huang",
        "given_name": "Wei"
      },
      {
        "surname": "Shi",
        "given_name": "Xinli"
      },
      {
        "surname": "Zhou",
        "given_name": "Xingye"
      }
    ]
  },
  {
    "title": "UniSKGRep: A unified representation learning framework of social network and knowledge graph",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.010",
    "abstract": "The human-oriented applications aim to exploit behaviors of people, which impose challenges on user modeling of integrating social network (SN) with knowledge graph (KG), and jointly analyzing two types of graph data. However, existing graph representation learning methods merely represent one of two graphs alone, and hence are unable to comprehensively consider features of both SN and KG with profiling the correlation between them, resulting in unsatisfied performance in downstream tasks. Considering the diverse gap of features and the difficulty of associating of the two graph data, we introduce a Unified Social Knowledge Graph Representation learning framework (UniSKGRep), with the goal to leverage the multi-view information inherent in the SN and KG for improving the downstream tasks of user modeling. To the best of our knowledge, we are the first to present a unified representation learning framework for SN and KG. Concretely, the SN and KG are organized as the Social Knowledge Graph (SKG), a unified representation of SN and KG. For the representation learning of SKG, first, two separate encoders in the Intra-graph model capture both the social-view and knowledge-view in two embedding spaces, respectively. Then the Inter-graph model is learned to associate the two separate spaces via bridging the semantics of overlapping node pairs. In addition, the overlapping node enhancement module is designed to effectively align two spaces with the consideration of a relatively small number of overlapping nodes. The two spaces are gradually unified by continuously iterating the joint training procedure. Extensive experiments on two real-world SKG datasets have proved the effectiveness of UniSKGRep in yielding general and substantial performance improvement compared with the strong baselines in various downstream tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004518",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Embedding",
      "Exploit",
      "Feature learning",
      "Graph",
      "Knowledge graph",
      "Leverage (statistics)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Yinghan"
      },
      {
        "surname": "Jiang",
        "given_name": "Xuhui"
      },
      {
        "surname": "Li",
        "given_name": "Zijian"
      },
      {
        "surname": "Wang",
        "given_name": "Yuanzhuo"
      },
      {
        "surname": "Xu",
        "given_name": "Chengjin"
      },
      {
        "surname": "Shen",
        "given_name": "Huawei"
      },
      {
        "surname": "Cheng",
        "given_name": "Xueqi"
      }
    ]
  },
  {
    "title": "Bayesian Disturbance Injection: Robust imitation learning of flexible policies for robot manipulation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.008",
    "abstract": "Humans demonstrate a variety of interesting behavioral characteristics when performing tasks, such as selecting between seemingly equivalent optimal actions, performing recovery actions when deviating from the optimal trajectory, or moderating actions in response to sensed risks. However, imitation learning, which attempts to teach robots to perform these same tasks from observations of human demonstrations, often fails to capture such behavior. Specifically, commonly used learning algorithms embody inherent contradictions between the learning assumptions (e.g., single optimal action) and actual human behavior (e.g., multiple optimal actions), thereby limiting robot generalizability, applicability, and demonstration feasibility. To address this, this paper proposes designing imitation learning algorithms with a focus on utilizing human behavioral characteristics, thereby embodying principles for capturing and exploiting actual demonstrator behavioral characteristics. This paper presents the first imitation learning framework, Bayesian Disturbance Injection (BDI), that typifies human behavioral characteristics by incorporating model flexibility, robustification, and risk sensitivity. Bayesian inference is used to learn flexible non-parametric multi-action policies, while simultaneously robustifying policies by injecting risk-sensitive disturbances to induce human recovery action and ensuring demonstration feasibility. Our method is evaluated through risk-sensitive simulations and real-robot experiments (e.g., table-sweep task, shaft-reach task and shaft-insertion task) using the UR5e 6-DOF robotic arm, to demonstrate the improved characterization of behavior. Results show significant improvement in task performance, through improved flexibility, robustness as well as demonstration feasibility.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200449X",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Developmental psychology",
      "Engineering",
      "Flexibility (engineering)",
      "Gene",
      "Generalizability theory",
      "Imitation",
      "Machine learning",
      "Mathematics",
      "Psychology",
      "Reinforcement learning",
      "Robot",
      "Robustness (evolution)",
      "Social psychology",
      "Statistics",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Oh",
        "given_name": "Hanbit"
      },
      {
        "surname": "Sasaki",
        "given_name": "Hikaru"
      },
      {
        "surname": "Michael",
        "given_name": "Brendan"
      },
      {
        "surname": "Matsubara",
        "given_name": "Takamitsu"
      }
    ]
  },
  {
    "title": "CT-Loc: Cross-domain visual localization with a channel-wise transformer",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.014",
    "abstract": "We tackle the cross-domain visual localization problem of estimating camera position and orientation from real images without three-dimensional (3D) spatial mapping or modeling. Recent studies have shown suboptimal performance in this task owing to the photometric and geometric differences between synthetic and real images. In this study, we present a deep learning approach that uses a channel-wise transformer localization (CT-Loc) framework. Inspired by the human behavior of looking for structural landmarks to estimate one’s location, CT-Loc encodes the most salient features of task-relevant objects in target scenes. To evaluate the efficacy of the proposed method in a real-world application, we built a complex and large-scale dataset of the interior of the mechanical room during operations and conducted extensive performance comparisons with the publicly available state-of-the-art University of Melbourne Corridor and Virtual KITTI 2 datasets. Compared with the otherwise best-performing BIM-PoseNet indoor camera localization model, our method significantly reduces position and orientation errors through the application of attention weights and saliency maps while also learning only the visual structural patterns (e.g., floors and doors) that are most relevant to localization tasks. Our model successfully ignores uninformative objects. This approach yields higher-level robust camera-pose regression localization results without requiring prebuilt maps. The code is available at https://github.com/kdaeho27/CT-Loc.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004555",
    "keywords": [
      "Artificial intelligence",
      "Code (set theory)",
      "Computer science",
      "Computer vision",
      "Economics",
      "Finance",
      "Geometry",
      "Mathematics",
      "Orientation (vector space)",
      "Pattern recognition (psychology)",
      "Position (finance)",
      "Programming language",
      "Salient",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Daeho"
      },
      {
        "surname": "Kim",
        "given_name": "Jaeil"
      }
    ]
  },
  {
    "title": "7 Computers versus brains: Challenges of sustainable artificial and biological intelligence",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00013-0",
    "abstract": "Creating machines that can think and act just like humans has fascinated humanity for millennia. Breakthroughs of scientific and technological developments in recent decades allow us to build computers and robots that parallel or even surpass human abilities in many respects. The superhuman achievements are based on a new generation of Artificial Intelligence (AI) with neural networks using Deep Learning (DL). The performance of these AI systems increases exponentially, which requires exponentially increasing resources as well, including data, computational power, and energy. This development is not sustainable and there is a need for new AI approaches, which give careful consideration to limited resources. In this chapter, we discuss how new AI could benefit from lessons learnt from human brains, human intelligence, and human constraints. We describe various aspects of biological and artificial intelligence. We introduce a balanced approach based on the concepts of complementarity and multistability as manifested in human brain operation and cognitive processing. This approach provides insights into key principles of intelligence in biological brains and it helps building sustainable artificial intelligence.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000130",
    "keywords": [
      "Artificial general intelligence",
      "Artificial intelligence",
      "Biology",
      "Cognition",
      "Cognitive science",
      "Complementarity (molecular biology)",
      "Computer science",
      "Genetics",
      "Human intelligence",
      "Neuroscience",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Kozma",
        "given_name": "Robert"
      }
    ]
  },
  {
    "title": "Unsupervised graph-level representation learning with hierarchical contrasts",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.019",
    "abstract": "Unsupervised graph-level representation learning has recently shown great potential in a variety of domains, ranging from bioinformatics to social networks. Plenty of graph contrastive learning methods have been proposed to generate discriminative graph-level representations recently. They typically design multiple types of graph augmentations and enforce a graph to have consistent representations under different views. However, these techniques mostly neglect the intrinsic hierarchical structure of the graph, resulting in a limited exploration of semantic information for graph representation. Moreover, they often rely on a large number of negative samples to prevent collapsing into trivial solutions, while a great need for negative samples may lead to memory issues during optimization in graph domains. To address the two issues, this paper develops an unsupervised graph-level representation learning framework named Hierarchical Graph Contrastive Learning (HGCL), which investigates the hierarchical structural semantics of a graph at both node and graph levels. Specifically, our HGCL consists of three parts, i.e., node-level contrastive learning, graph-level contrastive learning, and mutual contrastive learning to capture graph semantics hierarchically. Furthermore, the Siamese network and momentum update are further involved to release the demand for excessive negative samples. Finally, the experimental results on both benchmark datasets for graph classification and large-scale OGB datasets for transfer learning demonstrate that our proposed HGCL significantly outperforms a broad range of state-of-the-art baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004609",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Discriminative model",
      "Feature learning",
      "Graph",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Ju",
        "given_name": "Wei"
      },
      {
        "surname": "Gu",
        "given_name": "Yiyang"
      },
      {
        "surname": "Luo",
        "given_name": "Xiao"
      },
      {
        "surname": "Wang",
        "given_name": "Yifan"
      },
      {
        "surname": "Yuan",
        "given_name": "Haochen"
      },
      {
        "surname": "Zhong",
        "given_name": "Huasong"
      },
      {
        "surname": "Zhang",
        "given_name": "Ming"
      }
    ]
  },
  {
    "title": "Bayesian Disturbance Injection: Robust imitation learning of flexible policies for robot manipulation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.008",
    "abstract": "Humans demonstrate a variety of interesting behavioral characteristics when performing tasks, such as selecting between seemingly equivalent optimal actions, performing recovery actions when deviating from the optimal trajectory, or moderating actions in response to sensed risks. However, imitation learning, which attempts to teach robots to perform these same tasks from observations of human demonstrations, often fails to capture such behavior. Specifically, commonly used learning algorithms embody inherent contradictions between the learning assumptions (e.g., single optimal action) and actual human behavior (e.g., multiple optimal actions), thereby limiting robot generalizability, applicability, and demonstration feasibility. To address this, this paper proposes designing imitation learning algorithms with a focus on utilizing human behavioral characteristics, thereby embodying principles for capturing and exploiting actual demonstrator behavioral characteristics. This paper presents the first imitation learning framework, Bayesian Disturbance Injection (BDI), that typifies human behavioral characteristics by incorporating model flexibility, robustification, and risk sensitivity. Bayesian inference is used to learn flexible non-parametric multi-action policies, while simultaneously robustifying policies by injecting risk-sensitive disturbances to induce human recovery action and ensuring demonstration feasibility. Our method is evaluated through risk-sensitive simulations and real-robot experiments (e.g., table-sweep task, shaft-reach task and shaft-insertion task) using the UR5e 6-DOF robotic arm, to demonstrate the improved characterization of behavior. Results show significant improvement in task performance, through improved flexibility, robustness as well as demonstration feasibility.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200449X",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Developmental psychology",
      "Engineering",
      "Flexibility (engineering)",
      "Gene",
      "Generalizability theory",
      "Imitation",
      "Machine learning",
      "Mathematics",
      "Psychology",
      "Reinforcement learning",
      "Robot",
      "Robustness (evolution)",
      "Social psychology",
      "Statistics",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Oh",
        "given_name": "Hanbit"
      },
      {
        "surname": "Sasaki",
        "given_name": "Hikaru"
      },
      {
        "surname": "Michael",
        "given_name": "Brendan"
      },
      {
        "surname": "Matsubara",
        "given_name": "Takamitsu"
      }
    ]
  },
  {
    "title": "11 From synapses to ephapsis: Embodied cognition and wearable personal assistants",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00005-1",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000051",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Cognition",
      "Cognitive science",
      "Computer science",
      "Embedded system",
      "Embodied cognition",
      "Human–computer interaction",
      "Neuroscience",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Wearable computer"
    ],
    "authors": [
      {
        "surname": "Ormandy",
        "given_name": "Roman"
      }
    ]
  },
  {
    "title": "7 Computers versus brains: Challenges of sustainable artificial and biological intelligence",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00013-0",
    "abstract": "Creating machines that can think and act just like humans has fascinated humanity for millennia. Breakthroughs of scientific and technological developments in recent decades allow us to build computers and robots that parallel or even surpass human abilities in many respects. The superhuman achievements are based on a new generation of Artificial Intelligence (AI) with neural networks using Deep Learning (DL). The performance of these AI systems increases exponentially, which requires exponentially increasing resources as well, including data, computational power, and energy. This development is not sustainable and there is a need for new AI approaches, which give careful consideration to limited resources. In this chapter, we discuss how new AI could benefit from lessons learnt from human brains, human intelligence, and human constraints. We describe various aspects of biological and artificial intelligence. We introduce a balanced approach based on the concepts of complementarity and multistability as manifested in human brain operation and cognitive processing. This approach provides insights into key principles of intelligence in biological brains and it helps building sustainable artificial intelligence.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000130",
    "keywords": [
      "Artificial general intelligence",
      "Artificial intelligence",
      "Biology",
      "Cognition",
      "Cognitive science",
      "Complementarity (molecular biology)",
      "Computer science",
      "Genetics",
      "Human intelligence",
      "Neuroscience",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Kozma",
        "given_name": "Robert"
      }
    ]
  },
  {
    "title": "Gateway identity and spatial remapping in a combined grid and place cell attractor",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.019",
    "abstract": "The spatial specificities of hippocampal place cells, i.e., their firing fields, are subject to change if the rat enters a new compartment in the experimental maze. This effect is known as remapping. It cannot be explained from path integration (grid cell activity) and local sensory cues alone but requires additional knowledge of the different compartments in the form of context recognition at the gateways between them. Here we present a model for the hippocampal–entorhinal interplay in which the activity of place and grid cells follows a joint attractor dynamic. Place cells depend on the current grid cell activity but can also reset the grid cell activity in the remapping process. Remapping is triggered by the passage through a gateway. When this happens, a previously stored pattern of place cell activity associated with the gateway is reactivated from a “gateway database”. The joint attractor will then reinstate the grid cell pattern that was active when the gateway had first been learned and path integration can proceed from there. The model is tested with various mazes used in the experimental literature and reproduces the published results, and we make predictions for remapping in a new maze type. We propose the involvement of memory in the form of “gate cells” that drive the place cells and with them the joint hippocampal–entorhinal loop into the corresponding attractor whenever a compartment is entered.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004154",
    "keywords": [
      "Artificial intelligence",
      "Attractor",
      "Biology",
      "Computer network",
      "Computer science",
      "Context (archaeology)",
      "Default gateway",
      "Economics",
      "Entorhinal cortex",
      "Financial economics",
      "Gateway (web page)",
      "Geometry",
      "Grid",
      "Grid cell",
      "Hippocampal formation",
      "Mathematical analysis",
      "Mathematics",
      "Neuroscience",
      "Paleontology",
      "Path integration",
      "Place cell",
      "Reset (finance)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Baumann",
        "given_name": "Tristan"
      },
      {
        "surname": "Mallot",
        "given_name": "Hanspeter A."
      }
    ]
  },
  {
    "title": "Unsupervised graph-level representation learning with hierarchical contrasts",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.019",
    "abstract": "Unsupervised graph-level representation learning has recently shown great potential in a variety of domains, ranging from bioinformatics to social networks. Plenty of graph contrastive learning methods have been proposed to generate discriminative graph-level representations recently. They typically design multiple types of graph augmentations and enforce a graph to have consistent representations under different views. However, these techniques mostly neglect the intrinsic hierarchical structure of the graph, resulting in a limited exploration of semantic information for graph representation. Moreover, they often rely on a large number of negative samples to prevent collapsing into trivial solutions, while a great need for negative samples may lead to memory issues during optimization in graph domains. To address the two issues, this paper develops an unsupervised graph-level representation learning framework named Hierarchical Graph Contrastive Learning (HGCL), which investigates the hierarchical structural semantics of a graph at both node and graph levels. Specifically, our HGCL consists of three parts, i.e., node-level contrastive learning, graph-level contrastive learning, and mutual contrastive learning to capture graph semantics hierarchically. Furthermore, the Siamese network and momentum update are further involved to release the demand for excessive negative samples. Finally, the experimental results on both benchmark datasets for graph classification and large-scale OGB datasets for transfer learning demonstrate that our proposed HGCL significantly outperforms a broad range of state-of-the-art baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004609",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Discriminative model",
      "Feature learning",
      "Graph",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Ju",
        "given_name": "Wei"
      },
      {
        "surname": "Gu",
        "given_name": "Yiyang"
      },
      {
        "surname": "Luo",
        "given_name": "Xiao"
      },
      {
        "surname": "Wang",
        "given_name": "Yifan"
      },
      {
        "surname": "Yuan",
        "given_name": "Haochen"
      },
      {
        "surname": "Zhong",
        "given_name": "Huasong"
      },
      {
        "surname": "Zhang",
        "given_name": "Ming"
      }
    ]
  },
  {
    "title": "5 The brain-mind-computer trichotomy: Hermeneutic approach",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00019-1",
    "abstract": "The unifying framework, that is, the brain-mind-computer trichotomy is suggested analyzed by using hermeneutic approach. While we argue that brain is a hermeneutic device, and hermeneutics is also necessary to understand situations and other's minds. Intentional dynamics is a possible approach to set a unifying framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000191",
    "keywords": [
      "Cognitive science",
      "Computer science",
      "Epistemology",
      "Hermeneutics",
      "Philosophy",
      "Programming language",
      "Psychology",
      "Set (abstract data type)",
      "Trichotomy (philosophy)"
    ],
    "authors": [
      {
        "surname": "Érdi",
        "given_name": "Péter"
      }
    ]
  },
  {
    "title": "10 Theory of the brain and mind: Visions and history",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00004-X",
    "abstract": "This chapter reviews the history of neural network modeling of the brain and mind. The original impulse to link biology and technology led to the founding of the International Neural Network Society, the journal Neural Networks, and the International Joint Conferences on Neural Networks. Yet many of the active researchers in the neural network field are not connected to those institutions. The chapter advocates various changes in the scientific culture that would help to reunite computational neuroscience with neural network theory and thereby come closer to realizing the dreams of INNS's founders.",
    "link": "https://www.sciencedirect.com/science/article/pii/B978032396104200004X",
    "keywords": [
      "Anthropology",
      "Artificial intelligence",
      "Artificial neural network",
      "Cognitive science",
      "Computer science",
      "Field (mathematics)",
      "Mathematics",
      "Nervous system network models",
      "Neuroscience",
      "Psychology",
      "Pure mathematics",
      "Recurrent neural network",
      "Sociology",
      "Types of artificial neural networks",
      "Vision"
    ],
    "authors": [
      {
        "surname": "Levine",
        "given_name": "Daniel S."
      }
    ]
  },
  {
    "title": "Continual learning with attentive recurrent neural networks for temporal data classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.031",
    "abstract": "Continual learning is an emerging research branch of deep learning, which aims to learn a model for a series of tasks continually without forgetting knowledge obtained from previous tasks. Despite receiving a lot of attention in the research community, temporal-based continual learning techniques are still underutilized. In this paper, we address the problem of temporal-based continual learning by allowing a model to continuously learn on temporal data. To solve the catastrophic forgetting problem of learning temporal data in task incremental scenarios, in this research, we propose a novel method based on attentive recurrent neural networks, called Temporal Teacher Distillation (TTD). TTD solves the catastrophic forgetting problem in an attentive recurrent neural network based on three hypotheses, namely Rotation Hypothesis, Redundant Hypothesis, and Recover Hypothesis. Rotation Hypothesis and Redundant hypotheses could cause the attention shift phenomenon, which degrades the model performance on the learned tasks. Moreover, not considering the Recover Hypothesis increases extra memory usage in continuously training different tasks. Therefore, the proposed TTD based on the above hypotheses complements the inadequacy of the existing methods for temporal-based continual learning. For evaluating the performance of our proposed method in task incremental setting, we use a public dataset, WIreless Sensor Data Mining (WISDM), and a synthetic dataset, Split-QuickDraw-100. According to experimental results, the proposed TTD significantly outperforms state-of-the-art methods by up to 14.6% and 45.1% in terms of accuracy and forgetting measures, respectively. To the best of our knowledge, this is the first work that studies continual learning in real-world incremental categories for temporal data classification with attentive recurrent neural networks and provides the proper application-oriented scenario.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004270",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognitive psychology",
      "Computer science",
      "Deep learning",
      "Economics",
      "Forgetting",
      "Machine learning",
      "Management",
      "Psychology",
      "Recurrent neural network",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Yin",
        "given_name": "Shao-Yu"
      },
      {
        "surname": "Huang",
        "given_name": "Yu"
      },
      {
        "surname": "Chang",
        "given_name": "Tien-Yu"
      },
      {
        "surname": "Chang",
        "given_name": "Shih-Fang"
      },
      {
        "surname": "Tseng",
        "given_name": "Vincent S."
      }
    ]
  },
  {
    "title": "Accelerating reinforcement learning with case-based model-assisted experience augmentation for process control",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.016",
    "abstract": "In the context of intelligent manufacturing in the process industry, traditional model-based optimization control methods cannot adapt to the situation of drastic changes in working conditions or operating modes. Reinforcement learning (RL) directly achieves the control objective by interacting with the environment, and has significant advantages in the presence of uncertainty since it does not require an explicit model of the operating plant. However, most RL algorithms fail to retain transfer learning capabilities in the presence of mode variation, which becomes a practical obstacle to industrial process control applications. To address these issues, we design a framework that uses local data augmentation to improve the training efficiency and transfer learning (adaptability) performance. Therefore, this paper proposes a novel RL control algorithm, CBR-MA-DDPG, organically integrating case-based reasoning (CBR), model-assisted (MA) experience augmentation, and deep deterministic policy gradient (DDPG). When the operating mode changes, CBR-MA-DDPG can quickly adapt to the varying environment and achieve the desired control performance within several training episodes. Experimental analyses on a continuous stirred tank reactor (CSTR) and an organic Rankine cycle (ORC) demonstrate the superiority of the proposed method in terms of both adaptability and control performance/robustness. The results show that the control performance of the CBR-MA-DDPG agent outperforms the conventional PI and MPC control schemes, and that it has higher training efficiency than the state-of-the-art DDPG, TD3, and PPO algorithms in transfer learning scenarios with mode shift situations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004129",
    "keywords": [
      "Adaptability",
      "Artificial intelligence",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Context (archaeology)",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Ecology",
      "Engineering",
      "Gene",
      "Operating system",
      "Paleontology",
      "Process (computing)",
      "Process control",
      "Reinforcement learning",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Lin",
        "given_name": "Runze"
      },
      {
        "surname": "Chen",
        "given_name": "Junghui"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      },
      {
        "surname": "Su",
        "given_name": "Hongye"
      }
    ]
  },
  {
    "title": "A Reinforcement Meta-Learning framework of executive function and information demand",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.004",
    "abstract": "Gathering information is crucial for maximizing fitness, but requires diverting resources from searching directly for primary rewards to actively exploring the environment. Optimal decision-making thus maximizes information while reducing effort costs, but little is known about the neuro-computational implementation of this tradeoff. We present a Reinforcement Meta-Learning (RML) computational model that solves the trade-off between the value and costs of gathering information. We implement the RML in a biologically plausible architecture that links catecholaminergic neuromodulators, the medial prefrontal cortex and topographically organized visual maps and show that it accounts for neural and behavioral findings on information demand motivated by instrumental incentives and intrinsic utility. Moreover, the utility function used by the RML, encoded by dopamine, is an approximation of variational free energy. Thus, the RML presents a biologically plausible mechanism for coordinating motivational, executive and sensory systems generate visual information gathering policies that minimize free energy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003884",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Incentive",
      "Machine learning",
      "Microeconomics",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Silvetti",
        "given_name": "Massimo"
      },
      {
        "surname": "Lasaponara",
        "given_name": "Stefano"
      },
      {
        "surname": "Daddaoua",
        "given_name": "Nabil"
      },
      {
        "surname": "Horan",
        "given_name": "Mattias"
      },
      {
        "surname": "Gottlieb",
        "given_name": "Jacqueline"
      }
    ]
  },
  {
    "title": "Continual learning with attentive recurrent neural networks for temporal data classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.031",
    "abstract": "Continual learning is an emerging research branch of deep learning, which aims to learn a model for a series of tasks continually without forgetting knowledge obtained from previous tasks. Despite receiving a lot of attention in the research community, temporal-based continual learning techniques are still underutilized. In this paper, we address the problem of temporal-based continual learning by allowing a model to continuously learn on temporal data. To solve the catastrophic forgetting problem of learning temporal data in task incremental scenarios, in this research, we propose a novel method based on attentive recurrent neural networks, called Temporal Teacher Distillation (TTD). TTD solves the catastrophic forgetting problem in an attentive recurrent neural network based on three hypotheses, namely Rotation Hypothesis, Redundant Hypothesis, and Recover Hypothesis. Rotation Hypothesis and Redundant hypotheses could cause the attention shift phenomenon, which degrades the model performance on the learned tasks. Moreover, not considering the Recover Hypothesis increases extra memory usage in continuously training different tasks. Therefore, the proposed TTD based on the above hypotheses complements the inadequacy of the existing methods for temporal-based continual learning. For evaluating the performance of our proposed method in task incremental setting, we use a public dataset, WIreless Sensor Data Mining (WISDM), and a synthetic dataset, Split-QuickDraw-100. According to experimental results, the proposed TTD significantly outperforms state-of-the-art methods by up to 14.6% and 45.1% in terms of accuracy and forgetting measures, respectively. To the best of our knowledge, this is the first work that studies continual learning in real-world incremental categories for temporal data classification with attentive recurrent neural networks and provides the proper application-oriented scenario.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004270",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognitive psychology",
      "Computer science",
      "Deep learning",
      "Economics",
      "Forgetting",
      "Machine learning",
      "Management",
      "Psychology",
      "Recurrent neural network",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Yin",
        "given_name": "Shao-Yu"
      },
      {
        "surname": "Huang",
        "given_name": "Yu"
      },
      {
        "surname": "Chang",
        "given_name": "Tien-Yu"
      },
      {
        "surname": "Chang",
        "given_name": "Shih-Fang"
      },
      {
        "surname": "Tseng",
        "given_name": "Vincent S."
      }
    ]
  },
  {
    "title": "ExpGCN: Review-aware Graph Convolution Network for explainable recommendation",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.014",
    "abstract": "Existing works in recommender system have widely explored extracting reviews as explanations beyond user–item interactions, and formulated the explanation generation as a ranking task to enhance item recommendation performance. To associate explanations with users and items, graph neural networks (GNN) are usually employed to learn node representations on the heterogeneous user–item–explanation interaction graph. However, modeling heterogeneous graph convolution poses limitations in both message passing styles and computational efficiency, resulting in sub-optimal recommendation performance. To address the limitations, we propose an Explanation-aware Graph Convolution Network (ExpGCN). In particular, the heterogeneous interaction graph is divided to subgraphs regard to the edge types in ExpGCN. By aggregating information from distinct subgraphs, ExpGCN is capable of generating node representations for explanation ranking task and item recommendation task respectively. Task-oriented graph convolution can not only reduce the complexity of heterogeneous node aggregation, but also alleviate the performance degeneration caused by the conflicts between task learning objectives, which has been neglected in current studies. Extensive experiments on four public datasets show that ExpGCN significantly outperforms state-of-the-art baselines with high efficiency, demonstrating the effectiveness of ExpGCN in explainable recommendations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004087",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Economics",
      "Engineering",
      "Graph",
      "Machine learning",
      "Management",
      "Node (physics)",
      "Ranking (information retrieval)",
      "Recommender system",
      "Structural engineering",
      "Task (project management)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Tianjun"
      },
      {
        "surname": "Chow",
        "given_name": "Tommy W.S."
      },
      {
        "surname": "Ma",
        "given_name": "Jianghong"
      },
      {
        "surname": "Zhao",
        "given_name": "Mingbo"
      }
    ]
  },
  {
    "title": "4 Meaning versus information, prediction versus memory, and question versus answer",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00003-8",
    "abstract": "Brain science and artificial intelligence have made great progress toward the understanding and engineering of the human mind. The progress has accelerated significantly since the turn of the century thanks to new methods for probing the brain (both structure and function), and rapid development in deep learning research. However, despite these new developments, there are still many open questions, such as how to understand the brain at the system level, and various robustness issues and limitations of deep learning. In this chapter, I will talk about some of the concepts that are central to brain science and artificial intelligence, such as information and memory, and discuss how a different view on these concepts can help us move forward, beyond current limits of our understanding in these fields.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000038",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Brain function",
      "Cognitive science",
      "Computer science",
      "Data science",
      "Evolutionary biology",
      "Function (biology)",
      "Meaning (existential)",
      "Neuroscience",
      "Psychology",
      "Psychotherapist"
    ],
    "authors": [
      {
        "surname": "Choe",
        "given_name": "Yoonsuck"
      }
    ]
  },
  {
    "title": "3 A half century of progress toward a unified neural theory of mind and brain with applications to autonomous adaptive agents and mental disorders",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00009-9",
    "abstract": "This article surveys some of the main design principles, mechanisms, circuits, and architectures that have been discovered during a half century of systematic research aimed at developing a unified theory that links mind and brain, and shows how psychological functions arise as emergent properties of brain mechanisms. The article describes a theoretical method that has enabled such a theory to be developed in stages by carrying out a kind of conceptual evolution. It also describes revolutionary computational paradigms like complementary computing and laminar computing that constrain the kind of unified theory that can describe the autonomous adaptive intelligence that emerges from advanced brains. Adaptive resonance theory, or ART, is one of the core models that has been discovered in this way. ART proposes how advanced brains learn to attend, recognize, and predict objects and events in a changing world that is filled with unexpected events. ART is not, however, a “theory of everything” if only because, due to complementary computing, different matching and learning laws tend to support perception and cognition on the one hand, and spatial representation and action on the other. The article mentions why a theory of this kind may be useful in the design of autonomous adaptive agents in engineering and technology. It also notes how the theory has led to new mechanistic insights about mental disorders such as autism, medial temporal amnesia, Alzheimer's disease, and schizophrenia, along with mechanistically informed proposals about how their symptoms may be ameliorated.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000099",
    "keywords": [
      "Action (physics)",
      "Adaptive resonance theory",
      "Artificial intelligence",
      "Artificial neural network",
      "Cognition",
      "Cognitive psychology",
      "Cognitive science",
      "Computer science",
      "Neuroscience",
      "Perception",
      "Physics",
      "Programming language",
      "Psychology",
      "Quantum mechanics",
      "Schizophrenia (object-oriented programming)"
    ],
    "authors": [
      {
        "surname": "Grossberg",
        "given_name": "Stephen"
      }
    ]
  },
  {
    "title": "More refined superbag: Distantly supervised relation extraction with deep clustering",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.008",
    "abstract": "Distant supervision (DS) can automatically generate annotated data for relation extraction (RE) with knowledge bases and corpora. The existing DS methods that train on bags selected by attention mechanism are susceptible to noisy bags and neglect useful information in noisy bags. In this paper, we propose DCSR, a novel DS method which utilizes deep clustering to obtain refined superbag representations for solving the wrong labeling problem. we substitute deep clustering for selective attention to construct superbags, capturing helpful information between spatially-close bags, including noisy bags. Moreover, we implement data augmentation on the input sentences to handle the long-tail problem. Experiments on the NYT2010 and NYT-H datasets show that our method can effectively improve RE and significantly outperforms state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003926",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Construct (python library)",
      "Data mining",
      "Information extraction",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Programming language",
      "Relation (database)",
      "Relationship extraction"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Suizhu"
      },
      {
        "surname": "Liu",
        "given_name": "Yanxia"
      },
      {
        "surname": "Jiang",
        "given_name": "Yuantong"
      },
      {
        "surname": "Liu",
        "given_name": "Zhiqiang"
      }
    ]
  },
  {
    "title": "Pairwise learning problems with regularization networks and Nyström subsampling approach",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.007",
    "abstract": "Pairwise learning usually refers to the learning problem that works with pairs of training samples, such as ranking, similarity and metric learning, and AUC maximization. To overcome the challenge of pairwise learning in the large scale computation, this paper introduces Nyström sampling approach to the coefficient-based regularized pairwise algorithm in the context of kernel networks. Our theorems establish that the obtained Nyström estimator achieves the minimax error over all estimators using the whole data provided that the subsampling level is not too small. We derive the function relation between the subsampling level and regularization parameter that guarantees computation cost reduction and asymptotic behaviors’ optimality simultaneously. The Nyström coefficient-based pairwise learning method does not require the kernel to be symmetric or positive semi-definite, which provides more flexibility and adaptivity in the learning process. We apply the method to the bipartite ranking problem, which improves the state-of-the-art theoretical results in previous works. By developing probability inequalities for U-statistics on Hilbert–Schmidt operators, we provide new mathematical tools for handling pairs of examples involved in pairwise learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003914",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Computer science",
      "Estimator",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Minimax",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Cheng"
      },
      {
        "surname": "Hu",
        "given_name": "Ting"
      },
      {
        "surname": "Jiang",
        "given_name": "Siyang"
      }
    ]
  },
  {
    "title": "Classification-based prediction of network connectivity robustness",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.013",
    "abstract": "Today, there is an increasing concern about malicious attacks on various networks in society and industry, against which the network robustness is critical. Network connectivity robustness, in particular, is of fundamental importance, which is generally measured by a sequence of calculated values that indicate the connectedness of the remaining network after a sequence of attacks by means of node- or edge-removal. It is computationally time-consuming, however, to measure and evaluate the network connectivity robustness using the conventional attack simulations, especially for large-scale networked systems. In the present paper, an efficient robustness predictor based on multiple convolutional neural networks (mCNN-RP) is proposed for predicting the network connectivity robustness, which is an natural extension of the single CNN-based predictor. In mCNN-RP, one CNN works as the classifier, while each of the rest CNNs works as an estimator for predicting the connectivity robustness of every classified network category. The network categories are classified according to the available prior knowledge. A data-based filter is installed for predictive data refinement. Extensive experimental studies on both synthetic and real-world networks, including directed and undirected as well as weighted and unweighted topologies, verify the effectiveness of mCNN-RP. The results demonstrate that the average prediction error is lower than the standard deviation of the tested data, which outperforms the single CNN-based framework. The runtime in assessing network connectivity robustness is significantly reduced by using the CNN-based technique. The proposed mCNN-RP not only can accurately predict the connectivity robustness of various complex networks, but also provides an excellent indicator for the connectivity robustness, better than other existing prediction measures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004075",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Estimator",
      "Gene",
      "Machine learning",
      "Mathematics",
      "Network topology",
      "Operating system",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Lou",
        "given_name": "Yang"
      },
      {
        "surname": "Wu",
        "given_name": "Ruizi"
      },
      {
        "surname": "Li",
        "given_name": "Junli"
      },
      {
        "surname": "Wang",
        "given_name": "Lin"
      },
      {
        "surname": "Tang",
        "given_name": "Chang-Bing"
      },
      {
        "surname": "Chen",
        "given_name": "Guanrong"
      }
    ]
  },
  {
    "title": "Strictly intermittent quantized control for fixed/predefined-time cluster lag synchronization of stochastic multi-weighted complex networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.033",
    "abstract": "This article addresses the fixed-time (F-T) and predefined-time (P-T) cluster lag synchronization of stochastic multi-weighted complex networks (SMWCNs) via strictly intermittent quantized control (SIQC). Firstly, by exploiting mathematical induction and reduction to absurdity, a novel F-T stability lemma is proved and an accurate estimation of settling time (ST) is obtained. Subsequently, by virtue of the proposed F-T stability, some simple conditions that ensure the F-T cluster lag synchronization of SMWCNs are derived by developing a SIQC strategy. Furthermore, the P-T cluster lag synchronization is also explored based on a SIQC design, where the ST can be predefined by an adjustable constant of the controller. Note that the designed controllers here are simpler and more economical than the traditional design whose the linear part is still activated during the rest interval. Finally, two numerical examples are provided to verify the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004300",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Constant (computer programming)",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Discrete time and continuous time",
      "Ecology",
      "Engineering",
      "Geometry",
      "Lag",
      "Lemma (botany)",
      "Machine learning",
      "Mathematics",
      "Poaceae",
      "Programming language",
      "Reduction (mathematics)",
      "Settling time",
      "Stability (learning theory)",
      "Statistics",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Qin",
        "given_name": "Xuejiao"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      },
      {
        "surname": "Qiu",
        "given_name": "Jianlong"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Ren",
        "given_name": "Yue"
      }
    ]
  },
  {
    "title": "Pinning synchronization of stochastic neutral memristive neural networks with reaction–diffusion terms",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.09.032",
    "abstract": "This paper investigates the pinning synchronization of stochastic neutral memristive neural networks with reaction–diffusion terms. Firstly, two novel pinning controllers, which contain both current state and past state, are designed. Subsequently, in terms of Green’s theorem, inequality technology, stochastic analysis theory and pinning control technology, two easy-to-test sufficient conditions based on algebraic inequalities are obtained to ensure the mean-square asymptotic synchronization of stochastic memristive neural networks with neutral delays and reaction–diffusion terms by providing a new Lyapunov–Krasovskii functional. In addition, some existing results can be regarded as special cases of our work. Finally, illustrative examples further verify the correctness and validity of the derived results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003823",
    "keywords": [
      "Algebraic number",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Correctness",
      "Diffusion",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Recurrent neural network",
      "State (computer science)",
      "Stochastic neural network",
      "Synchronization (alternating current)",
      "Thermodynamics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Xiang"
      },
      {
        "surname": "Liu",
        "given_name": "Shutang"
      },
      {
        "surname": "Wang",
        "given_name": "Huiyu"
      }
    ]
  },
  {
    "title": "Another bumper year",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.020",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004610",
    "keywords": [
      "Artificial intelligence",
      "Computer science"
    ],
    "authors": [
      {
        "surname": "Toyoizumi",
        "given_name": "Taro"
      },
      {
        "surname": "Wang",
        "given_name": "DeLiang"
      }
    ]
  },
  {
    "title": "2 Nature's learning rule: The Hebbian-LMS algorithm",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00012-9",
    "abstract": "Hebbian learning is widely accepted in the fields of psychology, neurology, and neurobiology. It is one of the fundamental premises of neuroscience. The least mean square (LMS) algorithm of Widrow and Hoff is the world's most widely used adaptive algorithm, fundamental in the fields of signal processing, control systems, communication systems, pattern recognition, and artificial neural networks. These learning paradigms are very different. Hebbian learning is unsupervised. LMS learning is supervised. However, a form of LMS can be constructed to perform unsupervised learning and, as such, LMS can be used in a natural way to implement Hebbian learning. Combining the two paradigms creates a new unsupervised learning algorithm, Hebbian-LMS. This algorithm has practical engineering applications and provides insight into learning in living neural networks. A fundamental question is how does learning take place in living neural networks? “Nature's little secret,” the learning algorithm practiced by nature at the neuron and synapse level, may well be the Hebbian-LMS algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000129",
    "keywords": [
      "Adaptive filter",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Competitive learning",
      "Computer science",
      "Generalization error",
      "Hebbian theory",
      "Leabra",
      "Least mean squares filter",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Unsupervised learning",
      "Wake-sleep algorithm"
    ],
    "authors": [
      {
        "surname": "Widrow",
        "given_name": "Bernard"
      },
      {
        "surname": "Kim",
        "given_name": "Youngsik"
      },
      {
        "surname": "Park",
        "given_name": "Dookun"
      },
      {
        "surname": "Perin",
        "given_name": "Jose Krause"
      }
    ]
  },
  {
    "title": "17 Emergence of tool construction and tool use through hierarchical reinforcement learning",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00008-7",
    "abstract": "Tool use and tool construction are important indicators of intelligence and high-level cognition. Various animals have been found to use rudimentary tools, and in limited cases tool construction has been observed. However, humans are by far the most advanced in terms of tool construction and use. Considering the potential impact tools have had on the enhancement of human intelligence and vice versa, understanding the nature of this kind of brain-tool interaction can provide us with key insights on how to build self-improving AI. In this chapter, as a first step, we investigated primitive tool construction and use using deep hierarchical reinforcement learning. The results show that with minimal reward shaping, an agent can learn to construct and use a simple tool. These are primitive results, but we hope they can serve as a steppingstone toward a full-blown tool-intelligence coevolution for open-ended AI.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000087",
    "keywords": [
      "Artificial intelligence",
      "Cognitive science",
      "Computer science",
      "Construct (python library)",
      "Epistemology",
      "Human–computer interaction",
      "Philosophy",
      "Programming language",
      "Psychology",
      "Reinforcement learning",
      "Simple (philosophy)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Qinbo"
      },
      {
        "surname": "Choe",
        "given_name": "Yoonsuck"
      }
    ]
  },
  {
    "title": "Maximum Decentral Projection Margin Classifier for High Dimension and Low Sample Size problems",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.017",
    "abstract": "Compared with relatively easy feature creation or generation in data analysis, manual data labeling needs a lot of time and effort in most cases. Even if automated data labeling​ seems to make it better in some cases, the labeling results still need to be checked and verified by manual. The High Dimension and Low Sample Size (HDLSS) data are therefore very common in data mining and machine learning. For classification problems with the HDLSS data, due to data piling and approximate equidistance between any two input points in high-dimension space, some traditional classifiers often give poor predictive performance. In this paper, we propose a Maximum Decentral Projection Margin Classifier (MDPMC) in the framework of a Support Vector Classifier (SVC). In the MDPMC model, the constraints of maximizing the projection distance between decentralized input points and their supporting hyperplane are integrated into the SVC model in addition to maximizing the margin of two supporting hyperplanes. On ten real HDLSS datasets, the experiment results show that the proposed MDPMC approach can deal well with data piling and approximate equidistance problems. Compared with SVC with Linear Kernel (SVC-LK) and Radial Basis Function Kernel (SVC-RBFK), Distance Weighted Discrimination (DWD), weighted DWD (wDWD), Distance-Weighted Support Vector Machine (DWSVM), Population-Guided Large Margin Classifier (PGLMC), and Data Maximum Dispersion Classifier (DMDC), MDPMC obtains better predictive accuracy and lower classification errors than the other seven classifiers on the HDLSS data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004130",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Data point",
      "Demography",
      "Geometry",
      "Hyperplane",
      "Kernel method",
      "Linear classifier",
      "Machine learning",
      "Margin (machine learning)",
      "Margin classifier",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Population",
      "Quadratic classifier",
      "Sample size determination",
      "Sociology",
      "Statistics",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Zhiwang"
      },
      {
        "surname": "He",
        "given_name": "Jing"
      },
      {
        "surname": "Cao",
        "given_name": "Jie"
      },
      {
        "surname": "Li",
        "given_name": "Shuqing"
      }
    ]
  },
  {
    "title": "Pairwise learning problems with regularization networks and Nyström subsampling approach",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.007",
    "abstract": "Pairwise learning usually refers to the learning problem that works with pairs of training samples, such as ranking, similarity and metric learning, and AUC maximization. To overcome the challenge of pairwise learning in the large scale computation, this paper introduces Nyström sampling approach to the coefficient-based regularized pairwise algorithm in the context of kernel networks. Our theorems establish that the obtained Nyström estimator achieves the minimax error over all estimators using the whole data provided that the subsampling level is not too small. We derive the function relation between the subsampling level and regularization parameter that guarantees computation cost reduction and asymptotic behaviors’ optimality simultaneously. The Nyström coefficient-based pairwise learning method does not require the kernel to be symmetric or positive semi-definite, which provides more flexibility and adaptivity in the learning process. We apply the method to the bipartite ranking problem, which improves the state-of-the-art theoretical results in previous works. By developing probability inequalities for U-statistics on Hilbert–Schmidt operators, we provide new mathematical tools for handling pairs of examples involved in pairwise learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003914",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Computer science",
      "Estimator",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Minimax",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Cheng"
      },
      {
        "surname": "Hu",
        "given_name": "Ting"
      },
      {
        "surname": "Jiang",
        "given_name": "Siyang"
      }
    ]
  },
  {
    "title": "Classification-based prediction of network connectivity robustness",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.013",
    "abstract": "Today, there is an increasing concern about malicious attacks on various networks in society and industry, against which the network robustness is critical. Network connectivity robustness, in particular, is of fundamental importance, which is generally measured by a sequence of calculated values that indicate the connectedness of the remaining network after a sequence of attacks by means of node- or edge-removal. It is computationally time-consuming, however, to measure and evaluate the network connectivity robustness using the conventional attack simulations, especially for large-scale networked systems. In the present paper, an efficient robustness predictor based on multiple convolutional neural networks (mCNN-RP) is proposed for predicting the network connectivity robustness, which is an natural extension of the single CNN-based predictor. In mCNN-RP, one CNN works as the classifier, while each of the rest CNNs works as an estimator for predicting the connectivity robustness of every classified network category. The network categories are classified according to the available prior knowledge. A data-based filter is installed for predictive data refinement. Extensive experimental studies on both synthetic and real-world networks, including directed and undirected as well as weighted and unweighted topologies, verify the effectiveness of mCNN-RP. The results demonstrate that the average prediction error is lower than the standard deviation of the tested data, which outperforms the single CNN-based framework. The runtime in assessing network connectivity robustness is significantly reduced by using the CNN-based technique. The proposed mCNN-RP not only can accurately predict the connectivity robustness of various complex networks, but also provides an excellent indicator for the connectivity robustness, better than other existing prediction measures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004075",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Estimator",
      "Gene",
      "Machine learning",
      "Mathematics",
      "Network topology",
      "Operating system",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Lou",
        "given_name": "Yang"
      },
      {
        "surname": "Wu",
        "given_name": "Ruizi"
      },
      {
        "surname": "Li",
        "given_name": "Junli"
      },
      {
        "surname": "Wang",
        "given_name": "Lin"
      },
      {
        "surname": "Tang",
        "given_name": "Chang-Bing"
      },
      {
        "surname": "Chen",
        "given_name": "Guanrong"
      }
    ]
  },
  {
    "title": "Strictly intermittent quantized control for fixed/predefined-time cluster lag synchronization of stochastic multi-weighted complex networks",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.10.033",
    "abstract": "This article addresses the fixed-time (F-T) and predefined-time (P-T) cluster lag synchronization of stochastic multi-weighted complex networks (SMWCNs) via strictly intermittent quantized control (SIQC). Firstly, by exploiting mathematical induction and reduction to absurdity, a novel F-T stability lemma is proved and an accurate estimation of settling time (ST) is obtained. Subsequently, by virtue of the proposed F-T stability, some simple conditions that ensure the F-T cluster lag synchronization of SMWCNs are derived by developing a SIQC strategy. Furthermore, the P-T cluster lag synchronization is also explored based on a SIQC design, where the ST can be predefined by an adjustable constant of the controller. Note that the designed controllers here are simpler and more economical than the traditional design whose the linear part is still activated during the rest interval. Finally, two numerical examples are provided to verify the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004300",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Constant (computer programming)",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Discrete time and continuous time",
      "Ecology",
      "Engineering",
      "Geometry",
      "Lag",
      "Lemma (botany)",
      "Machine learning",
      "Mathematics",
      "Poaceae",
      "Programming language",
      "Reduction (mathematics)",
      "Settling time",
      "Stability (learning theory)",
      "Statistics",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Qin",
        "given_name": "Xuejiao"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      },
      {
        "surname": "Qiu",
        "given_name": "Jianlong"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Ren",
        "given_name": "Yue"
      }
    ]
  },
  {
    "title": "Pinning synchronization of stochastic neutral memristive neural networks with reaction–diffusion terms",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.09.032",
    "abstract": "This paper investigates the pinning synchronization of stochastic neutral memristive neural networks with reaction–diffusion terms. Firstly, two novel pinning controllers, which contain both current state and past state, are designed. Subsequently, in terms of Green’s theorem, inequality technology, stochastic analysis theory and pinning control technology, two easy-to-test sufficient conditions based on algebraic inequalities are obtained to ensure the mean-square asymptotic synchronization of stochastic memristive neural networks with neutral delays and reaction–diffusion terms by providing a new Lyapunov–Krasovskii functional. In addition, some existing results can be regarded as special cases of our work. Finally, illustrative examples further verify the correctness and validity of the derived results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003823",
    "keywords": [
      "Algebraic number",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Correctness",
      "Diffusion",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Recurrent neural network",
      "State (computer science)",
      "Stochastic neural network",
      "Synchronization (alternating current)",
      "Thermodynamics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Xiang"
      },
      {
        "surname": "Liu",
        "given_name": "Shutang"
      },
      {
        "surname": "Wang",
        "given_name": "Huiyu"
      }
    ]
  },
  {
    "title": "Another bumper year",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.020",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004610",
    "keywords": [
      "Artificial intelligence",
      "Computer science"
    ],
    "authors": [
      {
        "surname": "Toyoizumi",
        "given_name": "Taro"
      },
      {
        "surname": "Wang",
        "given_name": "DeLiang"
      }
    ]
  },
  {
    "title": "Meta-HGT: Metapath-aware HyperGraph Transformer for heterogeneous information network embedding",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.08.028",
    "abstract": "Heterogeneous information network embedding aims to learn low-dimensional node vectors in heterogeneous information networks (HINs), concerning not only structural information but also heterogeneity of diverse node and relation types. Most existing HIN embedding models mainly rely on metapath to define composite relations between node pairs and thus extract substructures from the original HIN. However, due to the pairwise structure of metapath, these models fail to capture the high-order relations (such as “Multiple authors co-authoring a paper”) implicitly contained in HINs. To tackle the limitation, this paper proposes a Metapath-aware HyperGraph Transformer (Meta-HGT) for node embedding in HINs. Meta-HGT first extends metapath to guide the high-order relation extraction from original HIN and constructs multiple metapath based hypergraphs with diverse composite semantics. Then, Meta-HGT learns the latent node and hyperedge embeddings in each metapath based hypergraph through Meta-HGT layers. Each layer consists of two types of components, i.e., intra-hyperedge aggregation and inter-hyperedge aggregation, in which a novel type-dependent attention mechanism is proposed for node and hyperedge feature aggregation. Finally, it fuses multiple node embeddings learned from different metapath based hypergraphs via a semantic attention layer and generates the final node embeddings. Extensive experiments have been conducted on three HIN benchmarks for node classification. The results demonstrate that Meta-HGT achieves state-of-the-art performance on all three datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003288",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Discrete mathematics",
      "Embedding",
      "Engineering",
      "Hypergraph",
      "Mathematics",
      "Node (physics)",
      "Pairwise comparison",
      "Relation (database)",
      "Relationship extraction",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Jie"
      },
      {
        "surname": "Song",
        "given_name": "Lingyun"
      },
      {
        "surname": "Wang",
        "given_name": "Guangtao"
      },
      {
        "surname": "Shang",
        "given_name": "Xuequn"
      }
    ]
  },
  {
    "title": "Attention-enabled gated spiking neural P model for aspect-level sentiment classification",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.006",
    "abstract": "Gated spiking neural P (GSNP) model is a recently developed recurrent-like network, which is abstracted by nonlinear spiking mechanism of nonlinear spiking neural P systems. In this study, a modification of GSNP is combined with attention mechanism to develop a novel model for sentiment classification, called attention-enabled GSNP model or termed as AGSNP model. The AGSNP model has two channels that process content words and aspect item respectively, where two modified GSNPs are used to obtain dependencies between content words and between aspect words. Moreover, two attention components are used to establish semantic correlation between content words and aspect item. Comparative experiments on three real data sets and several baseline models are conducted to verify the effectiveness of the AGSNP model. The comparison results demonstrate that the AGSNP model is competent for aspect-level sentiment classification tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004464",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Epistemology",
      "Machine learning",
      "Mechanism (biology)",
      "Nonlinear system",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Process (computing)",
      "Quantum mechanics",
      "Sentiment analysis",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Yanping"
      },
      {
        "surname": "Peng",
        "given_name": "Hong"
      },
      {
        "surname": "Liu",
        "given_name": "Qian"
      },
      {
        "surname": "Yang",
        "given_name": "Qian"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Orellana-Martín",
        "given_name": "David"
      },
      {
        "surname": "Pérez-Jiménez",
        "given_name": "Mario J."
      }
    ]
  },
  {
    "title": "Multi-graph Fusion Graph Convolutional Networks with pseudo-label supervision",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.027",
    "abstract": "Graph convolutional networks (GCNs) have become a popular tool for learning unstructured graph data due to their powerful learning ability. Many researchers have been interested in fusing topological structures and node features to extract the correlation information for classification tasks. However, it is inadequate to integrate the embedding from topology and feature spaces to gain the most correlated information. At the same time, most GCN-based methods assume that the topology graph or feature graph is compatible with the properties of GCNs, but this is usually not satisfied since meaningless, missing, or even unreal edges are very common in actual graphs. To obtain a more robust and accurate graph structure, we intend to construct an adaptive graph with topology and feature graphs. We propose Multi-graph Fusion Graph Convolutional Networks with pseudo-label supervision (MFGCN), which learn a connected embedding by fusing the multi-graphs and node features. We can obtain the final node embedding for semi-supervised node classification by propagating node features over multi-graphs. Furthermore, to alleviate the problem of labels missing in semi-supervised classification, a pseudo-label generation mechanism is proposed to generate more reliable pseudo-labels based on the similarity of node features. Extensive experiments on six benchmark datasets demonstrate the superiority of MFGCN over state-of-the-art classification methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004683",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Embedding",
      "Feature learning",
      "Graph",
      "Graph embedding",
      "Graph isomorphism",
      "Line graph",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Theoretical computer science",
      "Topological graph theory",
      "Topology (electrical circuits)",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yachao"
      },
      {
        "surname": "Sun",
        "given_name": "Yanfeng"
      },
      {
        "surname": "Ju",
        "given_name": "Fujiao"
      },
      {
        "surname": "Wang",
        "given_name": "Shaofan"
      },
      {
        "surname": "Gao",
        "given_name": "Junbin"
      },
      {
        "surname": "Yin",
        "given_name": "Baocai"
      }
    ]
  },
  {
    "title": "A unified deep semi-supervised graph learning scheme based on nodes re-weighting and manifold regularization",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.017",
    "abstract": "In recent years, semi-supervised learning on graphs has gained importance in many fields and applications. The goal is to use both partially labeled data (labeled examples) and a large amount of unlabeled data to build more effective predictive models. Deep Graph Neural Networks (GNNs) are very useful in both unsupervised and semi-supervised learning problems. As a special class of GNNs, Graph Convolutional Networks (GCNs) aim to obtain data representation through graph-based node smoothing and layer-wise neural network transformations. However, GCNs have some weaknesses when applied to semi-supervised graph learning: (1) it ignores the manifold structure implicitly encoded by the graph; (2) it uses a fixed neighborhood graph and focuses only on the convolution of a graph, but pays little attention to graph construction; (3) it rarely considers the problem of topological imbalance. To overcome the above shortcomings, in this paper, we propose a novel semi-supervised learning method called Re-weight Nodes and Graph Learning Convolutional Network with Manifold Regularization (ReNode-GLCNMR). Our proposed method simultaneously integrates graph learning and graph convolution into a unified network architecture, which also enforces label smoothing through an unsupervised loss term. At the same time, it addresses the problem of imbalance in graph topology by adaptively reweighting the influence of labeled nodes based on their distances to the class boundaries. Experiments on 8 benchmark datasets show that ReNode-GLCNMR significantly outperforms the state-of-the-art semi-supervised GNN methods. 1 1 The code is available at https://github.com/BiJingjun/ReNode-GLCNMR.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004580",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Graph",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Semi-supervised learning",
      "Smoothing",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Dornaika",
        "given_name": "Fadi"
      },
      {
        "surname": "Bi",
        "given_name": "Jingjun"
      },
      {
        "surname": "Zhang",
        "given_name": "Chongsheng"
      }
    ]
  },
  {
    "title": "9 Pitfalls and opportunities in the development and evaluation of artificial intelligence systems",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.00017-8",
    "abstract": "We provide a somewhat whimsical and copiously illustrated overview of what we have learned from laboring to curb the enthusiasm of artificial intelligence (AI) algorithm developers with the cold reality of AI systems evaluation. This has become all the more necessary in view of the incredible progress being made in the computational intelligence community using deep learning methods to address real-world problems. Good development practices and reliable evaluation methodology ensure good applications. We stress the receiver operating characteristic (ROC) paradigm, but note the broad range of performance metrics that go beyond the simple calculation of success rate or accuracy on a limited test set. Both parametric and nonparametric uncertainty calculation techniques will be mentioned, with emphasis on bootstrap methodology. We discuss the gamut of conflicting problems that contribute to error and overestimation of the validity of modern computational intelligence algorithms and suggest potential solutions to encourage their successful implementation.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042000178",
    "keywords": [
      "Aerospace engineering",
      "Artificial intelligence",
      "Computer science",
      "Data science",
      "Engineering",
      "Enthusiasm",
      "Epistemology",
      "Machine learning",
      "Management science",
      "Mathematics",
      "Nonparametric statistics",
      "Parametric statistics",
      "Philosophy",
      "Programming language",
      "Psychology",
      "Range (aeronautics)",
      "Set (abstract data type)",
      "Simple (philosophy)",
      "Social psychology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Brown",
        "given_name": "David G."
      },
      {
        "surname": "Samuelson",
        "given_name": "Frank W."
      }
    ]
  },
  {
    "title": "A singular Riemannian geometry approach to Deep Neural Networks I. Theoretical foundations",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.022",
    "abstract": "Deep Neural Networks are widely used for solving complex problems in several scientific areas, such as speech recognition, machine translation, image analysis. The strategies employed to investigate their theoretical properties mainly rely on Euclidean geometry, but in the last years new approaches based on Riemannian geometry have been developed. Motivated by some open problems, we study a particular sequence of maps between manifolds, with the last manifold of the sequence equipped with a Riemannian metric. We investigate the structures induced through pullbacks on the other manifolds of the sequence and on some related quotients. In particular, we show that the pullbacks of the final Riemannian metric to any manifolds of the sequence is a degenerate Riemannian metric inducing a structure of pseudometric space. We prove that the Kolmogorov quotient of this pseudometric space yields a smooth manifold, which is the base space of a particular vertical bundle. We investigate the theoretical properties of the maps of such sequence, eventually we focus on the case of maps between manifolds implementing neural networks of practical interest and we present some applications of the geometric framework we introduced in the first part of the paper.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004634",
    "keywords": [
      "Algebra over a field",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Curvature",
      "Economics",
      "Engineering",
      "Euclidean space",
      "Genetics",
      "Geometry",
      "Information geometry",
      "Manifold (fluid mechanics)",
      "Mathematics",
      "Mechanical engineering",
      "Metric (unit)",
      "Operating system",
      "Operations management",
      "Pure mathematics",
      "Riemannian geometry",
      "Riemannian manifold",
      "Scalar curvature",
      "Sequence (biology)",
      "Space (punctuation)",
      "Statistical manifold",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Benfenati",
        "given_name": "Alessandro"
      },
      {
        "surname": "Marta",
        "given_name": "Alessio"
      }
    ]
  },
  {
    "title": "A fractional gradient descent algorithm robust to the initial weights of multilayer perceptron",
    "journal": "Neural Networks",
    "year": "2023",
    "doi": "10.1016/j.neunet.2022.11.018",
    "abstract": "For multilayer perceptron (MLP), the initial weights will significantly influence its performance. Based on the enhanced fractional derivative extend from convex optimization, this paper proposes a fractional gradient descent (RFGD) algorithm robust to the initial weights of MLP. We analyze the effectiveness of the RFGD algorithm. The convergence of the RFGD algorithm is also analyzed. The computational complexity of the RFGD algorithm is generally larger than that of the gradient descent (GD) algorithm but smaller than that of the Adam, Padam, AdaBelief, and AdaDiff algorithms. Numerical experiments show that the RFGD algorithm has strong robustness to the order of fractional calculus which is the only added parameter compared to the GD algorithm. More importantly, compared to the GD, Adam, Padam, AdaBelief, and AdaDiff algorithms, the experimental results show that the RFGD algorithm has the best robust performance for the initial weights of MLP. Meanwhile, the correctness of the theoretical analysis is verified.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022004592",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Asynchronous communication",
      "Biochemistry",
      "Broyden–Fletcher–Goldfarb–Shanno algorithm",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Convergence (economics)",
      "Correctness",
      "Economic growth",
      "Economics",
      "Gene",
      "Gradient descent",
      "Mathematics",
      "Multilayer perceptron",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Xuetao"
      },
      {
        "surname": "Pu",
        "given_name": "Yi-Fei"
      },
      {
        "surname": "Wang",
        "given_name": "Jian"
      }
    ]
  },
  {
    "title": "Introduction",
    "journal": "Artificial Intelligence in the Age of Neural Networks and Brain Computing",
    "year": "2024",
    "doi": "10.1016/B978-0-323-96104-2.09988-7",
    "abstract": "Unknown",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780323961042099887",
    "keywords": [
      "Computer science"
    ],
    "authors": []
  }
]