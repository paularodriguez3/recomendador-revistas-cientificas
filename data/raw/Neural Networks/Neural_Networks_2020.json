[
  {
    "title": "Comparing SNNs and RNNs on neuromorphic vision datasets: Similarities and differences",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.001",
    "abstract": "Neuromorphic data, recording frameless spike events, have attracted considerable attention for the spatiotemporal information components and the event-driven processing fashion. Spiking neural networks (SNNs) represent a family of event-driven models with spatiotemporal dynamics for neuromorphic computing, which are widely benchmarked on neuromorphic data. Interestingly, researchers in the machine learning community can argue that recurrent (artificial) neural networks (RNNs) also have the capability to extract spatiotemporal features although they are not event-driven. Thus, the question of “what will happen if we benchmark these two kinds of models together on neuromorphic data” comes out but remains unclear. In this work, we make a systematic study to compare SNNs and RNNs on neuromorphic data, taking the vision datasets as a case study. First, we identify the similarities and differences between SNNs and RNNs (including the vanilla RNNs and LSTM) from the modeling and learning perspectives. To improve comparability and fairness, we unify the supervised learning algorithm based on backpropagation through time (BPTT), the loss function exploiting the outputs at all timesteps, the network structure with stacked fully-connected or convolutional layers, and the hyper-parameters during training. Especially, given the mainstream loss function used in RNNs, we modify it inspired by the rate coding scheme to approach that of SNNs. Furthermore, we tune the temporal resolution of datasets to test model robustness and generalization. At last, a series of contrast experiments are conducted on two types of neuromorphic datasets: DVS-converted (N-MNIST) and DVS-captured (DVS Gesture). Extensive insights regarding recognition accuracy, feature extraction, temporal resolution and contrast, learning generalization, computational complexity and parameter volume are provided, which are beneficial for the model selection on different workloads and even for the invention of novel neural models in the future.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302902",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Machine learning",
      "Neuromorphic engineering",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Weihua"
      },
      {
        "surname": "Wu",
        "given_name": "YuJie"
      },
      {
        "surname": "Deng",
        "given_name": "Lei"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      },
      {
        "surname": "Wang",
        "given_name": "Haoyu"
      },
      {
        "surname": "Tian",
        "given_name": "Yang"
      },
      {
        "surname": "Ding",
        "given_name": "Wei"
      },
      {
        "surname": "Wang",
        "given_name": "Wenhui"
      },
      {
        "surname": "Xie",
        "given_name": "Yuan"
      }
    ]
  },
  {
    "title": "Hybrid tensor decomposition in neural network compression",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.006",
    "abstract": "Deep neural networks (DNNs) have enabled impressive breakthroughs in various artificial intelligence (AI) applications recently due to its capability of learning high-level features from big data. However, the current demand of DNNs for computational resources especially the storage consumption is growing due to that the increasing sizes of models are being required for more and more complicated applications. To address this problem, several tensor decomposition methods including tensor-train (TT) and tensor-ring (TR) have been applied to compress DNNs and shown considerable compression effectiveness. In this work, we introduce the hierarchical Tucker (HT), a classical but rarely-used tensor decomposition method, to investigate its capability in neural network compression. We convert the weight matrices and convolutional kernels to both HT and TT formats for comparative study, since the latter is the most widely used decomposition method and the variant of HT. We further theoretically and experimentally discover that the HT format has better performance on compressing weight matrices, while the TT format is more suited for compressing convolutional kernels. Based on this phenomenon we propose a strategy of hybrid tensor decomposition by combining TT and HT together to compress convolutional and fully connected parts separately and attain better accuracy than only using the TT or HT format on convolutional neural networks (CNNs). Our work illuminates the prospects of hybrid tensor decomposition for neural network compression.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303294",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Composite material",
      "Compression (physics)",
      "Computer science",
      "Convolutional neural network",
      "Data compression",
      "Decomposition",
      "Ecology",
      "Materials science",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Pure mathematics",
      "Tensor (intrinsic definition)",
      "Tensor decomposition",
      "Tucker decomposition"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Bijiao"
      },
      {
        "surname": "Wang",
        "given_name": "Dingheng"
      },
      {
        "surname": "Zhao",
        "given_name": "Guangshe"
      },
      {
        "surname": "Deng",
        "given_name": "Lei"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      }
    ]
  },
  {
    "title": "Exploiting bi-directional global transition patterns and personal preferences for missing POI category identification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.015",
    "abstract": "Recent years have witnessed the increasing popularity of Location-based Social Network (LBSN) services, which provides unparalleled opportunities to build personalized Point-of-Interest (POI) recommender systems. Existing POI recommendation and location prediction tasks utilize past information for future recommendation or prediction from a single direction perspective, while the missing POI category identification task needs to utilize the check-in information both before and after the missing category. Therefore, a long-standing challenge is how to effectively identify the missing POI categories at any time in the real-world check-in data of mobile users. To this end, in this paper, we propose a novel neural network approach to identify the missing POI categories by integrating both bi-directional global non-personal transition patterns and personal preferences of users. Specifically, we delicately design an attention matching cell to model how well the check-in category information matches their non-personal transition patterns and personal preferences. Finally, we evaluate our model on two real-world datasets, which clearly validate its effectiveness compared with the state-of-the-art baselines. Furthermore, our model can be naturally extended to address next POI category recommendation and prediction tasks with competitive performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030304X",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Computer science",
      "Computer security",
      "Data mining",
      "Data science",
      "Geometry",
      "Identification (biology)",
      "Information retrieval",
      "Machine learning",
      "Matching (statistics)",
      "Mathematics",
      "Missing data",
      "Personally identifiable information",
      "Perspective (graphical)",
      "Point (geometry)",
      "Point of interest",
      "Popularity",
      "Psychology",
      "Recommender system",
      "Social psychology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Xi",
        "given_name": "Dongbo"
      },
      {
        "surname": "Zhuang",
        "given_name": "Fuzhen"
      },
      {
        "surname": "Liu",
        "given_name": "Yanchi"
      },
      {
        "surname": "Zhu",
        "given_name": "Hengshu"
      },
      {
        "surname": "Zhao",
        "given_name": "Pengpeng"
      },
      {
        "surname": "Tan",
        "given_name": "Chang"
      },
      {
        "surname": "He",
        "given_name": "Qing"
      }
    ]
  },
  {
    "title": "On the robustness of skeleton detection against adversarial attacks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.018",
    "abstract": "Human perception of an object’s skeletal structure is particularly robust to diverse perturbations of shape. This skeleton representation possesses substantial advantages for parts-based and invariant shape encoding, which is essential for object recognition. Multiple deep learning-based skeleton detection models have been proposed, while their robustness to adversarial attacks remains unclear. (1) This paper is the first work to study the robustness of deep learning-based skeleton detection against adversarial attacks, which are only slightly unlike the original data but still imperceptible to humans. We systematically analyze the robustness of skeleton detection models through exhaustive adversarial attacking experiments. (2) We propose a novel Frequency attack, which can directly exploit the regular and interpretable perturbations to sharply disrupt skeleton detection models. Frequency attack consists of an excitatory-inhibition waveform with high frequency attribution, which confuses edge-sensitive convolutional filters due to the sudden contrast between crests and troughs. Our comprehensive results verify that skeleton detection models are also vulnerable to adversarial attacks. The meaningful findings will inspire researchers to explore more potential robust models by involving explicit skeleton features.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303415",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Exploit",
      "Gene",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Programming language",
      "Robustness (evolution)",
      "Skeleton (computer programming)"
    ],
    "authors": [
      {
        "surname": "Bai",
        "given_name": "Xiuxiu"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      },
      {
        "surname": "Liu",
        "given_name": "Zhe"
      }
    ]
  },
  {
    "title": "MGAT: Multi-view Graph Attention Networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.021",
    "abstract": "Multi-view graph embedding is aimed at learning low-dimensional representations of nodes that capture various relationships in a multi-view network, where each view represents a type of relationship among nodes. Multitudes of existing graph embedding approaches concentrate on single-view networks, that can only characterize one simple type of proximity relationships among objects. However, most of the real-world complex systems possess multiple types of relationships among entities. In this paper, a novel approach of graph embedding for multi-view networks is proposed, named Multi-view Graph Attention Networks (MGAT). We explore an attention-based architecture for learning node representations from each single view, the network parameters of which are constrained by a novel regularization term. In order to collaboratively integrate multiple types of relationships in different views, a view-focused attention method is explored to aggregate the view-wise node representations. We evaluate the proposed algorithm on several real-world datasets, and it demonstrates that the proposed approach outperforms existing state-of-the-art baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303105",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Embedding",
      "Graph",
      "Graph embedding",
      "Machine learning",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Yu"
      },
      {
        "surname": "Zhang",
        "given_name": "Yuanqiao"
      },
      {
        "surname": "Gong",
        "given_name": "Maoguo"
      },
      {
        "surname": "Tang",
        "given_name": "Zedong"
      },
      {
        "surname": "Han",
        "given_name": "Chao"
      }
    ]
  },
  {
    "title": "SympNets: Intrinsic structure-preserving symplectic networks for identifying Hamiltonian systems",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.017",
    "abstract": "We propose new symplectic networks (SympNets) for identifying Hamiltonian systems from data based on a composition of linear, activation and gradient modules. In particular, we define two classes of SympNets: the LA-SympNets composed of linear and activation modules, and the G-SympNets composed of gradient modules. Correspondingly, we prove two new universal approximation theorems that demonstrate that SympNets can approximate arbitrary symplectic maps based on appropriate activation functions. We then perform several experiments including the pendulum, double pendulum and three-body problems to investigate the expressivity and the generalization ability of SympNets. The simulation results show that even very small size SympNets can generalize well, and are able to handle both separable and non-separable Hamiltonian systems with data points resulting from short or long time steps. In all the test cases, SympNets outperform the baseline models, and are much faster in training and prediction. We also develop an extended version of SympNets to learn the dynamics from irregularly sampled data. This extended version of SympNets can be thought of as a universal model representing the solution to an arbitrary Hamiltonian system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303063",
    "keywords": [
      "Applied mathematics",
      "Computer science",
      "Generalization",
      "Hamiltonian (control theory)",
      "Hamiltonian system",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Pure mathematics",
      "Separable space",
      "Symplectic geometry"
    ],
    "authors": [
      {
        "surname": "Jin",
        "given_name": "Pengzhan"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhen"
      },
      {
        "surname": "Zhu",
        "given_name": "Aiqing"
      },
      {
        "surname": "Tang",
        "given_name": "Yifa"
      },
      {
        "surname": "Karniadakis",
        "given_name": "George Em"
      }
    ]
  },
  {
    "title": "High-content image generation for drug discovery using generative adversarial networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.007",
    "abstract": "Immense amount of high-content image data generated in drug discovery screening requires computationally driven automated analysis. Emergence of advanced machine learning algorithms, like deep learning models, has transformed the interpretation and analysis of imaging data. However, deep learning methods generally require large number of high-quality data samples, which could be limited during preclinical investigations. To address this issue, we propose a generative modeling based computational framework to synthesize images, which can be used for phenotypic profiling of perturbations induced by drug compounds. We investigated the use of three variants of Generative Adversarial Network (GAN) in our framework, viz., a basic Vanilla GAN, Deep Convolutional GAN (DCGAN) and Progressive GAN (ProGAN), and found DCGAN to be most efficient in generating realistic synthetic images. A pre-trained convolutional neural network (CNN) was used to extract features of both real and synthetic images, followed by a classification model trained on real and synthetic images. The quality of synthesized images was evaluated by comparing their feature distributions with that of real images. The DCGAN-based framework was applied to high-content image data from a drug screen to synthesize high-quality cellular images, which were used to augment the real image data. The augmented dataset was shown to yield better classification performance compared with that obtained using only real images. We also demonstrated the application of proposed method on the generation of bacterial images and computed feature distributions for bacterial images specific to different drug treatments. In summary, our results showed that the proposed DCGAN-based framework can be utilized to generate realistic synthetic high-content images, thus enabling the study of drug-induced effects on cells and bacteria.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303300",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Cell",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Feature (linguistics)",
      "Generative adversarial network",
      "Generative grammar",
      "Generative model",
      "Genetics",
      "High-content screening",
      "Image (mathematics)",
      "Linguistics",
      "Machine learning",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Profiling (computer programming)"
    ],
    "authors": [
      {
        "surname": "Hussain",
        "given_name": "Shaista"
      },
      {
        "surname": "Anees",
        "given_name": "Ayesha"
      },
      {
        "surname": "Das",
        "given_name": "Ankit"
      },
      {
        "surname": "Nguyen",
        "given_name": "Binh P."
      },
      {
        "surname": "Marzuki",
        "given_name": "Mardiana"
      },
      {
        "surname": "Lin",
        "given_name": "Shuping"
      },
      {
        "surname": "Wright",
        "given_name": "Graham"
      },
      {
        "surname": "Singhal",
        "given_name": "Amit"
      }
    ]
  },
  {
    "title": "Unsupervised spectral mapping and feature selection for hyperspectral anomaly detection",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.010",
    "abstract": "Exploring techniques that breakthrough the unknown space or material species is of considerable significance to military and civilian fields, and it is a challenging task without any prior information. Nowadays, the use of material-specific spectral information to detect unknowns has received increasing interest. However, affected by noise and interference, high-dimensional hyperspectral anomaly detection is difficult to meet the requirements of high detection accuracy and low false alarm rate. Besides, there is a problem of insufficient and unbalanced samples. To address these problems, we propose a novel hyperspectral anomaly detection framework based on spectral mapping and feature selection (SMFS) in an unsupervised manner. The SMFS introduces the essential properties of hyperspectral data into an unsupervised neural network to construct the nonlinear mapping relationship from high-dimensional spectral space to low-dimensional deep feature space. And it searches the optimal feature subset from the candidate feature space for standing out anomalies. Because of the compelling characterization of the encoder, we develop it specifically for spectral signatures to reveal the hidden data. Quantitative and qualitative experiments on real hyperspectral datasets indicate that the proposed method can provide the compact features overcoming the problems of noise, interference, redundancy and time-consuming caused by high-dimensionality and limited samples. And it has advantages over some state-of-the-art competitors concerning detecting anomalies of different scales.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302999",
    "keywords": [
      "Anomaly detection",
      "Artificial intelligence",
      "Computer science",
      "Curse of dimensionality",
      "Data mining",
      "Dimensionality reduction",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature selection",
      "Feature vector",
      "Hyperspectral imaging",
      "Image (mathematics)",
      "Linguistics",
      "Mathematics",
      "Noise (video)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pure mathematics",
      "Redundancy (engineering)",
      "Spectral space"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Weiying"
      },
      {
        "surname": "Li",
        "given_name": "Yunsong"
      },
      {
        "surname": "Lei",
        "given_name": "Jie"
      },
      {
        "surname": "Yang",
        "given_name": "Jian"
      },
      {
        "surname": "Li",
        "given_name": "Jiaojiao"
      },
      {
        "surname": "Jia",
        "given_name": "Xiuping"
      },
      {
        "surname": "Li",
        "given_name": "Zhen"
      }
    ]
  },
  {
    "title": "High-dimensional dynamics of generalization error in neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.022",
    "abstract": "We perform an analysis of the average generalization dynamics of large neural networks trained using gradient descent. We study the practically-relevant “high-dimensional” regime where the number of free parameters in the network is on the order of or even larger than the number of examples in the dataset. Using random matrix theory and exact solutions in linear models, we derive the generalization error and training error dynamics of learning and analyze how they depend on the dimensionality of data and signal to noise ratio of the learning problem. We find that the dynamics of gradient descent learning naturally protect against overtraining and overfitting in large networks. Overtraining is worst at intermediate network sizes, when the effective number of free parameters equals the number of samples, and thus can be reduced by making a network smaller or larger. Additionally, in the high-dimensional regime, low generalization error requires starting with small initial weights. We then turn to non-linear neural networks, and show that making networks very large does not harm their generalization performance. On the contrary, it can in fact reduce overtraining, even without early stopping or regularization of any sort. We identify two novel phenomena underlying this behavior in overcomplete models: first, there is a frozen subspace of the weights in which no learning occurs under gradient descent; and second, the statistical properties of the high-dimensional regime yield better-conditioned input correlations which protect against overtraining. We demonstrate that standard application of theories such as Rademacher complexity are inaccurate in predicting the generalization performance of deep neural networks, and derive an alternative bound which incorporates the frozen subspace and conditioning effects and qualitatively matches the behavior observed in simulation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303117",
    "keywords": [],
    "authors": [
      {
        "surname": "Advani",
        "given_name": "Madhu S."
      },
      {
        "surname": "Saxe",
        "given_name": "Andrew M."
      },
      {
        "surname": "Sompolinsky",
        "given_name": "Haim"
      }
    ]
  },
  {
    "title": "Boundary Mittag-Leffler stabilization of fractional reaction–diffusion cellular neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.009",
    "abstract": "Mittag-Leffler stabilization is studied for fractional reaction–diffusion cellular neural networks (FRDCNNs) in this paper. Different from previous literature, the FRDCNNs in this paper are high-dimensional systems, and boundary control and observed-based boundary control are both used to make FRDCNNs achieve Mittag-Leffler stability. First, a state-dependent boundary controller is designed when system states are available. By employing the spatial integral functional method and some inequalities, a criterion ensuring Mittag-Leffler stability of FRDCNNs is presented. Then, when the information of system states is not fully accessible, an observer is presented to estimate the system states based on boundary output and an observer-based boundary controller is provided aiming to stabilize the considered FRDCNNs. Furthermore, a robust observer-based boundary controller is proposed to ensure the Mittag-Leffler stability for FRDCNNs with uncertainties. Examples are given to illustrate the effectiveness of obtained theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303324",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Boundary (topology)",
      "Boundary value problem",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Observer (physics)",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "State (computer science)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Xiao-Zhen"
      },
      {
        "surname": "Li",
        "given_name": "Ze-Tao"
      },
      {
        "surname": "Wu",
        "given_name": "Kai-Ning"
      }
    ]
  },
  {
    "title": "Improved dual-scale residual network for image super-resolution",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.008",
    "abstract": "In recent years, convolutional neural networks have been successfully applied to single image super-resolution (SISR) tasks, making breakthrough progress both in accuracy and speed. In this work, an improved dual-scale residual network (IDSRN), achieving promising reconstruction performance without sacrificing too much calculations, is proposed for SISR. The proposed network extracts features through two independent parallel branches: dual-scale feature extraction branch and texture attention branch. The improved dual-scale residual block (IDSRB) combined with active weighted mapping strategy constitutes the dual-scale feature extraction branch, which aims to capture dual-scale features of the image. As regards the texture attention branch, an encoder–decoder network employing symmetric full convolutional-deconvolution structure acts as a feature selector to enhance the high-frequency details. The integration of two branches reaches the goal of capturing dual-scale features with high-frequency information. Comparative experiments and extensive studies indicate that the proposed IDSRN can catch up with the state-of-the-art approaches in terms of accuracy and efficiency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302975",
    "keywords": [
      "Algorithm",
      "Art",
      "Artificial intelligence",
      "Block (permutation group theory)",
      "Computer science",
      "Convolutional neural network",
      "Deconvolution",
      "Dual (grammatical number)",
      "Encoder",
      "Feature (linguistics)",
      "Feature extraction",
      "Geometry",
      "Image (mathematics)",
      "Linguistics",
      "Literature",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Residual",
      "Scale (ratio)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Huan"
      },
      {
        "surname": "Cao",
        "given_name": "Feilong"
      }
    ]
  },
  {
    "title": "Learning image features with fewer labels using a semi-supervised deep convolutional network",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.016",
    "abstract": "Learning feature embeddings for pattern recognition is a relevant task for many applications. Deep learning methods such as convolutional neural networks can be employed for this assignment with different training strategies: leveraging pre-trained models as baselines; training from scratch with the target dataset; or fine-tuning from the pre-trained model. Although there are separate systems used for learning features from labelled and unlabelled data, there are few models combining all available information. Therefore, in this paper, we present a novel semi-supervised deep network training strategy that comprises a convolutional network and an autoencoder using a joint classification and reconstruction loss function. We show our network improves the learned feature embedding when including the unlabelled data in the training process. The results using the feature embedding obtained by our network achieve better classification accuracy when compared with competing methods, as well as offering good generalisation in the context of transfer learning. Furthermore, the proposed network ensemble and loss function is highly extensible and applicable in many recognition tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303051",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Convolutional neural network",
      "Deep learning",
      "Embedding",
      "Feature (linguistics)",
      "Feature learning",
      "Linguistics",
      "Machine learning",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "dos Santos",
        "given_name": "Fernando P."
      },
      {
        "surname": "Zor",
        "given_name": "Cemre"
      },
      {
        "surname": "Kittler",
        "given_name": "Josef"
      },
      {
        "surname": "Ponti",
        "given_name": "Moacir A."
      }
    ]
  },
  {
    "title": "Analysis of the transferability and robustness of GANs evolved for Pareto set approximations",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.003",
    "abstract": "The generative adversarial network (GAN) is a good example of a strong-performing, neural network-based generative model, even though it does have some drawbacks of its own. Mode collapsing and the difficulty in finding the optimal network structure are two of the most concerning issues. In this paper, we address these two issues at the same time by proposing a neuro-evolutionary approach with an agile evaluation method for the fast evolution of robust deep architectures that avoid mode collapsing. The computation of Pareto set approximations with GANs is chosen as a suitable benchmark to evaluate the quality of our approach. Furthermore, we demonstrate the consistency, scalability, and generalization capabilities of the proposed method, which shows its potential applications to many areas. We finally readdress the issue of designing this kind of models by analyzing the characteristics of the best performing GAN specifications, and conclude with a set of general guidelines. This results in a reduction of the many-dimensional problem of structural manual design or automated search.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303269",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biochemistry",
      "Chemistry",
      "Computation",
      "Computer science",
      "Consistency (knowledge bases)",
      "Database",
      "Gene",
      "Generalization",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Pareto principle",
      "Programming language",
      "Robustness (evolution)",
      "Scalability",
      "Set (abstract data type)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Garciarena",
        "given_name": "Unai"
      },
      {
        "surname": "Mendiburu",
        "given_name": "Alexander"
      },
      {
        "surname": "Santana",
        "given_name": "Roberto"
      }
    ]
  },
  {
    "title": "Multi-label zero-shot learning with graph convolutional networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.010",
    "abstract": "The goal of zero-shot learning (ZSL) is to build a classifier that recognizes novel categories with no corresponding annotated training data. The typical routine is to transfer knowledge from seen classes to unseen ones by learning a visual-semantic embedding. Existing multi-label zero-shot learning approaches either ignore correlations among labels, suffer from large label combinations, or learn the embedding using only local or global visual features. In this paper, we propose a Graph Convolution Networks based Multi-label Zero-Shot Learning model, abbreviated as MZSL-GCN. Our model first constructs a label relation graph using label co-occurrences and compensates the absence of unseen labels in the training phase by semantic similarity. It then takes the graph and the word embedding of each seen (unseen) label as inputs to the GCN to learn the label semantic embedding, and to obtain a set of inter-dependent object classifiers. MZSL-GCN simultaneously trains another attention network to learn compatible local and global visual features of objects with respect to the classifiers, and thus makes the whole network end-to-end trainable. In addition, the use of unlabeled training data can reduce the bias toward seen labels and boost the generalization ability. Experimental results on benchmark datasets show that our MZSL-GCN competes with state-of-the-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303336",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Embedding",
      "Graph",
      "Machine learning",
      "Multi-label classification",
      "Pattern recognition (psychology)",
      "Theoretical computer science",
      "Training set"
    ],
    "authors": [
      {
        "surname": "Ou",
        "given_name": "Guangjin"
      },
      {
        "surname": "Yu",
        "given_name": "Guoxian"
      },
      {
        "surname": "Domeniconi",
        "given_name": "Carlotta"
      },
      {
        "surname": "Lu",
        "given_name": "Xuequan"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiangliang"
      }
    ]
  },
  {
    "title": "Neurodynamical classifiers with low model complexity",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.013",
    "abstract": "The recently proposed Minimal Complexity Machine (MCM) finds a hyperplane classifier by minimizing an upper bound on the Vapnik–Chervonenkis (VC) dimension. The VC dimension measures the capacity or model complexity of a learning machine. Vapnik’s risk formula indicates that models with smaller VC dimension are expected to show improved generalization. On many benchmark datasets, the MCM generalizes better than SVMs and uses far fewer support vectors than the number used by SVMs. In this paper, we describe a neural network that converges to the MCM solution. We employ the MCM neurodynamical system as the final layer of a neural network architecture. Our approach also optimizes the weights of all layers in order to minimize the objective, which is a combination of a bound on the VC dimension and the classification error. We illustrate the use of this model for robust binary and multi-class classification. Numerical experiments on benchmark datasets from the UCI repository show that the proposed approach is scalable and accurate, and learns models with improved accuracies and fewer support vectors.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303026",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Machine learning"
    ],
    "authors": [
      {
        "surname": "Pant",
        "given_name": "Himanshu"
      },
      {
        "surname": "Soman",
        "given_name": "Sumit"
      },
      {
        "surname": "Jayadeva",
        "given_name": ""
      },
      {
        "surname": "Bhaya",
        "given_name": "Amit"
      }
    ]
  },
  {
    "title": "Event-triggered impulsive synchronization of discrete-time coupled neural networks with stochastic perturbations and multiple delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.012",
    "abstract": "This paper deals with the synchronization for discrete-time coupled neural networks (DTCNNs), in which stochastic perturbations and multiple delays are simultaneously involved. The multiple delays mean that both discrete time-varying delays and distributed delays are included. Time-triggered impulsive control (TTIC) is proposed to investigate the synchronization issue of the DTCNNs based on the recently proposed impulsive control scheme for continuous neural networks with single time delays. Furthermore, a novel event-triggered impulsive control (ETIC) is designed to further reduce the communication bandwidth. By using linear matrix inequality (LMI) technique and constructing appropriate Lyapunov functions, some sufficient criteria guaranteeing the synchronization of the DTCNNs are obtained. Finally, We propose a simulation example to illustrate the validity and feasibility of the theoretical results obtained.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030335X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Linear matrix inequality",
      "Lyapunov function",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Statistics",
      "Stochastic neural network",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Huiyuan"
      },
      {
        "surname": "Fang",
        "given_name": "Jian-an"
      },
      {
        "surname": "Li",
        "given_name": "Xiaofan"
      },
      {
        "surname": "Rutkowski",
        "given_name": "Leszek"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Deconvolutional neural network for image super-resolution",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.017",
    "abstract": "This study builds a fully deconvolutional neural network (FDNN) and addresses the problem of single image super-resolution (SISR) by using the FDNN. Although SISR using deep neural networks has been a major research focus, the problem of reconstructing a high resolution (HR) image with an FDNN has received little attention. A few recent approaches toward SISR are to embed deconvolution operations into multilayer feedforward neural networks. This paper constructs a deep FDNN for SISR that possesses two remarkable advantages compared to existing SISR approaches. The first improves the network performance without increasing the depth of the network or embedding complex structures. The second replaces all convolution operations with deconvolution operations to implement an effective reconstruction. That is, the proposed FDNN only contains deconvolution layers and learns an end-to-end mapping from low resolution (LR) to HR images. Furthermore, to avoid the oversmoothness of the mean squared error loss, the trained image is treated as a probability distribution, and the Kullback–Leibler divergence is introduced into the final loss function to achieve enhanced recovery. Although the proposed FDNN only has 10 layers, it is successfully evaluated through extensive experiments. Compared with other state-of-the-art methods and deep convolution neural networks with 20 or 30 layers, the proposed FDNN achieves better performance for SISR.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303403",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Deconvolution",
      "Deep learning",
      "Divergence (linguistics)",
      "Embedding",
      "Focus (optics)",
      "Image (mathematics)",
      "Image resolution",
      "Iterative reconstruction",
      "Linguistics",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics"
    ],
    "authors": [
      {
        "surname": "Cao",
        "given_name": "Feilong"
      },
      {
        "surname": "Yao",
        "given_name": "Kaixuan"
      },
      {
        "surname": "Liang",
        "given_name": "Jiye"
      }
    ]
  },
  {
    "title": "An improved Lyapunov functional with application to stability of Cohen–Grossberg neural networks of neutral-type with multiple delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.023",
    "abstract": "The essential objective of this research article is to investigate stability issue of neutral-type Cohen–Grossberg neural networks involving multiple time delays in states of neurons and multiple neutral delays in time derivatives of states of neurons in the network. By exploiting a modified and improved version of a previously introduced Lyapunov functional, a new sufficient stability criterion is obtained for global asymptotic stability of Cohen–Grossberg neural networks of neutral-type possessing multiple delays. The proposed new stability condition does not involve the time and neutral delay parameters. The obtained stability criterion is totally dependent on the system elements of Cohen–Grossberg neural network model. Moreover, the validity of this novel global asymptotic stability condition may be tested by only checking simple appropriate algebraic equations established within the parameters of the considered neutral-type neural network. In addition, an instructive numerical example is presented to indicate the advantages of our proposed stability result over the existing literature results obtained for stability of various classes of neutral-type neural networks having multiple delays.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303543",
    "keywords": [
      "Algebraic number",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Ecology",
      "Epistemology",
      "Exponential stability",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Simple (philosophy)",
      "Stability (learning theory)",
      "Stability conditions",
      "Statistics",
      "Type (biology)"
    ],
    "authors": [
      {
        "surname": "Faydasicok",
        "given_name": "Ozlem"
      }
    ]
  },
  {
    "title": "Adaptive balancing of exploration and exploitation around the edge of chaos in internal-chaos-based learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.002",
    "abstract": "This paper addresses learning with exploration driven by chaotic internal dynamics of a neural network. Hoerzer et al. showed that a chaotic reservoir network (RN) can learn with exploration driven by external random noise and a sequential reward. In this paper, we demonstrate that a chaotic RN can learn without external noise because the output fluctuation originated from its internal chaotic dynamics functions as exploration. As learning progresses, the chaoticity decreases and the network can automatically switch from exploration mode to exploitation mode. Furthermore, the network can resume exploration when presented with a new situation. In addition, we found that even when the two parameters that influence the chaoticity are varied, learning performance always improves around the edge of chaos. From these results, we think that exploration is generated from internal chaotic dynamics, and exploitation appears in the process of forming attractors on the chaotic dynamics through learning. Consequently, exploration and exploitation are well-balanced around the edge of chaos, which leads to good learning performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302914",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Attractor",
      "CHAOS (operating system)",
      "Chaotic",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Control theory (sociology)",
      "Edge of chaos",
      "Enhanced Data Rates for GSM Evolution",
      "Image (mathematics)",
      "Mathematical analysis",
      "Mathematics",
      "Mode (computer interface)",
      "Noise (video)",
      "Operating system",
      "Physics",
      "Process (computing)",
      "Statistical physics"
    ],
    "authors": [
      {
        "surname": "Matsuki",
        "given_name": "Toshitaka"
      },
      {
        "surname": "Shibata",
        "given_name": "Katsunari"
      }
    ]
  },
  {
    "title": "AMD-GAN: Attention encoder and multi-branch structure based generative adversarial networks for fundus disease detection from scanning laser ophthalmoscopy images",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.005",
    "abstract": "The scanning laser ophthalmoscopy (SLO) has become an important tool for the determination of peripheral retinal pathology, in recent years. However, the collected SLO images are easily interfered by the eyelash and frame of the devices, which heavily affect the key feature extraction of the images. To address this, we propose a generative adversarial network called AMD-GAN based on the attention encoder (AE) and multi-branch (MB) structure for fundus disease detection from SLO images. Specifically, the designed generator consists of two parts: the AE and generation flow network, where the real SLO images are encoded by the AE module to extract features and the generation flow network to handle the random Gaussian noise by a series of residual block with up-sampling (RU) operations to generate fake images with the same size as the real ones, where the AE is also used to mine features for generator. For discriminator, a ResNet network using MB is devised by copying the stage 3 and stage 4 structures of the ResNet-34 model to extract deep features. Furthermore, the depth-wise asymmetric dilated convolution is leveraged to extract local high-level contextual features and accelerate the training process. Besides, the last layer of discriminator is modified to build the classifier to detect the diseased and normal SLO images. In addition, the prior knowledge of experts is utilized to improve the detection results. Experimental results on the two local SLO datasets demonstrate that our proposed method is promising in detecting the diseased and normal SLO images with the experts labeling.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303282",
    "keywords": [
      "Adaptive optics",
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Detector",
      "Discriminator",
      "Feature extraction",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Residual",
      "Scanning laser ophthalmoscopy",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Hai"
      },
      {
        "surname": "Lei",
        "given_name": "Haijun"
      },
      {
        "surname": "Zeng",
        "given_name": "Xianlu"
      },
      {
        "surname": "He",
        "given_name": "Yejun"
      },
      {
        "surname": "Chen",
        "given_name": "Guozhen"
      },
      {
        "surname": "Elazab",
        "given_name": "Ahmed"
      },
      {
        "surname": "Yue",
        "given_name": "Guanghui"
      },
      {
        "surname": "Wang",
        "given_name": "Jiantao"
      },
      {
        "surname": "Zhang",
        "given_name": "Guoming"
      },
      {
        "surname": "Lei",
        "given_name": "Baiying"
      }
    ]
  },
  {
    "title": "Emotional EEG classification using connectivity features and convolutional neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.009",
    "abstract": "Convolutional neural networks (CNNs) are widely used to recognize the user’s state through electroencephalography (EEG) signals. In the previous studies, the EEG signals are usually fed into the CNNs in the form of high-dimensional raw data. However, this approach makes it difficult to exploit the brain connectivity information that can be effective in describing the functional brain network and estimating the perceptual state of the user. We introduce a new classification system that utilizes brain connectivity with a CNN and validate its effectiveness via the emotional video classification by using three different types of connectivity measures. Furthermore, two data-driven methods to construct the connectivity matrix are proposed to maximize classification performance. Further analysis reveals that the level of concentration of the brain connectivity related to the emotional property of the target video is correlated with classification performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302987",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Electroencephalography",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Moon",
        "given_name": "Seong-Eun"
      },
      {
        "surname": "Chen",
        "given_name": "Chun-Jui"
      },
      {
        "surname": "Hsieh",
        "given_name": "Cho-Jui"
      },
      {
        "surname": "Wang",
        "given_name": "Jane-Ling"
      },
      {
        "surname": "Lee",
        "given_name": "Jong-Seok"
      }
    ]
  },
  {
    "title": "Latent Dirichlet allocation based generative adversarial networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.012",
    "abstract": "Generative adversarial networks have been extensively studied in recent years and powered a wide range of applications, ranging from image generation, image-to-image translation, to text-to-image generation, and visual recognition. These methods typically model the mapping from latent space to image with single or multiple generators. However, they have obvious drawbacks: (i) ignoring the multi-modal structure of images, and (ii) lacking model interpretability. Importantly, the existing methods mostly assume one or more generators can cover all image modes even if we do not know the structure of data. Thus, mode dropping and collapse often take place along with GANs training. Despite the importance of exploring the data structure in generation, it has been almost unexplored. In this work, aiming at generating multi-modal images and interpreting model explicitly, we explore the theory on how to integrate GANs with data structure prior, and propose latent Dirichlet allocation based generative adversarial networks (LDAGAN). This framework is extended to combine with a variety of state-of-the-art single-generator GANs and achieves improved performance. Extensive experiments on synthetic and real datasets demonstrate the efficacy of LDAGAN for multi-modal image generation. An implementation of LDAGAN is available at https://github.com/Sumching/LDAGAN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303014",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Composite material",
      "Computer science",
      "Cover (algebra)",
      "Engineering",
      "Generative grammar",
      "Generator (circuit theory)",
      "Image (mathematics)",
      "Image translation",
      "Interpretability",
      "Latent Dirichlet allocation",
      "Machine learning",
      "Materials science",
      "Mechanical engineering",
      "Modal",
      "Pattern recognition (psychology)",
      "Physics",
      "Polymer chemistry",
      "Power (physics)",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Topic model",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Pan",
        "given_name": "Lili"
      },
      {
        "surname": "Cheng",
        "given_name": "Shen"
      },
      {
        "surname": "Liu",
        "given_name": "Jian"
      },
      {
        "surname": "Tang",
        "given_name": "Peijun"
      },
      {
        "surname": "Wang",
        "given_name": "Bowen"
      },
      {
        "surname": "Ren",
        "given_name": "Yazhou"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      }
    ]
  },
  {
    "title": "Adaptive balancing of exploration and exploitation around the edge of chaos in internal-chaos-based learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.002",
    "abstract": "This paper addresses learning with exploration driven by chaotic internal dynamics of a neural network. Hoerzer et al. showed that a chaotic reservoir network (RN) can learn with exploration driven by external random noise and a sequential reward. In this paper, we demonstrate that a chaotic RN can learn without external noise because the output fluctuation originated from its internal chaotic dynamics functions as exploration. As learning progresses, the chaoticity decreases and the network can automatically switch from exploration mode to exploitation mode. Furthermore, the network can resume exploration when presented with a new situation. In addition, we found that even when the two parameters that influence the chaoticity are varied, learning performance always improves around the edge of chaos. From these results, we think that exploration is generated from internal chaotic dynamics, and exploitation appears in the process of forming attractors on the chaotic dynamics through learning. Consequently, exploration and exploitation are well-balanced around the edge of chaos, which leads to good learning performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302914",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Attractor",
      "CHAOS (operating system)",
      "Chaotic",
      "Computer science",
      "Computer security",
      "Control (management)",
      "Control theory (sociology)",
      "Edge of chaos",
      "Enhanced Data Rates for GSM Evolution",
      "Image (mathematics)",
      "Mathematical analysis",
      "Mathematics",
      "Mode (computer interface)",
      "Noise (video)",
      "Operating system",
      "Physics",
      "Process (computing)",
      "Statistical physics"
    ],
    "authors": [
      {
        "surname": "Matsuki",
        "given_name": "Toshitaka"
      },
      {
        "surname": "Shibata",
        "given_name": "Katsunari"
      }
    ]
  },
  {
    "title": "Quantum-like influence diagrams for decision-making",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.009",
    "abstract": "This article proposes a novel and comprehensive framework on how to describe the probabilistic nature of decision-making process. We suggest extending the quantum-like Bayesian network formalism to incorporate the notion of maximum expected utility to model human paradoxical, sub-optimal and irrational decisions. What distinguishes this work is that we take advantage of the quantum interference effects produced in quantum-like Bayesian Networks during the inference process to influence the probabilities used to compute the maximum expected utility of some decision. The proposed quantum-like decision model is able to (1) predict the probability distributions found in different experiments reported in the literature by modelling uncertainty through quantum interference, (2) to identify decisions that the decision-makers perceive to be optimal within their belief space, but that are actually irrational with respect to expected utility theory, (3) gain an understanding of how the decision-maker’s beliefs evolve within a decision-making scenario. The proposed model has the potential to provide new insights in decision science, as well as having direct implications for decision support systems that deal with human data, such as in the fields of economics, finance, psychology, etc.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302501",
    "keywords": [
      "Artificial intelligence",
      "Bayesian inference",
      "Bayesian network",
      "Bayesian probability",
      "Business decision mapping",
      "Computer science",
      "Decision analysis",
      "Decision field theory",
      "Decision rule",
      "Decision support system",
      "Decision theory",
      "Decision tree",
      "Economics",
      "Evidential decision theory",
      "Evidential reasoning approach",
      "Expected utility hypothesis",
      "Finance",
      "Geometry",
      "Inference",
      "Influence diagram",
      "Irrational number",
      "Mathematical economics",
      "Mathematics",
      "Optimal decision",
      "Physics",
      "Probabilistic logic",
      "Prospect theory",
      "Quantum",
      "Quantum mechanics",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Moreira",
        "given_name": "Catarina"
      },
      {
        "surname": "Tiwari",
        "given_name": "Prayag"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      },
      {
        "surname": "Bruza",
        "given_name": "Peter"
      },
      {
        "surname": "Wichert",
        "given_name": "Andreas"
      }
    ]
  },
  {
    "title": "Low-rank tensor constrained co-regularized multi-view spectral clustering",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.019",
    "abstract": "Due to the efficiency of exploiting relationships and complex structures hidden in multi-views data, graph-oriented clustering methods have achieved remarkable progress in recent years. But most existing graph-based spectral methods still have the following demerits: (1) They regularize each view equally, which does not make sense in real applications. (2) By employing different norms, most existing methods calculate the error feature by feature, resulting in neglecting the spatial structure information and the complementary information. To tackle the aforementioned drawbacks, we propose an enhanced multi-view spectral clustering model. Our model characterizes the consistency among indicator matrices by minimizing our proposed weighted tensor nuclear norm, which explicitly exploits the salient different information between singular values of the matrix. Moreover, our model adaptively assigns a reasonable weight to each view, which helps improve robustness of the algorithm. Finally, the proposed tensor nuclear norm well exploits both high-order and complementary information, which helps mine the consistency between indicator matrices. Extensive experiments indicate the efficiency of our method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303087",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Cluster analysis",
      "Computer science",
      "Computer security",
      "Data mining",
      "Eigenvalues and eigenvectors",
      "Exploit",
      "Gene",
      "Graph",
      "Mathematics",
      "Matrix norm",
      "Pattern recognition (psychology)",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Robustness (evolution)",
      "Salient",
      "Singular value",
      "Spectral clustering",
      "Tensor (intrinsic definition)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Huiling"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiangdong"
      },
      {
        "surname": "Xia",
        "given_name": "Wei"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Dynamic event-based state estimation for delayed artificial neural networks with multiplicative noises: A gain-scheduled approach",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.023",
    "abstract": "This study is concerned with the state estimation issue for a kind of delayed artificial neural networks with multiplicative noises. The occurrence of the time delay is in a random way that is modeled by a Bernoulli distributed stochastic variable whose occurrence probability is time-varying and confined within a given interval. A gain-scheduled approach is proposed for the estimator design to accommodate the time-varying nature of the occurrence probability. For the sake of utilizing the communication resource as efficiently as possible, a dynamic event triggering mechanism is put forward to orchestrate the data delivery from the sensor to the estimator. Sufficient conditions are established to ensure that, in the simultaneous presence of the external noises, the randomly occurring time delays with time-varying occurrence probability as well as the dynamic event triggering communication protocol, the estimation error is exponentially ultimately bounded in the mean square. Moreover, the estimator gain matrices are explicitly calculated in terms of the solution to certain easy-to-solve matrix inequalities. Simulation examples are provided to show the validity of the proposed state estimation method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303129",
    "keywords": [
      "Aerospace engineering",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bernoulli distribution",
      "Bernoulli's principle",
      "Bounded function",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Engineering",
      "Estimator",
      "Event (particle physics)",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Multiplicative function",
      "Physics",
      "Quantum mechanics",
      "Random variable",
      "State (computer science)",
      "Statistics",
      "Stochastic process"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Shuai"
      },
      {
        "surname": "Wang",
        "given_name": "Zidong"
      },
      {
        "surname": "Chen",
        "given_name": "Yun"
      },
      {
        "surname": "Wei",
        "given_name": "Guoliang"
      }
    ]
  },
  {
    "title": "GP-GAN: Brain tumor growth prediction using stacked 3D generative adversarial networks from longitudinal MR Images",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.004",
    "abstract": "Brain tumors are one of the major common causes of cancer-related death, worldwide. Growth prediction of these tumors, particularly gliomas which are the most dominant type, can be quite useful to improve treatment planning, quantify tumor aggressiveness, and estimate patients’ survival time towards precision medicine. Studying tumor growth prediction basically requires multiple time points of single or multimodal medical images of the same patient. Recent models are based on complex mathematical formulations that basically rely on a system of partial differential equations, e.g. reaction diffusion model, to capture the diffusion and proliferation of tumor cells in the surrounding tissue. However, these models usually have small number of parameters that are insufficient to capture different patterns and other characteristics of the tumors. In addition, such models consider tumor growth independently for each subject, not being able to get benefit from possible common growth patterns existed in the whole population under study. In this paper, we propose a novel data-driven method via stacked 3D generative adversarial networks (GANs), named GP-GAN, for growth prediction of glioma. Specifically, we use stacked conditional GANs with a novel objective function that includes both l 1 and Dice losses. Moreover, we use segmented feature maps to guide the generator for better generated images. Our generator is designed based on a modified 3D U-Net architecture with skip connections to combine hierarchical features and thus have a better generated image. The proposed method is trained and tested on 18 subjects with 3 time points (9 subjects from collaborative hospital and 9 subjects from BRATS 2014 dataset). Results show that our proposed GP-GAN outperforms state-of-the-art methods for glioma growth prediction and attain average Jaccard index and Dice coefficient of 78.97% and 88.26%, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303270",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Generative adversarial network",
      "Generative grammar",
      "Image (mathematics)",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Elazab",
        "given_name": "Ahmed"
      },
      {
        "surname": "Wang",
        "given_name": "Changmiao"
      },
      {
        "surname": "Gardezi",
        "given_name": "Syed Jamal Safdar"
      },
      {
        "surname": "Bai",
        "given_name": "Hongmin"
      },
      {
        "surname": "Hu",
        "given_name": "Qingmao"
      },
      {
        "surname": "Wang",
        "given_name": "Tianfu"
      },
      {
        "surname": "Chang",
        "given_name": "Chunqi"
      },
      {
        "surname": "Lei",
        "given_name": "Baiying"
      }
    ]
  },
  {
    "title": "Frequency-dependent organization of the brain’s functional network through delayed-interactions",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.003",
    "abstract": "The structure of the brain network exhibits modularity at multiple spatial scales. The effect of the modular structure on the brain dynamics has been the focus of several studies in recent years but many aspects remain to be explored. For example, it is not well-known how the delays in the transmission of signals between the neurons and the brain regions interact with the modular structure to determine the brain dynamics. In this paper, we show an important impact of the delays on the collective dynamics of brain networks with modular structure; that is, the degree of the synchrony between different brain regions depends on the oscillating frequency. In particular, we show that when increasing the frequency of the nodes the network transits from a global synchrony state to an asynchronous state, through a transition region over which the local synchrony inside the modules is stronger than the global synchrony. When the delays depend on the distance between the nodes, the modular structure of different spatial scales appears in the correlation matrix over different specific frequency bands, so that, finer spatial modular structures reveal in higher frequency bands. The results are corroborated by a simple theoretical argument and elaborated by simulations on several simplified modular networks and the connectome with different spatial resolutions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302926",
    "keywords": [
      "Asynchronous communication",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Connectome",
      "Discrete mathematics",
      "Functional connectivity",
      "Genetics",
      "Mathematics",
      "Modular design",
      "Modularity (biology)",
      "Network dynamics",
      "Neuroscience",
      "Operating system",
      "Psychology",
      "Telecommunications",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Ziaeemehr",
        "given_name": "Abolfazl"
      },
      {
        "surname": "Zarei",
        "given_name": "Mina"
      },
      {
        "surname": "Valizadeh",
        "given_name": "Alireza"
      },
      {
        "surname": "Mirasso",
        "given_name": "Claudio R."
      }
    ]
  },
  {
    "title": "Efficient search for informational cores in complex systems: Application to brain networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.020",
    "abstract": "An important step in understanding the nature of the brain is to identify “cores” in the brain network, where brain areas strongly interact with each other. Cores can be considered as essential sub-networks for brain functions. In the last few decades, an information-theoretic approach to identifying cores has been developed. In this approach, interactions between parts are measured by an information loss function, which quantifies how much information would be lost if interactions between parts were removed. Then, a core called a “complex” is defined as a subsystem wherein the amount of information loss is locally maximal. Although identifying complexes can be a novel and useful approach, its application is practically impossible because computation time grows exponentially with system size. Here we propose a fast and exact algorithm for finding complexes, called Hierarchical Partitioning for Complex search (HPC). HPC hierarchically partitions systems to narrow down candidates for complexes. The computation time of HPC is polynomial, enabling us to find complexes in large systems (up to several hundred) in a practical amount of time. We prove that HPC is exact when an information loss function satisfies a mathematical property, monotonicity. We show that mutual information is one such information loss function. We also show that a broad class of submodular functions can be considered as such information loss functions, indicating the expandability of our framework to the class. We applied HPC to electrocorticogram recordings from a monkey and demonstrated that HPC revealed temporally stable and characteristic complexes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303099",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Class (philosophy)",
      "Computation",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Information loss",
      "Information theory",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Monotonic function",
      "Mutual information",
      "Statistics",
      "Submodular set function",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Kitazono",
        "given_name": "Jun"
      },
      {
        "surname": "Kanai",
        "given_name": "Ryota"
      },
      {
        "surname": "Oizumi",
        "given_name": "Masafumi"
      }
    ]
  },
  {
    "title": "High tissue contrast image synthesis via multistage attention-GAN: Application to segmenting brain MR scans",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.014",
    "abstract": "Magnetic resonance imaging (MRI) presents a detailed image of the internal organs via a magnetic field. Given MRI’s non-invasive advantage in repeated imaging, the low-contrast MR images in the target area make segmentation of tissue a challenging problem. This study shows the potential advantages of synthetic high tissue contrast (HTC) images through image-to-image translation techniques. Mainly, we use a novel cycle generative adversarial network (Cycle-GAN), which provides a mechanism of attention to increase the contrast within the tissue. The attention block and training on HTC images are beneficial to our model to enhance tissue visibility. We use a multistage architecture to concentrate on a single tissue as a preliminary and filter out the irrelevant context in every stage in order to increase the resolution of HTC images. The multistage architecture reduces the gap between source and target domains and alleviates synthetic images’ artefacts. We apply our HTC image synthesising method to two public datasets. In order to validate the effectiveness of these images we use HTC MR images in both end-to-end and two-stage segmentation structures. The experiments on three segmentation baselines on BraTS’18 demonstrate that joining the synthetic HTC images in the multimodal segmentation framework develops the average Dice similarity scores (DSCs) of 0.8%, 0.6%, and 0.5% respectively on the whole tumour (WT), tumour core (TC), and enhancing tumour (ET) while removing one real MRI channels from the segmentation pipeline. Moreover, segmentation of infant brain tissue in T1w MR slices through our framework improves DSCs approximately 1% in cerebrospinal fluid (CSF), grey matter (GM), and white matter (WM) compared to state-of-the-art segmentation techniques. The source code of synthesising HTC images is publicly available.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303038",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Brain tissue",
      "Computer science",
      "Computer vision",
      "Contrast (vision)",
      "Image (mathematics)",
      "Image contrast",
      "Neuroscience",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Hamghalam",
        "given_name": "Mohammad"
      },
      {
        "surname": "Wang",
        "given_name": "Tianfu"
      },
      {
        "surname": "Lei",
        "given_name": "Baiying"
      }
    ]
  },
  {
    "title": "H ∞ and l 2 - l ∞ state estimation for delayed memristive neural networks on finite horizon: The Round-Robin protocol",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.006",
    "abstract": "In this paper, a protocol-based finite-horizon H ∞ and l 2 - l ∞ estimation approach is put forward to solve the state estimation problem for discrete-time memristive neural networks (MNNs) subject to time-varying delays and energy-bounded disturbances. The Round-Robin protocol is utilized to mitigate unnecessary network congestion occurring in the sensor-to-estimator communication channel. For the delayed MNNs, our aim is to devise an estimator that not only ensures a prescribed disturbance attenuation level over a finite time-horizon, but also keeps the peak value of the estimation error within a given range. By resorting to the Lyapunov–Krasovskii functional method, the delay-dependent criteria are formulated that guarantee the existence of the desired estimator. Subsequently, the estimator gains are obtained via figuring out a bank of convex optimization problems. The validity of our estimator is finally shown via a numerical example.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302951",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Computer science",
      "Convex optimization",
      "Estimator",
      "Geometry",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Regular polygon",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Hongjian"
      },
      {
        "surname": "Wang",
        "given_name": "Zidong"
      },
      {
        "surname": "Fei",
        "given_name": "Weiyin"
      },
      {
        "surname": "Li",
        "given_name": "Jiahui"
      }
    ]
  },
  {
    "title": "A robust algorithm for explaining unreliable machine learning survival models using the Kolmogorov–Smirnov bounds",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.007",
    "abstract": "A new robust algorithm based on the explanation method SurvLIME called SurvLIME-KS is proposed for explaining machine learning survival models. The algorithm is developed to ensure robustness to cases of a small amount of training data or outliers of survival data. The first idea behind SurvLIME-KS is to apply the Cox proportional hazards model to approximate the black-box survival model at the local area around a test example due to the linear relationship of covariates in the model. The second idea is to incorporate the well-known Kolmogorov–Smirnov bounds for constructing sets of predicted cumulative hazard functions. As a result, the robust maximin strategy is used, which aims to minimize the average distance between cumulative hazard functions of the explained black-box model and of the approximating Cox model, and to maximize the distance over all cumulative hazard functions in the interval produced by the Kolmogorov–Smirnov bounds. The maximin optimization problem is reduced to the quadratic program. Various numerical experiments with synthetic and real datasets demonstrate the SurvLIME-KS efficiency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302963",
    "keywords": [],
    "authors": [
      {
        "surname": "Kovalev",
        "given_name": "Maxim S."
      },
      {
        "surname": "Utkin",
        "given_name": "Lev V."
      }
    ]
  },
  {
    "title": "Stochastic DCA for minimizing a large sum of DC functions with application to multi-class logistic regression",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.024",
    "abstract": "We consider the large sum of DC (Difference of Convex) functions minimization problem which appear in several different areas, especially in stochastic optimization and machine learning. Two DCA (DC Algorithm) based algorithms are proposed: stochastic DCA and inexact stochastic DCA. We prove that the convergence of both algorithms to a critical point is guaranteed with probability one. Furthermore, we develop our stochastic DCA for solving an important problem in multi-task learning, namely group variables selection in multi class logistic regression. The corresponding stochastic DCA is very inexpensive, all computations are explicit. Numerical experiments on several benchmark datasets and synthetic datasets illustrate the efficiency of our algorithms and their superiority over existing methods, with respect to classification accuracy, sparsity of solution as well as running time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303233",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Class (philosophy)",
      "Computation",
      "Computer science",
      "Computer security",
      "Convergence (economics)",
      "Convex function",
      "Economic growth",
      "Economics",
      "Geodesy",
      "Geography",
      "Geometry",
      "Key (lock)",
      "Logistic regression",
      "Machine learning",
      "Management",
      "Mathematical optimization",
      "Mathematics",
      "Minification",
      "Regular polygon",
      "Selection (genetic algorithm)",
      "Stochastic approximation",
      "Stochastic optimization",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Le Thi",
        "given_name": "Hoai An"
      },
      {
        "surname": "Le",
        "given_name": "Hoai Minh"
      },
      {
        "surname": "Phan",
        "given_name": "Duy Nhat"
      },
      {
        "surname": "Tran",
        "given_name": "Bach"
      }
    ]
  },
  {
    "title": "CariGAN: Caricature generation through weakly paired adversarial learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.011",
    "abstract": "Caricature generation is an interesting yet challenging task. The primary goal is to generate a plausible caricature with reasonable exaggerations given a face image. Conventional caricature generation approaches mainly use low-level geometric transformations such as image warping to generate exaggerated images, which lack richness and diversity in terms of content and style. The recent progress in generative adversarial networks (GANs) makes it possible to learn an image-to-image transformation from data so as to generate diverse images. However, directly applying GAN-based models to this task leads to unsatisfactory results due to the large variance in the caricature distribution. Moreover, conventional models typically require pixel-wisely paired training data which largely limits their usage scenarios. In this paper, we model caricature generation as a weakly paired image-to-image translation task, and propose CariGAN to address these issues. Specifically, to enforce reasonable exaggeration and facial deformation, manually annotated caricature facial landmarks are used as an additional condition to constrain the generated image. Furthermore, an image fusion mechanism is designed to encourage our model to focus on the key facial parts so that more vivid details in these regions can be generated. Finally, a diversity loss is proposed to encourage the model to produce diverse results. Extensive experiments on a large-scale “WebCaricature” dataset show that the proposed CariGAN can generate more visually plausible caricatures with larger diversity compared with the state-of-the-art models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303002",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Economics",
      "Exaggeration",
      "Face (sociological concept)",
      "Focus (optics)",
      "Gene",
      "Generative grammar",
      "Image (mathematics)",
      "Image translation",
      "Image warping",
      "Management",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Psychiatry",
      "Psychology",
      "Social science",
      "Sociology",
      "Task (project management)",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Wenbin"
      },
      {
        "surname": "Xiong",
        "given_name": "Wei"
      },
      {
        "surname": "Liao",
        "given_name": "Haofu"
      },
      {
        "surname": "Huo",
        "given_name": "Jing"
      },
      {
        "surname": "Gao",
        "given_name": "Yang"
      },
      {
        "surname": "Luo",
        "given_name": "Jiebo"
      }
    ]
  },
  {
    "title": "Dual-regression model for visual tracking",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.011",
    "abstract": "Existing regression based tracking methods built on correlation filter model or convolution model do not take both accuracy and robustness into account at the same time. In this paper, we propose a dual-regression framework comprising a discriminative fully convolutional module and a fine-grained correlation filter component for visual tracking. The convolutional module trained in a classification manner with hard negative mining ensures the discriminative ability of the proposed tracker, which facilitates the handling of several challenging problems, such as drastic deformation, distractors, and complicated backgrounds. The correlation filter component built on the shallow features with fine-grained features enables accurate localization. By fusing these two branches in a coarse-to-fine manner, the proposed dual-regression tracking framework achieves a robust and accurate tracking performance. Extensive experiments on the OTB2013, OTB2015, and VOT2015 datasets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303348",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Component (thermodynamics)",
      "Computer science",
      "Computer vision",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Discriminative model",
      "Eye tracking",
      "Filter (signal processing)",
      "Gene",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Regression",
      "Robustness (evolution)",
      "Statistics",
      "Thermodynamics",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xin"
      },
      {
        "surname": "Liu",
        "given_name": "Qiao"
      },
      {
        "surname": "Fan",
        "given_name": "Nana"
      },
      {
        "surname": "Zhou",
        "given_name": "Zikun"
      },
      {
        "surname": "He",
        "given_name": "Zhenyu"
      },
      {
        "surname": "Jing",
        "given_name": "Xiao-yuan"
      }
    ]
  },
  {
    "title": "Real-time gun detection in CCTV: An open problem",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.013",
    "abstract": "Object detectors have improved in recent years, obtaining better results and faster inference time. However, small object detection is still a problem that has not yet a definitive solution. The autonomous weapons detection on Closed-circuit television (CCTV) has been studied recently, being extremely useful in the field of security, counter-terrorism, and risk mitigation. This article presents a new dataset obtained from a real CCTV installed in a university and the generation of synthetic images, to which Faster R-CNN was applied using Feature Pyramid Network with ResNet-50 resulting in a weapon detection model able to be used in quasi real-time CCTV (90 ms of inference time with an NVIDIA GeForce GTX-1080Ti card) improving the state of the art on weapon detection in a two stages training. In this work, an exhaustive experimental study of the detector with these datasets was performed, showing the impact of synthetic datasets on the training of weapons detection systems, as well as the main limitations that these systems present nowadays. The generated synthetic dataset and the real CCTV dataset are available to the whole research community.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303361",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Data mining",
      "Deep learning",
      "Detector",
      "Feature (linguistics)",
      "Field (mathematics)",
      "Inference",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Object detection",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Pure mathematics",
      "Pyramid (geometry)",
      "Real-time computing",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Salazar González",
        "given_name": "Jose L."
      },
      {
        "surname": "Zaccaro",
        "given_name": "Carlos"
      },
      {
        "surname": "Álvarez-García",
        "given_name": "Juan A."
      },
      {
        "surname": "Soria Morillo",
        "given_name": "Luis M."
      },
      {
        "surname": "Sancho Caparrini",
        "given_name": "Fernando"
      }
    ]
  },
  {
    "title": "Self-grouping convolutional neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.015",
    "abstract": "Although group convolution operators are increasingly used in deep convolutional neural networks to improve the computational efficiency and to reduce the number of parameters, most existing methods construct their group convolution architectures by a predefined partitioning of the filters of each convolutional layer into multiple regular filter groups with an equal spatial group size and data-independence, which prevents a full exploitation of their potential. To tackle this issue, we propose a novel method of designing self-grouping convolutional neural networks, called SG-CNN, in which the filters of each convolutional layer group themselves based on the similarity of their importance vectors. Concretely, for each filter, we first evaluate the importance value of their input channels to identify the importance vectors, and then group these vectors by clustering. Using the resulting data-dependent centroids, we prune the less important connections, which implicitly minimizes the accuracy loss of the pruning, thus yielding a set of diverse group convolution filters. Subsequently, we develop two fine-tuning schemes, i.e. (1) both local and global fine-tuning and (2) global only fine-tuning, which experimentally deliver comparable results, to recover the recognition capacity of the pruned network. Comprehensive experiments carried out on the CIFAR-10/100 and ImageNet datasets demonstrate that our self-grouping convolution method adapts to various state-of-the-art CNN architectures, such as ResNet and DenseNet, and delivers superior performance in terms of compression ratio, speedup and recognition accuracy. We demonstrate the ability of SG-CNN to generalize by transfer learning, including domain adaption and object detection, showing competitive results. Our source code is available at https://github.com/QingbeiGuo/SG-CNN.git.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303385",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer vision",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Deep learning",
      "Filter (signal processing)",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Pruning",
      "Speedup"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Qingbei"
      },
      {
        "surname": "Wu",
        "given_name": "Xiao-Jun"
      },
      {
        "surname": "Kittler",
        "given_name": "Josef"
      },
      {
        "surname": "Feng",
        "given_name": "Zhiquan"
      }
    ]
  },
  {
    "title": "Lower dimensional kernels for video discriminators",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.016",
    "abstract": "This work presents an analysis of the discriminators used in Generative Adversarial Networks (GANs) for Video. We show that unconstrained video discriminator architectures induce a loss surface with high curvature which make optimization difficult. We also show that this curvature becomes more extreme as the maximal kernel dimension of video discriminators increases. With these observations in hand, we propose a methodology for the design of a family of efficient Lower-Dimensional Video Discriminators for GANs (LDVD-GANs). The proposed methodology improves the performance and efficiency of video GAN models it is applied to and demonstrates good performance on complex and diverse datasets such as UCF-101. In particular, we show that LDVDs can double the performance of Temporal-GANs and provide for state-of-the-art performance on a single GPU using the proposed methodology.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303397",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Curvature",
      "Deep learning",
      "Detector",
      "Dimension (graph theory)",
      "Discriminator",
      "Generative adversarial network",
      "Geometry",
      "Kernel (algebra)",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Pure mathematics",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Kahembwe",
        "given_name": "Emmanuel"
      },
      {
        "surname": "Ramamoorthy",
        "given_name": "Subramanian"
      }
    ]
  },
  {
    "title": "Learning to select actions shapes recurrent dynamics in the corticostriatal system",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.008",
    "abstract": "Learning to select appropriate actions based on their values is fundamental to adaptive behavior. This form of learning is supported by fronto-striatal systems. The dorsal-lateral prefrontal cortex (dlPFC) and the dorsal striatum (dSTR), which are strongly interconnected, are key nodes in this circuitry. Substantial experimental evidence, including neurophysiological recordings, have shown that neurons in these structures represent key aspects of learning. The computational mechanisms that shape the neurophysiological responses, however, are not clear. To examine this, we developed a recurrent neural network (RNN) model of the dlPFC-dSTR circuit and trained it on an oculomotor sequence learning task. We compared the activity generated by the model to activity recorded from monkey dlPFC and dSTR in the same task. This network consisted of a striatal component which encoded action values, and a prefrontal component which selected appropriate actions. After training, this system was able to autonomously represent and update action values and select actions, thus being able to closely approximate the representational structure in corticostriatal recordings. We found that learning to select the correct actions drove action-sequence representations further apart in activity space, both in the model and in the neural data. The model revealed that learning proceeds by increasing the distance between sequence-specific representations. This makes it more likely that the model will select the appropriate action sequence as learning develops. Our model thus supports the hypothesis that learning in networks drives the neural representations of actions further apart, increasing the probability that the network generates correct actions as learning proceeds. Altogether, this study advances our understanding of how neural circuit dynamics are involved in neural computation, revealing how dynamics in the corticostriatal system support task learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303312",
    "keywords": [
      "Action (physics)",
      "Action selection",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Component (thermodynamics)",
      "Computer science",
      "Economics",
      "Genetics",
      "Machine learning",
      "Management",
      "Neuroscience",
      "Perception",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Sequence (biology)",
      "Sequence learning",
      "Task (project management)",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Márton",
        "given_name": "Christian D."
      },
      {
        "surname": "Schultz",
        "given_name": "Simon R."
      },
      {
        "surname": "Averbeck",
        "given_name": "Bruno B."
      }
    ]
  },
  {
    "title": "Exponential synchronization of neural networks with time-varying delays and stochastic impulses",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.09.014",
    "abstract": "This paper concentrates on the exponential synchronization problem of the delayed neural networks (DNNs) with stochastic impulses. First, the impulsive Halanay differential inequality is further extended to the case that the impulsive strengths are random variables. Then, based on the generalized inequalities, synchronization criteria are respectively proposed for DNNs with two kinds of stochastic impulses, i.e., impulses with independent property/Markovian property. It should be pointed out that only some basic statistical characteristics are needed to verify the proposed criteria. Numerical examples are provided to show the validation of the obtained theoretical results at the end of this paper.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303373",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Epistemology",
      "Exponential function",
      "Impulse (physics)",
      "Mathematical analysis",
      "Mathematics",
      "Philosophy",
      "Physics",
      "Property (philosophy)",
      "Quantum mechanics",
      "Recurrent neural network",
      "Statistics",
      "Stochastic neural network",
      "Stochastic process",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Yifan"
      },
      {
        "surname": "Li",
        "given_name": "Lulu"
      },
      {
        "surname": "Liu",
        "given_name": "Xiaoyang"
      }
    ]
  },
  {
    "title": "Event-driven H ∞ control with critic learning for nonlinear systems",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.004",
    "abstract": "In this paper, we study an event-driven H ∞ control problem of continuous-time nonlinear systems. Initially, with the introduction of a discounted cost function, we convert the nonlinear H ∞ control problem into an event-driven nonlinear two-player zero-sum game. Then, we develop an event-driven Hamilton–Jacobi–Isaacs equation (HJIE) related to the two-player zero-sum game. After that, we propose a novel event-triggering condition guaranteeing Zeno behavior not to happen. The triggering threshold in the newly proposed event-triggering condition can be kept positive without requiring to properly choose the prescribed level of disturbance attenuation. To solve the event-driven HJIE, we employ an adaptive critic architecture which contains a unique critic neural network (NN). The weight parameters used in the critic NN are tuned via the gradient descent method. After that, we carry out stability analysis of the hybrid closed-loop system based on Lyapunov’s direct approach. Finally, we provide two nonlinear plants, including the pendulum system, to validate the proposed event-driven H ∞ control scheme.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302938",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Event (particle physics)",
      "Gradient descent",
      "Inverted pendulum",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Xiong"
      },
      {
        "surname": "Gao",
        "given_name": "Zhongke"
      },
      {
        "surname": "Zhang",
        "given_name": "Jinhui"
      }
    ]
  },
  {
    "title": "A direct approach for function approximation on data defined manifolds",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.08.018",
    "abstract": "In much of the literature on function approximation by deep networks, the function is assumed to be defined on some known domain, such as a cube or a sphere. In practice, the data might not be dense on these domains, and therefore, the approximation theory results are observed to be too conservative. In manifold learning, one assumes instead that the data is sampled from an unknown manifold; i.e., the manifold is defined by the data itself. Function approximation on this unknown manifold is then a two stage procedure: first, one approximates the Laplace–Beltrami operator (and its eigen-decomposition) on this manifold using a graph Laplacian, and next, approximates the target function using the eigen-functions. Alternatively, one estimates first some atlas on the manifold and then uses local approximation techniques based on the local coordinate charts. In this paper, we propose a more direct approach to function approximation on unknown, data defined manifolds without computing the eigen-decomposition of some operator or an atlas for the manifold, and without any kind of training in the classical sense. Our constructions are universal; i.e., do not require the knowledge of any prior on the target function other than continuity on the manifold. We estimate the degree of approximation. For smooth functions, the estimates do not suffer from the so-called saturation phenomenon. We demonstrate via a property called good propagation of errors how the results can be lifted for function approximation using deep networks where each channel evaluates a Gaussian network on a possibly unknown manifold.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020303075",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Atlas (anatomy)",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Dimensionality reduction",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Function approximation",
      "Gene",
      "Laplace operator",
      "Manifold (fluid mechanics)",
      "Manifold alignment",
      "Mathematical analysis",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Operator (biology)",
      "Paleontology",
      "Repressor",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Mhaskar",
        "given_name": "H.N."
      }
    ]
  },
  {
    "title": "ASSAF: Advanced and Slim StegAnalysis Detection Framework for JPEG images based on deep convolutional denoising autoencoder and Siamese networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.022",
    "abstract": "Steganography is the art of embedding a confidential message within a host message. Modern steganography is focused on widely used multimedia file formats, such as images, video files, and Internet protocols. Recently, cyber attackers have begun to include steganography (for communication purposes) in their arsenal of tools for evading detection. Steganalysis is the counter-steganography domain which aims at detecting the existence of steganography within a host file. The presence of steganography in files raises suspicion regarding the file itself, as well as its origin and receiver, and might be an indication of a sophisticated attack. The JPEG file format is one of the most popular image file formats and thus is an attractive and commonly used carrier for steganography embedding. State-of-the-art JPEG steganalysis methods, which are mainly based on neural networks, are limited in their ability to detect sophisticated steganography use cases. In this paper, we propose ASSAF, a novel deep neural network architecture composed of a convolutional denoising autoencoder and a Siamese neural network, specially designed to detect steganography in JPEG images. We focus on detecting the J-UNIWARD method, which is one of the most sophisticated adaptive steganography methods used today. We evaluated our novel architecture using the BOSSBase dataset, which contains 10,000 JPEG images, in eight different use cases which combine different JPEG’s quality factors and embedding rates (bpnzAC). Our results show that ASSAF can detect stenography with high accuracy rates, outperforming, in all eight use cases, the state-of-the-art steganalysis methods by 6% to 40%.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030263X",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Embedding",
      "Image (mathematics)",
      "Image file formats",
      "JPEG",
      "Pattern recognition (psychology)",
      "Steganalysis",
      "Steganography",
      "Steganography tools"
    ],
    "authors": [
      {
        "surname": "Cohen",
        "given_name": "Assaf"
      },
      {
        "surname": "Cohen",
        "given_name": "Aviad"
      },
      {
        "surname": "Nissim",
        "given_name": "Nir"
      }
    ]
  },
  {
    "title": "Theory of deep convolutional neural networks II: Spherical analysis",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.029",
    "abstract": "Deep learning based on deep neural networks of various structures and architectures has been powerful in many practical applications, but it lacks enough theoretical verifications. In this paper, we consider a family of deep convolutional neural networks applied to approximate functions on the unit sphere S d − 1 of R d . Our analysis presents rates of uniform approximation when the approximated function lies in the Sobolev space W ∞ r ( S d − 1 ) with r > 0 or takes an additive ridge form. Our work verifies theoretically the modelling and approximation ability of deep convolutional neural networks followed by downsampling and one fully connected layer or two. The key idea of our spherical analysis is to use the inner product form of the reproducing kernels of the spaces of spherical harmonics and then to apply convolutional factorizations of filters to realize the generated linear features.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302707",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Deep learning",
      "Function approximation",
      "Image (mathematics)",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Sobolev space",
      "Spherical harmonics",
      "Unit sphere",
      "Upsampling"
    ],
    "authors": [
      {
        "surname": "Fang",
        "given_name": "Zhiying"
      },
      {
        "surname": "Feng",
        "given_name": "Han"
      },
      {
        "surname": "Huang",
        "given_name": "Shuo"
      },
      {
        "surname": "Zhou",
        "given_name": "Ding-Xuan"
      }
    ]
  },
  {
    "title": "Compressing 3DCNNs based on tensor train decomposition",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.028",
    "abstract": "Three-dimensional convolutional neural networks (3DCNNs) have been applied in many tasks, e.g., video and 3D point cloud recognition. However, due to the higher dimension of convolutional kernels, the space complexity of 3DCNNs is generally larger than that of traditional two-dimensional convolutional neural networks (2DCNNs). To miniaturize 3DCNNs for the deployment in confining environments such as embedded devices, neural network compression is a promising approach. In this work, we adopt the tensor train (TT) decomposition, a straightforward and simple in situ training compression method, to shrink the 3DCNN models. Through proposing tensorizing 3D convolutional kernels in TT format, we investigate how to select appropriate TT ranks for achieving higher compression ratio. We have also discussed the redundancy of 3D convolutional kernels for compression, core significance and future directions of this work, as well as the theoretical computation complexity versus practical executing time of convolution in TT. In the light of multiple contrast experiments based on VIVA challenge, UCF11, UCF101, and ModelNet40 datasets, we conclude that TT decomposition can compress 3DCNNs by around one hundred times without significant accuracy loss, which will enable its applications in extensive real world scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302690",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Compression (physics)",
      "Computation",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Geometry",
      "Materials science",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Redundancy (engineering)",
      "Tensor (intrinsic definition)",
      "Tensor decomposition",
      "Tucker decomposition"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Dingheng"
      },
      {
        "surname": "Zhao",
        "given_name": "Guangshe"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      },
      {
        "surname": "Deng",
        "given_name": "Lei"
      },
      {
        "surname": "Wu",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Exponential synchronization of stochastic delayed memristive neural networks via a novel hybrid control",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.034",
    "abstract": "This paper investigates the exponential synchronization issue of stochastic delayed memristive neural networks (SDMNNs) via a novel hybrid control (HC), where impulsive instants are determined by the state-dependent trigger condition. The switching and quantification strategies are applied to the event-based impulsive controller to cope with the challenges induced concurrently by interval parameters, impulses, stochastic disturbance and time-varying delays. Furthermore, the control costs can be reduced and communication channels and bandwidths can be saved by using this designed controller. Then, novel Lyapunov functions and new analytical methods are constructed, which can be used to realize the exponential synchronization of SDMNNs via HC. Finally, a numerical simulation is provided to demonstrate our theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302756",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Electronic engineering",
      "Engineering",
      "Exponential function",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Memristor",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Stochastic neural network",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Nijing"
      },
      {
        "surname": "Yu",
        "given_name": "Yongbin"
      },
      {
        "surname": "Zhong",
        "given_name": "Shouming"
      },
      {
        "surname": "Wang",
        "given_name": "Xiangxiang"
      },
      {
        "surname": "Shi",
        "given_name": "Kaibo"
      },
      {
        "surname": "Cai",
        "given_name": "Jingye"
      }
    ]
  },
  {
    "title": "Two-hidden-layer feed-forward networks are universal approximators: A constructive approach",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.021",
    "abstract": "It is well-known that artificial neural networks are universal approximators. The classical existence result proves that, given a continuous function on a compact set embedded in an n -dimensional space, there exists a one-hidden-layer feed-forward network that approximates the function. In this paper, a constructive approach to this problem is given for the case of a continuous function on triangulated spaces. Once a triangulation of the space is given, a two-hidden-layer feed-forward network with a concrete set of weights is computed. The level of the approximation depends on the refinement of the triangulation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302628",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Constructive",
      "Layer (electronics)",
      "Operating system",
      "Organic chemistry",
      "Process (computing)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Paluzo-Hidalgo",
        "given_name": "Eduardo"
      },
      {
        "surname": "Gonzalez-Diaz",
        "given_name": "Rocio"
      },
      {
        "surname": "Gutiérrez-Naranjo",
        "given_name": "Miguel A."
      }
    ]
  },
  {
    "title": "Integral reinforcement learning based event-triggered control with input saturation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.016",
    "abstract": "In this paper, a novel integral reinforcement learning (IRL)-based event-triggered adaptive dynamic programming scheme is developed for input-saturated continuous-time nonlinear systems. By using the IRL technique, the learning system does not require the knowledge of the drift dynamics. Then, a single critic neural network is designed to approximate the unknown value function and its learning is not subjected to the requirement of an initial admissible control. In order to reduce computational and communication costs, the event-triggered control law is designed. The triggering threshold is given to guarantee the asymptotic stability of the control system. Two examples are employed in the simulation studies, and the results verify the effectiveness of the developed IRL-based event-triggered control method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302574",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Dynamic programming",
      "Event (particle physics)",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Xue",
        "given_name": "Shan"
      },
      {
        "surname": "Luo",
        "given_name": "Biao"
      },
      {
        "surname": "Liu",
        "given_name": "Derong"
      }
    ]
  },
  {
    "title": "Synthesis of recurrent neural dynamics for monotone inclusion with application to Bayesian inference",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.037",
    "abstract": "We propose a top-down approach to construct recurrent neural circuit dynamics for the mathematical problem of monotone inclusion (MoI). MoI in a general optimization framework that encompasses a wide range of contemporary problems, including Bayesian inference and Markov decision making. We show that in a recurrent neural circuit/network with Poisson neurons, each neuron’s firing curve can be understood as a proximal operator of a local objective function, while the overall circuit dynamics constitutes an operator-splitting system of ordinary differential equations whose equilibrium point corresponds to the solution of the MoI problem. Our analysis thus establishes that neural circuits are a substrate for solving a broad class of computational tasks. In this regard, we provide an explicit synthesis procedure for building neural circuits for specific MoI problems and demonstrate it for the specific case of Bayesian inference and sparse neural coding.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302896",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bayesian probability",
      "Computer science",
      "Geometry",
      "Inference",
      "Mathematical optimization",
      "Mathematics",
      "Monotone polygon",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Yi",
        "given_name": "Peng"
      },
      {
        "surname": "Ching",
        "given_name": "ShiNung"
      }
    ]
  },
  {
    "title": "Bifurcations in a fractional-order neural network with multiple leakage delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.015",
    "abstract": "This paper expatiates the stability and bifurcation for a fractional-order neural network (FONN) with double leakage delays. Firstly, the characteristic equation of the developed FONN is circumspectly researched by employing inequable delays as bifurcation parameters. Simultaneously the bifurcation criteria are correspondingly extrapolated. Then, unequal delays-spurred-bifurcation diagrams are primarily delineated to confirm the precision and correctness for the values of bifurcation points. Furthermore, it lavishly illustrates from the evidence that the stability performance of the proposed FONN can be demolished with the presence of leakage delays in accordance with comparative studies. Eventually, two numerical examples are exploited to underpin the feasibility of the developed theory. The results derived in this paper have perfected the retrievable outcomes on bifurcations of FONNs embodying unique leakage delay, which can nicely serve a benchmark deliberation and provide a comparatively credible guidance for the influence of multiple leakage delays on bifurcations of FONNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302562",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Bifurcation",
      "Bifurcation diagram",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Correctness",
      "Economics",
      "Geodesy",
      "Geography",
      "Leakage (economics)",
      "Machine learning",
      "Macroeconomics",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Saddle-node bifurcation",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Chengdai"
      },
      {
        "surname": "Liu",
        "given_name": "Heng"
      },
      {
        "surname": "Shi",
        "given_name": "Xiangyun"
      },
      {
        "surname": "Chen",
        "given_name": "Xiaoping"
      },
      {
        "surname": "Xiao",
        "given_name": "Min"
      },
      {
        "surname": "Wang",
        "given_name": "Zhengxin"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Improved recurrent neural network-based manipulator control with remote center of motion constraints: Experimental results",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.033",
    "abstract": "In this paper, an improved recurrent neural network (RNN) scheme is proposed to perform the trajectory control of redundant robot manipulators using remote center of motion (RCM) constraints. Firstly, learning by demonstration is implemented to model the surgical operation skills in the Cartesian space. After that, considering the kinematic constraints associated with the optimization control of redundant manipulators, we propose a novel RNN-based approach to facilitate accurate task tracking based on the general quadratic performance index, which includes managing the constraints on RCM joint angle, and joint velocity, simultaneously. The results of the conducted theoretical analysis confirm that the RCM constraint has been established successfully, and accordingly. The corresponding end-effector tracking errors asymptotically converge to zero. Finally, demonstration experiments are conducted in a laboratory setup environment using KUKA LWR4+ to validate the effectiveness of the proposed control strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302744",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Cartesian coordinate system",
      "Classical mechanics",
      "Computer science",
      "Constraint (computer-aided design)",
      "Control (management)",
      "Control theory (sociology)",
      "Geometry",
      "Kinematics",
      "Mathematics",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Recurrent neural network",
      "Tracking (education)",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Su",
        "given_name": "Hang"
      },
      {
        "surname": "Hu",
        "given_name": "Yingbai"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      },
      {
        "surname": "Knoll",
        "given_name": "Alois"
      },
      {
        "surname": "Ferrigno",
        "given_name": "Giancarlo"
      },
      {
        "surname": "De Momi",
        "given_name": "Elena"
      }
    ]
  },
  {
    "title": "MetalGAN: Multi-domain label-less image synthesis using cGANs and meta-learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.031",
    "abstract": "Image synthesis is currently one of the most addressed image processing topic in computer vision and deep learning fields of study. Researchers have tackled this problem focusing their efforts on its several challenging problems, e.g. image quality and size, domain and pose changing, architecture of the networks, and so on. Above all, producing images belonging to different domains by using a single architecture is a very relevant goal for image generation. In fact, a single multi-domain network would allow greater flexibility and robustness in the image synthesis task than other approaches. This paper proposes a novel architecture and a training algorithm, which are able to produce multi-domain outputs using a single network. A small portion of a dataset is intentionally used, and there are no hard-coded labels (or classes). This is achieved by combining a conditional Generative Adversarial Network (cGAN) for image generation and a Meta-Learning algorithm for domain switch, and we called our approach MetalGAN. The approach has proved to be appropriate for solving the multi-domain label-less problem and it is validated on facial attribute transfer, using CelebA dataset.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302720",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Domain (mathematical analysis)",
      "Flexibility (engineering)",
      "Gene",
      "Generative adversarial network",
      "Generative grammar",
      "Image (mathematics)",
      "Image synthesis",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Statistics",
      "Transfer of learning",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Fontanini",
        "given_name": "Tomaso"
      },
      {
        "surname": "Iotti",
        "given_name": "Eleonora"
      },
      {
        "surname": "Donati",
        "given_name": "Luca"
      },
      {
        "surname": "Prati",
        "given_name": "Andrea"
      }
    ]
  },
  {
    "title": "Deep learning on image denoising: An overview",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.025",
    "abstract": "Deep learning techniques have received much attention in the area of image denoising. However, there are substantial differences in the various types of deep learning methods dealing with image denoising. Specifically, discriminative learning based on deep learning can ably address the issue of Gaussian noise. Optimization models based on deep learning are effective in estimating the real noise. However, there has thus far been little related research to summarize the different deep learning techniques for image denoising. In this paper, we offer a comparative study of deep techniques in image denoising. We first classify the deep convolutional neural networks (CNNs) for additive white noisy images; the deep CNNs for real noisy images; the deep CNNs for blind denoising and the deep CNNs for hybrid noisy images, which represents the combination of noisy, blurred and low-resolution images. Then, we analyze the motivations and principles of the different types of deep learning methods. Next, we compare the state-of-the-art methods on public denoising datasets in terms of quantitative and qualitative analyses. Finally, we point out some potential challenges and directions of future research.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302665",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Deep belief network",
      "Deep learning",
      "Discriminative model",
      "Image (mathematics)",
      "Machine learning",
      "Noise (video)",
      "Noise reduction",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Chunwei"
      },
      {
        "surname": "Fei",
        "given_name": "Lunke"
      },
      {
        "surname": "Zheng",
        "given_name": "Wenxian"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      },
      {
        "surname": "Zuo",
        "given_name": "Wangmeng"
      },
      {
        "surname": "Lin",
        "given_name": "Chia-Wen"
      }
    ]
  },
  {
    "title": "Leveraging maximum entropy and correlation on latent factors for learning representations",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.027",
    "abstract": "Many tasks involve learning representations from matrices, and Non-negative Matrix Factorization (NMF) has been widely used due to its excellent interpretability. Through factorization, sample vectors are reconstructed as additive combinations of latent factors, which are represented as non-negative distributions over the raw input features. NMF models are significantly affected by latent factors’ distribution characteristics and the correlations among them. And NMF models are faced with the challenge of learning robust latent factor. To this end, we propose to learn representations with an awareness of the semantic quality evaluated from the aspects of intra- and inter-factors. On the one hand, a Maximum Entropy-based function is devised for the intra-factor semantic quality. On the other hand, the semantic uniqueness is evaluated via inter-factor correlation, which reinforces the aim of semantic compactness. Moreover, we present a novel non-linear NMF framework. The learning algorithm is presented and the convergence is theoretically analyzed and proved. Extensive experimental results on multiple datasets demonstrate that our method can be successfully applied to representative NMF models and boost performances over state-of-the-art models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302689",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Correlation",
      "Eigenvalues and eigenvectors",
      "Entropy (arrow of time)",
      "Factor analysis",
      "Geometry",
      "Interpretability",
      "Machine learning",
      "Mathematics",
      "Matrix decomposition",
      "Non-negative matrix factorization",
      "Pattern recognition (psychology)",
      "Physics",
      "Principle of maximum entropy",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Zhicheng"
      },
      {
        "surname": "Liu",
        "given_name": "Jie"
      },
      {
        "surname": "Dang",
        "given_name": "Kai"
      },
      {
        "surname": "Zhuang",
        "given_name": "Fuzhen"
      },
      {
        "surname": "Huang",
        "given_name": "Yalou"
      }
    ]
  },
  {
    "title": "Synthesis of recurrent neural dynamics for monotone inclusion with application to Bayesian inference",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.037",
    "abstract": "We propose a top-down approach to construct recurrent neural circuit dynamics for the mathematical problem of monotone inclusion (MoI). MoI in a general optimization framework that encompasses a wide range of contemporary problems, including Bayesian inference and Markov decision making. We show that in a recurrent neural circuit/network with Poisson neurons, each neuron’s firing curve can be understood as a proximal operator of a local objective function, while the overall circuit dynamics constitutes an operator-splitting system of ordinary differential equations whose equilibrium point corresponds to the solution of the MoI problem. Our analysis thus establishes that neural circuits are a substrate for solving a broad class of computational tasks. In this regard, we provide an explicit synthesis procedure for building neural circuits for specific MoI problems and demonstrate it for the specific case of Bayesian inference and sparse neural coding.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302896",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bayesian probability",
      "Computer science",
      "Geometry",
      "Inference",
      "Mathematical optimization",
      "Mathematics",
      "Monotone polygon",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Yi",
        "given_name": "Peng"
      },
      {
        "surname": "Ching",
        "given_name": "ShiNung"
      }
    ]
  },
  {
    "title": "Bifurcations in a fractional-order neural network with multiple leakage delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.015",
    "abstract": "This paper expatiates the stability and bifurcation for a fractional-order neural network (FONN) with double leakage delays. Firstly, the characteristic equation of the developed FONN is circumspectly researched by employing inequable delays as bifurcation parameters. Simultaneously the bifurcation criteria are correspondingly extrapolated. Then, unequal delays-spurred-bifurcation diagrams are primarily delineated to confirm the precision and correctness for the values of bifurcation points. Furthermore, it lavishly illustrates from the evidence that the stability performance of the proposed FONN can be demolished with the presence of leakage delays in accordance with comparative studies. Eventually, two numerical examples are exploited to underpin the feasibility of the developed theory. The results derived in this paper have perfected the retrievable outcomes on bifurcations of FONNs embodying unique leakage delay, which can nicely serve a benchmark deliberation and provide a comparatively credible guidance for the influence of multiple leakage delays on bifurcations of FONNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302562",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Bifurcation",
      "Bifurcation diagram",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Correctness",
      "Economics",
      "Geodesy",
      "Geography",
      "Leakage (economics)",
      "Machine learning",
      "Macroeconomics",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Saddle-node bifurcation",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Chengdai"
      },
      {
        "surname": "Liu",
        "given_name": "Heng"
      },
      {
        "surname": "Shi",
        "given_name": "Xiangyun"
      },
      {
        "surname": "Chen",
        "given_name": "Xiaoping"
      },
      {
        "surname": "Xiao",
        "given_name": "Min"
      },
      {
        "surname": "Wang",
        "given_name": "Zhengxin"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "SVM-Boosting based on Markov resampling: Theory and algorithm",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.036",
    "abstract": "In this article we introduce the idea of Markov resampling for Boosting methods. We first prove that Boosting algorithm with general convex loss function based on uniformly ergodic Markov chain (u.e.M.c.) examples is consistent and establish its fast convergence rate. We apply Boosting algorithm based on Markov resampling to Support Vector Machine (SVM), and introduce two new resampling-based Boosting algorithms: SVM-Boosting based on Markov resampling (SVM-BM) and improved SVM-Boosting based on Markov resampling (ISVM-BM). In contrast with SVM-BM, ISVM-BM uses the support vectors to calculate the weights of base classifiers. The numerical studies based on benchmark datasets show that the proposed two resampling-based SVM Boosting algorithms for linear base classifiers have smaller misclassification rates, less total time of sampling and training compared to three classical AdaBoost algorithms: Gentle AdaBoost, Real AdaBoost, Modest AdaBoost. In addition, we compare the proposed SVM-BM algorithm with the widely used and efficient gradient Boosting algorithm-XGBoost (eXtreme Gradient Boosting), SVM-AdaBoost and present some useful discussions on the technical parameters.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302884",
    "keywords": [
      "AdaBoost",
      "Algorithm",
      "Artificial intelligence",
      "Boosting (machine learning)",
      "Computer science",
      "Gradient boosting",
      "Machine learning",
      "Markov chain",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Random forest",
      "Resampling",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Hongwei"
      },
      {
        "surname": "Zou",
        "given_name": "Bin"
      },
      {
        "surname": "Xu",
        "given_name": "Chen"
      },
      {
        "surname": "Xu",
        "given_name": "Jie"
      },
      {
        "surname": "Tang",
        "given_name": "Yuan Yan"
      }
    ]
  },
  {
    "title": "Improved object recognition using neural networks trained to mimic the brain’s statistical properties",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.013",
    "abstract": "The current state-of-the-art object recognition algorithms, deep convolutional neural networks (DCNNs), are inspired by the architecture of the mammalian visual system, and are capable of human-level performance on many tasks. As they are trained for object recognition tasks, it has been shown that DCNNs develop hidden representations that resemble those observed in the mammalian visual system (Razavi and Kriegeskorte, 2014; Yamins and Dicarlo, 2016; Gu and van Gerven, 2015; Mcclure and Kriegeskorte, 2016). Moreover, DCNNs trained on object recognition tasks are currently among the best models we have of the mammalian visual system. This led us to hypothesize that teaching DCNNs to achieve even more brain-like representations could improve their performance. To test this, we trained DCNNs on a composite task, wherein networks were trained to: (a) classify images of objects; while (b) having intermediate representations that resemble those observed in neural recordings from monkey visual cortex. Compared with DCNNs trained purely for object categorization, DCNNs trained on the composite task had better object recognition performance and are more robust to label corruption. Interestingly, we found that neural data was not required for this process, but randomized data with the same statistical properties as neural data also boosted performance. While the performance gains we observed when training on the composite task vs the “pure” object recognition task were modest, they were remarkably robust. Notably, we observed these performance gains across all network variations we studied, including: smaller (CORNet-Z) vs larger (VGG-16) architectures; variations in optimizers (Adam vs gradient descent); variations in activation function (ReLU vs ELU); and variations in network initialization. Our results demonstrate the potential utility of a new approach to training object recognition networks, using strategies in which the brain – or at least the statistical properties of its activation patterns – serves as a teacher signal for training DCNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302549",
    "keywords": [],
    "authors": [
      {
        "surname": "Federer",
        "given_name": "Callie"
      },
      {
        "surname": "Xu",
        "given_name": "Haoyan"
      },
      {
        "surname": "Fyshe",
        "given_name": "Alona"
      },
      {
        "surname": "Zylberberg",
        "given_name": "Joel"
      }
    ]
  },
  {
    "title": "Finite-time stabilization and energy consumption estimation for delayed neural networks with bounded activation function",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.032",
    "abstract": "This paper concentrates on finite-time stabilization and energy consumption estimation for one type of delayed neural networks (DNNs) with bounded activation function. Under the bounded activation function condition and using the comparison theorem, a new switch controller is proposed to ensure the finite-time stability of the considered DNNs. Furthermore, the energy consumption produced in system controlling is estimated by inequality techniques. We generalize the previous results about the problem of finite-time stabilization and energy consumption estimation for neural networks. Ultimately, two numerical simulations are carried out to verify the validity of our results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302732",
    "keywords": [
      "Activation function",
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Electrical engineering",
      "Energy (signal processing)",
      "Energy consumption",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Stability (learning theory)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Chongyang"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      },
      {
        "surname": "Wang",
        "given_name": "Min"
      },
      {
        "surname": "Yang",
        "given_name": "Chunyu"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "DANTE: Deep alternations for training neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.026",
    "abstract": "We present DANTE, a novel method for training neural networks using the alternating minimization principle. DANTE provides an alternate perspective to traditional gradient-based backpropagation techniques commonly used to train deep networks. It utilizes an adaptation of quasi-convexity to cast training a neural network as a bi-quasi-convex optimization problem. We show that for neural network configurations with both differentiable (e.g. sigmoid) and non-differentiable (e.g. ReLU) activation functions, we can perform the alternations effectively in this formulation. DANTE can also be extended to networks with multiple hidden layers. In experiments on standard datasets, neural networks trained using the proposed method were found to be promising and competitive to traditional backpropagation techniques, both in terms of quality of the solution, as well as training speed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302677",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Computer science",
      "Convexity",
      "Deep learning",
      "Deep neural networks",
      "Differentiable function",
      "Economics",
      "Financial economics",
      "Mathematical analysis",
      "Mathematics",
      "Perspective (graphical)",
      "Sigmoid function",
      "Time delay neural network",
      "Types of artificial neural networks"
    ],
    "authors": [
      {
        "surname": "Sinha",
        "given_name": "Vaibhav B."
      },
      {
        "surname": "Kudugunta",
        "given_name": "Sneha"
      },
      {
        "surname": "Sankar",
        "given_name": "Adepu Ravi"
      },
      {
        "surname": "Chavali",
        "given_name": "Surya Teja"
      },
      {
        "surname": "Balasubramanian",
        "given_name": "Vineeth N."
      }
    ]
  },
  {
    "title": "Intermittent boundary stabilization of stochastic reaction–diffusion Cohen–Grossberg neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.019",
    "abstract": "Cohen–Grossberg neural networks (CGNNs) play an important role in many applications and the stabilization of this system has been well studied. This study considers the exponential stabilization for stochastic reaction–diffusion Cohen–Grossberg neural networks (SRDCGNNs) by means of an aperiodically intermittent boundary control. Both SRDCGNNs without and with time-delays are discussed. By employing the spatial integral functional method and Poincare’s inequality, criteria are derived to ensure the controlled systems achieve mean square exponential stabilization. Based on these criteria, the effects of diffusion item, control gains, the minimum control proportion and time-delays on exponential stability are analyzed. Examples are given to illustrate the effectiveness of the obtained theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302604",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Boundary (topology)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Diffusion",
      "Exponential function",
      "Exponential stability",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Reaction–diffusion system",
      "Stability (learning theory)",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Xiao-Zhen"
      },
      {
        "surname": "Wu",
        "given_name": "Kai-Ning"
      },
      {
        "surname": "Zhang",
        "given_name": "Weihai"
      }
    ]
  },
  {
    "title": "Unsupervised multi-domain multimodal image-to-image translation with explicit domain-constrained disentanglement",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.023",
    "abstract": "Image-to-image translation has drawn great attention during the past few years. It aims to translate an image in one domain to a target image in another domain. However, three big challenges remain in image-to-image translation: (1) the lack of large amounts of aligned training pairs for various tasks; (2) the ambiguity of multiple possible outputs from a single input image; and (3) the lack of simultaneous training for multi-domain translation with a single network. Therefore in this paper, we propose a unified framework for learning to generate diverse outputs using unpaired training data and allow for simultaneous multi-domain translation via a single model. Moreover, we also observed from experiments that the implicit disentanglement of content and style could lead to undesirable results. Thus we investigate how to extract domain-level signal as explicit supervision so as to achieve better image-to-image translation. Extensive experiments show that the proposed method outperforms or is comparable with the state-of-the-art methods for various applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302641",
    "keywords": [
      "Ambiguity",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Domain (mathematical analysis)",
      "Gene",
      "Image (mathematics)",
      "Image translation",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Messenger RNA",
      "Pattern recognition (psychology)",
      "Programming language",
      "Translation (biology)"
    ],
    "authors": [
      {
        "surname": "Xia",
        "given_name": "Weihao"
      },
      {
        "surname": "Yang",
        "given_name": "Yujiu"
      },
      {
        "surname": "Xue",
        "given_name": "Jing-Hao"
      }
    ]
  },
  {
    "title": "Sparse coding with a somato-dendritic rule",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.007",
    "abstract": "Cortical neurons are silent most of the time: sparse activity enables low-energy computation in the brain, and promises to do the same in neuromorphic hardware. Beyond power efficiency, sparse codes have favourable properties for associative learning, as they can store more information than local codes but are easier to read out than dense codes. Auto-encoders with a sparse constraint can learn sparse codes, and so can single-layer networks that combine recurrent inhibition with unsupervised Hebbian learning. But the latter usually require fast homeostatic plasticity, which could lead to catastrophic forgetting in embodied agents that learn continuously. Here we set out to explore whether plasticity at recurrent inhibitory synapses could take up that role instead, regulating both the population sparseness and the firing rates of individual neurons. We put the idea to the test in a network that employs compartmentalised inputs to solve the task: rate-based dendritic compartments integrate the feedforward input, while spiking integrate-and-fire somas compete through recurrent inhibition. A somato-dendritic learning rule allows somatic inhibition to modulate nonlinear Hebbian learning in the dendrites. Trained on MNIST digits and natural images, the network discovers independent components that form a sparse encoding of the input and support linear decoding. These findings confirm that intrinsic homeostatic plasticity is not strictly required for regulating sparseness: inhibitory synaptic plasticity can have the same effect. Our work illustrates the usefulness of compartmentalised inputs, and makes the case for moving beyond point neuron models in artificial spiking neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302203",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Computer science",
      "Content-addressable memory",
      "Control engineering",
      "Engineering",
      "Feed forward",
      "Generalization error",
      "Hebbian theory",
      "Homeostatic plasticity",
      "Leabra",
      "Learning rule",
      "MNIST database",
      "Metaplasticity",
      "Neural coding",
      "Neuromorphic engineering",
      "Receptor",
      "Spiking neural network",
      "Synaptic plasticity",
      "Wake-sleep algorithm"
    ],
    "authors": [
      {
        "surname": "Drix",
        "given_name": "Damien"
      },
      {
        "surname": "Hafner",
        "given_name": "Verena V."
      },
      {
        "surname": "Schmuker",
        "given_name": "Michael"
      }
    ]
  },
  {
    "title": "Global μ -synchronization of impulsive pantograph neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.004",
    "abstract": "This paper investigates the problem of global μ -synchronization of impulsive pantograph neural networks. In this paper, new concept of ν -asymptotic periodic impulsive interval T a s y ν is proposed for pantograph networks. By employing the Lyapunov method combined with the mathematical analysis approach for impulsive systems, some useful criteria are derived to guarantee the global μ -synchronization of coupled pantograph neural networks when the asymptotic logarithmic periodic impulsive interval T a s y ln < ∞ and T a s y ln = ∞ , respectively. Especially when T a s y ln = ∞ , as long as the networks are unstable, impulsive control cannot achieve synchronization regardless of the size of the impulse gain. Numerical simulations are exploited to illustrate our theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302458",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Exponential stability",
      "Impulse (physics)",
      "Interval (graph theory)",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear system",
      "Pantograph",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xuechen"
      },
      {
        "surname": "Wang",
        "given_name": "Nan"
      },
      {
        "surname": "Lou",
        "given_name": "Jungang"
      },
      {
        "surname": "Lu",
        "given_name": "Jianquan"
      }
    ]
  },
  {
    "title": "Fast Deep Stacked Networks based on Extreme Learning Machine applied to regression problems",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.018",
    "abstract": "Deep learning techniques are commonly used to process large amounts of data, and good results are obtained in many applications. Those methods, however, can lead to long training times. An alternative to simultaneously tune all parameters of a large network is to stack smaller modules, improving the model efficiency. However, methods such as Deep Stacked Network (DSN) have some problems that increase its training time and memory usage. To deal with these problems, Fast DSN (FDSN) was proposed, where the modules are trained using an Extreme Learning Machine (ELM) variant. Nonetheless, to speed-up the FDSN training, the ELM random feature mapping is shared among the modules, which can impact the network performance if the weights are not properly chosen. In this paper, we focus on the weight initialization of FDSN in order to improve its performance. We also propose FKDSN, a kernel-based variant of FDSN, besides discussing the theoretical complexity of the methods. We evaluate three different initialization approaches on ELM-trained neural networks over 50 public real-world regression datasets. Our experiments show that FDSN when combined with a more complex initialization method achieves similar results to ELM algorithms applied to large SLFNs, besides having a shorter training time and memory usage, implying that it can be suitable to be used on systems with restrict resources, such as Internet of Things devices. FKDSN also obtained similar results and training time to the large SLFNs, requiring less memory.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302598",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Deep learning",
      "Extreme learning machine",
      "Feature (linguistics)",
      "Initialization",
      "Kernel (algebra)",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Operating system",
      "Philosophy",
      "Process (computing)",
      "Programming language"
    ],
    "authors": [
      {
        "surname": "da Silva",
        "given_name": "Bruno Légora Souza"
      },
      {
        "surname": "Inaba",
        "given_name": "Fernando Kentaro"
      },
      {
        "surname": "Salles",
        "given_name": "Evandro Ottoni Teatini"
      },
      {
        "surname": "Ciarelli",
        "given_name": "Patrick Marques"
      }
    ]
  },
  {
    "title": "Twin minimax probability machine for pattern classification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.030",
    "abstract": "We propose a new distribution-free Bayes optimal classifier, called the twin minimax probability machine (TWMPM), which combines the benefits of both minimax probability machine(MPM) and twin support vector machine (TWSVM). TWMPM tries to construct two nonparallel hyperplanes such that each hyperplane separates one class samples with maximal probability, and is distant from the other class samples simultaneously. Moreover, the proposed TWMPM can control the misclassification error of samples in a worst-case setting by minimizing the upper bound on misclassification probability. An efficient algorithm for TWMPM is first proposed, which transforms TWMPM into concave fractional programming by applying multivariate Chebyshev inequality. Then the proposed TWMPM is reformulated as a pair of convex quadric programming (QP) by proper mathematical transformations. This guarantees TWMPM to have global optimal solution and be solved simply and effectively. In addition, we develop also an iterative algorithm for the proposed TWMPM. By comparing the two proposed algorithms theoretically, it is easy to know that the convex quadric programming algorithm is with lower computation burden than iterative algorithm for the TWMPM. A linear TWMPM version is first built, and then we show how to exploit mercer kernel to obtain nonlinear TWMPM version. The computation complexity for QP algorithm of TWMPM is in the same order as the traditional twin support vector machine (TWSVM). Experiments are carried out on three databases: UCI benchmark database, a practical application database and an artificial database. With low computation complexity and fewer parameters, experiments show the feasibility and effectiveness of the proposed TWMPM and its QP algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302719",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Combinatorics",
      "Computation",
      "Computer science",
      "Geometry",
      "Hyperplane",
      "Kernel (algebra)",
      "Mathematical optimization",
      "Mathematics",
      "Minimax",
      "Probability distribution",
      "Statistics",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Liming"
      },
      {
        "surname": "Wen",
        "given_name": "Yakun"
      },
      {
        "surname": "Zhang",
        "given_name": "Min"
      },
      {
        "surname": "Wang",
        "given_name": "Xue"
      }
    ]
  },
  {
    "title": "Memristor-based LSTM network with in situ training and its applications",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.035",
    "abstract": "Artificial neural networks (ANNs), such as the convolutional neural network (CNN) and long short-term memory (LSTM), have high complexity and contain large numbers of parameters. Memristor-based neural networks, which have the ability of in-memory and parallel computing, are therefore proposed to accelerate the operations of ANNs. In this paper, a memristor-based hardware realization of long short-term memory (LSTM) network with in situ training is presented. The designed memristor-based LSTM (MbLSTM) network is composed of memristor-based LSTM cell and memristor-based dense layer. Sigmoid and tanh (hyperbolic tangent) activation functions are approximately implemented through intentionally designing circuit parameters. A weight update scheme with row-parallel characteristic is put forward to update the conductance of memristors in crossbars. The highlights of MbLSTM include an effective hardware-based inference process and in situ training. The validity of MbLSTM is substantiated through classification tasks. The robustness of MbLSTM to conductance variations is also analyzed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302768",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "Gene",
      "Hyperbolic function",
      "Mathematical analysis",
      "Mathematics",
      "Memristor",
      "Operating system",
      "Process (computing)",
      "Resistive random-access memory",
      "Robustness (evolution)",
      "Sigmoid function",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Xiaoyang"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      },
      {
        "surname": "Wunsch II",
        "given_name": "Donald C."
      }
    ]
  },
  {
    "title": "Hungarian layer: A novel interpretable neural layer for paraphrase identification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.024",
    "abstract": "Paraphrase identification serves as an important topic in natural language processing while sequence alignment and matching underlie the principle of this task. Traditional alignment methods take advantage of attention mechanism. Attention mechanism, i.e. weighting technique, could pick out the most similar/dissimilar parts, but is weak in modeling the aligned unmatched parts, which are the crucial evidence to identify paraphrases. In this paper, we empower neural architecture with Hungarian algorithm to extract the aligned unmatched parts. Specifically, first, our model applies BiLSTM/BERT to encode the input sentences into hidden representations. Then, Hungarian layer leverages the hidden representations to extract the aligned unmatched parts. Last, we apply cosine similarity to metric the aligned unmatched parts for a final discrimination. Extensive experiments show that our model outperforms other baselines, substantially and significantly.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302653",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Botany",
      "Chemistry",
      "Computer science",
      "Cosine similarity",
      "ENCODE",
      "Economics",
      "Epistemology",
      "Gene",
      "Genetics",
      "Identification (biology)",
      "Image (mathematics)",
      "Layer (electronics)",
      "Management",
      "Matching (statistics)",
      "Mathematics",
      "Mechanism (biology)",
      "Medicine",
      "Metric (unit)",
      "Natural language processing",
      "Operations management",
      "Organic chemistry",
      "Paraphrase",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Radiology",
      "Sequence (biology)",
      "Similarity (geometry)",
      "Statistics",
      "Task (project management)",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Han"
      }
    ]
  },
  {
    "title": "k-hop graph neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.008",
    "abstract": "Graph neural networks (GNNs) have emerged recently as a powerful architecture for learning node and graph representations. Standard GNNs have the same expressive power as the Weisfeiler–Lehman test of graph isomorphism in terms of distinguishing non-isomorphic graphs. However, it was recently shown that this test cannot identify fundamental graph properties such as connectivity and triangle freeness. We show that GNNs also suffer from the same limitation. To address this limitation, we propose a more expressive architecture, k -hop GNNs, which updates a node’s representation by aggregating information not only from its direct neighbors, but from its k -hop neighborhood. We show that the proposed architecture can identify fundamental graph properties. We evaluate the proposed architecture on standard node classification and graph classification datasets. Our experimental evaluation confirms our theoretical findings since the proposed model achieves performance better or comparable to standard GNNs and to state-of-the-art algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302495",
    "keywords": [],
    "authors": [
      {
        "surname": "Nikolentzos",
        "given_name": "Giannis"
      },
      {
        "surname": "Dasoulas",
        "given_name": "George"
      },
      {
        "surname": "Vazirgiannis",
        "given_name": "Michalis"
      }
    ]
  },
  {
    "title": "Block-term tensor neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.034",
    "abstract": "Deep neural networks (DNNs) have achieved outstanding performance in a wide range of applications, e.g., image classification, natural language processing, etc. Despite the good performance, the huge number of parameters in DNNs brings challenges to efficient training of DNNs and also their deployment in low-end devices with limited computing resources. In this paper, we explore the correlations in the weight matrices, and approximate the weight matrices with the low-rank block-term tensors. We name the new corresponding structure as block-term tensor layers (BT-layers), which can be easily adapted to neural network models, such as CNNs and RNNs. In particular, the inputs and the outputs in BT-layers are reshaped into low-dimensional high-order tensors with a similar or improved representation power. Sufficient experiments have demonstrated that BT-layers in CNNs and RNNs can achieve a very large compression ratio on the number of parameters while preserving or improving the representation power of the original DNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302045",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Block (permutation group theory)",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Law",
      "Materials science",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Physics",
      "Political science",
      "Politics",
      "Power (physics)",
      "Pure mathematics",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Rank (graph theory)",
      "Representation (politics)",
      "Tensor (intrinsic definition)",
      "Term (time)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Ye",
        "given_name": "Jinmian"
      },
      {
        "surname": "Li",
        "given_name": "Guangxi"
      },
      {
        "surname": "Chen",
        "given_name": "Di"
      },
      {
        "surname": "Yang",
        "given_name": "Haiqin"
      },
      {
        "surname": "Zhe",
        "given_name": "Shandian"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      }
    ]
  },
  {
    "title": "Controller design for finite-time and fixed-time stabilization of fractional-order memristive complex-valued BAM neural networks with uncertain parameters and time-varying delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.021",
    "abstract": "In this paper we investigate controller design problem for finite-time and fixed-time stabilization of fractional-order memristive complex-valued BAM neural networks (FMCVBAMNNs) with uncertain parameters and time-varying delays. By using the Lyapunov theory, differential inclusion theory, and fractional calculus theory, finite-time stabilization condition for fractional-order memristive complex-valued BAM neural networks and the upper bound of the settling time for stabilization are obtained. The nonlinear complex-valued activation functions are split into two (real and imaginary) components. Moreover, the settling time of fixed time stabilization, that does not depend upon the initial values, is merely calculated. A novel criterion for guaranteeing the fixed-time stabilization of FMCVBAMNNs is derived. Our control scheme achieves system stabilization within bounded time and has an advantage in convergence rate. Numerical simulations are furnished to demonstrate the effectiveness of the theoretical analysis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302367",
    "keywords": [
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Convergence (economics)",
      "Differential inclusion",
      "Economic growth",
      "Economics",
      "Engineering",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Settling time",
      "Stability theory",
      "Step response",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Arslan",
        "given_name": "Emel"
      },
      {
        "surname": "Narayanan",
        "given_name": "G."
      },
      {
        "surname": "Ali",
        "given_name": "M. Syed"
      },
      {
        "surname": "Arik",
        "given_name": "Sabri"
      },
      {
        "surname": "Saroha",
        "given_name": "Sumit"
      }
    ]
  },
  {
    "title": "Deep clustering with a Dynamic Autoencoder: From reconstruction towards centroids construction",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.005",
    "abstract": "In unsupervised learning, there is no apparent straightforward cost function that can capture the significant factors of variations and similarities. Since natural systems have smooth dynamics, an opportunity is lost if an unsupervised objective function remains static. The absence of concrete supervision suggests that smooth dynamics should be integrated during the training process. Compared to classical static cost functions, dynamic objective functions allow to better make use of the gradual and uncertain knowledge acquired through pseudo-supervision. In this paper, we propose Dynamic Autoencoder (DynAE), a novel model for deep clustering that addresses a clustering–reconstruction trade-off, by gradually and smoothly eliminating the reconstruction objective function in favor of a construction one. Experimental evaluations on benchmark datasets show that our approach achieves state-of-the-art results compared to the most relevant deep clustering methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030246X",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Centroid",
      "Cluster analysis",
      "Computer science",
      "Deep learning",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Mrabah",
        "given_name": "Nairouz"
      },
      {
        "surname": "Khan",
        "given_name": "Naimul Mefraz"
      },
      {
        "surname": "Ksantini",
        "given_name": "Riadh"
      },
      {
        "surname": "Lachiri",
        "given_name": "Zied"
      }
    ]
  },
  {
    "title": "Landslide displacement interval prediction using lower upper bound estimation method with pre-trained random vector functional link network initialization",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.020",
    "abstract": "Interval prediction is an efficient approach to quantifying the uncertainties associated with landslide evolution. In this paper, a novel method, termed lower upper bound estimation (LUBE), of constructing prediction intervals (PIs) based on neural networks (NNs) is applied and extended to landslide displacement prediction. A random vector functional link network (RVFLN) is adopted as the NN used in the improved LUBE. A hybrid evolutionary algorithm, termed PSOGSA, that combines particle swarm optimization (PSO) and gravitational search algorithm (GSA) is utilized to train LUBE. The loss function of LUBE is redesigned by considering the quality of PI centre, which allows for a more comprehensive evaluation of PIs. The population initialization in the training process of LUBE is implemented by transferring the weights of a series of pre-trained RVFLNs. The performance of the improved LUBE method is validated by considering a comprehensive set of cases using seven benchmark datasets. In addition, a hybrid method that integrates ensemble empirical mode decomposition (EEMD) with the improved LUBE is proposed for the special case of landslide displacement prediction. Six real-world reservoir-induced landslides are considered to validate the capability and merit of the proposed hybrid method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302616",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Combinatorics",
      "Computer science",
      "Displacement (psychology)",
      "Engineering",
      "Geodesy",
      "Geology",
      "Geotechnical engineering",
      "Initialization",
      "Interval (graph theory)",
      "Landslide",
      "Mathematical analysis",
      "Mathematics",
      "Particle swarm optimization",
      "Programming language",
      "Psychology",
      "Psychotherapist",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Lian",
        "given_name": "Cheng"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      },
      {
        "surname": "Wang",
        "given_name": "Xiaoping"
      },
      {
        "surname": "Yao",
        "given_name": "Wei"
      },
      {
        "surname": "Su",
        "given_name": "Yixin"
      },
      {
        "surname": "Tang",
        "given_name": "Huiming"
      }
    ]
  },
  {
    "title": "Discretely-constrained deep network for weakly supervised segmentation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.011",
    "abstract": "An efficient strategy for weakly-supervised segmentation is to impose constraints or regularization priors on target regions. Recent efforts have focused on incorporating such constraints in the training of convolutional neural networks (CNN), however this has so far been done within a continuous optimization framework. Yet, various segmentation constraints and regularization priors can be modeled and optimized more efficiently in a discrete formulation. This paper proposes a method, based on the alternating direction method of multipliers (ADMM) algorithm, to train a CNN with discrete constraints and regularization priors. This method is applied to the segmentation of medical images with weak annotations, where both size constraints and boundary length regularization are enforced. Experiments on two benchmark datasets for medical image segmentation show our method to provide significant improvements compared to existing approaches in terms of segmentation accuracy, constraint satisfaction and convergence speed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302525",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Bayesian probability",
      "Computer science",
      "Convolutional neural network",
      "Image segmentation",
      "Mathematical optimization",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Prior probability",
      "Regularization (linguistics)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Jizong"
      },
      {
        "surname": "Kervadec",
        "given_name": "Hoel"
      },
      {
        "surname": "Dolz",
        "given_name": "Jose"
      },
      {
        "surname": "Ben Ayed",
        "given_name": "Ismail"
      },
      {
        "surname": "Pedersoli",
        "given_name": "Marco"
      },
      {
        "surname": "Desrosiers",
        "given_name": "Christian"
      }
    ]
  },
  {
    "title": "Delay-distribution-dependent state estimation for neural networks under stochastic communication protocol with uncertain transition probabilities",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.023",
    "abstract": "In this paper, the protocol-based remote state estimation problem is considered for a kind of delayed artificial neural networks. The random time-varying delays fall into certain intervals with known probability distributions. For the sake of reducing the data collisions in communication channel from the sensors to the estimator, the stochastic communication protocol (SCP) is employed to decide which sensor is allowed to transmit its data to the remote estimator through the channel at each fixed instant. The scheduling principle of the SCP is governed by a Markov chain whose transition probability is allowed to be uncertain so as to reflect the possible imprecision when implementing the SCP. Through a combination of Lyapunov–Krasovskii functional method and the stochastic analysis technique, a sufficient criterion is obtained for the existence of the desired remote state estimator ensuring that the corresponding augmented estimation error dynamics is asymptotically stable with a prescribed H ∞ performance index. Furthermore, the estimator parameter is acquired by solving a convex optimization problem. Finally, the validity of the established theoretical results is demonstrated via a numerical simulation example.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302380",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Estimator",
      "Machine learning",
      "Markov chain",
      "Mathematical optimization",
      "Mathematics",
      "Probability distribution",
      "Scheduling (production processes)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Jiahui"
      },
      {
        "surname": "Wang",
        "given_name": "Zidong"
      },
      {
        "surname": "Dong",
        "given_name": "Hongli"
      },
      {
        "surname": "Fei",
        "given_name": "Weiyin"
      }
    ]
  },
  {
    "title": "Asynchronous dissipative filtering for nonhomogeneous Markov switching neural networks with variable packet dropouts",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.012",
    "abstract": "This work focuses on the problem of asynchronous filtering for nonhomogeneous Markov switching neural networks with variable packet dropouts (VPDs). The discrete-time nonhomogeneous Markov process is adopted to depict the modes switching of target plant, where time-varying transition probabilities are revealed by utilizing a polytope technology. By means of the Bernoulli distributed sequence, the randomly occurring packet dropouts are presented, where VPD rates are mode-dependent and remain variable. Unlike the existing results, the hidden Markov model scheme is formulated to describe the asynchronization between nonhomogeneous neural networks and filter, and resilient filters are presented, which makes the designed filters more general. Eventually, a simulation example is established to verify the effectiveness of the developed filter scheme.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302537",
    "keywords": [
      "Aerospace engineering",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Asynchronous communication",
      "Bernoulli's principle",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Filter (signal processing)",
      "Machine learning",
      "Markov chain",
      "Markov model",
      "Markov process",
      "Mathematical analysis",
      "Mathematics",
      "Network packet",
      "Statistics",
      "Telecommunications",
      "Variable (mathematics)",
      "Variable-order Markov model"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Xia"
      },
      {
        "surname": "Cheng",
        "given_name": "Jun"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Ragulskis",
        "given_name": "Minvydas"
      }
    ]
  },
  {
    "title": "Self-organizing subspace clustering for high-dimensional and multi-view data",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.022",
    "abstract": "A surge in the availability of data from multiple sources and modalities is correlated with advances in how to obtain, compress, store, transfer, and process large amounts of complex high-dimensional data. The clustering challenge increases with the growth of data dimensionality which decreases the discriminate power of the distance metrics. Subspace clustering aims to group data drawn from a union of subspaces. In such a way, there is a large number of state-of-the-art approaches and we divide them into families regarding the method used in the clustering. We introduce a soft subspace clustering algorithm, a Self-organizing Map (SOM) with a time-varying structure, to cluster data without any prior knowledge of the number of categories or of the neural network topology, both determined during the training process. The model also assigns proper relevancies (weights) to different dimensions, capturing from the learning process the influence of each dimension on uncovering clusters. We employ a number of real-world datasets to validate the model. This algorithm presents a competitive performance in a diverse range of contexts among them data mining, gene expression, multi-view, computer vision and text clustering problems which include high-dimensional data. Extensive experiments suggest that our method very often outperforms the state-of-the-art approaches in all types of problems considered.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302379",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Clustering high-dimensional data",
      "Computer science",
      "Curse of dimensionality",
      "Data mining",
      "Dimension (graph theory)",
      "Geometry",
      "Linear subspace",
      "Machine learning",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Pure mathematics",
      "Subspace topology"
    ],
    "authors": [
      {
        "surname": "Araújo",
        "given_name": "Aluizio F.R."
      },
      {
        "surname": "Antonino",
        "given_name": "Victor O."
      },
      {
        "surname": "Ponce-Guevara",
        "given_name": "Karina L."
      }
    ]
  },
  {
    "title": "A pruning feedforward small-world neural network based on Katz centrality for nonlinear system modeling",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.017",
    "abstract": "Approaching to the biological neural network, small-world neural networks have been demonstrated to improve the generalization performance of artificial neural networks. However, the architecture of small-world neural networks is typically large and predefined. This may cause the problems of overfitting and time consuming, and cannot obtain an optimal network structure automatically for a given problem. To solve the above problems, this paper proposes a pruning feedforward small-world neural network (PFSWNN), and applies it to nonlinear system modeling. Firstly, a feedforward small-world neural network (FSWNN) is constructed according to the rewiring rule of Watts–Strogatz. Secondly, the importance of each hidden neuron is evaluated based on its Katz centrality. If the Katz centrality of a hidden neuron is below the predefined threshold, this neuron is considered to be an unimportant node and then merged with its most correlated neuron in the same hidden layer. The connection weights are trained using the gradient-based algorithm, and the convergence of the proposed PFSWNN is theoretically analyzed in this paper. Finally, the PFSWNN model is tested on some problems for nonlinear system modeling, including the approximation for a rapidly changing function, CATS missing time-series prediction, four benchmark problems of UCI public datasets and a practical problem for wastewater treatment process. Experimental results demonstrate that PFSWNN exhibits superior generalization performance by small-world property as well as the pruning algorithm, and the training time of PFSWNN is shortened owning to a compact structure.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302586",
    "keywords": [
      "Activation function",
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Control engineering",
      "Engineering",
      "Feed forward",
      "Feedforward neural network",
      "Generalization",
      "Geodesy",
      "Geography",
      "Mathematical analysis",
      "Mathematics",
      "Overfitting",
      "Pruning",
      "Time delay neural network"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Wenjing"
      },
      {
        "surname": "Chu",
        "given_name": "Minghui"
      },
      {
        "surname": "Qiao",
        "given_name": "Junfei"
      }
    ]
  },
  {
    "title": "R-ELMNet: Regularized extreme learning machine network",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.009",
    "abstract": "Principal component analysis network (PCANet), as an unsupervised shallow network, demonstrates noticeable effectiveness on datasets of various volumes. It carries a two-layer convolution with PCA as filter learning method, followed by a block-wise histogram post-processing stage. Following the structure of PCANet, extreme learning machine auto-encoder (ELM-AE) variants are employed to replace the PCA’s role, which come from extreme learning machine network (ELMNet) and hierarchical ELMNet. ELMNet emphasizes the importance of orthogonal projection while overlooking non-linearity. The latter introduces complex pre-processing to overcome drawback of non-linear ELM-AE. In this paper, we analyze intrinsic characteristics of ELM-AE variants and accordingly propose a regularized ELM-AE, which combines non-linearity learning capability and approximately orthogonal projection. Experiments on image classification show the effectiveness compared to supervised convolutional neural networks and related shallow networks on unsupervised feature learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302240",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Extreme learning machine",
      "Feature (linguistics)",
      "Linearity",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Principal component analysis",
      "Projection (relational algebra)",
      "Quantum mechanics",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Guanghao"
      },
      {
        "surname": "Li",
        "given_name": "Yue"
      },
      {
        "surname": "Cui",
        "given_name": "Dongshun"
      },
      {
        "surname": "Mao",
        "given_name": "Shangbo"
      },
      {
        "surname": "Huang",
        "given_name": "Guang-Bin"
      }
    ]
  },
  {
    "title": "Visual interaction networks: A novel bio-inspired computational model for image classification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.019",
    "abstract": "Inspired by biological mechanisms and structures in neuroscience, many biologically inspired visual computational models have been presented to provide new solutions for visual recognition task. For example, convolutional neural network (CNN) was proposed according to the hierarchical structure of biological vision, which could achieve superior performance in large-scale image classification. In this paper, we propose a new framework called visual interaction networks (VIN-Net), which is inspired by visual interaction mechanisms. More specifically, self-interaction, mutual-interaction, multi-interaction, and adaptive interaction are proposed in VIN-Net, forming the first interactive completeness of the visual interaction model. To further enhance the representation ability of visual features, the adaptive adjustment mechanism is integrated into the VIN-Net model. Finally, our model is evaluated on three benchmark datasets and two self-built textile defect datasets. The experimental results demonstrate that the proposed model exhibits its efficiency on visual classification tasks. Furthermore, a textile industrial application shows that the proposed architecture outperforms the state-of-the-art approaches in classification performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302343",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Convolutional neural network",
      "Economics",
      "Geodesy",
      "Geography",
      "Law",
      "Machine learning",
      "Management",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Task (project management)",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Bing"
      },
      {
        "surname": "He",
        "given_name": "Haibo"
      },
      {
        "surname": "Hao",
        "given_name": "Kuangrong"
      },
      {
        "surname": "Gao",
        "given_name": "Lei"
      },
      {
        "surname": "Tang",
        "given_name": "Xue-song"
      }
    ]
  },
  {
    "title": "Learning explicitly transferable representations for domain adaptation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.016",
    "abstract": "Domain adaptation tackles the problem where the training source domain and the test target domain have distinctive data distributions, and therefore improves the generalization ability of deep models. The very popular mechanism of domain adaptation is to learn a new feature representation which is supposed to be domain-invariant, so that the classifiers trained on the source domain can be directly applied to the target domain. However, recent work reveals that learning new feature representations may potentially deteriorate the adaptability of the original features and increase the expected error bound of the target domain. To address this, we propose to adapt classifiers rather than features. Specifically, we fill in the distribution gaps between domains by some additional transferable representations which are explicitly learned from the original features while keeping the original features unchanged. In addition, we argue that transferable representations should be able to be translated from one domain to the other with appropriate mappings. At the same time, we introduce conditional entropy to mitigate the semantic confusion during mapping. Experiments on both standard and large-scale datasets verify that our method is able to achieve the new state-of-the-art results on unsupervised domain adaptation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302318",
    "keywords": [
      "Adaptability",
      "Artificial intelligence",
      "Biology",
      "Classifier (UML)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Ecology",
      "Feature (linguistics)",
      "Law",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Jing",
        "given_name": "Mengmeng"
      },
      {
        "surname": "Li",
        "given_name": "Jingjing"
      },
      {
        "surname": "Lu",
        "given_name": "Ke"
      },
      {
        "surname": "Zhu",
        "given_name": "Lei"
      },
      {
        "surname": "Yang",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Heart sound classification based on improved MFCC features and convolutional recurrent neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.015",
    "abstract": "Heart sound classification plays a vital role in the early detection of cardiovascular disorders, especially for small primary health care clinics. Despite that much progress has been made for heart sound classification in recent years, most of them are based on conventional segmented features and shallow structure based classifiers. These conventional acoustic representation and classification methods may be insufficient in characterizing heart sound, and generally suffer from a degraded performance due to the complicated and changeable cardiac acoustic environment. In this paper, we propose a new heart sound classification method based on improved Mel-frequency cepstrum coefficient (MFCC) features and convolutional recurrent neural networks. The Mel-frequency cepstrums are firstly calculated without dividing the heart sound signal. A new improved feature extraction scheme based on MFCC is proposed to elaborate the dynamic characteristics among consecutive heart sound signals. Finally, the MFCC-based features are fed to a deep convolutional and recurrent neural network (CRNN) for feature learning and later classification task. The proposed deep learning framework can take advantage of the encoded local characteristics extracted from the convolutional neural network (CNN) and the long-term dependencies captured by the recurrent neural network (RNN). Comprehensive studies on the performance of different network parameters and different network connection strategies are presented in this paper. Performance comparisons with state-of-the-art algorithms are given for discussions. Experiments show that, for the two-class classification problem (pathological or non-pathological), a classification accuracy of 98% has been achieved on the 2016 PhysioNet/CinC Challenge database.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302306",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cepstrum",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Feature (linguistics)",
      "Feature extraction",
      "Linguistics",
      "Mel-frequency cepstrum",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Recurrent neural network",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Deng",
        "given_name": "Muqing"
      },
      {
        "surname": "Meng",
        "given_name": "Tingting"
      },
      {
        "surname": "Cao",
        "given_name": "Jiuwen"
      },
      {
        "surname": "Wang",
        "given_name": "Shimin"
      },
      {
        "surname": "Zhang",
        "given_name": "Jing"
      },
      {
        "surname": "Fan",
        "given_name": "Huijie"
      }
    ]
  },
  {
    "title": "Towards explainable deep neural networks (xDNN)",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.010",
    "abstract": "In this paper, we propose an elegant solution that is directly addressing the bottlenecks of the traditional deep learning approaches and offers an explainable internal architecture that can outperform the existing methods, requires very little computational resources (no need for GPUs) and short training times (in the order of seconds). The proposed approach, xDNN is using prototypes. Prototypes are actual training data samples (images), which are local peaks of the empirical data distribution called typicality as well as of the data density. This generative model is identified in a closed form and equates to the pdf but is derived automatically and entirely from the training data with no user- or problem-specific thresholds, parameters or intervention. The proposed xDNN offers a new deep learning architecture that combines reasoning and learning in a synergy. It is non-iterative and non-parametric, which explains its efficiency in terms of time and computational resources. From the user perspective, the proposed approach is clearly understandable to human users. We tested it on challenging problems as the classification of different lighting conditions for driving scenes (iROADS), object detection (Caltech-256, and Caltech-101), and SARS-CoV-2 identification via computed tomography scan (COVID CT-scans dataset). xDNN outperforms the other methods including deep learning in terms of accuracy, time to train and offers an explainable classifier.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302513",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Generative grammar",
      "Generative model",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematics",
      "Parametric statistics",
      "Statistics",
      "Training set",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Angelov",
        "given_name": "Plamen"
      },
      {
        "surname": "Soares",
        "given_name": "Eduardo"
      }
    ]
  },
  {
    "title": "Towards explainable deep neural networks (xDNN)",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.010",
    "abstract": "In this paper, we propose an elegant solution that is directly addressing the bottlenecks of the traditional deep learning approaches and offers an explainable internal architecture that can outperform the existing methods, requires very little computational resources (no need for GPUs) and short training times (in the order of seconds). The proposed approach, xDNN is using prototypes. Prototypes are actual training data samples (images), which are local peaks of the empirical data distribution called typicality as well as of the data density. This generative model is identified in a closed form and equates to the pdf but is derived automatically and entirely from the training data with no user- or problem-specific thresholds, parameters or intervention. The proposed xDNN offers a new deep learning architecture that combines reasoning and learning in a synergy. It is non-iterative and non-parametric, which explains its efficiency in terms of time and computational resources. From the user perspective, the proposed approach is clearly understandable to human users. We tested it on challenging problems as the classification of different lighting conditions for driving scenes (iROADS), object detection (Caltech-256, and Caltech-101), and SARS-CoV-2 identification via computed tomography scan (COVID CT-scans dataset). xDNN outperforms the other methods including deep learning in terms of accuracy, time to train and offers an explainable classifier.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302513",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Generative grammar",
      "Generative model",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematics",
      "Parametric statistics",
      "Statistics",
      "Training set",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Angelov",
        "given_name": "Plamen"
      },
      {
        "surname": "Soares",
        "given_name": "Eduardo"
      }
    ]
  },
  {
    "title": "Quantifying the generalization error in deep learning in terms of data distribution and neural network smoothness",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.024",
    "abstract": "The accuracy of deep learning, i.e., deep neural networks, can be characterized by dividing the total error into three main types: approximation error, optimization error, and generalization error. Whereas there are some satisfactory answers to the problems of approximation and optimization, much less is known about the theory of generalization. Most existing theoretical works for generalization fail to explain the performance of neural networks in practice. To derive a meaningful bound, we study the generalization error of neural networks for classification problems in terms of data distribution and neural network smoothness. We introduce the cover complexity (CC) to measure the difficulty of learning a data set and the inverse of the modulus of continuity to quantify neural network smoothness. A quantitative bound for expected accuracy/error is derived by considering both the CC and neural network smoothness. Although most of the analysis is general and not specific to neural networks, we validate our theoretical assumptions and results numerically for neural networks by several data sets of images. The numerical results confirm that the expected error of trained networks scaled with the square root of the number of classes has a linear relationship with respect to the CC. We also observe a clear consistency between test loss and neural network smoothness during the training process. In addition, we demonstrate empirically that the neural network smoothness decreases when the network size increases whereas the smoothness is insensitive to training dataset size.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302392",
    "keywords": [],
    "authors": [
      {
        "surname": "Jin",
        "given_name": "Pengzhan"
      },
      {
        "surname": "Lu",
        "given_name": "Lu"
      },
      {
        "surname": "Tang",
        "given_name": "Yifa"
      },
      {
        "surname": "Karniadakis",
        "given_name": "George Em"
      }
    ]
  },
  {
    "title": "A novel feature representation: Aggregating convolution kernels for image retrieval",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.010",
    "abstract": "Activated hidden units in convolutional neural networks (CNNs), known as feature maps, dominate image representation, which is compact and discriminative. For ultra-large datasets, high dimensional feature maps in float format not only result in high computational complexity, but also occupy massive memory space. To this end, a new image representation by aggregating convolution kernels (ACK) is proposed, where some convolution kernels capturing certain patterns are activated. The top-n index numbers of the convolution kernels are extracted directly as image representation in discrete integer values, which rebuild relationship between convolution kernels and image. Furthermore, a distance measurement is defined from the perspective of ordered sets to calculate position-sensitive similarities between image representations. Extensive experiments conducted on Oxford Buildings, Paris, and Holidays, etc., manifest that the proposed ACK achieves competitive performance on image retrieval with much lower computational cost, outperforming the ones using feature maps for image representation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302252",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Discrete mathematics",
      "Discriminative model",
      "Feature (linguistics)",
      "Feature vector",
      "Image (mathematics)",
      "Kernel (algebra)",
      "Law",
      "Linguistics",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Qi"
      },
      {
        "surname": "Lai",
        "given_name": "Jinxing"
      },
      {
        "surname": "Claesen",
        "given_name": "Luc"
      },
      {
        "surname": "Yang",
        "given_name": "Zhenguo"
      },
      {
        "surname": "Lei",
        "given_name": "Liang"
      },
      {
        "surname": "Liu",
        "given_name": "Wenyin"
      }
    ]
  },
  {
    "title": "Dynamical system based compact deep hybrid network for classification of Parkinson disease related EEG signals",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.018",
    "abstract": "Electroencephalogram (EEG) signals accumulate the brain’s spiking activities using standardized electrodes placed at the scalp. These cumulative brain signals are chaotic in nature and vary depending upon current physical and/or mental activities. The anatomy of the brain is altered when dopamine releasing neurons die because of Parkinson Disease (PD), a neurodegenerative disorder. The resulting alterations force synchronized neuronal activity in β frequency components deep within motor region of the brain. This synchronization in the motor region affects the dynamical behavior of the brain activities, which induce motor related impairments in patient’s limbs. Identification of reliable bio-markers for PD is active research area since there are no tests or scans to diagnose PD. We use embedding reconstruction, a tool from chaos theory, to highlight PD-related alterations in dynamical properties of EEG and present it as a potentially reliable bio-marker for PD related classification. We use Individual Component Analysis (ICA) to demonstrate that the strengthened synchronizations can be cumulatively collected from EEG channels over the motor region of the brain. We use this information to select the 12 EEG channels for classification of On and Off medication PD patients. Additionally, there is the strong synchronization between amplitude of higher frequency components and phase of β components for PD patients. This information is used to improve the performance of this classification. We apply embedding reconstruction to design a new architecture of a deep neural network called Dynamical system Generated Hybrid Network. We report that this network outperforms the state of the art in terms of classification accuracy of 99 . 2 % ( + 0 . 52 % ) with approximately 24% of the computational resources. Apart from classification accuracy, we use well known statistical measures like specificity, sensitivity, Matthews Correlation Coefficient (MCC), F1 score, and Cohen Kappa score for the analysis and comparison of classification performances.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302331",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Disease",
      "Electroencephalography",
      "Medicine",
      "Neuroscience",
      "Parkinson's disease",
      "Pathology",
      "Pattern recognition (psychology)",
      "Phase synchronization",
      "Psychology",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Shah",
        "given_name": "Syed Aamir Ali"
      },
      {
        "surname": "Zhang",
        "given_name": "Lei"
      },
      {
        "surname": "Bais",
        "given_name": "Abdul"
      }
    ]
  },
  {
    "title": "Hybrid multi-mode machine learning-based fault diagnosis strategies with application to aircraft gas turbine engines",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.001",
    "abstract": "In this work, a novel data-driven fault diagnostic framework is developed by using hybrid multi-mode machine learning strategies to monitor system health status. The coexistence of multi-mode and concurrent faults and their adverse coupling effects pose serious limitations for developing reliable diagnostic methodologies. A novel framework is proposed by exploiting inherent embedded health information contained in the I/O sensor data. The proposed hybrid strategies consist of optimal integration of recurrent neural network-based feature generation and self-organizing map diagnostic modules. To construct reliable fault diagnostic modules, a systematic clustering and modeling methodology is developed that has two primary advantages: (i) it does not require any a priori knowledge of data set characteristics or system mathematical model, and (ii) it does address and resolve the key limitations and challenges in conventional self-organizing map approaches. The effectiveness of our proposed framework is validated by utilizing sensor data including healthy and various degradation modes in application to compressor and turbine of an aircraft gas turbine engine. Comparisons with other machine learning-based methods in the literature are provided to demonstrate the performance and superiority of our proposed framework in fault diagnostic accuracy, false alarm rates, and in dealing with multi-mode and concurrent fault scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302422",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Artificial neural network",
      "Cluster analysis",
      "Computer science",
      "Construct (python library)",
      "Data mining",
      "Fault (geology)",
      "Fault detection and isolation",
      "Geology",
      "Machine learning",
      "Programming language",
      "Seismology"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Yanyan"
      },
      {
        "surname": "Khorasani",
        "given_name": "Khashayar"
      }
    ]
  },
  {
    "title": "Quantum neural networks model based on swap test and phase estimation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.003",
    "abstract": "In this paper, a neural networks model for quantum computer is proposed. The core of this model is quantum neuron. Firstly, the inner product of the input qubits and the weight qubits is mapped to the phase of the control qubits in the neuron by the swap test technology, and then these phases are obtained by the phase estimation method, which are further used as the phase of the output qubit in the neuron. In this way, the mapping of input qubits to output qubit in quantum neuron is completed. The quantum neurons mentioned above can be used to construct quantum neural networks. In this paper, the quantum circuit for each operation step are given. The simulation results on the classic computer verify the effectiveness of the proposed model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302446",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biological neuron model",
      "Combinatorics",
      "Computer science",
      "Mathematics",
      "Physics",
      "Quantum",
      "Quantum circuit",
      "Quantum computer",
      "Quantum error correction",
      "Quantum mechanics",
      "Quantum phase estimation algorithm",
      "Qubit",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Panchi"
      },
      {
        "surname": "Wang",
        "given_name": "Bing"
      }
    ]
  },
  {
    "title": "A learning approach with incomplete pixel-level labels for deep neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.025",
    "abstract": "Learning with incomplete labels in Neural Networks has been actively investigated these last years. Among different kinds of incomplete labels, we investigate incomplete pixel-level labels which are tackled in many concrete problems. One of the challenges for incomplete pixel-level labels is the missing information at local-level. Most of the current researches with incomplete labels in Neural Network focus on the incompleteness of global labels, only a few works focus on the incompleteness of local labels. To deal with the local incompleteness, we propose a learning approach which uses two dynamic weighted maps in parallel: one for object pixels and another one for background pixels. The two maps are integrated into the loss function of the target Neural Networks, to optimize the model by the present labels and to minimize the damage of the missing labels. We validate our approach on the speech balloon extraction problem in comic book images. Our approach uses the output of a balloon extraction algorithm as incomplete labels. The results are comparable with the state of the art supervised approach with manual labels. The results are very promising because our method does not require any manual labels. In addition, we apply our method to the medical image segmentation task to confirm the generalization of our approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302409",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Economics",
      "Focus (optics)",
      "Generalization",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Object (grammar)",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Pixel",
      "Segmentation",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Nguyen",
        "given_name": "Nhu-Van"
      },
      {
        "surname": "Rigaud",
        "given_name": "Christophe"
      },
      {
        "surname": "Revel",
        "given_name": "Arnaud"
      },
      {
        "surname": "Burie",
        "given_name": "Jean-Christophe"
      }
    ]
  },
  {
    "title": "Feature fusion via Deep Random Forest for facial age estimation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.006",
    "abstract": "In the last few years, human age estimation from face images attracted the attention of many researchers in computer vision and machine learning fields. This is due to its numerous applications. In this paper, we propose a new architecture for age estimation based on facial images. It is mainly based on a cascade of classification trees ensembles, which are known recently as a Deep Random Forest. Our architecture is composed of two types of DRF. The first type extends and enhances the feature representation of a given facial descriptor. The second type operates on the fused form of all enhanced representations in order to provide a prediction for the age while taking into account the fuzziness property of the human age. While the proposed methodology is able to work with all kinds of image features, the face descriptors adopted in this work used off-the-shelf deep features allowing to retain both the rich deep features and the powerful enhancement and decision provided by the proposed architecture. Experiments conducted on six public databases prove the superiority of the proposed architecture over other state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302471",
    "keywords": [
      "Archaeology",
      "Architecture",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Epistemology",
      "Face (sociological concept)",
      "Feature (linguistics)",
      "Feature extraction",
      "Geography",
      "Law",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Property (philosophy)",
      "Random forest",
      "Representation (politics)",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Guehairia",
        "given_name": "O."
      },
      {
        "surname": "Ouamane",
        "given_name": "A."
      },
      {
        "surname": "Dornaika",
        "given_name": "F."
      },
      {
        "surname": "Taleb-Ahmed",
        "given_name": "A."
      }
    ]
  },
  {
    "title": "Hybrid neural network with cost-sensitive support vector machine for class-imbalanced multimodal data",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.026",
    "abstract": "Although deep learning exhibits advantages in various applications involving multimodal data, it cannot effectively solve the class-imbalance problem. Herein, we propose a hybrid neural network with a cost-sensitive support vector machine (hybrid NN-CSSVM) for class-imbalanced multimodal data. We used a fused multiple-network structure obtained by extracting the features of different modality data, and used cost-sensitive support vector machines (SVMs) as a classifier. To alleviate the insufficiency of learning from minority-class data, our proposed cost-sensitive SVM loss function reflects different weights of misclassification errors from both majority and minority classes, by controlling cost parameters. Additionally, we present a theoretical setting of the cost parameters in our model. The proposed model is validated on real datasets that range from low to high imbalance ratios. By exploiting the complementary advantages of two architectures, the hybrid NN-CSSVM performs excellently, even with data having a minor-class proportion of only 2%.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302410",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Classifier (UML)",
      "Computer science",
      "Data mining",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Kyung Hye"
      },
      {
        "surname": "Sohn",
        "given_name": "So Young"
      }
    ]
  },
  {
    "title": "Fixed-time synchronization of stochastic memristor-based neural networks with adaptive control",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.07.002",
    "abstract": "In this study, we consider the fixed-time synchronization problem for stochastic memristor-based neural networks (MNNs) via two different controllers. First, a new stochastic differential equation is established using differential inclusions and set-valued maps. Next, two kinds of control protocols are designed, including a nonlinear delayed state feedback control scheme and a novel adaptive control strategy, by which fixed-time synchronization of MNNs can be achieved. Then based on stochastic analysis techniques and a Lyapunov function, some sufficient criteria are obtained to ensure that stochastic MNNs achieve stochastic fixed-time synchronization in probability. In addition, the upper bound of the settling time is estimated. Finally, simulation results are provided to demonstrate the validity of the proposed schemes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302434",
    "keywords": [
      "Adaptive control",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Differential inclusion",
      "Electrical engineering",
      "Engineering",
      "Lyapunov function",
      "Mathematical optimization",
      "Mathematics",
      "Memristor",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Settling time",
      "Statistics",
      "Step response",
      "Stochastic differential equation",
      "Stochastic neural network",
      "Stochastic process",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Ren",
        "given_name": "Hongwei"
      },
      {
        "surname": "Peng",
        "given_name": "Zhiping"
      },
      {
        "surname": "Gu",
        "given_name": "Yu"
      }
    ]
  },
  {
    "title": "Deep learning for symbols detection and classification in engineering drawings",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.025",
    "abstract": "Engineering drawings are commonly used in different industries such as Oil and Gas, construction, and other types of engineering. Digitising these drawings is becoming increasingly important. This is mainly due to the need to improve business practices such as inventory, assets management, risk analysis, and other types of applications. However, processing and analysing these drawings is a challenging task. A typical diagram often contains a large number of different types of symbols belonging to various classes and with very little variation among them. Another key challenge is the class-imbalance problem, where some types of symbols largely dominate the data while others are hardly represented in the dataset. In this paper, we propose methods to handle these two challenges. First, we propose an advanced bounding-box detection method for localising and recognising symbols in engineering diagrams. Our method is end-to-end with no user interaction. Thorough experiments on a large collection of diagrams from an industrial partner proved that our methods accurately recognise more than 94% of the symbols. Secondly, we present a method based on Deep Generative Adversarial Neural Network for handling class-imbalance. The proposed GAN model proved to be capable of learning from a small number of training examples. Experiment results showed that the proposed method greatly improved the classification of symbols in engineering drawings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301957",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Astrophysics",
      "Class (philosophy)",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Economics",
      "Engineering",
      "Engineering drawing",
      "Generative grammar",
      "Image (mathematics)",
      "Key (lock)",
      "Machine learning",
      "Management",
      "Minimum bounding box",
      "Physics",
      "Task (project management)",
      "Technical drawing",
      "Variation (astronomy)"
    ],
    "authors": [
      {
        "surname": "Elyan",
        "given_name": "Eyad"
      },
      {
        "surname": "Jamieson",
        "given_name": "Laura"
      },
      {
        "surname": "Ali-Gombe",
        "given_name": "Adamu"
      }
    ]
  },
  {
    "title": "Initializing photonic feed-forward neural networks using auxiliary tasks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.024",
    "abstract": "Photonics is among the most promising emerging technologies for providing fast and energy-efficient Deep Learning (DL) implementations. Despite their advantages, these photonic DL accelerators also come with certain important limitations. For example, the majority of existing photonic accelerators do not currently support many of the activation functions that are commonly used in DL, such as the ReLU activation function. Instead, sinusoidal and sigmoidal nonlinearities are usually employed, rendering the training process unstable and difficult to tune, mainly due to vanishing gradient phenomena. Thus, photonic DL models usually require carefully fine-tuning all their training hyper-parameters in order to ensure that the training process will proceed smoothly. Despite the recent advances in initialization schemes, as well as in optimization algorithms, training photonic DL models is still especially challenging. To overcome these limitations, we propose a novel adaptive initialization method that employs auxiliary tasks to estimate the optimal initialization variance for each layer of a network. The effectiveness of the proposed approach is demonstrated using two different datasets, as well as two recently proposed photonic activation functions and three different initialization methods. Apart from significantly increasing the stability of the training process, the proposed method can be directly used with any photonic activation function, without further requiring any other kind of fine-tuning, as also demonstrated through the conducted experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301945",
    "keywords": [
      "Activation function",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer engineering",
      "Computer science",
      "Initialization",
      "Operating system",
      "Optics",
      "Photonics",
      "Physics",
      "Process (computing)",
      "Programming language",
      "Rendering (computer graphics)"
    ],
    "authors": [
      {
        "surname": "Passalis",
        "given_name": "Nikolaos"
      },
      {
        "surname": "Mourgias-Alexandris",
        "given_name": "George"
      },
      {
        "surname": "Pleros",
        "given_name": "Nikos"
      },
      {
        "surname": "Tefas",
        "given_name": "Anastasios"
      }
    ]
  },
  {
    "title": "Error bounds for deep ReLU networks using the Kolmogorov–Arnold superposition theorem",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.013",
    "abstract": "We prove a theorem concerning the approximation of multivariate functions by deep ReLU networks, for which the curse of the dimensionality is lessened. Our theorem is based on a constructive proof of the Kolmogorov–Arnold superposition theorem, and on a subset of multivariate continuous functions whose outer superposition functions can be efficiently approximated by deep ReLU networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304058",
    "keywords": [
      "Applied mathematics",
      "Computer science",
      "Constructive",
      "Constructive proof",
      "Curse of dimensionality",
      "Discrete mathematics",
      "Mathematical analysis",
      "Mathematics",
      "Multivariate statistics",
      "Operating system",
      "Process (computing)",
      "Pure mathematics",
      "Statistics",
      "Superposition principle"
    ],
    "authors": [
      {
        "surname": "Montanelli",
        "given_name": "Hadrien"
      },
      {
        "surname": "Yang",
        "given_name": "Haizhao"
      }
    ]
  },
  {
    "title": "A spiking neural network-based long-term prediction system for biogas production",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.001",
    "abstract": "Efficient energy production from biomass is a central issue in the context of clean alternative energy resource. In this work we propose a novel model based on spiking neural networks cubes in order to model the chemical processes that goes on in a digestor for the production of usable biogas. For the implementation of the predictive structure, we have used the NeuCube computational framework. The goals of the proposed model were: develop a tool for real applications (low-cost and efficient), generalize the data when the system presents high sensitivity to small differences on the initial conditions, take in account the “multi-scale” temporal dynamics of the chemical processes occurring in the digestor, since the variations present in the early stages of the processes are very quick, whereas in the later stages are slower. By using the first ten days of observation the implemented system has been proven able to predict the evolution of the chemical process up to the 100th day obtaining a high degree of accuracy with respect to the experimental data measured in laboratory. This is due to the fact that the spiking neural networks have shown to be able to modeling complex information processes and then it has been shown that spiking neurons are able to handle patterns of activity that spans different time scales. Thanks to such properties, our system is able to capture the multi-scale trend of the time series associated to the early-stage evolutions, as well as their interaction, which are crucial in the point of view of the information content to obtain a good long-term prediction.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302069",
    "keywords": [
      "Anaerobic digestion",
      "Artificial intelligence",
      "Artificial neural network",
      "Biogas",
      "Biogas production",
      "Biological system",
      "Biology",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Context (archaeology)",
      "Data mining",
      "Economics",
      "Electronic engineering",
      "Engineering",
      "Machine learning",
      "Macroeconomics",
      "Methane",
      "Operating system",
      "Organic chemistry",
      "Paleontology",
      "Physics",
      "Process (computing)",
      "Process engineering",
      "Production (economics)",
      "Quantum mechanics",
      "Resource (disambiguation)",
      "Scale (ratio)",
      "Sensitivity (control systems)",
      "Spiking neural network",
      "Term (time)",
      "USable",
      "Waste management",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Capizzi",
        "given_name": "Giacomo"
      },
      {
        "surname": "Lo Sciuto",
        "given_name": "Grazia"
      },
      {
        "surname": "Napoli",
        "given_name": "Christian"
      },
      {
        "surname": "Woźniak",
        "given_name": "Marcin"
      },
      {
        "surname": "Susi",
        "given_name": "Gianluca"
      }
    ]
  },
  {
    "title": "Graph embedded rules for explainable predictions in data streams",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.035",
    "abstract": "Understanding the reason why a prediction has been made by a machine is crucial to grant trust to a human decision-maker. However, data mining based decision support systems are, in general, not designed to promote interpretability; instead, they are developed to improve accuracy. Interpretability becomes a more challenging issue in the context of data stream mining. Where the prediction model has to deal with enormous volumes of data gathered continuously at a fast rate and whose underlying distribution may change over time. On the one hand, the majority of the methods that address classification in a data stream are black-box models or white-box models into ensembles. Either do not provide a clear view of why a particular decision has been made. On the other hand, white-box models, such as rule-based models, do not provide acceptable accuracy to be considered in many applications. This paper proposes modeling the data as a special graph, which is built over the attribute space, and from which interpretable rules can be extracted. To overcome concept drift and enhance model accuracy, different variants of such graphs are considered within an ensemble that is updated over time. The proposed approach has shown the best overall classification results when compared to six rule-based algorithms in twelve streaming domains.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302057",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Black box",
      "Computer science",
      "Concept drift",
      "Context (archaeology)",
      "Data mining",
      "Data stream",
      "Data stream mining",
      "Graph",
      "Interpretability",
      "Machine learning",
      "Paleontology",
      "Streaming data",
      "Telecommunications",
      "Theoretical computer science",
      "White box"
    ],
    "authors": [
      {
        "surname": "Bertini",
        "given_name": "João Roberto"
      }
    ]
  },
  {
    "title": "Encoding primitives generation policy learning for robotic arm to overcome catastrophic forgetting in sequential multi-tasks learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.003",
    "abstract": "Continual learning, a widespread ability in people and animals, aims to learn and acquire new knowledge and skills continuously. Catastrophic forgetting usually occurs in continual learning when an agent attempts to learn different tasks sequentially without storing or accessing previous task information. Unfortunately, current learning systems, e.g., neural networks, are prone to deviate the weights learned in previous tasks after training new tasks, leading to catastrophic forgetting, especially in a sequential multi-tasks scenario. To address this problem, in this paper, we propose to overcome catastrophic forgetting with the focus on learning a series of robotic tasks sequentially. Particularly, a novel hierarchical neural network’s framework called Encoding Primitives Generation Policy Learning (E-PGPL) is developed to enable continual learning with two components. By employing a variational autoencoder to project the original state space into a meaningful low-dimensional feature space, representative state primitives could be sampled to help learn corresponding policies for different tasks. In learning a new task, the feature space is required to be close to the previous ones so that previously learned tasks can be protected. Extensive experiments on several simulated robotic tasks demonstrate our method’s efficacy to learn control policies for handling sequentially arriving multi-tasks, delivering improvement substantially over some other continual learning methods, especially for the tasks with more diversity.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302082",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Economics",
      "Encoding (memory)",
      "Feature (linguistics)",
      "Forgetting",
      "Linguistics",
      "Machine learning",
      "Management",
      "Mathematics",
      "Philosophy",
      "Reinforcement learning",
      "State space",
      "Statistics",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Xiong",
        "given_name": "Fangzhou"
      },
      {
        "surname": "Liu",
        "given_name": "Zhiyong"
      },
      {
        "surname": "Huang",
        "given_name": "Kaizhu"
      },
      {
        "surname": "Yang",
        "given_name": "Xu"
      },
      {
        "surname": "Qiao",
        "given_name": "Hong"
      },
      {
        "surname": "Hussain",
        "given_name": "Amir"
      }
    ]
  },
  {
    "title": "Interpretable and lightweight convolutional neural network for EEG decoding: Application to movement execution and imagination",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.032",
    "abstract": "Convolutional neural networks (CNNs) are emerging as powerful tools for EEG decoding: these techniques, by automatically learning relevant features for class discrimination, improve EEG decoding performances without relying on handcrafted features. Nevertheless, the learned features are difficult to interpret and most of the existing CNNs introduce many trainable parameters. Here, we propose a lightweight and interpretable shallow CNN (Sinc-ShallowNet), by stacking a temporal sinc-convolutional layer (designed to learn band-pass filters, each having only the two cut-off frequencies as trainable parameters), a spatial depthwise convolutional layer (reducing channel connectivity and learning spatial filters tied to each band-pass filter), and a fully-connected layer finalizing the classification. This convolutional module limits the number of trainable parameters and allows direct interpretation of the learned spectral–spatial​ features via simple kernel visualizations. Furthermore, we designed a post-hoc gradient-based technique to enhance interpretation by identifying the more relevant and more class-specific features. Sinc-ShallowNet was evaluated on benchmark motor-execution and motor-imagery datasets and against different design choices and training strategies. Results show that (i) Sinc-ShallowNet outperformed a traditional machine learning algorithm and other CNNs for EEG decoding; (ii) The learned spectral–spatial features matched well-known EEG motor-related activity; (iii) The proposed architecture performed better with a larger number of temporal kernels still maintaining a good compromise between accuracy and parsimony, and with a trialwise rather than a cropped training strategy. In perspective, the proposed approach, with its interpretative capacity, can be exploited to investigate cognitive/motor aspects whose EEG correlates are yet scarcely known, potentially characterizing their relevant features.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302021",
    "keywords": [
      "Aesthetics",
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Decoding methods",
      "Electroencephalography",
      "Movement (music)",
      "Neural decoding",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Psychology",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Borra",
        "given_name": "Davide"
      },
      {
        "surname": "Fantozzi",
        "given_name": "Silvia"
      },
      {
        "surname": "Magosso",
        "given_name": "Elisa"
      }
    ]
  },
  {
    "title": "Novel results on finite-time stabilization of state-based switched chaotic inertial neural networks with distributed delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.004",
    "abstract": "The p -norm finite-time stabilization (FTS) issue of a class of state-based switched inertial chaotic neural networks (SBSCINNs) with distributed time-varying delays is investigated. By using a suitable variable transformation, such second-order SBSCINNs are turned into the first-order differential equations. Then some novel criteria are obtained to stabilize SBSCINNs in a finite time based on the theory of finite-time control and non-smooth analysis together with designing two proper delay-dependent feedback controllers. Besides, the settling time of FTS is also estimated and discussed. Finally, the validity and practicability of the deduced theoretical results are verified by examples and applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302173",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chaotic",
      "Chemistry",
      "Class (philosophy)",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Gene",
      "Inertial frame of reference",
      "Law",
      "Norm (philosophy)",
      "Physics",
      "Political science",
      "Quantum mechanics",
      "Settling time",
      "State variable",
      "Step response",
      "Thermodynamics",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Long",
        "given_name": "Changqing"
      },
      {
        "surname": "Zhang",
        "given_name": "Guodong"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "A neurodynamic model of the interaction between color perception and color memory",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.008",
    "abstract": "The memory color effect and Spanish castle illusion have been taken as evidence of the cognitive penetrability of vision. In the same manner, the successful decoding of color-related brain signals in functional neuroimaging studies suggests the retrieval of memory colors associated with a perceived gray object. Here, we offer an alternative account of these findings based on the design principles of adaptive resonance theory (ART). In ART, conscious perception is a consequence of a resonant state. Resonance emerges in a recurrent cortical circuit when a bottom-up spatial pattern agrees with the top-down expectation. When they do not agree, a special control mechanism is activated that resets the network and clears off erroneous expectation, thus allowing the bottom-up activity to always dominate in perception. We developed a color ART circuit and evaluated its behavior in computer simulations. The model helps to explain how traces of erroneous expectations about incoming color are eventually removed from the color perception, although their transient effect may be visible in behavioral responses or in brain imaging. Our results suggest that the color ART circuit, as a predictive computational system, is almost never penetrable, because it is equipped with computational mechanisms designed to constrain the impact of the top-down predictions on ongoing perceptual processing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302215",
    "keywords": [
      "Adaptive resonance theory",
      "Artificial intelligence",
      "Artificial neural network",
      "Cognition",
      "Cognitive psychology",
      "Cognitive science",
      "Color vision",
      "Computational model",
      "Computer science",
      "Computer vision",
      "Illusion",
      "Neuroscience",
      "Perception",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Marić",
        "given_name": "Mateja"
      },
      {
        "surname": "Domijan",
        "given_name": "Dražen"
      }
    ]
  },
  {
    "title": "Appearance variation adaptation tracker using adversarial network",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.011",
    "abstract": "Visual trackers using deep neural networks have demonstrated favorable performance in object tracking. However, training a deep classification network using overlapped initial target regions may lead an overfitted model. To increase the model generalization, we propose an appearance variation adaptation (AVA) tracker that aligns the feature distributions of target regions over time by learning an adaptation mask in an adversarial network. The proposed adversarial network consists of a generator and a discriminator network that compete with each other over optimizing a discriminator loss in a mini-max optimization problem. Specifically, the discriminator network aims to distinguish recent target regions from earlier ones by minimizing the discriminator loss, while the generator network aims to produce an adaptation mask to maximize the discriminator loss. We incorporate a gradient reverse layer in the adversarial network to solve the aforementioned mini-max optimization in an end-to-end manner. We compare the performance of the proposed AVA tracker with the most recent state-of-the-art trackers by doing extensive experiments on OTB50, OTB100, and VOT2016 tracking benchmarks. Among the compared methods, AVA yields the highest area under curve (AUC) score of 0.712 and the highest average precision score of 0.951 on the OTB50 tracking benchmark. It achieves the second best AUC score of 0.688 and the best precision score of 0.924 on the OTB100 tracking benchmark. AVA also achieves the second best expected average overlap (EAO) score of 0.366, the best failure rate of 0.68, and the second best accuracy of 0.53 on the VOT2016 tracking benchmark.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302264",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Artificial neural network",
      "Astrophysics",
      "Benchmark (surveying)",
      "BitTorrent tracker",
      "Computer network",
      "Computer science",
      "Detector",
      "Discriminator",
      "Eye tracking",
      "Feature (linguistics)",
      "Generalization",
      "Generator (circuit theory)",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Network performance",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Telecommunications",
      "Variation (astronomy)"
    ],
    "authors": [
      {
        "surname": "Javanmardi",
        "given_name": "Mohammadreza"
      },
      {
        "surname": "Qi",
        "given_name": "Xiaojun"
      }
    ]
  },
  {
    "title": "A neurodynamic model of the interaction between color perception and color memory",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.008",
    "abstract": "The memory color effect and Spanish castle illusion have been taken as evidence of the cognitive penetrability of vision. In the same manner, the successful decoding of color-related brain signals in functional neuroimaging studies suggests the retrieval of memory colors associated with a perceived gray object. Here, we offer an alternative account of these findings based on the design principles of adaptive resonance theory (ART). In ART, conscious perception is a consequence of a resonant state. Resonance emerges in a recurrent cortical circuit when a bottom-up spatial pattern agrees with the top-down expectation. When they do not agree, a special control mechanism is activated that resets the network and clears off erroneous expectation, thus allowing the bottom-up activity to always dominate in perception. We developed a color ART circuit and evaluated its behavior in computer simulations. The model helps to explain how traces of erroneous expectations about incoming color are eventually removed from the color perception, although their transient effect may be visible in behavioral responses or in brain imaging. Our results suggest that the color ART circuit, as a predictive computational system, is almost never penetrable, because it is equipped with computational mechanisms designed to constrain the impact of the top-down predictions on ongoing perceptual processing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302215",
    "keywords": [
      "Adaptive resonance theory",
      "Artificial intelligence",
      "Artificial neural network",
      "Cognition",
      "Cognitive psychology",
      "Cognitive science",
      "Color vision",
      "Computational model",
      "Computer science",
      "Computer vision",
      "Illusion",
      "Neuroscience",
      "Perception",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Marić",
        "given_name": "Mateja"
      },
      {
        "surname": "Domijan",
        "given_name": "Dražen"
      }
    ]
  },
  {
    "title": "Interpretable and lightweight convolutional neural network for EEG decoding: Application to movement execution and imagination",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.032",
    "abstract": "Convolutional neural networks (CNNs) are emerging as powerful tools for EEG decoding: these techniques, by automatically learning relevant features for class discrimination, improve EEG decoding performances without relying on handcrafted features. Nevertheless, the learned features are difficult to interpret and most of the existing CNNs introduce many trainable parameters. Here, we propose a lightweight and interpretable shallow CNN (Sinc-ShallowNet), by stacking a temporal sinc-convolutional layer (designed to learn band-pass filters, each having only the two cut-off frequencies as trainable parameters), a spatial depthwise convolutional layer (reducing channel connectivity and learning spatial filters tied to each band-pass filter), and a fully-connected layer finalizing the classification. This convolutional module limits the number of trainable parameters and allows direct interpretation of the learned spectral–spatial​ features via simple kernel visualizations. Furthermore, we designed a post-hoc gradient-based technique to enhance interpretation by identifying the more relevant and more class-specific features. Sinc-ShallowNet was evaluated on benchmark motor-execution and motor-imagery datasets and against different design choices and training strategies. Results show that (i) Sinc-ShallowNet outperformed a traditional machine learning algorithm and other CNNs for EEG decoding; (ii) The learned spectral–spatial features matched well-known EEG motor-related activity; (iii) The proposed architecture performed better with a larger number of temporal kernels still maintaining a good compromise between accuracy and parsimony, and with a trialwise rather than a cropped training strategy. In perspective, the proposed approach, with its interpretative capacity, can be exploited to investigate cognitive/motor aspects whose EEG correlates are yet scarcely known, potentially characterizing their relevant features.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302021",
    "keywords": [
      "Aesthetics",
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Decoding methods",
      "Electroencephalography",
      "Movement (music)",
      "Neural decoding",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Psychology",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Borra",
        "given_name": "Davide"
      },
      {
        "surname": "Fantozzi",
        "given_name": "Silvia"
      },
      {
        "surname": "Magosso",
        "given_name": "Elisa"
      }
    ]
  },
  {
    "title": "Appearance variation adaptation tracker using adversarial network",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.011",
    "abstract": "Visual trackers using deep neural networks have demonstrated favorable performance in object tracking. However, training a deep classification network using overlapped initial target regions may lead an overfitted model. To increase the model generalization, we propose an appearance variation adaptation (AVA) tracker that aligns the feature distributions of target regions over time by learning an adaptation mask in an adversarial network. The proposed adversarial network consists of a generator and a discriminator network that compete with each other over optimizing a discriminator loss in a mini-max optimization problem. Specifically, the discriminator network aims to distinguish recent target regions from earlier ones by minimizing the discriminator loss, while the generator network aims to produce an adaptation mask to maximize the discriminator loss. We incorporate a gradient reverse layer in the adversarial network to solve the aforementioned mini-max optimization in an end-to-end manner. We compare the performance of the proposed AVA tracker with the most recent state-of-the-art trackers by doing extensive experiments on OTB50, OTB100, and VOT2016 tracking benchmarks. Among the compared methods, AVA yields the highest area under curve (AUC) score of 0.712 and the highest average precision score of 0.951 on the OTB50 tracking benchmark. It achieves the second best AUC score of 0.688 and the best precision score of 0.924 on the OTB100 tracking benchmark. AVA also achieves the second best expected average overlap (EAO) score of 0.366, the best failure rate of 0.68, and the second best accuracy of 0.53 on the VOT2016 tracking benchmark.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302264",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Artificial neural network",
      "Astrophysics",
      "Benchmark (surveying)",
      "BitTorrent tracker",
      "Computer network",
      "Computer science",
      "Detector",
      "Discriminator",
      "Eye tracking",
      "Feature (linguistics)",
      "Generalization",
      "Generator (circuit theory)",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Network performance",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Telecommunications",
      "Variation (astronomy)"
    ],
    "authors": [
      {
        "surname": "Javanmardi",
        "given_name": "Mohammadreza"
      },
      {
        "surname": "Qi",
        "given_name": "Xiaojun"
      }
    ]
  },
  {
    "title": "Prediction of N6-methyladenosine sites using convolution neural network model based on distributed feature representations",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.027",
    "abstract": "N6-methyladenosine (m6A) is a well-studied and most common interior messenger RNA (mRNA) modification that plays an important function in cell development. N6A is found in all kingdoms​ of life and many other cellular processes such as RNA splicing, immune tolerance, regulatory functions, RNA processing, and cancer. Despite the crucial role of m6A in cells, it was targeted computationally, but unfortunately, the obtained results were unsatisfactory. It is imperative to develop an efficient computational model that can truly represent m6A sites. In this regard, an intelligent and highly discriminative computational model namely: m6A-word2vec is introduced for the discrimination of m6A sites. Here, a concept of natural language processing in the form of word2vec is used to represent the motif of the target class automatically. These motifs (numerical descriptors) are automatically targeted from the human genome without any clear definition. Further, the extracted feature space is then forwarded to the convolution neural network model as input for prediction. The developed computational model obtained 83.17%, 92.69%, and 90.50% accuracy for benchmark datasets S 1 , S 2 , and S 3 , respectively, using a 10-fold cross-validation test. The predictive outcomes validate that the developed intelligent computational model showed better performance compared to existing computational models. It is thus greatly estimated that the introduced computational model “m6A-word2vec” may be a supportive and practical tool for elementary and pharmaceutical research such as in drug design along with academia.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301970",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computational complexity theory",
      "Computational model",
      "Computer science",
      "Discriminative model",
      "Embedding",
      "Feature (linguistics)",
      "Feature vector",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Philosophy",
      "Word2vec"
    ],
    "authors": [
      {
        "surname": "Tahir",
        "given_name": "Muhammad"
      },
      {
        "surname": "Hayat",
        "given_name": "Maqsood"
      },
      {
        "surname": "Chong",
        "given_name": "Kil To"
      }
    ]
  },
  {
    "title": "Missing data imputation with adversarially-trained graph convolutional networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.005",
    "abstract": "Missing data imputation (MDI) is the task of replacing missing values in a dataset with alternative, predicted ones. Because of the widespread presence of missing data, it is a fundamental problem in many scientific disciplines. Popular methods for MDI use global statistics computed from the entire dataset (e.g., the feature-wise medians), or build predictive models operating independently on every instance. In this paper we propose a more general framework for MDI, leveraging recent work in the field of graph neural networks (GNNs). We formulate the MDI task in terms of a graph denoising autoencoder, where each edge of the graph encodes the similarity between two patterns. A GNN encoder learns to build intermediate representations for each example by interleaving classical projection layers and locally combining information between neighbors, while another decoding GNN learns to reconstruct the full imputed dataset from this intermediate embedding. In order to speed-up training and improve the performance, we use a combination of multiple losses, including an adversarial loss implemented with the Wasserstein metric and a gradient penalty. We also explore a few extensions to the basic architecture involving the use of residual connections between layers, and of global statistics computed from the dataset to improve the accuracy. On a large experimental evaluation with varying levels of artificial noise, we show that our method is on par or better than several alternative imputation methods. On three datasets with pre-existing missing values, we show that our method is robust to the choice of a downstream classifier, obtaining similar or slightly higher results compared to other choices.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302185",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Graph",
      "Imputation (statistics)",
      "Machine learning",
      "Missing data",
      "Pattern recognition (psychology)",
      "Residual",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Spinelli",
        "given_name": "Indro"
      },
      {
        "surname": "Scardapane",
        "given_name": "Simone"
      },
      {
        "surname": "Uncini",
        "given_name": "Aurelio"
      }
    ]
  },
  {
    "title": "Phase portraits as movement primitives for fast humanoid robot control",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.007",
    "abstract": "Currently, usual approaches for fast robot control are largely reliant on solving online optimal control problems. Such methods are known to be computationally intensive and sensitive to model accuracy. On the other hand, animals plan complex motor actions not only fast but seemingly with little effort even on unseen tasks. This natural sense to infer temporal dynamics and coordination motivates us to approach robot control from a motor skill learning perspective to design fast and computationally light controllers that can be learned autonomously by the robot under mild modeling assumptions. This article introduces Phase Portrait Movement Primitives (PPMP), a primitive that predicts dynamics on a low dimensional phase space which in turn is used to govern the high dimensional kinematics of the task. The stark difference with other primitive formulations is a built-in mechanism for phase prediction in the form of coupled oscillators that replaces model-based state estimators such as Kalman filters. The policy is trained by optimizing the parameters of the oscillators whose output is connected to a kinematic distribution in the form of a phase portrait. The drastic reduction in dimensionality allows us to efficiently train and execute PPMPs on a real human-sized, dual-arm humanoid upper body on a task involving 20 degrees-of-freedom. We demonstrate PPMPs in interactions requiring fast reactions times while generating anticipative pose adaptation in both discrete and cyclic tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301271",
    "keywords": [
      "Artificial intelligence",
      "Bifurcation",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Degrees of freedom (physics and chemistry)",
      "Economics",
      "Estimator",
      "Humanoid robot",
      "Kinematics",
      "Management",
      "Mathematics",
      "Nonlinear system",
      "Phase portrait",
      "Physics",
      "Quantum mechanics",
      "Robot",
      "Statistics",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Maeda",
        "given_name": "Guilherme"
      },
      {
        "surname": "Koç",
        "given_name": "Okan"
      },
      {
        "surname": "Morimoto",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Image style transfer with collection representation space and semantic-guided reconstruction",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.028",
    "abstract": "Image style transfer renders the content of an image into different styles. Current methods made decent progress with transferring the style of single image, however, visual statistics from one image cannot reflect the full scope of an artist. Also, previous work did not put content preservation in the important position, which would result in poor structure integrity, thus deteriorating the comprehensibility of generated image. These two problems would limit the visual quality improvement of style transfer results. Targeting at style resemblance and content preservation problems, we propose a style transfer system composed of collection representation space and semantic-guided reconstruction. We train an encoder–decoder network with art collections to construct a representation space that can reflect the style of the artist. Then, we use semantic information as guidance to reconstruct the target representation of the input image for better content preservation. We conduct both quantitative analysis and qualitative evaluation to assess the proposed method. Experiment results demonstrate that our approach well balanced the trade-off between capturing artistic characteristics and preserving content information in style transfer tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301982",
    "keywords": [
      "Archaeology",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Encoder",
      "History",
      "Image (mathematics)",
      "Information retrieval",
      "Law",
      "Operating system",
      "Political science",
      "Politics",
      "Programming language",
      "Representation (politics)",
      "Scope (computer science)",
      "Space (punctuation)",
      "Style (visual arts)"
    ],
    "authors": [
      {
        "surname": "Ma",
        "given_name": "Zhuoqi"
      },
      {
        "surname": "Li",
        "given_name": "Jie"
      },
      {
        "surname": "Wang",
        "given_name": "Nannan"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Group visualization of class-discriminative features",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.026",
    "abstract": "Research explaining the behavior of convolutional neural networks (CNNs) has gained a lot of attention over the past few years. Although many visualization methods have been proposed to explain network predictions, most fail to provide clear correlations between the target output and the features extracted by convolutional layers. In this work, we define a concept, i.e., class-discriminative feature groups, to specify features that are extracted by groups of convolutional kernels correlated with a particular image class. We propose a detection method to detect class-discriminative feature groups and a visualization method to highlight image regions correlated with particular output and to interpret class-discriminative feature groups intuitively. The experiments showed that the proposed method can disentangle features based on image classes and shed light on what feature groups are extracted from which regions of the image. We also applied this method to visualize “lost” features in adversarial samples and features in an image containing a non-class object to demonstrate its ability to debug why the network failed or succeeded.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301969",
    "keywords": [
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Contextual image classification",
      "Convolutional neural network",
      "Discriminative model",
      "Feature (linguistics)",
      "Feature extraction",
      "Image (mathematics)",
      "Linguistics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Shi",
        "given_name": "Rui"
      },
      {
        "surname": "Li",
        "given_name": "Tianxing"
      },
      {
        "surname": "Yamaguchi",
        "given_name": "Yasushi"
      }
    ]
  },
  {
    "title": "Noise can speed backpropagation learning and deep bidirectional pretraining",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.004",
    "abstract": "We show that the backpropagation algorithm is a special case of the generalized Expectation–Maximization (EM) algorithm for iterative maximum likelihood estimation. We then apply the recent result that carefully chosen noise can speed the average convergence of the EM algorithm as it climbs a hill of probability or log-likelihood. Then injecting such noise can speed the average convergence of the backpropagation algorithm for both the training and pretraining of multilayer neural networks. The beneficial noise adds to the hidden and visible neurons and related parameters. The noise also applies to regularized regression networks. This beneficial noise is just that noise that makes the current signal more probable. We show that such noise also tends to improve classification accuracy. The geometry of the noise-benefit region depends on the probability structure of the neurons in a given layer. The noise-benefit region in noise space lies above the noisy-EM (NEM) hyperplane for classification and involves a hypersphere for regression. Simulations demonstrate these noise benefits using MNIST digit classification. The NEM noise benefits substantially exceed those of simply adding blind noise to the neural network. We further prove that the noise speed-up applies to the deep bidirectional pretraining of neural-network bidirectional associative memories (BAMs) or their functionally equivalent restricted Boltzmann machines. We then show that learning with basic contrastive divergence also reduces to generalized EM for an energy-based network probability. The optimal noise adds to the input visible neurons of a BAM in stacked layers of trained BAMs. Global stability of generalized BAMs guarantees rapid convergence in pretraining where neural signals feed back between contiguous layers. Bipolar coding of inputs further improves pretraining performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301246",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Computer science",
      "Gaussian noise",
      "Gradient noise",
      "Image (mathematics)",
      "Mathematics",
      "Noise (video)",
      "Noise floor",
      "Noise measurement",
      "Noise reduction",
      "Pattern recognition (psychology)",
      "Restricted Boltzmann machine"
    ],
    "authors": [
      {
        "surname": "Kosko",
        "given_name": "Bart"
      },
      {
        "surname": "Audhkhasi",
        "given_name": "Kartik"
      },
      {
        "surname": "Osoba",
        "given_name": "Osonde"
      }
    ]
  },
  {
    "title": "Multi-view clustering on data with partial instances and clusters",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.021",
    "abstract": "Most multi-view clustering algorithms apply to data with complete instances and clusters in the views. Recently, multi-view clustering on data with partial instances has been studied. In this paper, we study the more general version of the problem, i.e., multi-view clustering on data with partial instances and clusters in the views. We propose a non-negative matrix factorization (NMF) based algorithm. For the special case with partial instances, it introduces an instance-view-indicator matrix to indicate whether an instance exists in a view. Then, it maps the instances representing the same object to the same vector, and maps the instances representing different objects to different vectors. For the general case with partial instances and clusters, it further introduces a cluster-view-indicator matrix to indicate whether a cluster exists in a view. In each view, it also maps the instances representing the same object to the same vector, but it further makes the elements of the vector 0 if the elements correspond to missing clusters. Then it minimizes the disagreements between the approximated indicator vectors of instances representing the same object. Experimental results show that the proposed algorithm performs well on data with partial instances and clusters, and outperforms existing algorithms on data with partial instances.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030191X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cluster (spacecraft)",
      "Cluster analysis",
      "Clustering high-dimensional data",
      "Computer science",
      "Data mining",
      "Eigenvalues and eigenvectors",
      "Mathematics",
      "Matrix decomposition",
      "Non-negative matrix factorization",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Physics",
      "Programming language",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Zong",
        "given_name": "Linlin"
      },
      {
        "surname": "Zhang",
        "given_name": "Xianchao"
      },
      {
        "surname": "Liu",
        "given_name": "Xinyue"
      },
      {
        "surname": "Yu",
        "given_name": "Hong"
      }
    ]
  },
  {
    "title": "Partial transfer learning in machinery cross-domain fault diagnostics using class-weighted adversarial networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.014",
    "abstract": "Recently, transfer learning has been receiving growing interests in machinery fault diagnosis due to its strong generalization across different industrial scenarios. The existing methods generally assume identical label spaces, and propose minimizing marginal distribution discrepancy between source and target domains. However, this assumption usually does not hold in real industries, where testing data mostly contain a subspace of the source label space. Therefore, transferring diagnosis knowledge from a comprehensive source domain to a target domain with limited machine conditions is motivated. This challenging partial transfer learning problem is addressed in this study using deep learning-based domain adaptation method. A class weighted adversarial neural network is proposed to encourage positive transfer of the shared classes and ignore the source outliers. Experimental results on two rotating machinery datasets suggest the proposed method is promising for partial transfer learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030229X",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Domain (mathematical analysis)",
      "Fault (geology)",
      "Generalization",
      "Geology",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Outlier",
      "Pattern recognition (psychology)",
      "Seismology",
      "Subspace topology",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xiang"
      },
      {
        "surname": "Zhang",
        "given_name": "Wei"
      },
      {
        "surname": "Ma",
        "given_name": "Hui"
      },
      {
        "surname": "Luo",
        "given_name": "Zhong"
      },
      {
        "surname": "Li",
        "given_name": "Xu"
      }
    ]
  },
  {
    "title": "A new Lyapunov functional for stability analysis of neutral-type Hopfield neural networks with multiple delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.013",
    "abstract": "This research paper conducts an investigation into the stability issue for a more general class of neutral-type Hopfield neural networks that involves multiple time delays in the states of neurons and multiple neutral delays in the time derivatives of the states of neurons. By constructing a new proper Lyapunov functional, an alternative easily verifiable algebraic criterion for global asymptotic stability of this type of Hopfield neural systems is derived. This new stability condition is entirely independent of time and neutral delays. Two instructive examples are employed to indicate that the result obtained in this paper reveals a new set of sufficient stability criteria when it is compared with the previously reported stability results. Therefore, the proposed stability result enlarges the application domain of Hopfield neural systems of neutral types.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302288",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Ecology",
      "Exponential stability",
      "Hopfield network",
      "Lyapunov function",
      "Machine learning",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Set (abstract data type)",
      "Stability (learning theory)",
      "Type (biology)",
      "Verifiable secret sharing"
    ],
    "authors": [
      {
        "surname": "Faydasicok",
        "given_name": "Ozlem"
      }
    ]
  },
  {
    "title": "A gentle introduction to deep learning for graphs",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.006",
    "abstract": "The adaptive processing of graph data is a long-standing research topic that has been lately consolidated as a theme of major interest in the deep learning community. The snap increase in the amount and breadth of related research has come at the price of little systematization of knowledge and attention to earlier literature. This work is a tutorial introduction to the field of deep learning for graphs. It favors a consistent and progressive presentation of the main concepts and architectural aspects over an exposition of the most recent literature, for which the reader is referred to available surveys. The paper takes a top-down view of the problem, introducing a generalized formulation of graph representation learning based on a local and iterative approach to structured information processing. Moreover, it introduces the basic building blocks that can be combined to design novel and effective neural models for graphs. We complement the methodological exposition with a discussion of interesting research challenges and applications in the field.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302197",
    "keywords": [
      "Art",
      "Artificial intelligence",
      "Computer science",
      "Data science",
      "Deep learning",
      "Deep neural networks",
      "Exposition (narrative)",
      "Field (mathematics)",
      "Graph",
      "Law",
      "Literature",
      "Machine learning",
      "Mathematics",
      "Political science",
      "Politics",
      "Pure mathematics",
      "Representation (politics)",
      "Theme (computing)",
      "Theoretical computer science",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Bacciu",
        "given_name": "Davide"
      },
      {
        "surname": "Errica",
        "given_name": "Federico"
      },
      {
        "surname": "Micheli",
        "given_name": "Alessio"
      },
      {
        "surname": "Podda",
        "given_name": "Marco"
      }
    ]
  },
  {
    "title": "Pinning bipartite synchronization for inertial coupled delayed neural networks with signed digraph via non-reduced order method",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.017",
    "abstract": "The study investigates bipartite synchronization of inertial coupled delayed neural networks (ICDNNs) with signed digraph by non-reduced order method and pinning control. The second-order CDNNs will not be converted into a first-order differential system by introducing variable substitution. Instead, a novel Lyapunov–Krasovskii functional is proposed which depends on the topology of the ICDNNs. Some sufficient conditions for linear matrix inequalities (LMI) are derived to realize bipartite synchronization, which is based on matrix decomposition theory and Barbalat Lemma in strongly connected signed networks. And then, M-matrix theory is utilized to generalize the results to networks containing directed spanning trees. Finally, two examples are used to verify the validity of the derived theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030232X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bipartite graph",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Digraph",
      "Discrete mathematics",
      "Ecology",
      "Economics",
      "Finance",
      "Graph",
      "Inertial frame of reference",
      "Lemma (botany)",
      "Materials science",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Order (exchange)",
      "Physics",
      "Poaceae",
      "Quantum mechanics",
      "Strongly connected component",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Shanshan"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      },
      {
        "surname": "Lu",
        "given_name": "Binglong"
      },
      {
        "surname": "Yu",
        "given_name": "Zhiyong"
      },
      {
        "surname": "Li",
        "given_name": "Liang"
      }
    ]
  },
  {
    "title": "Self-organization of action hierarchy and compositionality by reinforcement learning with recurrent neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.002",
    "abstract": "Recurrent neural networks (RNNs) for reinforcement learning (RL) have shown distinct advantages, e.g., solving memory-dependent tasks and meta-learning. However, little effort has been spent on improving RNN architectures and on understanding the underlying neural mechanisms for performance gain. In this paper, we propose a novel, multiple-timescale, stochastic RNN for RL. Empirical results show that the network can autonomously learn to abstract sub-goals and can self-develop an action hierarchy using internal dynamics in a challenging continuous control task. Furthermore, we show that the self-developed compositionality of the network enhances faster re-learning when adapting to a new task that is a re-composition of previously learned sub-goals, than when starting from scratch. We also found that improved performance can be achieved when neural activities are subject to stochastic rather than deterministic dynamics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302070",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Economics",
      "Hierarchy",
      "Machine learning",
      "Management",
      "Market economy",
      "Physics",
      "Principle of compositionality",
      "Quantum mechanics",
      "Recurrent neural network",
      "Reinforcement learning",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Han",
        "given_name": "Dongqi"
      },
      {
        "surname": "Doya",
        "given_name": "Kenji"
      },
      {
        "surname": "Tani",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "DLPNet: A deep manifold network for feature extraction of hyperspectral imagery",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.022",
    "abstract": "Deep learning has received increasing attention in recent years and it has been successfully applied for feature extraction (FE) of hyperspectral images. However, most deep learning methods fail to explore the manifold structure in hyperspectral image (HSI). To tackle this issue, a novel graph-based deep learning model, termed deep locality preserving neural network (DLPNet), was proposed in this paper. Traditional deep learning methods use random initialization to initialize network parameters. Different from that, DLPNet initializes each layer of the network by exploring the manifold structure in hyperspectral data. In the stage of network optimization, it designed a deep-manifold learning joint loss function to exploit graph embedding process while measuring the difference between the predictive value and the actual value, then the proposed model can take into account the extraction of deep features and explore the manifold structure of data simultaneously. Experimental results on real-world HSI datasets indicate that the proposed DLPNet performs significantly better than some state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301921",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Dimensionality reduction",
      "Embedding",
      "Engineering",
      "Feature extraction",
      "Feature learning",
      "Graph",
      "Hyperspectral imaging",
      "Initialization",
      "Linguistics",
      "Locality",
      "Manifold (fluid mechanics)",
      "Manifold alignment",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Zhengying"
      },
      {
        "surname": "Huang",
        "given_name": "Hong"
      },
      {
        "surname": "Duan",
        "given_name": "Yule"
      },
      {
        "surname": "Shi",
        "given_name": "Guangyao"
      }
    ]
  },
  {
    "title": "Energy-efficient and damage-recovery slithering gait design for a snake-like robot based on reinforcement learning and inverse reinforcement learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.029",
    "abstract": "Similar to real snakes in nature, the flexible trunks of snake-like robots enhance their movement capabilities and adaptabilities in diverse environments. However, this flexibility corresponds to a complex control task involving highly redundant degrees of freedom, where traditional model-based methods usually fail to propel the robots energy-efficiently and adaptively to unforeseeable joint damage. In this work, we present an approach for designing an energy-efficient and damage-recovery slithering gait for a snake-like robot using the reinforcement learning (RL) algorithm and the inverse reinforcement learning (IRL) algorithm. Specifically, we first present an RL-based controller for generating locomotion gaits at a wide range of velocities, which is trained using the proximal policy optimization (PPO) algorithm. Then, by taking the RL-based controller as an expert and collecting trajectories from it, we train an IRL-based controller using the adversarial inverse reinforcement learning (AIRL) algorithm. For the purpose of comparison, a traditional parameterized gait controller is presented as the baseline and the parameter sets are optimized using the grid search and Bayesian optimization algorithm. Based on the analysis of the simulation results, we first demonstrate that this RL-based controller exhibits very natural and adaptive movements, which are also substantially more energy-efficient than the gaits generated by the parameterized controller. We then demonstrate that the IRL-based controller cannot only exhibit similar performances as the RL-based controller, but can also recover from the unpredictable damage body joints and still outperform the model-based controller, which has an undamaged body, in terms of energy efficiency. Videos can be viewed at https://videoviewsite.wixsite.com/rlsnake.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301994",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Energy (signal processing)",
      "Flexibility (engineering)",
      "Gait",
      "Mathematics",
      "Parameterized complexity",
      "Physiology",
      "Reinforcement learning",
      "Robot",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Bing",
        "given_name": "Zhenshan"
      },
      {
        "surname": "Lemke",
        "given_name": "Christian"
      },
      {
        "surname": "Cheng",
        "given_name": "Long"
      },
      {
        "surname": "Huang",
        "given_name": "Kai"
      },
      {
        "surname": "Knoll",
        "given_name": "Alois"
      }
    ]
  },
  {
    "title": "Contextual encoder–decoder network for visual saliency prediction",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.004",
    "abstract": "Predicting salient regions in natural images requires the detection of objects that are present in a scene. To develop robust representations for this challenging task, high-level visual features at multiple spatial scales must be extracted and augmented with contextual information. However, existing models aimed at explaining human fixation maps do not incorporate such a mechanism explicitly. Here we propose an approach based on a convolutional neural network pre-trained on a large-scale image classification task. The architecture forms an encoder–decoder structure and includes a module with multiple convolutional layers at different dilation rates to capture multi-scale features in parallel. Moreover, we combine the resulting representations with global scene information for accurately predicting visual saliency. Our model achieves competitive and consistent results across multiple evaluation metrics on two public saliency benchmarks and we demonstrate the effectiveness of the suggested approach on five datasets and selected examples. Compared to state of the art approaches, the network is based on a lightweight image classification backbone and hence presents a suitable choice for applications with limited computational resources, such as (virtual) robotic systems, to estimate human fixations across complex natural scenes. Our TensorFlow implementation is openly available at https://github.com/alexanderkroner/saliency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301660",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Economics",
      "Encoder",
      "Machine learning",
      "Management",
      "Operating system",
      "Pattern recognition (psychology)",
      "Salient",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Kroner",
        "given_name": "Alexander"
      },
      {
        "surname": "Senden",
        "given_name": "Mario"
      },
      {
        "surname": "Driessens",
        "given_name": "Kurt"
      },
      {
        "surname": "Goebel",
        "given_name": "Rainer"
      }
    ]
  },
  {
    "title": "Fast generalization error bound of deep learning without scale invariance of activation functions",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.033",
    "abstract": "In the theoretical analysis of deep learning, discovering which features of deep learning lead to good performance is an important task. Using the framework for analyzing the generalization error developed by Suzuki (2018), we derive a fast learning rate for deep neural networks with general activation functions. According to Suzuki (2018), scale invariance of the activation functions is essential to derive tight error bounds. While the rectified linear unit (ReLU; Nair and Hinton, 2010) satisfies scale invariance, the other famous activation functions, such as the sigmoid, the hyperbolic tangent functions, and the exponential linear unit (ELU; Clevert et al., 2016), do not satisfy this condition. The existing analysis indicates the possibility that deep learning with non scale invariant activations may have a slower convergence rate of O ( 1 ∕ n ) whereas with scale invariant activation functions it can reach a faster rate. In this paper, without scale invariance of activation functions, we derive the tight generalization error bound which is essentially the same as that of Suzuki (2018). From this result, at least in the framework of Suzuki (2018), we show that scale invariance of the activation functions is not essential to obtain a fast rate of convergence. We also conclude that the theoretical framework proposed by Suzuki (2018) can be widely applied to the analysis of deep learning with general activation functions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302033",
    "keywords": [
      "Activation function",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Exponential function",
      "Generalization",
      "Generalization error",
      "Hyperbolic function",
      "Invariant (physics)",
      "Key (lock)",
      "Mathematical analysis",
      "Mathematical physics",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Rate of convergence",
      "Scale (ratio)",
      "Scale invariance",
      "Sigmoid function",
      "Statistics",
      "Word error rate"
    ],
    "authors": [
      {
        "surname": "Terada",
        "given_name": "Yoshikazu"
      },
      {
        "surname": "Hirose",
        "given_name": "Ryoma"
      }
    ]
  },
  {
    "title": "Batch process fault detection for multi-stage broad learning system",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.031",
    "abstract": "In the real industrial production process, some minor faults are difficult to be detected by multivariate statistical analysis methods with mean and variance as detection indicators due to the aging equipment and catalyst deactivation. With structural characteristics, deep neural networks can better extract data features to detect such faults. However, most deep learning models contain a large number of connection parameters between layers, which causes the training time-consuming and thus makes it difficult to achieve a fast-online response. The Broad Learning System (BLS) network structure is expanded without a retraining process and thus saves a lot of training time. Considering that different stages of the batch production process have different production characteristics, we use the Affinity Propagation (AP) algorithm to separate the different stages of the production process. This paper conducts research on a multi-stage process monitoring framework that integrates AP and the BLS. Compared with other monitoring models, the monitoring results in the penicillin fermentation process have verified the superiority of the AP-BLS model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030201X",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Artificial neural network",
      "Batch processing",
      "Business",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Economics",
      "Fault detection and isolation",
      "International trade",
      "Machine learning",
      "Macroeconomics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Production (economics)",
      "Programming language",
      "Retraining"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Chang"
      },
      {
        "surname": "Lu",
        "given_name": "RuiWei"
      },
      {
        "surname": "Kang",
        "given_name": "Olivia"
      },
      {
        "surname": "Kai",
        "given_name": "Wang"
      }
    ]
  },
  {
    "title": "Structure learning with similarity preserving",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.030",
    "abstract": "Leveraging on the underlying low-dimensional structure of data, low-rank and sparse modeling approaches have achieved great success in a wide range of applications. However, in many applications the data can display structures beyond simply being low-rank or sparse. Fully extracting and exploiting hidden structure information in the data is always desirable and favorable. To reveal more underlying effective manifold structure, in this paper, we explicitly model the data relation. Specifically, we propose a structure learning framework that retains the pairwise similarities between the data points. Rather than just trying to reconstruct the original data based on self-expression, we also manage to reconstruct the kernel matrix, which functions as similarity preserving. Consequently, this technique is particularly suitable for the class of learning problems that are sensitive to sample similarity, e.g., clustering and semisupervised classification. To take advantage of representation power of deep neural network, a deep auto-encoder architecture is further designed to implement our model. Extensive experiments on benchmark data sets demonstrate that our proposed framework can consistently and significantly improve performance on both evaluation tasks. We conclude that the quality of structure learning can be enhanced if similarity information is incorporated.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302008",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Benchmark (surveying)",
      "Cluster analysis",
      "Combinatorics",
      "Computer science",
      "Data mining",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Kernel (algebra)",
      "Law",
      "Machine learning",
      "Mathematics",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Rank (graph theory)",
      "Representation (politics)",
      "Similarity (geometry)",
      "Similarity learning"
    ],
    "authors": [
      {
        "surname": "Kang",
        "given_name": "Zhao"
      },
      {
        "surname": "Lu",
        "given_name": "Xiao"
      },
      {
        "surname": "Lu",
        "given_name": "Yiwei"
      },
      {
        "surname": "Peng",
        "given_name": "Chong"
      },
      {
        "surname": "Chen",
        "given_name": "Wenyu"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      }
    ]
  },
  {
    "title": "An end-to-end exemplar association for unsupervised person Re-identification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.015",
    "abstract": "Tracklet association methods learn the cross camera retrieval ability though associating underlying cross camera positive samples, which have proven to be successful in unsupervised person re-identification task. However, most of them use poor-efficiency association strategies which costs long training hours but gains the low performance. To solve this, we propose an effective end-to-end exemplar associations (EEA) framework in this work. EEA mainly adapts three strategies to improve efficiency: (1) end-to-end exemplar-based training, (2) exemplar association and (3) dynamic selection threshold. The first one is to accelerate the training process, while the others aim to improve the tracklet association precision. Compared with existing tracklet associating methods, EEA obviously reduces the training cost and achieves the higher performance. Extensive experiments and ablation studies on seven RE-ID datasets demonstrate the superiority of the proposed EEA over most state-of-the-art unsupervised and domain adaptation RE-ID methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301854",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Association (psychology)",
      "Biology",
      "Botany",
      "Computer science",
      "Domain (mathematical analysis)",
      "Economics",
      "End-to-end principle",
      "Epistemology",
      "Identification (biology)",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Process (computing)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Jinlin"
      },
      {
        "surname": "Yang",
        "given_name": "Yang"
      },
      {
        "surname": "Lei",
        "given_name": "Zhen"
      },
      {
        "surname": "Wang",
        "given_name": "Jinqiao"
      },
      {
        "surname": "Li",
        "given_name": "Stan Z."
      },
      {
        "surname": "Tiwari",
        "given_name": "Prayag"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      }
    ]
  },
  {
    "title": "A neurodynamic optimization approach for complex-variables programming problem",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.06.012",
    "abstract": "A neural network model upon differential inclusion is designed for solving the complex-variables convex programming, and the chain rule for real-valued function with the complex-variables is established in this paper. The model does not need to choose penalty parameters when applied to practical problems, which makes it easier to design. The result is obtained that its state reaches the feasible region in finite time. Furthermore, the convergence for its state to an optimal solution is proved. Some typical examples are shown for the effectiveness of the designed model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020302276",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bayesian probability",
      "Biology",
      "Chain rule (probability)",
      "Computer science",
      "Convergence (economics)",
      "Convex optimization",
      "Differential inclusion",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Geometry",
      "Law of total probability",
      "Mathematical optimization",
      "Mathematics",
      "Penalty method",
      "Physics",
      "Posterior probability",
      "Regular polygon",
      "State (computer science)",
      "State variable",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Shuxin"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      },
      {
        "surname": "Zhang",
        "given_name": "Liwei"
      },
      {
        "surname": "Mei",
        "given_name": "Xuehui"
      }
    ]
  },
  {
    "title": "Deep Multi-Critic Network for accelerating Policy Learning in multi-agent environments",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.023",
    "abstract": "Humans live among other humans, not in isolation. Therefore, the ability to learn and behave in multi-agent environments is essential for any autonomous system that intends to interact with people. Due to the presence of multiple simultaneous learners in a multi-agent learning environment, the Markov assumption used for single-agent environments is not tenable, necessitating the development of new Policy Learning algorithms. Recent Actor–Critic algorithms proposed for multi-agent environments, such as Multi-Agent Deep Deterministic Policy Gradients and Counterfactual Multi-Agent Policy Gradients, find a way to use the same mathematical framework as single agent environments by augmenting the Critic with extra information. However, this extra information can slow down the learning process and afflict the Critic with Curse of Dimensionality. To combat this, we propose a novel Deep Neural Network configuration called Deep Multi-Critic Network. This architecture works by taking a weighted sum over the outputs of multiple critic networks of varying complexity and size. The configuration was tested on data collected from a real-world multi-agent environment. The results illustrate that by using Deep Multi-Critic Network, less data is needed to reach the same level of performance as when not using the configuration. This suggests that as the configuration learns faster from less data, then the Critic may be able to learn Q-values faster, accelerating Actor training as well.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301519",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Counterfactual thinking",
      "Curse of dimensionality",
      "Deep learning",
      "Distributed computing",
      "Epistemology",
      "Machine learning",
      "Markov decision process",
      "Markov process",
      "Mathematics",
      "Network architecture",
      "Operating system",
      "Philosophy",
      "Process (computing)",
      "Reinforcement learning",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Hook",
        "given_name": "Joosep"
      },
      {
        "surname": "Silva",
        "given_name": "Varuna De"
      },
      {
        "surname": "Kondoz",
        "given_name": "Ahmet"
      }
    ]
  },
  {
    "title": "Synchronization criteria for quaternion-valued coupled neural networks with impulses",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.027",
    "abstract": "We consider the global exponential synchronization of a category of quaternion-valued coupled neural networks (QVCNNs) with impulses in this article. It makes up for the gap of coupled neural networks with impulses in quaternion. On account of the product of two quaternions cannot be exchanged under normal circumstances, for convenience, we isolate the QVCNN into four real-valued coupled neural networks (RVCNNs) which are converted into an augmented system by defining a new augmented vector. By leveraging a distinctive Lyapunov–Krasovskii function and some matrix inequalities, several sufficient conditions for the global exponential synchronization of the system are attained. Ultimately, two examples are used to prove the validity of the theories in this paper.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301556",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Evolutionary biology",
      "Exponential function",
      "Function (biology)",
      "Geometry",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Product (mathematics)",
      "Quantum mechanics",
      "Quaternion",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Qi",
        "given_name": "Xingnan"
      },
      {
        "surname": "Bao",
        "given_name": "Haibo"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Performance metrics for online seizure prediction",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.022",
    "abstract": "Many recent studies on online seizure prediction from iEEG signal describe various prediction algorithms and their prediction performance. In contrast, this paper focuses on proper specification of system parameters, such as prediction period, prediction horizon and data-driven characterization of lead seizures. Whereas prediction performance clearly depends on these system parameters many researchers simply set the values of these parameters in an ad hoc manner. Our paper investigates the effect of these system parameters on online prediction performance, using both synthetic and real-life data sets. Therefore, meaningful comparison of methods/algorithms (for online seizure prediction) should consider proper specification of system parameters.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301428",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Contrast (vision)",
      "Data mining",
      "Data set",
      "Machine learning",
      "Performance prediction",
      "Predictive modelling",
      "Programming language",
      "Set (abstract data type)",
      "Simulation"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Hsiang-Han"
      },
      {
        "surname": "Cherkassky",
        "given_name": "Vladimir"
      }
    ]
  },
  {
    "title": "Generalized norm for existence, uniqueness and stability of Hopfield neural networks with discrete and distributed delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.014",
    "abstract": "In this paper, the existence, uniqueness and stability criteria of solutions for Hopfield neural networks with discrete and distributed delays (DDD HNNs) are investigated by the definitions of three kinds of generalized norm ( ξ -norm). A general DDD HNN model is firstly introduced, where the discrete delays τ p q ( t ) are asynchronous time-varying delays. Then, { ξ , 1 } -norm, { ξ , 2 } -norm and { ξ , ∞ } -norm are successively used to derive the existence, uniqueness and stability criteria of solutions for the DDD HNNs. In the proof of theorems, special functions and assumptions are given to deal with discrete and distributed delays. Furthermore, a corollary is concluded for the existence and stability criteria of solutions. The methods given in this paper can also be used to study the synchronization and μ -stability of different DDD NNs. Finally, two numerical examples and their simulation figures are given to illustrate the effectiveness of these results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301842",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Asynchronous communication",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Corollary",
      "Discrete mathematics",
      "Exponential stability",
      "Hopfield network",
      "Law",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Norm (philosophy)",
      "Physics",
      "Political science",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Uniqueness"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Huamin"
      },
      {
        "surname": "Wei",
        "given_name": "Guoliang"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Approximation rates for neural networks with general activation functions",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.019",
    "abstract": "We prove some new results concerning the approximation rate of neural networks with general activation functions. Our first result concerns the rate of approximation of a two layer neural network with a polynomially-decaying non-sigmoidal activation function. We extend the dimension independent approximation rates previously obtained to this new class of activation functions. Our second result gives a weaker, but still dimension independent, approximation rate for a larger class of activation functions, removing the polynomial decay assumption. This result applies to any bounded, integrable activation function. Finally, we show that a stratified sampling approach can be used to improve the approximation rate for polynomially decaying activation functions under mild additional assumptions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301891",
    "keywords": [
      "Activation function",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Class (philosophy)",
      "Computer science",
      "Dimension (graph theory)",
      "Evolutionary biology",
      "Function (biology)",
      "Integrable system",
      "Mathematical analysis",
      "Mathematics",
      "Polynomial",
      "Pure mathematics",
      "Sigmoid function"
    ],
    "authors": [
      {
        "surname": "Siegel",
        "given_name": "Jonathan W."
      },
      {
        "surname": "Xu",
        "given_name": "Jinchao"
      }
    ]
  },
  {
    "title": "Progressive learning: A deep learning framework for continual learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.011",
    "abstract": "Continual learning is the ability of a learning system to solve new tasks by utilizing previously acquired knowledge from learning and performing prior tasks without having significant adverse effects on the acquired prior knowledge. Continual learning is key to advancing machine learning and artificial intelligence. Progressive learning is a deep learning framework for continual learning that comprises three procedures: curriculum, progression, and pruning. The curriculum procedure is used to actively select a task to learn from a set of candidate tasks. The progression procedure is used to grow the capacity of the model by adding new parameters that leverage parameters learned in prior tasks, while learning from data available for the new task at hand, without being susceptible to catastrophic forgetting. The pruning procedure is used to counteract the growth in the number of parameters as further tasks are learned, as well as to mitigate negative forward transfer, in which prior knowledge unrelated to the task at hand may interfere and worsen performance. Progressive learning is evaluated on a number of supervised classification tasks in the image recognition and speech recognition domains to demonstrate its advantages compared with baseline methods. It is shown that, when tasks are related, progressive learning leads to faster learning that converges to better generalization performance using a smaller number of dedicated parameters.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301817",
    "keywords": [
      "Active learning (machine learning)",
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Deep learning",
      "Economics",
      "Feature learning",
      "Forgetting",
      "Instance-based learning",
      "Leverage (statistics)",
      "Linguistics",
      "Machine learning",
      "Management",
      "Mobile robot",
      "Multi-task learning",
      "Online machine learning",
      "Philosophy",
      "Pruning",
      "Robot",
      "Robot learning",
      "Semi-supervised learning",
      "Sequence learning",
      "Task (project management)",
      "Transfer of learning",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Fayek",
        "given_name": "Haytham M."
      },
      {
        "surname": "Cavedon",
        "given_name": "Lawrence"
      },
      {
        "surname": "Wu",
        "given_name": "Hong Ren"
      }
    ]
  },
  {
    "title": "Impulsive synchronization of coupled delayed neural networks with actuator saturation and its application to image encryption",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.016",
    "abstract": "The actuator of any physical control systems is constrained by amplitude and energy, which causes the control systems to be inevitably affected by actuator saturation. In this paper, impulsive synchronization of coupled delayed neural networks with actuator saturation is presented. A new controller is designed to introduce actuator saturation term into impulsive controller. Based on sector nonlinearity model approach, impulsive controls with actuator saturation and with partial actuator saturation are studied, respectively, and some effective sufficient conditions are obtained. Numerical simulation is presented to verify the validity of the theoretical analysis results. Finally, the impulsive synchronization is applied to image encryption. The experimental results show that the proposed image encryption system has high security properties.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301866",
    "keywords": [
      "Actuator",
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Encryption",
      "Engineering",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Quantum mechanics",
      "Saturation (graph theory)",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Ouyang",
        "given_name": "Deqiang"
      },
      {
        "surname": "Shao",
        "given_name": "Jie"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      },
      {
        "surname": "Nguang",
        "given_name": "Sing Kiong"
      },
      {
        "surname": "Shen",
        "given_name": "Heng Tao"
      }
    ]
  },
  {
    "title": "Sparsity through evolutionary pruning prevents neuronal networks from overfitting",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.007",
    "abstract": "Modern Machine learning techniques take advantage of the exponentially rising calculation power in new generation processor units. Thus, the number of parameters which are trained to solve complex tasks was highly increased over the last decades. However, still the networks fail – in contrast to our brain – to develop general intelligence in the sense of being able to solve several complex tasks with only one network architecture. This could be the case because the brain is not a randomly initialized neural network, which has to be trained from scratch by simply investing a lot of calculation power, but has from birth some fixed hierarchical structure. To make progress in decoding the structural basis of biological neural networks we here chose a bottom-up approach, where we evolutionarily trained small neural networks in performing a maze task. This simple maze task requires dynamic decision making with delayed rewards. We were able to show that during the evolutionary optimization random severance of connections leads to better generalization performance of the networks compared to fully connected networks. We conclude that sparsity is a central property of neural networks and should be considered for modern Machine learning approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301696",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Economics",
      "Evolutionary algorithm",
      "Generalization",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Overfitting",
      "Pruning",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Gerum",
        "given_name": "Richard C."
      },
      {
        "surname": "Erpenbeck",
        "given_name": "André"
      },
      {
        "surname": "Krauss",
        "given_name": "Patrick"
      },
      {
        "surname": "Schilling",
        "given_name": "Achim"
      }
    ]
  },
  {
    "title": "Multi-projection of unequal dimension optimal transport theory for Generative Adversary Networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.029",
    "abstract": "As a major step forward in machine learning, generative adversarial networks (GANs) employ the Wasserstein distance as a metric between the generative distribution and target data distribution, and thus can be viewed as optimal transport (OT) problems to reflect the underlying geometry of the probability distribution. However, the unequal dimensions between the source random distribution and the target data, result in often instability in the training processes, and lack of diversity in the generative images. To resolve the challenges, we propose here a multiple-projection approach, to project the source and target probability measures into multiple different low-dimensional subspaces. Moreover, we show that the original problem can be transformed into a variant multi-marginal OT problem, and we provide the explicit properties of the solutions. In addition, we employ parameterized approximation for the objective, and study the corresponding differentiability and convergence properties, ensuring that the problem can indeed be computed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030157X",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Computer science",
      "Curse of dimensionality",
      "Differentiable function",
      "Dimension (graph theory)",
      "Economics",
      "Generative grammar",
      "Generative model",
      "Geometry",
      "Intrinsic dimension",
      "Linear subspace",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Metric (unit)",
      "Operations management",
      "Parameterized complexity",
      "Probability distribution",
      "Projection (relational algebra)",
      "Pure mathematics",
      "Statistics",
      "Wasserstein metric"
    ],
    "authors": [
      {
        "surname": "Lin",
        "given_name": "Judy Yangjun"
      },
      {
        "surname": "Guo",
        "given_name": "Shaoyan"
      },
      {
        "surname": "Xie",
        "given_name": "Longhan"
      },
      {
        "surname": "Xu",
        "given_name": "Gu"
      }
    ]
  },
  {
    "title": "Real-time multiple spatiotemporal action localization and prediction approach using deep learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.017",
    "abstract": "Detecting the locations of multiple actions in videos and classifying them in real-time are challenging problems termed ”action localization and prediction” problem. Convolutional neural networks (ConvNets) have achieved great success for action localization and prediction in still images. A major advance occurred when the AlexNet architecture was introduced in the ImageNet competition. ConvNets have since achieved state-of-the-art performances across a wide variety of machine vision tasks, including object detection, image segmentation, image classification, facial recognition, human pose estimation, and tracking. However, few works exist that address action localization and prediction in videos. The current action localization research primarily focuses on the classification of temporally trimmed videos in which only one action occurs per frame. Moreover, nearly all the current approaches work only offline and are too slow to be useful in real-world environments. In this work, we propose a fast and accurate deep-learning approach to perform real-time action localization and prediction. The proposed approach uses convolutional neural networks to localize multiple actions and predict their classes in real time. This approach starts by using appearance and motion detection networks (known as ”you only look once” (YOLO) networks) to localize and classify actions from RGB frames and optical flow frames using a two-stream model. We then propose a fusion step that increases the localization accuracy of the proposed approach. Moreover, we generate an action tube based on frame level detection. The frame by frame processing introduces an early action detection and prediction with top performance in terms of detection speed and precision. The experimental results demonstrate this superiority of our proposed approach in terms of both processing time and accuracy compared to recent offline and online action localization and prediction approaches on the challenging UCF-101-24 and J-HMDB-21 benchmarks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301878",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Frame (networking)",
      "Image (mathematics)",
      "Machine learning",
      "Object detection",
      "Optical flow",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "RGB color model",
      "Segmentation",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Hammam",
        "given_name": "Ahmed Ali"
      },
      {
        "surname": "Soliman",
        "given_name": "Mona M."
      },
      {
        "surname": "Hassanien",
        "given_name": "Aboul Ella"
      }
    ]
  },
  {
    "title": "Sequential vessel segmentation via deep channel attention network",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.005",
    "abstract": "Accurately segmenting contrast-filled vessels from X-ray coronary angiography (XCA) image sequence is an essential step for the diagnosis and therapy of coronary artery disease. However, developing automatic vessel segmentation is particularly challenging due to the overlapping structures, low contrast and the presence of complex and dynamic background artifacts in XCA images. This paper develops a novel encoder–decoder deep network architecture which exploits the several contextual frames of 2D+t sequential images in a sliding window centered at current frame to segment 2D vessel masks from the current frame. The architecture is equipped with temporal–spatial feature extraction in encoder stage, feature fusion in skip connection layers and channel attention mechanism in decoder stage. In the encoder stage, a series of 3D convolutional layers are employed to hierarchically extract temporal–spatial features. Skip connection layers subsequently fuse the temporal–spatial feature maps and deliver them to the corresponding decoder stages. To efficiently discriminate vessel features from the complex and noisy backgrounds in the XCA images, the decoder stage effectively utilizes channel attention blocks to refine the intermediate feature maps from skip connection layers for subsequently decoding the refined features in 2D ways to produce the segmented vessel masks. Furthermore, Dice loss function is implemented to train the proposed deep network in order to tackle the class imbalance problem in the XCA data due to the wide distribution of complex background artifacts. Extensive experiments by comparing our method with other state-of-the-art algorithms demonstrate the proposed method’s superior performance over other methods in terms of the quantitative metrics and visual validation. To facilitate the reproductive research in XCA community, we publicly release our dataset and source codes at https://github.com/Binjie-Qin/SVS-net.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301672",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Decoding methods",
      "Deep learning",
      "Encoder",
      "Feature (linguistics)",
      "Feature extraction",
      "Frame (networking)",
      "Linguistics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Segmentation",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Hao",
        "given_name": "Dongdong"
      },
      {
        "surname": "Ding",
        "given_name": "Song"
      },
      {
        "surname": "Qiu",
        "given_name": "Linwei"
      },
      {
        "surname": "Lv",
        "given_name": "Yisong"
      },
      {
        "surname": "Fei",
        "given_name": "Baowei"
      },
      {
        "surname": "Zhu",
        "given_name": "Yueqi"
      },
      {
        "surname": "Qin",
        "given_name": "Binjie"
      }
    ]
  },
  {
    "title": "Training memristor-based multilayer neuromorphic networks with SGD, momentum and adaptive learning rates",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.025",
    "abstract": "Neural networks implemented with traditional hardware face inherent limitation of memory latency. Specifically, the processing units like GPUs, FPGAs, and customized ASICs, must wait for inputs to read from memory and outputs to write back. This motivates memristor-based neuromorphic computing in which the memory units (i.e., memristors) have computing capabilities. However, training a memristor-based neural network is difficult since memristors work differently from CMOS hardware. This paper proposes a new training approach that enables prevailing neural network training techniques to be applied for memristor-based neuromorphic networks. Particularly, we introduce momentum and adaptive learning rate to the circuit training, both of which are proven methods that significantly accelerate the convergence of neural network parameters. Furthermore, we show that this circuit can be used for neural networks with arbitrary numbers of layers, neurons, and parameters. Simulation results on four classification tasks demonstrate that the proposed circuit achieves both high accuracy and fast speed. Compared with the SGD-based training circuit, on the WBC data set, the training speed of our circuit is increased by 37.2% while the accuracy is only reduced by 0.77%. On the MNIST data set, the new circuit even leads to improved accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301532",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "CMOS",
      "Computer architecture",
      "Computer engineering",
      "Computer science",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "MNIST database",
      "Memistor",
      "Memristor",
      "Neuromorphic engineering",
      "Resistive random-access memory",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Yan",
        "given_name": "Zheng"
      },
      {
        "surname": "Chen",
        "given_name": "Jiadong"
      },
      {
        "surname": "Hu",
        "given_name": "Rui"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      },
      {
        "surname": "Chen",
        "given_name": "Yiran"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Automated classification of cells into multiple classes in epithelial tissue of oral squamous cell carcinoma using transfer learning and convolutional neural network",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.003",
    "abstract": "The analysis of tissue of a tumor in the oral cavity is essential for the pathologist to ascertain its grading. Recent studies using biopsy images reveal computer-aided diagnosis for oral sub-mucous fibrosis (OSF) carried out using machine learning algorithms, but no research has yet been outlined for multi-class grading of oral squamous cell carcinoma (OSCC). Pertinently, with the advent of deep learning in digital imaging and computational aid in the diagnosis, multi-class classification of OSCC biopsy images can help in timely and effective prognosis and multi-modal treatment protocols for oral cancer patients, thus reducing the operational workload of pathologists while enhancing management of the disease. With this motivation, this study attempts to classify OSCC into its four classes as per the Broder’s system of histological grading. The study is conducted on oral biopsy images applying two methods: (i) through the application of transfer learning using pre-trained deep convolutional neural network (CNN) wherein four candidate pre-trained models, namely Alexnet, VGG-16, VGG-19 and Resnet-50, were chosen to find the most suitable model for our classification problem, and (ii) by a proposed CNN model. Although the highest classification accuracy of 92.15% is achieved by Resnet-50 model, the experimental findings highlight that the proposed CNN model outperformed the transfer learning approaches displaying accuracy of 97.5%. It can be concluded that the proposed CNN based multi-class grading method of OSCC could be used for diagnosis of patients with OSCC.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301659",
    "keywords": [
      "Artificial intelligence",
      "Basal cell",
      "Biopsy",
      "Civil engineering",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Engineering",
      "Grading (engineering)",
      "Machine learning",
      "Medicine",
      "Pathology",
      "Pattern recognition (psychology)",
      "Residual neural network",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Das",
        "given_name": "Navarun"
      },
      {
        "surname": "Hussain",
        "given_name": "Elima"
      },
      {
        "surname": "Mahanta",
        "given_name": "Lipi B."
      }
    ]
  },
  {
    "title": "Accurate and efficient sequential ensemble learning for highly imbalanced multi-class data",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.010",
    "abstract": "Multi-class classification for highly imbalanced data is a challenging task in which multiple issues must be resolved simultaneously, including (i) accuracy on classifying highly imbalanced multi-class data; (ii) training efficiency for large data; and (iii) sensitivity to high imbalance ratio (IR). In this paper, a novel sequential ensemble learning (SEL) framework is designed to simultaneously resolve these issues. SEL framework provides a significant property over traditional AdaBoost, in which the majority samples can be divided into multiple small and disjoint subsets for training multiple weak learners without compromising accuracy (while AdaBoost cannot). To ensure the class balance and majority-disjoint property of subsets, a learning strategy called balanced and majority-disjoint subsets division (BMSD) is developed. Unfortunately it is difficult to derive a general learner combination method (LCM) for any kind of weak learner. In this work, LCM is specifically designed for extreme learning machine, called LCM-ELM. The proposed SEL framework with BMSD and LCM-ELM has been compared with state-of-the-art methods over 16 benchmark datasets. In the experiments, under highly imbalanced multi-class data (IR up to 14K; data size up to 493K), (i) the proposed works improve the performance in different measures including G-mean, macro-F, micro-F, MAUC; (ii) training time is significantly reduced.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301805",
    "keywords": [
      "AdaBoost",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Boosting (machine learning)",
      "Class (philosophy)",
      "Combinatorics",
      "Computer science",
      "Disjoint sets",
      "Ensemble learning",
      "Epistemology",
      "Extreme learning machine",
      "Generalization",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Property (philosophy)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Vong",
        "given_name": "Chi-Man"
      },
      {
        "surname": "Du",
        "given_name": "Jie"
      }
    ]
  },
  {
    "title": "Uni-image: Universal image construction for robust neural model",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.018",
    "abstract": "Deep neural networks have shown high performance in prediction, but they are defenseless when they predict on adversarial examples which are generated by adversarial attack techniques. In image classification, those attack techniques usually perturb the pixel of an image to fool the deep neural networks. To improve the robustness of the neural networks, many researchers have introduced several defense techniques against those attack techniques. To the best of our knowledge, adversarial training is one of the most effective defense techniques against the adversarial examples. However, the defense technique could fail against a semantic adversarial image that performs arbitrary perturbation to fool the neural networks, where the modified image semantically represents the same object as the original image. Against this background, we propose a novel defense technique, Uni-Image Procedure (UIP) method. UIP generates a universal-image (uni-image) from a given image, which can be a clean image or a perturbed image by some attacks. The generated uni-image preserves its own characteristics (i.e. color) regardless of the transformations of the original image. Note that those transformations include inverting the pixel value of an image, modifying the saturation, hue, and value of an image, etc. Our experimental results using several benchmark datasets show that our method not only defends well known adversarial attacks and semantic adversarial attack but also boosts the robustness of the neural network.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030188X",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Deep neural networks",
      "Gene",
      "Image (mathematics)",
      "Pattern recognition (psychology)",
      "Pixel",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Ho",
        "given_name": "Jiacang"
      },
      {
        "surname": "Lee",
        "given_name": "Byung-Gook"
      },
      {
        "surname": "Kang",
        "given_name": "Dae-Ki"
      }
    ]
  },
  {
    "title": "Robust image classification against adversarial attacks using elastic similarity measures between edge count sequences",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.030",
    "abstract": "Due to their unprecedented capacity to learn patterns from raw data, deep neural networks have become the de facto modeling choice to address complex machine learning tasks. However, recent works have emphasized the vulnerability of deep neural networks when being fed with intelligently manipulated adversarial data instances tailored to confuse the model. In order to overcome this issue, a major effort has been made to find methods capable of making deep learning models robust against adversarial inputs. This work presents a new perspective for improving the robustness of deep neural networks in image classification. In computer vision scenarios, adversarial images are crafted by manipulating legitimate inputs so that the target classifier is eventually fooled, but the manipulation is not visually distinguishable by an external observer. The reason for the imperceptibility of the attack is that the human visual system fails to detect minor variations in color space, but excels at detecting anomalies in geometric shapes. We capitalize on this fact by extracting color gradient features from input images at multiple sensitivity levels to detect possible manipulations. We resort to a deep neural classifier to predict the category of unseen images, whereas a discrimination model analyzes the extracted color gradient features with time series techniques to determine the legitimacy of input images. The performance of our method is assessed over experiments comprising state-of-the-art techniques for crafting adversarial attacks. Results corroborate the increased robustness of the classifier when using our discrimination module, yielding drastically reduced success rates of adversarial attacks that operate on the whole image rather than on localized regions or around the existing shapes of the image. Future research is outlined towards improving the detection accuracy of the proposed method for more general attack strategies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301581",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Classifier (UML)",
      "Computer science",
      "Computer vision",
      "Contextual image classification",
      "Deep learning",
      "Deep neural networks",
      "Gene",
      "Image (mathematics)",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Oregi",
        "given_name": "Izaskun"
      },
      {
        "surname": "Del Ser",
        "given_name": "Javier"
      },
      {
        "surname": "Pérez",
        "given_name": "Aritz"
      },
      {
        "surname": "Lozano",
        "given_name": "José A."
      }
    ]
  },
  {
    "title": "T-Net: Nested encoder–decoder architecture for the main vessel segmentation in coronary angiography",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.002",
    "abstract": "In this paper, we proposed nested encoder–decoder architecture named T-Net. T-Net consists of several small encoder–decoders for each block constituting convolutional network. T-Net overcomes the limitation that U-Net can only have a single set of the concatenate layer between encoder and decoder block. To be more precise, the U-Net symmetrically forms the concatenate layers, so the low-level feature of the encoder is connected to the latter part of the decoder, and the high-level feature is connected to the beginning of the decoder. T-Net arranges the pooling and up-sampling appropriately during the encoding process, and likewise during the decoding process so that feature-maps of various sizes are obtained in a single block. As a result, all features from the low-level to the high-level extracted from the encoder are delivered from the beginning of the decoder to predict a more accurate mask. We evaluated T-Net for the problem of segmenting three main vessels in coronary angiography images. The experiment consisted of a comparison of U-Net and T-Nets under the same conditions, and an optimized T-Net for the main vessel segmentation. As a result, T-Net recorded a Dice Similarity Coefficient score (DSC) of 83.77%, 10.69% higher than that of U-Net, and the optimized T-Net recorded a DSC of 88.97% which was 15.89% higher than that of U-Net. In addition, we visualized the weight activation of the convolutional layer of T-Net and U-Net to show that T-Net actually predicts the mask from earlier decoders. Therefore, we expect that T-Net can be effectively applied to other similar medical image segmentation problems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301647",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Block (permutation group theory)",
      "Computer science",
      "Convolutional neural network",
      "Decoding methods",
      "Encoder",
      "Feature (linguistics)",
      "Geometry",
      "Linguistics",
      "Mathematics",
      "Net (polyhedron)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pooling",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Jun",
        "given_name": "Tae Joon"
      },
      {
        "surname": "Kweon",
        "given_name": "Jihoon"
      },
      {
        "surname": "Kim",
        "given_name": "Young-Hak"
      },
      {
        "surname": "Kim",
        "given_name": "Daeyoung"
      }
    ]
  },
  {
    "title": "Graph transform learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.020",
    "abstract": "Transform learning is a new representation learning framework where we learn an operator/transform that analyses the data to generate the coefficient/representation. We propose a variant of it called the graph transform learning; in this we explicitly account for the correlation in the dataset in terms of graph Laplacian. We will give two variants; in the first one the graph is computed from the data and fixed during the operation. In the second, the graph is learnt iteratively from the data during operation. The first technique will be applied for clustering, and the second one for solving inverse problems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301908",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Clustering coefficient",
      "Computer science",
      "External Data Representation",
      "Graph",
      "Laplace operator",
      "Laplacian matrix",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Majumdar",
        "given_name": "Angshul"
      }
    ]
  },
  {
    "title": "Common stochastic inputs induce neuronal transient synchronization with partial reset",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.019",
    "abstract": "Neuronal synchronization plays important roles in information encoding and transmission in the brain. Mathematical models of neurons have been widely used to simulate synchronization behavior and analyze its mechanisms. Common stochastic inputs are considered to be effective in facilitating synchronization. However, the mechanisms of how partial reset affects neuronal synchronization are still not well understood. In this paper, the synchronization of Stein’s model neurons with partial reset is studied. The differences in synchronization mechanisms between neurons with full reset and those with partial reset are analyzed, and the findings lead to the novel concept of transient synchronization. Furthermore, it is proven analytically that due to common stochastic inputs, Stein’s model neurons with different initial membrane potentials and partial reset achieve transient synchronization with probability 1. Additionally, a systematic numerical analysis is performed to explore the similarities and differences between full reset and partial reset regarding model parameters, synchronization time, and desynchronization behavior. Thus, partial reset is a powerful and flexible tool that facilitates neuronal synchronization while reserving the possibility of desynchronization. Our analysis also provides an alternative approach to analyze neurons of the integrate-and-fire family and a theoretical complement implying possible information encoding mechanisms in the brain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301398",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Economics",
      "Encoding (memory)",
      "Financial economics",
      "Operating system",
      "Reset (finance)",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Transient (computer programming)",
      "Transmission (telecommunications)"
    ],
    "authors": [
      {
        "surname": "Leng",
        "given_name": "Siyang"
      },
      {
        "surname": "Aihara",
        "given_name": "Kazuyuki"
      }
    ]
  },
  {
    "title": "Deep learning from label proportions with labeled samples",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.026",
    "abstract": "Learning from label proportions (LLP), where the training data is in form of bags, and only the proportions of classes in each bag are available, has attracted wide interest in machine learning community. In general, most LLP algorithms adopt random sampling to obtain the proportional information of different categories, which correspondingly obtains some labeled samples in each bag. However, LLP training process always fails to leverage these labeled samples, which may contain essential data distribution information. To address this issue, in this paper, we propose end-to-end LLP solver based on convolutional neural networks (ConvNets), called LLP with labeled samples (LLP-LS). First, we reshape the cross entropy loss in ConvNets, so that it can combine the proportional information and labeled samples in each bag. Second, in order to comply with the training data in a bag manner, ADAM based on batch is employed to train LLP-LS. Hence, the batch size in training process is in accordance with the bag size. Compared with up-to-date methods on multi-class problem, our algorithm can obtain the state-of-the-art on several image datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301544",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Entropy (arrow of time)",
      "Leverage (statistics)",
      "Machine learning",
      "Operating system",
      "Pattern recognition (psychology)",
      "Physics",
      "Process (computing)",
      "Quantum mechanics",
      "Random forest"
    ],
    "authors": [
      {
        "surname": "Shi",
        "given_name": "Yong"
      },
      {
        "surname": "Liu",
        "given_name": "Jiabin"
      },
      {
        "surname": "Wang",
        "given_name": "Bo"
      },
      {
        "surname": "Qi",
        "given_name": "Zhiquan"
      },
      {
        "surname": "Tian",
        "given_name": "YingJie"
      }
    ]
  },
  {
    "title": "Regularized least squares locality preserving projections with applications to image recognition",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.023",
    "abstract": "Locality preserving projection (LPP), as a well-known technique for dimensionality reduction, is designed to preserve the local structure of the original samples which usually lie on a low-dimensional manifold in the real world. However, it suffers from the undersampled or small-sample-size problem, when the dimension of the features is larger than the number of samples which causes the corresponding generalized eigenvalue problem to be ill-posed. To address this problem, we show that LPP is equivalent to a multivariate linear regression under a mild condition, and establish the connection between LPP and a least squares problem with multiple columns on the right-hand side. Based on the developed connection, we propose two regularized least squares methods for solving LPP. Experimental results on real-world databases illustrate the performance of our methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301933",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Connection (principal bundle)",
      "Curse of dimensionality",
      "Dimension (graph theory)",
      "Dimensionality reduction",
      "Eigenvalues and eigenvectors",
      "Engineering",
      "Estimator",
      "Geometry",
      "Intrinsic dimension",
      "Least-squares function approximation",
      "Linguistics",
      "Locality",
      "Manifold (fluid mechanics)",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Principal component analysis",
      "Projection (relational algebra)",
      "Quantum mechanics",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Wei"
      },
      {
        "surname": "Dai",
        "given_name": "Hua"
      },
      {
        "surname": "Liang",
        "given_name": "Weitai"
      }
    ]
  },
  {
    "title": "Accurate and efficient sequential ensemble learning for highly imbalanced multi-class data",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.010",
    "abstract": "Multi-class classification for highly imbalanced data is a challenging task in which multiple issues must be resolved simultaneously, including (i) accuracy on classifying highly imbalanced multi-class data; (ii) training efficiency for large data; and (iii) sensitivity to high imbalance ratio (IR). In this paper, a novel sequential ensemble learning (SEL) framework is designed to simultaneously resolve these issues. SEL framework provides a significant property over traditional AdaBoost, in which the majority samples can be divided into multiple small and disjoint subsets for training multiple weak learners without compromising accuracy (while AdaBoost cannot). To ensure the class balance and majority-disjoint property of subsets, a learning strategy called balanced and majority-disjoint subsets division (BMSD) is developed. Unfortunately it is difficult to derive a general learner combination method (LCM) for any kind of weak learner. In this work, LCM is specifically designed for extreme learning machine, called LCM-ELM. The proposed SEL framework with BMSD and LCM-ELM has been compared with state-of-the-art methods over 16 benchmark datasets. In the experiments, under highly imbalanced multi-class data (IR up to 14K; data size up to 493K), (i) the proposed works improve the performance in different measures including G-mean, macro-F, micro-F, MAUC; (ii) training time is significantly reduced.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301805",
    "keywords": [
      "AdaBoost",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Boosting (machine learning)",
      "Class (philosophy)",
      "Combinatorics",
      "Computer science",
      "Disjoint sets",
      "Ensemble learning",
      "Epistemology",
      "Extreme learning machine",
      "Generalization",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Property (philosophy)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Vong",
        "given_name": "Chi-Man"
      },
      {
        "surname": "Du",
        "given_name": "Jie"
      }
    ]
  },
  {
    "title": "Theory of adaptive SVD regularization for deep neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.021",
    "abstract": "Deep networks can learn complex problems, however, they suffer from overfitting. To solve this problem, regularization methods have been proposed that are not adaptable to the dynamic changes in the training process. With a different approach, this paper presents a regularization method based on the Singular Value Decomposition (SVD) that adjusts the learning model adaptively. To this end, the overfitting can be evaluated by condition numbers of the synaptic matrices. When the overfitting is high, the matrices are substituted with their SVD approximations. Some theoretical results are derived to show the performance of this regularization method. It is proved that SVD approximation cannot solve overfitting after several iterations. Thus, a new Tikhonov term is added to the loss function to converge the synaptic weights to the SVD approximation of the best-found results. Following this approach, an Adaptive SVD Regularization (ASR) is proposed to adjust the learning model with respect to the dynamic training characteristics. ASR results are visualized to show how ASR overcomes overfitting. The different configurations of Convolutional Neural Networks (CNN) are implemented with different augmentation schemes to compare ASR with state-of-the-art regularization methods. The results show that on MNIST, F-MNIST, SVHN, CIFAR-10 and CIFAR-100, the accuracies of ASR are 99.4%, 95.7%, 97.1%, 93.2% and 55.6%, respectively. Although ASR improves the overfitting and validation loss, its elapsed time is not significantly greater than the learning without regularization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301416",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Inverse problem",
      "MNIST database",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Singular value decomposition",
      "Tikhonov regularization"
    ],
    "authors": [
      {
        "surname": "Bejani",
        "given_name": "Mohammad Mahdi"
      },
      {
        "surname": "Ghatee",
        "given_name": "Mehdi"
      }
    ]
  },
  {
    "title": "A unified robust framework for multi-view feature extraction with L2,1-norm constraint",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.024",
    "abstract": "Multi-view feature extraction methods mainly focus on exploiting the consistency and complementary information between multi-view samples, and most of the current methods apply the F-norm or L2-norm as the metric, which are sensitive to the outliers or noises. In this paper, based on L2,1-norm, we propose a unified robust feature extraction framework, which includes four special multi-view feature extraction methods, and extends the state-of-art methods to a more generalized form. The proposed methods are less sensitive to outliers or noises. An efficient iterative algorithm is designed to solve L2,1-norm based methods. Comprehensive analyses, such as convergence analysis, rotational invariance analysis and relationship between our methods and previous F-norm based methods illustrate the effectiveness of our proposed methods. Experiments on two artificial datasets and six real datasets demonstrate that the proposed L2,1-norm based methods have better performance than the related methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301520",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Constraint (computer-aided design)",
      "Feature extraction",
      "Gene",
      "Geometry",
      "Law",
      "Mathematics",
      "Norm (philosophy)",
      "Outlier",
      "Pattern recognition (psychology)",
      "Political science",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Jinxin"
      },
      {
        "surname": "Liu",
        "given_name": "Liming"
      },
      {
        "surname": "Zhen",
        "given_name": "Ling"
      },
      {
        "surname": "Jing",
        "given_name": "Ling"
      }
    ]
  },
  {
    "title": "Embedding and approximation theorems for echo state networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.013",
    "abstract": "Echo State Networks (ESNs) are a class of single-layer recurrent neural networks that have enjoyed recent attention. In this paper we prove that a suitable ESN, trained on a series of measurements of an invertible dynamical system, induces a C 1 map from the dynamical system’s phase space to the ESN’s reservoir space. We call this the Echo State Map. We then prove that the Echo State Map is generically an embedding with positive probability. Under additional mild assumptions, we further conjecture that the Echo State Map is almost surely an embedding. For sufficiently large, and specially structured, but still randomly generated ESNs, we prove that there exists a linear readout layer that allows the ESN to predict the next observation of a dynamical system arbitrarily well. Consequently, if the dynamical system under observation is structurally stable then the trained ESN will exhibit dynamics that are topologically conjugate to the future behaviour of the observed dynamical system. Our theoretical results connect the theory of ESNs to the delay-embedding literature for dynamical systems, and are supported by numerical evidence from simulations of the traditional Lorenz equations. The simulations confirm that, from a one dimensional observation function, an ESN can accurately infer a range of geometric and topological features of the dynamics such as the eigenvalues of equilibrium points, Lyapunov exponents and homology groups.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301830",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chaotic",
      "Computer science",
      "Dynamical system (definition)",
      "Dynamical systems theory",
      "Echo state network",
      "Embedding",
      "Invertible matrix",
      "Lyapunov exponent",
      "Mathematics",
      "Phase space",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Recurrent neural network",
      "State space",
      "Statistical physics",
      "Statistics",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Hart",
        "given_name": "Allen"
      },
      {
        "surname": "Hook",
        "given_name": "James"
      },
      {
        "surname": "Dawes",
        "given_name": "Jonathan"
      }
    ]
  },
  {
    "title": "Cross-modality paired-images generation and augmentation for RGB-infrared person re-identification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.008",
    "abstract": "RGB-Infrared (IR) person re-identification is very challenging due to the large cross-modality variations between RGB and IR images. Considering no correspondence labels between every pair of RGB and IR images, most methods try to alleviate the variations with set-level alignment by reducing marginal distribution divergence between the entire RGB and IR sets. However, this set-level alignment strategy may lead to misalignment of some instances, which limit the performance for RGB–IR Re-ID. Different from existing methods, in this paper, we propose to generate cross-modality paired-images and perform both global set-level and fine-grained instance-level alignments. Our proposed method enjoys several merits. First, our method can perform set-level alignment by disentangling modality-specific and modality-invariant features. Compared with conventional methods, ours can explicitly remove the modality-specific features and the modality variation can be better reduced. Second, given cross-modality unpaired-images of a person, our method can generate cross-modality paired images from exchanged features. With them, we can directly perform instance-level alignment by minimizing distances of every pair of images. Third, our method learns a latent manifold space. In the space, we can random sample and generate lots of images of unseen classes. Training with those images, the learned identity feature space is more smooth can generalize better when test. Finally, extensive experimental results on two standard benchmarks demonstrate that the proposed model favorably against state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301702",
    "keywords": [
      "Artificial intelligence",
      "Color space",
      "Computer science",
      "Computer vision",
      "Feature (linguistics)",
      "Feature vector",
      "Image (mathematics)",
      "Linguistics",
      "Mathematics",
      "Modality (human–computer interaction)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "RGB color model",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Guan’an"
      },
      {
        "surname": "Yang",
        "given_name": "Yang"
      },
      {
        "surname": "Zhang",
        "given_name": "Tianzhu"
      },
      {
        "surname": "Cheng",
        "given_name": "Jian"
      },
      {
        "surname": "Hou",
        "given_name": "Zengguang"
      },
      {
        "surname": "Tiwari",
        "given_name": "Prayag"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      }
    ]
  },
  {
    "title": "BPGAN: Bidirectional CT-to-MRI prediction using multi-generative multi-adversarial nets with spectral normalization and localization",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.001",
    "abstract": "Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) are widely used detection technology in screening, diagnosis, and image-guided therapy for both clinical and research. However, CT imposes ionizing radiation to patients during acquisition. Compared to CT, MRI is much safer and does not involve any radiations, but it is more expensive and has prolonged acquisition time. Therefore, it is necessary to estimate one modal image from another given modal image of the same subject for the case of radiotherapy planning. Considering that there is currently no bidirectional prediction model between MRI and CT images, we propose a bidirectional prediction by using multi-generative multi-adversarial nets (BPGAN) for the prediction of any modal from another modal image in paired and unpaired fashion. In BPGAN, two nonlinear maps are learned by projecting same pathological features from one domain to another with cycle consistency strategy. Technologically, pathological prior information is introduced to constrain the feature generation to attack the potential risk of pathological variance, and edge retention metric is adopted to preserve geometrically distortion and anatomical structure. Algorithmically, spectral normalization is designed to control the performance of discriminator and to make predictor learn better and faster, and the localization is proposed to impose regularizer on predictor to reduce generalization error. Experimental results show that BPGAN generates better predictions than recently state-of-the-art methods. Specifically, BPGAN achieves average increment of MAE 33.2% and 37.4%, and SSIM 24.5% and 44.6% on two baseline datasets than comparisons.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301635",
    "keywords": [
      "Anthropology",
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Detector",
      "Discriminator",
      "Economics",
      "Medical imaging",
      "Metric (unit)",
      "Modal",
      "Normalization (sociology)",
      "Operations management",
      "Pattern recognition (psychology)",
      "Polymer chemistry",
      "Sociology",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Liming"
      },
      {
        "surname": "Zeng",
        "given_name": "Xianhua"
      },
      {
        "surname": "Zhang",
        "given_name": "He"
      },
      {
        "surname": "Li",
        "given_name": "Weisheng"
      },
      {
        "surname": "Lei",
        "given_name": "Jianbo"
      },
      {
        "surname": "Huang",
        "given_name": "Zhiwei"
      }
    ]
  },
  {
    "title": "Fixed-time synchronization of delayed Cohen–Grossberg neural networks based on a novel sliding mode",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.020",
    "abstract": "This paper has discussed fixed-time synchronization of discontinuous Cohen–Grossberg neural networks with time-varying delays and matched disturbances based on sliding mode control technology. First, a novel sliding-mode surface is established. And, the dynamics on the sliding-mode surface can be achieved in the fixed time by employing the Gudermannian function. Then, considering the effect of delay, two different control schemes are introduced to ensure the fixed time reachability of the sliding mode. In addition, some useful criteria are given out for fixed-time synchronization of neural networks, and the setting time is formulated in a straightforward way. Finally, some examples and simulations are presented to verify the validity of the proposed results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301404",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Mode (computer interface)",
      "Operating system",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Jian"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      },
      {
        "surname": "Wu",
        "given_name": "Ailong"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Fast Haar Transforms for Graph Neural Networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.028",
    "abstract": "Graph Neural Networks (GNNs) have become a topic of intense research recently due to their powerful capability in high-dimensional classification and regression tasks for graph-structured data. However, as GNNs typically define the graph convolution by the orthonormal basis for the graph Laplacian, they suffer from high computational cost when the graph size is large. This paper introduces a Haar basis, which is a sparse and localized orthonormal system for a coarse-grained chain on the graph. The graph convolution under Haar basis, called Haar convolution, can be defined accordingly for GNNs. The sparsity and locality of the Haar basis allow Fast Haar Transforms (FHTs) on the graph, by which one then achieves a fast evaluation of Haar convolution between graph data and filters. We conduct experiments on GNNs equipped with Haar convolution, which demonstrates state-of-the-art results on graph-based regression and node classification tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301568",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Graph",
      "Haar",
      "Linguistics",
      "Locality",
      "Orthonormal basis",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Theoretical computer science",
      "Wavelet"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Ming"
      },
      {
        "surname": "Ma",
        "given_name": "Zheng"
      },
      {
        "surname": "Wang",
        "given_name": "Yu Guang"
      },
      {
        "surname": "Zhuang",
        "given_name": "Xiaosheng"
      }
    ]
  },
  {
    "title": "Analog neuron hierarchy",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.006",
    "abstract": "In order to refine the analysis of the computational power of discrete-time recurrent neural networks (NNs) between the binary-state NNs which are equivalent to finite automata (level 3 in the Chomsky hierarchy), and the analog-state NNs with rational weights which are Turing-complete (Chomsky level 0), we study an intermediate model α ANN of a binary-state NN that is extended with α ≥ 0 extra analog-state neurons. For rational weights, we establish an analog neuron hierarchy 0ANNs ⊂ 1ANNs ⊂ 2ANNs ⊆ 3ANNs and separate its first two levels. In particular, 0ANNs coincide with the binary-state NNs (Chomsky level 3) being a proper subset of 1ANNs which accept at most context-sensitive languages (Chomsky level 1) including some non-context-free ones (above Chomsky level 2). We prove that the deterministic (context-free) language L # = { 0 n 1 n ∣ n ≥ 1 } cannot be recognized by any 1ANN even with real weights. In contrast, we show that deterministic pushdown automata accepting deterministic languages can be simulated by 2ANNs with rational weights, which thus constitute a proper superset of 1ANNs. Finally, we prove that the analog neuron hierarchy collapses to 3ANNs by showing that any Turing machine can be simulated by a 3ANN having rational weights, with linear-time overhead.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301684",
    "keywords": [
      "Algorithm",
      "Arithmetic",
      "Artificial intelligence",
      "Artificial neural network",
      "Automaton",
      "Binary number",
      "Biology",
      "Chomsky hierarchy",
      "Computation",
      "Computer science",
      "Context (archaeology)",
      "Economics",
      "Finite-state machine",
      "Formal language",
      "Hierarchy",
      "Market economy",
      "Mathematics",
      "Paleontology",
      "Programming language",
      "Pushdown automaton",
      "State (computer science)",
      "Theoretical computer science",
      "Turing",
      "Turing machine"
    ],
    "authors": [
      {
        "surname": "Šíma",
        "given_name": "Jiří"
      }
    ]
  },
  {
    "title": "Generalized Guerra’s interpolation schemes for dense associative neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.05.009",
    "abstract": "In this work we develop analytical techniques to investigate a broad class of associative neural networks set in the high-storage regime. These techniques translate the original statistical–mechanical problem into an analytical–mechanical one which implies solving a set of partial differential equations, rather than tackling the canonical probabilistic route. We test the method on the classical Hopfield model – where the cost function includes only two-body interactions (i.e., quadratic terms) – and on the “relativistic” Hopfield model — where the (expansion of the) cost function includes p -body (i.e., of degree p ) contributions. Under the replica symmetric assumption, we paint the phase diagrams of these models by obtaining the explicit expression of their free energy as a function of the model parameters (i.e., noise level and memory storage). Further, since for non-pairwise models ergodicity breaking is non necessarily a critical phenomenon, we develop a fluctuation analysis and find that criticality is preserved in the relativistic model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301714",
    "keywords": [],
    "authors": [
      {
        "surname": "Agliari",
        "given_name": "Elena"
      },
      {
        "surname": "Alemanno",
        "given_name": "Francesco"
      },
      {
        "surname": "Barra",
        "given_name": "Adriano"
      },
      {
        "surname": "Fachechi",
        "given_name": "Alberto"
      }
    ]
  },
  {
    "title": "Novel deep neural network based pattern field classification architectures",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.011",
    "abstract": "Field classification is a new extension of traditional classification frameworks that attempts to utilize consistent information from a group of samples (termed fields). By forgoing the independent identically distributed (i.i.d.) assumption, field classification can achieve remarkably improved accuracy compared to traditional classification methods. Most studies of field classification have been conducted on traditional machine learning methods. In this paper, we propose integration with a Bayesian framework, for the first time, in order to extend field classification to deep learning and propose two novel deep neural network architectures: the Field Deep Perceptron (FDP) and the Field Deep Convolutional Neural Network (FDCNN). Specifically, we exploit a deep perceptron structure, typically a 6-layer structure, where the first 3 layers remove (learn) a ‘style’ from a group of samples to map them into a more discriminative space and the last 3 layers are trained to perform classification. For the FDCNN, we modify the AlexNet framework by adding style transformation layers within the hidden layers. We derive a novel learning scheme from a Bayesian framework and design a novel and efficient learning algorithm with guaranteed convergence for training the deep networks. The whole framework is interpreted with visualization features showing that the field deep neural network can better learn the style of a group of samples. Our developed models are also able to achieve transfer learning and learn transformations for newly introduced fields. We conduct extensive comparative experiments on benchmark data (including face, speech, and handwriting data) to validate our learning approach. Experimental results demonstrate that our proposed deep frameworks achieve significant improvements over other state-of-the-art algorithms, attaining new benchmark performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300885",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Discriminative model",
      "Field (mathematics)",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematics",
      "Multilayer perceptron",
      "Pattern recognition (psychology)",
      "Perceptron",
      "Pure mathematics",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Kaizhu"
      },
      {
        "surname": "Zhang",
        "given_name": "Shufei"
      },
      {
        "surname": "Zhang",
        "given_name": "Rui"
      },
      {
        "surname": "Hussain",
        "given_name": "Amir"
      }
    ]
  },
  {
    "title": "Generative Adversarial Networks are special cases of Artificial Curiosity (1990) and also closely related to Predictability Minimization (1991)",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.008",
    "abstract": "I review unsupervised or self-supervised neural networks playing minimax games in game-theoretic settings: (i) Artificial Curiosity (AC, 1990) is based on two such networks. One network learns to generate a probability distribution over outputs, the other learns to predict effects of the outputs. Each network minimizes the objective function maximized by the other. (ii) Generative Adversarial Networks (GANs, 2010-2014) are an application of AC where the effect of an output is 1 if the output is in a given set, and 0 otherwise. (iii) Predictability Minimization (PM, 1990s) models data distributions through a neural encoder that maximizes the objective function minimized by a neural predictor of the code components. I correct a previously published claim that PM is not based on a minimax game.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301283",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Code (set theory)",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Generative grammar",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Minification",
      "Minimax",
      "Predictability",
      "Programming language",
      "Set (abstract data type)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Schmidhuber",
        "given_name": "Jürgen"
      }
    ]
  },
  {
    "title": "Novel deep neural network based pattern field classification architectures",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.011",
    "abstract": "Field classification is a new extension of traditional classification frameworks that attempts to utilize consistent information from a group of samples (termed fields). By forgoing the independent identically distributed (i.i.d.) assumption, field classification can achieve remarkably improved accuracy compared to traditional classification methods. Most studies of field classification have been conducted on traditional machine learning methods. In this paper, we propose integration with a Bayesian framework, for the first time, in order to extend field classification to deep learning and propose two novel deep neural network architectures: the Field Deep Perceptron (FDP) and the Field Deep Convolutional Neural Network (FDCNN). Specifically, we exploit a deep perceptron structure, typically a 6-layer structure, where the first 3 layers remove (learn) a ‘style’ from a group of samples to map them into a more discriminative space and the last 3 layers are trained to perform classification. For the FDCNN, we modify the AlexNet framework by adding style transformation layers within the hidden layers. We derive a novel learning scheme from a Bayesian framework and design a novel and efficient learning algorithm with guaranteed convergence for training the deep networks. The whole framework is interpreted with visualization features showing that the field deep neural network can better learn the style of a group of samples. Our developed models are also able to achieve transfer learning and learn transformations for newly introduced fields. We conduct extensive comparative experiments on benchmark data (including face, speech, and handwriting data) to validate our learning approach. Experimental results demonstrate that our proposed deep frameworks achieve significant improvements over other state-of-the-art algorithms, attaining new benchmark performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300885",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Discriminative model",
      "Field (mathematics)",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematics",
      "Multilayer perceptron",
      "Pattern recognition (psychology)",
      "Perceptron",
      "Pure mathematics",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Kaizhu"
      },
      {
        "surname": "Zhang",
        "given_name": "Shufei"
      },
      {
        "surname": "Zhang",
        "given_name": "Rui"
      },
      {
        "surname": "Hussain",
        "given_name": "Amir"
      }
    ]
  },
  {
    "title": "Generative Adversarial Networks are special cases of Artificial Curiosity (1990) and also closely related to Predictability Minimization (1991)",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.008",
    "abstract": "I review unsupervised or self-supervised neural networks playing minimax games in game-theoretic settings: (i) Artificial Curiosity (AC, 1990) is based on two such networks. One network learns to generate a probability distribution over outputs, the other learns to predict effects of the outputs. Each network minimizes the objective function maximized by the other. (ii) Generative Adversarial Networks (GANs, 2010-2014) are an application of AC where the effect of an output is 1 if the output is in a given set, and 0 otherwise. (iii) Predictability Minimization (PM, 1990s) models data distributions through a neural encoder that maximizes the objective function minimized by a neural predictor of the code components. I correct a previously published claim that PM is not based on a minimax game.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301283",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Code (set theory)",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Generative grammar",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Minification",
      "Minimax",
      "Predictability",
      "Programming language",
      "Set (abstract data type)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Schmidhuber",
        "given_name": "Jürgen"
      }
    ]
  },
  {
    "title": "Novel deep neural network based pattern field classification architectures",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.011",
    "abstract": "Field classification is a new extension of traditional classification frameworks that attempts to utilize consistent information from a group of samples (termed fields). By forgoing the independent identically distributed (i.i.d.) assumption, field classification can achieve remarkably improved accuracy compared to traditional classification methods. Most studies of field classification have been conducted on traditional machine learning methods. In this paper, we propose integration with a Bayesian framework, for the first time, in order to extend field classification to deep learning and propose two novel deep neural network architectures: the Field Deep Perceptron (FDP) and the Field Deep Convolutional Neural Network (FDCNN). Specifically, we exploit a deep perceptron structure, typically a 6-layer structure, where the first 3 layers remove (learn) a ‘style’ from a group of samples to map them into a more discriminative space and the last 3 layers are trained to perform classification. For the FDCNN, we modify the AlexNet framework by adding style transformation layers within the hidden layers. We derive a novel learning scheme from a Bayesian framework and design a novel and efficient learning algorithm with guaranteed convergence for training the deep networks. The whole framework is interpreted with visualization features showing that the field deep neural network can better learn the style of a group of samples. Our developed models are also able to achieve transfer learning and learn transformations for newly introduced fields. We conduct extensive comparative experiments on benchmark data (including face, speech, and handwriting data) to validate our learning approach. Experimental results demonstrate that our proposed deep frameworks achieve significant improvements over other state-of-the-art algorithms, attaining new benchmark performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300885",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Discriminative model",
      "Field (mathematics)",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematics",
      "Multilayer perceptron",
      "Pattern recognition (psychology)",
      "Perceptron",
      "Pure mathematics",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Kaizhu"
      },
      {
        "surname": "Zhang",
        "given_name": "Shufei"
      },
      {
        "surname": "Zhang",
        "given_name": "Rui"
      },
      {
        "surname": "Hussain",
        "given_name": "Amir"
      }
    ]
  },
  {
    "title": "Generative Adversarial Networks are special cases of Artificial Curiosity (1990) and also closely related to Predictability Minimization (1991)",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.008",
    "abstract": "I review unsupervised or self-supervised neural networks playing minimax games in game-theoretic settings: (i) Artificial Curiosity (AC, 1990) is based on two such networks. One network learns to generate a probability distribution over outputs, the other learns to predict effects of the outputs. Each network minimizes the objective function maximized by the other. (ii) Generative Adversarial Networks (GANs, 2010-2014) are an application of AC where the effect of an output is 1 if the output is in a given set, and 0 otherwise. (iii) Predictability Minimization (PM, 1990s) models data distributions through a neural encoder that maximizes the objective function minimized by a neural predictor of the code components. I correct a previously published claim that PM is not based on a minimax game.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301283",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Code (set theory)",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Generative grammar",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Minification",
      "Minimax",
      "Predictability",
      "Programming language",
      "Set (abstract data type)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Schmidhuber",
        "given_name": "Jürgen"
      }
    ]
  },
  {
    "title": "Training of deep neural networks for the generation of dynamic movement primitives",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.010",
    "abstract": "Dynamic movement primitives (DMPs) have proven to be an effective movement representation for motor skill learning. In this paper, we propose a new approach for training deep neural networks to synthesize dynamic movement primitives. The distinguishing property of our approach is that it can utilize a novel loss function that measures the physical distance between movement trajectories as opposed to measuring the distance between the parameters of DMPs that have no physical meaning. This was made possible by deriving differential equations that can be applied to compute the gradients of the proposed loss function, thus enabling an effective application of backpropagation to optimize the parameters of the underlying deep neural network. While the developed approach is applicable to any neural network architecture, it was evaluated on two different architectures based on encoder–decoder networks and convolutional neural networks. Our results show that the minimization of the proposed loss function leads to better results than when more conventional loss functions are used.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301301",
    "keywords": [
      "Activation function",
      "Aesthetics",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Biology",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Encoder",
      "Epistemology",
      "Evolutionary biology",
      "Function (biology)",
      "Law",
      "Movement (music)",
      "Operating system",
      "Philosophy",
      "Political science",
      "Politics",
      "Property (philosophy)",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Pahič",
        "given_name": "Rok"
      },
      {
        "surname": "Ridge",
        "given_name": "Barry"
      },
      {
        "surname": "Gams",
        "given_name": "Andrej"
      },
      {
        "surname": "Morimoto",
        "given_name": "Jun"
      },
      {
        "surname": "Ude",
        "given_name": "Aleš"
      }
    ]
  },
  {
    "title": "A classification-based approach to semi-supervised clustering with pairwise constraints",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.017",
    "abstract": "In this paper, we introduce a neural network framework for semi-supervised clustering with pairwise (must-link or cannot-link) constraints. In contrast to existing approaches, we decompose semi-supervised clustering into two simpler classification tasks: the first stage uses a pair of Siamese neural networks to label the unlabeled pairs of points as must-link or cannot-link; the second stage uses the fully pairwise-labeled dataset produced by the first stage in a supervised neural-network-based clustering method. The proposed approach is motivated by the observation that binary classification (such as assigning pairwise relations) is usually easier than multi-class clustering with partial supervision. On the other hand, being classification-based, our method solves only well-defined classification problems, rather than less well specified clustering tasks. Extensive experiments on various datasets demonstrate the high performance of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301374",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Binary classification",
      "Class (philosophy)",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Machine learning",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Śmieja",
        "given_name": "Marek"
      },
      {
        "surname": "Struski",
        "given_name": "Łukasz"
      },
      {
        "surname": "Figueiredo",
        "given_name": "Mário A.T."
      }
    ]
  },
  {
    "title": "Finite-time synchronization of memristor neural networks via interval matrix method",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.003",
    "abstract": "In this paper, the finite-time synchronization problems of two types of driven-response memristor neural networks (MNNs) without time-delay and with time-varying delays are investigated via interval matrix method, respectively. Based on interval matrix transformation, the driven-response MNNs are transformed into a kind of system with interval parameters, which is different from the previous research approaches. Several sufficient conditions in terms of linear matrix inequalities (LMIs) are driven to guarantee finite-time synchronization for MNNs. Correspondingly, two types of nonlinear feedback controllers are designed. Meanwhile, the upper-bounded of the settling time functions are estimated. Finally, two numerical examples with simulations are given to illustrate the correctness of the theoretical results and the effectiveness of the proposed controllers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301234",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Correctness",
      "Electrical engineering",
      "Engineering",
      "Interval (graph theory)",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Memristor",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Settling time",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Fei"
      },
      {
        "surname": "Chen",
        "given_name": "Guici"
      },
      {
        "surname": "Wang",
        "given_name": "Wenbo"
      }
    ]
  },
  {
    "title": "Finite-time synchronization of memristor neural networks via interval matrix method",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.003",
    "abstract": "In this paper, the finite-time synchronization problems of two types of driven-response memristor neural networks (MNNs) without time-delay and with time-varying delays are investigated via interval matrix method, respectively. Based on interval matrix transformation, the driven-response MNNs are transformed into a kind of system with interval parameters, which is different from the previous research approaches. Several sufficient conditions in terms of linear matrix inequalities (LMIs) are driven to guarantee finite-time synchronization for MNNs. Correspondingly, two types of nonlinear feedback controllers are designed. Meanwhile, the upper-bounded of the settling time functions are estimated. Finally, two numerical examples with simulations are given to illustrate the correctness of the theoretical results and the effectiveness of the proposed controllers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301234",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Correctness",
      "Electrical engineering",
      "Engineering",
      "Interval (graph theory)",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Memristor",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Settling time",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Fei"
      },
      {
        "surname": "Chen",
        "given_name": "Guici"
      },
      {
        "surname": "Wang",
        "given_name": "Wenbo"
      }
    ]
  },
  {
    "title": "Neural memory plasticity for medical anomaly detection",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.011",
    "abstract": "In the domain of machine learning, Neural Memory Networks (NMNs) have recently achieved impressive results in a variety of application areas including visual question answering, trajectory prediction, object tracking, and language modelling. However, we observe that the attention based knowledge retrieval mechanisms used in current NMNs restrict them from achieving their full potential as the attention process retrieves information based on a set of static connection weights. This is suboptimal in a setting where there are vast differences among samples in the data domain; such as anomaly detection where there is no consistent criteria for what constitutes an anomaly. In this paper, we propose a plastic neural memory access mechanism which exploits both static and dynamic connection weights in the memory read, write and output generation procedures. We demonstrate the effectiveness and flexibility of the proposed memory model in three challenging anomaly detection tasks in the medical domain: abnormal EEG identification, MRI tumour type classification and schizophrenia risk detection in children. In all settings, the proposed approach outperforms the current state-of-the-art. Furthermore, we perform an in-depth analysis demonstrating the utility of neural plasticity for the knowledge retrieval process and provide evidence on how the proposed memory model generates sparse yet informative memory outputs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301313",
    "keywords": [
      "Anomaly detection",
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Computer science",
      "Domain (mathematical analysis)",
      "Flexibility (engineering)",
      "Identification (biology)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Fernando",
        "given_name": "Tharindu"
      },
      {
        "surname": "Denman",
        "given_name": "Simon"
      },
      {
        "surname": "Ahmedt-Aristizabal",
        "given_name": "David"
      },
      {
        "surname": "Sridharan",
        "given_name": "Sridha"
      },
      {
        "surname": "Laurens",
        "given_name": "Kristin R."
      },
      {
        "surname": "Johnston",
        "given_name": "Patrick"
      },
      {
        "surname": "Fookes",
        "given_name": "Clinton"
      }
    ]
  },
  {
    "title": "Synchronization of coupled neural networks under mixed impulsive effects: A novel delay inequality approach",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.002",
    "abstract": "In this paper, the synchronization problems of an array of coupled neural networks with mixed impulses are considered. Here mixed impulses contain desynchronizing delay-free impulses, synchronizing delay-free impulses, desynchronizing delayed impulses and synchronizing delayed impulses. A novel concept named average delayed impulsive gain is proposed to quantify the effects of mixed impulses. Besides, we establish a delayed impulsive differential inequality which extends famous Halanay inequality, and apply it to study the synchronization problems of delayed neural networks with mixed impulses. It is interesting to notice that both delay-free impulses and delayed impulses can contribute to the synchronization of coupled neural networks. Meanwhile, we also discuss the synchronization of neural networks only with delay-dependent impulses. Some sufficient conditions are derived to ensure the exponential synchronization of delayed neural networks. Finally, some numerical examples are provided to illustrate the validity and superiority of the obtained results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301222",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Impulse (physics)",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Synchronizing",
      "Telecommunications",
      "Topology (electrical circuits)",
      "Transmission (telecommunications)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yaqi"
      },
      {
        "surname": "Lu",
        "given_name": "Jianquan"
      },
      {
        "surname": "Li",
        "given_name": "Xiaodi"
      },
      {
        "surname": "Liang",
        "given_name": "Jinling"
      }
    ]
  },
  {
    "title": "Neural memory plasticity for medical anomaly detection",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.011",
    "abstract": "In the domain of machine learning, Neural Memory Networks (NMNs) have recently achieved impressive results in a variety of application areas including visual question answering, trajectory prediction, object tracking, and language modelling. However, we observe that the attention based knowledge retrieval mechanisms used in current NMNs restrict them from achieving their full potential as the attention process retrieves information based on a set of static connection weights. This is suboptimal in a setting where there are vast differences among samples in the data domain; such as anomaly detection where there is no consistent criteria for what constitutes an anomaly. In this paper, we propose a plastic neural memory access mechanism which exploits both static and dynamic connection weights in the memory read, write and output generation procedures. We demonstrate the effectiveness and flexibility of the proposed memory model in three challenging anomaly detection tasks in the medical domain: abnormal EEG identification, MRI tumour type classification and schizophrenia risk detection in children. In all settings, the proposed approach outperforms the current state-of-the-art. Furthermore, we perform an in-depth analysis demonstrating the utility of neural plasticity for the knowledge retrieval process and provide evidence on how the proposed memory model generates sparse yet informative memory outputs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301313",
    "keywords": [
      "Anomaly detection",
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Computer science",
      "Domain (mathematical analysis)",
      "Flexibility (engineering)",
      "Identification (biology)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Fernando",
        "given_name": "Tharindu"
      },
      {
        "surname": "Denman",
        "given_name": "Simon"
      },
      {
        "surname": "Ahmedt-Aristizabal",
        "given_name": "David"
      },
      {
        "surname": "Sridharan",
        "given_name": "Sridha"
      },
      {
        "surname": "Laurens",
        "given_name": "Kristin R."
      },
      {
        "surname": "Johnston",
        "given_name": "Patrick"
      },
      {
        "surname": "Fookes",
        "given_name": "Clinton"
      }
    ]
  },
  {
    "title": "Micro-cracks detection of solar cells surface via combining short-term and long-term deep features",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.012",
    "abstract": "The machine vision based methods for micro-cracks detection of solar cells surface have become one of the main research directions with its efficiency and convenience. The existed methods are roughly classified into two categories: current viewing information based methods, prior knowledge based methods, however, the former usually adopt hand-designed features with poor generality and lacks the guidance of prior knowledge, the latter are usually implemented through the machine learning, and the generalization ability is also limited since the large-scale annotation dataset is scarce. To resolve above problems, a novel micro-cracks detection method via combining short-term and long-term deep features is proposed in this paper. The short-term deep features which represent the current viewing information are learned from the input image itself through stacked denoising auto encoder (SDAE), the long-term deep features which represent the prior knowledge are learned from a large number of natural scene images that people often see through convolutional neural networks (CNNs). The subjective and objective evaluations demonstrate that: 1) the performance of combining the short-term and long-term deep features is better than any of them alone, 2) the performance of proposed method is superior to the shallow learning based methods, 3) the proposed method can effectively detect various kinds of micro-cracks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301325",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Generality",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Physics",
      "Psychology",
      "Psychotherapist",
      "Quantum mechanics",
      "Term (time)"
    ],
    "authors": [
      {
        "surname": "Qian",
        "given_name": "Xiaoliang"
      },
      {
        "surname": "Li",
        "given_name": "Jing"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Wu",
        "given_name": "Yuanyuan"
      },
      {
        "surname": "Wang",
        "given_name": "Wei"
      }
    ]
  },
  {
    "title": "Micro-cracks detection of solar cells surface via combining short-term and long-term deep features",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.012",
    "abstract": "The machine vision based methods for micro-cracks detection of solar cells surface have become one of the main research directions with its efficiency and convenience. The existed methods are roughly classified into two categories: current viewing information based methods, prior knowledge based methods, however, the former usually adopt hand-designed features with poor generality and lacks the guidance of prior knowledge, the latter are usually implemented through the machine learning, and the generalization ability is also limited since the large-scale annotation dataset is scarce. To resolve above problems, a novel micro-cracks detection method via combining short-term and long-term deep features is proposed in this paper. The short-term deep features which represent the current viewing information are learned from the input image itself through stacked denoising auto encoder (SDAE), the long-term deep features which represent the prior knowledge are learned from a large number of natural scene images that people often see through convolutional neural networks (CNNs). The subjective and objective evaluations demonstrate that: 1) the performance of combining the short-term and long-term deep features is better than any of them alone, 2) the performance of proposed method is superior to the shallow learning based methods, 3) the proposed method can effectively detect various kinds of micro-cracks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301325",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Generality",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Physics",
      "Psychology",
      "Psychotherapist",
      "Quantum mechanics",
      "Term (time)"
    ],
    "authors": [
      {
        "surname": "Qian",
        "given_name": "Xiaoliang"
      },
      {
        "surname": "Li",
        "given_name": "Jing"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Wu",
        "given_name": "Yuanyuan"
      },
      {
        "surname": "Wang",
        "given_name": "Wei"
      }
    ]
  },
  {
    "title": "Vulnerability of classifiers to evolutionary generated adversarial examples",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.015",
    "abstract": "This paper deals with the vulnerability of machine learning models to adversarial examples and its implication for robustness and generalization properties. We propose an evolutionary algorithm that can generate adversarial examples for any machine learning model in the black-box attack scenario. This way, we can find adversarial examples without access to model’s parameters, only by querying the model at hand. We have tested a range of machine learning models including deep and shallow neural networks. Our experiments have shown that the vulnerability to adversarial examples is not only the problem of deep networks, but it spreads through various machine learning architectures. Rather, it depends on the type of computational units. Local units, such as Gaussian kernels, are less vulnerable to adversarial examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301350",
    "keywords": [
      "Adversarial machine learning",
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Black box",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Deep neural networks",
      "Gene",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Robustness (evolution)",
      "Vulnerability (computing)"
    ],
    "authors": [
      {
        "surname": "Vidnerová",
        "given_name": "Petra"
      },
      {
        "surname": "Neruda",
        "given_name": "Roman"
      }
    ]
  },
  {
    "title": "Neural memory plasticity for medical anomaly detection",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.011",
    "abstract": "In the domain of machine learning, Neural Memory Networks (NMNs) have recently achieved impressive results in a variety of application areas including visual question answering, trajectory prediction, object tracking, and language modelling. However, we observe that the attention based knowledge retrieval mechanisms used in current NMNs restrict them from achieving their full potential as the attention process retrieves information based on a set of static connection weights. This is suboptimal in a setting where there are vast differences among samples in the data domain; such as anomaly detection where there is no consistent criteria for what constitutes an anomaly. In this paper, we propose a plastic neural memory access mechanism which exploits both static and dynamic connection weights in the memory read, write and output generation procedures. We demonstrate the effectiveness and flexibility of the proposed memory model in three challenging anomaly detection tasks in the medical domain: abnormal EEG identification, MRI tumour type classification and schizophrenia risk detection in children. In all settings, the proposed approach outperforms the current state-of-the-art. Furthermore, we perform an in-depth analysis demonstrating the utility of neural plasticity for the knowledge retrieval process and provide evidence on how the proposed memory model generates sparse yet informative memory outputs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301313",
    "keywords": [
      "Anomaly detection",
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Computer science",
      "Domain (mathematical analysis)",
      "Flexibility (engineering)",
      "Identification (biology)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Fernando",
        "given_name": "Tharindu"
      },
      {
        "surname": "Denman",
        "given_name": "Simon"
      },
      {
        "surname": "Ahmedt-Aristizabal",
        "given_name": "David"
      },
      {
        "surname": "Sridharan",
        "given_name": "Sridha"
      },
      {
        "surname": "Laurens",
        "given_name": "Kristin R."
      },
      {
        "surname": "Johnston",
        "given_name": "Patrick"
      },
      {
        "surname": "Fookes",
        "given_name": "Clinton"
      }
    ]
  },
  {
    "title": "Vulnerability of classifiers to evolutionary generated adversarial examples",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.015",
    "abstract": "This paper deals with the vulnerability of machine learning models to adversarial examples and its implication for robustness and generalization properties. We propose an evolutionary algorithm that can generate adversarial examples for any machine learning model in the black-box attack scenario. This way, we can find adversarial examples without access to model’s parameters, only by querying the model at hand. We have tested a range of machine learning models including deep and shallow neural networks. Our experiments have shown that the vulnerability to adversarial examples is not only the problem of deep networks, but it spreads through various machine learning architectures. Rather, it depends on the type of computational units. Local units, such as Gaussian kernels, are less vulnerable to adversarial examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301350",
    "keywords": [
      "Adversarial machine learning",
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Black box",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Deep neural networks",
      "Gene",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Robustness (evolution)",
      "Vulnerability (computing)"
    ],
    "authors": [
      {
        "surname": "Vidnerová",
        "given_name": "Petra"
      },
      {
        "surname": "Neruda",
        "given_name": "Roman"
      }
    ]
  },
  {
    "title": "Graph Convolution Networks with manifold regularization for semi-supervised learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.016",
    "abstract": "In recent times, Graph Convolution Networks (GCN) have been proposed as a powerful tool for graph-based semi-supervised learning. In this paper, we introduce a model that enhances label propagation of Graph Convolution Networks (GCN). More precisely, we propose GCNs with Manifold Regularization (GCNMR). The objective function of the proposed GCNMR is composed by a supervised term and an unsupervised term. The supervised term enforces the fitting term between the predicted labels and the known labels. The unsupervised term imposes the smoothness of the predicted labels of the whole data samples. By learning a Graph Convolution Network with the proposed objective function, we are able to derive a more powerful semi-supervised learning. The proposed model retains the advantages of the classic GCN, yet it can improve it with no increase in time complexity. Experiments on three public image datasets show that the proposed model is superior to the GCN and several competing existing graph-based semi-supervised learning methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301362",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Graph",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Semi-supervised learning",
      "Supervised learning",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Kejani",
        "given_name": "M. Tavassoli"
      },
      {
        "surname": "Dornaika",
        "given_name": "F."
      },
      {
        "surname": "Talebi",
        "given_name": "H."
      }
    ]
  },
  {
    "title": "Dendrite P systems",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.014",
    "abstract": "It was recently found that dendrites are not just a passive channel. They can perform mixed computation of analog and digital signals, and therefore can be abstracted as information processors. Moreover, dendrites possess a feedback mechanism. Motivated by these computational and feedback characteristics, this article proposes a new variant of neural-like P systems, dendrite P (DeP) systems, where neurons simulate the computational function of dendrites and perform a firing–storing process instead of the storing–firing process in spiking neural P (SNP) systems. Moreover, the behavior of the neurons is characterized by dendrite rules that are abstracted by two characteristics of dendrites. Different from the usual firing rules in SNP systems, the firing of a dendrite rule is controlled by the states of the corresponding source neurons. Therefore, DeP systems can provide a collaborative control capability for neurons. We discuss the computational power of DeP systems. In particular, it is proven that DeP systems are Turing-universal number generating/accepting devices. Moreover, we construct a small universal DeP system consisting of 115 neurons for computing functions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301349",
    "keywords": [
      "Algorithm",
      "Computation",
      "Computer science",
      "Dendrite (mathematics)",
      "Geometry",
      "Mathematics",
      "Operating system",
      "Process (computing)",
      "Programming language",
      "Turing"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Hong"
      },
      {
        "surname": "Bao",
        "given_name": "Tingting"
      },
      {
        "surname": "Luo",
        "given_name": "Xiaohui"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Song",
        "given_name": "Xiaoxiao"
      },
      {
        "surname": "Riscos-Núñez",
        "given_name": "Agustín"
      },
      {
        "surname": "Pérez-Jiménez",
        "given_name": "Mario J."
      }
    ]
  },
  {
    "title": "Linear embedding by joint Robust Discriminant Analysis and Inter-class Sparsity",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.018",
    "abstract": "Linear Discriminant Analysis (LDA) and its variants are widely used as feature extraction methods. They have been used for different classification tasks. However, these methods have some limitations that need to be overcome. The main limitation is that the projection obtained by LDA does not provide a good interpretability for the features. In this paper, we propose a novel supervised method used for multi-class classification that simultaneously performs feature selection and extraction. The targeted projection transformation focuses on the most discriminant original features, and at the same time, makes sure that the transformed features (extracted features) belonging to each class have common sparsity. Our proposed method is called Robust Discriminant Analysis with Feature Selection and Inter-class Sparsity (RDA _ FSIS). The corresponding model integrates two types of sparsity. The first type is obtained by imposing the ℓ 2 , 1 constraint on the projection matrix in order to perform feature selection. The second type of sparsity is obtained by imposing the inter-class sparsity constraint used for ensuring a common sparsity structure in each class. An orthogonal matrix is also introduced in our model in order to guarantee that the extracted features can retain the main variance of the original data and thus improve the robustness to noise. The proposed method retrieves the LDA transformation by taking into account the two types of sparsity. Various experiments are conducted on several image datasets including faces, objects and digits. The projected features are used for multi-class classification. Obtained results show that the proposed method outperforms other competing methods by learning a more compact and discriminative transformation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301386",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Constraint (computer-aided design)",
      "Discriminant",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature selection",
      "Gene",
      "Geometry",
      "Interpretability",
      "Linear discriminant analysis",
      "Linguistics",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Projection (relational algebra)",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Dornaika",
        "given_name": "F."
      },
      {
        "surname": "Khoder",
        "given_name": "A."
      }
    ]
  },
  {
    "title": "Further results on finite-time synchronization of delayed inertial memristive neural networks via a novel analysis method",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.009",
    "abstract": "In this paper, we propose a novel analysis method to investigate the finite-time synchronization (FTS) control problem of the drive–response inertial memristive neural networks (IMNNs) with mixed time-varying delays (MTVDs). Firstly, an improved control scheme is proposed under the delay-independent conditions, which can work even when the past state cannot be measured or the specific time delay function is unknown. Secondly, based on the assumption of bounded activation functions, we establish a new Lemma, which can effectively deal with the difficulties caused by memristive connection weights and MTVDs. Thirdly, by constructing a suitable Lyapunov functions and using a new inequality method, novel sufficient conditions to ensure the FTS for the discussed IMNNs are obtained. Compared with the existing results, our results obtained in a more general framework are more practical. Finally, some numerical simulations are given to substantiate the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301295",
    "keywords": [
      "Activation function",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Ecology",
      "Electrical engineering",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Inertial frame of reference",
      "Lemma (botany)",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Memristor",
      "Nonlinear system",
      "Physics",
      "Poaceae",
      "Quantum mechanics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Hua",
        "given_name": "Lanfeng"
      },
      {
        "surname": "Zhong",
        "given_name": "Shouming"
      },
      {
        "surname": "Shi",
        "given_name": "Kaibo"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiaojun"
      }
    ]
  },
  {
    "title": "Randomized sketches for kernel CCA",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.04.006",
    "abstract": "Kernel canonical correlation analysis (KCCA) is a popular tool as a nonlinear extension of canonical correlation analysis. Consistency and optimal convergence rate have been established in the literature. However, the time complexity of KCCA scales as O ( n 3 ) and is thus prohibitive when n is large. We propose an m -dimensional randomized sketches approach for KCCA with m < < n , based on the recent work on randomized sketches for kernel ridge regression (KRR). Technically we establish our theoretical results relying on an interesting connection between KCCA and KRR by utilizing a novel “duality tracking” device that alternates between the infinite-dimensional operator-theory-based view of KCCA and the finite-dimensional kernel-matrix-based view.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030126X",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Kernel (algebra)",
      "Mathematics",
      "Medicine",
      "Pattern recognition (psychology)",
      "Randomized controlled trial",
      "Surgery"
    ],
    "authors": [
      {
        "surname": "Lian",
        "given_name": "Heng"
      },
      {
        "surname": "Zhang",
        "given_name": "Fode"
      },
      {
        "surname": "Lu",
        "given_name": "Wenqi"
      }
    ]
  },
  {
    "title": "Variational approximation error in non-negative matrix factorization",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.009",
    "abstract": "Non-negative matrix factorization (NMF) is a knowledge discovery method that is used in many fields. Variational inference and Gibbs sampling methods for it are also well-known. However, the variational approximation error has not been clarified yet, because NMF is not statistically regular and the prior distribution used in variational Bayesian NMF (VBNMF) has zero or divergence points. In this paper, using algebraic geometrical methods, we theoretically analyze the difference in negative log evidence (a.k.a. free energy) between VBNMF and Bayesian NMF, i.e., the Kullback–Leibler divergence between the variational posterior and the true posterior. We derive an upper bound for the learning coefficient (a.k.a. the real log canonical threshold) in Bayesian NMF. By using the upper bound, we find a lower bound for the approximation error, asymptotically. The result quantitatively shows how well the VBNMF algorithm can approximate Bayesian NMF; the lower bound depends on the hyperparameters and the true non-negative rank. A numerical experiment demonstrates the theoretical result.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300861",
    "keywords": [
      "Applied mathematics",
      "Bayesian inference",
      "Bayesian probability",
      "Divergence (linguistics)",
      "Eigenvalues and eigenvectors",
      "Gibbs sampling",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Matrix decomposition",
      "Non-negative matrix factorization",
      "Philosophy",
      "Physics",
      "Posterior probability",
      "Quantum mechanics",
      "Statistics",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Hayashi",
        "given_name": "Naoki"
      }
    ]
  },
  {
    "title": "Extracting boolean and probabilistic rules from trained neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.024",
    "abstract": "This paper presents two approaches to extracting rules from a trained neural network consisting of linear threshold functions. The first one leads to an algorithm that extracts rules in the form of Boolean functions. Compared with an existing one, this algorithm outputs much more concise rules if the threshold functions correspond to 1-decision lists, majority functions, or certain combinations of these. The second one extracts probabilistic rules representing relations between some of the input variables and the output using a dynamic programming algorithm. The algorithm runs in pseudo-polynomial time if each hidden layer has a constant number of neurons. We demonstrate the effectiveness of these two approaches by computational experiments.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301180",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Boolean function",
      "Computer science",
      "Constant (computer programming)",
      "Mathematical analysis",
      "Mathematics",
      "Polynomial",
      "Probabilistic logic",
      "Probabilistic neural network",
      "Programming language",
      "Time complexity",
      "Time delay neural network"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Pengyu"
      },
      {
        "surname": "Melkman",
        "given_name": "Avraham A."
      },
      {
        "surname": "Akutsu",
        "given_name": "Tatsuya"
      }
    ]
  },
  {
    "title": "Cross-modal dual subspace learning with adversarial network",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.015",
    "abstract": "Cross-modal retrieval has recently attracted much interest along with the rapid development of multimodal data, and effectively utilizing the complementary relationship of different modal data and eliminating the heterogeneous gap as much as possible are the two key challenges. In this paper, we present a novel network model termed cross-modal Dual Subspace learning with Adversarial Network (DSAN). The main contributions are as follows: (1) Dual subspaces (visual subspace and textual subspace) are proposed, which can better mine the underlying structure information of different modalities as well as modality-specific information. (2) An improved quadruplet loss is proposed, which takes into account the relative distance and absolute distance between positive and negative samples, together with the introduction of the idea of hard sample mining. (3) Intra-modal constrained loss is proposed to maximize the distance of the most similar cross-modal negative samples and their corresponding cross-modal positive samples. In particular, feature preserving and modality classification act as two antagonists. DSAN tries to narrow the heterogeneous gap between different modalities, and distinguish the original modality of random samples in dual subspaces. Comprehensive experimental results demonstrate that, DSAN significantly outperforms 9 state-of-the-art methods on four cross-modal datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300927",
    "keywords": [
      "Art",
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Dual (grammatical number)",
      "Feature (linguistics)",
      "Geometry",
      "Key (lock)",
      "Linear subspace",
      "Linguistics",
      "Literature",
      "Machine learning",
      "Mathematics",
      "Modal",
      "Modalities",
      "Modality (human–computer interaction)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Polymer chemistry",
      "Social science",
      "Sociology",
      "Subspace topology"
    ],
    "authors": [
      {
        "surname": "Shang",
        "given_name": "Fei"
      },
      {
        "surname": "Zhang",
        "given_name": "Huaxiang"
      },
      {
        "surname": "Sun",
        "given_name": "Jiande"
      },
      {
        "surname": "Nie",
        "given_name": "Liqiang"
      },
      {
        "surname": "Liu",
        "given_name": "Li"
      }
    ]
  },
  {
    "title": "Cross-modal dual subspace learning with adversarial network",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.015",
    "abstract": "Cross-modal retrieval has recently attracted much interest along with the rapid development of multimodal data, and effectively utilizing the complementary relationship of different modal data and eliminating the heterogeneous gap as much as possible are the two key challenges. In this paper, we present a novel network model termed cross-modal Dual Subspace learning with Adversarial Network (DSAN). The main contributions are as follows: (1) Dual subspaces (visual subspace and textual subspace) are proposed, which can better mine the underlying structure information of different modalities as well as modality-specific information. (2) An improved quadruplet loss is proposed, which takes into account the relative distance and absolute distance between positive and negative samples, together with the introduction of the idea of hard sample mining. (3) Intra-modal constrained loss is proposed to maximize the distance of the most similar cross-modal negative samples and their corresponding cross-modal positive samples. In particular, feature preserving and modality classification act as two antagonists. DSAN tries to narrow the heterogeneous gap between different modalities, and distinguish the original modality of random samples in dual subspaces. Comprehensive experimental results demonstrate that, DSAN significantly outperforms 9 state-of-the-art methods on four cross-modal datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300927",
    "keywords": [
      "Art",
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Dual (grammatical number)",
      "Feature (linguistics)",
      "Geometry",
      "Key (lock)",
      "Linear subspace",
      "Linguistics",
      "Literature",
      "Machine learning",
      "Mathematics",
      "Modal",
      "Modalities",
      "Modality (human–computer interaction)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Polymer chemistry",
      "Social science",
      "Sociology",
      "Subspace topology"
    ],
    "authors": [
      {
        "surname": "Shang",
        "given_name": "Fei"
      },
      {
        "surname": "Zhang",
        "given_name": "Huaxiang"
      },
      {
        "surname": "Sun",
        "given_name": "Jiande"
      },
      {
        "surname": "Nie",
        "given_name": "Liqiang"
      },
      {
        "surname": "Liu",
        "given_name": "Li"
      }
    ]
  },
  {
    "title": "Dynamic resource allocation during reinforcement learning accounts for ramping and phasic dopamine activity",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.005",
    "abstract": "For an animal to learn about its environment with limited motor and cognitive resources, it should focus its resources on potentially important stimuli. However, too narrow focus is disadvantageous for adaptation to environmental changes. Midbrain dopamine neurons are excited by potentially important stimuli, such as reward-predicting or novel stimuli, and allocate resources to these stimuli by modulating how an animal approaches, exploits, explores, and attends. The current study examined the theoretical possibility that dopamine activity reflects the dynamic allocation of resources for learning. Dopamine activity may transition between two patterns: (1) phasic responses to cues and rewards, and (2) ramping activity arising as the agent approaches the reward. Phasic excitation has been explained by prediction errors generated by experimentally inserted cues. However, when and why dopamine activity transitions between the two patterns remain unknown. By parsimoniously modifying a standard temporal difference (TD) learning model to accommodate a mixed presentation of both experimental and environmental stimuli, we simulated dopamine transitions and compared them with experimental data from four different studies. The results suggested that dopamine transitions from ramping to phasic patterns as the agent focuses its resources on a small number of reward-predicting stimuli, thus leading to task dimensionality reduction. The opposite occurs when the agent re-distributes its resources to adapt to environmental changes, resulting in task dimensionality expansion. This research elucidates the role of dopamine in a broader context, providing a potential explanation for the diverse repertoire of dopamine activity that cannot be explained solely by prediction error.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300824",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Central nervous system",
      "Cognition",
      "Cognitive psychology",
      "Computer science",
      "Context (archaeology)",
      "Dopamine",
      "Midbrain",
      "Neuroscience",
      "Paleontology",
      "Perception",
      "Psychology",
      "Reinforcement",
      "Reinforcement learning",
      "Social psychology",
      "Temporal difference learning"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Minryung R."
      },
      {
        "surname": "Lee",
        "given_name": "Sang Wan"
      }
    ]
  },
  {
    "title": "Recommendation via Collaborative Autoregressive Flows",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.010",
    "abstract": "Although it is one of the most widely used methods in recommender systems, Collaborative Filtering (CF) still has difficulties in modeling non-linear user–item interactions. Complementary to this, recently developed deep generative model variants (e.g., Variational Autoencoder (VAE)) allowing Bayesian inference and approximation of the variational posterior distributions in these models, have achieved promising performance improvement in many areas. However, the choices of variation distribution – e.g., the popular diagonal-covariance Gaussians – are insufficient to recover the true distributions, often resulting in biased maximum likelihood estimates of the model parameters. Aiming at more tractable and expressive variational families, in this work we extend the flow-based generative model to CF for modeling implicit feedbacks. We present the Collaborative Autoregressive Flows (CAF) for the recommender system, transforming a simple initial density into more complex ones via a sequence of invertible transformations, until a desired level of complexity is attained. CAF is a non-linear probabilistic approach allowing uncertainty representation and exact tractability of latent-variable inference in item recommendations. Compared to the agnostic-presumed prior approximation used in existing deep generative recommendation approaches, CAF is more effective in estimating the probabilistic posterior and achieves better recommendation accuracy. We conducted extensive experimental evaluations demonstrating that CAF can capture more effective representation of latent factors, resulting in a substantial gain on recommendation compared to the state-of-the-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300873",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Autoencoder",
      "Autoregressive model",
      "Bayesian probability",
      "Collaborative filtering",
      "Computer science",
      "Covariance",
      "Deep learning",
      "Diagonal",
      "Econometrics",
      "Generative grammar",
      "Generative model",
      "Geometry",
      "Inference",
      "Latent variable",
      "Law",
      "Machine learning",
      "Mathematics",
      "Political science",
      "Politics",
      "Posterior probability",
      "Probabilistic logic",
      "Recommender system",
      "Representation (politics)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Fan"
      },
      {
        "surname": "Mo",
        "given_name": "Yuhua"
      },
      {
        "surname": "Trajcevski",
        "given_name": "Goce"
      },
      {
        "surname": "Zhang",
        "given_name": "Kunpeng"
      },
      {
        "surname": "Wu",
        "given_name": "Jin"
      },
      {
        "surname": "Zhong",
        "given_name": "Ting"
      }
    ]
  },
  {
    "title": "AdaEn-Net: An ensemble of adaptive 2D–3D Fully Convolutional Networks for medical image segmentation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.007",
    "abstract": "Fully Convolutional Networks (FCNs) have emerged as powerful segmentation models but are usually designed manually, which requires extensive time and can result in large and complex architectures. There is a growing interest to automatically design efficient architectures that can accurately segment 3D medical images. However, most approaches either do not fully exploit volumetric information or do not optimize the model’s size. To address these problems, we propose a self-adaptive 2D–3D ensemble of FCNs called AdaEn-Net for 3D medical image segmentation that incorporates volumetric data and adapts to a particular dataset by optimizing both the model’s performance and size. The AdaEn-Net consists of a 2D FCN that extracts intra-slice information and a 3D FCN that exploits inter-slice information. The architecture and hyperparameters of the 2D and 3D architectures are found through a multiobjective evolutionary based algorithm that maximizes the expected segmentation accuracy and minimizes the number of parameters in the network. The main contribution of this work is a model that fully exploits volumetric information and automatically searches for a high-performing and efficient architecture. The AdaEn-Net was evaluated for prostate segmentation on the PROMISE12 Grand Challenge and for cardiac segmentation on the MICCAI ACDC challenge. In the first challenge, the AdaEn-Net ranks 9 out of 297 submissions and surpasses the performance of an automatically-generated segmentation network while producing an architecture with 13 × fewer parameters. In the second challenge, the proposed model is ranked within the top 8 submissions and outperforms an architecture designed with reinforcement learning while having 1.25 × fewer parameters.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300848",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Exploit",
      "Hyperparameter",
      "Image segmentation",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Baldeon Calisto",
        "given_name": "Maria"
      },
      {
        "surname": "Lai-Yuen",
        "given_name": "Susana K."
      }
    ]
  },
  {
    "title": "NeuroBayesSLAM: Neurobiologically inspired Bayesian integration of multisensory information for robot navigation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.023",
    "abstract": "Spatial navigation depends on the combination of multiple sensory cues from idiothetic and allothetic sources. The computational mechanisms of mammalian brains in integrating different sensory modalities under uncertainty for navigation is enlightening for robot navigation. We propose a Bayesian attractor network model to integrate visual and vestibular inputs inspired by the spatial memory systems of mammalian brains. In the model, the pose of the robot is encoded separately by two sub-networks, namely head direction network for angle representation and grid cell network for position representation, using similar neural codes of head direction cells and grid cells observed in mammalian brains. The neural codes in each of the sub-networks are updated in a Bayesian manner by a population of integrator cells for vestibular cue integration, as well as a population of calibration cells for visual cue calibration. The conflict between vestibular cue and visual cue is resolved by the competitive dynamics between the two populations. The model, implemented on a monocular visual simultaneous localization and mapping (SLAM) system, termed NeuroBayesSLAM, successfully builds semi-metric topological maps and self-localizes in outdoor and indoor environments of difference characteristics, achieving comparable performance as previous neurobiologically inspired navigation systems but with much less computation complexity. The proposed multisensory integration method constitutes a concise yet robust and biologically plausible method for robot navigation in large environments. The model provides a viable Bayesian mechanism for multisensory integration that may pertain to other neural subsystems beyond spatial cognition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300770",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer vision",
      "Demography",
      "Multisensory integration",
      "Neuroscience",
      "Path integration",
      "Population",
      "Sensory system",
      "Sociology",
      "Stimulus modality",
      "Vestibular system"
    ],
    "authors": [
      {
        "surname": "Zeng",
        "given_name": "Taiping"
      },
      {
        "surname": "Tang",
        "given_name": "Fengzhen"
      },
      {
        "surname": "Ji",
        "given_name": "Daxiong"
      },
      {
        "surname": "Si",
        "given_name": "Bailu"
      }
    ]
  },
  {
    "title": "Prediction of admission in pediatric emergency department with deep neural networks and triage textual data",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.012",
    "abstract": "Emergency department (ED) overcrowding is a global condition that severely worsens attention to patients, increases clinical risks and affects hospital cost management. A correct and early prediction of ED’s admission is of high value and a motivation to adopt machine learning models. However, several of these studies do not consider data collected in textual form, which is a feature set that contains detailed information about patients and presents great potential for medical health care improvement. To this end, we propose and compare predictive models for admission that use both structured and unstructured data available at triage time. In total, our dataset comprised 499,853 pediatric ED’s presentations (with an admission rate of 5.76%) of patients with age up to 18 years old observed over 3.5 years. Our best model consists of a 2-stage architecture with a deep neural network (DNN) to extract information from textual data followed by a gradient boosting classifier. This combined model achieved a value of 0.892 for the Area Under the Curve (AUC) in the test data. We highlight the importance of DNN-based text processing for better prediction, since the absence of text features resulted in AUC reduction of approximately two percentage points. Also, the feature importance of text was higher than that of the Manchester Triage System (MTS), which is a widely used risk classification protocol. These results suggest that activations from a trained DNN should be used in transfer learning setups in future studies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300897",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Big data",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Economic growth",
      "Economics",
      "Emergency department",
      "Gradient boosting",
      "Machine learning",
      "Medical emergency",
      "Medicine",
      "Overcrowding",
      "Psychiatry",
      "Random forest",
      "Recurrent neural network",
      "Triage",
      "Unstructured data"
    ],
    "authors": [
      {
        "surname": "Roquette",
        "given_name": "Bruno P."
      },
      {
        "surname": "Nagano",
        "given_name": "Hitoshi"
      },
      {
        "surname": "Marujo",
        "given_name": "Ernesto C."
      },
      {
        "surname": "Maiorano",
        "given_name": "Alexandre C."
      }
    ]
  },
  {
    "title": "A fast conformal predictive system with regularized extreme learning machine",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.022",
    "abstract": "A conformal predictive system(CPS) is based on the learning framework of conformal prediction, which outputs cumulative distribution functions(CDFs) for labels in regression problems. The CDFs output by a CPS provide useful information for users, as they not only provide probability for the events related to the test labels, but also can be transformed to prediction intervals with the corresponding quantiles. Moreover, CPSs have the property of validity since the distributions and intervals they output have statistical compatibility with the realizations. This property is very useful for many risk-sensitive applications such as financial time series forecast and weather forecast. However, as based on conformal predictors, CPSs inherit the computational issue. To build a fast CPS, in this paper, we propose a CPS with regularized extreme learning machine as the underlying algorithm. To be specific, we combine the leave-one-out cross-conformal predictive system(Leave-One-Out CCPS), a variant of the original CPS, with regularized extreme learning machine(RELM), which is named as LOO-CCPS-RELM. We analyse the computational complexity of it and prove its asymptotic validity based on some regularity assumptions. We also prove that the error rate of the prediction interval output by LOO-CCPS-RELM is under control in the asymptotic setting. Experiments with 20 public data sets were conducted to test LOO-CCPS-RELM and the results showed that LOO-CCPS-RELM is empirically valid and compared favourably with the other CPSs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301167",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Conformal map",
      "Econometrics",
      "Extreme learning machine",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Quantile",
      "Quantile regression"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Di"
      },
      {
        "surname": "Wang",
        "given_name": "Ping"
      },
      {
        "surname": "Yuan",
        "given_name": "Yue"
      },
      {
        "surname": "Wang",
        "given_name": "Pingping"
      },
      {
        "surname": "Shi",
        "given_name": "Junzhi"
      }
    ]
  },
  {
    "title": "Deep neural networks with a set of node-wise varying activation functions",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.004",
    "abstract": "In this study, we present deep neural networks with a set of node-wise varying activation functions. The feature-learning abilities of the nodes are affected by the selected activation functions, where the nodes with smaller indices become increasingly more sensitive during training. As a result, the features learned by the nodes are sorted by the node indices in order of their importance such that more sensitive nodes are related to more important features. The proposed networks learn input features but also the importance of the features. Nodes with lower importance in the proposed networks can be pruned to reduce the complexity of the networks, and the pruned networks can be retrained without incurring performance losses. We validated the feature-sorting property of the proposed method using both shallow and deep networks as well as deep networks transferred from existing networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300812",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Engineering",
      "Epistemology",
      "Feature (linguistics)",
      "Linguistics",
      "Node (physics)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Property (philosophy)",
      "Set (abstract data type)",
      "Sorting",
      "Structural engineering"
    ],
    "authors": [
      {
        "surname": "Jang",
        "given_name": "Jinhyeok"
      },
      {
        "surname": "Cho",
        "given_name": "Hyunjoong"
      },
      {
        "surname": "Kim",
        "given_name": "Jaehong"
      },
      {
        "surname": "Lee",
        "given_name": "Jaeyeon"
      },
      {
        "surname": "Yang",
        "given_name": "Seungjoon"
      }
    ]
  },
  {
    "title": "Learning in the machine: To share or not to share?",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.016",
    "abstract": "Weight-sharing is one of the pillars behind Convolutional Neural Networks and their successes. However, in physical neural systems such as the brain, weight-sharing is implausible. This discrepancy raises the fundamental question of whether weight-sharing is necessary. If so, to which degree of precision? If not, what are the alternatives? The goal of this study is to investigate these questions, primarily through simulations where the weight-sharing assumption is relaxed. Taking inspiration from neural circuitry, we explore the use of Free Convolutional Networks and neurons with variable connection patterns. Using Free Convolutional Networks, we show that while weight-sharing is a pragmatic optimization approach, it is not a necessity in computer vision applications. Furthermore, Free Convolutional Networks match the performance observed in standard architectures when trained using properly translated data (akin to video). Under the assumption of translationally augmented data, Free Convolutional Networks learn translationally invariant representations that yield an approximate form of weight-sharing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300939",
    "keywords": [
      "Alternative medicine",
      "Artificial intelligence",
      "Computer science",
      "Connection (principal bundle)",
      "Convolutional neural network",
      "Data sharing",
      "Geometry",
      "Invariant (physics)",
      "Machine learning",
      "Materials science",
      "Mathematical analysis",
      "Mathematical physics",
      "Mathematics",
      "Medicine",
      "Metallurgy",
      "Pathology",
      "Theoretical computer science",
      "Variable (mathematics)",
      "Yield (engineering)"
    ],
    "authors": [
      {
        "surname": "Ott",
        "given_name": "Jordan"
      },
      {
        "surname": "Linstead",
        "given_name": "Erik"
      },
      {
        "surname": "LaHaye",
        "given_name": "Nicholas"
      },
      {
        "surname": "Baldi",
        "given_name": "Pierre"
      }
    ]
  },
  {
    "title": "Exponential synchronization of memristive neural networks with time-varying delays via quantized sliding-mode control",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.014",
    "abstract": "In the paper, exponential synchronization issue is considered for memristive neural networks (MNNs) with time-varying delays via quantized sliding-mode algorithm. Quantized Sliding-mode controller is introduced to ensure the slave system can be exponentially synchronized with the host system via the super-twisting algorithm, which has been proved in the main results. Quantization function consists of uniform quantizer and logarithmic quantizer. Simulation results are given with comparisons between two quantizers in the end.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300915",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Exponential function",
      "Exponential growth",
      "Logarithm",
      "Mathematical analysis",
      "Mathematics",
      "Mode (computer interface)",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Quantization (signal processing)",
      "Quantum mechanics",
      "Sliding mode control",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Bo"
      },
      {
        "surname": "Wang",
        "given_name": "Shengbo"
      },
      {
        "surname": "Cao",
        "given_name": "Yuting"
      },
      {
        "surname": "Guo",
        "given_name": "Zhenyuan"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Automata complete computation with Hodgkin–Huxley neural networks composed of synfire rings",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.019",
    "abstract": "Synfire rings are neural circuits capable of conveying synchronous, temporally precise and self-sustained activities in a robust manner. We propose a cell assembly based paradigm for abstract neural computation centered on the concept of synfire rings. More precisely, we empirically show that Hodgkin–Huxley neural networks modularly composed of synfire rings are automata complete. We provide an algorithmic construction which, starting from any given finite state automaton, builds a corresponding Hodgkin–Huxley neural network modularly composed of synfire rings and capable of simulating it. We illustrate the correctness of the construction on two specific examples. We further analyze the stability and robustness of the construction as a function of changes in the ring topologies as well as with respect to cell death and synaptic failure mechanisms, respectively. These results establish the possibility of achieving abstract computation with bio-inspired neural networks. They might constitute a theoretical ground for the realization of biological neural computers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300964",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Automaton",
      "Biochemistry",
      "Biological neural network",
      "Cellular automaton",
      "Chemistry",
      "Combinatorics",
      "Computation",
      "Computer science",
      "Correctness",
      "Gene",
      "Machine learning",
      "Mathematics",
      "Models of neural computation",
      "Realization (probability)",
      "Robustness (evolution)",
      "Statistics",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Cabessa",
        "given_name": "Jérémie"
      },
      {
        "surname": "Tchaptchet",
        "given_name": "Aubin"
      }
    ]
  },
  {
    "title": "SDARE: A stacked denoising autoencoder method for game dynamics network structure reconstruction",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.008",
    "abstract": "Complex network is a general model to represent the interactions within technological, social, information, and biological interaction. Often, the direct detection of the interaction relationship is costly. Thus, network structure reconstruction, the inverse problem in complex networked systems, is of utmost importance for understanding many complex systems with unknown interaction structures. In addition, the data collected from real network system is often contaminated by noise, which makes the network structure inference task much more challenging. In this paper, we develop a new framework for the game dynamics network structure reconstruction based on deep learning method. In contrast to the compressive sensing methods that employ computationally complex convex/greedy algorithms to solve the network reconstruction task, we introduce a deep learning framework that can learn a structured representation from nodes data and efficiently reconstruct the game dynamics network structure with few observation data. Specifically, we propose the denoising autoencoders (DAEs) as the unsupervised feature learner to capture statistical dependencies between different nodes. Compared to the compressive sensing based method, the proposed method is a global network structure inference method, which can not only get the state-of-art performance, but also obtain the structure of network directly. Besides, the proposed method is robust to noise in the observation data. Moreover, the proposed method is also effective for the network which is not exactly sparse. Accordingly, the proposed method can extend to a wide scope of network reconstruction task in practice.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030085X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Complex network",
      "Compressed sensing",
      "Computer science",
      "Image (mathematics)",
      "Inference",
      "Law",
      "Machine learning",
      "Noise (video)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Keke"
      },
      {
        "surname": "Li",
        "given_name": "Shuo"
      },
      {
        "surname": "Dai",
        "given_name": "Penglin"
      },
      {
        "surname": "Wang",
        "given_name": "Zhen"
      },
      {
        "surname": "Yu",
        "given_name": "Zhaofei"
      }
    ]
  },
  {
    "title": "Multi-way backpropagation for training compact deep neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.001",
    "abstract": "Depth is one of the key factors behind the success of convolutional neural networks (CNNs). Since ResNet (He et al., 2016), we are able to train very deep CNNs as the gradient vanishing issue has been largely addressed by the introduction of skip connections. However, we observe that, when the depth is very large, the intermediate layers (especially shallow layers) may fail to receive sufficient supervision from the loss due to severe transformation through long backpropagation path. As a result, the representation power of intermediate layers can be very weak and the model becomes very redundant with limited performance. In this paper, we first investigate the supervision vanishing issue in existing backpropagation (BP) methods. And then, we propose to address it via an effective method, called Multi-way BP (MW-BP), which relies on multiple auxiliary losses added to the intermediate layers of the network. The proposed MW-BP method can be applied to most deep architectures with slight modifications, such as ResNet and MobileNet. Our method often gives rise to much more compact models (denoted by “Mw+Architecture”) than existing methods. For example, MwResNet-44 with 44 layers performs better than ResNet-110 with 110 layers on CIFAR-10 and CIFAR-100. More critically, the resultant models even outperform the light models obtained by state-of-the-art model compression methods. Last, our method inherently produces multiple compact models with different depths at the same time, which is helpful for model selection. Extensive experiments on both image classification and face recognition demonstrate the superiority of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300782",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Biochemistry",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Gene",
      "Law",
      "Meteorology",
      "Network architecture",
      "Path (computing)",
      "Pattern recognition (psychology)",
      "Physics",
      "Political science",
      "Politics",
      "Power (physics)",
      "Quantum mechanics",
      "Representation (politics)",
      "Residual neural network",
      "Training (meteorology)",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Yong"
      },
      {
        "surname": "Chen",
        "given_name": "Jian"
      },
      {
        "surname": "Du",
        "given_name": "Qing"
      },
      {
        "surname": "Van Den Hengel",
        "given_name": "Anton"
      },
      {
        "surname": "Shi",
        "given_name": "Qinfeng"
      },
      {
        "surname": "Tan",
        "given_name": "Mingkui"
      }
    ]
  },
  {
    "title": "Learning visual features under motion invariance",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.013",
    "abstract": "Humans are continuously exposed to a stream of visual data with a natural temporal structure. However, most successful computer vision algorithms work at image level, completely discarding the precious information carried by motion. In this paper, we claim that processing visual streams naturally leads to formulate the motion invariance principle, which enables the construction of a new theory of learning that originates from variational principles, just like in physics. Such principled approach is well suited for a discussion on a number of interesting questions that arise in vision, and it offers a well-posed computational scheme for the discovery of convolutional filters over the retina. Differently from traditional convolutional networks, which need massive supervision, the proposed theory offers a truly new scenario for the unsupervised processing of video signals, where features are extracted in a multi-layer architecture with motion invariance. While the theory enables the implementation of novel computer vision systems, it also sheds light on the role of information-based principles to drive possible biological solutions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300903",
    "keywords": [],
    "authors": [
      {
        "surname": "Betti",
        "given_name": "Alessandro"
      },
      {
        "surname": "Gori",
        "given_name": "Marco"
      },
      {
        "surname": "Melacci",
        "given_name": "Stefano"
      }
    ]
  },
  {
    "title": "Global exponential stabilization and lag synchronization control of inertial neural networks with time delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.006",
    "abstract": "The global exponential stabilization and lag synchronization control of delayed inertial neural networks (INNs) are investigated. By constructing nonnegative function and employing inequality techniques, several new results about exponential stabilization and exponential lag synchronization are derived via adaptive control. And the theoretical outcomes are developed directly from the INNs themselves without variable substitution. In addition, the synchronization results are also applied to image encryption and decryption. Finally, an example is presented to illustrate the validity of the derived results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300836",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Encryption",
      "Exponential function",
      "Exponential growth",
      "Inertial frame of reference",
      "Lag",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Shi",
        "given_name": "Jichen"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "Chimera states in hybrid coupled neuron populations",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.002",
    "abstract": "Here we study the emergence of chimera states, a recently reported phenomenon referring to the coexistence of synchronized and unsynchronized dynamical units, in a population of Morris–Lecar neurons which are coupled by both electrical and chemical synapses, constituting a hybrid synaptic architecture, as in actual brain connectivity. This scheme consists of a nonlocal network where the nearest neighbor neurons are coupled by electrical synapses, while the synapses from more distant neurons are of the chemical type. We demonstrate that peculiar dynamical behaviors, including chimera state and traveling wave, exist in such a hybrid coupled neural system, and analyze how the relative abundance of chemical and electrical synapses affects the features of chimera and different synchrony states (i.e. incoherent, traveling wave and coherent) and the regions in the space of relevant parameters for their emergence. Additionally, we show that, when the relative population of chemical synapses increases further, a new intriguing chaotic dynamical behavior appears above the region for chimera states. This is characterized by the coexistence of two distinct synchronized states with different amplitude, and an unsynchronized state, that we denote as a chaotic amplitude chimera. We also discuss about the computational implications of such state.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300794",
    "keywords": [
      "Amplitude",
      "Artificial intelligence",
      "Biochemistry",
      "Biological system",
      "Biology",
      "Cell biology",
      "Chaotic",
      "Chimera (genetics)",
      "Combinatorics",
      "Computer science",
      "Demography",
      "Electrical Synapses",
      "Gap junction",
      "Gene",
      "Intracellular",
      "Mathematical analysis",
      "Mathematics",
      "Neural system",
      "Neuroscience",
      "Physics",
      "Population",
      "Quantum mechanics",
      "Sociology",
      "Statistical physics",
      "Topology (electrical circuits)",
      "Traveling wave"
    ],
    "authors": [
      {
        "surname": "Calim",
        "given_name": "Ali"
      },
      {
        "surname": "Torres",
        "given_name": "Joaquin J."
      },
      {
        "surname": "Ozer",
        "given_name": "Mahmut"
      },
      {
        "surname": "Uzuntarla",
        "given_name": "Muhammet"
      }
    ]
  },
  {
    "title": "Backpropagation algorithms and Reservoir Computing in Recurrent Neural Networks for the forecasting of complex spatiotemporal dynamics",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.016",
    "abstract": "We examine the efficiency of Recurrent Neural Networks in forecasting the spatiotemporal dynamics of high dimensional and reduced order complex systems using Reservoir Computing (RC) and Backpropagation through time (BPTT) for gated network architectures. We highlight advantages and limitations of each method and discuss their implementation for parallel computing architectures. We quantify the relative prediction accuracy of these algorithms for the long-term forecasting of chaotic systems using as benchmarks the Lorenz-96 and the Kuramoto–Sivashinsky (KS) equations. We find that, when the full state dynamics are available for training, RC outperforms BPTT approaches in terms of predictive performance and in capturing of the long-term statistics, while at the same time requiring much less training time. However, in the case of reduced order data, large scale RC models can be unstable and more likely than the BPTT algorithms to diverge. In contrast, RNNs trained via BPTT show superior forecasting abilities and capture well the dynamics of reduced order systems. Furthermore, the present study quantifies for the first time the Lyapunov Spectrum of the KS equation with BPTT, achieving similar accuracy as RC. This study establishes that RNNs are a potent computational framework for the learning and forecasting of complex spatiotemporal systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300708",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Chaotic",
      "Computer science",
      "Lorenz system",
      "Lyapunov exponent",
      "Machine learning",
      "Recurrent neural network",
      "Reservoir computing"
    ],
    "authors": [
      {
        "surname": "Vlachas",
        "given_name": "P.R."
      },
      {
        "surname": "Pathak",
        "given_name": "J."
      },
      {
        "surname": "Hunt",
        "given_name": "B.R."
      },
      {
        "surname": "Sapsis",
        "given_name": "T.P."
      },
      {
        "surname": "Girvan",
        "given_name": "M."
      },
      {
        "surname": "Ott",
        "given_name": "E."
      },
      {
        "surname": "Koumoutsakos",
        "given_name": "P."
      }
    ]
  },
  {
    "title": "Multi-view projected clustering with graph learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.020",
    "abstract": "Graph based multi-view learning is well known due to its effectiveness and good clustering performance. However, most existing methods directly construct graph from original high-dimensional data which always contain redundancy, noise and outlying entries in real applications, resulting in unreliable and inaccurate graph. Moreover, they do not effectively select some useful features which are important for graph learning and clustering. To solve these limits, we propose a novel model that combines dimensionality reduction, manifold structure learning and feature selection into a framework. We map high-dimensional data into low-dimensional space to reduce the complexity of the algorithm and reduce the effect of noise and redundance. Therefore, we can adaptively learn a more accurate graph. Further more, ℓ 21 -norm regularization is adopted to adaptively select some important features which help improve clustering performance. Finally, an efficiently algorithm is proposed to solve the optimal solution. Extensive experimental results on some benchmark datasets demonstrate the superiority of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300976",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Clustering high-dimensional data",
      "Computer science",
      "Data mining",
      "Dimensionality reduction",
      "Graph",
      "Pattern recognition (psychology)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Wan",
        "given_name": "Zhizhen"
      },
      {
        "surname": "Liang",
        "given_name": "Ying"
      },
      {
        "surname": "Wang",
        "given_name": "Qianqian"
      },
      {
        "surname": "Liu",
        "given_name": "Yang"
      },
      {
        "surname": "Shao",
        "given_name": "Ling"
      }
    ]
  },
  {
    "title": "Hyperlink regression via Bregman divergence",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.026",
    "abstract": "A collection of U ( ∈ N ) data vectors is called a U -tuple, and the association strength among the vectors of a tuple is termed as the hyperlink weight, that is assumed to be symmetric with respect to permutation of the entries in the index. We herein propose Bregman hyperlink regression (BHLR), which learns a user-specified symmetric similarity function such that it predicts the tuple’s hyperlink weight from data vectors stored in the U -tuple. BHLR is a simple and general framework for hyper-relational learning, that minimizes Bregman-divergence (BD) between the hyperlink weights and estimated similarities defined for the corresponding tuples; BHLR encompasses various existing methods, such as logistic regression ( U = 1 ), Poisson regression ( U = 1 ), link prediction ( U = 2 ), and those for representation learning, such as graph embedding ( U = 2 ), matrix factorization ( U = 2 ), tensor factorization ( U ≥ 2 ), and their variants equipped with arbitrary BD. Nonlinear functions (e.g., neural networks), can be employed for the similarity functions. However, there are theoretical challenges such that some of different tuples of BHLR may share data vectors therein, unlike the i.i.d. setting of classical regression. We address these theoretical issues, and proved that BHLR equipped with arbitrary BD and U ∈ N is (P-1) statistically consistent, that is, it asymptotically recovers the underlying true conditional expectation of hyperlink weights given data vectors, and (P-2) computationally tractable, that is, it is efficiently computed by stochastic optimization algorithms using a novel generalized minibatch sampling procedure for hyper-relational data. Consequently, theoretical guarantees for BHLR including several existing methods, that have been examined experimentally, are provided in a unified manner.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020301209",
    "keywords": [
      "Artificial intelligence",
      "Bregman divergence",
      "Computer science",
      "Discrete mathematics",
      "Hyperlink",
      "Image (mathematics)",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Similarity (geometry)",
      "Statistics",
      "Tuple",
      "Web page",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Okuno",
        "given_name": "Akifumi"
      },
      {
        "surname": "Shimodaira",
        "given_name": "Hidetoshi"
      }
    ]
  },
  {
    "title": "New optimization algorithms for neural network training using operator splitting techniques",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.018",
    "abstract": "In the following paper we present a new type of optimization algorithms adapted for neural network training. These algorithms are based upon sequential operator splitting technique for some associated dynamical systems. Furthermore, we investigate through numerical simulations the empirical rate of convergence of these iterative schemes toward a local minimum of the loss function, with some suitable choices of the underlying hyper-parameters. We validate the convergence of these optimizers using the results of the accuracy and of the loss function on the MNIST, MNIST-Fashion and CIFAR 10 classification datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300952",
    "keywords": [],
    "authors": [
      {
        "surname": "Alecsa",
        "given_name": "Cristian Daniel"
      },
      {
        "surname": "Pinţa",
        "given_name": "Titus"
      },
      {
        "surname": "Boros",
        "given_name": "Imre"
      }
    ]
  },
  {
    "title": "Probabilistic inference of binary Markov random fields in spiking neural networks through mean-field approximation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.003",
    "abstract": "Recent studies have suggested that the cognitive process of the human brain is realized as probabilistic inference and can be further modeled by probabilistic graphical models like Markov random fields. Nevertheless, it remains unclear how probabilistic inference can be implemented by a network of spiking neurons in the brain. Previous studies have tried to relate the inference equation of binary Markov random fields to the dynamic equation of spiking neural networks through belief propagation algorithm and reparameterization, but they are valid only for Markov random fields with limited network structure. In this paper, we propose a spiking neural network model that can implement inference of arbitrary binary Markov random fields. Specifically, we design a spiking recurrent neural network and prove that its neuronal dynamics are mathematically equivalent to the inference process of Markov random fields by adopting mean-field theory. Furthermore, our mean-field approach unifies previous works. Theoretical analysis and experimental results, together with the application to image denoising, demonstrate that our proposed spiking neural network can get comparable results to that of mean-field inference.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300800",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Belief propagation",
      "Computer science",
      "Decoding methods",
      "Graphical model",
      "Image (mathematics)",
      "Image segmentation",
      "Inference",
      "Machine learning",
      "Markov chain",
      "Markov model",
      "Markov process",
      "Markov random field",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Probabilistic logic",
      "Random field",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Zheng",
        "given_name": "Yajing"
      },
      {
        "surname": "Jia",
        "given_name": "Shanshan"
      },
      {
        "surname": "Yu",
        "given_name": "Zhaofei"
      },
      {
        "surname": "Huang",
        "given_name": "Tiejun"
      },
      {
        "surname": "Liu",
        "given_name": "Jian K."
      },
      {
        "surname": "Tian",
        "given_name": "Yonghong"
      }
    ]
  },
  {
    "title": "Finite-time synchronization of fractional-order gene regulatory networks with time delay",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.004",
    "abstract": "As multi-gene networks transmit signals and products by synchronous cooperation, investigating the synchronization of gene regulatory networks may help us to explore the biological rhythm and internal mechanisms at molecular and cellular levels. We aim to induce a type of fractional-order gene regulatory networks to synchronize at finite-time point by designing feedback controls. Firstly, a unique equilibrium point of the network is proved by applying the principle of contraction mapping. Secondly, some sufficient conditions for finite-time synchronization of fractional-order gene regulatory networks with time delay are explored based on two kinds of different control techniques and fractional Lyapunov function approach, and the corresponding setting time is estimated. Finally, some numerical examples are given to demonstrate the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300496",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differential equation",
      "Equilibrium point",
      "Function (biology)",
      "Gene",
      "Gene expression",
      "Gene regulatory network",
      "Genetics",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Qiao",
        "given_name": "Yuanhua"
      },
      {
        "surname": "Yan",
        "given_name": "Hongyun"
      },
      {
        "surname": "Duan",
        "given_name": "Lijuan"
      },
      {
        "surname": "Miao",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Crowding in humans is unlike that in convolutional neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.03.021",
    "abstract": "Object recognition is a primary function of the human visual system. It has recently been claimed that the highly successful ability to recognise objects in a set of emergent computer vision systems—Deep Convolutional Neural Networks (DCNNs)—can form a useful guide to recognition in humans. To test this assertion, we systematically evaluated visual crowding, a dramatic breakdown of recognition in clutter, in DCNNs and compared their performance to extant research in humans. We examined crowding in three architectures of DCNNs with the same methodology as that used among humans. We manipulated multiple stimulus factors including inter-letter spacing, letter colour, size, and flanker location to assess the extent and shape of crowding in DCNNs. We found that crowding followed a predictable pattern across architectures that was different from that in humans. Some characteristic hallmarks of human crowding, such as invariance to size, the effect of target-flanker similarity, and confusions between target and flanker identities, were completely missing, minimised or even reversed. These data show that DCNNs, while proficient in object recognition, likely achieve this competence through a set of mechanisms that are distinct from those in humans. They are not necessarily equivalent models of human or primate object recognition and caution must be exercised when inferring mechanisms derived from their operation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300988",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Convolutional neural network",
      "Crowding",
      "Machine learning",
      "Neuroscience",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Lonnqvist",
        "given_name": "Ben"
      },
      {
        "surname": "Clarke",
        "given_name": "Alasdair D.F."
      },
      {
        "surname": "Chakravarthi",
        "given_name": "Ramakrishna"
      }
    ]
  },
  {
    "title": "Modeling coherence by ordering paragraphs using pointer networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.022",
    "abstract": "Coherence is a distinctive feature in well-written documents. One method to study coherence is to analyze how sentences are ordered in a document. In Multi-document Summarization, sentences from different sources need to be ordered. Cluster-based ordering algorithms aim to study various themes or topics that are present in a set of sentences. After the clusters of sentences have been identified, sentences are ordered within each cluster in isolation. One challenge that remains is to order these clusters or paragraphs to obtain a coherent ordering of information. Inspired by the success of deep neural networks in several NLP tasks, we propose an RNN-based encoder–decoder system to predict order for a given set of loose clusters or paragraphs. Universal Sentence Encoder (USE) is used to encode paragraphs into high dimensional embeddings, which are then fed into an LSTM encoder and consecutively passed to a pointer network, which finally outputs the paragraph order. Since Wikipedia is a source of well- structured articles, it is used to generate multiple datasets. Based on our experimental results, the proposed model satisfactorily outperforms the baseline model across multiple datasets. We observe a two-fold increase in Kendall’s tau values for the final paragraph orderings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300769",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Automatic summarization",
      "Biochemistry",
      "Chemistry",
      "Coherence (philosophical gambling strategy)",
      "Computer science",
      "ENCODE",
      "Encoder",
      "Gene",
      "Mathematics",
      "Natural language processing",
      "Operating system",
      "Paragraph",
      "Pattern recognition (psychology)",
      "Pointer (user interface)",
      "Programming language",
      "Sentence",
      "Set (abstract data type)",
      "Statistics",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Pandey",
        "given_name": "Divesh"
      },
      {
        "surname": "Chowdary",
        "given_name": "C. Ravindranath"
      }
    ]
  },
  {
    "title": "NFN＋: A novel network followed network for retinal vessel segmentation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.018",
    "abstract": "In the early diagnosis of diabetic retinopathy, the morphological attributes of blood vessels play an essential role to construct a retinal computer-aided diagnosis system. However, due to the challenges including limited densely annotated data, inter-vessel differences and structured prediction problem, it remains challenging to segment accurately the retinal vessels, particularly the capillaries on color fundus images. To address these issues, in this paper, we propose a novel deep learning-based model called NFN＋ to effectively extract multi-scale information and make full use of deep feature maps. In NFN＋, the front network converts an image patch into a probabilistic retinal vessel map, and the followed network further refines the map to achieve a better post-processing module, which helps represent the vessel structures implicitly. We employ the inter-network skip connections to unite two identical multi-scale backbones, which enables the useful multi-scale features to be directly transferred from shallow layers to deeper layers. The refined probabilistic retinal vessel maps produced from the augmented images are then averaged to construct the segmentation results. We evaluated this model on the digital retinal images for vessel extraction (DRIVE), structured analysis of the retina (STARE), and the child heart and health study (CHASE) databases. Our results indicate that the elaborated cascaded designs can produce performance gain and the proposed NFN＋ model, to our best knowledge, achieved the state-of-the-art retinal vessel segmentation accuracy on color fundus images (AUC: 98.30%, 98.75% and 98.94%, respectively).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300721",
    "keywords": [
      "Anatomy",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Medicine",
      "Ophthalmology",
      "Retinal",
      "Segmentation",
      "Vascular network"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Yicheng"
      },
      {
        "surname": "Xia",
        "given_name": "Yong"
      },
      {
        "surname": "Song",
        "given_name": "Yang"
      },
      {
        "surname": "Zhang",
        "given_name": "Yanning"
      },
      {
        "surname": "Cai",
        "given_name": "Weidong"
      }
    ]
  },
  {
    "title": "Reachable set bounding for neural networks with mixed delays: Reciprocally convex approach",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.005",
    "abstract": "This paper discusses the reachable set estimation problem of neural networks with mixed delays. Firstly, by means of the maximal Lyapunov–Krasovskii functional, we obtain a non-ellipsoid form of the reachable set. Further more, when calculating the derivative of the maximum Lyapunov functional, the lower bound lemma and reciprocally convex approach method are used to solve the reciprocally convex combination term, which reduce the related decision variables. Secondly, we extend the results to polytopic uncertainties neural networks and consider the case of uncertain differentiable parameters. Finally, two numerical examples and one application example are listed to show the validity of our methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300502",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Biology",
      "Bounding overwatch",
      "Computer science",
      "Convex combination",
      "Convex optimization",
      "Convex set",
      "Differentiable function",
      "Ecology",
      "Ellipsoid",
      "Geometry",
      "Lemma (botany)",
      "Mathematical optimization",
      "Mathematics",
      "Physics",
      "Poaceae",
      "Programming language",
      "Pure mathematics",
      "Regular polygon",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Ruihan"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      },
      {
        "surname": "Qi",
        "given_name": "Yongqiang"
      },
      {
        "surname": "Hou",
        "given_name": "Yuxin"
      }
    ]
  },
  {
    "title": "Skeleton-based Chinese sign language recognition and generation for bidirectional communication between deaf and hearing people",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.030",
    "abstract": "Chinese sign language (CSL) is one of the most widely used sign language systems in the world. As such, the automatic recognition and generation of CSL is a key technology enabling bidirectional communication between deaf and hearing people. Most previous studies have focused solely on sign language recognition (SLR), which only addresses communication in a single direction. As such, there is a need for sign language generation (SLG) to enable communication in the other direction (i.e., from hearing people to deaf people). To achieve a smoother exchange of ideas between these two groups, we propose a skeleton-based CSL recognition and generation framework based on a recurrent neural network (RNN), to support bidirectional CSL communication. This process can also be extended to other sequence-to-sequence information interactions. The core of the proposed framework is a two-level probability generative model. Compared with previous techniques, this approach offers a more flexible approximate posterior distribution, which can produce skeletal sequences of varying styles that are recognizable to humans. In addition, the proposed generation method compensated for a lack of training data. A series of experiments in bidirectional communication were conducted on the large 500 CSL dataset. The proposed algorithm achieved high recognition accuracy for both real and synthetic data, with a reduced runtime. Furthermore, the generated data improved the performance of the discriminator. These results suggest the proposed bidirectional communication framework and generation algorithm to be an effective new approach to CSL recognition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030040X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Detector",
      "Discriminator",
      "Key (lock)",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Philosophy",
      "Process (computing)",
      "Sign (mathematics)",
      "Sign language",
      "Speech recognition",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Qinkun"
      },
      {
        "surname": "Qin",
        "given_name": "Minying"
      },
      {
        "surname": "Yin",
        "given_name": "Yuting"
      }
    ]
  },
  {
    "title": "Resilient fault-tolerant anti-synchronization for stochastic delayed reaction–diffusion neural networks with semi-Markov jump parameters",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.015",
    "abstract": "This paper deals with the anti-synchronization issue for stochastic delayed reaction–diffusion neural networks subject to semi-Markov jump parameters. A resilient fault-tolerant controller is utilized to ensure the anti-synchronization in the presence of actuator failures as well as gain perturbations, simultaneously. Firstly, by means of the Lyapunov functional and stochastic analysis methods, a mean-square exponential stability criterion is derived for the resulting error system. It is shown the obtained criterion improves a previously reported result. Then, based on the present analysis result and using several decoupling techniques, a strategy for designing the desired resilient fault-tolerant controller is proposed. At last, two numerical examples are given to illustrate the superiority of the present stability analysis method and the applicability of the proposed resilient fault-tolerant anti-synchronization control strategy, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300691",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Decoupling (probability)",
      "Distributed computing",
      "Engineering",
      "Fault tolerance",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Jianping"
      },
      {
        "surname": "Liu",
        "given_name": "Yamin"
      },
      {
        "surname": "Xia",
        "given_name": "Jianwei"
      },
      {
        "surname": "Wang",
        "given_name": "Zhen"
      },
      {
        "surname": "Arik",
        "given_name": "Sabri"
      }
    ]
  },
  {
    "title": "Transductive LSTM for time-series prediction: An application to weather forecasting",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.030",
    "abstract": "Long Short-Term Memory (LSTM) has shown significant performance on many real-world applications due to its ability to capture long-term dependencies. In this paper, we utilize LSTM to obtain a data-driven forecasting model for an application of weather forecasting. Moreover, we propose Transductive LSTM (T-LSTM) which exploits the local information in time-series prediction. In transductive learning, the samples in the test point vicinity are considered to have higher impact on fitting the model. In this study, a quadratic cost function is considered for the regression problem. Localizing the objective function is done by considering a weighted quadratic cost function at which point the samples in the neighborhood of the test point have larger weights. We investigate two weighting schemes based on the cosine similarity between the training samples and the test point. In order to assess the performance of the proposed method in different weather conditions, the experiments are conducted on two different time periods of a year. The results show that T-LSTM results in better performance in the prediction task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300010",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Cosine similarity",
      "Data mining",
      "Evolutionary biology",
      "Function (biology)",
      "Geometry",
      "Image (mathematics)",
      "Machine learning",
      "Mathematics",
      "Medicine",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Physics",
      "Quadratic equation",
      "Quantum mechanics",
      "Radiology",
      "Regression",
      "Series (stratigraphy)",
      "Similarity (geometry)",
      "Statistics",
      "Term (time)",
      "Time series",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Karevan",
        "given_name": "Zahra"
      },
      {
        "surname": "Suykens",
        "given_name": "Johan A.K."
      }
    ]
  },
  {
    "title": "Multiple Discrimination and Pairwise CNN for view-based 3D object retrieval",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.017",
    "abstract": "With the rapid development and wide application of computer, camera device, network and hardware technology, 3D object (or model) retrieval has attracted widespread attention and it has become a hot research topic in the computer vision domain. Deep learning features already available in 3D object retrieval have been proven to be better than the retrieval performance of hand-crafted features. However, most existing networks do not take into account the impact of multi-view image selection on network training, and the use of contrastive loss alone only forcing the same-class samples to be as close as possible. In this work, a novel solution named Multi-view Discrimination and Pairwise CNN (MDPCNN) for 3D object retrieval is proposed to tackle these issues. It can simultaneously input multiple batches and multiple views by adding the Slice layer and the Concat layer. Furthermore, a highly discriminative network is obtained by training samples that are not easy to be classified by clustering. Lastly, we deploy the contrastive-center loss and contrastive loss as the optimization objective that has better intra-class compactness and inter-class separability. Large-scale experiments show that the proposed MDPCNN can achieve a significant performance over the state-of-the-art algorithms in 3D object retrieval.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030071X",
    "keywords": [
      "Artificial intelligence",
      "Class (philosophy)",
      "Cluster analysis",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Discriminative model",
      "Image (mathematics)",
      "Image retrieval",
      "Object (grammar)",
      "Pairwise comparison",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Zan"
      },
      {
        "surname": "Xue",
        "given_name": "Haixin"
      },
      {
        "surname": "Wan",
        "given_name": "Shaohua"
      }
    ]
  },
  {
    "title": "End-to-end semantic segmentation of personalized deep brain structures for non-invasive brain stimulation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.006",
    "abstract": "Electro-stimulation or modulation of deep brain regions is commonly used in clinical procedures for the treatment of several nervous system disorders. In particular, transcranial direct current stimulation (tDCS) is widely used as an affordable clinical application that is applied through electrodes attached to the scalp. However, it is difficult to determine the amount and distribution of the electric field (EF) in the different brain regions due to anatomical complexity and high inter-subject variability. Personalized tDCS is an emerging clinical procedure that is used to tolerate electrode montage for accurate targeting. This procedure is guided by computational head models generated from anatomical images such as MRI. Distribution of the EF in segmented head models can be calculated through simulation studies. Therefore, fast, accurate, and feasible segmentation of different brain structures would lead to a better adjustment for customized tDCS studies. In this study, a single-encoder multi-decoders convolutional neural network is proposed for deep brain segmentation. The proposed architecture is trained to segment seven deep brain structures using T1-weighted MRI. Network generated models are compared with a reference model constructed using a semi-automatic method, and it presents a high matching especially in Thalamus (Dice Coefficient (DC) = 94.70%), Caudate (DC = 91.98%) and Putamen (DC = 90.31%) structures. Electric field distribution during tDCS in generated and reference models matched well each other, suggesting its potential usefulness in clinical practice.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300514",
    "keywords": [
      "Artificial intelligence",
      "Brain stimulation",
      "Computer science",
      "Convolutional neural network",
      "Deep brain stimulation",
      "Deep learning",
      "Disease",
      "Image segmentation",
      "Medicine",
      "Neuroscience",
      "Parkinson's disease",
      "Pathology",
      "Pattern recognition (psychology)",
      "Psychology",
      "Segmentation",
      "Stimulation",
      "Sørensen–Dice coefficient",
      "Transcranial direct-current stimulation"
    ],
    "authors": [
      {
        "surname": "Rashed",
        "given_name": "Essam A."
      },
      {
        "surname": "Gomez-Tames",
        "given_name": "Jose"
      },
      {
        "surname": "Hirata",
        "given_name": "Akimasa"
      }
    ]
  },
  {
    "title": "Robust min–max optimal control design for systems with uncertain models: A neural dynamic programming approach",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.016",
    "abstract": "The design of an artificial neural network (ANN) based sub-optimal controller to solve the finite-horizon optimization problem for a class of systems with uncertainties is the main outcome of this study. The optimization problem considers a convex performance index in the Bolza form. The dynamic uncertain restriction is considered as a linear system affected by modeling uncertainties, as well as by external bounded perturbations. The proposed controller implements a min–max approach based on the dynamic neural programming approximate solution. An ANN approximates the Value function to get the estimate of the Hamilton–Jacobi–Bellman (HJB) equation solution. The explicit adaptive law for the weights in the ANN is obtained from the approximation of the HJB solution. The stability analysis based on the Lyapunov theory yields to confirm that the approximate Value function serves as a Lyapunov function candidate and to conclude the practical stability of the equilibrium point. A simulation example illustrates the characteristics of the sub-optimal controller. The comparison of the performance indexes obtained with the application of different controllers evaluates the effect of perturbations and the sub-optimal solution.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300186",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Biology",
      "Bounded function",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Convex optimization",
      "Dynamic programming",
      "Geometry",
      "Hamilton–Jacobi–Bellman equation",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Optimal control",
      "Physics",
      "Quantum mechanics",
      "Regular polygon",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Ballesteros",
        "given_name": "Mariana"
      },
      {
        "surname": "Chairez",
        "given_name": "Isaac"
      },
      {
        "surname": "Poznyak",
        "given_name": "Alexander"
      }
    ]
  },
  {
    "title": "New criteria for global stability of neutral-type Cohen–Grossberg neural networks with multiple delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.020",
    "abstract": "The significant contribution of this paper is the addressing the stability issue of neutral-type Cohen–Grossberg neural networks possessing multiple time delays in the states of the neurons and multiple neutral delays in time derivative of states of the neurons. By making the use of a novel and enhanced Lyapunov functional, some new sufficient stability criteria are presented for this model of neutral-type neural systems. The obtained stability conditions are completely dependent of the parameters of the neural system and independent of time delays and neutral delays. A constructive numerical example is presented for the sake of proving the key advantages of the proposed stability results over the previously reported corresponding stability criteria for Cohen–Grossberg neural networks of neutral type. Since, stability analysis of Cohen–Grossberg neural networks involving multiple time delays and multiple neutral delays is a difficult problem to overcome, the investigations of the stability conditions of the neutral-type the stability analysis of this class of neural network models have not been given much attention. Therefore, the stability criteria derived in this work can be evaluated as a valuable contribution to the stability analysis of neutral-type Cohen–Grossberg neural systems involving multiple delays.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300745",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Constructive",
      "Control (management)",
      "Control theory (sociology)",
      "Ecology",
      "Machine learning",
      "Neutral network",
      "Operating system",
      "Process (computing)",
      "Stability (learning theory)",
      "Type (biology)"
    ],
    "authors": [
      {
        "surname": "Faydasicok",
        "given_name": "Ozlem"
      }
    ]
  },
  {
    "title": "CNN–MHSA: A Convolutional Neural Network and multi-head self-attention combined approach for detecting phishing websites",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.013",
    "abstract": "Increasing phishing sites today have posed great threats due to their terribly imperceptible hazard. They expect users to mistake them as legitimate ones so as to steal user information and properties without notice. The conventional way to mitigate such threats is to set up blacklists. However, it cannot detect one-time Uniform Resource Locators (URL) that have not appeared in the list. As an improvement, deep learning methods are applied to increase detection accuracy and reduce the misjudgment ratio. However, some of them only focus on the characters in URLs but ignore the relationships between characters, which results in that the detection accuracy still needs to be improved. Considering the multi-head self-attention (MHSA) can learn the inner structures of URLs, in this paper, we propose CNN–MHSA, a Convolutional Neural Network (CNN) and the MHSA combined approach for highly-precise. To achieve this goal, CNN–MHSA first takes a URL string as the input data and feeds it into a mature CNN model so as to extract its features. In the meanwhile, MHSA is applied to exploit characters’ relationships in the URL so as to calculate the corresponding weights for the CNN learned features. Finally, CNN–MHSA can produce highly-precise detection result for a URL object by integrating its features and their weights. The thorough experiments on a dataset collected in real environment demonstrate that our method achieves 99.84% accuracy, which outperforms the classical method CNN–LSTM and at least 6.25% higher than other similar methods on average.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300587",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Geology",
      "Geomorphology",
      "Head (geology)",
      "Machine learning",
      "Phishing",
      "The Internet",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Xi"
      },
      {
        "surname": "Zhang",
        "given_name": "Dianyan"
      },
      {
        "surname": "Hu",
        "given_name": "Guangwu"
      },
      {
        "surname": "Jiang",
        "given_name": "Yong"
      },
      {
        "surname": "Xia",
        "given_name": "Shutao"
      }
    ]
  },
  {
    "title": "Mu-net: Multi-scale U-net for two-photon microscopy image denoising and restoration",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.026",
    "abstract": "Advances in two two-photon microscopy (2PM) have made three-dimensional (3D) neural imaging of deep cortical regions possible. However, 2PM often suffers from poor image quality because of various noise factors, including blur, white noise, and photo bleaching. In addition, the effectiveness of the existing image processing methods is limited because of the special features of 2PM images such as deeper tissue penetration but higher image noises owing to rapid laser scanning. To address the denoising problems in 2PM 3D images, we present a new algorithm based on deep convolutional neural networks (CNNs). The proposed model consists of multiple U-nets in which an individual U-net removes noises at different scales and then yields a performance improvement based on a coarse-to-fine strategy. Moreover, the constituent CNNs employ fully 3D convolution operations. Such an architecture enables the proposed model to facilitate end-to-end learning without any pre/post processing. Based on the experiments on 2PM image denoising, we observed that our new algorithm demonstrates substantial performance improvements over other baseline methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300368",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Deep learning",
      "Image (mathematics)",
      "Image processing",
      "Image quality",
      "Image restoration",
      "Noise (video)",
      "Noise reduction",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Sehyung"
      },
      {
        "surname": "Negishi",
        "given_name": "Makiko"
      },
      {
        "surname": "Urakubo",
        "given_name": "Hidetoshi"
      },
      {
        "surname": "Kasai",
        "given_name": "Haruo"
      },
      {
        "surname": "Ishii",
        "given_name": "Shin"
      }
    ]
  },
  {
    "title": "On the localness modeling for the self-attention based end-to-end speech synthesis",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.034",
    "abstract": "Attention based end-to-end speech synthesis achieves better performance in both prosody and quality compared to the conventional “front-end”–“back-end” structure. But training such end-to-end framework is usually time-consuming because of the use of recurrent neural networks. To enable parallel calculation and long-range dependency modeling, a solely self-attention based framework named Transformer is proposed recently in the end-to-end family. However, it lacks position information in sequential modeling, so that the extra position representation is crucial to achieve good performance. Besides, the weighted sum form of self-attention is conducted over the whole input sequence when computing latent representation, which may disperse the attention to the whole input sequence other than focusing on the more important neighboring input states, resulting in generation errors. In this paper, we introduce two localness modeling methods to enhance the self-attention based representation for speech synthesis, which maintain the abilities of parallel computation and global-range dependency modeling in self-attention while improving the generation stability. We systematically analyze the solely self-attention based end-to-end speech synthesis framework, and unveil the importance of local context. Then we add the proposed relative-position-aware method to enhance local edges and experiment with different architectures to examine the effectiveness of localness modeling. In order to achieve query-specific window and discard the hyper-parameter of the relative-position-aware approach, we further conduct Gaussian-based bias to enhance localness. Experimental results indicate that the two proposed localness enhanced methods can both improve the performance of the self-attention model, especially when applied to the encoder part. And the query-specific window of Gaussian bias approach is more robust compared with the fixed relative edges.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300447",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "End-to-end principle",
      "Speech recognition",
      "Speech synthesis"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Shan"
      },
      {
        "surname": "Lu",
        "given_name": "Heng"
      },
      {
        "surname": "Kang",
        "given_name": "Shiyin"
      },
      {
        "surname": "Xue",
        "given_name": "Liumeng"
      },
      {
        "surname": "Xiao",
        "given_name": "Jinba"
      },
      {
        "surname": "Su",
        "given_name": "Dan"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      },
      {
        "surname": "Yu",
        "given_name": "Dong"
      }
    ]
  },
  {
    "title": "Improved multi-view GEPSVM via Inter-View Difference Maximization and Intra-view Agreement Minimization",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.002",
    "abstract": "Multiview Generalized Eigenvalue Proximal Support Vector Machine (MvGEPSVM) is an effective method for multiview data classification proposed recently. However, it ignores discriminations between different views and the agreement of the same view. Moreover, there is no robustness guarantee. In this paper, we propose an improved multiview GEPSVM (IMvGEPSVM) method, which adds a multi-view regularization that can connect different views of the same class and simultaneously considers the maximization of the samples from different classes in heterogeneous views for promoting discriminations. This makes the classification more effective. In addition, L1-norm rather than squared L2-norm is employed to calculate the distances from each of the sample points to the hyperplane so as to reduce the effect of outliers in the proposed model. To solve the resulting objective, an efficient iterative algorithm is presented. Theoretically, we conduct the proof of the algorithm’s convergence. Experimental results show the effectiveness of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300472",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Eigenvalues and eigenvectors",
      "Gene",
      "Geometry",
      "Hyperplane",
      "Law",
      "Mathematical optimization",
      "Mathematics",
      "Maximization",
      "Minification",
      "Norm (philosophy)",
      "Outlier",
      "Physics",
      "Political science",
      "Quantum mechanics",
      "Regularization (linguistics)",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Cheng",
        "given_name": "Yawen"
      },
      {
        "surname": "Yin",
        "given_name": "Hang"
      },
      {
        "surname": "Ye",
        "given_name": "Qiaolin"
      },
      {
        "surname": "Huang",
        "given_name": "Peng"
      },
      {
        "surname": "Fu",
        "given_name": "Liyong"
      },
      {
        "surname": "Yang",
        "given_name": "Zhangjing"
      },
      {
        "surname": "Tian",
        "given_name": "Yuan"
      }
    ]
  },
  {
    "title": "Preserving differential privacy in deep neural networks with relevance-based adaptive noise imposition",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.001",
    "abstract": "In recent years, deep learning achieves remarkable results in the field of artificial intelligence. However, the training process of deep neural networks may cause the leakage of individual privacy. Given the model and some background information of the target individual, the adversary can maliciously infer the sensitive feature of the target individual. Therefore, it is imperative to preserve the sensitive information in the training data. Differential privacy is a state-of-the-art paradigm for providing the privacy guarantee of datasets, which protects the private and sensitive information from the attack of adversaries significantly. However, the existing privacy-preserving models based on differential privacy are less than satisfactory since traditional approaches always inject the same amount of noise into parameters to preserve the sensitive information, which may impact the trade-off between the model utility and the privacy guarantee of training data. In this paper, we present a general differentially private deep neural networks learning framework based on relevance analysis, which aims to bridge the gap between private and non-private models while providing an effective privacy guarantee of sensitive information. The proposed model perturbs gradients according to the relevance between neurons in different layers and the model output. Specifically, during the process of backward propagation, more noise is added to gradients of neurons that have less relevance to the model output, and vice-versa. Experiments on five real datasets demonstrate that our mechanism not only bridges the gap between private and non-private models, but also prevents the disclosure of sensitive information effectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300460",
    "keywords": [
      "Adversary",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Data mining",
      "Deep learning",
      "Differential privacy",
      "Image (mathematics)",
      "Information leakage",
      "Information privacy",
      "Information sensitivity",
      "Law",
      "Machine learning",
      "Noise (video)",
      "Operating system",
      "Political science",
      "Private information retrieval",
      "Process (computing)",
      "Relevance (law)"
    ],
    "authors": [
      {
        "surname": "Gong",
        "given_name": "Maoguo"
      },
      {
        "surname": "Pan",
        "given_name": "Ke"
      },
      {
        "surname": "Xie",
        "given_name": "Yu"
      },
      {
        "surname": "Qin",
        "given_name": "A.K."
      },
      {
        "surname": "Tang",
        "given_name": "Zedong"
      }
    ]
  },
  {
    "title": "Reconstruction of natural visual scenes from neural spikes with deep neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.033",
    "abstract": "Neural coding is one of the central questions in systems neuroscience for understanding how the brain processes stimulus from the environment, moreover, it is also a cornerstone for designing algorithms of brain–machine interface, where decoding incoming stimulus is highly demanded for better performance of physical devices. Traditionally researchers have focused on functional magnetic resonance imaging (fMRI) data as the neural signals of interest for decoding visual scenes. However, our visual perception operates in a fast time scale of millisecond in terms of an event termed neural spike. There are few studies of decoding by using spikes. Here we fulfill this aim by developing a novel decoding framework based on deep neural networks, named spike-image decoder (SID), for reconstructing natural visual scenes, including static images and dynamic videos, from experimentally recorded spikes of a population of retinal ganglion cells. The SID is an end-to-end decoder with one end as neural spikes and the other end as images, which can be trained directly such that visual scenes are reconstructed from spikes in a highly accurate fashion. Our SID also outperforms on the reconstruction of visual stimulus compared to existing fMRI decoding models. In addition, with the aid of a spike encoder, we show that SID can be generalized to arbitrary visual scenes by using the image datasets of MNIST, CIFAR10, and CIFAR100. Furthermore, with a pre-trained SID, one can decode any dynamic videos to achieve real-time encoding and decoding of visual scenes by spikes. Altogether, our results shed new light on neuromorphic computing for artificial visual systems, such as event-based visual cameras and visual neuroprostheses.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300435",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Brain–computer interface",
      "Computer science",
      "Computer vision",
      "Decoding methods",
      "Electroencephalography",
      "Functional magnetic resonance imaging",
      "MNIST database",
      "Neural coding",
      "Neural decoding",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Perception",
      "Psychology",
      "Psychotherapist",
      "Stimulus (psychology)",
      "Visual cortex",
      "Visual perception"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yichen"
      },
      {
        "surname": "Jia",
        "given_name": "Shanshan"
      },
      {
        "surname": "Zheng",
        "given_name": "Yajing"
      },
      {
        "surname": "Yu",
        "given_name": "Zhaofei"
      },
      {
        "surname": "Tian",
        "given_name": "Yonghong"
      },
      {
        "surname": "Ma",
        "given_name": "Siwei"
      },
      {
        "surname": "Huang",
        "given_name": "Tiejun"
      },
      {
        "surname": "Liu",
        "given_name": "Jian K."
      }
    ]
  },
  {
    "title": "Parametric Deformable Exponential Linear Units for deep neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.012",
    "abstract": "Rectified activation units make an important contribution to the success of deep neural networks in many computer vision tasks. In this paper, we propose a Parametric Deformable Exponential Linear Unit (PDELU) and theoretically verify its effectiveness for improving the convergence speed of learning procedure. By means of flexible map shape, the proposed PDELU could push the mean value of activation responses closer to zero, which ensures the steepest descent in training a deep neural network. We verify the effectiveness of the proposed method in the image classification task. Extensive experiments on three classical databases (i.e., CIFAR-10, CIFAR-100, and ImageNet-2015) indicate that the proposed method leads to higher convergence speed and better accuracy when it is embedded into different CNN architectures (i.e., NIN, ResNet, WRN, and DenseNet). Meanwhile, the proposed PDELU outperforms many existing shape-specific activation functions (i.e., Maxout, ReLU, LeakyReLU, ELU, SELU, SoftPlus, Swish) and the shape-adaptive activation functions (i.e., APL, PReLU, MPELU, FReLU).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300575",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convergence (economics)",
      "Deep learning",
      "Deep neural networks",
      "Economic growth",
      "Economics",
      "Geometry",
      "Gradient descent",
      "Management",
      "Mathematics",
      "Parametric equation",
      "Parametric statistics",
      "Pattern recognition (psychology)",
      "Residual neural network",
      "Statistics",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Cheng",
        "given_name": "Qishang"
      },
      {
        "surname": "Li",
        "given_name": "HongLiang"
      },
      {
        "surname": "Wu",
        "given_name": "Qingbo"
      },
      {
        "surname": "Ma",
        "given_name": "Lei"
      },
      {
        "surname": "Ngan",
        "given_name": "King Ngi"
      }
    ]
  },
  {
    "title": "SOMprocessor: A high throughput FPGA-based architecture for implementing Self-Organizing Maps and its application to video processing",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.019",
    "abstract": "The design of neuromorphic chips aims to develop electronic circuits dedicated to executing artificial neural networks, mainly by exploring parallel processing. Unsupervised learning models, such as Self-organizing Maps (SOM), may benefit from massively concurrent hardware-based implementations to meet the requirements of real-time and embedded applications. This work first presents a theoretical analysis of the algorithms implemented in hardware to compute SOM learning and recall phases. This is important because, albeit similar, the processing steps executed in hardware are not necessarily identical to those executed in software. Then, the proposed FPGA architecture entitled SOMprocessor is shown in detail. The circuit of the processor explores two different computational strategies for increasing the performance of current state-of-the-art works. These computational strategies aim to improve the data flow through the processor and its flexibility to implement different network topologies. Finally, this work presents the application of the SOMprocessor to a video categorization task. The results show that topographic and quantization errors are similar between hardware and software implementations, as well as the overall accuracy. Moreover, the proposed FPGA architecture achieves acceleration of 3 to 4 orders of magnitude as compared to CPU executions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300733",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer architecture",
      "Computer engineering",
      "Computer science",
      "Embedded system",
      "Field-programmable gate array",
      "Hardware acceleration",
      "Massively parallel",
      "Neuromorphic engineering",
      "Parallel computing",
      "Programming language",
      "Quantization (signal processing)",
      "Software"
    ],
    "authors": [
      {
        "surname": "Sousa",
        "given_name": "Miguel Angelo de Abreu de"
      },
      {
        "surname": "Pires",
        "given_name": "Ricardo"
      },
      {
        "surname": "Del-Moral-Hernandez",
        "given_name": "Emilio"
      }
    ]
  },
  {
    "title": "Training high-performance and large-scale deep neural networks with full 8-bit integers",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.027",
    "abstract": "Deep neural network (DNN) quantization converting floating-point (FP) data in the network to integers (INT) is an effective way to shrink the model size for memory saving and simplify the operations for compute acceleration. Recently, researches on DNN quantization develop from inference to training, laying a foundation for the online training on accelerators. However, existing schemes leaving batch normalization (BN) untouched during training are mostly incomplete quantization that still adopts high precision FP in some parts of the data paths. Currently, there is no solution that can use only low bit-width INT data during the whole training process of large-scale DNNs with acceptable accuracy. In this work, through decomposing all the computation steps in DNNs and fusing three special quantization functions to satisfy the different precision requirements, we propose a unified complete quantization framework termed as “WAGEUBN” to quantize DNNs involving all data paths including W (Weights), A (Activation), G (Gradient), E (Error), U (Update), and BN. Moreover, the Momentum optimizer is also quantized to realize a completely quantized framework. Experiments on ResNet18/34/50 models demonstrate that WAGEUBN can achieve competitive accuracy on the ImageNet dataset. For the first time, the study of quantization in large-scale DNNs is advanced to the full 8-bit INT level. In this way, all the operations in the training and inference can be bit-wise operations, pushing towards faster processing speed, decreased memory cost, and higher energy efficiency. Our throughout quantization framework has great potential for future efficient portable devices with online learning ability.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304290",
    "keywords": [
      "Algorithm",
      "Anthropology",
      "Artificial intelligence",
      "Artificial neural network",
      "Computation",
      "Computer engineering",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Floating point",
      "Inference",
      "Normalization (sociology)",
      "Parallel computing",
      "Quantization (signal processing)",
      "Sociology",
      "Speedup",
      "Training set"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yukuan"
      },
      {
        "surname": "Deng",
        "given_name": "Lei"
      },
      {
        "surname": "Wu",
        "given_name": "Shuang"
      },
      {
        "surname": "Yan",
        "given_name": "Tianyi"
      },
      {
        "surname": "Xie",
        "given_name": "Yuan"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      }
    ]
  },
  {
    "title": "Low-rank discriminative regression learning for image classification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.007",
    "abstract": "As a famous multivariable analysis technique, regression methods, such as ridge regression, are widely used for image representation and dimensionality reduction. However, the metric of ridge regression and its variants is always the Frobenius norm (F-norm), which is sensitive to outliers and noise in data. At the same time, the performance of the ridge regression and its extensions is limited by the class number of the data. To address these problems, we propose a novel regression learning method which named low-rank discriminative regression learning (LDRL) for image representation. LDRL assumes that the input data is corrupted and thus the L 1 norm can be used as a sparse constraint on the noised matrix to recover the clean data for regression, which can improve the robustness of the algorithm. Due to learn a novel project matrix that is not limited by the number of classes, LDRL is suitable for classifying the data set no matter whether there is a small or large number of classes. The performance of the proposed LDRL is evaluated on six public image databases. The experimental results prove that LDRL obtains better performance than existing regression methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300526",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Dimensionality reduction",
      "Discriminative model",
      "Gene",
      "Mathematics",
      "Outlier",
      "Pattern recognition (psychology)",
      "Regression",
      "Regression analysis",
      "Robustness (evolution)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Lu",
        "given_name": "Yuwu"
      },
      {
        "surname": "Lai",
        "given_name": "Zhihui"
      },
      {
        "surname": "Wong",
        "given_name": "Wai Keung"
      },
      {
        "surname": "Li",
        "given_name": "Xuelong"
      }
    ]
  },
  {
    "title": "Constructing large-scale cortical brain networks from scalp EEG with Bayesian nonnegative matrix factorization",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.021",
    "abstract": "A large-scale network provides a high hierarchical level for understanding the adaptive adjustment of the human brain during cognition processes. Since high spatial resolution is required, most of the related works are based on functional magnetic resonance imaging (fMRI); however, fMRI lacks the temporal information that is important in investigating the high cognition processes. Although combining electroencephalography (EEG) inverse solution and independent component analysis (ICA), researchers detected large-scale functional subnetworks recently, few researchers focus on the unreasonable negative activation, which is biased from the nonnegative electrical source activations in the brain. In this study, considering the favorable nonnegative property of Bayesian nonnegative matrix factorization (Bayesian NMF) and combining EEG source imaging, we developed a robust approach for EEG large-scale network construction and applied it to two independent real EEG datasets (i.e., decision-making and P300). Eight and nine best-fit networks, including such important subnetworks as the somatosensory-motor network (SMN), the default mode network (DMN), etc., were successfully identified for decision-making and P300, respectively. Compared to the networks acquired with ICA, these networks not only lacked confusing negative activations but also showed clear spatial distributions that are compatible with specific brain function. Based on the constructed large-scale network, we further probed that the self-referential network (SRN), the primary visual network (PVN), and the visual network (VN) demonstrated different interaction patterns with other networks between different responses in decision-making. Our results confirm the possibility of probing the neural mechanisms of high cognition processes at a very high temporal and spatial resolution level.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300757",
    "keywords": [
      "Artificial intelligence",
      "Bayesian probability",
      "Cognition",
      "Computer science",
      "Default mode network",
      "Eigenvalues and eigenvectors",
      "Electroencephalography",
      "Functional magnetic resonance imaging",
      "Independent component analysis",
      "Matrix decomposition",
      "Neuroscience",
      "Non-negative matrix factorization",
      "Pattern recognition (psychology)",
      "Physics",
      "Psychology",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Yi",
        "given_name": "Chanlin"
      },
      {
        "surname": "Chen",
        "given_name": "Chunli"
      },
      {
        "surname": "Si",
        "given_name": "Yajing"
      },
      {
        "surname": "Li",
        "given_name": "Fali"
      },
      {
        "surname": "Zhang",
        "given_name": "Tao"
      },
      {
        "surname": "Liao",
        "given_name": "Yuanyuan"
      },
      {
        "surname": "Jiang",
        "given_name": "Yuanling"
      },
      {
        "surname": "Yao",
        "given_name": "Dezhong"
      },
      {
        "surname": "Xu",
        "given_name": "Peng"
      }
    ]
  },
  {
    "title": "Collaborative learning with corrupted labels",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.010",
    "abstract": "Deep neural networks (DNNs) have been very successful for supervised learning. However, their high generalization performance often comes with the high cost of annotating data manually. Collecting low-quality labeled dataset is relatively cheap, e.g., using web search engines, while DNNs tend to overfit to corrupted labels easily. In this paper, we propose a collaborative learning (co-learning) approach to improve the robustness and generalization performance of DNNs on datasets with corrupted labels. This is achieved by designing a deep network with two separate branches, coupled with a relabeling mechanism. Co-learning could safely recover the true labels of most mislabeled samples, not only preventing the model from overfitting the noise, but also exploiting useful information from all the samples. Although being very simple, the proposed algorithm is able to achieve high generalization performance even a large portion of the labels are corrupted. Experiments show that co-learning consistently outperforms existing state-of-the-art methods on three widely used benchmark datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300551",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Gene",
      "Generalization",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Supervised learning"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yulin"
      },
      {
        "surname": "Huang",
        "given_name": "Rui"
      },
      {
        "surname": "Huang",
        "given_name": "Gao"
      },
      {
        "surname": "Song",
        "given_name": "Shiji"
      },
      {
        "surname": "Wu",
        "given_name": "Cheng"
      }
    ]
  },
  {
    "title": "Weighted discriminative collaborative competitive representation for robust image classification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.020",
    "abstract": "Collaborative representation-based classification (CRC) is a famous representation-based classification method in pattern recognition. Recently, many variants of CRC have been designed for many classification tasks with the good classification performance. However, most of them ignore the inter-class pattern discrimination among the class-specific representations, which is very critical for strengthening the pattern discrimination of collaborative representation (CR). In this article, we propose a novel CR approach for image classification, called weighted discriminative collaborative competitive representation (WDCCR). The proposed WDCCR designs the discriminative and competitive collaborative representation among all the classes by fully considering the class information. On the one hand, we incorporate two discriminative constraints into the unified WDCCR model. Both constraints are the competitive class-specific representation residuals and the pairs of class-specific representations for each query sample. On the other hand, the constraint of the weighted categorical representation coefficients is introduced into the proposed model for further enhancing the power of discriminative and competitive representation. In the weighted constraint, we assume that the different classes of each query sample should have less contribution to the representation with the small representation coefficients, and then two types of weight factors are designed to constrain the representation coefficients. Furthermore, the robust WDCCR (R-WDCCR) is proposed with l 1 -norm representation fidelity for recognizing noisy images. Extensive experiments on six image data sets demonstrate the effective and robust superiorities of the proposed WDCCR and R-WDCCR over the related state-of-the-art representation-based classification methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300228",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Categorical variable",
      "Chemistry",
      "Class (philosophy)",
      "Computer science",
      "Constraint (computer-aided design)",
      "Contextual image classification",
      "Discriminative model",
      "Gene",
      "Geometry",
      "Image (mathematics)",
      "Law",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Gou",
        "given_name": "Jianping"
      },
      {
        "surname": "Wang",
        "given_name": "Lei"
      },
      {
        "surname": "Yi",
        "given_name": "Zhang"
      },
      {
        "surname": "Yuan",
        "given_name": "Yunhao"
      },
      {
        "surname": "Ou",
        "given_name": "Weihua"
      },
      {
        "surname": "Mao",
        "given_name": "Qirong"
      }
    ]
  },
  {
    "title": "Chaos in fractional-order discrete neural networks with application to image encryption",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.008",
    "abstract": "In this paper, a three-dimensional fractional-order (FO) discrete Hopfield neural network (FODHNN) in the left Caputo discrete delta’s sense is proposed, the dynamic behavior and synchronization of FODHNN are studied, and the system is applied to image encryption. First, FODHNN is shown to exhibit rich nonlinear dynamics behaviors. Phase portraits, bifurcation diagrams and Lyapunov exponents are carried out to verify chaotic dynamics in this system. Moreover, by using stability theorem of FO discrete linear systems, a suitable control scheme is designed to achieve synchronization of the FODHNN. Finally, image encryption system based on the chaotic FODHNN is presented. Some security analysis and tests are given to show the effective of the encryption system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300538",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bifurcation",
      "Cellular neural network",
      "Chaotic",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete system",
      "Encryption",
      "Hopfield network",
      "Image (mathematics)",
      "Lyapunov exponent",
      "Lyapunov stability",
      "Machine learning",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Phase portrait",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Liping"
      },
      {
        "surname": "Yin",
        "given_name": "Hao"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      },
      {
        "surname": "Yuan",
        "given_name": "Liguo"
      },
      {
        "surname": "Zheng",
        "given_name": "Song"
      },
      {
        "surname": "Yin",
        "given_name": "Lisheng"
      }
    ]
  },
  {
    "title": "Hyper-Laplacian regularized multi-view subspace clustering with low-rank tensor constraint",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.014",
    "abstract": "In this paper, we propose a novel hyper-Laplacian regularized multiview subspace clustering with low-rank tensor constraint method, which is referred as HLR-MSCLRT. In the HLR-MSCLRT model, the subspace representation matrices of different views are stacked as a tensor, and then the high order correlations among data can be captured. To reduce the redundancy information of the learned subspace representations, a low-rank constraint is adopted to the constructed tensor. Since data in the real world often reside in multiple nonlinear subspaces, the HLR-MSCLRT model utilizes the hyper-Laplacian graph regularization to preserve the local geometry structure embedded in a high-dimensional ambient space. An efficient algorithm is also presented to solve the optimization problem of the HLR-MSCLRT model. The experimental results on some data sets show that the proposed HLR-MSCLRT model outperforms many state-of-the-art multi-view clustering approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300599",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Combinatorics",
      "Computer science",
      "Constraint (computer-aided design)",
      "Geometry",
      "Laplace operator",
      "Laplacian matrix",
      "Linear subspace",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Pure mathematics",
      "Rank (graph theory)",
      "Spectral clustering",
      "Subspace topology",
      "Tensor (intrinsic definition)"
    ],
    "authors": [
      {
        "surname": "Lu",
        "given_name": "Gui-Fu"
      },
      {
        "surname": "Yu",
        "given_name": "Qin-Ru"
      },
      {
        "surname": "Wang",
        "given_name": "Yong"
      },
      {
        "surname": "Tang",
        "given_name": "Ganyi"
      }
    ]
  },
  {
    "title": "Event-triggered synchronization of discrete-time neural networks: A switching approach",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.024",
    "abstract": "This paper investigates the event-triggered synchronization control of discrete-time neural networks. The main highlights are threefold: (1) a new event-triggered mechanism (ETM) is presented, which can be regarded as a switching between the discrete-time periodic sampled-data control and a continuous ETM; (2) a saturating controller which is equipped with two switching gains is designed to match the switching property of the proposed ETM; (3) a dedicated switching Lyapunov–Krasovskii functional is constructed, which takes the sawtooth constraints of control input into account. Based on these ingredients, the synchronization criteria are derived such that the considered error systems are locally stable. Whereafter, two co-design problems are discussed to maximize the set of admissible initial conditions and the triggering threshold, respectively. Finally, the effectiveness and advantages of the proposed method are validated by two numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300344",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Discrete time and continuous time",
      "Epistemology",
      "Event (particle physics)",
      "Mathematics",
      "Philosophy",
      "Physics",
      "Programming language",
      "Property (philosophy)",
      "Quantum mechanics",
      "Sawtooth wave",
      "Set (abstract data type)",
      "Statistics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Ding",
        "given_name": "Sanbo"
      },
      {
        "surname": "Wang",
        "given_name": "Zhanshan"
      }
    ]
  },
  {
    "title": "Modeling uncertainty-seeking behavior mediated by cholinergic influence on dopamine",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.032",
    "abstract": "Recent findings suggest that acetylcholine mediates uncertainty-seeking behaviors through its projection to dopamine neurons — another neuromodulatory system known for its major role in reinforcement learning and decision-making. In this paper, we propose a leaky-integrate-and-fire model of this mechanism. It implements a softmax-like selection with an uncertainty bonus by a cholinergic drive to dopaminergic neurons, which in turn influence synaptic currents of downstream neurons. The model is able to reproduce experimental data in two decision-making tasks. It also predicts that: (i) in the absence of cholinergic input, dopaminergic activity would not correlate with uncertainty, and that (ii) the adaptive advantage brought by the implemented uncertainty-seeking mechanism is most useful when sources of reward are not highly uncertain. Moreover, this modeling work allows us to propose novel experiments which might shed new light on the role of acetylcholine in both random and directed exploration. Overall, this study contributes to a more comprehensive understanding of the role of the cholinergic system and, in particular, its involvement in decision-making.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300423",
    "keywords": [
      "Acetylcholine",
      "Artificial intelligence",
      "Biology",
      "Cholinergic",
      "Cholinergic neuron",
      "Computer science",
      "Dopamine",
      "Dopaminergic",
      "Mechanism (biology)",
      "Neuroscience",
      "Pharmacology",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Belkaid",
        "given_name": "Marwen"
      },
      {
        "surname": "Krichmar",
        "given_name": "Jeffrey L."
      }
    ]
  },
  {
    "title": "Synchronization of complex networks with time-varying delay of unknown bound via delayed impulsive control",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.003",
    "abstract": "The synchronization problem for complex networks with time-varying delays of unknown bound is investigated in this paper. From the impulsive control point of view, a novel delayed impulsive differential inequality is proposed, where the bounds of time-varying delays in continuous dynamic and discrete dynamic are both unknown. Based on the inequality, a class of delayed impulsive controllers is designed to achieve the synchronization of complex networks, where the restriction between impulses interval and time-varying delays is dropped. A numerical example is presented to illustrate the effectiveness of the obtained results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300484",
    "keywords": [
      "Aerospace engineering",
      "Artificial intelligence",
      "Class (philosophy)",
      "Combinatorics",
      "Complex network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differential (mechanical device)",
      "Engineering",
      "Impulse (physics)",
      "Interval (graph theory)",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Upper and lower bounds",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Zhilu"
      },
      {
        "surname": "Li",
        "given_name": "Xiaodi"
      },
      {
        "surname": "Duan",
        "given_name": "Peiyong"
      }
    ]
  },
  {
    "title": "PET image super-resolution using generative adversarial networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.029",
    "abstract": "The intrinsically low spatial resolution of positron emission tomography (PET) leads to image quality degradation and inaccurate image-based quantitation. Recently developed supervised super-resolution (SR) approaches are of great relevance to PET but require paired low- and high-resolution images for training, which are usually unavailable for clinical datasets. In this paper, we present a self-supervised SR (SSSR) technique for PET based on dual generative adversarial networks (GANs), which precludes the need for paired training data, ensuring wider applicability and adoptability. The SSSR network receives as inputs a low-resolution PET image, a high-resolution anatomical magnetic resonance (MR) image, spatial information (axial and radial coordinates), and a high-dimensional feature set extracted from an auxiliary CNN which is separately-trained in a supervised manner using paired simulation datasets. The network is trained using a loss function which includes two adversarial loss terms, a cycle consistency term, and a total variation penalty on the SR image. We validate the SSSR technique using a clinical neuroimaging dataset. We demonstrate that SSSR is promising in terms of image quality, peak signal-to-noise ratio, structural similarity index, contrast-to-noise ratio, and an additional no-reference metric developed specifically for SR image quality assessment. Comparisons with other SSSR variants suggest that its high performance is largely attributable to simulation guidance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300393",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Consistency (knowledge bases)",
      "Economics",
      "Image (mathematics)",
      "Image quality",
      "Image resolution",
      "Metric (unit)",
      "Noise (video)",
      "Operations management",
      "Pattern recognition (psychology)",
      "Programming language",
      "Set (abstract data type)",
      "Signal-to-noise ratio (imaging)",
      "Similarity (geometry)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Tzu-An"
      },
      {
        "surname": "Chowdhury",
        "given_name": "Samadrita Roy"
      },
      {
        "surname": "Yang",
        "given_name": "Fan"
      },
      {
        "surname": "Dutta",
        "given_name": "Joyita"
      }
    ]
  },
  {
    "title": "Neuromodulated attention and goal-driven perception in uncertain domains",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.031",
    "abstract": "In uncertain domains, the goals are often unknown and need to be predicted by the organism or system. In this paper, contrastive Excitation Backprop (c-EB) was used in two goal-driven perception tasks – one with pairs of noisy MNIST digits and the other with a robot in an action-based attention scenario. The first task included attending to even, odd, low, and high digits, whereas the second task included action goals, such as “eat”, “work-on-computer”, “read”, and “say-hi” that led to attention to objects associated with those actions. The system needed to increase attention to target items and decrease attention to distractor items and background noise. Because the valid goal was unknown, an online learning model based on the cholinergic and noradrenergic neuromodulatory systems was used to predict a noisy goal (expected uncertainty) and re-adapt when the goal changed (unexpected uncertainty). This neurobiologically plausible model demonstrates how neuromodulatory systems can predict goals in uncertain domains and how attentional mechanisms can enhance the perception for that goal.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300411",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Artificial neural network",
      "Cognitive psychology",
      "Computer science",
      "Economics",
      "Human–computer interaction",
      "MNIST database",
      "Machine learning",
      "Management",
      "Neuroscience",
      "Perception",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Robot",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Zou",
        "given_name": "Xinyun"
      },
      {
        "surname": "Kolouri",
        "given_name": "Soheil"
      },
      {
        "surname": "Pilly",
        "given_name": "Praveen K."
      },
      {
        "surname": "Krichmar",
        "given_name": "Jeffrey L."
      }
    ]
  },
  {
    "title": "Causal importance of low-level feature selectivity for generalization in image recognition",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.02.009",
    "abstract": "Although our brain and deep neural networks (DNNs) can perform high-level sensory-perception tasks, such as image or speech recognition, the inner mechanism of these hierarchical information-processing systems is poorly understood in both neuroscience and machine learning. Recently, Morcos et al. (2018) examined the effect of class-selective units in DNNs, i.e., units with high-level selectivity, on network generalization, concluding that hidden units that are selectively activated by specific input patterns may harm the network’s performance. In this study, we revisited their hypothesis, considering units with selectivity for lower-level features, and argue that selective units are not always harmful to the network performance. Specifically, by using DNNs trained for image classification, we analyzed the orientation selectivity of individual units, a low-level selectivity widely studied in visual neuroscience. We found that orientation-selective units exist in both lower and higher layers of these DNNs, as in our brain. In particular, units in lower layers became more orientation-selective as the generalization performance improved during the course of training. Consistently, networks that generalized better were more orientation-selective in the lower layers. We finally revealed that ablating these selective units in the lower layers substantially degraded the generalization performance of the networks, at least by disrupting the shift-invariance of the higher layers. These results suggest that orientation selectivity can play a causally important role in object recognition, and that, contrary to the triviality of units with high-level selectivity, lower-layer units with selectivity for low-level features may be indispensable for generalization, at least for the several network architectures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030054X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Catalysis",
      "Computer science",
      "Feature (linguistics)",
      "Generalization",
      "Geometry",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Neuroscience",
      "Orientation (vector space)",
      "Pattern recognition (psychology)",
      "Perception",
      "Philosophy",
      "Psychology",
      "Selectivity"
    ],
    "authors": [
      {
        "surname": "Ukita",
        "given_name": "Jumpei"
      }
    ]
  },
  {
    "title": "Person Re-Identification with Feature Pyramid Optimization and Gradual Background Suppression",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.012",
    "abstract": "Compared with face recognition, the performance of person re-identification (re-ID) is still far from practical application. Among various interferences, there are two factors seriously limiting the performance improvement, i.e., the feature discriminability determined by “external network effectiveness”, and the image quality determined by “internal background clutters”. Target at the “external network effectiveness” problem, feature pyramids are effective to learn discriminative features because they can learn both detailed features from high-resolution shallow layers and semantical features from low-resolution deep layers, however, it can only achieve slight improvement on re-ID tasks because of the error back propagation problem. To handle the problem and utilize the effectiveness of feature pyramids, we propose a strategy called Feature Pyramid Optimization (FPO). Instead of concatenating features directly, the selected layers are optimized independently in a top–bottom order. Target at the “internal background clutters” problem, background suppression is generally considered for removing the environmental interference and improving the image quality. Several mask-based methods are used attempting to totally remove background clutters but achieve limited promotion because of the mask sharpening effect. We propose a novel strategy, i.e., Gradual Background Suppression (GBS) to reduce the background clutters and keep the smoothness of images simultaneously. Extensive experiments have been conducted and the results demonstrate the effectiveness of both FPO and GBS.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300149",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Computer science",
      "Computer vision",
      "Discriminative model",
      "Feature (linguistics)",
      "Geometry",
      "Identification (biology)",
      "Linguistics",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pyramid (geometry)",
      "Sharpening"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Yingzhi"
      },
      {
        "surname": "Yang",
        "given_name": "Xi"
      },
      {
        "surname": "Wang",
        "given_name": "Nannan"
      },
      {
        "surname": "Song",
        "given_name": "Bin"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Adaptive neural tree exploiting expert nodes to classify high-dimensional data",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.029",
    "abstract": "Classification of high dimensional data suffers from curse of dimensionality and over-fitting. Neural tree is a powerful method which combines a local feature selection and recursive partitioning to solve these problems, but it leads to high depth trees in classifying high dimensional data. On the other hand, if less depth trees are used, the classification accuracy decreases or over-fitting increases. This paper introduces a novel Neural Tree exploiting Expert Nodes (NTEN) to classify high-dimensional data. It is based on a decision tree structure, whose internal nodes are expert nodes performing multi-dimensional splitting. Any expert node has three decision-making abilities. Firstly, they can select the most eligible neural network with respect to the data complexity. Secondly, they evaluate the over-fitting. Thirdly, they can cluster the features to jointly minimize redundancy and overlapping. To this aim, metaheuristic optimization algorithms including GA, NSGA-II, PSO and ACO are applied. Based on these concepts, any expert node splits a class when the over-fitting is low, and clusters the features when the over-fitting is high. Some theoretical results on NTEN are derived, and experiments on 35 standard data show that NTEN reaches good classification results, reduces tree depth without over-fitting and degrading accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304319",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Curse of dimensionality",
      "Data mining",
      "Decision tree",
      "Engineering",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Node (physics)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Redundancy (engineering)",
      "Structural engineering",
      "Tree (set theory)"
    ],
    "authors": [
      {
        "surname": "Abpeikar",
        "given_name": "Shadi"
      },
      {
        "surname": "Ghatee",
        "given_name": "Mehdi"
      },
      {
        "surname": "Foresti",
        "given_name": "Gian Luca"
      },
      {
        "surname": "Micheloni",
        "given_name": "Christian"
      }
    ]
  },
  {
    "title": "A 3D deep supervised densely network for small organs of human temporal bone segmentation in CT images",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.005",
    "abstract": "Computed Tomography (CT) has become an important way for examining the critical anatomical organs of the human temporal bone in the diagnosis and treatment of ear diseases. Segmentation of the critical anatomical organs is an important fundamental step for the computer assistant analysis of human temporal bone CT images. However, it is challenging to segment sophisticated and small organs. To deal with this issue, a novel 3D Deep Supervised Densely Network (3D-DSD Net) is proposed in this paper. The network adopts a dense connection design and a 3D multi-pooling feature fusion strategy in the encoding stage of the 3D-Unet, and a 3D deep supervised mechanism is employed in the decoding stage. The experimental results show that our method achieved competitive performance in the CT data segmentation task of the small organs in the temporal bone.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300071",
    "keywords": [
      "Algorithm",
      "Anatomy",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Decoding methods",
      "Deep learning",
      "Encoding (memory)",
      "Feature (linguistics)",
      "Linguistics",
      "Medicine",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pooling",
      "Segmentation",
      "Temporal bone"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xiaoguang"
      },
      {
        "surname": "Gong",
        "given_name": "Zhaopeng"
      },
      {
        "surname": "Yin",
        "given_name": "Hongxia"
      },
      {
        "surname": "Zhang",
        "given_name": "Hui"
      },
      {
        "surname": "Wang",
        "given_name": "Zhenchang"
      },
      {
        "surname": "Zhuo",
        "given_name": "Li"
      }
    ]
  },
  {
    "title": "Cluster stochastic synchronization of complex dynamical networks via fixed-time control scheme",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.019",
    "abstract": "By means of fixed-time (FDT) control technique, cluster stochastic synchronization of complex networks (CNs) is investigated. Quantized controller is designed to realize the synchronization of CNs within a settling time. FDT synchronization criteria are established with the help of Lyapunov functional and comparison system methods. It should be noted that the convergence of synchronization is further improved by comparing with existing FDT synchronization results. Numerical simulations are given to illustrate our results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304198",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Channel (broadcasting)",
      "Cluster (spacecraft)",
      "Complex network",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Engineering",
      "Mathematical analysis",
      "Mathematics",
      "Programming language",
      "Scheme (mathematics)",
      "Settling time",
      "Step response",
      "Synchronization (alternating current)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Wanli"
      },
      {
        "surname": "Li",
        "given_name": "Chuandong"
      },
      {
        "surname": "Li",
        "given_name": "Hongfei"
      },
      {
        "surname": "Yang",
        "given_name": "Xinsong"
      }
    ]
  },
  {
    "title": "l 2 – l ∞ state estimation for delayed artificial neural networks under high-rate communication channels with Round-Robin protocol",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.013",
    "abstract": "In this paper, the l 2 – l ∞ state estimation problem is addressed for a class of delayed artificial neural networks under high-rate communication channels with Round-Robin (RR) protocol. To estimate the state of the artificial neural networks, numerous sensors are deployed to measure the artificial neural networks. The sensors communicate with the remote state estimator through a shared high-rate communication channel. In the high-rate communication channel, the RR protocol is utilized to schedule the transmission sequence of the numerous sensors. The aim of this paper is to design an estimator such that, under the high-rate communication channel and the RR protocol, the exponential stability of the estimation error dynamics as well as the l 2 – l ∞ performance constraint are ensured. First, sufficient conditions are given which guarantee the existence of the desired l 2 – l ∞ state estimator. Then, the estimator gains are obtained by solving two sets of matrix inequalities. Finally, numerical examples are provided to verify the effectiveness of the developed l 2 – l ∞ state estimation scheme.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300150",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Estimator",
      "Machine learning",
      "Mathematics",
      "State (computer science)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Yuxuan"
      },
      {
        "surname": "Wang",
        "given_name": "Zidong"
      },
      {
        "surname": "Shen",
        "given_name": "Bo"
      },
      {
        "surname": "Alsaadi",
        "given_name": "Fuad E."
      },
      {
        "surname": "Dobaie",
        "given_name": "Abdullah M."
      }
    ]
  },
  {
    "title": "A 3D deep supervised densely network for small organs of human temporal bone segmentation in CT images",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.005",
    "abstract": "Computed Tomography (CT) has become an important way for examining the critical anatomical organs of the human temporal bone in the diagnosis and treatment of ear diseases. Segmentation of the critical anatomical organs is an important fundamental step for the computer assistant analysis of human temporal bone CT images. However, it is challenging to segment sophisticated and small organs. To deal with this issue, a novel 3D Deep Supervised Densely Network (3D-DSD Net) is proposed in this paper. The network adopts a dense connection design and a 3D multi-pooling feature fusion strategy in the encoding stage of the 3D-Unet, and a 3D deep supervised mechanism is employed in the decoding stage. The experimental results show that our method achieved competitive performance in the CT data segmentation task of the small organs in the temporal bone.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300071",
    "keywords": [
      "Algorithm",
      "Anatomy",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Decoding methods",
      "Deep learning",
      "Encoding (memory)",
      "Feature (linguistics)",
      "Linguistics",
      "Medicine",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pooling",
      "Segmentation",
      "Temporal bone"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xiaoguang"
      },
      {
        "surname": "Gong",
        "given_name": "Zhaopeng"
      },
      {
        "surname": "Yin",
        "given_name": "Hongxia"
      },
      {
        "surname": "Zhang",
        "given_name": "Hui"
      },
      {
        "surname": "Wang",
        "given_name": "Zhenchang"
      },
      {
        "surname": "Zhuo",
        "given_name": "Li"
      }
    ]
  },
  {
    "title": "Adaptive neural tree exploiting expert nodes to classify high-dimensional data",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.029",
    "abstract": "Classification of high dimensional data suffers from curse of dimensionality and over-fitting. Neural tree is a powerful method which combines a local feature selection and recursive partitioning to solve these problems, but it leads to high depth trees in classifying high dimensional data. On the other hand, if less depth trees are used, the classification accuracy decreases or over-fitting increases. This paper introduces a novel Neural Tree exploiting Expert Nodes (NTEN) to classify high-dimensional data. It is based on a decision tree structure, whose internal nodes are expert nodes performing multi-dimensional splitting. Any expert node has three decision-making abilities. Firstly, they can select the most eligible neural network with respect to the data complexity. Secondly, they evaluate the over-fitting. Thirdly, they can cluster the features to jointly minimize redundancy and overlapping. To this aim, metaheuristic optimization algorithms including GA, NSGA-II, PSO and ACO are applied. Based on these concepts, any expert node splits a class when the over-fitting is low, and clusters the features when the over-fitting is high. Some theoretical results on NTEN are derived, and experiments on 35 standard data show that NTEN reaches good classification results, reduces tree depth without over-fitting and degrading accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304319",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Curse of dimensionality",
      "Data mining",
      "Decision tree",
      "Engineering",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Node (physics)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Redundancy (engineering)",
      "Structural engineering",
      "Tree (set theory)"
    ],
    "authors": [
      {
        "surname": "Abpeikar",
        "given_name": "Shadi"
      },
      {
        "surname": "Ghatee",
        "given_name": "Mehdi"
      },
      {
        "surname": "Foresti",
        "given_name": "Gian Luca"
      },
      {
        "surname": "Micheloni",
        "given_name": "Christian"
      }
    ]
  },
  {
    "title": "Theory of deep convolutional neural networks: Downsampling",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.018",
    "abstract": "Establishing a solid theoretical foundation for structured deep neural networks is greatly desired due to the successful applications of deep learning in various practical domains. This paper aims at an approximation theory of deep convolutional neural networks whose structures are induced by convolutions. To overcome the difficulty in theoretical analysis of the networks with linearly increasing widths arising from convolutions, we introduce a downsampling operator to reduce the widths. We prove that the downsampled deep convolutional neural networks can be used to approximate ridge functions nicely, which hints some advantages of these structured networks in terms of approximation or modeling. We also prove that the output of any multi-layer fully-connected neural network can be realized by that of a downsampled deep convolutional neural network with free parameters of the same order, which shows that in general, the approximation ability of deep convolutional neural networks is at least as good as that of fully-connected networks. Finally, a theorem for approximating functions on Riemannian manifolds is presented, which demonstrates that deep convolutional neural networks can be used to learn manifold features of data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300204",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Image (mathematics)",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Topology (electrical circuits)",
      "Upsampling"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Ding-Xuan"
      }
    ]
  },
  {
    "title": "Robust adaptation regularization based on within-class scatter for domain adaptation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.009",
    "abstract": "In many practical applications, the assumption that the distributions of the data employed for training and test are identical is rarely valid, which would result in a rapid decline in performance. To address this problem, the domain adaptation strategy has been developed in recent years. In this paper, we propose a novel unsupervised domain adaptation method, referred to as Robust Adaptation Regularization based on Within-Class Scatter (WCS-RAR), to simultaneously optimize the regularized loss, the within-class scatter, the joint distribution between domains, and the manifold consistency. On the one hand, to make the model robust against outliers, we adopt an l 2 , 1 -norm based loss function in virtue of its row sparsity, instead of the widely-used l 2 -norm based squared loss or hinge loss function to determine the residual. On the other hand, to well preserve the structure knowledge of the source data within the same class and strengthen the discriminant ability of the classifier, we incorporate the minimum within-class scatter into the process of domain adaptation. Lastly, to efficiently solve the resulting optimization problem, we extend the form of the Representer Theorem through the kernel trick, and thus derive an elegant solution for the proposed model. The extensive comparison experiments with the state-of-the-art methods on multiple benchmark data sets demonstrate the superiority of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300113",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Domain adaptation",
      "Hinge loss",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Nonparametric statistics",
      "Outlier",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Statistics",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Liran"
      },
      {
        "surname": "Zhong",
        "given_name": "Ping"
      }
    ]
  },
  {
    "title": "Adaptive complex-valued stepsize based fast learning of complex-valued neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.011",
    "abstract": "Complex-valued gradient descent algorithm is a popular tool to optimize functions of complex variables, especially for the training of complex-valued neural networks. However, the choice of suitable learning stepsize is a challenging task during the training process. In this paper, an adaptive complex-valued stepsize design method is proposed for complex-valued neural networks by generalizing the adaptable learning rate tree technique to the complex domain. The scaling and rotation factors are introduced to simultaneously adjust the amplitude and phase of complex-valued stepsize. The search range is thus expanded from half line to half plane such that better search direction is obtained at each iteration. We analyze the dynamics of the algorithm near a saddle point and find that it is very easy to escape from the saddle point to guarantee fast convergence and high accuracy. Some experimental results on function approximation and pattern classification tasks are presented to illustrate the advantages of the proposed algorithm over some previous ones.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300137",
    "keywords": [
      "Adaptive stepsize",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Geometry",
      "Gradient descent",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Numerical analysis",
      "Range (aeronautics)",
      "Saddle point"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Yongliang"
      },
      {
        "surname": "Huang",
        "given_name": "He"
      }
    ]
  },
  {
    "title": "A model for navigation in unknown environments based on a reservoir of hippocampal sequences",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.014",
    "abstract": "Hippocampal place cell populations are activated in sequences on multiple time scales during active behavior, resting and sleep states, suggesting that these sequences are the genuine dynamical motifs of the hippocampal circuit. Recently, prewired hippocampal place cell sequences have even been reported to correlate to future behaviors, but so far there is no explanation of what could be the computational benefits of such a mapping between intrinsic dynamical structure and external sensory inputs. Here, I propose a computational model in which a set of predefined internal sequences is used as a dynamical reservoir to construct a spatial map of a large unknown maze based on only a small number of salient landmarks. The model is based on a new variant of temporal difference learning and implements a simultaneous localization and mapping algorithm. As a result sequences during intermittent replay periods can be decoded as spatial trajectories and improve navigation performance, which supports the functional interpretation of replay to consolidate memories of motor actions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300162",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Construct (python library)",
      "Dynamical systems theory",
      "Hippocampal formation",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Physics",
      "Place cell",
      "Programming language",
      "Quantum mechanics",
      "Salient",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Leibold",
        "given_name": "Christian"
      }
    ]
  },
  {
    "title": "EEG based multi-class seizure type classification using convolutional neural network and transfer learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.017",
    "abstract": "Recognition of epileptic seizure type is essential for the neurosurgeon to understand the cortical connectivity of the brain. Though automated early recognition of seizures from normal electroencephalogram (EEG) was existing, no attempts have been made towards the classification of variants of seizures. Therefore, this study attempts to classify seven variants of seizures with non-seizure EEG through the application of convolutional neural networks (CNN) and transfer learning by making use of the Temple University Hospital EEG corpus. The objective of our study is to perform a multi-class classification of epileptic seizure type, which includes simple partial, complex partial, focal non-specific, generalized non-specific, absence, tonic, and tonic–clonic, and non-seizures. The 19 channels EEG time series was converted into a spectrogram stack before feeding as input to CNN. The following two different modalities were proposed using CNN: (1) Transfer learning using pretrained network, (2) Extract image features using pretrained network and classify using the support vector machine classifier. The following ten pretrained networks were used to identify the optimal network for the proposed study: Alexnet, Vgg16, Vgg19, Squeezenet, Googlenet, Inceptionv3, Densenet201, Resnet18, Resnet50, and Resnet101. The highest classification accuracy of 82.85% (using Googlenet) and 88.30% (using Inceptionv3) was achieved using transfer learning and extract image features approach respectively. Comparison results showed that CNN based approach outperformed conventional feature and clustering based approaches. It can be concluded that the EEG based classification of seizure type using CNN model could be used in pre-surgical evaluation for treating patients with epilepsy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300198",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Electroencephalography",
      "Machine learning",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Support vector machine",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Raghu",
        "given_name": "S."
      },
      {
        "surname": "Sriraam",
        "given_name": "Natarajan"
      },
      {
        "surname": "Temel",
        "given_name": "Yasin"
      },
      {
        "surname": "Rao",
        "given_name": "Shyam Vasudeva"
      },
      {
        "surname": "Kubben",
        "given_name": "Pieter L."
      }
    ]
  },
  {
    "title": "Adaptive tracking synchronization for coupled reaction–diffusion neural networks with parameter mismatches",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.025",
    "abstract": "In this paper, tracking synchronization for coupled reaction–diffusion neural networks with parameter mismatches is investigated. For such a networked control system, only local neighbor information is used to compensate the mismatch characteristic termed as parameter mismatch, uncertainty or external disturbance. Different from the general boundedness hypothesis, the parameter mismatches are permitted to be unbounded. For the known parameter mismatches, parameter-dependent controller and parameter-independent adaptive controller are respectively designed. While for fully unknown network parameters and parameter mismatches, a distributed adaptive controller is proposed. By means of partial differential equation theories and differential inequality techniques, the tracking synchronization errors driven by these nonlinear controllers are proved to be uniformly ultimately bounded and exponentially convergent to some adjustable bounded domains. Finally, three numerical examples are given to test the effectiveness of the proposed controllers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304253",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biological system",
      "Biology",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Diffusion",
      "Mathematical analysis",
      "Mathematics",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Reaction–diffusion system",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Thermodynamics",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Hao"
      },
      {
        "surname": "Ding",
        "given_name": "Zhixia"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "Exponential and adaptive synchronization of inertial complex-valued neural networks: A non-reduced order and non-separation approach",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.002",
    "abstract": "This paper mainly deals with the problem of exponential and adaptive synchronization for a type of inertial complex-valued neural networks via directly constructing Lyapunov functionals without utilizing standard reduced-order transformation for inertial neural systems and common separation approach for complex-valued systems. At first, a complex-valued feedback control scheme is designed and a nontrivial Lyapunov functional, composed of the complex-valued state variables and their derivatives, is proposed to analyze exponential synchronization. Some criteria involving multi-parameters are derived and a feasible method is provided to determine these parameters so as to clearly show how to choose control gains in practice. In addition, an adaptive control strategy in complex domain is developed to adjust control gains and asymptotic synchronization is ensured by applying the method of undeterminated coefficients in the construction of Lyapunov functional and utilizing Barbalat Lemma. Lastly, a numerical example along with simulation results is provided to support the theoretical work.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300046",
    "keywords": [
      "Adaptive control",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Ecology",
      "Exponential stability",
      "Gene",
      "Inertial frame of reference",
      "Lemma (botany)",
      "Lyapunov function",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Poaceae",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Juan"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      },
      {
        "surname": "Wang",
        "given_name": "Leimin"
      }
    ]
  },
  {
    "title": "Medi-Care AI: Predicting medications from billing codes via robust recurrent neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.001",
    "abstract": "In this paper, we present an effective deep prediction framework based on robust recurrent neural networks (RNNs) to predict the likely therapeutic classes of medications a patient is taking, given a sequence of diagnostic billing codes in their record. Accurately capturing the list of medications currently taken by a given patient is extremely challenging due to undefined errors and omissions. We present a general robust framework that explicitly models the possible contamination through overtime decay mechanism on the input billing codes and noise injection into the recurrent hidden states, respectively. By doing this, billing codes are reformulated into its temporal patterns with decay rates on each medical variable, and the hidden states of RNNs are regularized by random noises which serve as dropout to improved RNNs robustness towards data variability in terms of missing values and multiple errors. The proposed method is extensively evaluated on real health care data to demonstrate its effectiveness in suggesting medication orders from contaminated values.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300034",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Code (set theory)",
      "Computer science",
      "Data mining",
      "Dropout (neural networks)",
      "Gene",
      "Genetics",
      "Machine learning",
      "Missing data",
      "Programming language",
      "Recurrent neural network",
      "Robustness (evolution)",
      "Sequence (biology)",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Deyin"
      },
      {
        "surname": "Wu",
        "given_name": "Yuanbo Lin"
      },
      {
        "surname": "Li",
        "given_name": "Xue"
      },
      {
        "surname": "Qi",
        "given_name": "Lin"
      }
    ]
  },
  {
    "title": "Differential-game for resource aware approximate optimal control of large-scale nonlinear systems with multiple players",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.031",
    "abstract": "In this paper, we propose a novel differential-game based neural network (NN) control architecture to solve an optimal control problem for a class of large-scale nonlinear systems involving N -players. We focus on optimizing the usage of the computational resources along with the system performance simultaneously. In particular, the N -players’ control policies are desired to be designed such that they cooperatively optimize the large-scale system performance, and the sampling intervals for each player are desired to reduce the frequency of feedback execution. To develop a unified design framework that achieves both these objectives, we propose an optimal control problem by integrating both the design requirements, which leads to a multi-player differential-game. A solution to this problem is numerically obtained by solving the associated Hamilton-Jacobi (HJ) equation using event-driven approximate dynamic programming (E-ADP) and artificial NNs online and forward-in-time. We employ the critic neural networks to approximate the solution to the HJ equation, i.e., the optimal value function, with aperiodically available feedback information. Using the NN approximated value function, we design the control policies and the sampling schemes. Finally, the event-driven N -player system is remodeled as a hybrid dynamical system with impulsive weight update rules for analyzing its stability and convergence properties. The closed-loop practical stability of the system and Zeno free behavior of the sampling scheme are demonstrated using the Lyapunov method. Simulation results using a numerical example are also included to substantiate the analytical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300022",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Differential game",
      "Economic growth",
      "Economics",
      "Filter (signal processing)",
      "Lyapunov function",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Optimal control",
      "Physics",
      "Quantum mechanics",
      "Sampling (signal processing)",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Sahoo",
        "given_name": "Avimanyu"
      },
      {
        "surname": "Narayanan",
        "given_name": "Vignesh"
      }
    ]
  },
  {
    "title": "Adaptive tracking synchronization for coupled reaction–diffusion neural networks with parameter mismatches",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.025",
    "abstract": "In this paper, tracking synchronization for coupled reaction–diffusion neural networks with parameter mismatches is investigated. For such a networked control system, only local neighbor information is used to compensate the mismatch characteristic termed as parameter mismatch, uncertainty or external disturbance. Different from the general boundedness hypothesis, the parameter mismatches are permitted to be unbounded. For the known parameter mismatches, parameter-dependent controller and parameter-independent adaptive controller are respectively designed. While for fully unknown network parameters and parameter mismatches, a distributed adaptive controller is proposed. By means of partial differential equation theories and differential inequality techniques, the tracking synchronization errors driven by these nonlinear controllers are proved to be uniformly ultimately bounded and exponentially convergent to some adjustable bounded domains. Finally, three numerical examples are given to test the effectiveness of the proposed controllers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304253",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biological system",
      "Biology",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Diffusion",
      "Mathematical analysis",
      "Mathematics",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Reaction–diffusion system",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Thermodynamics",
      "Tracking (education)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Hao"
      },
      {
        "surname": "Ding",
        "given_name": "Zhixia"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "FOM: Fourth-order moment based causal direction identification on the heteroscedastic data",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.006",
    "abstract": "Identification of the causal direction is a fundamental problem in many scientific research areas. The independence between the noise and the cause variable is a widely used assumption to identify the causal direction. However, such an independence assumption is usually violated due to heteroscedasticity of the real-world data. In this paper, we propose a new criterion for the causal direction identification which is robust to the heteroscedasticity of the data. In detail, the fourth-order moment of noise is proposed to measure the asymmetry between the cause and effect. A heteroscedastic Gaussian process regression-based estimation of the fourth-order moment is proposed accordingly. Under some commonly used assumptions of the causal mechanism, we theoretically show that the noise’s fourth-order moment of the causal direction is smaller than that of the anti-causal direction. Experimental results on both simulated and real-world data illustrate the efficiency of the proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300083",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Botany",
      "Classical mechanics",
      "Computer science",
      "Data mining",
      "Econometrics",
      "Gaussian",
      "Heteroscedasticity",
      "Identification (biology)",
      "Image (mathematics)",
      "Independence (probability theory)",
      "Mathematics",
      "Measure (data warehouse)",
      "Moment (physics)",
      "Noise (video)",
      "Physics",
      "Quantum mechanics",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Cai",
        "given_name": "Ruichu"
      },
      {
        "surname": "Ye",
        "given_name": "Jincheng"
      },
      {
        "surname": "Qiao",
        "given_name": "Jie"
      },
      {
        "surname": "Fu",
        "given_name": "Huiyuan"
      },
      {
        "surname": "Hao",
        "given_name": "Zhifeng"
      }
    ]
  },
  {
    "title": "Learning deformable registration of medical images with anatomical constraints",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.023",
    "abstract": "Deformable image registration is a fundamental problem in the field of medical image analysis. During the last years, we have witnessed the advent of deep learning-based image registration methods which achieve state-of-the-art performance, and drastically reduce the required computational time. However, little work has been done regarding how can we encourage our models to produce not only accurate, but also anatomically plausible results, which is still an open question in the field. In this work, we argue that incorporating anatomical priors in the form of global constraints into the learning process of these models, will further improve their performance and boost the realism of the warped images after registration. We learn global non-linear representations of image anatomy using segmentation masks, and employ them to constraint the registration process. The proposed AC-RegNet architecture is evaluated in the context of chest X-ray image registration using three different datasets, where the high anatomical variability makes the task extremely challenging. Our experiments show that the proposed anatomically constrained registration model produces more realistic and accurate results than state-of-the-art methods, demonstrating the potential of this approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300253",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Constraint (computer-aided design)",
      "Context (archaeology)",
      "Deep learning",
      "Economics",
      "Field (mathematics)",
      "Geometry",
      "Image (mathematics)",
      "Image registration",
      "Management",
      "Mathematics",
      "Operating system",
      "Paleontology",
      "Process (computing)",
      "Pure mathematics",
      "Segmentation",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Mansilla",
        "given_name": "Lucas"
      },
      {
        "surname": "Milone",
        "given_name": "Diego H."
      },
      {
        "surname": "Ferrante",
        "given_name": "Enzo"
      }
    ]
  },
  {
    "title": "Deep feature transfer learning for trusted and automated malware signature generation in private cloud environments",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.003",
    "abstract": "This paper presents TrustSign, a novel, trusted automatic malware signature generation method based on high-level deep features transferred from a VGG-19 neural network model pretrained on the ImageNet dataset. While traditional automatic malware signature generation techniques rely on static or dynamic analysis of the malware’s executable, our method overcomes the limitations associated with these techniques by producing signatures based on the presence of the malicious process in the volatile memory. By leveraging the cloud’s virtualization technology, TrustSign analyzes the malicious process in a trusted manner, since the malware is unaware and cannot interfere with the inspection procedure. Additionally, by removing the dependency on the malware’s executable, our method is fully capable of signing fileless malware as well. TrustSign’s signature generation process does not require feature engineering or any additional model training, and it is done in a completely unsupervised manner, eliminating the need for a human expert. Because of this, our method has the advantage of dramatically reducing signature generation and distribution time. In fact, in this paper we rethink the typical use of deep convolutional neural networks and use the VGG-19 model as a topological feature extractor for a vastly different task from the one it was trained for. The results of our experimental evaluation demonstrate TrustSign’s ability to generate signatures impervious to the process state over time. By using the signatures generated by TrustSign as input for various supervised classifiers, we achieved up to 99.5% classification accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300058",
    "keywords": [
      "Artificial intelligence",
      "Cloud computing",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Data mining",
      "Deep learning",
      "Executable",
      "Feature (linguistics)",
      "Geometry",
      "Linguistics",
      "Machine learning",
      "Malware",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Process (computing)",
      "Signature (topology)"
    ],
    "authors": [
      {
        "surname": "Nahmias",
        "given_name": "Daniel"
      },
      {
        "surname": "Cohen",
        "given_name": "Aviad"
      },
      {
        "surname": "Nissim",
        "given_name": "Nir"
      },
      {
        "surname": "Elovici",
        "given_name": "Yuval"
      }
    ]
  },
  {
    "title": "Effective metric learning with co-occurrence embedding for collaborative recommendations",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.021",
    "abstract": "In recommender systems, matrix factorization and its variants have grown up to be dominant in collaborative filtering due to their simplicity and effectiveness. In matrix factorization based methods, dot product which is actually used as a measure of distance from users to items, does not satisfy the inequality property, and thus may fail to capture the inner grained preference information and further limits the performance of recommendations. Metric learning produces distance functions that capture the essential relationships among rating data and has been successfully explored in collaborative recommendations. However, without the global statistical information of user–user pairs and item–item pairs, it makes the model easy to achieve a suboptimal metric. For this, we present a co-occurrence embedding regularized metric learning model (CRML) for collaborative recommendations. We consider the optimization problem as a multi-task learning problem which includes optimizing a primary task of metric learning and two auxiliary tasks of representation learning. In particular, we develop an effective approach for learning the embedding representations of both users and items, and then exploit the strategy of soft parameter sharing to optimize the model parameters. Empirical experiments on four datasets demonstrate that the CRML model can enhance the naive metric learning model and significantly outperforms the state-of-the-art methods in terms of accuracy of collaborative recommendations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030023X",
    "keywords": [
      "Artificial intelligence",
      "Business",
      "Collaborative learning",
      "Computer science",
      "Embedding",
      "Knowledge management",
      "Machine learning",
      "Marketing",
      "Metric (unit)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Hao"
      },
      {
        "surname": "Zhou",
        "given_name": "Qimin"
      },
      {
        "surname": "Nie",
        "given_name": "Rencan"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "A deep CNN approach to decode motor preparation of upper limbs from time–frequency maps of EEG signals at source level",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.027",
    "abstract": "A system that can detect the intention to move and decode the planned movement could help all those subjects that can plan motion but are unable to implement it. In this paper, motor planning activity is investigated by using electroencephalographic (EEG) signals with the aim to decode motor preparation phases. A publicly available database of 61-channels EEG signals recorded from 15 healthy subjects during the execution of different movements (elbow flexion/extension, forearm pronation/supination, hand open/close) of the right upper limb was employed to generate a dataset of EEG epochs preceding resting and movement’s onset. A novel system is introduced for the classification of premovement vs resting and of premovement vs premovement epochs. For every epoch, the proposed system generates a time–frequency (TF) map of every source signal in the motor cortex, through beamforming and Continuous Wavelet Transform (CWT), then all the maps are embedded in a volume and used as input to a deep CNN. The proposed system succeeded in discriminating premovement from resting with an average accuracy of 90.3% (min 74.6%, max 100%), outperforming comparable methods in the literature, and in discriminating premovement vs premovement with an average accuracy of 62.47%. The achieved results encourage to investigate motor planning at source level in the time–frequency domain through deep learning approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030037X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Electroencephalography",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Speech recognition",
      "Wavelet"
    ],
    "authors": [
      {
        "surname": "Mammone",
        "given_name": "Nadia"
      },
      {
        "surname": "Ieracitano",
        "given_name": "Cosimo"
      },
      {
        "surname": "Morabito",
        "given_name": "Francesco C."
      }
    ]
  },
  {
    "title": "The feature extraction of resting-state EEG signal from amnestic mild cognitive impairment with type 2 diabetes mellitus based on feature-fusion multispectral image method",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.025",
    "abstract": "Recently, combining feature extraction and classification method of electroencephalogram (EEG) signals has been widely used in identifying mild cognitive impairment. However, it remains unclear which feature of EEG signals is best effective in assessing amnestic mild cognitive impairment (aMCI) with type 2 diabetes mellitus (T2DM) when combining one classifier. This study proposed a novel feature extraction method of EEG signals named feature-fusion multispectral image method (FMIM) for diagnosis of aMCI with T2DM. The FMIM was integrated with convolutional neural network (CNN) to classify the processed multispectral image data. The results showed that FMIM could effectively identify aMCI with T2DM from the control group compared to existing multispectral image method (MIM), with improvements including the type and quantity of feature extraction. Meanwhile, part of the invalid calculation could be avoided during the classification process. In addition, the classification evaluation indexes were best under the combination of Alpha2-Beta1-Beta2 frequency bands in data set based on FMIM-1, and were also best under the combination of the Theta-Alpha1-Alpha2-Beta1-Beta2 frequency bands in data set based on FMIM-2. Therefore, FMIM can be used as an effective feature extraction method of aMCI with T2DM, and as a valuable biomarker in clinical applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300356",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Electroencephalography",
      "Feature (linguistics)",
      "Feature extraction",
      "Linguistics",
      "Medicine",
      "Multispectral image",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Psychiatry"
    ],
    "authors": [
      {
        "surname": "Wen",
        "given_name": "Dong"
      },
      {
        "surname": "Li",
        "given_name": "Peng"
      },
      {
        "surname": "Li",
        "given_name": "Xiaoli"
      },
      {
        "surname": "Wei",
        "given_name": "Zhenhao"
      },
      {
        "surname": "Zhou",
        "given_name": "Yanhong"
      },
      {
        "surname": "Pei",
        "given_name": "Huan"
      },
      {
        "surname": "Li",
        "given_name": "Fengnian"
      },
      {
        "surname": "Bian",
        "given_name": "Zhijie"
      },
      {
        "surname": "Wang",
        "given_name": "Lei"
      },
      {
        "surname": "Yin",
        "given_name": "Shimin"
      }
    ]
  },
  {
    "title": "Bipartite synchronization for inertia memristor-based neural networks on coopetition networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.010",
    "abstract": "This paper addresses the bipartite synchronization problem of coupled inertia memristor-based neural networks with both cooperative and competitive interactions. Generally, coopetition interaction networks are modeled by a signed graph, and the corresponding Laplacian matrix is different from the nonnegative graph. The coopetition networks with structural balance can reach a final state with identical magnitude but opposite sign, which is called bipartite synchronization. Additionally, an inertia system is a second-order differential system. In this paper, firstly, by using suitable variable substitutions, the inertia memristor-based neural networks (IMNNs) are transformed into the first-order differential equations. Secondly, by designing suitable discontinuous controllers, the bipartite synchronization criteria for IMNNs with or without a leader node on coopetition networks are obtained. Finally, two illustrative examples with simulations are provided to validate the effectiveness of the proposed discontinuous control strategies for achieving bipartite synchronization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303491",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bipartite graph",
      "Channel (broadcasting)",
      "Classical mechanics",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Coopetition",
      "Electrical engineering",
      "Engineering",
      "Game theory",
      "Graph",
      "Inertia",
      "Mathematical economics",
      "Mathematics",
      "Memristor",
      "Physics",
      "Signed graph",
      "Synchronization (alternating current)",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Ning"
      },
      {
        "surname": "Zheng",
        "given_name": "Wei Xing"
      }
    ]
  },
  {
    "title": "A unified model of rule-set learning and selection",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.028",
    "abstract": "The ability to focus on relevant information and ignore irrelevant information is a fundamental part of intelligent behavior. It not only allows faster acquisition of new tasks by reducing the size of the problem space but also allows for generalizations to novel stimuli. Task-switching, task-sets, and rule-set learning are all intertwined with this ability. There are many models that attempt to individually describe these cognitive abilities. However, there are few models that try to capture the breadth of these topics in a unified model and fewer still that do it while adhering to the biological constraints imposed by the findings from the field of neuroscience. Presented here is a comprehensive model of rule-set learning and selection that can capture the learning curve results, error-type data, and transfer effects found in rule-learning studies while also replicating the reaction time data and various related effects of task-set and task-switching experiments. The model also factors in many disparate neurological findings, several of which are often disregarded by similar models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300381",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Economics",
      "Field (mathematics)",
      "Focus (optics)",
      "Learning rule",
      "Machine learning",
      "Management",
      "Mathematics",
      "Model selection",
      "Optics",
      "Physics",
      "Programming language",
      "Pure mathematics",
      "Selection (genetic algorithm)",
      "Set (abstract data type)",
      "Task (project management)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Fleischer",
        "given_name": "Pierson"
      },
      {
        "surname": "Hélie",
        "given_name": "Sébastien"
      }
    ]
  },
  {
    "title": "Improved value iteration for neural-network-based stochastic optimal control design",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.004",
    "abstract": "In this paper, a novel value iteration adaptive dynamic programming (ADP) algorithm is presented, which is called an improved value iteration ADP algorithm, to obtain the optimal policy for discrete stochastic processes. In the improved value iteration ADP algorithm, for the first time we propose a new criteria to verify whether the obtained policy is stable or not for stochastic processes. By analyzing the convergence properties of the proposed algorithm, it is shown that the iterative value functions can converge to the optimum. In addition, our algorithm allows the initial value function to be an arbitrary positive semi-definite function. Finally, two simulation examples are presented to validate the effectiveness of the developed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802030006X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Biology",
      "Computer science",
      "Convergence (economics)",
      "Dynamic programming",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Iterative method",
      "Machine learning",
      "Markov decision process",
      "Markov process",
      "Mathematical optimization",
      "Mathematics",
      "Reinforcement learning",
      "Statistics",
      "Value (mathematics)"
    ],
    "authors": [
      {
        "surname": "Liang",
        "given_name": "Mingming"
      },
      {
        "surname": "Wang",
        "given_name": "Ding"
      },
      {
        "surname": "Liu",
        "given_name": "Derong"
      }
    ]
  },
  {
    "title": "A neurodynamic approach to nonsmooth constrained pseudoconvex optimization problem",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.015",
    "abstract": "This paper presents a new neurodynamic approach for solving the constrained pseudoconvex optimization problem based on more general assumptions. The proposed neural network is equipped with a hard comparator function and a piecewise linear function, which make the state solution not only stay in the feasible region, but also converge to an optimal solution of the constrained pseudoconvex optimization problem. Compared with other related existing conclusions, the neurodynamic approach here enjoys global convergence and lower dimension of the solution space. Moreover, the neurodynamic approach does not depend on some additional assumptions, such as the feasible region is bounded, the objective function is lower bounded over the feasible region or the objective function is coercive. Finally, both numerical illustrations and simulation results in support vector regression problem show the well performance and the viability of the proposed neurodynamic approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304071",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Computer science",
      "Convergence (economics)",
      "Dimension (graph theory)",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Feasible region",
      "Function (biology)",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Chen"
      },
      {
        "surname": "Chai",
        "given_name": "Yiyuan"
      },
      {
        "surname": "Qin",
        "given_name": "Sitian"
      },
      {
        "surname": "Wang",
        "given_name": "Zhenkun"
      },
      {
        "surname": "Feng",
        "given_name": "Jiqiang"
      }
    ]
  },
  {
    "title": "K-Anonymity inspired adversarial attack and multiple one-class classification defense",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.015",
    "abstract": "A novel adversarial attack methodology for fooling deep neural network classifiers in image classification tasks is proposed, along with a novel defense mechanism to counter such attacks. Two concepts are introduced, namely the K-Anonymity-inspired Adversarial Attack (K-A 3 ) and the Multiple Support Vector Data Description Defense (M-SVDD-D). The proposed K-A 3 introduces novel optimization criteria to standard adversarial attack methodologies, inspired by the K-Anonymity principles. Its generated adversarial examples are not only misclassified by the neural network classifier, but are uniformly spread along K different ranked output positions. The proposed M-SVDD-D consists of a deep neural architecture layer consisting of multiple non-linear one-class classifiers based on Support Vector Data Description that can be used to replace the final linear classification layer of a deep neural architecture, and an additional class verification mechanism. Its application decreases the effectiveness of adversarial attacks, by increasing the noise energy required to deceive the protected model, attributed to the introduced non-linearity. In addition, M-SVDD-D can be used to prevent adversarial attacks in black-box attack settings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300174",
    "keywords": [
      "Adversarial system",
      "Anonymity",
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Classifier (UML)",
      "Computer science",
      "Computer security",
      "Data mining",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Mygdalis",
        "given_name": "Vasileios"
      },
      {
        "surname": "Tefas",
        "given_name": "Anastasios"
      },
      {
        "surname": "Pitas",
        "given_name": "Ioannis"
      }
    ]
  },
  {
    "title": "A causal discovery algorithm based on the prior selection of leaf nodes",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.020",
    "abstract": "In recent years, Linear Non-Gaussian Acyclic Model (LiNGAM) has been widely used for the discovery of causal network. However, solutions based on LiNGAM usually yield high computational complexity as well as unsatisfied accuracy when the data is high-dimensional or the sample size is too small. Such complexity or accuracy problems here are often originated from their prior selection of root nodes when estimating a causal ordering. Thus, a causal discovery algorithm termed as GPL algorithm (the LiNGAM algorithm of Giving Priority to Leaf-nodes) under a mild assumption is proposed in this paper. It assigns priority to leaf nodes other than root nodes. Since leaf nodes do not affect others in a structure, we can directly estimate a causal ordering in a bottom-up way without performing additional operations like data updating process. Corresponding proofs for both feasibility and superiority are offered based on the properties of leaf nodes. Aside from theoretical analyses, practical experiments are conducted on both synthetic and real-world data, which confirm that GPL algorithm outperforms the other two state-of-the-art algorithms in computational complexity and accuracy, especially when dealing with high-dimensional data (up to 200) or small sample size (down to 100 for the dimension of 70).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304204",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computational complexity theory",
      "Computer science",
      "Data mining",
      "Dimension (graph theory)",
      "Gaussian",
      "Geometry",
      "Mathematical proof",
      "Mathematics",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Selection (genetic algorithm)"
    ],
    "authors": [
      {
        "surname": "Zeng",
        "given_name": "Yan"
      },
      {
        "surname": "Hao",
        "given_name": "Zhifeng"
      },
      {
        "surname": "Cai",
        "given_name": "Ruichu"
      },
      {
        "surname": "Xie",
        "given_name": "Feng"
      },
      {
        "surname": "Ou",
        "given_name": "Liang"
      },
      {
        "surname": "Huang",
        "given_name": "Ruihui"
      }
    ]
  },
  {
    "title": "Directed EEG neural network analysis by LAPPS (p ≤ 1) Penalized sparse Granger approach",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.022",
    "abstract": "The conventional multivariate Granger Analysis (GA) of directed interactions has been widely applied in brain network construction based on EEG recordings as well as fMRI. Nevertheless, EEG is usually inevitably contaminated by strong noise, which may cause network distortion due to the L2-norm used in GAs for directed network recovery. The Lp (p ≤ 1) norm has been shown to be more robust to outliers as compared to LASSO and L2-GAs. Motivated to construct the sparse brain networks under strong noise condition, we hereby introduce a new approach for GA analysis, termed LAPPS (Least Absolute LP (0<p<1) Penalized Solution). LAPPS utilizes the L1-loss function for the residual error to alleviate the effect of outliers, and another Lp-penalty term (p = 0.5) to obtain the sparse connections while suppressing the spurious linkages in the networks. The simulation results reveal that LAPPS obtained the best performance under various noise conditions. In a real EEG data test when subjects performed the left and right hand Motor Imagery (MI) for brain network estimation, LAPPS also obtained a sparse network pattern with the hub at the contralateral brain primary motor areas consistent with the physiological basis of MI.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300241",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Image (mathematics)",
      "Lasso (programming language)",
      "Machine learning",
      "Noise (video)",
      "Outlier",
      "Pattern recognition (psychology)",
      "Spurious relationship",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Bore",
        "given_name": "Joyce Chelangat"
      },
      {
        "surname": "Li",
        "given_name": "Peiyang"
      },
      {
        "surname": "Harmah",
        "given_name": "Dennis Joe"
      },
      {
        "surname": "Li",
        "given_name": "Fali"
      },
      {
        "surname": "Yao",
        "given_name": "Dezhong"
      },
      {
        "surname": "Xu",
        "given_name": "Peng"
      }
    ]
  },
  {
    "title": "Multi-context aware user–item embedding for recommendation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2020.01.008",
    "abstract": "Real recommender systems usually contain various auxiliary information. Some of the most recent works make meaningful exploration of incorporating auxiliary information into the representation model for competitive recommendation. However, learning user and item representations still faces two challenges: (1) existing works do not well address the problem of integrating multi-type auxiliary information; (2) learning representations for inactive users is still challenging due to the high sparsity of explicit user–item associations. In order to tackle these problems, in this paper, the attributed heterogeneous network and bipartite interaction network are employed to incorporate various auxiliary information and user–item associations. A joint objective function and an efficient algorithm are devised for the representation learning. Experimental results show that the proposed algorithm has significant advantages over the state-of-the-art baselines. What is remarkable is that our proposed method is demonstrated to be especially useful for dealing with low-active users in the system.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608020300101",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Embedding",
      "Human–computer interaction",
      "Information retrieval",
      "Machine learning",
      "Paleontology",
      "Recommender system"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Biao"
      },
      {
        "surname": "Wen",
        "given_name": "Wen"
      },
      {
        "surname": "Hao",
        "given_name": "Zhifeng"
      },
      {
        "surname": "Cai",
        "given_name": "Ruichu"
      }
    ]
  },
  {
    "title": "Attention-guided CNN for image denoising",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.024",
    "abstract": "Deep convolutional neural networks (CNNs) have attracted considerable interest in low-level computer vision. Researches are usually devoted to improving the performance via very deep CNNs. However, as the depth increases, influences of the shallow layers on deep layers are weakened. Inspired by the fact, we propose an attention-guided denoising convolutional neural network (ADNet), mainly including a sparse block (SB), a feature enhancement block (FEB), an attention block (AB) and a reconstruction block (RB) for image denoising. Specifically, the SB makes a tradeoff between performance and efficiency by using dilated and common convolutions to remove the noise. The FEB integrates global and local features information via a long path to enhance the expressive ability of the denoising model. The AB is used to finely extract the noise information hidden in the complex background, which is very effective for complex noisy images, especially real noisy images and bind denoising. Also, the FEB is integrated with the AB to improve the efficiency and reduce the complexity for training a denoising model. Finally, a RB aims to construct the clean image through the obtained noise mapping and the given noisy image. Additionally, comprehensive experiments show that the proposed ADNet performs very well in three tasks (i.e. synthetic and real noisy images, and blind denoising) in terms of both quantitative and qualitative evaluations. The code of ADNet is accessible at https://github.com/hellloxiaotian/ADNet.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304241",
    "keywords": [
      "Artificial intelligence",
      "Block (permutation group theory)",
      "Code (set theory)",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Feature (linguistics)",
      "Geometry",
      "Image (mathematics)",
      "Linguistics",
      "Mathematics",
      "Noise (video)",
      "Noise reduction",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Chunwei"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      },
      {
        "surname": "Li",
        "given_name": "Zuoyong"
      },
      {
        "surname": "Zuo",
        "given_name": "Wangmeng"
      },
      {
        "surname": "Fei",
        "given_name": "Lunke"
      },
      {
        "surname": "Liu",
        "given_name": "Hong"
      }
    ]
  },
  {
    "title": "Global synchronization of coupled delayed memristive reaction–diffusion neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.016",
    "abstract": "This paper focuses on the global exponential synchronization of multiple memristive reaction–diffusion neural networks (MRDNNs) with time delay. Due to introducing the influences of space as well as time on state variables and replacing resistors with memristors in circuit realization, the state-dependent partial differential mathematical model of MRDNN is more general and realistic than traditional neural network model. Based on Lyapunov functional theory, Divergence theorem and inequality techniques, global exponential synchronization criteria of coupled delayed MRDNNs are derived via directed and undirected nonlinear coupling. Finally, three numerical simulation examples are presented to verify the feasibility of our main results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304083",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer science",
      "Diffusion",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Reaction–diffusion system",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Thermodynamics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Shiqin"
      },
      {
        "surname": "Guo",
        "given_name": "Zhenyuan"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Cuneate spiking neural network learning to classify naturalistic texture stimuli under varying sensing conditions",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.020",
    "abstract": "We implemented a functional neuronal network that was able to learn and discriminate haptic features from biomimetic tactile sensor inputs using a two-layer spiking neuron model and homeostatic synaptic learning mechanism. The first order neuron model was used to emulate biological tactile afferents and the second order neuron model was used to emulate biological cuneate neurons. We have evaluated 10 naturalistic textures using a passive touch protocol, under varying sensing conditions. Tactile sensor data acquired with five textures under five sensing conditions were used for a synaptic learning process, to tune the synaptic weights between tactile afferents and cuneate neurons. Using post-learning synaptic weights, we evaluated the individual and population cuneate neuron responses by decoding across 10 stimuli, under varying sensing conditions. This resulted in a high decoding performance. We further validated the decoding performance across stimuli, irrespective of sensing velocities using a set of 25 cuneate neuron responses. This resulted in a median decoding performance of 96% across the set of cuneate neurons. Being able to learn and perform generalized discrimination across tactile stimuli, makes this functional spiking tactile system effective and suitable for further robotic applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303880",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biological neuron model",
      "Computer science",
      "Decoding methods",
      "Neuron",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Programming language",
      "Psychology",
      "Robot",
      "Sensory system",
      "Set (abstract data type)",
      "Spiking neural network",
      "Tactile sensor",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Rongala",
        "given_name": "Udaya B."
      },
      {
        "surname": "Mazzoni",
        "given_name": "Alberto"
      },
      {
        "surname": "Spanne",
        "given_name": "Anton"
      },
      {
        "surname": "Jörntell",
        "given_name": "Henrik"
      },
      {
        "surname": "Oddo",
        "given_name": "Calogero M."
      }
    ]
  },
  {
    "title": "Global exponential synchronization of delayed memristive neural networks with reaction–diffusion terms",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.008",
    "abstract": "This paper investigates the global exponential synchronization problem of delayed memristive neural networks (MNNs) with reaction–diffusion terms. First, by utilizing the pinning control technique, two novel kinds of control methods are introduced to achieve synchronization of delayed MNNs with reaction–diffusion terms. Then, with the help of inequality techniques, pinning control technique, the drive–response concept and Lyapunov functional method, two sufficient conditions are obtained in the form of algebraic inequalities, which can be used for ensuring the exponential synchronization of the proposed delayed MNNs with reaction–diffusion terms. Moreover, the obtained results based on algebraic inequality complement and improve the previously known results. Finally, two illustrative examples are given to support the effectiveness and validity of the obtained theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303478",
    "keywords": [
      "Algebraic number",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Combinatorics",
      "Complement (music)",
      "Complementation",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Diffusion",
      "Exponential function",
      "Exponential growth",
      "Exponential stability",
      "Gene",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Phenotype",
      "Physics",
      "Quantum mechanics",
      "Reaction–diffusion system",
      "Synchronization (alternating current)",
      "Thermodynamics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Cao",
        "given_name": "Yanyi"
      },
      {
        "surname": "Cao",
        "given_name": "Yuting"
      },
      {
        "surname": "Guo",
        "given_name": "Zhenyuan"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "A counterexample regarding “New study on neural networks: The essential order of approximation”",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.007",
    "abstract": "The paper “New study on neural networks: the essential order of approximation” by Jianjun Wang and Zongben Xu, which appeared in Neural Networks 23 (2010), deals with upper and lower estimates for the error of best approximation with sums of nearly exponential type activation functions in terms of moduli of smoothness. In particular, the presented lower bound is astonishingly good. However, the proof is incorrect and the bound is wrong.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303995",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Approximation error",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Counterexample",
      "Deep neural networks",
      "Discrete mathematics",
      "Ecology",
      "Economics",
      "Exponential function",
      "Finance",
      "Mathematical analysis",
      "Mathematics",
      "Moduli",
      "Order (exchange)",
      "Physics",
      "Quantum mechanics",
      "Smoothness",
      "Type (biology)",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Goebbels",
        "given_name": "Steffen"
      }
    ]
  },
  {
    "title": "Structured pruning of recurrent neural networks through neuron selection",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.018",
    "abstract": "Recurrent neural networks (RNNs) have recently achieved remarkable successes in a number of applications. However, the huge sizes and computational burden of these models make it difficult for their deployment on edge devices. A practically effective approach is to reduce the overall storage and computation costs of RNNs by network pruning techniques. Despite their successful applications, those pruning methods based on Lasso either produce irregular sparse patterns in weight matrices, which is not helpful in practical speedup. To address these issues, we propose a structured pruning method through neuron selection which can remove the independent neuron of RNNs. More specifically, we introduce two sets of binary random variables, which can be interpreted as gates or switches to the input neurons and the hidden neurons, respectively. We demonstrate that the corresponding optimization problem can be addressed by minimizing the L 0 norm of the weight matrix. Finally, experimental results on language modeling and machine reading comprehension tasks have indicated the advantages of the proposed method in comparison with state-of-the-art pruning competitors. In particular, nearly 20 × practical speedup during inference was achieved without losing performance for the language model on the Penn TreeBank dataset, indicating the promising performance of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303776",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computation",
      "Computer science",
      "Inference",
      "Language model",
      "Machine learning",
      "Parallel computing",
      "Parsing",
      "Pruning",
      "Recurrent neural network",
      "Speedup",
      "Treebank"
    ],
    "authors": [
      {
        "surname": "Wen",
        "given_name": "Liangjian"
      },
      {
        "surname": "Zhang",
        "given_name": "Xuanyang"
      },
      {
        "surname": "Bai",
        "given_name": "Haoli"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      }
    ]
  },
  {
    "title": "New H ∞ state estimation criteria of delayed static neural networks via the Lyapunov–Krasovskii functional with negative definite terms",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.008",
    "abstract": "In the estimation problem for delayed static neural networks (SNNs), constructing a proper Lyapunov–Krasovskii functional (LKF) is crucial for deriving less conservative estimation criteria. In this paper, a delay-product-type LKF with negative definite terms is proposed. Based on the third-order Bessel–Legendre (B–L) integral inequality and mixed convex combination approaches, a less conservative estimator design criterion is derived. Furthermore, the desired estimator gain matrices and the H ∞ performance index are obtained by solving a set of linear matrix inequalities (LMIs). Finally, a numerical example is given to demonstrate the effectiveness of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304009",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Bessel function",
      "Combinatorics",
      "Computer science",
      "Estimator",
      "Mathematical analysis",
      "Mathematics",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Jing"
      },
      {
        "surname": "Liang",
        "given_name": "Yan"
      },
      {
        "surname": "Yang",
        "given_name": "Feisheng"
      },
      {
        "surname": "Yang",
        "given_name": "Feng"
      }
    ]
  },
  {
    "title": "A scalable multi-signal approach for the parallelization of self-organizing neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.016",
    "abstract": "Self-Organizing Neural Networks (SONNs) have a wide range of applications with massive computational requirements that often need to be satisfied with optimized parallel algorithms and implementations. In literature, SONN have been generally parallelized with GPU computing according to a single-signal paradigm: each GPU thread manages one or more nodes of the network and works concurrently on one input signal at the time. This paper presents two contributions. The first one is the experimental proof that the single-signal approach for SONNs is not optimal for the task, as it is intrinsically sequential at its core and thus inherently limited in its performance. The non-optimality of the single-signal paradigm is illustrated via a specific and simplified benchmark. The second contribution is the introduction of a new multi-signal paradigm for the parallelization of SONNs, whereby multiple signals are processed at once in each iteration hence allowing different GPU threads to work on different signals. The advantages of the multi-signal approach are shown through several benchmarks involving the Self-Organizing Adaptive Map (SOAM) algorithm as a basis for evaluation. Having a graph-based termination condition that depends on the features of the network being grown, the SOAM algorithm allows assessing both functional equivalence and performances of the paradigm proposed without relying on arbitrary thresholds. Nonetheless, the evaluation proposed has a broader scope since it refers to a unified framework for the GPU parallelization of a generic SONN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303752",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer engineering",
      "Computer science",
      "Database",
      "Geodesy",
      "Geography",
      "Implementation",
      "Operating system",
      "Parallel computing",
      "Programming language",
      "Radar",
      "SIGNAL (programming language)",
      "Scalability",
      "Signal processing",
      "Telecommunications",
      "Theoretical computer science",
      "Thread (computing)"
    ],
    "authors": [
      {
        "surname": "Musci",
        "given_name": "Mirto"
      },
      {
        "surname": "Parigi",
        "given_name": "Giacomo"
      },
      {
        "surname": "Cantoni",
        "given_name": "Virginio"
      },
      {
        "surname": "Piastra",
        "given_name": "Marco"
      }
    ]
  },
  {
    "title": "Simplified calcium signaling cascade for synaptic plasticity",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.022",
    "abstract": "We propose a model for synaptic plasticity based on a calcium signaling cascade. The model simplifies the full signaling pathways from a calcium influx to the phosphorylation (potentiation) and dephosphorylation (depression) of glutamate receptors that are gated by fictive C1 and C2 catalysts, respectively. This model is based on tangible chemical reactions, including fictive catalysts, for long-term plasticity rather than the conceptual theories commonplace in various models, such as preset thresholds of calcium concentration. Our simplified model successfully reproduced the experimental synaptic plasticity induced by different protocols such as (i) a synchronous pairing protocol and (ii) correlated presynaptic and postsynaptic action potentials (APs). Further, the ocular dominance plasticity (or the experimental verification of the celebrated Bienenstock—Cooper—Munro theory) was reproduced by two model synapses that compete by means of back-propagating APs (bAPs). The key to this competition is synapse-specific bAPs with reference to bAP-boosting on the physiological grounds.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303909",
    "keywords": [],
    "authors": [
      {
        "surname": "Kornijcuk",
        "given_name": "Vladimir"
      },
      {
        "surname": "Kim",
        "given_name": "Dohun"
      },
      {
        "surname": "Kim",
        "given_name": "Guhyun"
      },
      {
        "surname": "Jeong",
        "given_name": "Doo Seok"
      }
    ]
  },
  {
    "title": "Finite-time nonfragile time-varying proportional retarded synchronization for Markovian Inertial Memristive NNs with reaction–diffusion items",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.011",
    "abstract": "The issue of synchronization for a class of inertial memristive neural networks over a finite-time interval is investigated in this paper. Specifically, reaction–diffusion items and Markovian jump parameters are both considered in the system model, meanwhile, a novel nonfragile time-varying proportional retarded control strategy is proposed. First, a befitting variable substitution is invoked to transform the original second-order differential system into a first-order one so that the corresponding synchronization error system that is represented by a first-order differential form is established. Second, by utilizing the integral inequality technique, reciprocally convex combination approach and free-weighting matrix method, a less conservative synchronization criterion in terms of linear matrix inequalities is obtained. Finally, three simulations are exploited to illustrate the feasibility, practicability and superiority of the designed controller so that the acquired theoretical results are supported.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304034",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Inertial frame of reference",
      "Linear matrix inequality",
      "Machine learning",
      "Materials science",
      "Mathematical optimization",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Song",
        "given_name": "Xiaona"
      },
      {
        "surname": "Man",
        "given_name": "Jingtao"
      },
      {
        "surname": "Song",
        "given_name": "Shuai"
      },
      {
        "surname": "Wang",
        "given_name": "Zhen"
      }
    ]
  },
  {
    "title": "Evolving artificial neural networks with feedback",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.004",
    "abstract": "Neural networks in the brain are dominated by sometimes more than 60% feedback connections, which most often have small synaptic weights. Different from this, little is known how to introduce feedback into artificial neural networks. Here we use transfer entropy in the feed-forward paths of deep networks to identify feedback candidates between the convolutional layers and determine their final synaptic weights using genetic programming. This adds about 70% more connections to these layers all with very small weights. Nonetheless performance improves substantially on different standard benchmark tasks and in different networks. To verify that this effect is generic we use 36000 configurations of small (2–10 hidden layer) conventional neural networks in a non-linear classification task and select the best performing feed-forward nets. Then we show that feedback reduces total entropy in these networks always leading to performance increase. This method may, thus, supplement standard techniques (e.g. error backprop) adding a new quality to network learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930396X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Control engineering",
      "Economics",
      "Engineering",
      "Entropy (arrow of time)",
      "Feed forward",
      "Feedforward neural network",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Management",
      "Physics",
      "Quantum mechanics",
      "Task (project management)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Herzog",
        "given_name": "Sebastian"
      },
      {
        "surname": "Tetzlaff",
        "given_name": "Christian"
      },
      {
        "surname": "Wörgötter",
        "given_name": "Florentin"
      }
    ]
  },
  {
    "title": "Spacial sampled-data control for H ∞ output synchronization of directed coupled reaction–diffusion neural networks with mixed delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.026",
    "abstract": "This work investigates the H ∞ output synchronization (HOS) of the directed coupled reaction–diffusion (R–D) neural networks (NNs) with mixed delays. Firstly, a model of the directed state coupled R–D NNs is introduced, which not only contains some discrete and distributed time delays, but also obeys a mixed Dirichlet–Neumann boundary condition. Secondly, a spacial sampled-data controller is proposed to achieve the HOS of the considered networks. This type of controller can reduce the update rate in the process of control by measuring the state of networks at some fixed sampling points in the space region. Moreover, some criteria for the HOS are established by designing an appropriate Lyapunov functional, and some quantitative relations between diffusion coefficients, mixed delays, coupling strength and control parameters are given accurately by these criteria. Thirdly, the case of directed spatial diffusion coupled networks is also studied and, the following finding is obtained: the spatial diffusion coupling can suppress the HOS while the state coupling can promote it. Finally, one example is simulated as the verification of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304265",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Boundary value problem",
      "Computer science",
      "Controller (irrigation)",
      "Coupling (piping)",
      "Diffusion",
      "Dirichlet distribution",
      "Engineering",
      "Mathematical analysis",
      "Mathematics",
      "Mechanical engineering",
      "Physics",
      "State (computer science)",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Lu",
        "given_name": "Binglong"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Abdurahman",
        "given_name": "Abdujelil"
      }
    ]
  },
  {
    "title": "Dimension independent bounds for general shallow networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.006",
    "abstract": "This paper proves an abstract theorem addressing in a unified manner two important problems in function approximation: avoiding curse of dimensionality and estimating the degree of approximation for out-of-sample extension in manifold learning. We consider an abstract (shallow) network that includes, for example, neural networks, radial basis function networks, and kernels on data defined manifolds used for function approximation in various settings. A deep network is obtained by a composition of the shallow networks according to a directed acyclic graph, representing the architecture of the deep network. In this paper, we prove dimension independent bounds for approximation by shallow networks in the very general setting of what we have called G -networks on a compact metric measure space, where the notion of dimension is defined in terms of the cardinality of maximal distinguishable sets, generalizing the notion of dimension of a cube or a manifold. Our techniques give bounds that improve without saturation with the smoothness of the kernel involved in an integral representation of the target function. In the context of manifold learning, our bounds provide estimates on the degree of approximation for an out-of-sample extension of the target function to the ambient space. One consequence of our theorem is that without the requirement of robust parameter selection, deep networks using a non-smooth activation function such as the ReLU, do not provide any significant advantage over shallow networks in terms of the degree of approximation alone.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303454",
    "keywords": [
      "Acoustics",
      "Applied mathematics",
      "Biology",
      "Context (archaeology)",
      "Curse of dimensionality",
      "Degree (music)",
      "Dimension (graph theory)",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Intrinsic dimension",
      "Manifold (fluid mechanics)",
      "Mathematical optimization",
      "Mathematics",
      "Mechanical engineering",
      "Paleontology",
      "Physics",
      "Pure mathematics",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Mhaskar",
        "given_name": "H.N."
      }
    ]
  },
  {
    "title": "CS-MRI reconstruction based on analysis dictionary learning and manifold structure regularization",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.010",
    "abstract": "Compressed sensing (CS) significantly accelerates magnetic resonance imaging (MRI) by allowing the exact reconstruction of image from highly undersampling k-space data. In this process, the high sparsity obtained by the learned dictionary and exploitation of correlation among patches are essential to the reconstructed image quality. In this paper, by a use of these two aspects, we propose a novel CS-MRI model based on analysis dictionary learning and manifold structure regularization (ADMS). Furthermore, a proper tight frame constraint is used to obtain an effective overcomplete analysis dictionary with a high sparsifying capacity. The constructed manifold structure regularization nonuniformly enforces the correlation of each group formed by similar patches, which is more consistent with the diverse nonlocal similarity in realistic images. The proposed model is efficiently solved by the alternating direction method of multipliers (ADMM), in which the fast algorithm for each sub-problem is separately developed. The experimental results demonstrate that main components in the proposed method contribute to the final reconstruction performance and the effectiveness of the proposed model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304022",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Canonical correlation",
      "Compressed sensing",
      "Computer science",
      "Dictionary learning",
      "Dimensionality reduction",
      "Engineering",
      "Image (mathematics)",
      "Iterative reconstruction",
      "Manifold (fluid mechanics)",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Similarity (geometry)",
      "Undersampling"
    ],
    "authors": [
      {
        "surname": "Cao",
        "given_name": "Jianxin"
      },
      {
        "surname": "Liu",
        "given_name": "Shujun"
      },
      {
        "surname": "Liu",
        "given_name": "Hongqing"
      },
      {
        "surname": "Lu",
        "given_name": "Hongwei"
      }
    ]
  },
  {
    "title": "Multiple Partial Empirical Kernel Learning with Instance Weighting and Boundary Fitting",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.019",
    "abstract": "By dividing the original data set into several sub-sets, Multiple Partial Empirical Kernel Learning (MPEKL) constructs multiple kernel matrixes corresponding to the sub-sets, and these kernel matrixes are decomposed to provide the explicit kernel functions. Then, the instances in the original data set are mapped into multiple kernel spaces, which provide better performance than single kernel space. It is known that the instances in different locations and distributions behave differently. Therefore, this paper defines the weight of instance in accordance with the location and distribution of the instances. According to the location, the instances can be categorized into intrinsic instances, boundary instances and noise instances. Generally, the boundary instances, as well as the minority instances in the imbalanced data set, are assigned high weight. Meanwhile, a regularization term, which regulates the classification hyperplane to fit the distribution trend of the class boundary, is constructed by the boundary instances. Then, the weight of instance and the regularization term are introduced into MPEKL to form an algorithm named Multiple Partial Empirical Kernel Learning with Instance Weighting and Boundary Fitting (IBMPEKL). Experiments demonstrate the good performance of IBMPEKL and validate the effectiveness of the instance weighting and boundary fitting.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303788",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Boundary (topology)",
      "Computer science",
      "Discrete mathematics",
      "Hilbert space",
      "Kernel (algebra)",
      "Kernel embedding of distributions",
      "Kernel method",
      "Kernel smoother",
      "Mathematical analysis",
      "Mathematics",
      "Medicine",
      "Pattern recognition (psychology)",
      "Radial basis function kernel",
      "Radiology",
      "Regularization (linguistics)",
      "Reproducing kernel Hilbert space",
      "Support vector machine",
      "Variable kernel density estimation",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Zonghai"
      },
      {
        "surname": "Wang",
        "given_name": "Zhe"
      },
      {
        "surname": "Li",
        "given_name": "Dongdong"
      },
      {
        "surname": "Du",
        "given_name": "Wenli"
      },
      {
        "surname": "Zhou",
        "given_name": "Yangming"
      }
    ]
  },
  {
    "title": "Bayesian deep matrix factorization network for multiple images denoising",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.023",
    "abstract": "This paper aims at proposing a robust and fast low rank matrix factorization model for multiple images denoising. To this end, a novel model, Bayesian deep matrix factorization network (BDMF), is presented, where a deep neural network (DNN) is designed to model the low rank components and the model is optimized via stochastic gradient variational Bayes. By the virtue of deep learning and Bayesian modeling, BDMF makes significant improvement on synthetic experiments and real-world tasks (including shadow removal and hyperspectral image denoising), compared with existing state-of-the-art models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930423X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Bayesian probability",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Deep learning",
      "Eigenvalues and eigenvectors",
      "Factorization",
      "Hyperspectral imaging",
      "Machine learning",
      "Materials science",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Matrix decomposition",
      "Noise reduction",
      "Non-negative matrix factorization",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Rank (graph theory)"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Shuang"
      },
      {
        "surname": "Zhang",
        "given_name": "Chunxia"
      },
      {
        "surname": "Zhang",
        "given_name": "Jiangshe"
      }
    ]
  },
  {
    "title": "Learning physical properties in complex visual scenes: An intelligent machine for perceiving blood flow dynamics from static CT angiography imaging",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.017",
    "abstract": "Humans perceive physical properties such as motion and elastic force by observing objects in visual scenes. Recent research has proven that computers are capable of inferring physical properties from camera images like humans. However, few studies perceive the physical properties in more complex environment, i.e. humans have difficulty estimating physical quantities directly from the visual observation, or encounter difficulty visualizing the physical process in mind according to their daily experiences. As an appropriate example, fractional flow reserve (FFR), which measures the blood pressure difference across the vessel stenosis, becomes an important physical quantitative value determining the likelihood of myocardial ischemia in clinical coronary intervention procedure. In this study, we propose a novel deep neural network solution (TreeVes-Net) that allows machines to perceive FFR values directly from static coronary CT angiography images. Our framework fully utilizes a tree-structured recurrent neural network (RNN) with a coronary representation encoder. The encoder captures coronary geometric information providing the blood fluid-related representation. The tree-structured RNN builds a long-distance spatial dependency of blood flow information inside the coronary tree. The experiments performed on 13000 synthetic coronary trees and 180 real coronary trees from clinical patients show that the values of the area under ROC curve (AUC) are 0.92 and 0.93 under two clinical criterions. These results can demonstrate the effectiveness of our framework and its superiority to seven FFR computation methods based on machine learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303764",
    "keywords": [
      "Artificial intelligence",
      "Blood flow",
      "Computer science",
      "Computer vision",
      "Encoder",
      "Law",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Medicine",
      "Operating system",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Radiology",
      "Representation (politics)",
      "Tree (set theory)",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Zhifan"
      },
      {
        "surname": "Wang",
        "given_name": "Xin"
      },
      {
        "surname": "Sun",
        "given_name": "Shanhui"
      },
      {
        "surname": "Wu",
        "given_name": "Dan"
      },
      {
        "surname": "Bai",
        "given_name": "Junjie"
      },
      {
        "surname": "Yin",
        "given_name": "Youbing"
      },
      {
        "surname": "Liu",
        "given_name": "Xin"
      },
      {
        "surname": "Zhang",
        "given_name": "Heye"
      },
      {
        "surname": "de Albuquerque",
        "given_name": "Victor Hugo C."
      }
    ]
  },
  {
    "title": "Liver disease screening based on densely connected deep neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.005",
    "abstract": "Liver disease is an important public health problem. Liver Function Tests (LFT) is the most achievable test for liver disease diagnosis. Most liver diseases are manifested as abnormal LFT. Liver disease screening by LFT data is helpful for computer aided diagnosis. In this paper, we propose a densely connected deep neural network (DenseDNN), on 13 most commonly used LFT indicators and demographic information of subjects for liver disease screening. The algorithm was tested on a dataset of 76,914 samples (more than 100 times of data than the previous datasets). The Area Under Curve (AUC) of DenseDNN is 0.8919, that of DNN is 0.8867, that of random forest is 0.8790, and that of logistic regression is 0.7974. The performance of deep learning models are significantly better than conventional methods. As for the deep learning methods, DenseDNN shows better performance than DNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303442",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Disease",
      "Internal medicine",
      "Liver disease",
      "Liver function tests",
      "Logistic regression",
      "Machine learning",
      "Medicine",
      "Pathology",
      "Pattern recognition (psychology)",
      "Random forest"
    ],
    "authors": [
      {
        "surname": "Yao",
        "given_name": "Zhenjie"
      },
      {
        "surname": "Li",
        "given_name": "Jiangong"
      },
      {
        "surname": "Guan",
        "given_name": "Zhaoyu"
      },
      {
        "surname": "Ye",
        "given_name": "Yancheng"
      },
      {
        "surname": "Chen",
        "given_name": "Yixin"
      }
    ]
  },
  {
    "title": "Global collaboration through local interaction in competitive learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.018",
    "abstract": "Feature maps, that preserve the global topology of arbitrary datasets, can be formed by self-organizing competing agents. So far, it has been presumed that global interaction of agents is necessary for this process. We establish that this is not the case, and that global topology can be uncovered through strictly local interactions. Enforcing uniformity of map quality across all agents results in an algorithm that is able to consistently uncover the global topology of diversely challenging datasets. The applicability and scalability of this approach is further tested on a large point cloud dataset, revealing a linear relation between map training time and size. The presented work not only reduces algorithmic complexity but also constitutes first step towards a distributed self organizing map.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304186",
    "keywords": [
      "Artificial intelligence",
      "Cloud computing",
      "Combinatorics",
      "Computer science",
      "Data mining",
      "Database",
      "Distributed computing",
      "Epistemology",
      "Feature (linguistics)",
      "Linguistics",
      "Mathematics",
      "Operating system",
      "Philosophy",
      "Point cloud",
      "Process (computing)",
      "Quality (philosophy)",
      "Relation (database)",
      "Scalability",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Siddiqui",
        "given_name": "Abbas"
      },
      {
        "surname": "Georgiadis",
        "given_name": "Dionysios"
      }
    ]
  },
  {
    "title": "Synchronization of Hindmarsh Rose Neurons",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.024",
    "abstract": "Modeling and implementation of biological neurons are key to the fundamental understanding of neural network architectures in the brain and its cognitive behavior. Synchronization of neuronal models play a significant role in neural signal processing as it is very difficult to identify the actual interaction between neurons in living brain. Therefore, the synchronization study of these neuronal architectures has received extensive attention from researchers. Higher biological accuracy of these neuronal units demands more computational overhead and requires more hardware resources for implementation. This paper presents a two coupled hardware implementation of Hindmarsh Rose neuron model which is mathematically simpler model and yet mimics several behaviors of a real biological neuron. These neurons are synchronized using an exponential function. The coupled system shows several behaviors depending upon the parameters of HR model and coupling function. An approximation of coupling function is also provided to reduce the hardware cost. Both simulations and a low cost hardware implementations of exponential synaptic coupling function and its approximation are carried out for comparison. Hardware implementation on field programmable gate array (FPGA) of approximated coupling function shows that the coupled network produces different dynamical behaviors with acceptable error. Hardware implementation shows that the approximated coupling function has significantly lower implementation cost. A spiking neural network based on HR neuron is also shown as a practical application of this coupled HR neural networks. The spiking network successfully encodes and decodes a time varying input.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303922",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biological neural network",
      "Biological neuron model",
      "Biology",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer hardware",
      "Computer network",
      "Computer science",
      "Coupling (piping)",
      "Engineering",
      "Evolutionary biology",
      "Field-programmable gate array",
      "Function (biology)",
      "Machine learning",
      "Mathematics",
      "Mechanical engineering",
      "Operating system",
      "Overhead (engineering)",
      "Spiking neural network",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "S.A.",
        "given_name": "Malik"
      },
      {
        "surname": "A.H.",
        "given_name": "Mir"
      }
    ]
  },
  {
    "title": "Discriminative structure learning of sum–product networks for data stream classification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.002",
    "abstract": "Sum–product network (SPN) is a deep probabilistic representation that allows for exact and tractable inference. There has been a trend of online SPN structure learning from massive and continuous data streams. However, online structure learning of SPNs has been introduced only for the generative settings so far. In this paper, we present an online discriminative approach for SPNs for learning both the structure and parameters. The basic idea is to keep track of informative and representative examples to capture the trend of time-changing class distributions. Specifically, by estimating the goodness of model fitting of data points and dynamically maintaining a certain amount of informative examples over time, we generate new sub-SPNs in a recursive and top-down manner. Meanwhile, an outlier-robust margin-based log-likelihood loss is applied locally to each data point and the parameters of SPN are updated continuously using most probable explanation (MPE) inference. This leads to a fast yet powerful optimization procedure and improved discrimination capability between the genuine class and rival classes. Empirical results show that the proposed approach achieves better prediction performance than the state-of-the-art online structure learner for SPNs, while promising order-of-magnitude speedup. Comparison with state-of-the-art stream classifiers further proves the superiority of our approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303946",
    "keywords": [
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Data stream",
      "Discriminative model",
      "Generative grammar",
      "Generative model",
      "Inference",
      "Law",
      "Machine learning",
      "Margin (machine learning)",
      "Outlier",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Probabilistic logic",
      "Representation (politics)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Zhengya"
      },
      {
        "surname": "Liu",
        "given_name": "Cheng-Lin"
      },
      {
        "surname": "Niu",
        "given_name": "Jinghao"
      },
      {
        "surname": "Zhang",
        "given_name": "Wensheng"
      }
    ]
  },
  {
    "title": "Neonatal seizure detection from raw multi-channel EEG using a fully convolutional architecture",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.023",
    "abstract": "A deep learning classifier for detecting seizures in neonates is proposed. This architecture is designed to detect seizure events from raw electroencephalogram (EEG) signals as opposed to the state-of-the-art hand engineered feature-based representation employed in traditional machine learning based solutions. The seizure detection system utilises only convolutional layers in order to process the multichannel time domain signal and is designed to exploit the large amount of weakly labelled data in the training stage. The system performance is assessed on a large database of continuous EEG recordings of 834h in duration; this is further validated on a held-out publicly available dataset and compared with two baseline SVM based systems. The developed system achieves a 56% relative improvement with respect to a feature-based state-of-the art baseline, reaching an AUC of 98.5%; this also compares favourably both in terms of performance and run-time. The effect of varying architectural parameters is thoroughly studied. The performance improvement is achieved through novel architecture design which allows more efficient usage of available training data and end-to-end optimisation from the front-end feature extraction to the back-end classification. The proposed architecture opens new avenues for the application of deep learning to neonatal EEG, where the performance becomes a function of the amount of training data with less dependency on the availability of precise clinical labels.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303910",
    "keywords": [
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Electroencephalography",
      "Feature extraction",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Psychiatry",
      "Psychology",
      "Support vector machine",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "O’Shea",
        "given_name": "Alison"
      },
      {
        "surname": "Lightbody",
        "given_name": "Gordon"
      },
      {
        "surname": "Boylan",
        "given_name": "Geraldine"
      },
      {
        "surname": "Temko",
        "given_name": "Andriy"
      }
    ]
  },
  {
    "title": "Finite-time and fixed-time anti-synchronization of Markovian neural networks with stochastic disturbances via switching control",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.012",
    "abstract": "This paper proposes a unified theoretical framework to study the problem of finite/fixed-time drive–response anti-synchronization for a class of Markovian stochastic neural networks. State feedback switching controllers without the sign function are designed to achieve the finite/fixed-time anti-synchronization of the addressed systems. Compared with the existing synchronization criteria, our results indicate that the controllers via the switching control without the sign function are given with less conservativeness, and the controllers without any sign function can deal with the chattering problem. By employing Lyapunov functional method and properties of the Weiner process, several finite/fixed-time synchronization criteria are presented and the corresponding settling times are calculated as well. Finally, three numerical examples are provided to illustrate the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303521",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Lyapunov function",
      "Markov process",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Settling time",
      "Sign (mathematics)",
      "Sign function",
      "Statistics",
      "Step response",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Wan",
        "given_name": "Peng"
      },
      {
        "surname": "Sun",
        "given_name": "Dihua"
      },
      {
        "surname": "Zhao",
        "given_name": "Min"
      }
    ]
  },
  {
    "title": "Multi-task learning for the prediction of wind power ramp events with deep neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.017",
    "abstract": "In Machine Learning, the most common way to address a given problem is to optimize an error measure by training a single model to solve the desired task. However, sometimes it is possible to exploit latent information from other related tasks to improve the performance of the main one, resulting in a learning paradigm known as Multi-Task Learning (MTL). In this context, the high computational capacity of deep neural networks (DNN) can be combined with the improved generalization performance of MTL, by designing independent output layers for every task and including a shared representation for them. In this paper we exploit this theoretical framework on a problem related to Wind Power Ramps Events (WPREs) prediction in wind farms. Wind energy is one of the fastest growing industries in the world, with potential global spreading and deep penetration in developed and developing countries. One of the main issues with the majority of renewable energy resources is their intrinsic intermittency, which makes it difficult to increase the penetration of these technologies into the energetic mix. In this case, we focus on the specific problem of WPREs prediction, which deeply affect the wind speed and power prediction, and they are also related to different turbines damages. Specifically, we exploit the fact that WPREs are spatially-related events, in such a way that predicting the occurrence of WPREs in different wind farms can be taken as related tasks, even when the wind farms are far away from each other. We propose a DNN-MTL architecture, receiving inputs from all the wind farms at the same time to predict WPREs simultaneously in each of the farms locations. The architecture includes some shared layers to learn a common representation for the information from all the wind farms, and it also includes some specification layers, which refine the representation to match the specific characteristics of each location. Finally we modified the Adam optimization algorithm for dealing with imbalanced data, adding costs which are updated dynamically depending on the worst classified class. We compare the proposal against a baseline approach based on building three different independent models (one for each wind farm considered), and against a state-of-the-art reservoir computing approach. The DNN-MTL proposal achieves very good performance in WPREs prediction, obtaining a good balance for all the classes included in the problem (negative ramp, no ramp and positive ramp).",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304174",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer security",
      "Context (archaeology)",
      "Deep learning",
      "Electrical engineering",
      "Engineering",
      "Exploit",
      "Generalization",
      "Intermittency",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Paleontology",
      "Physics",
      "Renewable energy",
      "Systems engineering",
      "Task (project management)",
      "Thermodynamics",
      "Turbulence",
      "Wind power"
    ],
    "authors": [
      {
        "surname": "Dorado-Moreno",
        "given_name": "M."
      },
      {
        "surname": "Navarin",
        "given_name": "N."
      },
      {
        "surname": "Gutiérrez",
        "given_name": "P.A."
      },
      {
        "surname": "Prieto",
        "given_name": "L."
      },
      {
        "surname": "Sperduti",
        "given_name": "A."
      },
      {
        "surname": "Salcedo-Sanz",
        "given_name": "S."
      },
      {
        "surname": "Hervás-Martínez",
        "given_name": "C."
      }
    ]
  },
  {
    "title": "Modeling functional resting-state brain networks through neural message passing on the human connectome",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.014",
    "abstract": "In this work, we propose a natural model for information flow in the brain through a neural message-passing dynamics on a structural network of macroscopic regions, such as the human connectome (HC). In our model, each brain region is assumed to have a binary behavior (active or not), the strengths of interactions among them are encoded in the anatomical connectivity matrix defined by the HC, and the dynamics of the system is defined by the Belief Propagation (BP) algorithm, working near the critical point of the network. We show that in the absence of direct external stimuli the BP algorithm converges to a spatial map of activations that is similar to the Default Mode Network (DMN) of the brain, which has been defined from the analysis of functional MRI data. Moreover, we use Susceptibility Propagation (SP) to compute the matrix of long-range correlations between the different regions and show that the modules defined by a clustering of this matrix resemble several Resting State Networks (RSN) determined experimentally. Both results suggest that the functional DMN and RSNs can be seen as simple consequences of the anatomical structure of the brain and a neural message-passing dynamics between macroscopic regions. With the new model, we explore predictions on how functional maps change when the anatomical brain network suffers structural alterations, like in Alzheimer’s disease and in lesions of the Corpus Callosum. The implications and novel interpretations suggested by the model, as well as the role of criticality, are discussed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303739",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Connectome",
      "Connectomics",
      "Default mode network",
      "Distributed computing",
      "Functional connectivity",
      "Human Connectome Project",
      "Human brain",
      "Materials science",
      "Matrix (chemical analysis)",
      "Message passing",
      "Neuroscience",
      "Psychology",
      "Resting state fMRI"
    ],
    "authors": [
      {
        "surname": "Peraza-Goicolea",
        "given_name": "Julio A."
      },
      {
        "surname": "Martínez-Montes",
        "given_name": "Eduardo"
      },
      {
        "surname": "Aubert",
        "given_name": "Eduardo"
      },
      {
        "surname": "Valdés-Hernández",
        "given_name": "Pedro A."
      },
      {
        "surname": "Mulet",
        "given_name": "Roberto"
      }
    ]
  },
  {
    "title": "Efficient network architecture search via multiobjective particle swarm optimization based on decomposition",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.005",
    "abstract": "The efforts devoted to manually increasing the width and depth of convolutional neural network (CNN) usually require a large amount of time and expertise. It has stimulated a rising demand of neural architecture search (NAS) over these years. However, most popular NAS approaches solely optimize for low prediction error without penalizing high structure complexity. To this end, this paper proposes MOPSO/D-Net, a CNN architecture search method with multiobjective particle swarm optimization based on decomposition (MOPSO/D). The main goal is to reformulate NAS as a multiobjective evolutionary optimization problem, where the optimal architecture is learned by minimizing two conflicting objectives, namely the error rate of classification and number of parameters of the network. Along with the hybrid binary encoding and adaptive penalty-based boundary intersection, an improved MOPSO/D is further proposed to solve the formulated multiobjective NAS and provide diverse tradeoff solutions. Experimental studies verify the effectiveness of MOPSO/D-Net compared with current manual and automated CNN generation methods. The proposed algorithm achieves impressive classification performance with a small number of parameters on each of two benchmark datasets, particularly, 0.4% error rate with 0.16M params on MNIST and 5.88% error rate with 8.1M params on CIFAR-10, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303971",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Convolutional neural network",
      "Evolutionary algorithm",
      "Geodesy",
      "Geography",
      "MNIST database",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Multi-objective optimization",
      "Particle swarm optimization"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Jing"
      },
      {
        "surname": "Han",
        "given_name": "Fei"
      },
      {
        "surname": "Ling",
        "given_name": "Qinghua"
      },
      {
        "surname": "Wang",
        "given_name": "Jie"
      },
      {
        "surname": "Li",
        "given_name": "Tiange"
      },
      {
        "surname": "Han",
        "given_name": "Henry"
      }
    ]
  },
  {
    "title": "ELM embedded discriminative dictionary learning for image classification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.015",
    "abstract": "Dictionary learning is a widely adopted approach for image classification. Existing methods focus either on finding a dictionary that produces discriminative sparse representation, or on enforcing priors that best describe the dataset distribution. In many cases, the dataset size is often small with large intra-class variability and nondiscriminative feature space. In this work we propose a simple and effective framework called ELM-DDL to address these issues. Specifically, we represent input features with Extreme Learning Machine (ELM) with orthogonal output projection, which enables diverse representation on nonlinear hidden space and task specific feature learning on output space. The embeddings are further regularized via a maximum margin criterion (MMC) to maximize the inter-class variance and minimize intra-class variance. For dictionary learning, we design a novel weighted class specific ℓ 1 , 2 norm to regularize the sparse coding vectors, which promotes uniformity of the sparse patterns of samples belonging to the same class and suppresses support overlaps of different classes. We show that such regularization is robust, discriminative and easy to optimize. The proposed method is combined with a sparse representation classifier (SRC) to evaluate on benchmark datasets. Results show that our approach achieves state-of-the-art performance compared to other dictionary learning methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303740",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Computer science",
      "Contextual image classification",
      "Discriminative model",
      "Extreme learning machine",
      "Feature learning",
      "Feature vector",
      "Image (mathematics)",
      "Machine learning",
      "Neural coding",
      "Pattern recognition (psychology)",
      "Sparse approximation"
    ],
    "authors": [
      {
        "surname": "Zeng",
        "given_name": "Yijie"
      },
      {
        "surname": "Li",
        "given_name": "Yue"
      },
      {
        "surname": "Chen",
        "given_name": "Jichao"
      },
      {
        "surname": "Jia",
        "given_name": "Xiaofan"
      },
      {
        "surname": "Huang",
        "given_name": "Guang-Bin"
      }
    ]
  },
  {
    "title": "Existence and finite-time stability of discrete fractional-order complex-valued neural networks with time delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.012",
    "abstract": "Without decomposing complex-valued systems into real-valued systems, the existence and finite-time stability for discrete fractional-order complex-valued neural networks with time delays are discussed in this paper. First of all, in order to obtain the main results, a new discrete Caputo fractional difference equation is proposed in complex field based on the theory of discrete fractional calculus, which generalizes the fractional-order neural networks in the real domain. Additionally, by utilizing Arzela–Ascoli’s theorem, inequality scaling skills and fixed point theorem, some sufficient criteria of delay-dependent are deduced to ensure the existence and finite-time stability of solutions for proposed networks. Finally, the validity and feasibility of the derived theoretical results are indicated by two numerical examples with simulations. Furthermore, we have drawn the following facts: with the lower order, the discrete fractional-order complex-valued neural networks will achieve the finite-time stability more easily.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304046",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Discrete time and continuous time",
      "Domain (mathematical analysis)",
      "Economics",
      "Finance",
      "Fixed-point theorem",
      "Fractional calculus",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Order (exchange)",
      "Stability (learning theory)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "You",
        "given_name": "Xingxing"
      },
      {
        "surname": "Song",
        "given_name": "Qiankun"
      },
      {
        "surname": "Zhao",
        "given_name": "Zhenjiang"
      }
    ]
  },
  {
    "title": "Robust face alignment by cascaded regression and de-occlusion",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.009",
    "abstract": "Face alignment is a typical facial behavior analysis task in computer vision. However, the performance of face alignment is degraded greatly when the face image is partially occluded. In order to achieve better mapping between facial appearance features and shape increments, we propose a robust and occlusion-free face alignment algorithm in which a face de-occlusion module and a deep regression module are integrated into a cascaded deep generative regression model. The face de-occlusion module is a disentangled representation learning Generative Adversarial Networks (GANs) which aims to locate occlusions and recover the genuine appearance from partially occluded face image. The deep regression module can enhance facial appearance representation by utilizing the recovered faces to obtain more accurate regressors. Then, by the cascaded deep generative regression model, we recover the partially occluded face image and achieve accurate locating of landmarks gradually. It is interesting to show that the cascaded deep generative regression model can effectively locate occlusions and recover more genuine faces, which can be further used to improve the performance of face alignment. Experimental results conducted on four challenging occluded face datasets demonstrate that our method outperforms state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304010",
    "keywords": [
      "Artificial intelligence",
      "Cardiology",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Face (sociological concept)",
      "Facial recognition system",
      "Generative grammar",
      "Generative model",
      "Image (mathematics)",
      "Law",
      "Mathematics",
      "Medicine",
      "Occlusion",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Regression",
      "Representation (politics)",
      "Social science",
      "Sociology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Wan",
        "given_name": "Jun"
      },
      {
        "surname": "Li",
        "given_name": "Jing"
      },
      {
        "surname": "Lai",
        "given_name": "Zhihui"
      },
      {
        "surname": "Du",
        "given_name": "Bo"
      },
      {
        "surname": "Zhang",
        "given_name": "Lefei"
      }
    ]
  },
  {
    "title": "Exploiting the stimuli encoding scheme of evolving Spiking Neural Networks for stream learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.021",
    "abstract": "Stream data processing has lately gained momentum with the arrival of new Big Data scenarios and applications dealing with continuously produced information flows. Unfortunately, traditional machine learning algorithms are not prepared to tackle the specific challenges imposed by data stream processing, such as the need for learning incrementally, limited memory and processing time requirements, and adaptation to non-stationary data, among others. To face these paradigms, Spiking Neural Networks have emerged as one of the most promising stream learning techniques, with variants such as Evolving Spiking Neural Networks capable of efficiently addressing many of these challenges. Interestingly, these networks resort to a particular population encoding scheme – Gaussian Receptive Fields – to transform the incoming stimuli into temporal spikes. The study presented in this manuscript sheds light on the predictive potential of this encoding scheme, focusing on how it can be applied as a computationally lightweight, model-agnostic preprocessing step for data stream learning. We provide informed intuition to unveil under which circumstances the aforementioned population encoding method yields effective prediction gains in data stream classification with respect to the case where no preprocessing is performed. Results obtained for a variety of stream learning models and both synthetic and real stream datasets are discussed to empirically buttress the capability of Gaussian Receptive Fields to boost the predictive performance of stream learning methods, spanning further research towards extrapolating our findings to other machine learning problems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303892",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Concept drift",
      "Data pre-processing",
      "Data stream",
      "Data stream mining",
      "Demography",
      "Encoding (memory)",
      "Machine learning",
      "Population",
      "Preprocessor",
      "Sociology",
      "Spiking neural network",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Lobo",
        "given_name": "Jesus L."
      },
      {
        "surname": "Oregi",
        "given_name": "Izaskun"
      },
      {
        "surname": "Bifet",
        "given_name": "Albert"
      },
      {
        "surname": "Del Ser",
        "given_name": "Javier"
      }
    ]
  },
  {
    "title": "A new fixed-time stability theorem and its application to the fixed-time synchronization of neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.028",
    "abstract": "In this paper, we derive a new fixed-time stability theorem based on definite integral, variable substitution and some inequality techniques. The fixed-time stability criterion and the upper bound estimate formula for the settling time are different from those in the existing fixed-time stability theorems. Based on the new fixed-time stability theorem, the fixed-time synchronization of neural networks is investigated by designing feedback controller, and sufficient conditions are derived to guarantee the fixed-time synchronization of neural networks. To show the usability and superiority of the obtained theoretical results, we propose a secure communication scheme based on the fixed-time synchronization of neural networks. Numerical simulations illustrate that the new upper bound estimate formula for the settling time is much tighter than those in the existing fixed-time stability theorems. Moreover, the plaintext signals can be recovered according to the new fixed-time stability theorem, while the plaintext signals cannot be recovered according to the existing fixed-time stability theorems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304307",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Discrete mathematics",
      "Engineering",
      "Fixed point",
      "Fixed-point theorem",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Settling time",
      "Stability (learning theory)",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Chuan"
      },
      {
        "surname": "Li",
        "given_name": "Lixiang"
      },
      {
        "surname": "Peng",
        "given_name": "Haipeng"
      },
      {
        "surname": "Yang",
        "given_name": "Yixian"
      },
      {
        "surname": "Mi",
        "given_name": "Ling"
      },
      {
        "surname": "Zhao",
        "given_name": "Hui"
      }
    ]
  },
  {
    "title": "On the minimax optimality and superiority of deep neural network learning over sparse parameter spaces",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.014",
    "abstract": "Deep learning has been applied to various tasks in the field of machine learning and has shown superiority to other common procedures such as kernel methods. To provide a better theoretical understanding of the reasons for its success, we discuss the performance of deep learning and other methods on a nonparametric regression problem with a Gaussian noise. Whereas existing theoretical studies of deep learning have been based mainly on mathematical theories of well-known function classes such as Hölder and Besov classes, we focus on function classes with discontinuity and sparsity, which are those naturally assumed in practice. To highlight the effectiveness of deep learning, we compare deep learning with a class of linear estimators representative of a class of shallow estimators. It is shown that the minimax risk of a linear estimator on the convex hull of a target function class does not differ from that of the original target function class. This results in the suboptimality of linear methods over a simple but non-convex function class, on which deep learning can attain nearly the minimax-optimal rate. In addition to this extreme case, we consider function classes with sparse wavelet coefficients. On these function classes, deep learning also attains the minimax rate up to log factors of the sample size, and linear methods are still suboptimal if the assumed sparsity is strong. We also point out that the parameter sharing of deep neural networks can remarkably reduce the complexity of the model in our setting.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930406X",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Deep learning",
      "Estimator",
      "Evolutionary biology",
      "Function (biology)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Minimax",
      "Smoothness",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Hayakawa",
        "given_name": "Satoshi"
      },
      {
        "surname": "Suzuki",
        "given_name": "Taiji"
      }
    ]
  },
  {
    "title": "Extreme learning machine for a new hybrid morphological/linear perceptron",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.003",
    "abstract": "Morphological neural networks (MNNs) can be characterized as a class of artificial neural networks that perform an operation of mathematical morphology at every node, possibly followed by the application of an activation function. Morphological perceptrons (MPs) and (gray-scale) morphological associative memories are among the most widely known MNN models. Since their neuronal aggregation functions are not differentiable, classical methods of non-linear optimization can in principle not be directly applied in order to train these networks. The same observation holds true for hybrid morphological/linear perceptrons and other related models. Circumventing these problems of non-differentiability, this paper introduces an extreme learning machine approach for training a hybrid morphological/linear perceptron, whose morphological components were drawn from previous MP models. We apply the resulting model to a number of well-known classification problems from the literature and compare the performance of our model with the ones of several related models, including some recent MNNs and hybrid morphological/linear neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303958",
    "keywords": [
      "Activation function",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Differentiable function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Perceptron"
    ],
    "authors": [
      {
        "surname": "Sussner",
        "given_name": "Peter"
      },
      {
        "surname": "Campiotti",
        "given_name": "Israel"
      }
    ]
  },
  {
    "title": "Minimum variance-embedded deep kernel regularized least squares method for one-class classification and its applications to biomedical data",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.001",
    "abstract": "Deep kernel learning has been well explored for multi-class classification tasks; however, relatively less work is done for one-class classification (OCC). OCC needs samples from only one class to train the model. Most recently, kernel regularized least squares (KRL) method-based deep architecture is developed for the OCC task. This paper introduces a novel extension of this method by embedding minimum variance information within this architecture. This embedding improves the generalization capability of the classifier by reducing the intra-class variance. In contrast to traditional deep learning methods, this method can effectively work with small-size datasets. We conduct a comprehensive set of experiments on 18 benchmark datasets (13 biomedical and 5 other datasets) to demonstrate the performance of the proposed classifier. We compare the results with 16 state-of-the-art one-class classifiers. Further, we also test our method for 2 real-world biomedical datasets viz.; detection of Alzheimer’s disease from structural magnetic resonance imaging data and detection of breast cancer from histopathological images. Proposed method exhibits more than 5% F 1 score compared to existing state-of-the-art methods for various biomedical benchmark datasets. This makes it viable for application in biomedical fields where relatively less amount of data is available.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303934",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Combinatorics",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Embedding",
      "Geodesy",
      "Geography",
      "Kernel (algebra)",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Test set"
    ],
    "authors": [
      {
        "surname": "Gautam",
        "given_name": "Chandan"
      },
      {
        "surname": "Mishra",
        "given_name": "Pratik K."
      },
      {
        "surname": "Tiwari",
        "given_name": "Aruna"
      },
      {
        "surname": "Richhariya",
        "given_name": "Bharat"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      },
      {
        "surname": "Wang",
        "given_name": "Shuihua"
      },
      {
        "surname": "Tanveer",
        "given_name": "M."
      }
    ]
  },
  {
    "title": "A novel multi-modal machine learning based approach for automatic classification of EEG recordings in dementia",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.006",
    "abstract": "Electroencephalographic (EEG) recordings generate an electrical map of the human brain that are useful for clinical inspection of patients and in biomedical smart Internet-of-Things (IoT) and Brain-Computer Interface (BCI) applications. From a signal processing perspective, EEGs yield a nonlinear and nonstationary, multivariate representation of the underlying neural circuitry interactions. In this paper, a novel multi-modal Machine Learning (ML) based approach is proposed to integrate EEG engineered features for automatic classification of brain states. EEGs are acquired from neurological patients with Mild Cognitive Impairment (MCI) or Alzheimer’s disease (AD) and the aim is to discriminate Healthy Control (HC) subjects from patients. Specifically, in order to effectively cope with nonstationarities, 19-channels EEG signals are projected into the time–frequency (TF) domain by means of the Continuous Wavelet Transform (CWT) and a set of appropriate features (denoted as CWT features) are extracted from δ , θ , α 1 , α 2 , β EEG sub-bands. Furthermore, to exploit nonlinear phase-coupling information of EEG signals, higher order statistics (HOS) are extracted from the bispectrum (BiS) representation. BiS generates a second set of features (denoted as BiS features) which are also evaluated in the five EEG sub-bands. The CWT and BiS features are fed into a number of ML classifiers to perform both 2-way (AD vs. HC, AD vs. MCI, MCI vs. HC) and 3-way (AD vs. MCI vs. HC) classifications. As an experimental benchmark, a balanced EEG dataset that includes 63 AD, 63 MCI and 63 HC is analyzed. Comparative results show that when the concatenation of CWT and BiS features (denoted as multi-modal (CWT+BiS) features) is used as input, the Multi-Layer Perceptron (MLP) classifier outperforms all other models, specifically, the Autoencoder (AE), Logistic Regression (LR) and Support Vector Machine (SVM). Consequently, our proposed multi-modal ML scheme can be considered a viable alternative to state-of-the-art computationally intensive deep learning approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303983",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Dementia",
      "Disease",
      "Electroencephalography",
      "Machine learning",
      "Medicine",
      "Modal",
      "Neuroscience",
      "Pathology",
      "Pattern recognition (psychology)",
      "Polymer chemistry",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Ieracitano",
        "given_name": "Cosimo"
      },
      {
        "surname": "Mammone",
        "given_name": "Nadia"
      },
      {
        "surname": "Hussain",
        "given_name": "Amir"
      },
      {
        "surname": "Morabito",
        "given_name": "Francesco C."
      }
    ]
  },
  {
    "title": "The role of coupling connections in a model of the cortico-basal ganglia-thalamocortical neural loop for the generation of beta oscillations",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.12.021",
    "abstract": "Excessive neural synchronization in the cortico-basal ganglia-thalamocortical circuits in the beta ( β ) frequency range (12–35 Hz) is closely associated with dopamine depletion in Parkinson’s disease (PD) and correlated with movement impairments, but the neural basis remains unclear. In this work, we establish a double-oscillator neural mass model for the cortico-basal ganglia-thalamocortical closed-loop system and explore the impacts of dopamine depletion induced changes in coupling connections within or between the two oscillators on neural activities within the loop. Spectral analysis of the neural mass activities revealed that the power and frequency of their principal components are greatly dependent on the coupling strengths between nuclei. We found that the increased intra-coupling in the basal ganglia-thalamic (BG-Th) oscillator contributes to increased oscillations in the lower β frequency band (12–25 Hz), while increased intra-coupling in the cortical oscillator mainly contributes to increased oscillations in the upper β frequency band (26–35 Hz). Interestingly, pathological upper β oscillations in the cortical oscillator may be another origin of the lower β oscillations in the BG-Th oscillator, in addition to increased intra-coupling strength within the BG-Th network. Lower β oscillations in the BG-Th oscillator can also change the dominant oscillation frequency of a cortical nucleus from the upper to the lower β band. Thus, this work may pave the way towards revealing a possible neural basis underlying the Parkinsonian state.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019304216",
    "keywords": [
      "Basal ganglia",
      "Biology",
      "Central nervous system",
      "Coupling (piping)",
      "Dopamine",
      "Genetics",
      "Materials science",
      "Metallurgy",
      "Neuroscience",
      "Oscillation (cell signaling)",
      "Physics"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Chen"
      },
      {
        "surname": "Zhou",
        "given_name": "Changsong"
      },
      {
        "surname": "Wang",
        "given_name": "Jiang"
      },
      {
        "surname": "Fietkiewicz",
        "given_name": "Chris"
      },
      {
        "surname": "Loparo",
        "given_name": "Kenneth A."
      }
    ]
  },
  {
    "title": "Discriminative margin-sensitive autoencoder for collective multi-view disease analysis",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.013",
    "abstract": "Medical prediction is always collectively determined based on bioimages collected from different sources or various clinical characterizations described from multiple physiological features. Notably, learning intrinsic structures from multiple heterogeneous features is significant but challenging in multi-view disease understanding. Different from existing methods that separately deal with each single view, this paper proposes a discriminative Margin-Sensitive Autoencoder (MSAE) framework for automated Alzheimer’s disease (AD) diagnosis and accurate protein fold recognition. Generally, our MSAE aims to collaboratively explore the complementary properties of multi-view bioimage features in a semantic-sensitive encoder–decoder paradigm, where the discriminative semantic space is explicitly constructed in a margin-scalable regression model. Specifically, we develop a semantic-sensitive autoencoder, where an encoder projects multi-view visual features into the common semantic-aware latent space, and a decoder is exerted as an additional constraint to reconstruct the respective visual features. In particular, the importance of different views is adaptively weighted by self-adjusting learning scheme, such that their underlying correlations and complementary characteristics across multiple views are simultaneously preserved into the latent common representations. Moreover, a flexible semantic space is formulated by a margin-scalable support vector machine to improve the discriminability of the learning model. Importantly, correntropy induced metric is exploited as a robust regularization measurement to better control outliers for effective classification. A half-quadratic minimization and alternating learning strategy are devised to optimize the resulting framework such that each subproblem exists a closed-form solution in each iterative minimization phase. Extensive experimental results performed on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) datasets show that our MSAE can achieve superior performances for both binary and multi-class classification in AD diagnosis, and evaluations on protein folds demonstrate that our method can achieve very encouraging performance on protein structure recognition, outperforming the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303533",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Computer science",
      "Database",
      "Deep learning",
      "Discriminative model",
      "Encoder",
      "Feature learning",
      "Machine learning",
      "Margin (machine learning)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Regularization (linguistics)",
      "Scalability",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Zheng"
      },
      {
        "surname": "Zhu",
        "given_name": "Qi"
      },
      {
        "surname": "Xie",
        "given_name": "Guo-Sen"
      },
      {
        "surname": "Chen",
        "given_name": "Yi"
      },
      {
        "surname": "Li",
        "given_name": "Zhengming"
      },
      {
        "surname": "Wang",
        "given_name": "Shuihua"
      }
    ]
  },
  {
    "title": "A complementary learning systems approach to temporal difference learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.011",
    "abstract": "Complementary Learning Systems (CLS) theory suggests that the brain uses a ’neocortical’ and a ’hippocampal’ learning system to achieve complex behaviour. These two systems are complementary in that the ’neocortical’ system relies on slow learning of distributed representations while the ’hippocampal’ system relies on fast learning of pattern-separated representations. Both of these systems project to the striatum, which is a key neural structure in the brain’s implementation of Reinforcement Learning (RL). Current deep RL approaches share similarities with a ’neocortical’ system because they slowly learn distributed representations through backpropagation in Deep Neural Networks (DNNs). An ongoing criticism of such approaches is that they are data inefficient and lack flexibility. CLS theory suggests that the addition of a ’hippocampal’ system could address these criticisms. In the present study we propose a novel algorithm known as Complementary Temporal Difference Learning (CTDL), which combines a DNN with a Self-Organizing Map (SOM) to obtain the benefits of both a ’neocortical’ and a ’hippocampal’ system. Key features of CTDL include the use of Temporal Difference (TD) error to update a SOM and the combination of a SOM and DNN to calculate action values. We evaluate CTDL on Grid World, Cart–Pole and Continuous Mountain Car tasks and show several benefits over the classic Deep Q-Network (DQN) approach. These results demonstrate (1) the utility of complementary learning systems for the evaluation of actions, (2) that the TD error signal is a useful form of communication between the two systems and (3) that our approach extends to both discrete and continuous state and action spaces.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303338",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Deep learning",
      "Flexibility (engineering)",
      "Key (lock)",
      "Machine learning",
      "Mathematics",
      "Reinforcement learning",
      "Statistics",
      "Temporal difference learning"
    ],
    "authors": [
      {
        "surname": "Blakeman",
        "given_name": "Sam"
      },
      {
        "surname": "Mareschal",
        "given_name": "Denis"
      }
    ]
  },
  {
    "title": "Joint Ranking SVM and Binary Relevance with robust Low-rank learning for multi-label classification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.002",
    "abstract": "Multi-label classification studies the task where each example belongs to multiple labels simultaneously. As a representative method, Ranking Support Vector Machine (Rank-SVM) aims to minimize the Ranking Loss and can also mitigate the negative influence of the class-imbalance issue. However, due to its stacking-style way for thresholding, it may suffer error accumulation and thus reduces the final classification performance. Binary Relevance (BR) is another typical method, which aims to minimize the Hamming Loss and only needs one-step learning. Nevertheless, it might have the class-imbalance issue and does not take into account label correlations. To address the above issues, we propose a novel multi-label classification model, which joints Ranking support vector machine and Binary Relevance with robust Low-rank learning (RBRL). RBRL inherits the ranking loss minimization advantages of Rank-SVM, and thus overcomes the disadvantages of BR suffering the class-imbalance issue and ignoring the label correlations. Meanwhile, it utilizes the hamming loss minimization and one-step learning advantages of BR, and thus tackles the disadvantages of Rank-SVM including another thresholding learning step. Besides, a low-rank constraint is utilized to further exploit high-order label correlations under the assumption of low dimensional label space. Furthermore, to achieve nonlinear multi-label classifiers, we derive the kernelization RBRL. Two accelerated proximal gradient methods (APG) are used to solve the optimization problems efficiently. Extensive comparative experiments with several state-of-the-art methods illustrate a highly competitive or superior performance of our method RBRL.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303247",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Binary classification",
      "Combinatorics",
      "Computer science",
      "Hamming distance",
      "Image (mathematics)",
      "Learning to rank",
      "Machine learning",
      "Mathematics",
      "Multi-label classification",
      "Pattern recognition (psychology)",
      "Rank (graph theory)",
      "Ranking (information retrieval)",
      "Ranking SVM",
      "Support vector machine",
      "Thresholding"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Guoqiang"
      },
      {
        "surname": "Zheng",
        "given_name": "Ruobing"
      },
      {
        "surname": "Tian",
        "given_name": "Yingjie"
      },
      {
        "surname": "Liu",
        "given_name": "Dalian"
      }
    ]
  },
  {
    "title": "ℓ 1 -gain filter design of discrete-time positive neural networks with mixed delays",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.004",
    "abstract": "This paper mainly focuses on the filter design with ℓ 1 -gain disturbance attenuation performance for a class of discrete-time positive neural networks. Discrete and distributed time-varying delays occurring in neuron transmission are taken into account. Especially, the probabilistic distribution of distributed delays is described by a Bernoulli random process in the system model. First, criteria on the positiveness and the unique equilibrium of discrete-time neural networks are presented. Second, through linear Lyapunov method, sufficient conditions for globally asymptotic stability with ℓ 1 -gain disturbance attenuation performance of positive neural networks are proposed. Third, using the results obtained above, criteria on ℓ 1 -gain stability of the established filtering error system are presented, based on which a linear programming (LP) approach is put forward to design the desired positive filter. Finally, two examples of applications to water distribution network and genetic regulatory network are given to demonstrate the effectiveness and applicability of the derived results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303260",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Filter (signal processing)",
      "Machine learning",
      "Mathematics"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Shunyuan"
      },
      {
        "surname": "Zhang",
        "given_name": "Yijun"
      },
      {
        "surname": "Zhang",
        "given_name": "Baoyong"
      }
    ]
  },
  {
    "title": "Effects of infinite occurrence of hybrid impulses with quasi-synchronization of parameter mismatched neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.007",
    "abstract": "This article is deeply concerned with the effects of hybrid impulses on quasi-synchronization of neural networks with mixed time-varying delays and parameter mismatches. Hybrid impulses allow synchronizing as well as desynchronizing impulses in one impulsive sequence, so their infinite time occurrence with the system may destroy the synchronization process. Therefore, the effective hybrid impulsive controller has been designed to deal with the difficulties in achieving the quasi-synchronization under the effects of hybrid impulses, which occur all the time, but their density of occurrence gradually decrease. In addition, the new concepts of average impulsive interval and average impulsive gain have been applied to cope with the simultaneous existence of synchronizing and desynchronizing impulses. Based on the Lyapunov method together with the extended comparison principle and the formula of variation of parameters for mixed time-varying delayed impulsive system, the delay-dependent sufficient criteria of quasi-synchronization have been derived for two separate cases, viz., T a < ∞ and T a = ∞ . Finally, the efficiency of the theoretical results has been illustrated by providing two numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303296",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Interval (graph theory)",
      "Lyapunov function",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Process (computing)",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Synchronizing",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Kumar",
        "given_name": "Rakesh"
      },
      {
        "surname": "Das",
        "given_name": "Subir"
      },
      {
        "surname": "Cao",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Affinity and class probability-based fuzzy support vector machine for imbalanced data sets",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.016",
    "abstract": "The learning problem from imbalanced data sets poses a major challenge in data mining community. Although conventional support vector machine can generally show relatively robust performance in dealing with the classification problems of imbalanced data sets, it treats all training samples with the same contribution for learning, which results in the final decision boundary biasing toward the majority class especially in the presence of outliers or noises. In this paper, we propose a new affinity and class probability-based fuzzy support vector machine technique (ACFSVM). The affinity of a majority class sample is calculated according to support vector description domain (SVDD) model trained only by the given majority class training samples in kernel space similar to that used for FSVM learning. The obtained affinity can be used for identifying possible outliers and some border samples existing in the majority class training samples. In order to eliminate the effect of noises, we employ the kernel k -nearest neighbor method to determine the class probability of the majority class samples in the same kernel space as before. The samples with lower class probabilities are more likely to be noises and their contribution for learning seems to be reduced by their low memberships constructed by combining the affinities and the class probabilities. Thus, ACFSVM can pay more attention to the majority class samples with higher affinities and class probabilities while reducing their effects of the ones with lower affinities and class probabilities, eventually skewing the final classification boundary toward the majority class. In addition, the minority class samples are assigned relative high memberships to guarantee their importance for the model learning. The extensive experimental results on the different imbalanced datasets from UCI repository demonstrate that the proposed approach can achieve better generalization performance in terms of G-Mean, F-Measure, and AUC as compared to the other existing imbalanced dataset classification techniques.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303387",
    "keywords": [
      "Affinities",
      "Artificial intelligence",
      "Boundary (topology)",
      "Chemistry",
      "Class (philosophy)",
      "Combinatorics",
      "Computer science",
      "Decision boundary",
      "Kernel (algebra)",
      "Kernel method",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "One-class classification",
      "Outlier",
      "Pattern recognition (psychology)",
      "Stereochemistry",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Tao",
        "given_name": "Xinmin"
      },
      {
        "surname": "Li",
        "given_name": "Qing"
      },
      {
        "surname": "Ren",
        "given_name": "Chao"
      },
      {
        "surname": "Guo",
        "given_name": "Wenjie"
      },
      {
        "surname": "He",
        "given_name": "Qing"
      },
      {
        "surname": "Liu",
        "given_name": "Rui"
      },
      {
        "surname": "Zou",
        "given_name": "Junrong"
      }
    ]
  },
  {
    "title": "Perceptrons from memristors",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.013",
    "abstract": "Memristors, resistors with memory whose outputs depend on the history of their inputs, have been used with success in neuromorphic architectures, particularly as synapses and non-volatile memories. However, to the best of our knowledge, no model for a network in which both the synapses and the neurons are implemented using memristors has been proposed so far. In the present work we introduce models for single and multilayer perceptrons based exclusively on memristors. We adapt the delta rule to the memristor-based single-layer perceptron and the backpropagation algorithm to the memristor-based multilayer perceptron. Our results show that both perform as expected for perceptrons, including satisfying Minsky–Papert’s theorem. As a consequence of the Universal Approximation Theorem, they also show that memristors are universal function approximators. By using memristors for both the neurons and the synapses, our models pave the way for novel memristor-based neural network architectures and algorithms. A neural network based on memristors could show advantages in terms of energy conservation and open up possibilities for other learning systems to be adapted to a memristor-based paradigm, both in the classical and quantum learning realms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303351",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Electrical engineering",
      "Engineering",
      "Memristor",
      "Pattern recognition (psychology)",
      "Perceptron"
    ],
    "authors": [
      {
        "surname": "Silva",
        "given_name": "Francisco"
      },
      {
        "surname": "Sanz",
        "given_name": "Mikel"
      },
      {
        "surname": "Seixas",
        "given_name": "João"
      },
      {
        "surname": "Solano",
        "given_name": "Enrique"
      },
      {
        "surname": "Omar",
        "given_name": "Yasser"
      }
    ]
  },
  {
    "title": "Global Mittag-Leffler stability and synchronization of discrete-time fractional-order complex-valued neural networks with time delay",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.004",
    "abstract": "Without decomposing complex-valued systems into real-valued systems, this paper investigates existence, uniqueness, global Mittag-Leffler stability and global Mittag-Leffler synchronization of discrete-time fractional-order complex-valued neural networks (FCVNNs) with time delay. Inspired by Lyapunov’s direct method on continuous-time systems, a class of discrete-time FCVNNs is further discussed by employing the fractional-order extension of Lyapunov’s direct method. Firstly, by means of contraction mapping theory and Cauchy’s inequality, a sufficient condition is presented to ascertain the existence and uniqueness of the equilibrium point for discrete-time FCVNNs. Then, based on the theory of discrete fractional calculus, discrete Laplace transform, the theory of complex functions and discrete Mittag-Leffler functions, a sufficient condition is established for global Mittag-Leffler stability of the proposed networks. Additionally, by applying the Lyapunov’s direct method and designing a effective control scheme, the sufficient criterion is derived to ensure the global Mittag-Leffler synchronization of discrete-time FCVNNs. Finally, two numerical examples are also presented to manifest the feasibility and validity of the obtained results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303430",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Fractional calculus",
      "Laplace transform",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Statistics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Uniqueness"
    ],
    "authors": [
      {
        "surname": "You",
        "given_name": "Xingxing"
      },
      {
        "surname": "Song",
        "given_name": "Qiankun"
      },
      {
        "surname": "Zhao",
        "given_name": "Zhenjiang"
      }
    ]
  },
  {
    "title": "A review of learning in biologically plausible spiking neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.036",
    "abstract": "Artificial neural networks have been used as a powerful processing tool in various areas such as pattern recognition, control, robotics, and bioinformatics. Their wide applicability has encouraged researchers to improve artificial neural networks by investigating the biological brain. Neurological research has significantly progressed in recent years and continues to reveal new characteristics of biological neurons. New technologies can now capture temporal changes in the internal activity of the brain in more detail and help clarify the relationship between brain activity and the perception of a given stimulus. This new knowledge has led to a new type of artificial neural network, the Spiking Neural Network (SNN), that draws more faithfully on biological properties to provide higher processing abilities. A review of recent developments in learning of spiking neurons is presented in this paper. First the biological background of SNN learning algorithms is reviewed. The important elements of a learning algorithm such as the neuron model, synaptic plasticity, information encoding and SNN topologies are then presented. Then, a critical review of the state-of-the-art learning algorithms for SNNs using single and multiple spikes is presented. Additionally, deep spiking neural networks are reviewed, and challenges and opportunities in the SNN field are discussed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303181",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biological network",
      "Biological neural network",
      "Biology",
      "Computational biology",
      "Computer science",
      "Deep learning",
      "Machine learning",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Taherkhani",
        "given_name": "Aboozar"
      },
      {
        "surname": "Belatreche",
        "given_name": "Ammar"
      },
      {
        "surname": "Li",
        "given_name": "Yuhua"
      },
      {
        "surname": "Cosma",
        "given_name": "Georgina"
      },
      {
        "surname": "Maguire",
        "given_name": "Liam P."
      },
      {
        "surname": "McGinnity",
        "given_name": "T.M."
      }
    ]
  },
  {
    "title": "Spiking Neural Networks applied to the classification of motor tasks in EEG signals",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.037",
    "abstract": "Motivated by the recent progress of Spiking Neural Network (SNN) models in pattern recognition, we report on the development and evaluation of brain signal classifiers based on SNNs. The work shows the capabilities of this type of Spiking Neurons in the recognition of motor imagery tasks from EEG signals and compares their performance with other traditional classifiers commonly used in this application. This work includes two stages: the first stage consists of comparing the performance of the SNN models against some traditional neural network models. The second stage, compares the SNN models performance in two input conditions: input features with constant values and input features with temporal information. The EEG signals employed in this work represent five motor imagery tasks: i.e. rest, left hand, right hand, foot and tongue movements. These EEG signals were obtained from a public database provided by the Technological University of Graz (Brunner et al., 2008). The feature extraction stage was performed by applying two algorithms: power spectral density and wavelet decomposition. Likewise, this work uses raw EEG signals for the second stage of the problem solution. All of the models were evaluated in the classification between two motor imagery tasks. This work demonstrates that with a smaller number of Spiking neurons, simple problems can be solved. Better results are obtained by using patterns with temporal information, thereby exploiting the capabilities of the SNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303193",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Brain–computer interface",
      "Computer science",
      "Electroencephalography",
      "Feature extraction",
      "Motor imagery",
      "Pattern recognition (psychology)",
      "Programming language",
      "Psychiatry",
      "Psychology",
      "SIGNAL (programming language)",
      "Speech recognition",
      "Spiking neural network",
      "Wavelet"
    ],
    "authors": [
      {
        "surname": "Virgilio G.",
        "given_name": "Carlos D."
      },
      {
        "surname": "Sossa A.",
        "given_name": "Juan H."
      },
      {
        "surname": "Antelis",
        "given_name": "Javier M."
      },
      {
        "surname": "Falcón",
        "given_name": "Luis E."
      }
    ]
  },
  {
    "title": "A smoothing neural network for minimization l 1 - l p in sparse signal reconstruction with measurement noises",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.006",
    "abstract": "This paper investigates a smoothing neural network (SNN) to solve a robust sparse signal reconstruction in compressed sensing (CS), where the objective function is nonsmooth l 1 -norm and the feasible set satisfies an inequality of l p -norm 2 ≥ p ≥ 1 which is used for measuring residual errors. With a smoothing approximate technique, the non-smooth and non-Lipschitz continuous issues of the l 1 -norm and the gradient of l p -norm can be solved efficiently. We propose a SNN which is modeled by a differential equation and give its circuit implementation. In this case, we prove the proposed SNN converges to the optimal of considered problem. Simulation results are discussed to demonstrate the efficiency of the proposed algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303284",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Law",
      "Lipschitz continuity",
      "Mathematical optimization",
      "Mathematics",
      "Minification",
      "Norm (philosophy)",
      "Political science",
      "Pure mathematics",
      "Smoothing"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "You"
      },
      {
        "surname": "He",
        "given_name": "Xing"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      },
      {
        "surname": "Huang",
        "given_name": "Junjian"
      },
      {
        "surname": "Li",
        "given_name": "Peng"
      }
    ]
  },
  {
    "title": "A human-in-the-loop deep learning paradigm for synergic visual evaluation in children",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.003",
    "abstract": "Visual development during early childhood is a vital process. Examining the visual acuity of children is essential for early detection of visual abnormalities, but performing visual examination in children is challenging. Here, we developed a human-in-the-loop deep learning (DL) paradigm that combines traditional vision examination and DL with integration of software and hardware, thus facilitating the execution of vision examinations, offsetting the shortcomings of human doctors, and improving the abilities of both DL and doctors to evaluate the vision of children. Because this paradigm contains two rounds (a human round and DL round), doctors can learn from DL and the two can mutually supervise each other such that the precision of the DL system in evaluating the visual acuity of children is improved. Based on DL-based object localization and image identification, the experiences of doctors and the videos captured in the first round, the DL system in the second round can simulate doctors in evaluating the visual acuity of children with a final accuracy of 75.54%. For comparison, we also assessed an automatic deep learning method that did not consider the experiences of doctors, but its performance was not satisfactory. This entire paradigm can evaluate the visual acuity of children more accurately than humans alone. Furthermore, the paradigm facilitates automatic evaluation of the vision of children with a wearable device.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303259",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Embedded system",
      "Human–computer interaction",
      "Medicine",
      "Operating system",
      "Ophthalmology",
      "Process (computing)",
      "Visual acuity",
      "Wearable computer"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Kai"
      },
      {
        "surname": "Li",
        "given_name": "Xiaoyan"
      },
      {
        "surname": "He",
        "given_name": "Lin"
      },
      {
        "surname": "Guo",
        "given_name": "Chong"
      },
      {
        "surname": "Yang",
        "given_name": "Yahan"
      },
      {
        "surname": "Dong",
        "given_name": "Zhou"
      },
      {
        "surname": "Yang",
        "given_name": "Haoqing"
      },
      {
        "surname": "Zhu",
        "given_name": "Yi"
      },
      {
        "surname": "Chen",
        "given_name": "Chuan"
      },
      {
        "surname": "Zhou",
        "given_name": "Xiaojing"
      },
      {
        "surname": "Li",
        "given_name": "Wangting"
      },
      {
        "surname": "Liu",
        "given_name": "Zhenzhen"
      },
      {
        "surname": "Wu",
        "given_name": "Xiaohang"
      },
      {
        "surname": "Liu",
        "given_name": "Xiyang"
      },
      {
        "surname": "Lin",
        "given_name": "Haotian"
      }
    ]
  },
  {
    "title": "A new learning paradigm for random vector functional-link network: RVFL+",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.039",
    "abstract": "In school, a teacher plays an important role in various classroom teaching patterns. Likewise to this human learning activity, the learning using privileged information (LUPI) paradigm provides additional information generated by the teacher to ’teach’ learning models during the training stage. Therefore, this novel learning paradigm is a typical Teacher–Student Interaction mechanism. This paper is the first to present a random vector functional link (RVFL) network based on the LUPI paradigm, called RVFL+. The novel RVFL+ incorporates the LUPI paradigm that can leverage additional source of information into the RVFL, which offers an alternative way to train the RVFL. Rather than simply combining two existing approaches, the newly-derived RVFL+ fills the gap between classical randomized neural networks and the newfashioned LUPI paradigm. Moreover, the proposed RVFL+ can perform in conjunction with the kernel trick for highly complicated nonlinear feature learning, termed KRVFL+. Furthermore, the statistical property of the proposed RVFL+ is investigated, and the authors present a sharp and high-quality generalization error bound based on the Rademacher complexity. Competitive experimental results on 14 real-world datasets illustrate the great effectiveness and efficiency of the novel RVFL+ and KRVFL+, which can achieve better generalization performance than state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303211",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Generalization",
      "Kernel (algebra)",
      "Leverage (statistics)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Peng-Bo"
      },
      {
        "surname": "Yang",
        "given_name": "Zhi-Xin"
      }
    ]
  },
  {
    "title": "Partition level multiview subspace clustering",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.010",
    "abstract": "Multiview clustering has gained increasing attention recently due to its ability to deal with multiple sources (views) data and explore complementary information between different views. Among various methods, multiview subspace clustering methods provide encouraging performance. They mainly integrate the multiview information in the space where the data points lie. Hence, their performance may be deteriorated because of noises existing in each individual view or inconsistent between heterogeneous features. For multiview clustering, the basic premise is that there exists a shared partition among all views. Therefore, the natural space for multiview clustering should be all partitions. Orthogonal to existing methods, we propose to fuse multiview information in partition level following two intuitive assumptions: (i) each partition is a perturbation of the consensus clustering; (ii) the partition that is close to the consensus clustering should be assigned a large weight. Finally, we propose a unified multiview subspace clustering model which incorporates the graph learning from each view, the generation of basic partitions, and the fusion of consensus partition. These three components are seamlessly integrated and can be iteratively boosted by each other towards an overall optimal solution. Experiments on four benchmark datasets demonstrate the efficacy of our approach against the state-of-the-art techniques.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303326",
    "keywords": [
      "Artificial intelligence",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Clustering high-dimensional data",
      "Combinatorics",
      "Computer science",
      "Consensus clustering",
      "Correlation clustering",
      "Data mining",
      "Graph",
      "Graph partition",
      "Mathematics",
      "Partition (number theory)",
      "Pattern recognition (psychology)",
      "Subspace topology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Kang",
        "given_name": "Zhao"
      },
      {
        "surname": "Zhao",
        "given_name": "Xinjia"
      },
      {
        "surname": "Peng",
        "given_name": "Chong"
      },
      {
        "surname": "Zhu",
        "given_name": "Hongyuan"
      },
      {
        "surname": "Zhou",
        "given_name": "Joey Tianyi"
      },
      {
        "surname": "Peng",
        "given_name": "Xi"
      },
      {
        "surname": "Chen",
        "given_name": "Wenyu"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      }
    ]
  },
  {
    "title": "The robustness-fidelity trade-off in Grow When Required neural networks performing continuous novelty detection",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.015",
    "abstract": "Novelty detection allows robots to recognise unexpected data in their sensory field and can thus be utilised in applications such as reconnaissance, surveillance, self-monitoring, etc. We assess the suitability of Grow When Required Neural Networks (GWRNNs) for detecting novel features in a robot’s visual input in the context of randomised physics-based simulation environments. We compare, for the first time, several GWRNN architectures, including new Plastic architectures in which the number of activated input connections for individual neurons is adjusted dynamically as the robot senses a varying number of salient environmental features. The networks are studied in both one-shot and continuous novelty reporting tasks and we demonstrate that there is a trade-off, not unique to this type of novelty detector, between robustness and fidelity. Robustness is achieved through generalisation over the input space which minimises the impact of network parameters on performance, whereas high fidelity results from learning detailed models of the input space and is especially important when a robot encounters multiple novelties consecutively or must detect that previously encountered objects have disappeared from the environment. We propose a number of improvements that could mitigate the robustness-fidelity trade-off and demonstrate one of them, where localisation information is added to the input data stream being monitored.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303375",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Electrical engineering",
      "Engineering",
      "Fidelity",
      "Gene",
      "High fidelity",
      "Machine learning",
      "Novelty",
      "Novelty detection",
      "Philosophy",
      "Robot",
      "Robustness (evolution)",
      "Telecommunications",
      "Theology"
    ],
    "authors": [
      {
        "surname": "Pitonakova",
        "given_name": "Lenka"
      },
      {
        "surname": "Bullock",
        "given_name": "Seth"
      }
    ]
  },
  {
    "title": "Multistability and attraction basins of discrete-time neural networks with nonmonotonic piecewise linear activation functions",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.005",
    "abstract": "This paper is concerned with multistability and attraction basins of discrete-time neural networks with nonmonotonic piecewise linear activation functions. Under some reasonable conditions, the addressed networks have ( 2 m + 1 ) n equilibrium points. ( m + 1 ) n of which are locally asymptotically stable, and the others are unstable. The attraction basins of the locally asymptotically stable equilibrium points are given in the form of hyperspherical regions. These results here, which include existence, uniqueness, locally asymptotical stability, instability and attraction basins of the multiple equilibrium points, generalize and improve the earlier publications. Finally, an illustrative example with numerical simulation is given to show the feasibility and the effectiveness of the theoretical results. The theoretical results and illustrative example indicate that the activation functions improve the storage capacity of neural networks significantly.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303272",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Attraction",
      "Computer science",
      "Differential equation",
      "Equilibrium point",
      "Exponential stability",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Multistability",
      "Nonlinear system",
      "Philosophy",
      "Physics",
      "Piecewise",
      "Piecewise linear function",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Stability theory",
      "Uniqueness"
    ],
    "authors": [
      {
        "surname": "Wan",
        "given_name": "Peng"
      },
      {
        "surname": "Sun",
        "given_name": "Dihua"
      },
      {
        "surname": "Zhao",
        "given_name": "Min"
      },
      {
        "surname": "Wan",
        "given_name": "Li"
      },
      {
        "surname": "Jin",
        "given_name": "Shuang"
      }
    ]
  },
  {
    "title": "A new learning paradigm for random vector functional-link network: RVFL+",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.039",
    "abstract": "In school, a teacher plays an important role in various classroom teaching patterns. Likewise to this human learning activity, the learning using privileged information (LUPI) paradigm provides additional information generated by the teacher to ’teach’ learning models during the training stage. Therefore, this novel learning paradigm is a typical Teacher–Student Interaction mechanism. This paper is the first to present a random vector functional link (RVFL) network based on the LUPI paradigm, called RVFL+. The novel RVFL+ incorporates the LUPI paradigm that can leverage additional source of information into the RVFL, which offers an alternative way to train the RVFL. Rather than simply combining two existing approaches, the newly-derived RVFL+ fills the gap between classical randomized neural networks and the newfashioned LUPI paradigm. Moreover, the proposed RVFL+ can perform in conjunction with the kernel trick for highly complicated nonlinear feature learning, termed KRVFL+. Furthermore, the statistical property of the proposed RVFL+ is investigated, and the authors present a sharp and high-quality generalization error bound based on the Rademacher complexity. Competitive experimental results on 14 real-world datasets illustrate the great effectiveness and efficiency of the novel RVFL+ and KRVFL+, which can achieve better generalization performance than state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303211",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Generalization",
      "Kernel (algebra)",
      "Leverage (statistics)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Peng-Bo"
      },
      {
        "surname": "Yang",
        "given_name": "Zhi-Xin"
      }
    ]
  },
  {
    "title": "Partition level multiview subspace clustering",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.010",
    "abstract": "Multiview clustering has gained increasing attention recently due to its ability to deal with multiple sources (views) data and explore complementary information between different views. Among various methods, multiview subspace clustering methods provide encouraging performance. They mainly integrate the multiview information in the space where the data points lie. Hence, their performance may be deteriorated because of noises existing in each individual view or inconsistent between heterogeneous features. For multiview clustering, the basic premise is that there exists a shared partition among all views. Therefore, the natural space for multiview clustering should be all partitions. Orthogonal to existing methods, we propose to fuse multiview information in partition level following two intuitive assumptions: (i) each partition is a perturbation of the consensus clustering; (ii) the partition that is close to the consensus clustering should be assigned a large weight. Finally, we propose a unified multiview subspace clustering model which incorporates the graph learning from each view, the generation of basic partitions, and the fusion of consensus partition. These three components are seamlessly integrated and can be iteratively boosted by each other towards an overall optimal solution. Experiments on four benchmark datasets demonstrate the efficacy of our approach against the state-of-the-art techniques.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303326",
    "keywords": [
      "Artificial intelligence",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Clustering high-dimensional data",
      "Combinatorics",
      "Computer science",
      "Consensus clustering",
      "Correlation clustering",
      "Data mining",
      "Graph",
      "Graph partition",
      "Mathematics",
      "Partition (number theory)",
      "Pattern recognition (psychology)",
      "Subspace topology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Kang",
        "given_name": "Zhao"
      },
      {
        "surname": "Zhao",
        "given_name": "Xinjia"
      },
      {
        "surname": "Peng",
        "given_name": "Chong"
      },
      {
        "surname": "Zhu",
        "given_name": "Hongyuan"
      },
      {
        "surname": "Zhou",
        "given_name": "Joey Tianyi"
      },
      {
        "surname": "Peng",
        "given_name": "Xi"
      },
      {
        "surname": "Chen",
        "given_name": "Wenyu"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      }
    ]
  },
  {
    "title": "New approach to global Mittag-Leffler synchronization problem of fractional-order quaternion-valued BAM neural networks based on a new inequality",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.017",
    "abstract": "In this paper, a novel kind of neural networks named fractional-order quaternion-valued bidirectional associative memory neural networks (FQVBAMNNs) is formulated. On one hand, applying Hamilton rules in quaternion multiplication which is essentially non-commutative, the system of FQVBAMNNs is separated into eight fractional-order real-valued systems. Meanwhile, the activation functions are considered to be quaternion-valued linear threshold ones which help to reduce the unnecessary computational complexity. On the other hand, based on fractional-order Lyapunov technology, a new fractional-order derivative inequality is established. Mainly by employing the new inequality technique, constructing three novel Lyapunov–Krasovskii functionals (LKFs) and designing simple linear controllers, the global Mittag-Leffler synchronization problems are investigated and the corresponding criteria are acquired for the system of FQVBAMNNs and its special cases such as fractional-order complex-valued BAM neural networks (FCVBAMNNs) and fractional-order real-valued BAM neural networks (FRVBAMNNs), respectively. Finally, two numerical examples are given to show the effectiveness and availability of the proposed results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303399",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Commutative property",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Economics",
      "Finance",
      "Fractional calculus",
      "Geometry",
      "Lyapunov function",
      "Mathematics",
      "Nonlinear system",
      "Order (exchange)",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Quaternion",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Jianying"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Yang",
        "given_name": "Xujun"
      },
      {
        "surname": "Zhong",
        "given_name": "Shouming"
      }
    ]
  },
  {
    "title": "Regularized correntropy criterion based semi-supervised ELM",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.030",
    "abstract": "Along with the explosive growing of data, semi-supervised learning attracts increasing attention in the past years due to its powerful capability in labeling unlabeled data and knowledge mining. As an emerging method, the semi-supervised extreme learning machine (SSELM), that builds on ELM, has been developed for data classification and shown superiorities in learning efficiency and accuracy. However, the optimization of SSELM as well as most of the other ELMs is generally based on the mean square error (MSE) criterion, which has been shown less effective in dealing with non-Gaussian noises. In this paper, a robust regularized correntropy criterion based SSELM (RC-SSELM) is developed. The optimization of the output weight matrix of RC-SSELM is derived by the fixed-point iteration based approach. A convergent analysis of the proposed RC-SSELM is presented based on the half-quadratic optimization technique. Experimental results on 4 synthetic datasets and 13 benchmark UCI datasets are provided to show the superiorities of the proposed RC-SSELM over SSELM and other state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303120",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Extreme learning machine",
      "Gaussian",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Jie"
      },
      {
        "surname": "Cao",
        "given_name": "Jiuwen"
      },
      {
        "surname": "Wang",
        "given_name": "Tianlei"
      },
      {
        "surname": "Xue",
        "given_name": "Anke"
      },
      {
        "surname": "Chen",
        "given_name": "Badong"
      }
    ]
  },
  {
    "title": "Multistability of switched neural networks with sigmoidal activation functions under state-dependent switching",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.012",
    "abstract": "This paper presents theoretical results on the multistability of switched neural networks with commonly used sigmoidal activation functions under state-dependent switching. The multistability analysis with such an activation function is difficult because state–space partition is not as straightforward as that with piecewise-linear activations. Sufficient conditions are derived for ascertaining the existence and stability of multiple equilibria. It is shown that the number of stable equilibria of an n -neuron switched neural networks is up to 3 n under given conditions. In contrast to existing multistability results with piecewise-linear activation functions, the results herein are also applicable to the equilibria at switching points. Four examples are discussed to substantiate the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930334X",
    "keywords": [
      "Activation function",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Mathematical analysis",
      "Mathematics",
      "Multistability",
      "Nonlinear system",
      "Physics",
      "Piecewise",
      "Piecewise linear function",
      "Quantum mechanics",
      "Sigmoid function",
      "State space",
      "Statistics",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Zhenyuan"
      },
      {
        "surname": "Ou",
        "given_name": "Shiqin"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Multi-label zero-shot human action recognition via joint latent ranking embedding",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.029",
    "abstract": "Human action recognition is one of the most challenging tasks in computer vision. Most of the existing works in human action recognition are limited to single-label classification. A real-world video stream, however, often contains multiple human actions. Such a video stream is usually annotated collectively with a set of relevant human action labels, which leads to a multi-label learning problem. Furthermore, there are a great number of meaningful human actions in reality but it would be extremely difficult, if not impossible, to collect/annotate sufficient video clips regarding all these human actions for training a supervised learning model. In this paper, we formulate a real-world human action recognition task as a multi-label zero-shot learning problem. To address this problem, a joint latent ranking embedding framework is proposed. Our framework holistically tackles the issue of unknown temporal boundaries between different actions within a video clip for multi-label learning and exploits the side information regarding the semantic relationship between different human actions for zero-shot learning. Specifically, our framework consists of two component neural networks for visual and semantic embedding respectively. Thus, multi-label zero-shot recognition is done by measuring relatedness scores of concerned action labels to a test video clip in the joint latent visual and semantic embedding spaces. We evaluate our framework in different settings, including a novel data split scheme designed especially for evaluating multi-label zero-shot learning. The experimental results on two weakly annotated multi-label human action datasets (i.e. Breakfast and Charades) demonstrate the effectiveness of our framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303119",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Economics",
      "Embedding",
      "Exploit",
      "Machine learning",
      "Management",
      "Pattern recognition (psychology)",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Ranking (information retrieval)",
      "Set (abstract data type)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Qian"
      },
      {
        "surname": "Chen",
        "given_name": "Ke"
      }
    ]
  },
  {
    "title": "Realistic spiking neural network: Non-synaptic mechanisms improve convergence in cell assembly",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.038",
    "abstract": "Learning in neural networks inspired by brain tissue has been studied for machine learning applications. However, existing works primarily focused on the concept of synaptic weight modulation, and other aspects of neuronal interactions, such as non-synaptic mechanisms, have been neglected. Non-synaptic interaction mechanisms have been shown to play significant roles in the brain, and four classes of these mechanisms can be highlighted: (i) electrotonic coupling; (ii) ephaptic interactions; (iii) electric field effects; and iv) extracellular ionic fluctuations. In this work, we proposed simple rules for learning inspired by recent findings in machine learning adapted to a realistic spiking neural network. We show that the inclusion of non-synaptic interaction mechanisms improves cell assembly convergence. By including extracellular ionic fluctuation represented by the extracellular electrodiffusion in the network, we showed the importance of these mechanisms to improve cell assembly convergence. Additionally, we observed a variety of electrophysiological patterns of neuronal activity, particularly bursting and synchronism when the convergence is improved.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930320X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biological system",
      "Biology",
      "Bursting",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Learning rule",
      "Neuroscience",
      "Spiking neural network",
      "Synaptic weight"
    ],
    "authors": [
      {
        "surname": "Depannemaecker",
        "given_name": "Damien"
      },
      {
        "surname": "Canton Santos",
        "given_name": "Luiz Eduardo"
      },
      {
        "surname": "Rodrigues",
        "given_name": "Antônio Márcio"
      },
      {
        "surname": "Scorza",
        "given_name": "Carla Alessandra"
      },
      {
        "surname": "Scorza",
        "given_name": "Fulvio Alexandre"
      },
      {
        "surname": "Almeida",
        "given_name": "Antônio-Carlos Guimarães de"
      }
    ]
  },
  {
    "title": "Local distinguishability aggrandizing network for human anomaly detection",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.002",
    "abstract": "With the growing demand for an intelligent system to prevent abnormal events, many methods have been proposed to detect and locate anomalous behaviors in surveillance videos. However, most of these methods contain two shortcomings mainly: distraction of the network and insufficient discriminating ability. In this paper, we propose a local distinguishability aggrandizing network (LDA-Net) in a supervised manner, consisting of a human detection module and an anomaly detection module. In the human detection module, we obtain segmented patches of specific human subjects and take them as the input of the latter module to focus the network on learning motion characteristics of each person. In addition, considering that the auxiliary information, such as the specific type of an action, can aggrandize the whole network to extract distinguishable detail features of normal and abnormal behaviors, the proposed anomaly detection module comprises a primary binary classification sub-branch and an auxiliary distinguishability aggrandizing sub-branch, through which we can jointly detect anomalies and recognize actions. To further reduce the misclassification of the extremely imbalanced datasets, we design a novel inhibition loss function and embed it into the auxiliary sub-branch of the anomaly detection module. Experiments on several public benchmark datasets for frame-level and pixel-level anomaly detection show that the proposed supervised LDA-Net achieves state-of-the-art results on UCSD Ped2 and Subway Exit datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303417",
    "keywords": [
      "Anomaly (physics)",
      "Anomaly detection",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Condensed matter physics",
      "Frame (networking)",
      "Geodesy",
      "Geography",
      "Pattern recognition (psychology)",
      "Physics",
      "Pixel",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Gong",
        "given_name": "Maoguo"
      },
      {
        "surname": "Zeng",
        "given_name": "Huimin"
      },
      {
        "surname": "Xie",
        "given_name": "Yu"
      },
      {
        "surname": "Li",
        "given_name": "Hao"
      },
      {
        "surname": "Tang",
        "given_name": "Zedong"
      }
    ]
  },
  {
    "title": "A consensus algorithm based on collective neurodynamic system for distributed optimization with linear and bound constraints",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.008",
    "abstract": "In this paper, an algorithm based on collective neurodynamic system is investigated for distributed constrained convex optimization, whose objective function is a sum of smooth convex functions and non-smooth L 1 -norm functions. Inspired by recent advances in distributed convex optimization, the continuous-time and discrete-time distributed optimization algorithms described by collective neurodynamic systems are proposed. In the systems, each of the smooth objective functions is allocated to each node as well as each of the L 1 -norm functions. However, the L 1 -norm functions are realized by projection operators. Meanwhile, each node satisfies the local linear and bound constraints. Then a connected network is constituted from all the nodes with consensus to find the optimal solutions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303302",
    "keywords": [
      "Algorithm",
      "Biology",
      "Computer science",
      "Convex function",
      "Convex optimization",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Geometry",
      "Law",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Node (physics)",
      "Norm (philosophy)",
      "Optimization problem",
      "Political science",
      "Regular polygon",
      "Structural engineering",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Yan"
      },
      {
        "surname": "Liu",
        "given_name": "Qingshan"
      }
    ]
  },
  {
    "title": "A review on neural network models of schizophrenia and autism spectrum disorder",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.014",
    "abstract": "This survey presents the most relevant neural network models of autism spectrum disorder and schizophrenia, from the first connectionist models to recent deep neural network architectures. We analyzed and compared the most representative symptoms with its neural model counterpart, detailing the alteration introduced in the network that generates each of the symptoms, and identifying their strengths and weaknesses. We additionally cross-compared Bayesian and free-energy approaches, as they are widely applied to model psychiatric disorders and share basic mechanisms with neural networks. Models of schizophrenia mainly focused on hallucinations and delusional thoughts using neural dysconnections or inhibitory imbalance as the predominating alteration. Models of autism rather focused on perceptual difficulties, mainly excessive attention to environment details, implemented as excessive inhibitory connections or increased sensory precision. We found an excessively tight view of the psychopathologies around one specific and simplified effect, usually constrained to the technical idiosyncrasy of the used network architecture. Recent theories and evidence on sensorimotor integration and body perception combined with modern neural network architectures could offer a broader and novel spectrum to approach these psychopathologies. This review emphasizes the power of artificial neural networks for modeling some symptoms of neurological disorders but also calls for further developing of these techniques in the field of computational psychiatry.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303363",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autism",
      "Autism spectrum disorder",
      "Cognitive science",
      "Computer science",
      "Connectionism",
      "Machine learning",
      "Neuroscience",
      "Perception",
      "Psychiatry",
      "Psychology",
      "Schizophrenia (object-oriented programming)"
    ],
    "authors": [
      {
        "surname": "Lanillos",
        "given_name": "Pablo"
      },
      {
        "surname": "Oliva",
        "given_name": "Daniel"
      },
      {
        "surname": "Philippsen",
        "given_name": "Anja"
      },
      {
        "surname": "Yamashita",
        "given_name": "Yuichi"
      },
      {
        "surname": "Nagai",
        "given_name": "Yukie"
      },
      {
        "surname": "Cheng",
        "given_name": "Gordon"
      }
    ]
  },
  {
    "title": "Learning Cascade Attention for fine-grained image classification",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.009",
    "abstract": "Fine-grained image classification is a challenging task due to the large inter-class difference and small intra-class difference. In this paper, we propose a novel Cascade Attention Model using the Deep Convolutional Neural Network to address this problem. Our method first leverages the Spatial Confusion Attention to identify ambiguous areas of the input image. Two constraint loss functions are proposed: the Spatial Mask loss and the Spatial And loss; Second, the Cross-network Attention, applying different pre-train parameters to the two stream architecture. Also, two novel loss functions called Cross-network Similarity loss and Satisfied Rank loss are proposed to make the two-stream networks reinforce each other and get better results. Finally, the Network Fusion Attention merges intermediate results with the novel entropy add strategy to obtain the final predictions. All of these modules can work together and can be trained end to end. Besides, different from previous works, our model is fully weak-supervised and fully paralleled, which leads to easier generalization and faster computation. We obtain the state-of-the-art performance on three challenge benchmark datasets (CUB-200-2011, FGVC-Aircraft and Flower 102) with results of 90.8%, 92.1%, and 98.5%, respectively. The model will be publicly available at https://github.com/billzyx/LCA-CNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303314",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Cascade",
      "Chemistry",
      "Chromatography",
      "Computation",
      "Computer science",
      "Computer security",
      "Contextual image classification",
      "Convolutional neural network",
      "Cross entropy",
      "Deep learning",
      "Generalization",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Network architecture",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Youxiang"
      },
      {
        "surname": "Li",
        "given_name": "Ruochen"
      },
      {
        "surname": "Yang",
        "given_name": "Yin"
      },
      {
        "surname": "Ye",
        "given_name": "Ning"
      }
    ]
  },
  {
    "title": "Person identification using fusion of iris and periocular deep features",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.11.009",
    "abstract": "A novel method for person identification based on the fusion of iris and periocular biometrics has been proposed in this paper. The challenges for image acquisition for Near-Infrared or Visual Wavelength lights under constrained and unconstrained environments have been considered here. The proposed system is divided into image preprocessing data augmentation followed by feature learning for classification components. In image preprocessing an annular iris, the portion is segmented out from an eyeball image and then transformed into a fixed-sized image region. The parameters of iris localization have been used to extract the local periocular region. Due to different imaging environments, the images suffer from various noise artifacts which create data insufficiency and complicate the recognition task. To overcome this situation, a novel method for data augmentation technique has been introduced here. For features extraction and classification tasks well-known, VGG16, ResNet50, and Inception-v3 CNN architectures have been employed. The performance due to iris and periocular are fused together to increase the performance of the recognition system. The extensive experimental results have been demonstrated in four benchmark iris databases namely: MMU1, UPOL, CASIA-Iris-distance, and UBIRIS.v2. The comparison with the state-of-the-art methods with respect to these databases shows the robustness and effectiveness of the proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930348X",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biochemistry",
      "Biology",
      "Biometrics",
      "Botany",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Feature extraction",
      "Gene",
      "Geodesy",
      "Geography",
      "IRIS (biosensor)",
      "Identification (biology)",
      "Iris recognition",
      "Pattern recognition (psychology)",
      "Preprocessor",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Umer",
        "given_name": "Saiyed"
      },
      {
        "surname": "Sardar",
        "given_name": "Alamgir"
      },
      {
        "surname": "Dhara",
        "given_name": "Bibhas Chandra"
      },
      {
        "surname": "Rout",
        "given_name": "Ranjeet Kumar"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      }
    ]
  },
  {
    "title": "A broad class of discrete-time hypercomplex-valued Hopfield neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.040",
    "abstract": "In this paper, we address the stability of a broad class of discrete-time hypercomplex-valued Hopfield-type neural networks. To ensure the neural networks belonging to this class always settle down at a stationary state, we introduce novel hypercomplex number systems referred to as real-part associative hypercomplex number systems. Real-part associative hypercomplex number systems generalize the well-known Cayley–Dickson algebras and real Clifford algebras and include the systems of real numbers, complex numbers, dual numbers, hyperbolic numbers, quaternions, tessarines, and octonions as particular instances. Apart from the novel hypercomplex number systems, we introduce a family of hypercomplex-valued activation functions called B -projection functions. Broadly speaking, a B -projection function projects the activation potential onto the set of all possible states of a hypercomplex-valued neuron. Using the theory presented in this paper, we confirm the stability analysis of several discrete-time hypercomplex-valued Hopfield-type neural networks from the literature. Moreover, we introduce and provide the stability analysis of a general class of Hopfield-type neural networks on Cayley–Dickson algebras.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303223",
    "keywords": [
      "Algebra over a field",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Computer science",
      "Discrete mathematics",
      "Geometry",
      "Hopfield network",
      "Hypercomplex number",
      "Machine learning",
      "Mathematics",
      "Projection (relational algebra)",
      "Pure mathematics",
      "Quaternion",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "de Castro",
        "given_name": "Fidelis Zanetti"
      },
      {
        "surname": "Valle",
        "given_name": "Marcos Eduardo"
      }
    ]
  },
  {
    "title": "Preface",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00025-3",
    "abstract": "Unknown",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000253",
    "keywords": [
      "Computer science"
    ],
    "authors": [
      {
        "surname": "Spiga",
        "given_name": "Sabina"
      },
      {
        "surname": "Sebastian",
        "given_name": "Abu"
      },
      {
        "surname": "Querlioz",
        "given_name": "Damien"
      },
      {
        "surname": "Rajendran",
        "given_name": "Bipin"
      }
    ]
  },
  {
    "title": "Using a deep convolutional neural network to predict 2017 ozone concentrations, 24 hours in advance",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.033",
    "abstract": "In this study, we use a deep convolutional neural network (CNN) to develop a model that predicts ozone concentrations 24 h in advance. We have evaluated the model for 21 continuous ambient monitoring stations (CAMS) across Texas. The inputs for the CNN model consist of meteorology (e.g., wind field, temperature) and air pollution concentrations (NO x and ozone) from the previous day. The model is trained for predicting next-day, 24-hour ozone concentrations. We acquired meteorological and air pollution data from 2014 to 2017 from the Texas Commission on Environmental Quality (TCEQ). For 19 of the 21 stations in the study, results show that the yearly index of agreement (IOA) is above 0.85, confirming the acceptable accuracy of the CNN model. The results also show the model performed well, even for stations with varying monthly trends of ozone concentrations (specifically CAMS-012, located in El-Paso, and CAMS-013, located in Fort Worth, both with IOA=0.89). In addition, to ensure that the model was robust, we tested it on stations where fewer meteorological variables are monitored. Although these stations have fewer input features, their performance is similar to that of other stations. However, despite its success at capturing daily trends, the model mostly underpredicts the daily maximum ozone, which provides a direction for future study and improvement. As this model predicts ozone concentrations 24 h in advance with greater accuracy and computationally fewer resources, it can serve as an early warning system for individuals susceptible to ozone and those engaging in outdoor activities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303156",
    "keywords": [
      "Air pollution",
      "Air quality index",
      "Atmospheric sciences",
      "Biology",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Ecology",
      "Environmental science",
      "Geography",
      "Geology",
      "Machine learning",
      "Meteorology",
      "Organic chemistry",
      "Ozone",
      "Pollution"
    ],
    "authors": [
      {
        "surname": "Sayeed",
        "given_name": "Alqamah"
      },
      {
        "surname": "Choi",
        "given_name": "Yunsoo"
      },
      {
        "surname": "Eslami",
        "given_name": "Ebrahim"
      },
      {
        "surname": "Lops",
        "given_name": "Yannic"
      },
      {
        "surname": "Roy",
        "given_name": "Anirban"
      },
      {
        "surname": "Jung",
        "given_name": "Jia"
      }
    ]
  },
  {
    "title": "Design Space Exploration of Hardware Spiking Neurons for Embedded Artificial Intelligence",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.024",
    "abstract": "Machine learning is yielding unprecedented interest in research and industry, due to recent success in many applied contexts such as image classification and object recognition. However, the deployment of these systems requires huge computing capabilities, thus making them unsuitable for embedded systems. To deal with this limitation, many researchers are investigating brain-inspired computing, which would be a perfect alternative to the conventional Von Neumann architecture based computers (CPU/GPU) that meet the requirements for computing performance, but not for energy-efficiency. Therefore, neuromorphic hardware circuits that are adaptable for both parallel and distributed computations need to be designed. In this paper, we focus on Spiking Neural Networks (SNNs) with a comprehensive study of neural coding methods and hardware exploration. In this context, we propose a framework for neuromorphic hardware design space exploration, which allows to define a suitable architecture based on application-specific constraints and starting from a wide variety of possible architectural choices. For this framework, we have developed a behavioral level simulator for neuromorphic hardware architectural exploration named NAXT. Moreover, we propose modified versions of the standard Rate Coding technique to make trade-offs with the Time Coding paradigm, which is characterized by the low number of spikes propagating in the network. Thus, we are able to reduce the number of spikes while keeping the same neuron’s model, which results in an SNN with fewer events to process. By doing so, we seek to reduce the amount of power consumed by the hardware. Furthermore, we present three neuromorphic hardware architectures in order to quantitatively study the implementation of SNNs. One of these architectures integrates a novel hybrid structure: a highly-parallel computation core for most solicited layers, and time-multiplexed computation units for deeper layers. These architectures are derived from a novel funnel-like Design Space Exploration framework for neuromorphic hardware.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303041",
    "keywords": [
      "Artificial intelligence",
      "Computer architecture",
      "Computer hardware",
      "Computer science",
      "Operating system",
      "Space (punctuation)"
    ],
    "authors": [
      {
        "surname": "Abderrahmane",
        "given_name": "Nassim"
      },
      {
        "surname": "Lemaire",
        "given_name": "Edgar"
      },
      {
        "surname": "Miramond",
        "given_name": "Benoît"
      }
    ]
  },
  {
    "title": "Finite-time resilient H ∞ state estimation for discrete-time delayed neural networks under dynamic event-triggered mechanism",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.006",
    "abstract": "In this paper, the finite-time resilient H ∞ state estimation problem is investigated for a class of discrete-time delayed neural networks. For the sake of energy saving, a dynamic event-triggered mechanism is employed in the design of state estimator for the discrete-time delayed neural networks. In order to handle the possible fluctuation of the estimator gain parameters when the state estimator is implemented, a resilient state estimator is adopted. By constructing a Lyapunov–Krasovskii functional, a sufficient condition is established, which guarantees that the estimation error system is bounded and the H ∞ performance requirement is satisfied within the finite time. Then, the desired estimator gains are obtained via solving a set of linear matrix inequalities. Finally, a numerical example is employed to illustrate the usefulness of the proposed state estimation scheme.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302679",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Scalable Vector Graphics",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Yufei"
      },
      {
        "surname": "Shen",
        "given_name": "Bo"
      },
      {
        "surname": "Shu",
        "given_name": "Huisheng"
      }
    ]
  },
  {
    "title": "A sparse deep belief network with efficient fuzzy learning framework",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.035",
    "abstract": "Deep belief network (DBN) is one of the most feasible ways to realize deep learning (DL) technique, and it has been attracting more and more attentions in nonlinear system modeling. However, DBN cannot provide satisfactory results in learning speed, modeling accuracy and robustness, which is mainly caused by dense representation and gradient diffusion. To address these problems and promote DBN’s development in cross-models, we propose a Sparse Deep Belief Network with Fuzzy Neural Network (SDBFNN) for nonlinear system modeling. In this novel framework, the sparse DBN is considered as a pre-training technique to realize fast weight-initialization and to obtain feature vectors. It can balance the dense representation to improve its robustness. A fuzzy neural network is developed for supervised modeling so as to eliminate the gradient diffusion. Its input happens to be the obtained feature vector. As a novel cross-model, SDBFNN combines the advantages of both pre-training technique and fuzzy neural network to improve modeling capability. Its convergence is also analyzed as well. A benchmark problem and a practical problem in wastewater treatment are conducted to demonstrate the superiority of SDBFNN. The extensive experimental results show that SDBFNN achieves better performance than the existing methods in learning speed, modeling accuracy and robustness.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930317X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep belief network",
      "Deep learning",
      "Feature vector",
      "Fuzzy logic",
      "Gene",
      "Initialization",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Programming language",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Gongming"
      },
      {
        "surname": "Jia",
        "given_name": "Qing-Shan"
      },
      {
        "surname": "Qiao",
        "given_name": "Junfei"
      },
      {
        "surname": "Bi",
        "given_name": "Jing"
      },
      {
        "surname": "Liu",
        "given_name": "Caixia"
      }
    ]
  },
  {
    "title": "The GH-EXIN neural network for hierarchical clustering",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.07.018",
    "abstract": "Hierarchical clustering is an important tool for extracting information from data in a multi-resolution way. It is more meaningful if driven by data, as in the case of divisive algorithms, which split data until no more division is allowed. However, they have the drawback of the splitting threshold setting. The neural networks can address this problem, because they basically depend on data. The growing hierarchical GH-EXIN neural network builds a hierarchical tree in an incremental (data-driven architecture) and self-organized way. It is a top-down technique which defines the horizontal growth by means of an anisotropic region of influence, based on the novel idea of neighborhood convex hull. It also reallocates data and detects outliers by using a novel approach on all the leaves, simultaneously. Its complexity is estimated and an analysis of its user-dependent parameters is given. The advantages of the proposed approach, with regard to the best existing networks, are shown and analyzed, qualitatively and quantitatively, both in benchmark synthetic problems and in a real application (image recognition from video), in order to test the performance in building hierarchical trees. Furthermore, an important and very promising application of GH-EXIN in two-way hierarchical clustering, for the analysis of gene expression data in the study of the colorectal cancer is described.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302060",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Geodesy",
      "Geography",
      "Hierarchical clustering",
      "Mathematical analysis",
      "Mathematics",
      "Outlier",
      "Pattern recognition (psychology)",
      "Tree (set theory)"
    ],
    "authors": [
      {
        "surname": "Cirrincione",
        "given_name": "Giansalvo"
      },
      {
        "surname": "Ciravegna",
        "given_name": "Gabriele"
      },
      {
        "surname": "Barbiero",
        "given_name": "Pietro"
      },
      {
        "surname": "Randazzo",
        "given_name": "Vincenzo"
      },
      {
        "surname": "Pasero",
        "given_name": "Eros"
      }
    ]
  },
  {
    "title": "Gated spiking neural network using Iterative Free-Energy Optimization and rank-order coding for structure learning in memory sequences (INFERNO GATE)",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.023",
    "abstract": "We present a framework based on iterative free-energy optimization with spiking neural networks for modeling the fronto-striatal system (PFC-BG) for the generation and recall of audio memory sequences. In line with neuroimaging studies carried out in the PFC, we propose a genuine coding strategy using the gain-modulation mechanism to represent abstract sequences based solely on the rank and location of items within them. Based on this mechanism, we show that we can construct a repertoire of neurons sensitive to the temporal structure in sequences from which we can represent any novel sequences. Free-energy optimization is then used to explore and to retrieve the missing indices of the items in the correct order for executive control and compositionality. We show that the gain-modulation mechanism permits the network to be robust to variabilities and to have long-term dependencies as it implements a gated recurrent neural network. This model, called Inferno Gate, is an extension of the neural architecture Inferno standing for Iterative Free-Energy Optimization of Recurrent Neural Networks with Gating or Gain-modulation. In experiments performed with an audio database of ten thousand MFCC vectors, Inferno Gate is capable of encoding efficiently and retrieving chunks of fifty items length. We then discuss the potential of our network to model the features of working memory in the PFC-BG loop for structural learning, goal-direction and hierarchical reinforcement learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930303X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Coding (social sciences)",
      "Computer science",
      "Deep learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Pitti",
        "given_name": "Alexandre"
      },
      {
        "surname": "Quoy",
        "given_name": "Mathias"
      },
      {
        "surname": "Lavandier",
        "given_name": "Catherine"
      },
      {
        "surname": "Boucenna",
        "given_name": "Sofiane"
      }
    ]
  },
  {
    "title": "An analysis of training and generalization errors in shallow and deep networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.08.028",
    "abstract": "This paper is motivated by an open problem around deep networks, namely, the apparent absence of over-fitting despite large over-parametrization which allows perfect fitting of the training data. In this paper, we analyze this phenomenon in the case of regression problems when each unit evaluates a periodic activation function. We argue that the minimal expected value of the square loss is inappropriate to measure the generalization error in approximation of compositional functions in order to take full advantage of the compositional structure. Instead, we measure the generalization error in the sense of maximum loss, and sometimes, as a pointwise error. We give estimates on exactly how many parameters ensure both zero training error as well as a good generalization error. We prove that a solution of a regularization problem is guaranteed to yield a good training error as well as a good generalization error and estimate how much error to expect at which test data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302552",
    "keywords": [],
    "authors": [
      {
        "surname": "Mhaskar",
        "given_name": "H.N."
      },
      {
        "surname": "Poggio",
        "given_name": "T."
      }
    ]
  },
  {
    "title": "Multi-output parameter-insensitive kernel twin SVR model",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.022",
    "abstract": "Multi-output regression aims at mapping a multivariate input feature space to a multivariate output space. Currently, it is effective to extend the traditional support vector regression (SVR) mechanism to solve the multi-output case. However, some methods adopting a combination of single-output SVR models exhibit the severe drawback of not considering the possible correlations between outputs, and other multi-output SVRs show high computational complexity and are typically sensitive to parameters due to the influence of noise. To handle these problems, in this study, we determine the multi-output regression function through a pair of nonparallel up- and down-bound functions solved by two smaller-sized quadratic programming problems, which results in a fast learning speed. This method is named multi-output twin support vector regression (M-TSVR). Moreover, when the noise is heteroscedastic, based on our M-TSVR, we introduce a pair of multi-input/output nonparallel parameter insensitive up- and down-bound functions to evaluate a regression model named multi-output parameter-insensitive twin support vector regression (M-PITSVR). To handle the nonlinear case, we derive the kernelized extensions of M-TSVR and M-PITSVR. Finally, a series of comparative experiments with several other multi-output-based methods are performed on twelve multi-output datasets. The experimental results indicate that the proposed multi-output regressors yield fast learning speed as well as a better and more stable prediction performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303028",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Geometry",
      "Image (mathematics)",
      "Kernel (algebra)",
      "Mathematical optimization",
      "Mathematics",
      "Noise (video)",
      "Quadratic equation",
      "Quadratic programming",
      "Regression",
      "Statistics",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Yanmeng"
      },
      {
        "surname": "Sun",
        "given_name": "Huaijiang"
      },
      {
        "surname": "Yan",
        "given_name": "Wenzhu"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiaoqian"
      }
    ]
  },
  {
    "title": "Distinct role of flexible and stable encodings in sequential working memory",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.034",
    "abstract": "The serial-position effect in working memory is considered important for studying how a sequence of sensory information can be retained and manipulated simultaneously in neural memory circuits. Here, via a precise analysis of the primacy and recency effects in human psychophysical experiments, we propose that stable and flexible codings take distinct roles of retaining and updating information in working memory, and that their combination induces serial-position effects spontaneously. We found that stable encoding retains memory to induce the primacy effect, while flexible encoding used for learning new inputs induces the recency effect. A model simulation based on human data, confirmed that a neural network with both flexible and stable synapses could reproduce the major characteristics of serial-position effects. Our new prediction, that the control of resource allocation by flexible–stable coding balance can modulate memory performance in sequence-specific manner, was supported by pre-cued memory performance data in humans.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303168",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Coding (social sciences)",
      "Cognition",
      "Cognitive psychology",
      "Computer science",
      "Cued speech",
      "Encoding (memory)",
      "Free recall",
      "Genetics",
      "Mathematics",
      "Neuroscience",
      "Psychology",
      "Sequence (biology)",
      "Serial position effect",
      "Statistics",
      "Working memory"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Hyeonsu"
      },
      {
        "surname": "Choi",
        "given_name": "Woochul"
      },
      {
        "surname": "Park",
        "given_name": "Youngjin"
      },
      {
        "surname": "Paik",
        "given_name": "Se-Bum"
      }
    ]
  },
  {
    "title": "Title page",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00020-4",
    "abstract": "Unknown",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000204",
    "keywords": [
      "Computer science"
    ],
    "authors": []
  },
  {
    "title": "Modeling place cells and grid cells in multi-compartment environments: Entorhinal–hippocampal loop as a multisensory integration circuit",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.002",
    "abstract": "Hippocampal place cells and entorhinal grid cells are thought to form a representation of space by integrating internal and external sensory cues. Experimental data show that different subsets of place cells are controlled by vision, self-motion or a combination of both. Moreover, recent studies in environments with a high degree of visual aliasing suggest that a continuous interaction between place cells and grid cells can result in a deformation of hexagonal grids or in a progressive loss of visual cue control over grid fields. The computational nature of such a bidirectional interaction remains unclear. In this work we present a neural network model of the dynamic interaction between place cells and grid cells within the entorhinal–hippocampal processing loop. The model was tested in two recent experimental paradigms involving environments with visually similar compartments that provided conflicting evidence about visual cue control over self-motion-based spatial codes. Analysis of the model behavior suggests that the strength of entorhinal–hippocampal dynamical loop is the key parameter governing differential cue control in multi-compartment environments. Moreover, construction of separate spatial representations of visually identical compartments required a progressive weakening of visual cue control over place fields in favor of self-motion based mechanisms. More generally our results suggest a functional segregation between plastic and dynamic processes in hippocampal processing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302631",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Entorhinal cortex",
      "Geometry",
      "Grid",
      "Grid cell",
      "Hippocampal formation",
      "Mathematics",
      "Neuroscience",
      "Path integration",
      "Place cell"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Tianyi"
      },
      {
        "surname": "Arleo",
        "given_name": "Angelo"
      },
      {
        "surname": "Sheynikhovich",
        "given_name": "Denis"
      }
    ]
  },
  {
    "title": "MultiResUNet : Rethinking the U-Net architecture for multimodal biomedical image segmentation",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.08.025",
    "abstract": "In recent years Deep Learning has brought about a breakthrough in Medical Image Segmentation. In this regard, U-Net has been the most popular architecture in the medical imaging community. Despite outstanding overall performance in segmenting multimodal medical images, through extensive experimentations on some challenging datasets, we demonstrate that the classical U-Net architecture seems to be lacking in certain aspects. Therefore, we propose some modifications to improve upon the already state-of-the-art U-Net model. Following these modifications, we develop a novel architecture, MultiResUNet, as the potential successor to the U-Net architecture. We have tested and compared MultiResUNet with the classical U-Net on a vast repertoire of multimodal medical images. Although only slight improvements in the cases of ideal images are noticed, remarkable gains in performance have been attained for the challenging ones. We have evaluated our model on five different datasets, each with their own unique challenges, and have obtained a relative improvement in performance of 10.15%, 5.07%, 2.63%, 1.41%, and 0.62% respectively. We have also discussed and highlighted some qualitatively superior aspects of MultiResUNet over classical U-Net that are not really reflected in the quantitative measures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302503",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Geometry",
      "Image (mathematics)",
      "Image segmentation",
      "Mathematics",
      "Net (polyhedron)",
      "Pattern recognition (psychology)",
      "Segmentation",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Ibtehaz",
        "given_name": "Nabil"
      },
      {
        "surname": "Rahman",
        "given_name": "M. Sohel"
      }
    ]
  },
  {
    "title": "Chapter 7 Memristor-based in-memory logic and its application in image processing",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00007-1",
    "abstract": "In modern von Neumann systems, the data are stored in the memory but are processed in a separate unit. Data transfer between these units incurs energy and delay, which are several orders of magnitude greater than the energy and delay incurred by the computation itself. Recent works on in-memory computing (IMC) have been proposed to reduce the overhead of data transfer. Further reduction became possible with the emergence of memristive memory technologies. Numerous logic-in-memory techniques with memristors have been proposed where the computation is performed using the memory arrays. In this chapter, we overview different memristor-based logic techniques. As a case study of memristor-based logic in an IMC system, we demonstrate how Memristor Aided loGIC (MAGIC) allows NOR gates to be performed within a memristive crossbar array structure. We describe a potential memristive Memory Processing Unit (mMPU) where MAGIC NOR is employed as the basis for all data processings. We then show how to perform different image processing tasks within the mMPU to obtain superior performance and energy efficiency for these tasks over other state-of-the-art memristive logic systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000071",
    "keywords": [
      "Algorithm",
      "Computation",
      "Computer architecture",
      "Computer hardware",
      "Computer science",
      "Crossbar switch",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "In-Memory Processing",
      "Information retrieval",
      "Logic gate",
      "Memistor",
      "Memristor",
      "Operating system",
      "Overhead (engineering)",
      "Query by Example",
      "Resistive random-access memory",
      "Search engine",
      "Telecommunications",
      "Voltage",
      "Von Neumann architecture",
      "Web search query"
    ],
    "authors": [
      {
        "surname": "Haj-Ali",
        "given_name": "Ameer"
      },
      {
        "surname": "Ronen",
        "given_name": "Ronny"
      },
      {
        "surname": "Ben-Hur",
        "given_name": "Rotem"
      },
      {
        "surname": "Wald",
        "given_name": "Nimrod"
      },
      {
        "surname": "Kvatinsky",
        "given_name": "Shahar"
      }
    ]
  },
  {
    "title": "Chapter 11 Exploiting the stochasticity of memristive devices for computing",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00011-3",
    "abstract": "Many memristive devices are prone to partly unpredictable or stochastic behavior. For most applications this point constitutes a challenge that needs to be overcome. However, it does not necessarily need to be. In this chapter we start by reviewing scientific phenomena and methods that are able to harness randomness. Most of these techniques have been known for long, but have never delivered their promises of leveraging noise for computing. We articulate how finding an appropriate stochastic device can unlock the potential of these methods. In consequence we then review various memristive and spintronic technologies, whose intrinsic stochastic behaviors have been proposed for computing. We then present several modern projects that harness memristive randomness for computing, and how their energy efficiency can be benchmarked to more conventional computing approaches. We conclude on a discussion of the tasks and applications for which exploiting stochasticity is a good strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000113",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Distributed computing",
      "Geometry",
      "Image (mathematics)",
      "Mathematics",
      "Noise (video)",
      "Point (geometry)",
      "Randomness",
      "Statistics",
      "Stochastic computing"
    ],
    "authors": [
      {
        "surname": "Mizrahi",
        "given_name": "Alice"
      },
      {
        "surname": "Laurent",
        "given_name": "Raphaël"
      },
      {
        "surname": "Grollier",
        "given_name": "Julie"
      },
      {
        "surname": "Querlioz",
        "given_name": "Damien"
      }
    ]
  },
  {
    "title": "Chapter 2 Resistive switching memories",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00002-2",
    "abstract": "This chapter gives a general overview of the state-of-the-art of resistive switching random access memories (RRAM or ReRAM), which are metal/insulator/metal devices exhibiting resistance transition upon voltage application. They are also classified under the name of memristors or memristive devices. This chapter starts with an introduction to the various physical mechanisms, in relation to material science aspects, which produce resistance switching, including redox processes, ionic migration, metal–insulator phase transitions, conductive filament formation/dissolution, and metal/insulator barrier modifications. The presented physical mechanisms drive different macroscopic electric behavior (nonpolar and bipolar, volatile, and nonvolatile switching) with diverse performances, opportunities, and limitations. A specific section is dedicated to all these aspects and to the overview of the state-of-the-art of industrial-level demonstrations and products, with particular reference to the nonvolatile memory application. Furthermore, this chapter describes the current research lines aiming at augmenting the device functionality. The physical foundation and the typical material selection toward multilevel capability, plasticity, pulse rate– and pulse timing–dependent switching, and negative differential resistance are presented.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000022",
    "keywords": [
      "Computer science",
      "Electrical engineering",
      "Engineering",
      "Engineering physics",
      "Insulator (electricity)",
      "Materials science",
      "Memristor",
      "Nanotechnology",
      "Non-volatile memory",
      "Optoelectronics",
      "Resistive random-access memory",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Brivio",
        "given_name": "Stefano"
      },
      {
        "surname": "Menzel",
        "given_name": "Stephan"
      }
    ]
  },
  {
    "title": "Event-driven implementation of deep spiking convolutional neural networks for supervised classification using the SpiNNaker neuromorphic platform",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.008",
    "abstract": "Neural networks have enabled great advances in recent times due mainly to improved parallel computing capabilities in accordance to Moore’s Law, which allowed reducing the time needed for the parameter learning of complex, multi-layered neural architectures. However, with silicon technology reaching its physical limits, new types of computing paradigms are needed to increase the power efficiency of learning algorithms, especially for dealing with deep spatio-temporal knowledge on embedded applications. With the goal of mimicking the brain’s power efficiency, new hardware architectures such as the SpiNNaker board have been built. Furthermore, recent works have shown that networks using spiking neurons as learning units can match classical neural networks in supervised tasks. In this paper, we show that the implementation of state-of-the-art models on both the MNIST and the event-based NMNIST digit recognition datasets is possible on neuromorphic hardware. We use two approaches, by directly converting a classical neural network to its spiking version and by training a spiking network from scratch. For both cases, software simulations and implementations into a SpiNNaker 103 machine were performed. Numerical results approaching the state of the art on digit recognition are presented, and a new method to decrease the spike rate needed for the task is proposed, which allows a significant reduction of the spikes (up to 34 times for a fully connected architecture) while preserving the accuracy of the system. With this method, we provide new insights on the capabilities offered by networks of spiking neurons to efficiently encode spatio-temporal information.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302692",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer architecture",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "ENCODE",
      "Event (particle physics)",
      "Gene",
      "MNIST database",
      "Machine learning",
      "Neuromorphic engineering",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Software engineering",
      "Spike (software development)",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Patiño-Saucedo",
        "given_name": "Alberto"
      },
      {
        "surname": "Rostro-Gonzalez",
        "given_name": "Horacio"
      },
      {
        "surname": "Serrano-Gotarredona",
        "given_name": "Teresa"
      },
      {
        "surname": "Linares-Barranco",
        "given_name": "Bernabé"
      }
    ]
  },
  {
    "title": "Deep CovDenseSNN: A hierarchical event-driven dynamic framework with spiking neurons in noisy environment",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.08.034",
    "abstract": "Neurons in the brain use an event signal, termed spike, encode temporal information for neural computation. Spiking neural networks (SNNs) take this advantage to serve as biological relevant models. However, the effective encoding of sensory information and also its integration with downstream neurons of SNNs are limited by the current shallow structures and learning algorithms. To tackle this limitation, this paper proposes a novel hybrid framework combining the feature learning ability of continuous-valued convolutional neural networks (CNNs) and SNNs, named deep CovDenseSNN, such that SNNs can make use of feature extraction ability of CNNs during the encoding stage, but still process features with unsupervised learning rule of spiking neurons. We evaluate them on MNIST and its variations to show that our model can extract and transmit more important information than existing models, especially for anti-noise ability in the noisy environment. The proposed architecture provides efficient ways to perform feature representation and recognition in a consistent temporal learning framework, which is easily adapted to neuromorphic hardware implementations and bring more biological realism into modern image classification models, with the hope that the proposed framework can inform us how sensory information is transmitted and represented in the brain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302618",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "ENCODE",
      "Encoding (memory)",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature learning",
      "Gene",
      "Linguistics",
      "MNIST database",
      "Machine learning",
      "Neuromorphic engineering",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Software engineering",
      "Spike (software development)",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Qi"
      },
      {
        "surname": "Peng",
        "given_name": "Jianxin"
      },
      {
        "surname": "Shen",
        "given_name": "Jiangrong"
      },
      {
        "surname": "Tang",
        "given_name": "Huajin"
      },
      {
        "surname": "Pan",
        "given_name": "Gang"
      }
    ]
  },
  {
    "title": "Centralized/decentralized event-triggered pinning synchronization of stochastic coupled networks with noise and incomplete transitional rate",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.003",
    "abstract": "This paper studies the synchronous problem of Markovian switching complex networks associated with partly unknown transitional rates, stochastic noise, and randomly coupling strength. In order to achieve the synchronization for these array networks, event-triggered pinning control is established and developed, in which the pinning node undergoes a self-adapted switch, governed by a Markov chain. Two types of event-triggered sampling controls, centralized and decentralized event-triggered sampling, respectively, are established. Sufficient conditions for synchronization are developed by constructing a desirable stochastic Lyapunov functional as well as by employing the properties of Markov chain and It o ˆ integration. Numerical simulations are provided to demonstrate the effectiveness of the proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302643",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Combinatorics",
      "Complex network",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Coupling (piping)",
      "Detector",
      "Engineering",
      "Event (particle physics)",
      "Image (mathematics)",
      "Lyapunov function",
      "Machine learning",
      "Markov chain",
      "Markov process",
      "Mathematics",
      "Mechanical engineering",
      "Node (physics)",
      "Noise (video)",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Sampling (signal processing)",
      "Statistics",
      "Structural engineering",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Topology (electrical circuits)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Dong",
        "given_name": "Hailing"
      },
      {
        "surname": "Zhou",
        "given_name": "Jiamu"
      },
      {
        "surname": "Xiao",
        "given_name": "Mingqing"
      }
    ]
  },
  {
    "title": "Title page",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00020-4",
    "abstract": "Unknown",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000204",
    "keywords": [
      "Computer science"
    ],
    "authors": []
  },
  {
    "title": "Distributed dual vigilance fuzzy adaptive resonance theory learns online, retrieves arbitrarily-shaped clusters, and mitigates order dependence",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.08.033",
    "abstract": "This paper presents a novel adaptive resonance theory (ART)-based modular architecture for unsupervised learning, namely the distributed dual vigilance fuzzy ART (DDVFA). DDVFA consists of a global ART system whose nodes are local fuzzy ART modules. It is equipped with distributed higher-order activation and match functions and a dual vigilance mechanism. Together, these allow DDVFA to perform unsupervised modularization, create multi-prototype cluster representations, retrieve arbitrarily-shaped clusters, and reduce category proliferation. Another important contribution is the reduction of order-dependence, an issue that affects any agglomerative clustering method. This paper demonstrates two approaches for mitigating order-dependence: pre-processing using visual assessment of cluster tendency (VAT) or post-processing using a novel Merge ART module. The former is suitable for batch processing, whereas the latter also works for online learning. Experimental results in online mode carried out on 30 benchmark data sets show that DDVFA cascaded with Merge ART statistically outperformed the best other ART-based systems when samples were randomly presented. Conversely, they were found to be statistically equivalent in offline mode when samples were pre-processed using VAT. Remarkably, performance comparisons to non-ART-based clustering algorithms show that DDVFA (which learns incrementally) was also statistically equivalent to the non-incremental (offline) methods of density-based spatial clustering of applications with noise (DBSCAN), single linkage hierarchical agglomerative clustering (SL-HAC), and k-means, while retaining the appealing properties of ART. Links to the source code and data are provided. Considering the algorithm’s simplicity, online learning capability, and performance, it is an ideal choice for many agglomerative clustering applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302606",
    "keywords": [],
    "authors": [
      {
        "surname": "Brito da Silva",
        "given_name": "Leonardo Enzo"
      },
      {
        "surname": "Elnabarawy",
        "given_name": "Islam"
      },
      {
        "surname": "Wunsch",
        "given_name": "Donald C."
      }
    ]
  },
  {
    "title": "Synchronization in an array of coupled neural networks with delayed impulses: Average impulsive delay method",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.019",
    "abstract": "In the paper, synchronization of coupled neural networks with delayed impulses is investigated. In order to overcome the difficulty that time delays can be flexible and even larger than impulsive interval, we propose a new method of average impulsive delay (AID). By the methods of average impulsive interval (AII) and AID, some sufficient synchronization criteria for coupled neural networks with delayed impulses are obtained. We prove that the time delay in impulses can play double roles, namely, it may desynchronize a synchronous network or synchronize a nonsynchronized network. Moreover, a unified relationship is established among AII, AID and rate coefficients of the impulsive dynamical network such that the network is globally exponentially synchronized (GES). Further, we discuss the case that time delays in impulses may be unbounded, which has not been considered in existing results. Finally, two examples are presented to demonstrate the validity of the derived results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302849",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Impulse (physics)",
      "Interval (graph theory)",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Bangxin"
      },
      {
        "surname": "Lu",
        "given_name": "Jianquan"
      },
      {
        "surname": "Lou",
        "given_name": "Jungang"
      },
      {
        "surname": "Qiu",
        "given_name": "Jianlong"
      }
    ]
  },
  {
    "title": "Named entity recognition in electronic health records using transfer learning bootstrapped Neural Networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.08.032",
    "abstract": "Neural networks (NNs) have become the state of the art in many machine learning applications, such as image, sound (LeCun et al., 2015) and natural language processing (Young et al., 2017; Linggard et al., 2012). However, the success of NNs remains dependent on the availability of large labelled datasets, such as in the case of electronic health records (EHRs). With scarce data, NNs are unlikely to be able to extract this hidden information with practical accuracy. In this study, we develop an approach that solves these problems for named entity recognition, obtaining 94.6 F1 score in I2B2 2009 Medical Extraction Challenge (Uzuner et al., 2010), 4.3 above the architecture that won the competition. To achieve this, we bootstrap our NN models through transfer learning by pretraining word embeddings on a secondary task performed on a large pool of unannotated EHRs and using the output embeddings as a foundation of a range of NN architectures. Beyond the official I2B2 challenge, we further achieve 82.4 F1 on extracting relationships between medical terms using attention-based seq2seq models bootstrapped in the same manner.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930259X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Economic growth",
      "Economics",
      "F1 score",
      "Health care",
      "Health records",
      "Information extraction",
      "Leverage (statistics)",
      "Machine learning",
      "Management",
      "Named-entity recognition",
      "Natural language processing",
      "Task (project management)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Gligic",
        "given_name": "Luka"
      },
      {
        "surname": "Kormilitzin",
        "given_name": "Andrey"
      },
      {
        "surname": "Goldberg",
        "given_name": "Paul"
      },
      {
        "surname": "Nevado-Holgado",
        "given_name": "Alejo"
      }
    ]
  },
  {
    "title": "Spiking Neural Networks and online learning: An overview and perspectives",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.004",
    "abstract": "Applications that generate huge amounts of data in the form of fast streams are becoming increasingly prevalent, being therefore necessary to learn in an online manner. These conditions usually impose memory and processing time restrictions, and they often turn into evolving environments where a change may affect the input data distribution. Such a change causes that predictive models trained over these stream data become obsolete and do not adapt suitably to new distributions. Specially in these non-stationary scenarios, there is a pressing need for new algorithms that adapt to these changes as fast as possible, while maintaining good performance scores. Unfortunately, most off-the-shelf classification models need to be retrained if they are used in changing environments, and fail to scale properly. Spiking Neural Networks have revealed themselves as one of the most successful approaches to model the behavior and learning potential of the brain, and exploit them to undertake practical online learning tasks. Besides, some specific flavors of Spiking Neural Networks can overcome the necessity of retraining after a drift occurs. This work intends to merge both fields by serving as a comprehensive overview, motivating further developments that embrace Spiking Neural Networks for online learning scenarios, and being a friendly entry point for non-experts.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302655",
    "keywords": [],
    "authors": [
      {
        "surname": "Lobo",
        "given_name": "Jesus L."
      },
      {
        "surname": "Del Ser",
        "given_name": "Javier"
      },
      {
        "surname": "Bifet",
        "given_name": "Albert"
      },
      {
        "surname": "Kasabov",
        "given_name": "Nikola"
      }
    ]
  },
  {
    "title": "Chapter 15 Memristive devices for spiking neural networks",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00015-0",
    "abstract": "Spiking neural networks (SNNs) are artificial learning models that closely mimic the time-based information encoding and processing mechanisms observed in the brain. As opposed to deep learning models that use real numbers for information encoding, SNNs use binary spike signals and their arrival times to encode information, which could potentially improve the algorithmic efficiency of computation. However overall system efficiency improvement for learning and inference systems implementing SNNs will depend on the ability to reduce data movement between processor and memory units, and hence in-memory computing architectures employing nanoscale memristive devices that operate at low power would be essential. The requirements and specifications for these devices for realizing SNNs are quite different from those of regular deep learning models. In this chapter we introduce some of the fundamental aspects of spike-based information processing and how nanoscale memristive devices could be used to efficiently implement these algorithms for cognitive applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000150",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computation",
      "Computer architecture",
      "Computer science",
      "Deep learning",
      "ENCODE",
      "Encoding (memory)",
      "Gene",
      "Inference",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Rajendran",
        "given_name": "Bipin"
      },
      {
        "surname": "Querlioz",
        "given_name": "Damien"
      },
      {
        "surname": "Spiga",
        "given_name": "Sabina"
      },
      {
        "surname": "Sebastian",
        "given_name": "Abu"
      }
    ]
  },
  {
    "title": "Chapter 6 Memristive devices as computational memory",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00006-X",
    "abstract": "Traditional von Neumann computers have separate processing and memory units. This necessitates frequent shuttling of data between these units when performing computational tasks. The resulting latency and energy cost is a key challenge especially given the recent explosive growth in highly data-centric applications such as those related to artificial intelligence. In-memory computing is an emerging non-von Neumann paradigm where certain computational tasks are performed in the memory itself by exploiting the physical attributes of the memory devices. Memristive devices that store information in terms of their resistance values are particularly well suited for in-memory computing. These devices when organized within a computational memory unit can be used to perform a range of tasks from logical and arithmetic operations to stochastic computing. In this chapter we introduce this topic with an emphasis on the key physical attributes of memristive devices that facilitate in-memory computing. We also present a future outlook highlighting some of the challenges and device-level requirements.",
    "link": "https://www.sciencedirect.com/science/article/pii/B978008102782000006X",
    "keywords": [
      "Computer architecture",
      "Computer science",
      "Computer security",
      "Distributed computing",
      "Electronic engineering",
      "Engineering",
      "In-Memory Processing",
      "Information retrieval",
      "Key (lock)",
      "Memristor",
      "Operating system",
      "Query by Example",
      "Search engine",
      "Theoretical computer science",
      "Unconventional computing",
      "Von Neumann architecture",
      "Web search query"
    ],
    "authors": [
      {
        "surname": "Sebastian",
        "given_name": "Abu"
      },
      {
        "surname": "Querlioz",
        "given_name": "Damien"
      },
      {
        "surname": "Rajendran",
        "given_name": "Bipin"
      },
      {
        "surname": "Spiga",
        "given_name": "Sabina"
      }
    ]
  },
  {
    "title": "Chapter 5 Selector devices for emerging memories",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00005-8",
    "abstract": "Emerging nonvolatile memory devices, also named memristive devices, have drawn great attention due to their potential for ultra-high density memory application. To achieve such high-density memristive device, a crossbar array structure is introduced. However, implementing such crossbar array requires addressing issues such as unwanted current flow in the unselected cell, so-called the “sneak-path” current. Therefore an access device called a selector device is required to suppress such undesired current and to operate the target memory cell both selectively and nondestructively in the crossbar array. Although different kinds of selector devices have been studied, none of them met all requirements, such as simple two-terminal structure, highly nonlinear I–V characteristics, fast operation speed, high endurance, excellent uniformity, and good thermal stability. The insulator–metal transition (IMT), the ovonic threshold switching (OTS), and the conductive bridging RAM (CBRAM)-type device are promising candidates as a selector device due to their scalability. IMT- and OTS-based selectors exhibit excellent performance, such as high on-current density and extremely fast switching speed, but the off-current, especially for IMT-based selectors, still needs further improvement for the effective reduction of leakage current in the crossbar array. CBRAM-type selectors have ultralow leakage current, suitable for high selectivity and low power device applications. However, the poor on-current density and reliability issues hinder their applicability. There has been great effort to improve the performance of these three types of selector devices, and this chapter reviews recent progress and future directions on their implementation for high-density crossbar array.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000058",
    "keywords": [
      "Bridging (networking)",
      "Computer network",
      "Computer science",
      "Crossbar switch",
      "Database",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "Fast switching",
      "Materials science",
      "Non-volatile memory",
      "Optoelectronics",
      "Resistive random-access memory",
      "Scalability",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Chekol",
        "given_name": "Solomon Amsalu"
      },
      {
        "surname": "Song",
        "given_name": "Jeonghwan"
      },
      {
        "surname": "Park",
        "given_name": "Jaehyuk"
      },
      {
        "surname": "Yoo",
        "given_name": "Jongmyung"
      },
      {
        "surname": "Lim",
        "given_name": "Seokjae"
      },
      {
        "surname": "Hwang",
        "given_name": "Hyunsang"
      }
    ]
  },
  {
    "title": "Adaptive latent similarity learning for multi-view clustering",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.013",
    "abstract": "Most existing clustering methods employ the original multi-view data as input to learn the similarity matrix which characterizes the underlying cluster structure shared by multiple views. This reduces the flexibility of multi-view clustering methods due to the fact that multi-view data usually contains noise or the variation between multi-view data points, which should belong to the same cluster, is larger than the variation between data points belonging to different clusters. To address these problems, we propose a novel multi-view clustering model, namely adaptive latent similarity learning (ALSL) for multi-view clustering. ALSL employs the adaptively learned graph, which characterizes the relationship between clusters, as the new input to learn the latent data representation and integrates the latent similarity representation learning, manifold learning and spectral clustering into a unified framework. With the complementarity of multiple views, the latent similarity representation characterizes the underlying cluster structure shared by multiple views. Our model is intuitive and can be optimized efficiently by using the Augmented Lagrangian Multiplier with Alternating Direction Minimization (ALM-ADM) algorithm. Extensive experiments on benchmark datasets have demonstrated the superiority of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302746",
    "keywords": [
      "Artificial intelligence",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Computer science",
      "Constrained clustering",
      "Correlation clustering",
      "Data mining",
      "Data point",
      "Image (mathematics)",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Similarity (geometry)",
      "Single-linkage clustering",
      "Spectral clustering"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Deyan"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Wang",
        "given_name": "Qianqian"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiangdong"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Chapter 5 Selector devices for emerging memories",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00005-8",
    "abstract": "Emerging nonvolatile memory devices, also named memristive devices, have drawn great attention due to their potential for ultra-high density memory application. To achieve such high-density memristive device, a crossbar array structure is introduced. However, implementing such crossbar array requires addressing issues such as unwanted current flow in the unselected cell, so-called the “sneak-path” current. Therefore an access device called a selector device is required to suppress such undesired current and to operate the target memory cell both selectively and nondestructively in the crossbar array. Although different kinds of selector devices have been studied, none of them met all requirements, such as simple two-terminal structure, highly nonlinear I–V characteristics, fast operation speed, high endurance, excellent uniformity, and good thermal stability. The insulator–metal transition (IMT), the ovonic threshold switching (OTS), and the conductive bridging RAM (CBRAM)-type device are promising candidates as a selector device due to their scalability. IMT- and OTS-based selectors exhibit excellent performance, such as high on-current density and extremely fast switching speed, but the off-current, especially for IMT-based selectors, still needs further improvement for the effective reduction of leakage current in the crossbar array. CBRAM-type selectors have ultralow leakage current, suitable for high selectivity and low power device applications. However, the poor on-current density and reliability issues hinder their applicability. There has been great effort to improve the performance of these three types of selector devices, and this chapter reviews recent progress and future directions on their implementation for high-density crossbar array.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000058",
    "keywords": [
      "Bridging (networking)",
      "Computer network",
      "Computer science",
      "Crossbar switch",
      "Database",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "Fast switching",
      "Materials science",
      "Non-volatile memory",
      "Optoelectronics",
      "Resistive random-access memory",
      "Scalability",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Chekol",
        "given_name": "Solomon Amsalu"
      },
      {
        "surname": "Song",
        "given_name": "Jeonghwan"
      },
      {
        "surname": "Park",
        "given_name": "Jaehyuk"
      },
      {
        "surname": "Yoo",
        "given_name": "Jongmyung"
      },
      {
        "surname": "Lim",
        "given_name": "Seokjae"
      },
      {
        "surname": "Hwang",
        "given_name": "Hyunsang"
      }
    ]
  },
  {
    "title": "How are response properties in the middle temporal area related to inference on visual motion patterns?",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.08.027",
    "abstract": "Neurons in the primate middle temporal area (MT) respond to moving stimuli, with strong tuning for motion speed and direction. These responses have been characterized in detail, but the functional significance of these details (e.g. shapes and widths of speed tuning curves) is unclear, because they cannot be selectively manipulated. To estimate their functional significance, we used a detailed model of MT population responses as input to convolutional networks that performed sophisticated motion processing tasks (visual odometry and gesture recognition). We manipulated the distributions of speed and direction tuning widths, and studied the effects on task performance. We also studied performance with random linear mixtures of the responses, and with responses that had the same representational dissimilarity as the model populations, but were otherwise randomized. The width of speed and direction tuning both affected task performance, despite the networks having been optimized individually for each tuning variation, but the specific effects were different in each task. Random linear mixing improved performance of the odometry task, but not the gesture recognition task. Randomizing the responses while maintaining representational dissimilarity resulted in poor odometry performance. In summary, despite full optimization of the deep networks in each case, each manipulation of the representation affected performance of sophisticated visual tasks. Representation properties such as tuning width and representational similarity have been studied extensively from other perspectives, but this work provides new insight into their possible roles in sophisticated visual inference.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302527",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Economics",
      "Gesture",
      "Image (mathematics)",
      "Inference",
      "Law",
      "Management",
      "Mobile robot",
      "Motion (physics)",
      "Odometry",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Robot",
      "Similarity (geometry)",
      "Task (project management)",
      "Visual odometry"
    ],
    "authors": [
      {
        "surname": "Rezai",
        "given_name": "Omid"
      },
      {
        "surname": "Stoffl",
        "given_name": "Lucas"
      },
      {
        "surname": "Tripp",
        "given_name": "Bryan"
      }
    ]
  },
  {
    "title": "Interfering with a memory without erasing its trace",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.027",
    "abstract": "Previous research has shown that performance of a novice skill can be easily interfered with by subsequent training of another skill. We address the open questions whether extensively trained skills show the same vulnerability to interference as novice skills and which memory mechanism regulates interference between expert skills. We developed a recurrent neural network model of V1 able to learn from feedback experienced over the course of a long-term orientation discrimination experiment. After first exposing the model to one discrimination task for 3480 consecutive trials, we assessed how its performance was affected by subsequent training in a second, similar task. Training the second task strongly interfered with the first (highly trained) discrimination skill. The magnitude of interference depended on the relative amounts of training devoted to the different tasks. We used these and other model outcomes as predictions for a perceptual learning experiment in which human participants underwent the same training protocol as our model. Specifically, over the course of three months participants underwent baseline training in one orientation discrimination task for 15 sessions before being trained for 15 sessions on a similar task and finally undergoing another 15 sessions of training on the first task (to assess interference). Across all conditions, the pattern of interference observed empirically closely matched model predictions. According to our model, behavioral interference can be explained by antagonistic changes in neuronal tuning induced by the two tasks. Remarkably, this did not stem from erasing connections due to earlier learning but rather from a reweighting of lateral inhibition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303090",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Cognition",
      "Cognitive psychology",
      "Computer network",
      "Computer science",
      "Computer security",
      "Economics",
      "Geometry",
      "Interference (communication)",
      "Interference theory",
      "Management",
      "Mathematics",
      "Meteorology",
      "Neuroscience",
      "Orientation (vector space)",
      "Perception",
      "Physics",
      "Psychology",
      "Task (project management)",
      "Training (meteorology)",
      "Vulnerability (computing)",
      "Working memory"
    ],
    "authors": [
      {
        "surname": "Lange",
        "given_name": "Gesa"
      },
      {
        "surname": "Senden",
        "given_name": "Mario"
      },
      {
        "surname": "Radermacher",
        "given_name": "Alexandra"
      },
      {
        "surname": "De Weerd",
        "given_name": "Peter"
      }
    ]
  },
  {
    "title": "Adaptive latent similarity learning for multi-view clustering",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.013",
    "abstract": "Most existing clustering methods employ the original multi-view data as input to learn the similarity matrix which characterizes the underlying cluster structure shared by multiple views. This reduces the flexibility of multi-view clustering methods due to the fact that multi-view data usually contains noise or the variation between multi-view data points, which should belong to the same cluster, is larger than the variation between data points belonging to different clusters. To address these problems, we propose a novel multi-view clustering model, namely adaptive latent similarity learning (ALSL) for multi-view clustering. ALSL employs the adaptively learned graph, which characterizes the relationship between clusters, as the new input to learn the latent data representation and integrates the latent similarity representation learning, manifold learning and spectral clustering into a unified framework. With the complementarity of multiple views, the latent similarity representation characterizes the underlying cluster structure shared by multiple views. Our model is intuitive and can be optimized efficiently by using the Augmented Lagrangian Multiplier with Alternating Direction Minimization (ALM-ADM) algorithm. Extensive experiments on benchmark datasets have demonstrated the superiority of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302746",
    "keywords": [
      "Artificial intelligence",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Computer science",
      "Constrained clustering",
      "Correlation clustering",
      "Data mining",
      "Data point",
      "Image (mathematics)",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Similarity (geometry)",
      "Single-linkage clustering",
      "Spectral clustering"
    ],
    "authors": [
      {
        "surname": "Xie",
        "given_name": "Deyan"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Wang",
        "given_name": "Qianqian"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiangdong"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Indirect and direct training of spiking neural networks for end-to-end control of a lane-keeping vehicle",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.05.019",
    "abstract": "Building spiking neural networks (SNNs) based on biological synaptic plasticities holds a promising potential for accomplishing fast and energy-efficient computing, which is beneficial to mobile robotic applications. However, the implementations of SNNs in robotic fields are limited due to the lack of practical training methods. In this paper, we therefore introduce both indirect and direct end-to-end training methods of SNNs for a lane-keeping vehicle. First, we adopt a policy learned using the Deep Q-Learning (DQN) algorithm and then subsequently transfer it to an SNN using supervised learning. Second, we adopt the reward-modulated spike-timing-dependent plasticity (R-STDP) for training SNNs directly, since it combines the advantages of both reinforcement learning and the well-known spike-timing-dependent plasticity (STDP). We examine the proposed approaches in three scenarios in which a robot is controlled to keep within lane markings by using an event-based neuromorphic vision sensor. We further demonstrate the advantages of the R-STDP approach in terms of the lateral localization accuracy and training time steps by comparing them with other three algorithms presented in this paper.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019301595",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Block (permutation group theory)",
      "Chemistry",
      "Computer science",
      "End-to-end principle",
      "Geometry",
      "Machine learning",
      "Mathematics",
      "Neuromorphic engineering",
      "Receptor",
      "Reinforcement learning",
      "Software engineering",
      "Spike (software development)",
      "Spike-timing-dependent plasticity",
      "Spiking neural network",
      "Synaptic plasticity"
    ],
    "authors": [
      {
        "surname": "Bing",
        "given_name": "Zhenshan"
      },
      {
        "surname": "Meschede",
        "given_name": "Claus"
      },
      {
        "surname": "Chen",
        "given_name": "Guang"
      },
      {
        "surname": "Knoll",
        "given_name": "Alois"
      },
      {
        "surname": "Huang",
        "given_name": "Kai"
      }
    ]
  },
  {
    "title": "Chapter 14 RRAM-based coprocessors for deep learning",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00014-9",
    "abstract": "Resistive random access memory is a promising candidate for neuromorphic computing due to its simple device structure, low energy consumption, fast operation speed, and high scalability. This chapter presents the latest results on non-von Neumann coprocessors and various neural network (NN) applications where metal-oxide resistive memory devices serve as synaptic weights, including significant simulation works and experimental achievements. NN’s function ranges from pattern classification to signal processing. This chapter also includes sections addressing the requirements, as well as recent progress, for circuits and systems at application level. In addition, we will discuss how circuit-level nonideal effects affect the performance of the NNs and compare the robustness of the main design choices. Finally, design consideration for the realization of functional NN hardware is summarized.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000149",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer architecture",
      "Computer engineering",
      "Computer science",
      "Coprocessor",
      "Database",
      "Electrical engineering",
      "Electronic engineering",
      "Embedded system",
      "Engineering",
      "Gene",
      "Mathematics",
      "Memristor",
      "Neuromorphic engineering",
      "Operating system",
      "Realization (probability)",
      "Resistive random-access memory",
      "Robustness (evolution)",
      "Scalability",
      "Statistics",
      "Voltage",
      "Von Neumann architecture"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Ying"
      },
      {
        "surname": "Gao",
        "given_name": "Bin"
      },
      {
        "surname": "Dou",
        "given_name": "Chunmeng"
      },
      {
        "surname": "Chang",
        "given_name": "Meng-Fan"
      },
      {
        "surname": "Wu",
        "given_name": "Huaqiang"
      }
    ]
  },
  {
    "title": "A biologically plausible supervised learning method for spiking neural networks using the symmetric STDP rule",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.007",
    "abstract": "Spiking neural networks (SNNs) possess energy-efficient potential due to event-based computation. However, supervised training of SNNs remains a challenge as spike activities are non-differentiable. Previous SNNs training methods can be generally categorized into two basic classes, i.e., backpropagation-like training methods and plasticity-based learning methods. The former methods are dependent on energy-inefficient real-valued computation and non-local transmission, as also required in artificial neural networks (ANNs), whereas the latter are either considered to be biologically implausible or exhibit poor performance. Hence, biologically plausible (bio-plausible) high-performance supervised learning (SL) methods for SNNs remain deficient. In this paper, we proposed a novel bio-plausible SNN model for SL based on the symmetric spike-timing dependent plasticity (sym-STDP) rule found in neuroscience. By combining the sym-STDP rule with bio-plausible synaptic scaling and intrinsic plasticity of the dynamic threshold, our SNN model implemented SL well and achieved good performance in the benchmark recognition task (MNIST dataset). To reveal the underlying mechanism of our SL model, we visualized both layer-based activities and synaptic weights using the t-distributed stochastic neighbor embedding (t-SNE) method after training and found that they were well clustered, thereby demonstrating excellent classification ability. Furthermore, to verify the robustness of our model, we trained it on another more realistic dataset (Fashion-MNIST), which also showed good performance. As the learning rules were bio-plausible and based purely on local spike events, our model could be easily applied to neuromorphic hardware for online training and may be helpful for understanding SL information processing at the synaptic level in biological neural systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302680",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Embedding",
      "Gene",
      "Learning rule",
      "MNIST database",
      "Machine learning",
      "Neuromorphic engineering",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Hao",
        "given_name": "Yunzhe"
      },
      {
        "surname": "Huang",
        "given_name": "Xuhui"
      },
      {
        "surname": "Dong",
        "given_name": "Meng"
      },
      {
        "surname": "Xu",
        "given_name": "Bo"
      }
    ]
  },
  {
    "title": "Sliding mode control of neural networks via continuous or periodic sampling event-triggering algorithm",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.001",
    "abstract": "This paper presents the theoretical results on sliding mode control (SMC) of neural networks via continuous or periodic sampling event-triggered algorithm. Firstly, SMC with continuous sampling event-triggered scheme is developed and the practical sliding mode can be achieved. In addition, there is a consistent positive lower bound for the time interval between two successive trigger events which implies that the Zeno phenomenon will not occur. Next, a more economical and realistic SMC technique is presented with periodic sampling event-triggered algorithm, which guarantees the robust stability of the augmented system. Finally, two illustrative examples are presented to substantiate the effectiveness of the derived theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930262X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Event (particle physics)",
      "Filter (signal processing)",
      "Geometry",
      "Interval (graph theory)",
      "Machine learning",
      "Mathematics",
      "Mode (computer interface)",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Quantum mechanics",
      "Sampling (signal processing)",
      "Sampling interval",
      "Sliding mode control",
      "Stability (learning theory)",
      "Statistics",
      "Zeno's paradoxes"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Shiqin"
      },
      {
        "surname": "Cao",
        "given_name": "Yuting"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      },
      {
        "surname": "Chen",
        "given_name": "Yiran"
      },
      {
        "surname": "Li",
        "given_name": "Peng"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Chapter 3 Phase-change memory",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00003-4",
    "abstract": "Phase-change memory (PCM) is a key enabling technology for nonvolatile electrical data storage at the nanometer scale. A PCM device consists of a small active volume of phase-change material sandwiched between two electrodes. In PCM, data are stored using the electrical resistance contrast between a high-conductive crystalline phase and a low-conductive amorphous phase of the phase-change material. An appealing attribute of PCM is that the stored data are retained for a very long time (typically 10 years at room temperature), but is written in only a few nanoseconds. This property could enable PCM to be used for nonvolatile storage such as Flash and hard disk drives, while operating almost as fast as high-performance volatile memory such as dynamic random access memory (DRAM). Another particularly interesting emerging application for PCM is brain-inspired computing, where the memory devices are not only used to store data but also to perform some computational tasks. This chapter first explains the read and write operation principles of PCM and describes the physical mechanisms involved. Then key enablers of PCM for brain-inspired computing are presented along with experimental results on PCM arrays which highlight various opportunities and challenges involved in using PCM for this application.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000034",
    "keywords": [
      "Computer data storage",
      "Computer hardware",
      "Computer science",
      "Computer security",
      "Data retention",
      "Dram",
      "Dynamic random-access memory",
      "Embedded system",
      "Engineering",
      "Engineering physics",
      "Flash memory",
      "Key (lock)",
      "Layer (electronics)",
      "Materials science",
      "Nanotechnology",
      "Non-volatile memory",
      "Operating system",
      "Phase change",
      "Phase-change material",
      "Phase-change memory",
      "Semiconductor memory"
    ],
    "authors": [
      {
        "surname": "Le Gallo",
        "given_name": "Manuel"
      },
      {
        "surname": "Sebastian",
        "given_name": "Abu"
      }
    ]
  },
  {
    "title": "A waiting-time-based event-triggered scheme for stabilization of complex-valued neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.032",
    "abstract": "This paper addresses the global stabilization of complex-valued neural networks (CVNNs) via event-triggered control. First, a waiting-time-based event-triggered scheme is designed to reduce the data transmission rate. Therein, an exponential decay term is introduced into the predefined threshold function, which may postpone the triggering instant of the necessary data and therefore reduce the frequency of data transmission. Then, with the help of the input delay approach, a time-dependent piecewise-defined Lyapunov–Krasovskii functional is constructed for closed-loop system to formulate a less conservative stability criterion. In addition, by resorting to matrix transformation, the co-design method for both the feedback gains and the trigger parameters is derived. Finally, a numerical example is given to illustrate the feasibility and superiority of the proposed event-triggered scheme and the obtained theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303144",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Event (particle physics)",
      "Exponential stability",
      "Gene",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Piecewise",
      "Quantum mechanics",
      "Scheme (mathematics)",
      "Stability (learning theory)",
      "Telecommunications",
      "Term (time)",
      "Transformation (genetics)",
      "Transmission (telecommunications)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Xiaohong"
      },
      {
        "surname": "Wang",
        "given_name": "Zhen"
      },
      {
        "surname": "Song",
        "given_name": "Qiankun"
      },
      {
        "surname": "Shen",
        "given_name": "Hao"
      },
      {
        "surname": "Huang",
        "given_name": "Xia"
      }
    ]
  },
  {
    "title": "Tree-CNN: A hierarchical Deep Convolutional Neural Network for incremental learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.010",
    "abstract": "Over the past decade, Deep Convolutional Neural Networks (DCNNs) have shown remarkable performance in most computer vision tasks. These tasks traditionally use a fixed dataset, and the model, once trained, is deployed as is. Adding new information to such a model presents a challenge due to complex training issues, such as “catastrophic forgetting”, and sensitivity to hyper-parameter tuning. However, in this modern world, data is constantly evolving, and our deep learning models are required to adapt to these changes. In this paper, we propose an adaptive hierarchical network structure composed of DCNNs that can grow and learn as new data becomes available. The network grows in a tree-like fashion to accommodate new classes of data, while preserving the ability to distinguish the previously trained classes. The network organizes the incrementally available data into feature-driven super-classes and improves upon existing hierarchical CNN models by adding the capability of self-growth. The proposed hierarchical model, when compared against fine-tuning a deep network, achieves significant reduction of training effort, while maintaining competitive accuracy on CIFAR-10 and CIFAR-100.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302710",
    "keywords": [],
    "authors": [
      {
        "surname": "Roy",
        "given_name": "Deboleena"
      },
      {
        "surname": "Panda",
        "given_name": "Priyadarshini"
      },
      {
        "surname": "Roy",
        "given_name": "Kaushik"
      }
    ]
  },
  {
    "title": "Rethinking the performance comparison between SNNS and ANNS",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.005",
    "abstract": "Artificial neural networks (ANNs), a popular path towards artificial intelligence, have experienced remarkable success via mature models, various benchmarks, open-source datasets, and powerful computing platforms. Spiking neural networks (SNNs), a category of promising models to mimic the neuronal dynamics of the brain, have gained much attention for brain inspired computing and been widely deployed on neuromorphic devices. However, for a long time, there are ongoing debates and skepticisms about the value of SNNs in practical applications. Except for the low power attribute benefit from the spike-driven processing, SNNs usually perform worse than ANNs especially in terms of the application accuracy. Recently, researchers attempt to address this issue by borrowing learning methodologies from ANNs, such as backpropagation, to train high-accuracy SNN models. The rapid progress in this domain continuously produces amazing results with ever-increasing network size, whose growing path seems similar to the development of deep learning. Although these ways endow SNNs the capability to approach the accuracy of ANNs, the natural superiorities of SNNs and the way to outperform ANNs are potentially lost due to the use of ANN-oriented workloads and simplistic evaluation metrics. In this paper, we take the visual recognition task as a case study to answer the questions of “what workloads are ideal for SNNs and how to evaluate SNNs makes sense”. We design a series of contrast tests using different types of datasets (ANN-oriented and SNN-oriented), diverse processing models, signal conversion methods, and learning algorithms. We propose comprehensive metrics on the application accuracy and the cost of memory & compute to evaluate these models, and conduct extensive experiments. We evidence the fact that on ANN-oriented workloads, SNNs fail to beat their ANN counterparts; while on SNN-oriented workloads, SNNs can fully perform better. We further demonstrate that in SNNs there exists a trade-off between the application accuracy and the execution cost, which will be affected by the simulation time window and firing threshold. Based on these abundant analyses, we recommend the most suitable model for each scenario. To the best of our knowledge, this is the first work using systematical comparisons to explicitly reveal that the straightforward workload porting from ANNs to SNNs is unwise although many works are doing so and a comprehensive evaluation indeed matters. Finally, we highlight the urgent need to build a benchmarking framework for SNNs with broader tasks, datasets, and metrics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302667",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Machine learning",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Deng",
        "given_name": "Lei"
      },
      {
        "surname": "Wu",
        "given_name": "Yujie"
      },
      {
        "surname": "Hu",
        "given_name": "Xing"
      },
      {
        "surname": "Liang",
        "given_name": "Ling"
      },
      {
        "surname": "Ding",
        "given_name": "Yufei"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      },
      {
        "surname": "Zhao",
        "given_name": "Guangshe"
      },
      {
        "surname": "Li",
        "given_name": "Peng"
      },
      {
        "surname": "Xie",
        "given_name": "Yuan"
      }
    ]
  },
  {
    "title": "Operation-aware Neural Networks for user response prediction",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.020",
    "abstract": "User response prediction makes a crucial contribution to the rapid development of online advertising system and recommendation system. The importance of learning feature interactions has been emphasized by many works. Many deep models are proposed to automatically learn high-order feature interactions. Since most features in advertising systems and recommendation systems are high-dimensional sparse features, deep models usually learn a low-dimensional distributed representation for each feature in the bottom layer. Besides traditional fully-connected architectures, some new operations, such as convolutional operations and product operations, are proposed to learn feature interactions better. In these models, the representation is shared among different operations. However, the best representation for each operation may be different. In this paper, we propose a new neural model named Operation-aware Neural Networks (ONN) which learns different representations for different operations. Our experimental results on two large-scale real-world ad click/conversion datasets demonstrate that ONN consistently outperforms the state-of-the-art models in both offline-training environment and online-training environment.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302850",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Deep neural networks",
      "Feature (linguistics)",
      "Feature learning",
      "Law",
      "Layer (electronics)",
      "Linguistics",
      "Machine learning",
      "Organic chemistry",
      "Philosophy",
      "Political science",
      "Politics",
      "Recommender system",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yi"
      },
      {
        "surname": "Xu",
        "given_name": "Baile"
      },
      {
        "surname": "Shen",
        "given_name": "Shaofeng"
      },
      {
        "surname": "Shen",
        "given_name": "Furao"
      },
      {
        "surname": "Zhao",
        "given_name": "Jian"
      }
    ]
  },
  {
    "title": "Chapter 16 Neuronal realizations based on memristive devices",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00016-2",
    "abstract": "Development of hardware-based spiking neural networks calls for novel building blocks, such as artificial neurons. This could lead to the development of systems with reduced power consumption, fault tolerance, and biomimetic artificial intelligence. Memristors, which are devices with a signal history dependent resistance, are realized via various physical mechanisms such as phase-change phenomena, redox reactions, Ovonic switching, Mott insulator-to-metal transition, and magnetoresistance. These devices possess unique dynamics which could potentially replicate biological neuronal behaviors such as leaky integrate-and-fire function. Spiking networks enabled by such artificial neurons have demonstrated intrinsic bio-realistic unsupervised learning protocols, which promises a compact and energy-efficient hardware implementation of neuromorphic computing.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000162",
    "keywords": [
      "Computer science"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Zhongrui"
      },
      {
        "surname": "Midya",
        "given_name": "Rivu"
      },
      {
        "surname": "Yang",
        "given_name": "J. Joshua"
      }
    ]
  },
  {
    "title": "Image denoising using deep CNN with batch renormalization",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.08.022",
    "abstract": "Deep convolutional neural networks (CNNs) have attracted great attention in the field of image denoising. However, there are two drawbacks: (1) it is very difficult to train a deeper CNN for denoising tasks, and (2) most of deeper CNNs suffer from performance saturation. In this paper, we report the design of a novel network called a batch-renormalization denoising network (BRDNet). Specifically, we combine two networks to increase the width of the network, and thus obtain more features. Because batch renormalization is fused into BRDNet, we can address the internal covariate shift and small mini-batch problems. Residual learning is also adopted in a holistic way to facilitate the network training. Dilated convolutions are exploited to extract more information for denoising tasks. Extensive experimental results show that BRDNet outperforms state-of-the-art image-denoising methods. The code of BRDNet is accessible at http://www.yongxu.org/lunwen.html.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302394",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Code (set theory)",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Image (mathematics)",
      "Image denoising",
      "Mathematical physics",
      "Mathematics",
      "Noise (video)",
      "Noise reduction",
      "Pattern recognition (psychology)",
      "Programming language",
      "Renormalization",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Chunwei"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      },
      {
        "surname": "Zuo",
        "given_name": "Wangmeng"
      }
    ]
  },
  {
    "title": "A waiting-time-based event-triggered scheme for stabilization of complex-valued neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.032",
    "abstract": "This paper addresses the global stabilization of complex-valued neural networks (CVNNs) via event-triggered control. First, a waiting-time-based event-triggered scheme is designed to reduce the data transmission rate. Therein, an exponential decay term is introduced into the predefined threshold function, which may postpone the triggering instant of the necessary data and therefore reduce the frequency of data transmission. Then, with the help of the input delay approach, a time-dependent piecewise-defined Lyapunov–Krasovskii functional is constructed for closed-loop system to formulate a less conservative stability criterion. In addition, by resorting to matrix transformation, the co-design method for both the feedback gains and the trigger parameters is derived. Finally, a numerical example is given to illustrate the feasibility and superiority of the proposed event-triggered scheme and the obtained theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303144",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Event (particle physics)",
      "Exponential stability",
      "Gene",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Piecewise",
      "Quantum mechanics",
      "Scheme (mathematics)",
      "Stability (learning theory)",
      "Telecommunications",
      "Term (time)",
      "Transformation (genetics)",
      "Transmission (telecommunications)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Xiaohong"
      },
      {
        "surname": "Wang",
        "given_name": "Zhen"
      },
      {
        "surname": "Song",
        "given_name": "Qiankun"
      },
      {
        "surname": "Shen",
        "given_name": "Hao"
      },
      {
        "surname": "Huang",
        "given_name": "Xia"
      }
    ]
  },
  {
    "title": "Chapter 10 Computing with device dynamics",
    "journal": "Memristive Devices for Brain-Inspired Computing",
    "year": "2020",
    "doi": "10.1016/B978-0-08-102782-0.00010-1",
    "abstract": "Unlike the three fundamental circuit components, such as resistors, capacitors, and inductors, which usually contain some linear function of current or voltage, memristors exhibit a truly and invariably nonlinear relationship between currents and voltages. This results in rich nonlinear dynamics embedded within individual components, which would otherwise require hundreds of transistors to emulate, for example, chaotic dynamics emerging from a single memristor. Meanwhile, in the world of mathematical modeling of the brain’s functioning, it has been shown that nearly all processes embody nonlinear behavior, from connections among neurons and synapses to the edge-of-chaos behavior giving rise to action potentials. In this chapter we discuss a few examples of how the rich nonlinear dynamics emerging from memristors can be used to construct brain-inspired (neuromorphic) computing systems, which remain a vastly unexplored topic that is gaining enormous attention of late.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780081027820000101",
    "keywords": [
      "Acoustics",
      "Artificial intelligence",
      "Artificial neural network",
      "Capacitor",
      "Chaotic",
      "Computer science",
      "Dynamics (music)",
      "Edge of chaos",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "Memristor",
      "Neuromorphic engineering",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Resistor",
      "Transistor",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Bohaichuk",
        "given_name": "Stephanie"
      },
      {
        "surname": "Kumar",
        "given_name": "Suhas"
      }
    ]
  },
  {
    "title": "Dynamic behaviors of the FitzHugh–Nagumo neuron model with state-dependent impulsive effects",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.09.031",
    "abstract": "In present work, in order to reproduce spiking and bursting behavior of real neurons, a new hybrid biological neuron model is established and analyzed by combining the FitzHugh–Nagumo (FHN) neuron model, the threshold for spike initiation and the state-dependent impulsive effects (impulse resetting process). Firstly, we construct Poincaré mappings under different conditions by means of geometric analysis, and then obtain some sufficient criteria for the existence and stability of order-1 or order-2 periodic solution to the impulsive neuron model by finding the fixed point of Poincaré mapping and some geometric analysis techniques. Numerical simulations are given to illustrate and verify our theoretical results. The bifurcation diagrams are presented to describe the phenomena of period-doubling route to chaos, which implies that the dynamic behavior of the neuron model become more complex due to impulsive effects. Furthermore, the correctness and effectiveness of the proposed FitzHugh–Nagumo neuron model with state-dependent impulsive effects are verified by circuit simulation. Finally, the conclusions of this paper are analyzed and summarized, and the effects of random factors on the electrophysiological activities of neuron are discussed by numerical simulation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303132",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bifurcation",
      "Biological neuron model",
      "Biology",
      "Bursting",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Correctness",
      "Impulse (physics)",
      "Mathematics",
      "Neuron",
      "Neuroscience",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Zhilong"
      },
      {
        "surname": "Li",
        "given_name": "Chuandong"
      },
      {
        "surname": "Chen",
        "given_name": "Ling"
      },
      {
        "surname": "Cao",
        "given_name": "Zhengran"
      }
    ]
  },
  {
    "title": "Privacy-enhanced multi-party deep learning",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.10.001",
    "abstract": "In multi-party deep learning, multiple participants jointly train a deep learning model through a central server to achieve common objectives without sharing their private data. Recently, a significant amount of progress has been made toward the privacy issue of this emerging multi-party deep learning paradigm. In this paper, we mainly focus on two problems in multi-party deep learning. The first problem is that most of the existing works are incapable of defending simultaneously against the attacks of honest-but-curious participants and an honest-but-curious server without a manager trusted by all participants. To tackle this problem, we design a privacy-enhanced multi-party deep learning framework, which integrates differential privacy and homomorphic encryption to prevent potential privacy leakage to other participants and a central server without requiring a manager that all participants trust. The other problem is that existing frameworks consume high total privacy budget when applying differential privacy for preserving privacy, which leads to a high risk of privacy leakage. In order to alleviate this problem, we propose three strategies for dynamically allocating privacy budget at each epoch to further enhance privacy guarantees without compromising the model utility. Moreover, it provides participants with an intuitive handle to strike a balance between the privacy level and the training efficiency by choosing different strategies. Both analytical and experimental evaluations demonstrate the promising performance of our proposed framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019303235",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Data mining",
      "Deep learning",
      "Differential privacy",
      "Encryption",
      "Homomorphic encryption",
      "Information privacy",
      "Internet privacy"
    ],
    "authors": [
      {
        "surname": "Gong",
        "given_name": "Maoguo"
      },
      {
        "surname": "Feng",
        "given_name": "Jialun"
      },
      {
        "surname": "Xie",
        "given_name": "Yu"
      }
    ]
  },
  {
    "title": "Recognition of words from brain-generated signals of speech-impaired people: Application of autoencoders as a neural Turing machine controller in deep neural networks",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.07.012",
    "abstract": "There is an essential requirement to support people with speech and communication disabilities. A brain–computer interface using electroencephalography (EEG) is applied to satisfy this requirement. A number of research studies to recognize brain signals using machine learning and deep neural networks (DNNs) have been performed to increase the brain signal detection rate, yet there are several defects and limitations in the techniques. Among them is the use in specific circumstances of machine learning. On the one hand, DNNs extract the features well and automatically. On the other hand, their use results in overfitting and vanishing problems. Consequently, in this research, a deep network is designed on the basis of an autoencoder neural Turing machine (DN-AE-NTM) to resolve the problems by the use of NTM external memory. In addition, the DN-AE-NTM copes with all kinds of signals with high detection rates. The data were collected by P300 EEG devices from several individuals under the same conditions. During the test, each individual was requested to skim images with one to six labels and focus on only one of the images. Not to focus on some images is analogous to producing unimportant information in the individual’s brain, which provides unfamiliar signals. Besides the main P300 EEG dataset, EEG recordings of individuals with alcoholism and control individuals and the EEGMMIDB, MNIST, and ORL datasets were implemented and tested. The proposed DN-AE-NTM method classifies data with an average detection rate of 97.5%, 95%, 98%, 99.4%, and 99.1%, respectively, in situations where the signals are noisy so that only 20% of the data are reliable and include useful information.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360801930200X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Brain–computer interface",
      "Computer science",
      "Convolutional neural network",
      "Electroencephalography",
      "Focus (optics)",
      "MNIST database",
      "Machine learning",
      "Neuroscience",
      "Optics",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Physics",
      "Psychology",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Boloukian",
        "given_name": "Behzad"
      },
      {
        "surname": "Safi-Esfahani",
        "given_name": "Faramarz"
      }
    ]
  },
  {
    "title": "On the validity of memristor modeling in the neural network literature",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.08.026",
    "abstract": "An analysis of the literature shows that there are two types of non-memristive models that have been widely used in the modeling of so-called “memristive” neural networks. Here, we demonstrate that such models have nothing in common with the concept of memristive elements: they describe either non-linear resistors or certain bi-state systems, which all are devices without memory. Therefore, the results presented in a significant number of publications are at least questionable, if not completely irrelevant to the actual field of memristive neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302515",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "Field (mathematics)",
      "Mathematics",
      "Memistor",
      "Memristor",
      "Pure mathematics",
      "Resistive random-access memory",
      "Resistor",
      "Theoretical computer science",
      "Topology (electrical circuits)",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Pershin",
        "given_name": "Yuriy V."
      },
      {
        "surname": "Di Ventra",
        "given_name": "Massimiliano"
      }
    ]
  },
  {
    "title": "Integrating joint feature selection into subspace learning: A formulation of 2DPCA for outliers robust feature selection",
    "journal": "Neural Networks",
    "year": "2020",
    "doi": "10.1016/j.neunet.2019.08.030",
    "abstract": "Since the principal component analysis and its variants are sensitive to outliers that affect their performance and applicability in real world, several variants have been proposed to improve the robustness. However, most of the existing methods are still sensitive to outliers and are unable to select useful features. To overcome the issue of sensitivity of PCA against outliers, in this paper, we introduce two-dimensional outliers-robust principal component analysis (ORPCA) by imposing the joint constraints on the objective function. ORPCA relaxes the orthogonal constraints and penalizes the regression coefficient, thus, it selects important features and ignores the same features that exist in other principal components. It is commonly known that square Frobenius norm is sensitive to outliers. To overcome this issue, we have devised an alternative way to derive objective function. Experimental results on four publicly available benchmark datasets show the effectiveness of joint feature selection and provide better performance as compared to state-of-the-art dimensionality-reduction methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019302576",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Curse of dimensionality",
      "Data mining",
      "Dimensionality reduction",
      "Feature selection",
      "Feature vector",
      "Gene",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Outlier",
      "Pattern recognition (psychology)",
      "Principal component analysis",
      "Robust principal component analysis",
      "Robustness (evolution)",
      "Subspace topology"
    ],
    "authors": [
      {
        "surname": "Razzak",
        "given_name": "Imran"
      },
      {
        "surname": "Saris",
        "given_name": "Raghib Abu"
      },
      {
        "surname": "Blumenstein",
        "given_name": "Michael"
      },
      {
        "surname": "Xu",
        "given_name": "Guandong"
      }
    ]
  }
]