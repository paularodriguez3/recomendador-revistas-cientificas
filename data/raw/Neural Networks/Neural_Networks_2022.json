[
  {
    "title": "Perturbation of deep autoencoder weights for model compression and classification of tabular data",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.020",
    "abstract": "Fully connected deep neural networks (DNN) often include redundant weights leading to overfitting and high memory requirements. Additionally, in tabular data classification, DNNs are challenged by the often superior performance of traditional machine learning models. This paper proposes periodic perturbations (prune and regrow) of DNN weights, especially at the self-supervised pre-training stage of deep autoencoders. The proposed weight perturbation strategy outperforms dropout learning or weight regularization (L1 or L2) for four out of six tabular data sets in downstream classification tasks. Unlike dropout learning, the proposed weight perturbation routine additionally achieves 15% to 40% sparsity across six tabular data sets, resulting in compressed pretrained models. The proposed pretrained model compression improves the accuracy of downstream classification, unlike traditional weight pruning methods that trade off performance for model compression. Our experiments reveal that a pretrained deep autoencoder with weight perturbation can outperform traditional machine learning in tabular data classification, whereas baseline fully-connected DNNs yield the worst classification accuracy. However, traditional machine learning models are superior to any deep model when a tabular data set contains uncorrelated variables. Therefore, the performance of deep models with tabular data is contingent on the types and statistics of constituent variables.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003707",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Dropout (neural networks)",
      "Machine learning",
      "Overfitting",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Abrar",
        "given_name": "Sakib"
      },
      {
        "surname": "Samad",
        "given_name": "Manar D."
      }
    ]
  },
  {
    "title": "A leader-following paradigm based deep reinforcement learning method for multi-agent cooperation games",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.012",
    "abstract": "Multi-agent deep reinforcement learning algorithms with centralized training with decentralized execution (CTDE) paradigm has attracted growing attention in both industry and research community. However, the existing CTDE methods follow the action selection paradigm that all agents choose actions at the same time, which ignores the heterogeneous roles of different agents. Motivated by the human wisdom in cooperative behaviors, we present a novel leader-following paradigm based deep multi-agent cooperation method (LFMCO) for multi-agent cooperative games. Specifically, we define a leader as someone who broadcasts a message representing the selected action to all subordinates. After that, the followers choose their individual action based on the received message from the leader. To measure the influence of leader’s action on followers, we introduced a concept of information gain, i.e., the change of followers’ value function entropy, which is positively correlated with the influence of leader’s action. We evaluate the LFMCO on several cooperation scenarios of StarCraft2. Simulation results confirm the significant performance improvements of LFMCO compared with four state-of-the-art benchmarks on the challenging cooperative environment.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200346X",
    "keywords": [
      "Action (physics)",
      "Action selection",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Entropy (arrow of time)",
      "Evolutionary biology",
      "Function (biology)",
      "Neuroscience",
      "Perception",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Reinforcement learning",
      "Selection (genetic algorithm)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Feiye"
      },
      {
        "surname": "Yang",
        "given_name": "Qingyu"
      },
      {
        "surname": "An",
        "given_name": "Dou"
      }
    ]
  },
  {
    "title": "Switching pinning control for memristive neural networks system with Markovian switching topologies",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.011",
    "abstract": "This work concentrates on the issue of leader-following bipartite synchronization of multiple memristive neural networks with Markovian jump topology. In contrast to conventional coupled neural network systems, the coupled neural network model under consideration possesses both cooperative and competitive connections among neuron nodes. Specifically, the interaction between neighbors’ nodes is described by a signed graph, in which a positive weight represents an alliance relationship between two neuron nodes while a negative weight represents an adversarial relationship between two neuron nodes. By designing a pinning discontinuous controller that makes full use of the mode information, some effective criteria that ensure the stability of bipartite synchronization error states are obtained. All network nodes can synchronize the target node state bipartitely. Finally, two simulation examples are provided to demonstrate the viability of the suggested bipartite synchronization control approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003458",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bipartite graph",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Engineering",
      "Graph",
      "Jump",
      "Mathematics",
      "Network topology",
      "Node (physics)",
      "Physics",
      "Quantum mechanics",
      "Structural engineering",
      "Synaptic weight",
      "Synchronization (alternating current)",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Ning"
      },
      {
        "surname": "Zheng",
        "given_name": "Wei Xing"
      }
    ]
  },
  {
    "title": "Adaptive graph convolutional clustering network with optimal probabilistic graph",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.017",
    "abstract": "The graph convolutional network (GCN)-based clustering approaches have achieved the impressive performance due to strong ability of exploiting the topological structure. The adjacency graph seriously affects the clustering performance, especially for non-graph data. Existing approaches usually conduct two independent steps, i.e., constructing a fixed graph structure and then graph embedding representation learning by GCN. However, the constructed graph structure may be unreliable one due to noisy data, resulting in sub-optimal graph embedding representation. In this paper, we propose an adaptive graph convolutional clustering network (AGCCN) to alternatively learn the similarity graph structure and node embedding representation in a unified framework. Our AGCCN learns the weighted adjacency graph adaptively from the node representations by solving the optimization problem of graph learning, in which adaptive and optimal neighbors for each sample are assigned with probabilistic way according to local connectivity. Then, the attribute feature extracted by parallel Auto-Encoder (AE) module is fused into the input of adaptive graph convolution module layer-by-layer to learn the comprehensive node embedding representation and strengthen its representation ability. This also skillfully alleviates the over-smoothing problem of GCN. To further improve the discriminant ability of node representation, a dual self-supervised clustering mechanism is designed to guide model optimization with pseudo-labels information. Extensive experimental results on various real-world datasets consistently show the superiority and effectiveness of the proposed deep graph clustering method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003653",
    "keywords": [
      "Adjacency list",
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Feature learning",
      "Graph",
      "Graph embedding",
      "Line graph",
      "Pattern recognition (psychology)",
      "Theoretical computer science",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Jiayi"
      },
      {
        "surname": "Guo",
        "given_name": "Jipeng"
      },
      {
        "surname": "Sun",
        "given_name": "Yanfeng"
      },
      {
        "surname": "Gao",
        "given_name": "Junbin"
      },
      {
        "surname": "Wang",
        "given_name": "Shaofan"
      },
      {
        "surname": "Yin",
        "given_name": "Baocai"
      }
    ]
  },
  {
    "title": "Event-triggered H ∞ consensus for uncertain nonlinear systems using integral sliding mode based adaptive dynamic programming",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.024",
    "abstract": "This paper studies a robust optimal consensus problem for uncertain nonlinear multi-agent systems, where the uncertainties include both input and external disturbances. Adaptive distributed observer, integral sliding mode control and H ∞ adaptive dynamic programming are integrated to obtain a sub-optimal control protocol for each follower. Firstly, an adaptive distributed observer is designed for state estimation of the leader, which serves as the reference of the ADP algorithm. Then, an H ∞ ADP algorithm is presented to make each follower track the reference in real-time. An integral sliding manifold-based discontinuous control is designed to eliminate the matched uncertainty, and continuous control is obtained by solving the Hamilton–Jacobi–Isaac equation under the H ∞ tracking framework. Two event-triggered rules are developed to relieve the communication pressure. For simplicity, a critic-only structure is used to numerically implement the proposed algorithm, and a concurrent learning technique is employed to update weights of neural networks. All signals in the closed-loop system are proven to be uniformly ultimately bounded. Finally, a simulation is conducted to demonstrate demonstrates the effectiveness of the method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003744",
    "keywords": [
      "Computer science"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Zitao"
      },
      {
        "surname": "Chen",
        "given_name": "Kairui"
      },
      {
        "surname": "Chen",
        "given_name": "Si-Zhe"
      },
      {
        "surname": "Zhang",
        "given_name": "Yun"
      }
    ]
  },
  {
    "title": "Boundary heat diffusion classifier for a semi-supervised learning in a multilayer network embedding",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.10.005",
    "abstract": "The scarcity of high-quality annotations in many application scenarios has recently led to an increasing interest in devising learning techniques that combine unlabeled data with labeled data in a network. In this work, we focus on the label propagation problem in multilayer networks. Our approach is inspired by the heat diffusion model, which shows usefulness in machine learning problems such as classification and dimensionality reduction. We propose a novel boundary-based heat diffusion algorithm that guarantees a closed-form solution with an efficient implementation. We experimentally validated our method on synthetic networks and five real-world multilayer network datasets representing scientific coauthorship, spreading drug adoption among physicians, two bibliographic networks, and a movie network. The results demonstrate the benefits of the proposed algorithm, where our boundary-based heat diffusion dominates the performance of the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003896",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Curse of dimensionality",
      "Data mining",
      "Diffusion map",
      "Dimensionality reduction",
      "Embedding",
      "Machine learning",
      "Nonlinear dimensionality reduction",
      "Semi-supervised learning"
    ],
    "authors": [
      {
        "surname": "Timilsina",
        "given_name": "Mohan"
      },
      {
        "surname": "Nováček",
        "given_name": "Vít"
      },
      {
        "surname": "d’Aquin",
        "given_name": "Mathieu"
      },
      {
        "surname": "Yang",
        "given_name": "Haixuan"
      }
    ]
  },
  {
    "title": "MG-CNN: A deep CNN to predict saddle points of matrix games",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.014",
    "abstract": "Finding the saddle point of a matrix game is a classical problem that arises in various fields, e.g., economics, computer science, and engineering. The standard problem-solving methods consist of formulating the problem as a linear program (LP). However, this approach seems less efficient when many instances need to be solved. In this paper, we propose a Convolutional Neural Network based approach, which is able to predict both the strategy profile ( x , y ) and the optimal value v of the game. We call this approach Matrix Game-Conventional Neural Network or MG-CNN for short. Thanks to a global pooling technique, MG-CNN can solve matrix games with different shapes. We propose a specialized algorithm to train MG-CNN, which includes both data generation and model training. Our numerical experiments show that MG-CNN outperforms standard LP solvers in terms of computational CPU time and provides a high-quality prediction.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003586",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Convolutional neural network",
      "Geometry",
      "Materials science",
      "Mathematical optimization",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Pooling",
      "Saddle",
      "Saddle point",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Dawen"
      },
      {
        "surname": "Lisser",
        "given_name": "Abdel"
      }
    ]
  },
  {
    "title": "Extraction of bouton-like structures from neuropil calcium imaging data",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.033",
    "abstract": "The neuropil, the plexus of axons and dendrites, plays a critical role in operating the circuit processing of the nervous system. Revealing the spatiotemporal activity pattern within the neuropil would clarify how the information flows throughout the nervous system. However, calcium imaging to examine the circuit dynamics has mainly focused on the soma population due to their discrete distribution. The development of a methodology to analyze the calcium imaging data of a densely packed neuropil would provide us with new insights into the circuit dynamics. Here, we propose a new method to decompose calcium imaging data of the neuropil into populations of bouton-like synaptic structures with a standard desktop computer. To extract bouton-like structures from calcium imaging data, we introduced a new type of modularity, a widely used quality measure in graph theory, and optimized the clustering configuration by a simulated annealing algorithm, which is established in statistical physics. To assess this method’s performance, we conducted calcium imaging of the neuropil of Drosophila larvae. Based on the obtained data, we established artificial neuropil imaging datasets. We applied the decomposition procedure to the artificial and experimental calcium imaging data and extracted individual bouton-like structures successfully. Based on the extracted spatiotemporal data, we analyzed the network structure of the central nervous system of fly larvae and found it was scale-free. These results demonstrate that neuropil calcium imaging and its decomposition could provide new insight into our understanding of neural processing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003835",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Calcium",
      "Calcium imaging",
      "Central nervous system",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Extraction (chemistry)",
      "Neuropil",
      "Neuroscience",
      "Organic chemistry",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Fukumasu",
        "given_name": "Kazushi"
      },
      {
        "surname": "Nose",
        "given_name": "Akinao"
      },
      {
        "surname": "Kohsaka",
        "given_name": "Hiroshi"
      }
    ]
  },
  {
    "title": "Shared subspace-based radial basis function neural network for identifying ncRNAs subcellular localization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.026",
    "abstract": "Non-coding RNAs (ncRNAs) play an important role in revealing the mechanism of human disease for anti-tumor and anti-virus substances. Detecting subcellular locations of ncRNAs is a necessary way to study ncRNA. Traditional biochemical methods are time-consuming and labor-intensive, and computational-based methods can help detect the location of ncRNAs on a large scale. However, many models did not consider the correlation information among multiple subcellular localizations of ncRNAs. This study proposes a radial basis function neural network based on shared subspace learning (RBFNN-SSL), which extract shared structures in multi-labels. To evaluate performance, our classifier is tested on three ncRNA datasets. Our model achieves better performance in experimental results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003768",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Classifier (UML)",
      "Coding (social sciences)",
      "Computational biology",
      "Computer science",
      "Function (biology)",
      "Gene",
      "Genetics",
      "Machine learning",
      "Mathematics",
      "Non-coding RNA",
      "Pattern recognition (psychology)",
      "Radial basis function",
      "Statistics",
      "Subcellular localization",
      "Subspace topology",
      "microRNA"
    ],
    "authors": [
      {
        "surname": "Ding",
        "given_name": "Yijie"
      },
      {
        "surname": "Tiwari",
        "given_name": "Prayag"
      },
      {
        "surname": "Guo",
        "given_name": "Fei"
      },
      {
        "surname": "Zou",
        "given_name": "Quan"
      }
    ]
  },
  {
    "title": "EEG decoding method based on multi-feature information fusion for spinal cord injury",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.016",
    "abstract": "To develop an efficient brain–computer interface (BCI) system, electroencephalography (EEG) measures neuronal activities in different brain regions through electrodes. Many EEG-based motor imagery (MI) studies do not make full use of brain network topology. In this paper, a deep learning framework based on a modified graph convolution neural network (M-GCN) is proposed, in which temporal-frequency processing is performed on the data through modified S-transform (MST) to improve the decoding performance of original EEG signals in different types of MI recognition. MST can be matched with the spatial position relationship of the electrodes. This method fusions multiple features in the temporal-frequency-spatial domain to further improve the recognition performance. By detecting the brain function characteristics of each specific rhythm, EEG generated by imaginary movement can be effectively analyzed to obtain the subjects’ intention. Finally, the EEG signals of patients with spinal cord injury (SCI) are used to establish a correlation matrix containing EEG channel information, the M-GCN is employed to decode relation features. The proposed M-GCN framework has better performance than other existing methods. The accuracy of classifying and identifying MI tasks through the M-GCN method can reach 87.456%. After 10-fold cross-validation, the average accuracy rate is 87.442%, which verifies the reliability and stability of the proposed algorithm. Furthermore, the method provides effective rehabilitation training for patients with SCI to partially restore motor function.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003641",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Brain–computer interface",
      "Computer science",
      "Decoding methods",
      "Electroencephalography",
      "Graph",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Fangzhou"
      },
      {
        "surname": "Li",
        "given_name": "Jincheng"
      },
      {
        "surname": "Dong",
        "given_name": "Gege"
      },
      {
        "surname": "Li",
        "given_name": "Jianfei"
      },
      {
        "surname": "Chen",
        "given_name": "Xinyi"
      },
      {
        "surname": "Zhu",
        "given_name": "Jianqun"
      },
      {
        "surname": "Hu",
        "given_name": "Jinglu"
      },
      {
        "surname": "Zhang",
        "given_name": "Yang"
      },
      {
        "surname": "Yue",
        "given_name": "Shouwei"
      },
      {
        "surname": "Wen",
        "given_name": "Dong"
      },
      {
        "surname": "Leng",
        "given_name": "Jiancai"
      }
    ]
  },
  {
    "title": "Surface similarity parameter: A new machine learning loss metric for oscillatory spatio-temporal data",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.023",
    "abstract": "Supervised machine learning approaches require the formulation of a loss functional to be minimized in the training phase. Sequential data are ubiquitous across many fields of research, and are often treated with Euclidean distance-based loss functions that were designed for tabular data. For smooth oscillatory data, those conventional approaches lack the ability to penalize amplitude, frequency and phase prediction errors at the same time, and tend to be biased towards amplitude errors. We introduce the surface similarity parameter (SSP) as a novel loss function that is especially useful for training machine learning models on smooth oscillatory sequences. Our extensive experiments on chaotic spatio-temporal dynamical systems indicate that the SSP is beneficial for shaping gradients, thereby accelerating the training process, reducing the final prediction error, increasing weight initialization robustness, and implementing a stronger regularization effect compared to using classical loss functions. The results indicate the potential of the novel loss metric particularly for highly complex and chaotic data, such as data stemming from the nonlinear two-dimensional Kuramoto–Sivashinsky equation and the linear propagation of dispersive surface gravity waves in fluids.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003732",
    "keywords": [],
    "authors": [
      {
        "surname": "Wedler",
        "given_name": "Mathies"
      },
      {
        "surname": "Stender",
        "given_name": "Merten"
      },
      {
        "surname": "Klein",
        "given_name": "Marco"
      },
      {
        "surname": "Ehlers",
        "given_name": "Svenja"
      },
      {
        "surname": "Hoffmann",
        "given_name": "Norbert"
      }
    ]
  },
  {
    "title": "Feature extraction framework based on contrastive learning with adaptive positive and negative samples",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.029",
    "abstract": "Feature extraction is an efficient approach for alleviating the issue of dimensionality in high-dimensional data. As a popular self-supervised learning method, contrastive learning has recently garnered considerable attention. In this study, we propose a unified feature extraction framework based on contrastive learning with adaptive positive and negative samples (CL-FEFA) that is suitable for unsupervised, supervised, and semi-supervised feature extraction. CL-FEFA constructs adaptively positive and negative samples from the result of feature extraction, which makes them more appropriate and accurate. Meanwhile, the discriminative features are extracted based on adaptive positive and negative samples, which will make the intra-class embedded samples more compact and the inter-class embedded samples more dispersed. In the process, using the potential structure information of subspace samples to dynamically construct positive and negative samples can make our framework more robust to noisy data. Furthermore, it is proven that CL-FEFA actually maximizes the mutual information of positive samples, which captures non-linear statistical dependencies between similar samples in potential structure space and thus can act as a measure of true dependence. This also provides theoretical support for its advantages in feature extraction. The final numerical experiments prove that the proposed framework has a strong advantage over traditional feature extraction methods and contrastive learning methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003793",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Curse of dimensionality",
      "Dimensionality reduction",
      "Discriminative model",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature learning",
      "Feature vector",
      "Linguistics",
      "Machine learning",
      "Mutual information",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Subspace topology"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Hongjie"
      },
      {
        "surname": "Zhao",
        "given_name": "Siyu"
      },
      {
        "surname": "Qiang",
        "given_name": "Wenwen"
      },
      {
        "surname": "Chen",
        "given_name": "Yingyi"
      },
      {
        "surname": "Jing",
        "given_name": "Ling"
      }
    ]
  },
  {
    "title": "Not all edges are peers: Accurate structure-aware graph pooling networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.004",
    "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in graph-related tasks. For graph classification task, an elaborated pooling operator is vital for learning graph-level representations. Most pooling operators derived from existing GNNs generate a coarsen graph through ordering the nodes and selecting some top-ranked ones. However, these methods fail to explore the fundamental elements other than nodes in graphs, which may not efficiently utilize the structure information. Besides, all edges attached to the low-ranked nodes are discarded, which destroys graphs’ connectivity and loses information. Moreover, the selected nodes tend to concentrate on some substructures while overlooking information in others. To address these challenges, we propose a novel pooling operator called Accurate Structure-Aware Graph Pooling (ASPool), which can be integrated into various GNNs to learn graph-level representation. Specifically, ASPool adaptively retains a subset of edges to calibrate the graph structure and learns the abstracted representations, wherein all the edges are viewed as non-peers instead of simply connecting nodes. To preserve the graph’s connectivity, we further introduce the selection strategy considering both top-ranked nodes and dropped edges. Additionally, ASPool performs a two-stage calculation process to promise that the sampled nodes are distributed throughout the graph. Experiment results on 9 widely used benchmarks show that ASPool achieves superior performance over the state-of-the-art graph representation learning methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003380",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Pooling",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Hualei"
      },
      {
        "surname": "Yuan",
        "given_name": "Jinliang"
      },
      {
        "surname": "Yao",
        "given_name": "Yirong"
      },
      {
        "surname": "Wang",
        "given_name": "Chongjun"
      }
    ]
  },
  {
    "title": "One-shot many-to-many facial reenactment using Bi-Layer Graph Convolutional Networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.031",
    "abstract": "Facial reenactment is aimed at animating a source face image into a new place using a driving facial picture. In a few shot scenarios, the present strategies are designed with one or more identities or identity-sustained suffering protection challenges. These current solutions are either developed with one or more identities in mind, or face identity protection issues in one or more shot situations. Multiple pictures from the same entity have been used in previous research to model facial reenactment. In contrast, this paper presents a novel model of one-shot many-to-many facial reenactments that uses only one facial image of a face. The proposed model produces a face that represents the objective representation of the same source identity. The proposed technique can simulate motion from a single image by decomposing an object into two layers. Using bi-layer with Convolutional Neural Network (CNN), we named our model Bi-Layer Graph Convolutional Layers (BGCLN) which utilized to create the latent vector’s optical flow representation. This yields the precise structure and shape of the optical stream. Comprehensive studies suggest that our technique can produce high-quality results and outperform most recent techniques in both qualitative and quantitative data comparisons. Our proposed system can perform facial reenactment at 15 fps, which is approximately real time. Our code is publicly available at https://github.com/usaeed786/BGCLN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003811",
    "keywords": [
      "Acoustics",
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Face (sociological concept)",
      "Graph",
      "Identity (music)",
      "Law",
      "Layer (electronics)",
      "Operating system",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Physics",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Social science",
      "Sociology",
      "Source code",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Saeed",
        "given_name": "Uzair"
      },
      {
        "surname": "Armghan",
        "given_name": "Ammar"
      },
      {
        "surname": "Quanyu",
        "given_name": "Wang"
      },
      {
        "surname": "Alenezi",
        "given_name": "Fayadh"
      },
      {
        "surname": "Yue",
        "given_name": "Sun"
      },
      {
        "surname": "Tiwari",
        "given_name": "Prayag"
      }
    ]
  },
  {
    "title": "Time series (re)sampling using Generative Adversarial Networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.010",
    "abstract": "We propose a novel bootstrap procedure for time series data based on Generative Adversarial networks (GANs). We show that the dynamics of common stationary time series processes can be learned by GANs and demonstrate that GANs trained on a single sample path can be used to generate additional samples from the process. We find that temporal convolutional neural networks provide a suitable design for the generator and discriminator, and that convincing samples can be generated on the basis of a vector drawn from a normal distribution with zero mean and an identity variance–covariance matrix. We demonstrate the finite sample properties of GAN sampling and the suggested bootstrap using simulations where we compare the performance to circular block bootstrapping in the case of resampling an AR(1) time series processes. We find that resampling using the GAN can outperform circular block bootstrapping in terms of empirical coverage. Finally, we provide an empirical application to the Sharpe ratio.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003446",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Filter (signal processing)",
      "Generative grammar",
      "Geology",
      "Machine learning",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Sampling (signal processing)",
      "Series (stratigraphy)",
      "Time series"
    ],
    "authors": [
      {
        "surname": "Dahl",
        "given_name": "Christian M."
      },
      {
        "surname": "Sørensen",
        "given_name": "Emil N."
      }
    ]
  },
  {
    "title": "Synchronization of multi-cluster complex networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.027",
    "abstract": "In this paper, a class of multi-cluster complex networks is discussed. Complete synchronization of such networks is analysed in detail. It is explored how the synchronization depends on the intra coupling matrices, the inter coupling matrices and the corresponding coupling strengths. The approach proposed also applies to more general networks composed of multi-cluster networks, too.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200377X",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Class (philosophy)",
      "Cluster (spacecraft)",
      "Combinatorics",
      "Complex network",
      "Complex system",
      "Computer network",
      "Computer science",
      "Coupling (piping)",
      "Materials science",
      "Mathematics",
      "Metallurgy",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Theoretical computer science",
      "Topology (electrical circuits)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Tianping"
      }
    ]
  },
  {
    "title": "Label smoothing and task-adaptive loss function based on prototype network for few-shot learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.018",
    "abstract": "Aiming at solving the problems of prototype network that the label information is not reliable enough and that the hyperparameters of the loss function cannot follow the changes of image feature information, we propose a method that combines label smoothing and hyperparameters. First, the label information of an image is processed by label smoothing regularization. Then, according to different classification tasks, the distance matrix and logarithmic operation of the image feature are used to fuse the distance matrix of the image with the hyperparameters of the loss function. Finally, the hyperparameters are associated with the smoothed label and the distance matrix for predictive classification. The method is validated on the miniImageNet, FC100 and tieredImageNet datasets. The results show that, compared with the unsmoothed label and fixed hyperparameters methods, the classification accuracy of the flexible hyperparameters in the loss function under the condition of few-shot learning is improved by 2%–3%. The result shows that the proposed method can suppress the interference of false labels, and the flexibility of hyperparameters can improve classification accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003689",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Machine learning",
      "Management",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Shot (pellet)",
      "Smoothing",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Farong"
      },
      {
        "surname": "Luo",
        "given_name": "Xingsheng"
      },
      {
        "surname": "Yang",
        "given_name": "Zhangyi"
      },
      {
        "surname": "Zhang",
        "given_name": "Qizhong"
      }
    ]
  },
  {
    "title": "DEFEAT: Decoupled feature attack across deep neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.009",
    "abstract": "Adversarial attacks pose a security challenge for deep neural networks, motivating researchers to build various defense methods. Consequently, the performance of black-box attacks turns down under defense scenarios. A significant observation is that some feature-level attacks achieve an excellent success rate to fool undefended models, while their transferability is severely degraded when encountering defenses, which give a false sense of security. In this paper, we explain one possible reason caused this phenomenon is the domain-overfitting effect, which degrades the capabilities of feature perturbed images and makes them hardly fool adversarially trained defenses. To this end, we study a novel feature-level method, referred to as Decoupled Feature Attack (DEFEAT). Unlike the current attacks that use a round-robin procedure to estimate gradient estimation and update perturbation, DEFEAT decouples adversarial example generation from the optimization process. In the first stage, DEFEAT learns an distribution full of perturbations with high adversarial effects. And it then iteratively samples the noises from learned distribution to assemble adversarial examples. On top of that, we can apply transformations of existing methods into the DEFEAT framework to produce more robust perturbations. We also provide insights into the relationship between transferability and latent features that helps the community to understand the intrinsic mechanism of adversarial attacks. Extensive experiments evaluated on a variety of black-box models suggest the superiority of DEFEAT, i.e., our method fools defenses at an average success rate of 88.4%, remarkably outperforming state-of-the-art transferable attacks by a large margin of 11.5%. The code is publicly available at https://github.com/mesunhlf/DEFEAT.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003434",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Black box",
      "Computer science",
      "Deep neural networks",
      "Feature (linguistics)",
      "Linguistics",
      "Logit",
      "Machine learning",
      "Margin (machine learning)",
      "Operating system",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Process (computing)",
      "Transferability"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Lifeng"
      },
      {
        "surname": "Gao",
        "given_name": "Chengying"
      },
      {
        "surname": "Liu",
        "given_name": "Ning"
      }
    ]
  },
  {
    "title": "3D face-model reconstruction from a single image: A feature aggregation approach using hierarchical transformer with weak supervision",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.019",
    "abstract": "Convolutional Neural Networks (CNN) have gained popularity as the de-facto model for any computer vision task. However, CNN have drawbacks, i.e. they fail to extract long-range perceptions in images. Due to their ability to capture long-range dependencies, transformer networks are adopted in computer vision applications, where they show state-of-the-art (SOTA) results in popular tasks like image classification, instance segmentation, and object detection. Although they gained ample attention, transformers have not been applied to 3D face reconstruction tasks. In this work, we propose a novel hierarchical transformer model, added to a feature pyramid aggregation structure, to extract the 3D face parameters from a single 2D image. More specifically, we use pre-trained Swin Transformer backbone networks in a hierarchical manner and add the feature fusion module to aggregate the features in multiple stages. We use a semi-supervised training approach and train our model in a supervised way with the 3DMM parameters from a publicly available dataset and unsupervised training with a differential renderer on other parameters like facial keypoints and facial features. We also train our network on a hybrid unsupervised loss and compare the results with other SOTA approaches. When evaluated across two public datasets on face reconstruction and dense 3D face alignment tasks, our method can achieve comparable results to the current SOTA performance and in some instances do better than the SOTA methods. A detailed subjective evaluation also shows that our method performs better than the previous works in realism and occlusion resistance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003690",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Facial recognition system",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Segmentation",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Basak",
        "given_name": "Shubhajit"
      },
      {
        "surname": "Corcoran",
        "given_name": "Peter"
      },
      {
        "surname": "McDonnell",
        "given_name": "Rachel"
      },
      {
        "surname": "Schukat",
        "given_name": "Michael"
      }
    ]
  },
  {
    "title": "Neural network-based event-triggered data-driven control of disturbed nonlinear systems with quantized input",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.021",
    "abstract": "This paper is devoted to design an event-triggered data-driven control for a class of disturbed nonlinear systems with quantized input. A uniform quantizer reconstructed with decreasing quantization intervals is employed to reduce the quantization error. A neural network-based estimation strategy is proposed to estimate both the pseudo partial derivative and disturbances. Consequently, an input triggering rule for single-input single-output systems is provided by incorporating the estimated disturbances, the quantization error bound and tracking errors. Resorting to the Lyapunov method, sufficient conditions for synthesized error systems to be uniformly ultimately bounded are presented. The validity of the proposed scheme is demonstrated via a simulation example.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003719",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantization (signal processing)",
      "Quantum mechanics",
      "Tracking error"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Xianming"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      },
      {
        "surname": "Shen",
        "given_name": "Mouquan"
      },
      {
        "surname": "Liu",
        "given_name": "Dan"
      },
      {
        "surname": "Li",
        "given_name": "Li-Wei"
      },
      {
        "surname": "Shi",
        "given_name": "Jiantao"
      }
    ]
  },
  {
    "title": "BAT: Block and token self-attention for speech emotion recognition",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.022",
    "abstract": "Transformers have achieved great success in many artificial intelligence fields, such as computer vision (CV), audio processing and natural language processing (NLP). In speech emotion recognition (SER), transformer-based architectures usually compute attention in a token-by-token (frame-by-frame) manner, but this approach lacks adequate capacity to capture local emotion information and is easily affected by noise. This paper proposes a novel SER architecture, referred to as block and token self-attention (BAT), that splits a mixed spectrogram into blocks and computes self-attention by combining these blocks with tokens, which can alleviate the effect of local noise while capturing authentic sentiment expressions. Furthermore, we present a cross-block attention mechanism to facilitate information interaction among blocks while integrating a frequency compression and channel enhancement (FCCE) module to smooth the attention biases between blocks and tokens. BAT achieves 73.2% weighted accuracy (WA) and 75.2% unweighted accuracy (UA) on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset, surpassing the results of previously developed state-of-the-art approaches with the same dataset partitioning operation. Further experimental results reveal that our proposed method is also well suited for cross-database and cross-domain tasks, achieving 89% WA and 87.4% UA on Emo-DB and producing a top-1 recognition accuracy of 88.32% with only 15.01 Mb of parameters on the CIFAR-10 image dataset under a scenario with no data augmentation or pretraining.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003720",
    "keywords": [
      "Artificial intelligence",
      "Block (permutation group theory)",
      "Computer science",
      "Computer security",
      "Geometry",
      "Image (mathematics)",
      "Mathematics",
      "Noise (video)",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Security token",
      "Spectrogram",
      "Speech recognition",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Lei",
        "given_name": "Jianjun"
      },
      {
        "surname": "Zhu",
        "given_name": "Xiangwei"
      },
      {
        "surname": "Wang",
        "given_name": "Ying"
      }
    ]
  },
  {
    "title": "Lag H ∞ synchronization in coupled reaction–diffusion neural networks with multiple state or derivative couplings",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.030",
    "abstract": "This paper mainly attempts to discuss lag H ∞ synchronization in multiple state or derivative coupled reaction–diffusion neural networks without and with parameter uncertainties. Firstly, we respectively propose two types of reaction–diffusion neural networks with multiple state and derivative couplings subject to parameter uncertainties. Secondly, by exploiting designed state feedback controllers, several criteria of the lag H ∞ synchronization for these two networks are developed based on Lyapunov functional and inequality techniques. Thirdly, lag H ∞ synchronization issues of these two networks are also coped with by virtue of devised adaptive control strategies. Finally, we provide two numerical examples to verify the obtained lag H ∞ synchronization criteria.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200380X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Derivative (finance)",
      "Diffusion",
      "Economics",
      "Financial economics",
      "Lag",
      "Operating system",
      "Physics",
      "Scalable Vector Graphics",
      "State (computer science)",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Lu"
      },
      {
        "surname": "Bian",
        "given_name": "Yougang"
      },
      {
        "surname": "Guo",
        "given_name": "Zhenyuan"
      },
      {
        "surname": "Hu",
        "given_name": "Manjiang"
      }
    ]
  },
  {
    "title": "Neurodynamic approaches for sparse recovery problem with linear inequality constraints",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.013",
    "abstract": "This paper develops two neurodynamic approaches for solving the L 1 -minimization problem with the linear inequality constraints. First, a centralized neurodynamic approach is proposed based on projection operator and nonnegative quadrant. The stability and global convergence of the centralized neurodynamic approach are analyzed by the Lyapunov method in detail. Considering that the distributed optimization problem has the advantages of information protection and scalability, the L 1 -minimization problem with linear inequality constraints is transformed into a distributed sparse optimization problem under mild conditions. Then, using the centralized neurodynamic approach and multi-agent consensus theory, a distributed neurodynamic approach is proposed for the distributed optimization problem. Furthermore, relevant theories show that each agent globally converges to an optimal solution of the distributed optimization problem. Finally, the presented centralized neurodynamic approach is applied to sparse recovery problem with L ∞ -norm noise constraints and the effectiveness of distributed approach is shown by several experiments on sparse signal recovery.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003471",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convergence (economics)",
      "Database",
      "Economic growth",
      "Economics",
      "Lyapunov function",
      "Mathematical optimization",
      "Mathematics",
      "Minification",
      "Nonlinear system",
      "Optimization problem",
      "Physics",
      "Projection (relational algebra)",
      "Quantum mechanics",
      "Scalability"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Jiao"
      },
      {
        "surname": "He",
        "given_name": "Xing"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "A privacy preservation framework for feedforward-designed convolutional neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.005",
    "abstract": "A feedforward-designed convolutional neural network (FF-CNN) is an interpretable neural network with low training complexity. Unlike a neural network trained using backpropagation (BP) algorithms and optimizers (e.g., stochastic gradient descent (SGD) and Adam), a FF-CNN obtains the model parameters in one feed-forward calculation based on two methods of data statistics: subspace approximation with adjusted bias and least squares regression. Currently, models based on FF-CNN training methods have achieved outstanding performance in the fields of image classification and point cloud data processing. In this study, we analyze and verify that there is a risk of user privacy leakage during the training process of FF-CNN and existing privacy-preserving methods for model gradients or loss functions do not apply to FF-CNN models. Therefore, we propose a securely forward-designed convolutional neural network algorithm (SFF-CNN) to protect the privacy and security of data providers for the FF-CNN model. Firstly, we propose the DPSaab algorithm to add the corresponding noise to the one-stage Saab transform in the FF-CNN design for improved protection performance. Secondly, because noise addition brings the risk of model over-fitting and further increases the possibility of privacy leakage, we propose the SJS algorithm to filter the input features of the fully connected model layer. Finally, we theoretically prove that the proposed algorithm satisfies differential privacy and experimentally demonstrate that the proposed algorithm has strong privacy protection. The proposed algorithm outperforms the compared deep learning privacy-preserving algorithms in terms of utility and robustness.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003057",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Control engineering",
      "Convolutional neural network",
      "Data mining",
      "Deep learning",
      "Differential privacy",
      "Engineering",
      "Feed forward",
      "Feedforward neural network",
      "Gene",
      "Machine learning",
      "Robustness (evolution)",
      "Stochastic gradient descent"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "De"
      },
      {
        "surname": "Wang",
        "given_name": "Jinyan"
      },
      {
        "surname": "Li",
        "given_name": "Qiyu"
      },
      {
        "surname": "Hu",
        "given_name": "Yuhang"
      },
      {
        "surname": "Li",
        "given_name": "Xianxian"
      }
    ]
  },
  {
    "title": "AFINet: Attentive Feature Integration Networks for image classification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.026",
    "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success in a number of learning tasks including image classification. Residual-like networks, such as ResNets, mainly focus on the skip connection to avoid gradient vanishing. However, the skip connection mechanism limits the utilization of intermediate features due to simple iterative updates. To mitigate the redundancy of residual-like networks, we design Attentive Feature Integration (AFI) modules, which are widely applicable to most residual-like network architectures, leading to new architectures named AFI-Nets. AFI-Nets explicitly model the correlations among different levels of features and selectively transfer features with a little overhead. AFI-ResNet-152 obtains a 1.24% relative improvement on the ImageNet dataset while decreases the FLOPs by about 10% and the number of parameters by about 9.2% compared to ResNet-152.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003264",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "FLOPS",
      "Feature (linguistics)",
      "Linguistics",
      "Machine learning",
      "Operating system",
      "Overhead (engineering)",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Redundancy (engineering)",
      "Residual",
      "Residual neural network",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Pan",
        "given_name": "Xinglin"
      },
      {
        "surname": "Xu",
        "given_name": "Jing"
      },
      {
        "surname": "Pan",
        "given_name": "Yu"
      },
      {
        "surname": "Wen",
        "given_name": "Liangjian"
      },
      {
        "surname": "Lin",
        "given_name": "Wenxiang"
      },
      {
        "surname": "Bai",
        "given_name": "Kun"
      },
      {
        "surname": "Fu",
        "given_name": "Hongguang"
      },
      {
        "surname": "Xu",
        "given_name": "Zenglin"
      }
    ]
  },
  {
    "title": "A differentiable approach to the maximum independent set problem using dataless neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.008",
    "abstract": "The success of machine learning solutions for reasoning about discrete structures has brought attention to its adoption within combinatorial optimization algorithms. Such approaches generally rely on supervised learning by leveraging datasets of the combinatorial structures of interest drawn from some distribution of problem instances. Reinforcement learning has also been employed to find such structures. In this paper, we propose a different approach in that no data is required for training the neural networks that produce the solution. In this sense, what we present is not a machine learning solution, but rather one that is dependent on neural networks and where backpropagation is applied to a loss function defined by the structure of the neural network architecture as opposed to a training dataset. In particular, we reduce the popular combinatorial optimization problem of finding a maximum independent set to a neural network and employ a dataless training scheme to refine the parameters of the network such that those parameters yield the structure of interest. Additionally, we propose a universal graph reduction procedure to handle large-scale graphs. The reduction exploits community detection for graph partitioning and is applicable to any graph type and/or density. Experimental results on both real and synthetic graphs demonstrate that our proposed method performs on par or outperforms state-of-the-art learning-based methods in terms of the size of the found set without requiring any training data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003082",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Computer science",
      "Computer security",
      "Differentiable function",
      "Exploit",
      "Graph",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Reinforcement learning",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Alkhouri",
        "given_name": "Ismail R."
      },
      {
        "surname": "Atia",
        "given_name": "George K."
      },
      {
        "surname": "Velasquez",
        "given_name": "Alvaro"
      }
    ]
  },
  {
    "title": "Online spike sorting via deep contractive autoencoder",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.001",
    "abstract": "Spike sorting – the process of separating spikes from different neurons – is often the first and most critical step in the neural data analysis pipeline. Spike-sorting techniques isolate a single neuron’s activity from background electrical noise based on the shapes of the waveforms obtained from extracellular recordings. Despite several advancements in this area, an important remaining challenge in neuroscience is online spike sorting, which has the potential to significantly advance basic neuroscience research and the clinical setting by providing the means to produce real-time perturbations of neurons via closed-loop control. Current approaches to online spike sorting are not fully automated, are computationally expensive and are often outperformed by offline approaches. In this paper, we present a novel algorithm for fast and robust online classification of single neuron activity. This algorithm is based on a deep contractive autoencoder (CAE) architecture. CAEs are neural networks that can learn a latent state representation of their inputs. The main advantage of CAE-based approaches is that they are less sensitive to noise (i.e., small perturbations in their inputs). We therefore reasoned that they can form the basis for robust online spike sorting algorithms. Overall, our deep CAE-based online spike sorting algorithm achieves over 90% accuracy in sorting unseen spike waveforms, outperforming existing models and maintaining a performance close to the offline case. In the offline scenario, our method substantially outperforms the existing models, providing an average improvement of 40% in accuracy over different datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200301X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Image (mathematics)",
      "Machine learning",
      "Noise (video)",
      "Pattern recognition (psychology)",
      "Pipeline (software)",
      "Programming language",
      "Software engineering",
      "Sorting",
      "Spike (software development)",
      "Spike sorting"
    ],
    "authors": [
      {
        "surname": "Radmanesh",
        "given_name": "Mohammadreza"
      },
      {
        "surname": "Rezaei",
        "given_name": "Ahmad Asgharian"
      },
      {
        "surname": "Jalili",
        "given_name": "Mahdi"
      },
      {
        "surname": "Hashemi",
        "given_name": "Alireza"
      },
      {
        "surname": "Goudarzi",
        "given_name": "Morteza Moazami"
      }
    ]
  },
  {
    "title": "Attentional feature pyramid network for small object detection",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.029",
    "abstract": "Recent state-of-the-art detectors generally exploit the Feature Pyramid Networks (FPN) due to its advantage of detecting objects at different scales. Despite significant advances in object detection owing to the design of feature pyramids, it is still challenging to detect small objects with low resolution and dense distribution in complex scenes. To address these problems, we propose Attentional Feature Pyramid Network, a new feature pyramid architecture named AFPN which consists of three components to enhance the small object detection ability, specifically: Dynamic Texture Attention, Foreground-Aware Co-Attention, and Detail Context Attention. First, Dynamic Texture Attention augments the texture features dynamically by filtering out redundant semantics to highlight small objects in lower layers and amplifying credible details to emphasize large objects in higher layers. Then, Foreground-Aware Co-Attention is explored to detect densely arranged small objects by enhancing the objects feature via foreground-correlated contexts and suppressing the background noise. Finally, to better capture the features of small objects, Detail Context Attention adaptively aggregates detail cues of RoI features with different scales for a more accurate feature representation. By substituting FPN with AFPN in Faster R-CNN, our method performs on par with the state-of-the-art performance on Tsinghua-Tencent 100K. Furthermore, we achieve highly competitive results on small category of both PASCAL VOC and MS COCO.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200329X",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Context (archaeology)",
      "Exploit",
      "Feature (linguistics)",
      "Geometry",
      "Linguistics",
      "Mathematics",
      "Object detection",
      "Paleontology",
      "Pascal (unit)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Pyramid (geometry)"
    ],
    "authors": [
      {
        "surname": "Min",
        "given_name": "Kyungseo"
      },
      {
        "surname": "Lee",
        "given_name": "Gun-Hee"
      },
      {
        "surname": "Lee",
        "given_name": "Seong-Whan"
      }
    ]
  },
  {
    "title": "Fast multiple graphs learning for multi-view clustering",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.027",
    "abstract": "Graph-based multi-view clustering has become an active topic due to the efficiency in characterizing both the complex structure and relationship between multimedia data. However, existing methods have the following shortcomings: (1) They are inefficient or even fail for graph learning in large scale due to the graph construction and eigen-decomposition. (2) They cannot well exploit both the complementary information and spatial structure embedded in graphs of different views. To well exploit complementary information and tackle the scalability issue plaguing graph-based multi-view clustering, we propose an efficient multiple graph learning model via a small number of anchor points and tensor Schatten p -norm minimization. Specifically, we construct a hidden and tractable large graph by anchor graph for each view and well exploit complementary information embedded in anchor graphs of different views by tensor Schatten p -norm regularizer. Finally, we develop an efficient algorithm, which scales linearly with the data size, to solve our proposed model. Extensive experimental results on several datasets indicate that our proposed method outperforms some state-of-the-art multi-view clustering algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003276",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Clustering coefficient",
      "Computer science",
      "Computer security",
      "Data mining",
      "Database",
      "Exploit",
      "Graph",
      "Machine learning",
      "Scalability",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Tianyu"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      }
    ]
  },
  {
    "title": "Location-aware convolutional neural networks for graph classification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.035",
    "abstract": "Graph patterns play a critical role in various graph classification tasks, e.g., chemical patterns often determine the properties of molecular graphs. Researchers devote themselves to adapting Convolutional Neural Networks (CNNs) to graph classification due to their powerful capability in pattern learning. The varying numbers of neighbor nodes and the lack of canonical order of nodes on graphs pose challenges in constructing receptive fields for CNNs. Existing methods generally follow a heuristic ranking-based framework, which constructs receptive fields by selecting a fixed number of nodes and dropping the others according to predetermined rules. However, such methods may lose important structure information through dropping nodes, and they also cannot learn task-oriented graph patterns. In this paper, we propose a Location learning-based Convolutional Neural Networks (LCNN) for graph classification. LCNN constructs receptive fields by learning the location of each node according to its embedding that contains structures and features information, then standard CNNs are applied to capture graph patterns. Such a location learning mechanism not only retains the information of all nodes, but also provides the ability for task-oriented pattern learning. Experimental results show the effectiveness of the proposed LCNN, and visualization results further illustrate the valid pattern learning ability of our method for graph classification.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003008",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Embedding",
      "Graph",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Zhaohui"
      },
      {
        "surname": "Cao",
        "given_name": "Qi"
      },
      {
        "surname": "Shen",
        "given_name": "Huawei"
      },
      {
        "surname": "Xu",
        "given_name": "Bingbing"
      },
      {
        "surname": "Cen",
        "given_name": "Keting"
      },
      {
        "surname": "Cheng",
        "given_name": "Xueqi"
      }
    ]
  },
  {
    "title": "Imbalanced low-rank tensor completion via latent matrix factorization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.023",
    "abstract": "Tensor completion has been widely used in computer vision and machine learning. Most existing tensor completion methods empirically assume the intrinsic tensor is simultaneous low-rank in all over modes. However, tensor data recorded from real-world applications may conflict with these assumptions, e.g., face images taken from different subjects often lie in a union of low-rank subspaces, which may result in a quite high rank or even full rank structure in its sample mode. To this aim, in this paper, we propose an imbalanced low-rank tensor completion method, which can flexibly estimate the low-rank incomplete tensor via decomposing it into a mixture of multiple latent tensor ring (TR) rank components. Specifically, each latent component is approximated using low-rank matrix factorization based on TR unfolding matrix. In addition, an effective proximal alternating minimization algorithm is developed and theoretically proved to maintain the global convergence property, that is, the whole sequence of iterates is convergent and converges to a critical point. Extensive experiments on both synthetic and real-world tensor data demonstrate that the proposed method achieves more favorable completion results with less computational cost when compared to the state-of-the-art tensor completion methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003239",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Eigenvalues and eigenvectors",
      "Gaussian",
      "Genetics",
      "Iterated function",
      "Low-rank approximation",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Matrix completion",
      "Matrix decomposition",
      "Pattern recognition (psychology)",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Rank (graph theory)",
      "Sequence (biology)",
      "Tensor (intrinsic definition)"
    ],
    "authors": [
      {
        "surname": "Qiu",
        "given_name": "Yuning"
      },
      {
        "surname": "Zhou",
        "given_name": "Guoxu"
      },
      {
        "surname": "Zeng",
        "given_name": "Junhua"
      },
      {
        "surname": "Zhao",
        "given_name": "Qibin"
      },
      {
        "surname": "Xie",
        "given_name": "Shengli"
      }
    ]
  },
  {
    "title": "Fast 2-step regularization on style optimization for real face morphing",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.007",
    "abstract": "StyleGAN is now capable of achieving excellent results, especially high-quality face synthesis. Recently, some studies have tried to invert real face images into style latent space via StyleGAN. However, morphing real faces via latent representation is still in its infancy. Training costs are high and/or require huge samples with labels. By adding regularization to style optimization, we propose a novel method to morph real faces based on StyleGAN. To do the supervised task, we label latent vectors via synthesized faces and release the label set; then we utilize logistic regression to fast discover interpretable directions in latent space. Appropriate regularization helps us to optimize both latent vectors (faces and directions). Moreover, we use learned directions under different layer representations to handle real face morphing. Compared to the existing methods, our method faster yields a larger diverse and realistic output. Code and cases are available at https://github.com/disanda/RFM.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003070",
    "keywords": [
      "Artificial intelligence",
      "Code (set theory)",
      "Computer science",
      "Face (sociological concept)",
      "Law",
      "Machine learning",
      "Morphing",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Programming language",
      "Regularization (linguistics)",
      "Representation (politics)",
      "Set (abstract data type)",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Cheng"
      },
      {
        "surname": "Wang",
        "given_name": "Wenmin"
      },
      {
        "surname": "Li",
        "given_name": "Honglei"
      },
      {
        "surname": "Bugiolacchi",
        "given_name": "Roberto"
      }
    ]
  },
  {
    "title": "Unsupervised robust discriminative subspace representation based on discriminative approximate isometric embedding",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.003",
    "abstract": "Subspace learning has shown a tremendous potential in the fields of machine learning and computer vision due to its effectiveness. Subspace representation is a key subspace learning method that encodes subspace membership information. To effectively encode the subspace memberships of data, some structured prior constraints are imposed on the subspace representation, such as low-rank, sparse, and so on. To handle various noises, existing methods tend to separate a specific type of noise using a specific way to obtain robust subspace representation. When encountering diversified noises, their subspace-preserving property may not be guaranteed. To address this issue, we propose a novel unsupervised robust discriminative subspace representation to mitigate the impacts of diversified noises via discriminative approximate isometric embedding, rather than directly separating noises from the high-dimensional space, as done like the existing methods. To ensure the performance of our approach, we provide a crucial theorem, termed as noisy Johnson–Lindenstrauss theorem. Meanwhile, Laplacian rank constraint is imposed on the discriminative subspace representation to uncover the ground truth subspace memberships of noisy data and improve the graph connectivity of subspaces. Extensive experiments on several benchmark datasets and two large-scale datasets validate the effectiveness and robustness of our approach with respect to diversified noises.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002088",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Discriminative model",
      "Embedding",
      "Gene",
      "Geometry",
      "Graph",
      "Law",
      "Linear subspace",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Random subspace method",
      "Representation (politics)",
      "Robustness (evolution)",
      "Subspace topology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Jianwei"
      }
    ]
  },
  {
    "title": "Three approaches to facilitate invariant neurons and generalization to out-of-distribution orientations and illuminations",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.026",
    "abstract": "The training data distribution is often biased towards objects in certain orientations and illumination conditions. While humans have a remarkable capability of recognizing objects in out-of-distribution (OoD) orientations and illuminations, Deep Neural Networks (DNNs) severely suffer in this case, even when large amounts of training examples are available. Neurons that are invariant to orientations and illuminations have been proposed as a neural mechanism that could facilitate OoD generalization, but it is unclear how to encourage the emergence of such invariant neurons. In this paper, we investigate three different approaches that lead to the emergence of invariant neurons and substantially improve DNNs in recognizing objects in OoD orientations and illuminations. Namely, these approaches are (i) training much longer after convergence of the in-distribution (InD) validation accuracy, i.e., late-stopping, (ii) tuning the momentum parameter of the batch normalization layers, and (iii) enforcing invariance of the neural activity in an intermediate layer to orientation and illumination conditions. Each of these approaches substantially improves the DNN’s OoD accuracy (more than 20% in some cases). We report results in four datasets: two datasets are modified from the MNIST and iLab datasets, and the other two are novel (one of 3D rendered cars and another of objects taken from various controlled orientations and illumination conditions). These datasets allow to study the effects of different amounts of bias and are challenging as DNNs perform poorly in OoD conditions. Finally, we demonstrate that even though the three approaches focus on different aspects of DNNs, they all tend to lead to the same underlying neural mechanism to enable OoD accuracy gains — individual neurons in the intermediate layers become invariant to OoD orientations and illuminations. We anticipate this study to be a basis for further improvement of deep neural networks’ OoD generalization performance, which is highly demanded to achieve safe and fair AI applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200288X",
    "keywords": [
      "Anthropology",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep neural networks",
      "Generalization",
      "Invariant (physics)",
      "MNIST database",
      "Mathematical analysis",
      "Mathematical physics",
      "Mathematics",
      "Normalization (sociology)",
      "Pattern recognition (psychology)",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Sakai",
        "given_name": "Akira"
      },
      {
        "surname": "Sunagawa",
        "given_name": "Taro"
      },
      {
        "surname": "Madan",
        "given_name": "Spandan"
      },
      {
        "surname": "Suzuki",
        "given_name": "Kanata"
      },
      {
        "surname": "Katoh",
        "given_name": "Takashi"
      },
      {
        "surname": "Kobashi",
        "given_name": "Hiromichi"
      },
      {
        "surname": "Pfister",
        "given_name": "Hanspeter"
      },
      {
        "surname": "Sinha",
        "given_name": "Pawan"
      },
      {
        "surname": "Boix",
        "given_name": "Xavier"
      },
      {
        "surname": "Sasaki",
        "given_name": "Tomotake"
      }
    ]
  },
  {
    "title": "Joint clothes image detection and search via anchor free framework",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.011",
    "abstract": "Clothes image search is an important learning task in fashion analysis to find the most relevant clothes in a database given a user-provided query. To address this problem, most existing methods employ a two-step approach, i.e., first detect the target clothes, and then crop it to feed the model for similarity learning. But the two-step approach is time-consuming and resource-intensive. On the other hand, one-step methods provide efficient solutions to integrate clothes detection and search in a unified framework. However, since one-step methods usually explore anchor-based detectors, they inevitably inherit limitations, such as high computational complexity caused by dense anchors, and high sensitivity to hyperparameters. To address the aforementioned issues, we propose an anchor-free framework for joint clothes detection and search. Specifically, we first choose an anchor-free detector as backbone. We then add a mask prediction branch and a Re-ID embedding branch to the framework. The mask prediction branch aims to predict the masks of clothes, while Re-ID embedding branch aims to extract the rich embedding features of clothes, in which we aggregate the feature of clothes via a mask pooling module by referencing the estimated target clothes masks. In this way, the extracted target clothes features can grasp more information in the area of the clothes mask; finally, we further introduce a match loss to fine-tune the embedding feature in Re-ID branch for improving the retrieval performance. Simulation results based on real datasets demonstrate the effectiveness of the proposed work.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003112",
    "keywords": [
      "Aggregate (composite)",
      "Archaeology",
      "Artificial intelligence",
      "Clothing",
      "Composite material",
      "Computer science",
      "Computer vision",
      "Embedding",
      "Feature (linguistics)",
      "History",
      "Linguistics",
      "Machine learning",
      "Materials science",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pooling"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Mingbo"
      },
      {
        "surname": "Gao",
        "given_name": "Shanchuan"
      },
      {
        "surname": "Ma",
        "given_name": "Jianghong"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhao"
      }
    ]
  },
  {
    "title": "Integral representations of shallow neural network with rectified power unit activation function",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.005",
    "abstract": "In this paper we characterize the set of functions that can be represented by infinite width neural networks with RePU activation function max ( 0 , x ) p , when the network coefficients are regularized by an ℓ 2 / p (quasi)norm. Compared to the more well-known ReLU activation function (which corresponds to p = 1 ), the RePU activation functions exhibit a greater degree of smoothness which makes them preferable in several applications. Our main result shows that such representations are possible for a given function if and only if the function is κ -order Lipschitz and its R -norm is finite. This extends earlier work on this topic that has been restricted to the case of the ReLU activation function and coefficient bounds with respect to the ℓ 2 norm. Since for q < 2 , ℓ q regularizations are known to promote sparsity, our results also shed light on the ability to obtain sparse neural network representations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003392",
    "keywords": [
      "Activation function",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Law",
      "Lipschitz continuity",
      "Mathematics",
      "Norm (philosophy)",
      "Political science",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Abdeljawad",
        "given_name": "Ahmed"
      },
      {
        "surname": "Grohs",
        "given_name": "Philipp"
      }
    ]
  },
  {
    "title": "A novel Lyapunov stability analysis of neutral-type Cohen–Grossberg neural networks with multiple delays",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.022",
    "abstract": "The major target of this research article is to conduct a new Lyapunov stability analysis of a special model of Cohen–Grossberg neural networks that include multiple delay terms in state variables of systems neurons and multiple delay terms in time derivatives of state variables of systems neurons in the network structure. Employing some proper linear combinations of three different positive definite and positive semi-definite Lyapunov functionals, we obtain some novel sufficient criteria that guarantee global asymptotic stability of this type of multiple delayed Cohen–Grossberg type neural systems. These newly derived stability results are determined to be completely independent of the involved time delay terms and neutral delay terms, and they are totally characterized by the values of the interconnection parameters of Cohen–Grossberg neural system. Besides, the validation of the obtained stability criteria can be justified by applying some simple appropriate algebraic equations that form some particular relations among the constant system elements of the considered neutral neural systems. A useful and instructive numerical example is analysed to exhibit some major advantages and novelties of these newly proposed global stability results in this paper over some previously reported corresponding asymptotic stability conditions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003227",
    "keywords": [
      "Algebraic number",
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Ecology",
      "Eigenvalues and eigenvectors",
      "Epistemology",
      "Exponential stability",
      "Interconnection",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Philosophy",
      "Physics",
      "Positive-definite matrix",
      "Quantum mechanics",
      "Simple (philosophy)",
      "Stability (learning theory)",
      "State (computer science)",
      "State variable",
      "Thermodynamics",
      "Type (biology)"
    ],
    "authors": [
      {
        "surname": "Faydasicok",
        "given_name": "Ozlem"
      },
      {
        "surname": "Arik",
        "given_name": "Sabri"
      }
    ]
  },
  {
    "title": "LGLNN: Label Guided Graph Learning-Neural Network for few-shot learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.003",
    "abstract": "Graph Neural Networks (GNNs) have been employed for few-shot learning (FSL) tasks. The aim of GNN based FSL is to transform the few-shot learning problem into a graph node classification or edge labeling tasks, which can thus fully explore the relationships among samples in support and query sets. However, existing works generally consider the graph learned by node features which ignore the initial pairwise label constraints and thus are generally not guaranteed to be optimal for FSL tasks. Also, existing works generally learn graph edges independently based on node’s own features which lack of considering the consistent relationships among different edges. To address these issues, we propose a novel Label Guided Graph Learning-Neural network (LGLNN) model for FSL tasks. The aim of LGLNN is to incorporate the label information to learn an optimal metric graph for GNN by employing the pairwise constraint propagation. The main advantage of LGLNN is that it can learn the metrics (both similarity and dissimilarity) for each graph edge by aggregating the metric information from its neighboring edges and thus can conduct metric learning of all edges cooperatively and consistently. Experimental results demonstrate the effectiveness and better performance of the proposed LGLNN method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003033",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Economics",
      "Graph",
      "Machine learning",
      "Metric (unit)",
      "Operations management",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Kangkang"
      },
      {
        "surname": "Zhang",
        "given_name": "Ziyan"
      },
      {
        "surname": "Jiang",
        "given_name": "Bo"
      },
      {
        "surname": "Tang",
        "given_name": "Jin"
      }
    ]
  },
  {
    "title": "Neural Networks special issue on Artificial Intelligence and Brain Science",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.018",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003185",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognitive science",
      "Computer science",
      "Machine learning",
      "Nervous system network models",
      "Psychology",
      "Time delay neural network",
      "Types of artificial neural networks"
    ],
    "authors": [
      {
        "surname": "Doya",
        "given_name": "Kenji"
      },
      {
        "surname": "Friston",
        "given_name": "Karl"
      },
      {
        "surname": "Sugiyama",
        "given_name": "Masashi"
      },
      {
        "surname": "Tenenbaum",
        "given_name": "Josh"
      }
    ]
  },
  {
    "title": "Quantization-aware training for low precision photonic neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.015",
    "abstract": "Recent advances in Deep Learning (DL) fueled the interest in developing neuromorphic hardware accelerators that can improve the computational speed and energy efficiency of existing accelerators. Among the most promising research directions towards this is photonic neuromorphic architectures, which can achieve femtojoule per MAC efficiencies. Despite the benefits that arise from the use of neuromorphic architectures, a significant bottleneck is the use of expensive high-speed and precision analog-to-digital (ADCs) and digital-to-analog conversion modules (DACs) required to transfer the electrical signals, originating from the various Artificial Neural Networks (ANNs) operations (inputs, weights, etc.) in the photonic optical engines. The main contribution of this paper is to study quantization phenomena in photonic models, induced by DACs/ADCs, as an additional noise/uncertainty source and to provide a photonics-compliant framework for training photonic DL models with limited precision, allowing for reducing the need for expensive high precision DACs/ADCs. The effectiveness of the proposed method is demonstrated using different architectures, ranging from fully connected and convolutional networks to recurrent architectures, following recent advances in photonic DL.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003598",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bottleneck",
      "Computer architecture",
      "Computer engineering",
      "Computer science",
      "Convolutional neural network",
      "Efficient energy use",
      "Electrical engineering",
      "Electronic engineering",
      "Embedded system",
      "Engineering",
      "Neuromorphic engineering",
      "Optics",
      "Photonics",
      "Physics",
      "Quantization (signal processing)"
    ],
    "authors": [
      {
        "surname": "Kirtas",
        "given_name": "M."
      },
      {
        "surname": "Oikonomou",
        "given_name": "A."
      },
      {
        "surname": "Passalis",
        "given_name": "N."
      },
      {
        "surname": "Mourgias-Alexandris",
        "given_name": "G."
      },
      {
        "surname": "Moralis-Pegios",
        "given_name": "M."
      },
      {
        "surname": "Pleros",
        "given_name": "N."
      },
      {
        "surname": "Tefas",
        "given_name": "A."
      }
    ]
  },
  {
    "title": "Comprehensive analysis of fixed-time stability and energy cost for delay neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.024",
    "abstract": "This paper focuses on comprehensive analysis of fixed-time stability and energy consumed by controller in nonlinear neural networks with time-varying delays. A sufficient condition is provided to assure fixed-time stability by developing a global composite switched controller and employing inequality techniques. Then the specific expression of the upper of energy required for achieving control is deduced. Moreover, the comprehensive analysis of the energy cost and fixed-time stability is investigated utilizing a dual-objective optimization function. It illustrates that adjusting the control parameters can make the system converge to the equilibrium point under better control state. Finally, one numerical example is presented to verify the effectiveness of the provided control scheme.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003240",
    "keywords": [
      "Agronomy",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Dual (grammatical number)",
      "Energy (signal processing)",
      "Equilibrium point",
      "Evolutionary biology",
      "Fixed point",
      "Function (biology)",
      "Literature",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yuchun"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      },
      {
        "surname": "Shao",
        "given_name": "Hu"
      },
      {
        "surname": "Feng",
        "given_name": "Yu"
      },
      {
        "surname": "Wang",
        "given_name": "Li"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Explaining Aha! moments in artificial agents through IKE-XAI: Implicit Knowledge Extraction for eXplainable AI",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.002",
    "abstract": "During the learning process, a child develops a mental representation of the task he or she is learning. A Machine Learning algorithm develops also a latent representation of the task it learns. We investigate the development of the knowledge construction of an artificial agent through the analysis of its behavior, i.e., its sequences of moves while learning to perform the Tower of Hanoï (TOH) task. The TOH is a well-known task in experimental contexts to study the problem-solving processes and one of the fundamental processes of children’s knowledge construction about their world. We position ourselves in the field of explainable reinforcement learning for developmental robotics, at the crossroads of cognitive modeling and explainable AI. Our main contribution proposes a 3-step methodology named Implicit Knowledge Extraction with eXplainable Artificial Intelligence (IKE-XAI) to extract the implicit knowledge, in form of an automaton, encoded by an artificial agent during its learning. We showcase this technique to solve and explain the TOH task when researchers have only access to moves that represent observational behavior as in human–machine interaction. Therefore, to extract the agent acquired knowledge at different stages of its training, our approach combines: first, a Q-learning agent that learns to perform the TOH task; second, a trained recurrent neural network that encodes an implicit representation of the TOH task; and third, an XAI process using a post-hoc implicit rule extraction algorithm to extract finite state automata. We propose using graph representations as visual and explicit explanations of the behavior of the Q-learning agent. Our experiments show that the IKE-XAI approach helps understanding the development of the Q-learning agent behavior by providing a global explanation of its knowledge evolution during learning. IKE-XAI also allows researchers to identify the agent’s Aha! moment by determining from what moment the knowledge representation stabilizes and the agent no longer learns.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003021",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Economics",
      "Law",
      "Machine learning",
      "Management",
      "Operating system",
      "Political science",
      "Politics",
      "Process (computing)",
      "Reinforcement learning",
      "Representation (politics)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Chraibi Kaadoud",
        "given_name": "Ikram"
      },
      {
        "surname": "Bennetot",
        "given_name": "Adrien"
      },
      {
        "surname": "Mawhin",
        "given_name": "Barbara"
      },
      {
        "surname": "Charisi",
        "given_name": "Vicky"
      },
      {
        "surname": "Díaz-Rodríguez",
        "given_name": "Natalia"
      }
    ]
  },
  {
    "title": "Interpretable Artificial Intelligence through Locality Guided Neural Networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.009",
    "abstract": "In current deep learning architectures, each of the deeper layers in networks tends to contain hundreds of unorganized neurons which makes it hard for humans to understand how they interact with each other. By organizing the neurons using correlation as the criteria, humans can observe how clusters of neighbouring neurons interact with each other. Research in Explainable Artificial Intelligence (XAI) aims to all alleviate the black-box nature of current AI methods and make them understandable by humans. In this paper, we extend our previous algorithm for XAI in deep learning, called Locality Guided Neural Network (LGNN). LGNN preserves locality between neighbouring neurons within each layer of a deep network during training. Motivated by Self-Organizing Maps (SOMs), the goal is to enforce a local topology on each layer of a deep network such that neighbouring neurons are highly correlated with each other. Our algorithm can be easily plugged into current state of the art Convolutional Neural Network (CNN) models to make the neighbouring neurons more correlated. A cluster of neighbouring neurons activating for a class makes the network both quantitatively and qualitatively more interpretable when visualized, as we show through our experiments. This paper focuses on image processing with CNNs, but can theoretically be applied to any type of deep learning architecture. In our experiments, we train VGG and WRN networks for image classification on CIFAR100 and Imagenette. Our experiments analyse different perceptible clusters of activations in response to different input classes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003094",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Combinatorics",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Layer (electronics)",
      "Linguistics",
      "Locality",
      "Machine learning",
      "Mathematics",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Tan",
        "given_name": "Randy"
      },
      {
        "surname": "Gao",
        "given_name": "Lei"
      },
      {
        "surname": "Khan",
        "given_name": "Naimul"
      },
      {
        "surname": "Guan",
        "given_name": "Ling"
      }
    ]
  },
  {
    "title": "Sequential safe feature elimination rule for L 1 -regularized regression with Kullback–Leibler divergence",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.008",
    "abstract": "The L 1 -regularized regression with Kullback–Leibler divergence (KL- L 1 R) is a popular regression technique. Although many efforts have been devoted to its efficient implementation, it remains challenging when the number of features is extremely large. In this paper, to accelerate KL- L 1 R, we introduce a novel and fast sequential safe feature elimination rule (FER) based on its sparsity, local regularity properties, and duality theory. It takes negligible time to select and delete most redundant features before and during the training process. Only one reduced model needs to be solved, which makes the computational time shortened. To further speed up the reduced model, the Newton coordinate descent method (Newton-CDM) is chosen as a solver. The superiority of FER is safety, i.e., its solution is exactly the same as the original KL- L 1 R. Numerical experiments on three artificial datasets, five real-world datasets, and one handwritten digit dataset demonstrate the feasibility and validity of our FER.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003422",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Coordinate descent",
      "Divergence (linguistics)",
      "Feature (linguistics)",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Philosophy",
      "Programming language",
      "Solver"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Hongmei"
      },
      {
        "surname": "Jiang",
        "given_name": "Kun"
      },
      {
        "surname": "Xu",
        "given_name": "Yitian"
      }
    ]
  },
  {
    "title": "Synergetic learning structure-based neuro-optimal fault tolerant control for unknown nonlinear systems",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.010",
    "abstract": "In this paper, a synergetic learning structure-based neuro-optimal fault tolerant control (SLSNOFTC) method is proposed for unknown nonlinear continuous-time systems with actuator failures. Under the framework of the synergetic learning structure (SLS), the optimal control input and the actuator failure are viewed as two subsystems. Then, the fault tolerant control (FTC) problem can be regarded as a two-player zero-sum differential game according to the game theory. A radial basis function neural network-based identifier, which uses the measured input/output data, is constructed to identify the completely unknown system dynamics. To develop the SLSNOFTC method, the Hamilton–Jacobi–Isaacs equation is solved by an asymptotically stable critic neural network (ASCNN) which is composed of cooperative adaptive tuning laws. Besides, with the help of the Lyapunov stability analysis, the identification error, the weight error of ASCNN, and all signals of closed-loop system are guaranteed to be converged to zero asymptotically, rather than uniformly ultimately bounded. Numerical simulation examples further verify the effectiveness and reliability of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003100",
    "keywords": [
      "Actuator",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differential game",
      "Distributed computing",
      "Fault tolerance",
      "Identifier",
      "Lyapunov function",
      "Lyapunov stability",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Stability theory"
    ],
    "authors": [
      {
        "surname": "Xia",
        "given_name": "Hongbing"
      },
      {
        "surname": "Zhao",
        "given_name": "Bo"
      },
      {
        "surname": "Guo",
        "given_name": "Ping"
      }
    ]
  },
  {
    "title": "Support vector machine embedding discriminative dictionary pair learning for pattern classification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.031",
    "abstract": "Discriminative dictionary learning (DDL) aims to address pattern classification problems via learning dictionaries from training samples. Dictionary pair learning (DPL) based DDL has shown superiority as compared with most existing algorithms which only learn synthesis dictionaries or analysis dictionaries. However, in the original DPL algorithm, the discrimination capability is only promoted via the reconstruction error and the structures of the learned dictionaries, while the discrimination of coding coefficients is not considered in the process of dictionary learning. To address this issue, we propose a new DDL algorithm by introducing an additional discriminative term associated with coding coefficients. Specifically, a support vector machine (SVM) based term is employed to enhance the discrimination of coding coefficients. In this model, a structured dictionary pair and SVM classifiers are jointly learned, and an optimization method is developed to address the formulated optimization problem. A classification scheme based on both the reconstruction error and SVMs is also proposed. Simulation results on several widely used databases demonstrate that the proposed method can achieve competitive performance as compared with some state-of-the-art DDL algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003318",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Coding (social sciences)",
      "Computer science",
      "Discriminative model",
      "Embedding",
      "K-SVD",
      "Machine learning",
      "Mathematics",
      "Neural coding",
      "Optimization problem",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Sparse approximation",
      "Statistics",
      "Support vector machine",
      "Term (time)"
    ],
    "authors": [
      {
        "surname": "Dong",
        "given_name": "Jing"
      },
      {
        "surname": "Yang",
        "given_name": "Liu"
      },
      {
        "surname": "Liu",
        "given_name": "Chang"
      },
      {
        "surname": "Cheng",
        "given_name": "Wei"
      },
      {
        "surname": "Wang",
        "given_name": "Wenwu"
      }
    ]
  },
  {
    "title": "DualG-GAN, a Dual-channel Generator based Generative Adversarial Network for text-to-face synthesis",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.016",
    "abstract": "Text-to-image synthesis is a fundamental and challenging task in computer vision, which aims to synthesize realistic images from given descriptions. Recently, text-to-image synthesis methods have achieved great improvements in the quality of synthesized images. However, very few works have explored its application in the scenario of face synthesis, which is of great potentials in face-related applications and the public safety domain. On the other side, the faces generated by existing methods are generally of poor quality and have low consistency to the given text. To tackle this issue, in this paper, we build a novel end-to-end dual-channel generator based generative adversarial network, named DualG-GAN, to improve the quality of the generated images and the consistency to the text description. In DualG-GAN, to improve the consistency between the synthesized image and the input description, a dual-channel generator block is introduced, and a novel loss is designed to improve the similarity between the generated image and the ground-truth in three different semantic levels. Extensive experiments demonstrate that DualG-GAN achieves state-of-the-art results on SCU-Text2face dataset. To further verify the performance of DualG-GAN, we compare it with the current optimal methods on text-to-image synthesis tasks, where quantitative and qualitative results show that the proposed DualG-GAN achieves optimal performance in both Fréchet inception distance (FID) and R-precision metrics. As only a few works are focusing on text-to-face synthesis, this work can be seen as a baseline for future research.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003161",
    "keywords": [
      "Algorithm",
      "Art",
      "Artificial intelligence",
      "Block (permutation group theory)",
      "Channel (broadcasting)",
      "Computer engineering",
      "Computer network",
      "Computer science",
      "Consistency (knowledge bases)",
      "Dual (grammatical number)",
      "Economics",
      "Epistemology",
      "Face (sociological concept)",
      "Generative adversarial network",
      "Generative grammar",
      "Generator (circuit theory)",
      "Geometry",
      "Ground truth",
      "Image (mathematics)",
      "Image synthesis",
      "Literature",
      "Management",
      "Mathematics",
      "Philosophy",
      "Physics",
      "Power (physics)",
      "Quality (philosophy)",
      "Quantum mechanics",
      "Similarity (geometry)",
      "Social science",
      "Sociology",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Luo",
        "given_name": "Xiaodong"
      },
      {
        "surname": "He",
        "given_name": "Xiaohai"
      },
      {
        "surname": "Chen",
        "given_name": "Xiang"
      },
      {
        "surname": "Qing",
        "given_name": "Linbo"
      },
      {
        "surname": "Zhang",
        "given_name": "Jin"
      }
    ]
  },
  {
    "title": "LS-NTP: Unifying long- and short-range spatial correlations for near-surface temperature prediction",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.022",
    "abstract": "The near-surface temperature prediction (NTP) is an important spatial–temporal forecast problem, which can be used to prevent temperature crises. Most of the previous approaches fail to explicitly model the long- and short-range spatial correlations simultaneously, which is critical to making an accurate temperature prediction. In this study, both long- and short-range spatial correlations are captured to fill this gap by a novel convolution operator named Long- and Short-range Convolution (LS-Conv). The proposed LS-Conv operator includes three key components, namely, Node-based Spatial Attention (NSA), Long-range Adaptive Graph Constructor (LAGC), and Long- and Short-range Integrator (LSI). To capture long-range spatial correlations, NSA and LAGC are proposed to evaluate node importance aiming at auto-constructing long-range spatial correlations, which is named as Long-range aware Graph Convolution Network (LR-GCN). After that, the Short-range aware Convolution Neural Network (SR-CNN) accounts for the short-range spatial correlations. Finally, LSI is proposed to capture both long- and short-range spatial correlations by intra-unifying LR-GCN and SR-CNN. Upon the proposed LS-Conv operator, a new model called Long- and Short-range for NPT (LS-NTP) is developed. Extensive experiments are conducted on two real-world datasets and the results demonstrate that the proposed method outperforms state-of-the-art techniques. The source code is available on GitHub:https://github.com/xuguangning1218/LS_NTP.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002787",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bandwidth (computing)",
      "Biochemistry",
      "Chemistry",
      "Composite material",
      "Computer network",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Data mining",
      "Gene",
      "Graph",
      "Integrator",
      "Materials science",
      "Node (physics)",
      "Operator (biology)",
      "Physics",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Repressor",
      "Theoretical computer science",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Guangning"
      },
      {
        "surname": "Li",
        "given_name": "Xutao"
      },
      {
        "surname": "Feng",
        "given_name": "Shanshan"
      },
      {
        "surname": "Ye",
        "given_name": "Yunming"
      },
      {
        "surname": "Tu",
        "given_name": "Zhihua"
      },
      {
        "surname": "Lin",
        "given_name": "Kenghong"
      },
      {
        "surname": "Huang",
        "given_name": "Zhichao"
      }
    ]
  },
  {
    "title": "Hierarchical binding in convolutional neural networks: Making adversarial attacks geometrically challenging",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.003",
    "abstract": "We approach the issue of robust machine vision by presenting a novel deep-learning architecture, inspired by work in theoretical neuroscience on how the primate brain performs visual feature binding. Feature binding describes how separately represented features are encoded in a relationally meaningful way, such as an edge composing part of the larger contour of an object. We propose that the absence of such representations from current models might partly explain their vulnerability to small, often humanly-imperceptible distortions known as adversarial examples. It has been proposed that adversarial examples are a result of ‘off-manifold’ perturbations of images. Our novel architecture is designed to approximate hierarchical feature binding, providing explicit representations in these otherwise vulnerable directions. Having introduced these representations into convolutional neural networks, we provide empirical evidence of enhanced robustness against a broad range of L 0 , L 2 and L ∞ attacks, particularly in the black-box setting. While we eventually report that the model remains vulnerable to a sufficiently powerful attacker (i.e. the defense can be broken), we demonstrate that our main results cannot be accounted for by trivial, false robustness (gradient masking). Analysis of the representational geometry of our architectures shows a positive relationship between hierarchical binding, expanded manifolds, and robustness. Through hyperparameter manipulation, we find evidence that robustness emerges through the preservation of general low-level information alongside more abstract features, rather than by capturing which specific low-level features drove the abstract representation. Finally, we propose how hierarchical binding relates to the observation that, under appropriate viewing conditions, humans show sensitivity to adversarial examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002593",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Deep neural networks",
      "Gene",
      "Hyperparameter",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Leadholm",
        "given_name": "Niels"
      },
      {
        "surname": "Stringer",
        "given_name": "Simon"
      }
    ]
  },
  {
    "title": "Electrical coupling regulated by GABAergic nucleo-olivary afferent fibres facilitates cerebellar sensory–motor adaptation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.020",
    "abstract": "The inferior olivary (IO) nucleus makes up the signal gateway for several organs to the cerebellar cortex. Located within the sensory–motor-cerebellum pathway, the IO axons, i.e., climbing fibres (CFs), massively synapse onto the cerebellar Purkinje cells (PCs) regulating motor learning whilst the olivary nucleus receives negative feedback through the GABAergic nucleo-olivary​ (NO) pathway. The NO pathway regulates the electrical coupling (EC) amongst the olivary cells thus facilitating synchrony and timing. However, the involvement of this EC regulation on cerebellar adaptive behaviour is still under debate. In our study we have used a spiking cerebellar model to assess the role of the NO pathway in regulating vestibulo-ocular-reflex (VOR) adaptation. The model incorporates spike-based synaptic plasticity at multiple cerebellar sites and an electrically-coupled olivary system. The olivary system plays a central role in regulating the CF spike-firing patterns that drive the PCs, whose axons ultimately shape the cerebellar output. Our results suggest that a systematic GABAergic NO deactivation decreases the spatio-temporal complexity of the IO firing patterns thereby worsening the temporal resolution of the olivary system. Conversely, properly coded IO spatio-temporal firing patterns, thanks to NO modulation, finely shape the balance between long-term depression and potentiation, which optimises VOR adaptation. Significantly, the NO connectivity pattern constrained to the same micro-zone helps maintain the spatio-temporal complexity of the IO firing patterns through time. Moreover, the temporal alignment between the latencies found in the NO fibres and the sensory–motor pathway delay appears to be crucial for facilitating the VOR. When we consider all the above points we believe that these results predict that the NO pathway is instrumental in modulating the olivary coupling and relevant to VOR adaptation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003203",
    "keywords": [
      "Biology",
      "Cerebellar cortex",
      "Cerebellar hemisphere",
      "Cerebellum",
      "Climbing fiber",
      "Cochlear nucleus",
      "Coupling (piping)",
      "Deep cerebellar nuclei",
      "GABAergic",
      "Inferior olivary nucleus",
      "Inhibitory postsynaptic potential",
      "Materials science",
      "Metallurgy",
      "Neuroscience",
      "Nucleus",
      "Sensory system",
      "Superior olivary complex"
    ],
    "authors": [
      {
        "surname": "Luque",
        "given_name": "Niceto R."
      },
      {
        "surname": "Naveros",
        "given_name": "Francisco"
      },
      {
        "surname": "Abadía",
        "given_name": "Ignacio"
      },
      {
        "surname": "Ros",
        "given_name": "Eduardo"
      },
      {
        "surname": "Arleo",
        "given_name": "Angelo"
      }
    ]
  },
  {
    "title": "Multi-agent based optimal equilibrium selection with resilience constraints for traffic flow",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.013",
    "abstract": "Traffic guidance and traffic control are effective means to alleviate traffic problems. Formulating effective traffic guidance measures can improve the utilization rate of road resources and optimize the performance of the entire traffic network. Assuming that the traffic coordinator can capture traffic flow information in real-time utilizing sensors installed on each road, we consider the strong resilience constraints to construct an optimal selection problem of balanced flow in the traffic network. Based on multi-agent modeling, each agent has access to the corresponding traffic information of each link. We design a distributed optimization algorithm to tackle this optimization problem. In addition to the inherent advantages of distributed multi-agent algorithms, the communication topology among the sensors is allowed to be time-varying, which is more consistent with reality. To prove the effectiveness of the proposed algorithm, we also give a numerical simulation in the multi-agent environment. It should be reiterated that the optimization problem studied in this paper mainly focuses on traffic managers’ perspectives. The goal of the studied optimization problem is to minimize the overall cost of the traffic network by adjusting the optimal equilibrium traffic flow. This study provides a reference for solving congestion optimization in today’s cities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003136",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer network",
      "Computer science",
      "Distributed computing",
      "Engineering",
      "Floating car data",
      "Genetic algorithm",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Physics",
      "Real-time computing",
      "Resilience (materials science)",
      "Selection (genetic algorithm)",
      "Thermodynamics",
      "Traffic congestion",
      "Traffic flow (computer networking)",
      "Traffic generation model",
      "Traffic optimization",
      "Transport engineering"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Ping"
      },
      {
        "surname": "Korovin",
        "given_name": "Iakov"
      },
      {
        "surname": "Gorbachev",
        "given_name": "Sergey"
      },
      {
        "surname": "Gorbacheva",
        "given_name": "Nadezhda"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Deep learning-based image deconstruction method with maintained saliency",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.015",
    "abstract": "Visual properties that primarily attract bottom-up attention are collectively referred to as saliency. In this study, to understand the neural activity involved in top-down and bottom-up visual attention, we aim to prepare pairs of natural and unnatural images with common saliency. For this purpose, we propose an image transformation method based on deep neural networks that can generate new images while maintaining the consistent feature map, in particular the saliency map. This is an ill-posed problem because the transformation from an image to its corresponding feature map could be many-to-one, and in our particular case, the various images would share the same saliency map. Although stochastic image generation has the potential to solve such ill-posed problems, the most existing methods focus on adding diversity of the overall style/touch information while maintaining the naturalness of the generated images. To this end, we developed a new image transformation method that incorporates higher-dimensional latent variables so that the generated images appear unnatural with less context information but retain a high diversity of local image structures. Although such high-dimensional latent spaces are prone to collapse, we proposed a new regularization based on Kullback–Leibler divergence to avoid collapsing the latent distribution. We also conducted human experiments using our newly prepared natural and corresponding unnatural images to measure overt eye movements and functional magnetic resonance imaging, and found that those images induced distinctive neural activities related to top-down and bottom-up attentional processing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200315X",
    "keywords": [
      "Archaeology",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Context (archaeology)",
      "Deep learning",
      "Feature (linguistics)",
      "Focus (optics)",
      "Gene",
      "Geography",
      "Image (mathematics)",
      "Linguistics",
      "Naturalness",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Fujimoto",
        "given_name": "Keisuke"
      },
      {
        "surname": "Hayashi",
        "given_name": "Kojiro"
      },
      {
        "surname": "Katayama",
        "given_name": "Risa"
      },
      {
        "surname": "Lee",
        "given_name": "Sehyung"
      },
      {
        "surname": "Liang",
        "given_name": "Zhen"
      },
      {
        "surname": "Yoshida",
        "given_name": "Wako"
      },
      {
        "surname": "Ishii",
        "given_name": "Shin"
      }
    ]
  },
  {
    "title": "An inertial neural network approach for loco-manipulation trajectory tracking of mobile robot with redundant manipulator",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.012",
    "abstract": "This paper proposes a novel constrained optimization model to address the loco-manipulation problem of mobile robot with redundant manipulator for trajectory tracking. To alleviate the accumulative error of the end-effector’s position, a new control law is designed to eliminate the negative effect from the deviation of the initial position, leading to better performance than existing ones. To deal with the locomotion constraints in the loco-manipulation problem, the optimization model is converted to an augmented Lagrangian primal–dual problem. Furthermore, an inertial neural network approach is used to solve the problem and the corresponding Lyapunov proof guarantees the convergence of variables. The numerical simulations show that the proposed approach is more suitable for application since the model is more effective and the algorithm has better convergence rate.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003124",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Finance",
      "Inertial frame of reference",
      "Mathematical optimization",
      "Mathematics",
      "Mobile manipulator",
      "Mobile robot",
      "Physics",
      "Position (finance)",
      "Quantum mechanics",
      "Rate of convergence",
      "Robot",
      "Tracking error",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Chentao"
      },
      {
        "surname": "Wang",
        "given_name": "Miao"
      },
      {
        "surname": "Chi",
        "given_name": "Guoyi"
      },
      {
        "surname": "Liu",
        "given_name": "Qingshan"
      }
    ]
  },
  {
    "title": "Brain-inspired chaotic backpropagation for MLP",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.004",
    "abstract": "Backpropagation (BP) algorithm is one of the most basic learning algorithms in deep learning. Although BP has been widely used, it still suffers from the problem of easily falling into the local minima due to its gradient dynamics. Inspired by the fact that the learning of real brains may exploit chaotic dynamics, we propose the chaotic backpropagation (CBP) algorithm by integrating the intrinsic chaos of real neurons into BP. By validating on multiple datasets (e.g. cifar10), we show that, for multilayer perception (MLP), CBP has significantly better abilities than those of BP and its variants in terms of optimization and generalization from both computational and theoretical viewpoints. Actually, CBP can be regarded as a general form of BP with global searching ability inspired by the chaotic learning process in the brain. Therefore, CBP not only has the potential of complementing or replacing BP in deep learning practice, but also provides a new way for understanding the learning process of the real brain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003045",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Chaotic",
      "Computer science",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Maxima and minima",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)"
    ],
    "authors": [
      {
        "surname": "Tao",
        "given_name": "Peng"
      },
      {
        "surname": "Cheng",
        "given_name": "Jie"
      },
      {
        "surname": "Chen",
        "given_name": "Luonan"
      }
    ]
  },
  {
    "title": "Hyper-flexible Convolutional Neural Networks based on Generalized Lehmer and Power Means",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.017",
    "abstract": "Convolutional Neural Network is one of the famous members of the deep learning family of neural network architectures, which is used for many purposes, including image classification. In spite of the wide adoption, such networks are known to be highly tuned to the training data (samples representing a particular problem), and they are poorly reusable to address new problems. One way to change this would be, in addition to trainable weights, to apply trainable parameters of the mathematical functions, which simulate various neural computations within such networks. In this way, we may distinguish between the narrowly focused task-specific parameters (weights) and more generic capability-specific parameters. In this paper, we suggest a couple of flexible mathematical functions (Generalized Lehmer Mean and Generalized Power Mean) with trainable parameters to replace some fixed operations (such as ordinary arithmetic mean or simple weighted aggregation), which are traditionally used within various components of a convolutional neural network architecture. We named the overall architecture with such an update as a hyper-flexible convolutional neural network. We provide mathematical justification of various components of such architecture and experimentally show that it performs better than the traditional one, including better robustness regarding the adversarial perturbations of testing data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003173",
    "keywords": [
      "Algorithm",
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computation",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Deep learning",
      "Gene",
      "Machine learning",
      "Network architecture",
      "Pattern recognition (psychology)",
      "Robustness (evolution)",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Terziyan",
        "given_name": "Vagan"
      },
      {
        "surname": "Malyk",
        "given_name": "Diana"
      },
      {
        "surname": "Golovianko",
        "given_name": "Mariia"
      },
      {
        "surname": "Branytskyi",
        "given_name": "Vladyslav"
      }
    ]
  },
  {
    "title": "Tf-GCZSL: Task-free generalized continual zero-shot learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.034",
    "abstract": "Learning continually from a stream of training data or tasks with an ability to learn the unseen classes using a zero-shot learning framework is gaining attention in the literature. It is referred to as continual zero-shot learning (CZSL). Existing CZSL requires clear task-boundary information during training which is not practically feasible. This paper proposes a task-free generalized CZSL (Tf-GCZSL) method with short-term/long-term memory to overcome the requirement of task-boundary in training. A variational autoencoder (VAE) handles the fundamental ZSL tasks. The short-term and long-term memory help to overcome the condition of the task boundary in the CZSL framework. Further, the proposed Tf-GCZSL method combines the concept of experience replay with dark knowledge distillation and regularization to overcome the catastrophic forgetting issues in a continual learning framework. Finally, the Tf-GCZSL uses a fully connected classifier developed using the synthetic features generated at the latent space of the VAE. The performance of the proposed Tf-GCZSL is evaluated in the existing task-agnostic prediction setting and the proposed task-free setting for the generalized CZSL over the five ZSL benchmark datasets. The results clearly indicate that the proposed Tf-GCZSL improves the prediction at least by 12%, 1%, 3%, 4%, and 3% over existing state-of-the-art and baseline methods for CUB, aPY, AWA1, AWA2, and SUN datasets, respectively in both settings (task-agnostic prediction and task-free learning). The source code is available at https://github.com/Chandan-IITI/Tf-GCZSL.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003343",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Classifier (UML)",
      "Computer science",
      "Economics",
      "Forgetting",
      "Linguistics",
      "Machine learning",
      "Management",
      "Multi-task learning",
      "Philosophy",
      "Regularization (linguistics)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Gautam",
        "given_name": "Chandan"
      },
      {
        "surname": "Parameswaran",
        "given_name": "Sethupathy"
      },
      {
        "surname": "Mishra",
        "given_name": "Ashish"
      },
      {
        "surname": "Sundaram",
        "given_name": "Suresh"
      }
    ]
  },
  {
    "title": "Self-supervised knowledge distillation for complementary label learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.014",
    "abstract": "In this paper, we tackle a new learning paradigm called learning from complementary labels, where the training data specifies classes that instances do not belong to, instead of the accuracy labels. In general, it is more efficient to collect the complementary labels compared with collecting the supervised ones, with no need for selecting the correct one from a number of candidates. While current state-of-the-art methods design various loss functions to train competitive models by the limited supervised information, they overlook learning from the data and model themselves, which always contain fruitful information that can improve the performance of complementary label learning. In this paper, we propose a novel learning framework, which seamlessly integrates self-supervised and self-distillation to complementary learning. Based on the general complementary learning framework, we employ an entropy regularization term to guarantee the network outputs exhibit a sharper state. Then, to intensively learn information from the data, we leverage the self-supervised learning based on rotation and transformation operations as a plug-in auxiliary task to learn better transferable representations. Finally, knowledge distillation is introduced to further extract the “dark knowledge” from a network to guide the training of a student network. In the extensive experiments, our method surprisingly demonstrates compelling performance in accuracy over several state-of-the-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003148",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Distillation",
      "Entropy (arrow of time)",
      "Leverage (statistics)",
      "Machine learning",
      "Organic chemistry",
      "Physics",
      "Quantum mechanics",
      "Semi-supervised learning",
      "Supervised learning"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Jiabin"
      },
      {
        "surname": "Li",
        "given_name": "Biao"
      },
      {
        "surname": "Lei",
        "given_name": "Minglong"
      },
      {
        "surname": "Shi",
        "given_name": "Yong"
      }
    ]
  },
  {
    "title": "Sequential multi-view subspace clustering",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.007",
    "abstract": "Self-representation based subspace learning has shown its effectiveness in many applications, but most existing methods do not consider the difference between different views. As a result, the learned self-representation matrix cannot well characterize the clustering structure. Moreover, some methods involve an undesired weighted vector of the tensor nuclear norm, which reduces the flexibility of the algorithm in practical applications. To handle these problems, we present a tensorized multi-view subspace clustering. Specifically, our method employs matrix factorization and decomposes the self-representation matrix to orthogonal projection matrix and affinity matrix. We also add ℓ 1 , 2 -norm regularization on affinity representation to characterize the cluster structure. Moreover, the proposed method uses weighted tensor Schatten p -norm to explore higher-order structure and complementary information embedded in multi-view data, which can allocate the ideal weight for each view automatically without additional weight and penalty parameters. We apply the adaptive loss function to the model to maintain the robustness to outliers and efficiently learn the data distribution. Extensive experimental results on different datasets reveal that our method is superior to other state-of-the-art multi-view subspace clustering methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003410",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Eigenvalues and eigenvectors",
      "Mathematics",
      "Matrix decomposition",
      "Matrix norm",
      "Outlier",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Subspace topology"
    ],
    "authors": [
      {
        "surname": "Lei",
        "given_name": "Fangyuan"
      },
      {
        "surname": "Li",
        "given_name": "Qin"
      }
    ]
  },
  {
    "title": "A novel data-driven visualization of n -dimensional feasible region using interpretable self-organizing maps (iSOM)",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.019",
    "abstract": "Graphical optimization allows solving one or two dimensional optimization problems visually by merely plotting the objective function and constraint function contours. In addition to the discovery of optima, such a visualization-based approach enables understanding and interpretation of design variable and objective behavior with respect to feasibility and optimality, permitting intuitive decision making for designers. However, visualization of optimization problems in higher dimensions is challenging, though it is desirable. Interpretable self-organizing map (iSOM) is an artificial neural network that enables visualization of many dimensions via two-dimensional representations. We introduce iSOM to solve multidimensional optimization problems graphically. In the current work, a novel graphical representation of the n -dimensional feasible region, called B-matrix is constructed using iSOM. B-matrix is used to represent feasible range of design variables and objective function on separate plots. Consequently, dimension-wise shrinkage in the search space is also obtained. The proposed approach is demonstrated on various benchmark analytical examples and engineering examples with dimensions ranging from 2 to 30.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003197",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Constraint (computer-aided design)",
      "Dimension (graph theory)",
      "Discrete optimization",
      "Evolutionary biology",
      "Function (biology)",
      "Geodesy",
      "Geography",
      "Geometry",
      "Law",
      "Materials science",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Optimization problem",
      "Political science",
      "Politics",
      "Range (aeronautics)",
      "Representation (politics)",
      "Theoretical computer science",
      "Visualization"
    ],
    "authors": [
      {
        "surname": "Nagar",
        "given_name": "Deepak"
      },
      {
        "surname": "Pannerselvam",
        "given_name": "Kiran"
      },
      {
        "surname": "Ramu",
        "given_name": "Palaniappan"
      }
    ]
  },
  {
    "title": "TaskDrop: A competitive baseline for continual learning of sentiment classification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.033",
    "abstract": "In this paper, we study the multi-task sentiment classification problem in the continual learning setting, i.e., a model is sequentially trained to classify the sentiment of reviews of products in a particular category. The use of common sentiment words in reviews of different product categories leads to large cross-task similarity, which differentiates it from continual learning in other domains. This knowledge sharing nature renders forgetting reduction focused approaches less effective for the problem under consideration. Unlike existing approaches, where task-specific masks are learned with specifically presumed training objectives, we propose an approach called Task-aware Dropout (TaskDrop) to randomly sample a binary mask for each task. While the standard dropout generates and applies random masks for each training instance per epoch for regularization, random masks in TaskDrop are used for model capacity allocation and reuse to each coming task. We conducted experimental studies on Amazon review data and made comparison to various baselines and state-of-the-art approaches. Our empirical results show that regardless of simplicity, TaskDrop overall achieved competitive performance, especially after relatively long term learning. This demonstrates that the proposed random capacity allocation mechanism works well for continual sentiment classification.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003331",
    "keywords": [
      "Artificial intelligence",
      "Baseline (sea)",
      "Binary classification",
      "Biology",
      "Computer science",
      "Dropout (neural networks)",
      "Ecology",
      "Economics",
      "Forgetting",
      "Geology",
      "Linguistics",
      "Machine learning",
      "Management",
      "Oceanography",
      "Philosophy",
      "Reuse",
      "Sentiment analysis",
      "Support vector machine",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Mei",
        "given_name": "Jian-Ping"
      },
      {
        "surname": "Zhen",
        "given_name": "Yilun"
      },
      {
        "surname": "Zhou",
        "given_name": "Qianwei"
      },
      {
        "surname": "Yan",
        "given_name": "Rui"
      }
    ]
  },
  {
    "title": "Continuous learning of spiking networks trained with local rules",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.003",
    "abstract": "Artificial neural networks (ANNs) experience catastrophic forgetting (CF) during sequential learning. In contrast, the brain can learn continuously without any signs of catastrophic forgetting. Spiking neural networks (SNNs) are the next generation of ANNs with many features borrowed from biological neural networks. Thus, SNNs potentially promise better resilience to CF. In this paper, we study the susceptibility of SNNs to CF and test several biologically inspired methods for mitigating catastrophic forgetting. SNNs are trained with biologically plausible local training rules based on spike-timing-dependent plasticity (STDP). Local training prohibits the direct use of CF prevention methods based on gradients of a global loss function. We developed and tested the method to determine the importance of synapses (weights) based on stochastic Langevin dynamics without the need for the gradients. Several other methods of catastrophic forgetting prevention adapted from analog neural networks were tested as well. The experiments were performed on freely available datasets in the SpykeTorch environment.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003379",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Forgetting",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Software engineering",
      "Spike (software development)",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Antonov",
        "given_name": "D.I."
      },
      {
        "surname": "Sviatov",
        "given_name": "K.V."
      },
      {
        "surname": "Sukhov",
        "given_name": "S."
      }
    ]
  },
  {
    "title": "Latent adversarial regularized autoencoder for high-dimensional probabilistic time series prediction",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.025",
    "abstract": "Many practical applications require probabilistic prediction of time series to model the distribution on future horizons. With ever-increasing dimensions, much effort has been invested into developing methods that often make an assumption about the independence between time series. Consequently, the probabilistic prediction in high-dimensional environments has become an essential topic with significant challenges. In this paper, we propose a novel probabilistic model called latent adversarial regularized autoencoder, abbreviated as TimeLAR, specifically for high-dimensional multivariate Time Series Prediction (TSP). It integrates the flexibility of Generative Adversarial Networks (GANs) and the capability of autoencoders in extracting higher-level non-linear features. Through flexible autoencoder mapping, TimeLAR learns cross-series relationships and encodes this global information into several latent variables. We design a modified Transformer for these latent variables to capture global temporal patterns and infer latent space prediction distributions, where only one step is required to output multi-step predictions. Furthermore, we employ the GAN to further refine the performance of latent space predictions, by using a discriminator to guide the training of the autoencoder and the Transformer in an adversarial process. Finally, complex distributions of multivariate time series data can be modeled by the non-linear decoder of the autoencoder. The effectiveness of TimeLAR is empirically underpinned by extensive experiments conducted on five real-world high-dimensional time series datasets in the fields of transportation, electricity, and web page views.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003252",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Detector",
      "Discriminator",
      "Latent variable",
      "Machine learning",
      "Probabilistic logic",
      "Telecommunications",
      "Time series"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Jing"
      },
      {
        "surname": "Dai",
        "given_name": "Qun"
      }
    ]
  },
  {
    "title": "HVIOnet: A deep learning based hybrid visual–inertial odometry approach for unmanned aerial system position estimation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.001",
    "abstract": "Sensor fusion is used to solve the localization problem in autonomous mobile robotics applications by integrating complementary data acquired from various sensors. In this study, we adopt Visual–Inertial Odometry (VIO), a low-cost sensor fusion method that integrates inertial data with images using a Deep Learning (DL) framework to predict the position of an Unmanned Aerial System (UAS). The developed system has three steps. The first step extracts features from images acquired from a platform camera and uses a Convolutional Neural Network (CNN) to project them to a visual feature manifold. Next, temporal features are extracted from the Inertial Measurement Unit (IMU) data on the platform using a Bidirectional Long Short Term Memory (BiLSTM) network and are projected to an inertial feature manifold. The final step estimates the UAS position by fusing the visual and inertial feature manifolds via a BiLSTM-based architecture. The proposed approach is tested with the public EuRoC (European Robotics Challenge) dataset and simulation environment data generated within the Robot Operating System (ROS). The result of the EuRoC dataset shows that the proposed approach achieves successful position estimations comparable to previous popular VIO methods. In addition, as a result of the experiment with the simulation dataset, the UAS position is successfully estimated with 0.167 Mean Square Error (RMSE). The obtained results prove that the proposed deep architecture is useful for UAS position estimation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003355",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Economics",
      "Feature (linguistics)",
      "Finance",
      "Inertial frame of reference",
      "Inertial measurement unit",
      "Inertial navigation system",
      "Linguistics",
      "Mathematics",
      "Mean squared error",
      "Mobile robot",
      "Odometry",
      "Philosophy",
      "Physics",
      "Position (finance)",
      "Quantum mechanics",
      "Robot",
      "Robotics",
      "Sensor fusion",
      "Statistics",
      "Visual odometry"
    ],
    "authors": [
      {
        "surname": "Aslan",
        "given_name": "Muhammet Fatih"
      },
      {
        "surname": "Durdu",
        "given_name": "Akif"
      },
      {
        "surname": "Yusefi",
        "given_name": "Abdullah"
      },
      {
        "surname": "Yilmaz",
        "given_name": "Alper"
      }
    ]
  },
  {
    "title": "Natural Reweighted Wake–Sleep",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.09.006",
    "abstract": "Helmholtz Machines (HMs) are a class of generative models composed of two Sigmoid Belief Networks (SBNs), acting respectively as an encoder and a decoder. These models are commonly trained using a two-step optimization algorithm called Wake–Sleep (WS) and more recently by improved versions, such as Reweighted Wake–Sleep (RWS) and Bidirectional Helmholtz Machines (BiHM). The locality of the connections in an SBN induces sparsity in the Fisher Information Matrices associated to the probabilistic models, in the form of a finely-grained block-diagonal structure. In this paper we exploit this property to efficiently train SBNs and HMs using the natural gradient. We present a novel algorithm, called Natural Reweighted Wake–Sleep (NRWS), that corresponds to the geometric adaptation of its standard version. In a similar manner, we also introduce Natural Bidirectional Helmholtz Machine (NBiHM). Differently from previous work, we will show how for HMs the natural gradient can be efficiently computed without the need of introducing any approximation in the structure of the Fisher information matrix. The experiments performed on standard datasets from the literature show a consistent improvement of NRWS and NBiHM not only with respect to their non-geometric baselines but also with respect to state-of-the-art training algorithms for HMs. The improvement is quantified both in terms of speed of convergence as well as value of the log-likelihood reached after training.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003409",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Helmholtz free energy",
      "Linguistics",
      "Locality",
      "Philosophy",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Várady",
        "given_name": "Csongor"
      },
      {
        "surname": "Volpi",
        "given_name": "Riccardo"
      },
      {
        "surname": "Malagò",
        "given_name": "Luigi"
      },
      {
        "surname": "Ay",
        "given_name": "Nihat"
      }
    ]
  },
  {
    "title": "Multi-granularity heterogeneous graph attention networks for extractive document summarization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.021",
    "abstract": "Extractive document summarization is a fundamental task in natural language processing (NLP). Recently, several Graph Neural Networks (GNNs) are proposed for this task. However, most existing GNN-based models can neither effectively encode semantic nodes of multiple granularity level apart from sentences nor substantially capture different cross-sentence meta-paths. To address these issues, we propose MHgatSum, a novel Multi-granularity Heterogeneous Graph ATtention networks for extractive document SUMmarization. Specifically, we first build a multi-granularity heterogeneous graph (HetG) for each document, which is better to represent the semantic meaning of the document. The HetG contains not only sentence nodes but also multiple other granularity effective semantic units with different semantic levels, including keyphrases and topics. These additional nodes act as the intermediary between sentences to build the meta-paths involved in sentence node (i.e., Sentence-Keyphrase-Sentence and Sentence-Topic-Sentence). Then, we propose a heterogeneous graph attention networks to embed the constructed HetG for extractive summarization, which enjoys multi-granularity semantic representations. The model is based on a hierarchical attention mechanism, including node-level and semantic-level attentions. The node-level attention can learn the importance between a node and its meta-path based neighbors, while the semantic-level attention is able to learn the importance of different meta-paths. Moreover, to better integrate sentence global knowledge, we further incorporate sentence node global importance in local node-level attention. We conduct empirical experiments on two benchmark datasets, which demonstrates the superiority of MHgatSum over previous SOTA models on the task of extractive summarization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022003215",
    "keywords": [
      "Artificial intelligence",
      "Automatic summarization",
      "Computer science",
      "Engineering",
      "Granularity",
      "Graph",
      "Natural language processing",
      "Node (physics)",
      "Operating system",
      "Sentence",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Yu"
      },
      {
        "surname": "Wang",
        "given_name": "Leilei"
      },
      {
        "surname": "Wang",
        "given_name": "Cui"
      },
      {
        "surname": "Du",
        "given_name": "Huaming"
      },
      {
        "surname": "Wei",
        "given_name": "Shaopeng"
      },
      {
        "surname": "Feng",
        "given_name": "Huali"
      },
      {
        "surname": "Yu",
        "given_name": "Zongjian"
      },
      {
        "surname": "Li",
        "given_name": "Qing"
      }
    ]
  },
  {
    "title": "Low precision decentralized distributed training over IID and non-IID data",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.08.032",
    "abstract": "Decentralized distributed learning is the key to enabling large-scale machine learning (training) on the edge devices utilizing private user-generated local data, without relying on the cloud. However, practical realization of such on-device training is limited by the communication and compute bottleneck. In this paper, we propose and show the convergence of low precision decentralized training that aims to reduce the computational complexity and communication cost of decentralized training. Many feedback-based compression techniques have been proposed in the literature to reduce communication costs. To the best of our knowledge, there is no work that applies and shows compute efficient training techniques such as quantization, pruning etc., for peer-to-peer decentralized learning setups. Since real-world applications have a significant skew in the data distribution, we design ”Range-EvoNorm” as the normalization activation layer which is better suited for low precision training over non-IID data. Moreover, we show that the proposed low precision training can be used in synergy with other communication compression methods decreasing the communication cost further. Our experiments indicate that 8-bit decentralized training has minimal accuracy loss compared to its full precision counterpart even with non-IID data. However, when low precision training is accompanied by communication compression through sparsification we observe a 1 − 2 % drop in accuracy. The proposed low precision decentralized training decreases computational complexity, memory usage, and communication cost by ∼ 4 × and compute energy by a factor of ∼ 20 × , while trading off less than a 1% accuracy for both IID and non-IID data. In particular, for higher skew values, we observe an increase in accuracy (by ∼ 0 . 5 % ) with low precision training, indicating the regularization effect of the quantization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200332X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Bottleneck",
      "Computer engineering",
      "Computer science",
      "Distributed computing",
      "Embedded system",
      "Machine learning",
      "Memory footprint",
      "Operating system",
      "Quantization (signal processing)"
    ],
    "authors": [
      {
        "surname": "Aketi",
        "given_name": "Sai Aparna"
      },
      {
        "surname": "Kodge",
        "given_name": "Sangamesh"
      },
      {
        "surname": "Roy",
        "given_name": "Kaushik"
      }
    ]
  },
  {
    "title": "Event stream learning using spatio-temporal event surface",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.010",
    "abstract": "Event cameras sense changes in light intensity and record them as an asynchronous event stream. Efficiently encoding and learning spatiotemporal information of the event streams remain challenging. In this paper, we propose a novel event descriptor to encode the spatio-temporal features for event streams and a local-search based multi-spike learning algorithm for spiking neural networks to classify encoded features. The spatio-temporal event surface (STES) descriptor explicitly captures both spatial and temporal correlations among events, and thus can characterize spatiotemporal features more accurately than existing feature descriptors that focus only on temporal or spatial information. In classification with multi-spike learning, we introduce a local search and gradient clipping mechanism to ensure the efficiency and stability of learning, which avoids other multi-spike learning rules’ time-consuming global search and the gradient explosion problem. Experimental results demonstrate the superior classification performance of our proposed model, especially for event streams with rich spatiotemporal dynamics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002659",
    "keywords": [
      "Artificial intelligence",
      "Asynchronous communication",
      "Biochemistry",
      "Chemistry",
      "Computer network",
      "Computer science",
      "ENCODE",
      "Encoding (memory)",
      "Event (particle physics)",
      "Feature (linguistics)",
      "Focus (optics)",
      "Gene",
      "Linguistics",
      "Machine learning",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Software engineering",
      "Spike (software development)",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Dong",
        "given_name": "Junfei"
      },
      {
        "surname": "Jiang",
        "given_name": "Runhao"
      },
      {
        "surname": "Xiao",
        "given_name": "Rong"
      },
      {
        "surname": "Yan",
        "given_name": "Rui"
      },
      {
        "surname": "Tang",
        "given_name": "Huajin"
      }
    ]
  },
  {
    "title": "Finite-time stability of state-dependent delayed systems and application to coupled neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.009",
    "abstract": "Finite-time stability and stabilization problems of state-dependent delayed systems are studied in this paper. Different from discrete delays and time-dependent delays which can be well estimated over time, the information of state-dependent delays is usually hard to be estimated, especially when states are unknown or unmeasurable. To guarantee the stability of state-dependent delayed systems in the framework of finite time, a Razumikhin-type inequality is used, following which estimations on the settling time and the region of attraction are proposed. Moreover, the relationship between the variation speed of state-dependent delays and the size of the region of attraction is proposed. Then as an application of the theoretical result, finite-time stabilization is studied for a set of nonlinear coupled neural networks involving state-dependent transmission delay, where the design of memoryless finite-time controllers is addressed. Two numerical examples are given to show the effectiveness of the proposed results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002647",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Discrete time and continuous time",
      "Engineering",
      "Finite set",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical economics",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Set (abstract data type)",
      "Settling time",
      "Stability (learning theory)",
      "State (computer science)",
      "State dependent",
      "Statistics",
      "Step response",
      "Telecommunications",
      "Transmission (telecommunications)"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Xinyi"
      },
      {
        "surname": "Li",
        "given_name": "Xiaodi"
      },
      {
        "surname": "Song",
        "given_name": "Shiji"
      }
    ]
  },
  {
    "title": "Reservoir computing with 3D nanowire networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.001",
    "abstract": "Networks of nanowires are currently being explored for a range of applications in brain-like (or neuromorphic) computing, and especially in reservoir computing (RC). Fabrication of real-world computing devices requires that the nanowires are deposited sequentially, leading to stacking of the wires on top of each other. However, most simulations of computational tasks using these systems treat the nanowires as 1D objects lying in a perfectly 2D plane — the effect of stacking on RC performance has not yet been established. Here we use detailed simulations to compare the performance of perfectly 2D and quasi-3D (stacked) networks of nanowires in two tasks: memory capacity and nonlinear transformation. We also show that our model of the junctions between nanowires is general enough to describe a wide range of memristive networks, and consider the impact of physically realistic electrode configurations on performance. We show that the various networks and configurations have a strikingly similar performance in RC tasks, which is surprising given their radically different topologies. Our results show that networks with an experimentally achievable number of electrodes perform close to the upper bounds achievable when using the information from every wire. However, we also show important differences, in particular that the quasi-3D networks are more resilient to changes in the input parameters, generalizing better to noisy training data. Since previous literature suggests that topology plays an important role in computing performance, these results may have important implications for future applications of nanowire networks in neuromorphic computing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200257X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer network",
      "Computer science",
      "Distributed computing",
      "Electrical engineering",
      "Electronic engineering",
      "Engineering",
      "Materials science",
      "Memristor",
      "Nanotechnology",
      "Nanowire",
      "Network topology",
      "Neuromorphic engineering",
      "Nonlinear system",
      "Nuclear magnetic resonance",
      "Physics",
      "Quantum mechanics",
      "Range (aeronautics)",
      "Recurrent neural network",
      "Reservoir computing",
      "Stacking",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Daniels",
        "given_name": "R.K."
      },
      {
        "surname": "Mallinson",
        "given_name": "J.B."
      },
      {
        "surname": "Heywood",
        "given_name": "Z.E."
      },
      {
        "surname": "Bones",
        "given_name": "P.J."
      },
      {
        "surname": "Arnold",
        "given_name": "M.D."
      },
      {
        "surname": "Brown",
        "given_name": "S.A."
      }
    ]
  },
  {
    "title": "BackEISNN: A deep spiking neural network with adaptive self-feedback and balanced excitatory–inhibitory neurons",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.036",
    "abstract": "Spiking neural networks (SNNs) transmit information through discrete spikes that perform well in processing spatial–temporal information. Owing to their nondifferentiable characteristic, difficulties persist in designing SNNs that deliver good performance. SNNs trained with backpropagation have recently exhibited impressive performance by using gradient approximation. However, their performance on complex tasks remains significantly inferior to that of deep neural networks. By taking inspiration from autapses in the brain that connect spiking neurons with a self-feedback connection, we apply adaptive time-delayed self-feedback to the membrane potential to regulate the precision of the spikes. We also strike a balance between the excitatory and inhibitory mechanisms of neurons to dynamically control the output of spiking neurons. By combining these two mechanisms, we propose a deep SNN with adaptive self-feedback and balanced excitatory and inhibitory neurons (BackEISNN). The results of experiments on several standard datasets show that the two modules not only accelerate the convergence of the network but also increase its accuracy. Our model achieved state-of-the-art performance on the MNIST, Fashion-MNIST, and N-MNIST datasets. The proposed BackEISNN also achieved remarkably good performance on the CIFAR10 dataset while using a relatively light structure that competes against state-of-the-art SNNs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002520",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Biology",
      "Computer science",
      "Excitatory postsynaptic potential",
      "Inhibitory postsynaptic potential",
      "MNIST database",
      "Machine learning",
      "Neuroscience",
      "Spiking neural network"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Dongcheng"
      },
      {
        "surname": "Zeng",
        "given_name": "Yi"
      },
      {
        "surname": "Li",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Relational local electroencephalography representations for sleep scoring",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.020",
    "abstract": "Computational sleep scoring from multimodal neurophysiological time-series (polysomnography PSG) has achieved impressive clinical success. Models that use only a single electroencephalographic (EEG) channel from PSG have not yet received the same clinical recognition, since they lack Rapid Eye Movement (REM) scoring quality. The question whether this lack can be remedied at all remains an important one. We conjecture that predominant Long Short-Term Memory (LSTM) models do not adequately represent distant REM EEG segments (termed epochs), since LSTMs compress these to a fixed-size vector from separate past and future sequences. To this end, we introduce the EEG representation model ENGELBERT (electroEncephaloGraphic Epoch Local Bidirectional Encoder Representations from Transformer). It jointly attends to multiple EEG epochs from both past and future. Compared to typical token sequences in language, for which attention models have originally been conceived, overnight EEG sequences easily span more than 1000 30 s epochs. Local attention on overlapping windows reduces the critical quadratic computational complexity to linear, enabling versatile sub-one-hour to all-day scoring. ENGELBERT is at least one order of magnitude smaller than established LSTM models and is easy to train from scratch in a single phase. It surpassed state-of-the-art macro F1-scores in 3 single-EEG sleep scoring experiments. REM F1-scores were pushed to at least 86%. ENGELBERT virtually closed the gap to PSG-based methods from 4–5 percentage points (pp) to less than 1 pp F1-score.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002763",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer security",
      "Electroencephalography",
      "Machine learning",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Polysomnography",
      "Psychology",
      "Security token",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Brandmayr",
        "given_name": "Georg"
      },
      {
        "surname": "Hartmann",
        "given_name": "Manfred"
      },
      {
        "surname": "Fürbass",
        "given_name": "Franz"
      },
      {
        "surname": "Matz",
        "given_name": "Gerald"
      },
      {
        "surname": "Samwald",
        "given_name": "Matthias"
      },
      {
        "surname": "Kluge",
        "given_name": "Tilmann"
      },
      {
        "surname": "Dorffner",
        "given_name": "Georg"
      }
    ]
  },
  {
    "title": "PDE-READ: Human-readable partial differential equation discovery using deep learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.008",
    "abstract": "PDE discovery shows promise for uncovering predictive models of complex physical systems but has difficulty when measurements are noisy and limited. We introduce a new approach for PDE discovery that uses two Rational Neural Networks and a principled sparse regression algorithm to identify the hidden dynamics that govern a system’s response. The first network learns the system response function, while the second learns a hidden PDE describing the system’s evolution. We then use a parameter-free sparse regression algorithm to extract a human-readable form of the hidden PDE from the second network. We implement our approach in an open-source library called PDE-READ. Our approach successfully identifies the governing PDE in six benchmark examples. We demonstrate that our approach is robust to both sparsity and noise and it, therefore, holds promise for application to real-world observational data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002660",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Deep learning",
      "Evolutionary biology",
      "Function (biology)",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Noise (video)",
      "Partial differential equation"
    ],
    "authors": [
      {
        "surname": "Stephany",
        "given_name": "Robert"
      },
      {
        "surname": "Earls",
        "given_name": "Christopher"
      }
    ]
  },
  {
    "title": "Active learning of causal structures with deep reinforcement learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.028",
    "abstract": "We study the problem of experiment design to learn causal structures from interventional data. We consider an active learning setting in which the experimenter decides to intervene on one of the variables in the system in each step and uses the results of the intervention to recover further causal relationships among the variables. The goal is to fully identify the causal structures with minimum number of interventions. We present the first deep reinforcement learning based solution for the problem of experiment design. In the proposed method, we embed input graphs to vectors using a graph neural network and feed them to another neural network which outputs a variable for performing intervention in each step. Both networks are trained jointly via a Q-iteration algorithm. Experimental results show that the proposed method achieves competitive performance in recovering causal structures with respect to previous works, while significantly reducing execution time in dense graphs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200243X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Causal structure",
      "Computer science",
      "Graph",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Theoretical computer science",
      "Variable (mathematics)"
    ],
    "authors": [
      {
        "surname": "Amirinezhad",
        "given_name": "Amir"
      },
      {
        "surname": "Salehkaleybar",
        "given_name": "Saber"
      },
      {
        "surname": "Hashemi",
        "given_name": "Matin"
      }
    ]
  },
  {
    "title": "A portable clustering algorithm based on compact neighbors for face tagging",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.025",
    "abstract": "We focus on the following problem: Given a collection of unlabeled facial images, group them into the individual identities where the number of subjects is not known. To this end, a Portable clustering algorithm based on Compact Neighbors called PCN is proposed. (1) Benefiting from the compact neighbor, the local density of each sample can be determined automatically and only one user-specified parameter, the number of nearest neighbors k , is involved in our model. (2) More importantly, the performance of PCN is not sensitive to the number of nearest neighbors. Therefore this parameter is relatively easy to determine in practical applications. (3) The computational overhead of PCN is O ( n k ( k 2 + l o g ( n k ) ) ) that is nearly linear with respect to the number of samples, which means it is easily scalable to large-scale problems. In order to verify the effectiveness of PCN on the face clustering problem, extensive experiments based on a two-stage framework (extracting features using a deep model and performing clustering in the feature space) have been conducted on 16 middle- and 5 large-scale benchmark datasets. The experimental results have shown the efficiency and effectiveness of the proposed algorithm, compared with state-of-the-art methods. [code]",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002878",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Cluster analysis",
      "Computer science",
      "Database",
      "Face (sociological concept)",
      "Focus (optics)",
      "Geodesy",
      "Geography",
      "Operating system",
      "Optics",
      "Overhead (engineering)",
      "Pattern recognition (psychology)",
      "Physics",
      "Scalability",
      "Social science",
      "Sociology",
      "k-nearest neighbors algorithm"
    ],
    "authors": [
      {
        "surname": "Pei",
        "given_name": "Shenfei"
      },
      {
        "surname": "Zhang",
        "given_name": "Yuze"
      },
      {
        "surname": "Wang",
        "given_name": "Rong"
      },
      {
        "surname": "Nie",
        "given_name": "Feiping"
      }
    ]
  },
  {
    "title": "Compressing speaker extraction model with ultra-low precision quantization and knowledge distillation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.026",
    "abstract": "Recently, our proposed speaker extraction model, WASE (learning When to Attend for Speaker Extraction) yielded superior performance over the prior state-of-the-art methods by explicitly modeling onset clue and regarding it as important guidance in speaker extraction tasks. However, it still remains challenging when it comes to the deployments on the resource-constrained devices, where the model must be tiny and fast to perform inference with minimal budget in CPU and memory while keeping the speaker extraction performance. In this work, we utilize model compression techniques to alleviate the problem and propose a lightweight speaker extraction model, TinyWASE, which aims to run on resource-constrained devices. Specifically, we mainly investigate the grouping effects of quantization-aware training and knowledge distillation techniques in the speaker extraction task and propose Distillation-aware Quantization. Experiments on WSJ0-2mix dataset show that our proposed model can achieve comparable performance as the full-precision model while reducing the model size using ultra-low bits (e.g. 3 bits), obtaining 8.97x compression ratio and 2.15 MB model size. We further show that TinyWASE can combine with other model compression techniques, such as parameter sharing, to achieve compression ratio as high as 23.81 with limited performance degradation. Our code is available at https://github.com/aispeech-lab/TinyWASE.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002416",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Automotive engineering",
      "Chemistry",
      "Compression ratio",
      "Computer science",
      "Distillation",
      "Engineering",
      "Inference",
      "Internal combustion engine",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Quantization (signal processing)",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Yating"
      },
      {
        "surname": "Hao",
        "given_name": "Yunzhe"
      },
      {
        "surname": "Xu",
        "given_name": "Jiaming"
      },
      {
        "surname": "Xu",
        "given_name": "Bo"
      }
    ]
  },
  {
    "title": "Latent neighborhood-based heterogeneous graph representation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.028",
    "abstract": "Graph, as a powerful data structure, has shown superior capability on modeling complex systems. Since real-world objects and their interactions are often multi-modal and multi-typed, compared with traditional homogeneous graphs, heterogeneous graphs can represent real-world objects more effectively. Meanwhile, rich semantic information brings great challenges for learning heterogeneous graph representation (HGR). Most existing HGR methods are based on the concept of meta-path, which is constructed based on direct neighbors and define composite semantic relations in heterogeneous graph. However, when the direct neighbor information is inadequate, which always happens due to insufficient observation, the quality of meta-paths cannot be guaranteed. Therefore, we propose a novel HGR framework based on latent direct neighbors. Specifically, random walks are first utilized to discover the potential candidates from indirect neighbors. Then HodgeRank is introduced to determine the latent direct neighbors according to their importance to the target. After that, neighborhood relationships are augmented with the selected latent direct neighbors, and the adjacency tensor of the heterogeneous graph is refactored correspondingly. Finally, Graph Transformer Network is adopted to construct semantic meta-paths automatically and generate HGR. Numerical experiments on different real-world heterogeneous networks show that our new approach can produce more meta-path instances and introduce more complex and diverse semantic information, and consequently achieves more accurate predictions compared with several state-of-the-art baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002933",
    "keywords": [
      "Adjacency list",
      "Adjacency matrix",
      "Algorithm",
      "Computer science",
      "Data mining",
      "Graph",
      "Metamodeling",
      "Programming language",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Yang"
      },
      {
        "surname": "Quan",
        "given_name": "Pei"
      },
      {
        "surname": "Lei",
        "given_name": "MingLong"
      },
      {
        "surname": "Niu",
        "given_name": "Lingfeng"
      }
    ]
  },
  {
    "title": "Predictions on multi-class terminal ballistics datasets using conditional Generative Adversarial Networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.034",
    "abstract": "Ballistic impacts are a primary risk in both civil and military defence applications, where successfully predicting the dynamic response of a material or structure to impact crucial to the design of safe and fit-for-purpose protective structures. This study proposes a conditional Generative Adversarial Network (cGAN) architecture that can learn directly from available ballistic data and can be conditioned on additional information, such as class labels, to govern its output. A single Multi-Layer Perceptron (MLP) cGAN architecture is trained on a multi-class ballistic training set consisting of 10 classes labelled 0 − 9 where each class refers to a ballistic curve with a different ballistic limit velocity, v bl . A total of 5 models are trained on datasets consisting of 5, 10, 15, 20 and 25 samples within each class. For integer class labels 0 − 9 , all cGAN models successfully predict the v bl with a maximum error of 4.12%. Additionally, for non-integer class labels between 0 − 9 the v bl predictions are similar despite not explicitly appearing in the training set. Moreover, each cGAN model is challenged to generate new samples for class labels that exist beyond the scope of the training set for class labels between 9 − 20 . Four of the models predict the v bl with an error of less than 1.5% in all cases. This study showcases how a cGAN model can learn directly from a multi-class ballistic dataset and generate additional samples representative of that data for classes that do not appear explicitly in the training set.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002994",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Deep learning",
      "Generative adversarial network",
      "Generative grammar",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Telecommunications",
      "Terminal (telecommunication)"
    ],
    "authors": [
      {
        "surname": "Thompson",
        "given_name": "S."
      },
      {
        "surname": "Teixeira-Dias",
        "given_name": "F."
      },
      {
        "surname": "Paulino",
        "given_name": "M."
      },
      {
        "surname": "Hamilton",
        "given_name": "A."
      }
    ]
  },
  {
    "title": "Face image-sketch synthesis via generative adversarial fusion",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.013",
    "abstract": "Face image-sketch synthesis is widely applied in law enforcement and digital entertainment fields. Despite the extensive progression in face image-sketch synthesis, there are few methods focusing on generating a color face image from a sketch. The existing methods pay less attention to learning the illumination or highlight distribution on the face region. However, the illumination is the key factor that makes the generated color face image looks vivid and realistic. Moreover, existing methods tend to employ some image preprocessing technologies and facial region patching approaches to generate high-quality face images, which results in the high complexity and memory consumption in practice. In this paper, we propose a novel end-to-end generative adversarial fusion model, called GAF, which fuses two U-Net generators and a discriminator by jointly learning the content and adversarial loss functions. In particular, we propose a parametric tanh activation function to learn and control illumination highlight distribution over faces, which is integrated between the two U-Net generators by an illumination distribution layer. Additionally, we fuse the attention mechanism into the second U-Net generator of GAF to keep the identity consistency and refine the generated facial details. The qualitative and quantitative experiments on the public benchmark datasets show that the proposed GAF has better performance than existing image-sketch synthesis methods in synthesized face image quality (FSIM) and face recognition accuracy (NLDA). Meanwhile, the good generalization ability of GAF has also been verified. To further demonstrate the reliability and authenticity of face images generated using GAF, we use the generated face image to attack the well-known face recognition system. The result shows that the face images generated by GAF can maintain identity consistency and well maintain everyone’s unique facial characteristics, which can be further used in the benchmark of facial spoofing. Moreover, the experiments are implemented to verify the effectiveness and rationality of the proposed parametric tanh activation function and attention mechanism in GAF.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002696",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Face (sociological concept)",
      "Pattern recognition (psychology)",
      "Sketch",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Jianyuan"
      },
      {
        "surname": "Yu",
        "given_name": "Hongchuan"
      },
      {
        "surname": "Zhang",
        "given_name": "Jian J."
      },
      {
        "surname": "Dong",
        "given_name": "Junyu"
      },
      {
        "surname": "Yu",
        "given_name": "Hui"
      },
      {
        "surname": "Zhong",
        "given_name": "Guoqiang"
      }
    ]
  },
  {
    "title": "Periodic event-triggered adaptive tracking control design for nonlinear discrete-time systems via reinforcement learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.039",
    "abstract": "In this paper, an event-triggered control scheme with periodic characteristic is developed for nonlinear discrete-time systems under an actor–critic architecture of reinforcement learning (RL). The periodic event-triggered mechanism (ETM) is constructed to decide whether the sampling data are delivered to controllers or not. Meanwhile, the controller is updated only when the event-triggered condition deviates from a prescribed threshold. Compared with traditional continuous ETMs, the proposed periodic ETM can guarantee a minimal lower bound of the inter-event intervals and avoid sampling calculation point-to-point, which means that the partial communication resources can be efficiently economized. The critic and actor neural networks (NNs), consisting of radial basis function neural networks (RBFNNs), aim to approximate the unknown long-term performance index function and the ideal event-triggered controller, respectively. A rigorous stability analysis based on the Lyapunov difference method is provided to substantiate that the closed-loop system can be stabilized. All error signals of the closed-loop system are uniformly ultimately bounded (UUB) under the guidance of the proposed control scheme. Finally, two simulation examples are given to validate the effectiveness of the control design.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002544",
    "keywords": [
      "Adaptive control",
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Bounded function",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Event (particle physics)",
      "Filter (signal processing)",
      "Lyapunov function",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Sampling (signal processing)",
      "Stability (learning theory)",
      "Tracking error"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Fanghua"
      },
      {
        "surname": "Niu",
        "given_name": "Ben"
      },
      {
        "surname": "Zong",
        "given_name": "Guangdeng"
      },
      {
        "surname": "Zhao",
        "given_name": "Xudong"
      },
      {
        "surname": "Xu",
        "given_name": "Ning"
      }
    ]
  },
  {
    "title": "Using source data to aid and build variational state–space autoencoders with sparse target data for process monitoring",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.010",
    "abstract": "In industrial processes, different operating conditions and ratios of ingredients are used to produce multi-grade products in the same production line. Yet, the production grade changes so quickly as the demand from customers varies from time to time. As a result, the process data collected in certain operating regions are often scarce. Process dynamics, nonlinearity, and process uncertainty increase the hardship in developing a reliable model to monitor the process status. In this paper, the source-aided variational state–space autoencoder (SA-VSSAE) is proposed. It integrates variational state–space autoencoder with the Gaussian mixture. With the additional information from the source grades, SA-VSSAE can be used for monitoring processes with sparse target data by performing information sharing to enhance the reliability of the target model. Unlike the past works which perform information sharing and modeling in a two-step procedure, the proposed model is designed for information sharing and modeling in a one-step procedure without causing information loss. In contrast to the traditional state–space model, which is linear and deterministic, the variational state–space autoencoder (VSSAE) extracts the dynamic and nonlinear features in the process variables using neural networks. Also, by taking process uncertainty into consideration, VSSAE describes the features in a probabilistic form. Probability density estimates of the residual and latent variables are given to design the monitoring indices for fault detection. A numerical example and an industrial polyvinyl chloride drying process are presented to show the advantages of the proposed method over the comparative methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002234",
    "keywords": [
      "Actuator",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Data mining",
      "Fault detection and isolation",
      "Gaussian",
      "Gaussian process",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Probabilistic logic",
      "Process (computing)",
      "Quantum mechanics",
      "State space",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Yi Shan"
      },
      {
        "surname": "Chen",
        "given_name": "Junghui"
      }
    ]
  },
  {
    "title": "Extended analysis on the global Mittag-Leffler synchronization problem for fractional-order octonion-valued BAM neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.031",
    "abstract": "In this paper, a new case of neural networks called fractional-order octonion-valued bidirectional associative memory neural networks (FOOVBAMNNs) is established. First, the higher dimensional models are formulated for FOOVBAMNNs with general activation functions and the special linear threshold ones, respectively. On one hand, employing Cayley–Dichson construction in octonion multiplication which is essentially neither commutative nor associative, the system of FOOVBAMNNs is divided into four fractional-order complex-valued ones. On the other hand, Caputo fractional derivative’s character and BAM’s interactive feature are also properly dealt with. Second, the general criteria are obtained by the new design of LKFs, the application of the related inequalities and the construction of the linear feedback controllers for the global Mittag-Leffler synchronization problem of FOOVBAMNNs. Finally, we present two numerical examples to show the realizability and progress of the derived results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002969",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Associative property",
      "Combinatorics",
      "Commutative property",
      "Computer science",
      "Economics",
      "Finance",
      "Fractional calculus",
      "Mathematics",
      "Order (exchange)",
      "Pure mathematics",
      "Realizability",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Xiao",
        "given_name": "Jianying"
      },
      {
        "surname": "Guo",
        "given_name": "Xiao"
      },
      {
        "surname": "Li",
        "given_name": "Yongtao"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Shi",
        "given_name": "Kaibo"
      },
      {
        "surname": "Tang",
        "given_name": "Yiqian"
      }
    ]
  },
  {
    "title": "Simultaneous neural network approximation for smooth functions",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.040",
    "abstract": "We establish in this work approximation results of deep neural networks for smooth functions measured in Sobolev norms, motivated by recent development of numerical solvers for partial differential equations using deep neural networks. Our approximation results are nonasymptotic in the sense that the error bounds are explicitly characterized in terms of both the width and depth of the networks simultaneously with all involved constants explicitly determined. Namely, for f ∈ C s ( [ 0 , 1 ] d ) , we show that deep ReLU networks of width O ( N log N ) and of depth O ( L log L ) can achieve a nonasymptotic approximation rate of O ( N − 2 ( s − 1 ) / d L − 2 ( s − 1 ) / d ) with respect to the W 1 , p ( [ 0 , 1 ] d ) norm for p ∈ [ 1 , ∞ ) . If either the ReLU function or its square is applied as activation functions to construct deep neural networks of width O ( N log N ) and of depth O ( L log L ) to approximate f ∈ C s ( [ 0 , 1 ] d ) , the approximation rate is O ( N − 2 ( s − n ) / d L − 2 ( s − n ) / d ) with respect to the W n , p ( [ 0 , 1 ] d ) norm for p ∈ [ 1 , ∞ ) .",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002556",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Applied mathematics",
      "Approximation error",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Discrete mathematics",
      "Evolutionary biology",
      "Function (biology)",
      "Function approximation",
      "Law",
      "Mathematical analysis",
      "Mathematics",
      "Norm (philosophy)",
      "Political science",
      "Sobolev space"
    ],
    "authors": [
      {
        "surname": "Hon",
        "given_name": "Sean"
      },
      {
        "surname": "Yang",
        "given_name": "Haizhao"
      }
    ]
  },
  {
    "title": "Neural extraction of multiscale essential structure for network dismantling",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.015",
    "abstract": "Diverse real world systems can be abstracted as complex networks consisting of nodes and edges as functional components. Percolation theory has shown that the failure of a few of nodes could lead to the collapse of a whole network, which brings up the network dismantling problem: How to select the least number of nodes to decompose a network into disconnected components each smaller than a predefined threshold? For its NP-hardness, many heuristic approaches have been proposed to measure and rank each node according to its importance to network structural stability. However, these measures are from a uniscale viewpoint by regarding one complex network as a flatted topology. In this article, we argue that nodes’ structural importance can be measured in different scales of network topologies. Built upon recent deep learning techniques, we propose a self-supervised learning based network dismantling framework (NEES), which can hierarchically merge some compact substructures to convert a network into a coarser one with fewer nodes and edges. During the merging process, we design neural models to extract essential structures and utilize self-attention mechanisms to learn nodes’ importance hierarchy in each scale. Experiments on real world networks and synthetic model networks show that the proposed NEES outperforms the state-of-the-art schemes in most cases in terms of removing the least number of target nodes to dismantle a network. The dismantling effectiveness of our neural extraction framework also highlights the emerging role of multi-scale essential structures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002726",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Complex network",
      "Computer network",
      "Computer science",
      "Data mining",
      "Heuristic",
      "Hierarchical network model",
      "Information retrieval",
      "Interdependent networks",
      "Machine learning",
      "Mathematics",
      "Merge (version control)",
      "Network topology",
      "Percolation theory",
      "Topology (electrical circuits)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Qingxia"
      },
      {
        "surname": "Wang",
        "given_name": "Bang"
      }
    ]
  },
  {
    "title": "Brain-inspired meta-reinforcement learning cognitive control in conflictual inhibition decision-making task for artificial agents",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.020",
    "abstract": "Conflictual cues and unexpected changes in human real-case scenarios may be detrimental to the execution of tasks by artificial agents, thus affecting their performance. Meta-learning applied to reinforcement learning may enhance the design of control algorithms, where an outer learning system progressively adjusts the operation of an inner learning system, leading to practical benefits for the learning schema. Here, we developed a brain-inspired meta-learning framework for inhibition cognitive control that i) exploits the meta-learning principles in the neuromodulation theory proposed by Doya, ii) relies on a well-established neural architecture that contains distributed learning systems in the human brain, and iii) proposes optimization rules of meta-learning hyperparameters that mimic the dynamics of the major neurotransmitters in the brain. We tested an artificial agent in inhibiting the action command in two well-known tasks described in the literature: NoGo and Stop-Signal Paradigms. After a short learning phase, the artificial agent learned to react to the hold signal, and hence to successfully inhibit the motor command in both tasks, via the continuous adjustment of the learning hyperparameters. We found a significant increase in global accuracy, right inhibition, and a reduction in the latency time required to cancel the action process, i.e., the Stop-signal reaction time. We also performed a sensitivity analysis to evaluate the behavioral effects of the meta-parameters, focusing on the serotoninergic modulation of the dopamine release. We demonstrated that brain-inspired principles can be integrated into artificial agents to achieve more flexible behavior when conflictual inhibitory signals are present in the environment.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002350",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Hyperparameter",
      "Machine learning",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Robertazzi",
        "given_name": "Federica"
      },
      {
        "surname": "Vissani",
        "given_name": "Matteo"
      },
      {
        "surname": "Schillaci",
        "given_name": "Guido"
      },
      {
        "surname": "Falotico",
        "given_name": "Egidio"
      }
    ]
  },
  {
    "title": "Two-level group convolution",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.024",
    "abstract": "Group convolution has been widely used in order to reduce the computation time of convolution, which takes most of the training time of convolutional neural networks. However, it is well known that a large number of groups significantly reduce the performance of group convolution. In this paper, we propose a new convolution methodology called “two-level” group convolution that is robust with respect to the increase of the number of groups and suitable for multi-GPU parallel computation. We first observe that the group convolution can be interpreted as a one-level block Jacobi approximation of the standard convolution, which is a popular notion in the field of numerical analysis. In numerical analysis, there have been numerous studies on the two-level method that introduces an intergroup structure that resolves the performance degradation issue without disturbing parallel computation. Motivated by these, we introduce a coarse-level structure which promotes intergroup communication without being a bottleneck in the group convolution. We show that all the additional work induced by the coarse-level structure can be efficiently processed in a distributed memory system. Numerical results that verify the robustness of the proposed method with respect to the number of groups are presented. Moreover, we compare the proposed method to various approaches for group convolution in order to highlight the superiority of the proposed method in terms of execution time, memory efficiency, and performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002866",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Bottleneck",
      "Chemistry",
      "Computation",
      "Computer science",
      "Convolution (computer science)",
      "Convolution power",
      "Convolution theorem",
      "Convolutional neural network",
      "Embedded system",
      "Fourier analysis",
      "Fourier transform",
      "Fractional Fourier transform",
      "Gene",
      "Group (periodic table)",
      "Mathematical analysis",
      "Mathematics",
      "Organic chemistry",
      "Overlap–add method",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Youngkyu"
      },
      {
        "surname": "Park",
        "given_name": "Jongho"
      },
      {
        "surname": "Lee",
        "given_name": "Chang-Ock"
      }
    ]
  },
  {
    "title": "Correntropy based semi-supervised concept factorization with adaptive neighbors for clustering",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.021",
    "abstract": "Concept factorization (CF) has shown the effectiveness in the field of data clustering. In this paper, a novel and robust semi-supervised CF method, called correntropy based semi-supervised concept factorization with adaptive neighbors (CSCF), is proposed with improved performance in clustering applications. Specifically, on the one hand, the CSCF method adopts correntropy as the cost function to increase the robustness for non-Gaussian noise and outliers, and combines two different types of supervised information simultaneously for obtaining a compact low-dimensional representation of the original data. On the other hand, CSCF assigns the adaptive neighbors for each data point to construct a good data similarity matrix for reducing the sensitiveness of data. Moreover, a generalized version of CSCF is derived for enlarging the clustering application ranges. Analysis is also presented for the relationship of CSCF with several typical CF methods. Experimental results have shown that CSCF has better clustering performance than several state-of-the-art CF methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002775",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Eigenvalues and eigenvectors",
      "Gene",
      "Mathematics",
      "Matrix decomposition",
      "Non-negative matrix factorization",
      "Outlier",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Siyuan"
      },
      {
        "surname": "Yang",
        "given_name": "Zhijing"
      },
      {
        "surname": "Nie",
        "given_name": "Feiping"
      },
      {
        "surname": "Chen",
        "given_name": "Badong"
      },
      {
        "surname": "Lin",
        "given_name": "Zhiping"
      }
    ]
  },
  {
    "title": "How does the brain represent the semantic content of an image?",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.034",
    "abstract": "Using deep neural networks (DNNs) as models to explore the biological brain is controversial, which is mainly due to the impenetrability of DNNs. Inspired by neural style transfer, we circumvented this problem by using deep features that were given a clear meaning—the representation of the semantic content of an image. Using encoding models and the representational similarity analysis, we quantitatively showed that the deep features which represented the semantic content of an image mainly predicted the activity of voxels in the early visual areas (V1, V2, and V3) and these features were essentially depictive but also propositional. This result is in line with the core viewpoint of the grounded cognition to some extent, which suggested that the representation of information in our brain is essentially depictive and can implement symbolic functions naturally.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002490",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Content (measure theory)",
      "Image (mathematics)",
      "Law",
      "Mathematical analysis",
      "Mathematics",
      "Meaning (existential)",
      "Natural language processing",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Psychology",
      "Psychotherapist",
      "Representation (politics)",
      "Similarity (geometry)",
      "Voxel"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Huawei"
      },
      {
        "surname": "Liu",
        "given_name": "Ming"
      },
      {
        "surname": "Zhang",
        "given_name": "Delong"
      }
    ]
  },
  {
    "title": "Interpolated Adversarial Training: Achieving robust neural networks without sacrificing too much accuracy",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.012",
    "abstract": "Adversarial robustness has become a central goal in deep learning, both in the theory and the practice. However, successful methods to improve the adversarial robustness (such as adversarial training) greatly hurt generalization performance on the unperturbed data. This could have a major impact on how the adversarial robustness affects real world systems (i.e. many may opt to forego robustness if it can improve accuracy on the unperturbed data). We propose Interpolated Adversarial Training, which employs recently proposed interpolation based training methods in the framework of adversarial training. On CIFAR-10, adversarial training increases the standard test error ( when there is no adversary) from 4.43% to 12.32%, whereas with our Interpolated adversarial training we retain the adversarial robustness while achieving a standard test error of only 6.45%. With our technique, the relative increase in the standard error for the robust model is reduced from 178.1% to just 45.5%. Moreover, we provide mathematical analysis of Interpolated Adversarial Training to confirm its efficiencies and demonstrate its advantages in terms of robustness and generalization.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002684",
    "keywords": [
      "Adversarial system",
      "Adversary",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Deep neural networks",
      "Gene",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Robustness (evolution)",
      "Training set"
    ],
    "authors": [
      {
        "surname": "Lamb",
        "given_name": "Alex"
      },
      {
        "surname": "Verma",
        "given_name": "Vikas"
      },
      {
        "surname": "Kawaguchi",
        "given_name": "Kenji"
      },
      {
        "surname": "Matyasko",
        "given_name": "Alexander"
      },
      {
        "surname": "Khosla",
        "given_name": "Savya"
      },
      {
        "surname": "Kannala",
        "given_name": "Juho"
      },
      {
        "surname": "Bengio",
        "given_name": "Yoshua"
      }
    ]
  },
  {
    "title": "Multivariate time-series classification with hierarchical variational graph pooling",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.032",
    "abstract": "In recent years, multivariate time-series classification (MTSC) has attracted considerable attention owing to the advancement of sensing technology. Existing deep-learning-based MTSC techniques, which mostly rely on convolutional or recurrent neural networks, focus primarily on the temporal dependency of a single time series. Based on this, complex pairwise dependencies among multivariate variables can be better described using advanced graph methods, where each variable is regarded as a node in the graph, and their dependencies are regarded as edges. Furthermore, current spatial–temporal modeling (e.g., graph classification) methodologies based on graph neural networks (GNNs) are inherently flat and cannot hierarchically aggregate node information. To address these limitations, we propose a novel graph-pooling-based framework, MTPool, to obtain an expressive global representation of MTS. We first convert MTS slices into graphs using the interactions of variables via a graph structure learning module and obtain the spatial–temporal graph node features via a temporal convolutional module. To obtain global graph-level representation, we design an “encoder-decoder”-based variational graph pooling module to create adaptive centroids for cluster assignments. Then, we combine GNNs and our proposed variational graph pooling layers for joint graph representation learning and graph coarsening, after which the graph is progressively coarsened to one node. Finally, a differentiable classifier uses this coarsened representation to obtain the final predicted class. Experiments on ten benchmark datasets showed that MTPool outperforms state-of-the-art strategies in the MTSC task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002970",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Feature learning",
      "Graph",
      "Pairwise comparison",
      "Pattern recognition (psychology)",
      "Pooling",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Duan",
        "given_name": "Ziheng"
      },
      {
        "surname": "Xu",
        "given_name": "Haoyan"
      },
      {
        "surname": "Wang",
        "given_name": "Yueyang"
      },
      {
        "surname": "Huang",
        "given_name": "Yida"
      },
      {
        "surname": "Ren",
        "given_name": "Anni"
      },
      {
        "surname": "Xu",
        "given_name": "Zhongbin"
      },
      {
        "surname": "Sun",
        "given_name": "Yizhou"
      },
      {
        "surname": "Wang",
        "given_name": "Wei"
      }
    ]
  },
  {
    "title": "QMEDNet: A quaternion-based multi-order differential encoder–decoder model for 3D human motion prediction",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.005",
    "abstract": "In order to deal with the sequence information in the task of 3D human motion prediction effectively, many previous methods seek to predict the motion state of the next moment using the traditional recurrent neural network in Euclidean space. However human motion representation in Euclidean space has high distortion and shows a weak semantic expression when using deep learning models. In this work, we try to process human motion by mapping Euclidean space into a Hypercomplex vector space. We propose a novel model based on quaternion to predict the three-dimensional motion of a human body. The core idea of this study is to use the fusion information to understand and process the human motion state in quaternion space. The multi-order differential information is fused both in the encoder and decoder of feature extraction and mapped to the quaternion space, respectively. The encoder takes graph convolution as the basic unit and the decoder adopts gated recurrent units. Numerous experiments have been carried out to prove that the multi-order information in quaternion space can help build a more reasonable description for 3D human motion. The performance of the proposed QMEDNet is superior to most of the advanced short and long-term motion prediction methods in both public datasets, Human 3.6M and CMU Mocap.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002611",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Encoder",
      "Euclidean space",
      "Feature vector",
      "Geometry",
      "Mathematics",
      "Motion (physics)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Pure mathematics",
      "Quaternion"
    ],
    "authors": [
      {
        "surname": "Cao",
        "given_name": "Wenming"
      },
      {
        "surname": "Li",
        "given_name": "Shuangshuang"
      },
      {
        "surname": "Zhong",
        "given_name": "Jianqi"
      }
    ]
  },
  {
    "title": "Estimating heading from optic flow: Comparing deep learning network and human performance",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.007",
    "abstract": "Convolutional neural networks (CNNs) have made significant advances over the past decade with visual recognition, matching or exceeding human performance on certain tasks. Visual recognition is subserved by the ventral stream of the visual system, which, remarkably, CNNs also effectively model. Inspired by this connection, we investigated the extent to which CNNs account for human heading perception, an important function of the complementary dorsal stream. Heading refers to the direction of movement during self-motion, which humans judge with high degrees of accuracy from the streaming pattern of motion on the eye known as optic flow. We examined the accuracy with which CNNs estimate heading from optic flow in a range of situations in which human heading perception has been well studied. These scenarios include heading estimation from sparse optic flow, in the presence of moving objects, and in the presence of rotation. We assessed performance under controlled conditions wherein self-motion was simulated through minimal or realistic scenes. We found that the CNN did not capture the accuracy of heading perception. The addition of recurrent processing to the network, however, closed the gap in performance with humans substantially in many situations. Our work highlights important self-motion scenarios in which recurrent processing supports heading estimation that approaches human-like accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002635",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep learning",
      "Geodesy",
      "Geography",
      "Heading (navigation)",
      "Image (mathematics)",
      "Motion (physics)",
      "Motion perception",
      "Neuroscience",
      "Optical flow",
      "Pattern recognition (psychology)",
      "Perception"
    ],
    "authors": [
      {
        "surname": "Maus",
        "given_name": "Natalie"
      },
      {
        "surname": "Layton",
        "given_name": "Oliver W."
      }
    ]
  },
  {
    "title": "Breaking CAPTCHA with Capsule Networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.041",
    "abstract": "Convolutional Neural Networks have achieved state-of-the-art performance in image classification. Their lack of ability to recognise the spatial relationship between features, however, leads to misclassification of the variants of the same image. Capsule Networks were introduced to address this issue by incorporating the spatial information of image features into neural networks. In this paper, we are interested in showcasing the digit recognition task on CAPTCHA images, widely considered a challenge for computers in relation to human capabilities. Our intention is to provide a rigorous empirical regime in which we can compare the competitive performance of Capsule Networks against the Convolutional Neural Networks. Indeed since CAPTCHA distorts images, by adjusting the spatial positioning of features, we aim to demonstrate the advantages and limitations of Capsule Networks architecture. We train the Capsule Networks with Dynamic Routing version and the convolutional-neural-network-based deep-CAPTCHA baseline model to predict the digit sequences on numerical CAPTCHAs, investigate the performance results and propose two improvements to the Capsule Networks model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002568",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "CAPTCHA",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Economics",
      "Image (mathematics)",
      "Machine learning",
      "Management",
      "Pattern recognition (psychology)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Mocanu",
        "given_name": "Ionela Georgiana"
      },
      {
        "surname": "Yang",
        "given_name": "Zhenxu"
      },
      {
        "surname": "Belle",
        "given_name": "Vaishak"
      }
    ]
  },
  {
    "title": "Attention-based random forest and contamination model",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.029",
    "abstract": "A new approach called ABRF (the attention-based random forest) and its modifications for applying the attention mechanism to the random forest (RF) for regression and classification are proposed. The main idea behind the proposed ABRF models is to assign attention weights with trainable parameters to decision trees in a specific way. The attention weights depend on the distance between an instance, which falls into a corresponding leaf of a tree, and training instances, which fall in the same leaf. This idea stems from representation of the Nadaraya–Watson kernel regression in the form of a RF. Three modifications of the general approach are proposed. The first one is based on applying the Huber’s contamination model and on computing the attention weights by solving quadratic or linear optimization problems. The second and the third modifications use the gradient-based algorithms for computing an extended set of the attention trainable parameters. Numerical experiments with various regression and classification datasets illustrate the proposed method. The code implementing the approach is publicly available.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002945",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Code (set theory)",
      "Combinatorics",
      "Computer science",
      "Decision tree",
      "Geometry",
      "Kernel (algebra)",
      "Law",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Political science",
      "Politics",
      "Programming language",
      "Quadratic equation",
      "Random forest",
      "Regression",
      "Representation (politics)",
      "Set (abstract data type)",
      "Statistics",
      "Tree (set theory)"
    ],
    "authors": [
      {
        "surname": "Utkin",
        "given_name": "Lev V."
      },
      {
        "surname": "Konstantinov",
        "given_name": "Andrei V."
      }
    ]
  },
  {
    "title": "Deep reinforcement learning guided graph neural networks for brain network analysis",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.035",
    "abstract": "Modern neuroimaging techniques enable us to construct human brains as brain networks or connectomes. Capturing brain networks’ structural information and hierarchical patterns is essential for understanding brain functions and disease states. Recently, the promising network representation learning capability of graph neural networks (GNNs) has prompted related methods for brain network analysis to be proposed. Specifically, these methods apply feature aggregation and global pooling to convert brain network instances into vector representations encoding brain structure induction for downstream brain network analysis tasks. However, existing GNN-based methods often neglect that brain networks of different subjects may require various aggregation iterations and use GNN with a fixed number of layers to learn all brain networks. Therefore, how to fully release the potential of GNNs to promote brain network analysis is still non-trivial. In our work, a novel brain network representation framework, BN-GNN, is proposed to solve this difficulty, which searches for the optimal GNN architecture for each brain network. Concretely, BN-GNN employs deep reinforcement learning (DRL) to automatically predict the optimal number of feature propagations (reflected in the number of GNN layers) required for a given brain network. Furthermore, BN-GNN improves the upper bound of traditional GNNs’ performance in eight brain network disease analysis tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002507",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Feature (linguistics)",
      "Feature learning",
      "Graph",
      "Law",
      "Linguistics",
      "Machine learning",
      "Neuroimaging",
      "Neuroscience",
      "Philosophy",
      "Political science",
      "Politics",
      "Power graph analysis",
      "Reinforcement learning",
      "Representation (politics)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Xusheng"
      },
      {
        "surname": "Wu",
        "given_name": "Jia"
      },
      {
        "surname": "Peng",
        "given_name": "Hao"
      },
      {
        "surname": "Beheshti",
        "given_name": "Amin"
      },
      {
        "surname": "Monaghan",
        "given_name": "Jessica J.M."
      },
      {
        "surname": "McAlpine",
        "given_name": "David"
      },
      {
        "surname": "Hernandez-Perez",
        "given_name": "Heivet"
      },
      {
        "surname": "Dras",
        "given_name": "Mark"
      },
      {
        "surname": "Dai",
        "given_name": "Qiong"
      },
      {
        "surname": "Li",
        "given_name": "Yangyang"
      },
      {
        "surname": "Yu",
        "given_name": "Philip S."
      },
      {
        "surname": "He",
        "given_name": "Lifang"
      }
    ]
  },
  {
    "title": "Heterogeneous Pseudo-Supervised Learning for Few-shot Person Re-Identification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.017",
    "abstract": "How to obtain good retrieval performance in the case of few-shot labeled samples is the current research focus of Person Re-Identification. To facilitate formal analysis, we formally put forward the concept of Pseudo-Supervised Learning (PSL) to represent a series of research works based on label generation under few-shot condition. Through extensive investigations, we find that the main problem that needs to be solved of PSL is how we can improve the quality of pseudo-label. To solve this problem, in this work, we proposed a simple yet effective Heterogeneous Pseudo-Supervised Learning (H-PSL) framework based on classical PSL to implement asynchronous match, which boosts the feature expression and then a better label prediction in the following. Specifically, a novel isomer is constructed as the feature extractor and is trained with a much larger amount of pseudo-supervised data, i.e., samples with pseudo-labels. In this way, the isomer obtains advanced feature expression. We then deliberately implement a cross-level asynchronous match mechanism between model and pseudo-supervised data. As a result, the quality of pseudo-label is greatly improved and the feature expression performance also be optimized accordingly. In addition, to make better use of pseudo-supervised data, we also designed a knowledge fusion strategy to integrate the pseudo labels and their confidence which are easily obtained by the base model and isomer. Encouragingly, knowledge fusion strategy further removes the noise-labeled samples from candidate data. We conduct experiments on four popular datasets to fully verify the universality of the proposed method. The experimental results show that the proposed method improves the performance of all compared baseline works.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002325",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Asynchronous communication",
      "Computer network",
      "Computer science",
      "Data mining",
      "Engineering",
      "Extractor",
      "Feature (linguistics)",
      "Focus (optics)",
      "Linguistics",
      "Machine learning",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Process engineering",
      "Supervised learning"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Jing"
      },
      {
        "surname": "Lan",
        "given_name": "Long"
      },
      {
        "surname": "Huang",
        "given_name": "Da"
      },
      {
        "surname": "Ren",
        "given_name": "Jing"
      },
      {
        "surname": "Yang",
        "given_name": "Wenjing"
      }
    ]
  },
  {
    "title": "Distributed optimized dynamic event-triggered control for unknown heterogeneous nonlinear MASs with input-constrained",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.033",
    "abstract": "The distributed optimized dynamic event-triggered controller is investigated for completely unknown heterogeneous nonlinear multi-agent systems (MASs) on a directed graph subject to input-constrained. First, the distributed observer is designed to estimate the information of the leader for each follower, and a network of the augmented system is constructed by employing the dynamics of the followers and the observers. An identifier with a compensator is designed to approximate the unknown augmented system (agent) with an arbitrarily small identifier error. Then, consider that the input-constrained optimal controller, along with Hamilton–Jacobi–Bellman (HJB) equation, is under pressure to execute in certain systems associated with bottlenecks such as communication and computing burdens. A critic–actor-based optimized dynamic event-triggered controller, which tunes the parameters of critic–actor neural networks (NNs) by the dynamic triggering mechanism, is leveraged to determine the rule of aperiodic sampling and maintain the desired synchronization service. In addition, the existence of a positive minimum inter-event time (MIET) between consecutive events is also proved. Finally, the applications in non-identical nonlinear MAS and 2-DOF robots illustrate the availability of the proposed theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002489",
    "keywords": [
      "Agronomy",
      "Aperiodic graph",
      "Artificial intelligence",
      "Biology",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Graph",
      "Hamilton–Jacobi–Bellman equation",
      "Identifier",
      "Mathematical optimization",
      "Mathematics",
      "Multi-agent system",
      "Nonlinear system",
      "Observer (physics)",
      "Optimal control",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Xia",
        "given_name": "Lina"
      },
      {
        "surname": "Li",
        "given_name": "Qing"
      },
      {
        "surname": "Song",
        "given_name": "Ruizhuo"
      },
      {
        "surname": "Ge",
        "given_name": "Shuzhi Sam"
      }
    ]
  },
  {
    "title": "Federated learning with workload-aware client scheduling in heterogeneous systems",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.030",
    "abstract": "Federated Learning (FL) is a novel distributed machine learning, which allows thousands of edge devices to train models locally without uploading data to the central server. Since devices in real federated settings are resource-constrained, FL encounters systems heterogeneity, which causes considerable stragglers and incurs significant accuracy degradation. To tackle the challenges of systems heterogeneity and improve the robustness of the global model, we propose a novel adaptive federated framework in this paper. Specifically, we propose FedSAE that leverages the workload completion history of clients to adaptively predict the affordable training workload for each device. Consequently, FedSAE can significantly reduce stragglers in highly heterogeneous systems. We incorporate Active Learning into FedSAE to dynamically schedule participants. The server evaluates the devices’ training value based on their training loss in each round, and larger-value clients are selected with a higher probability. As a result, the model convergence is accelerated. Furthermore, we propose q-FedSAE that combines FedSAE and q-FFL to improve global fairness in highly heterogeneous systems. The evaluations conducted in a highly heterogeneous system demonstrate that both FedSAE and q-FedSAE converge faster than FedAvg. In particular, FedSAE outperforms FedAvg across multiple federated datasets — FedSAE improves testing accuracy by 22.19% and reduces stragglers by 90.69% on average. Moreover, holding the same accuracy as FedSAE, q-FedSAE allows for more robust convergence and fairer model performance than q-FedAvg, FedSAE.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002957",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Cloud computing",
      "Computer science",
      "Distributed computing",
      "Economics",
      "Edge device",
      "Federated learning",
      "Gene",
      "Machine learning",
      "Operating system",
      "Operations management",
      "Robustness (evolution)",
      "Schedule",
      "Scheduling (production processes)",
      "Upload",
      "Workload"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Li"
      },
      {
        "surname": "Liu",
        "given_name": "Duo"
      },
      {
        "surname": "Duan",
        "given_name": "Moming"
      },
      {
        "surname": "Zhang",
        "given_name": "Yu"
      },
      {
        "surname": "Ren",
        "given_name": "Ao"
      },
      {
        "surname": "Chen",
        "given_name": "Xianzhang"
      },
      {
        "surname": "Tan",
        "given_name": "Yujuan"
      },
      {
        "surname": "Wang",
        "given_name": "Chengliang"
      }
    ]
  },
  {
    "title": "SLIDE: A surrogate fairness constraint to ensure fairness consistency",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.027",
    "abstract": "As they take a crucial role in social decision makings, AI algorithms based on ML models should be not only accurate but also fair. Among many algorithms for fair AI, learning a prediction ML model by minimizing the empirical risk (e.g., cross-entropy) subject to a given fairness constraint has received much attention. To avoid computational difficulty, however, a given fairness constraint is replaced by a surrogate fairness constraint as the 0–1 loss is replaced by a convex surrogate loss for classification problems. In this paper, we investigate the validity of existing surrogate fairness constraints and propose a new surrogate fairness constraint called SLIDE, which is computationally feasible and asymptotically valid in the sense that the learned model satisfies the fairness constraint asymptotically and achieves a fast convergence rate. Numerical experiments confirm that the SLIDE works well for various benchmark datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002891",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Consistency (knowledge bases)",
      "Constraint (computer-aided design)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Fairness measure",
      "Geodesy",
      "Geography",
      "Geometry",
      "Mathematical optimization",
      "Mathematics",
      "Telecommunications",
      "Throughput",
      "Wireless"
    ],
    "authors": [
      {
        "surname": "Kim",
        "given_name": "Kunwoong"
      },
      {
        "surname": "Ohn",
        "given_name": "Ilsang"
      },
      {
        "surname": "Kim",
        "given_name": "Sara"
      },
      {
        "surname": "Kim",
        "given_name": "Yongdai"
      }
    ]
  },
  {
    "title": "Return of the normal distribution: Flexible deep continual learning with variational auto-encoders",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.016",
    "abstract": "Learning continually from sequentially arriving data has been a long standing challenge in machine learning. An emergent body of deep learning literature suggests various solutions, through introduction of significant simplifications to the problem statement. As a consequence of a growing focus on particular tasks and their respective benchmark assumptions, these efforts are thus becoming increasingly tailored to specific settings. Whereas approaches that leverage Variational Bayesian techniques seem to provide a more general perspective of key continual learning mechanisms, they however entail their own caveats. Inspired by prior theoretical work on solving the prevalent mismatch between prior and aggregate posterior in deep generative models, we return to a generic variational auto-encoder based formulation and investigate its utility for continual learning. Specifically, we propose to adapt a two-stage training framework towards a context conditioned variant for continual learning, where we then formulate mechanisms to alleviate catastrophic forgetting through choices of generative rehearsal or well-motivated extraction of data exemplar subsets. Although the proposed generic two-stage variational auto-encoder is not tailored towards a particular task and allows for flexible amounts of supervision, we empirically demonstrate it to surpass task-tailored methods in both supervised classification, as well as unsupervised representation learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002702",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Deep learning",
      "Economics",
      "Feature learning",
      "Forgetting",
      "Generative grammar",
      "Geodesy",
      "Geography",
      "Leverage (statistics)",
      "Linguistics",
      "Machine learning",
      "Management",
      "Multi-task learning",
      "Paleontology",
      "Perspective (graphical)",
      "Philosophy",
      "Task (project management)",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Hong",
        "given_name": "Yongwon"
      },
      {
        "surname": "Mundt",
        "given_name": "Martin"
      },
      {
        "surname": "Park",
        "given_name": "Sungho"
      },
      {
        "surname": "Uh",
        "given_name": "Yungjung"
      },
      {
        "surname": "Byun",
        "given_name": "Hyeran"
      }
    ]
  },
  {
    "title": "Physics guided neural networks for modelling of non-linear dynamics",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.023",
    "abstract": "The success of the current wave of artificial intelligence can be partly attributed to deep neural networks, which have proven to be very effective in learning complex patterns from large datasets with minimal human intervention. However, it is difficult to train these models on complex dynamical systems from data alone due to their low data efficiency and sensitivity to hyperparameters and initialisation. This work demonstrates that injection of partially known information at an intermediate layer in a DNN can improve model accuracy, reduce model uncertainty, and yield improved convergence during the training. The value of these physics-guided neural networks has been demonstrated by learning the dynamics of a wide variety of nonlinear dynamical systems represented by five well-known equations in nonlinear systems theory: the Lotka–Volterra, Duffing, Van der Pol, Lorenz, and Henon–Heiles systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002854",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convergence (economics)",
      "Deep learning",
      "Dynamical systems theory",
      "Economic growth",
      "Economics",
      "Electronic engineering",
      "Engineering",
      "Experimental data",
      "Hyperparameter",
      "Machine learning",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Sensitivity (control systems)",
      "Statistical physics",
      "Statistics",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Robinson",
        "given_name": "Haakon"
      },
      {
        "surname": "Pawar",
        "given_name": "Suraj"
      },
      {
        "surname": "Rasheed",
        "given_name": "Adil"
      },
      {
        "surname": "San",
        "given_name": "Omer"
      }
    ]
  },
  {
    "title": "Sparse signal reconstruction via collaborative neurodynamic optimization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.018",
    "abstract": "In this paper, we formulate a mixed-integer problem for sparse signal reconstruction and reformulate it as a global optimization problem with a surrogate objective function subject to underdetermined linear equations. We propose a sparse signal reconstruction method based on collaborative neurodynamic optimization with multiple recurrent neural networks for scattered searches and a particle swarm optimization rule for repeated repositioning. We elaborate on experimental results to demonstrate the outperformance of the proposed approach against ten state-of-the-art algorithms for sparse signal reconstruction.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200274X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Particle swarm optimization",
      "Pattern recognition (psychology)",
      "Programming language",
      "Radar",
      "SIGNAL (programming language)",
      "Signal processing",
      "Signal reconstruction",
      "Telecommunications",
      "Underdetermined system"
    ],
    "authors": [
      {
        "surname": "Che",
        "given_name": "Hangjun"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Cichocki",
        "given_name": "Andrzej"
      }
    ]
  },
  {
    "title": "Multimodal neural networks better explain multivoxel patterns in the hippocampus",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.033",
    "abstract": "The human hippocampus possesses “concept cells”, neurons that fire when presented with stimuli belonging to a specific concept, regardless of the modality. Recently, similar concept cells were discovered in a multimodal network called CLIP (Radford et al., 2021). Here, we ask whether CLIP can explain the fMRI activity of the human hippocampus better than a purely visual (or linguistic) model. We extend our analysis to a range of publicly available uni- and multi-modal models. We demonstrate that “multimodality” stands out as a key component when assessing the ability of a network to explain the multivoxel activity in the hippocampus.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002982",
    "keywords": [],
    "authors": [
      {
        "surname": "Choksi",
        "given_name": "Bhavin"
      },
      {
        "surname": "Mozafari",
        "given_name": "Milad"
      },
      {
        "surname": "VanRullen",
        "given_name": "Rufin"
      },
      {
        "surname": "Reddy",
        "given_name": "Leila"
      }
    ]
  },
  {
    "title": "Reward prediction errors, not sensory prediction errors, play a major role in model selection in human reinforcement learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.002",
    "abstract": "Model-based reinforcement learning enables an agent to learn in variable environments and tasks by optimizing its actions based on the predicted states and outcomes. This mechanism has also been considered in the brain. However, exactly how the brain selects an appropriate model for confronting environments has remained unclear. Here, we investigated the model selection algorithm in the human brain during a reinforcement learning task. One primary theory of model selection in the brain is based on sensory prediction errors. Here, we compared this theory with an alternative possibility of internal model selection with reward prediction errors. To compare these two theories, we devised a switching experiment from a first-order Markov decision process to a second-order Markov decision process that provides either reward- or sensory prediction error regarding environmental change. We tested two representative computational models driven by different prediction errors. One is the sensory prediction-error-driven Bayesian algorithm, which has been discussed as a representative internal model selection algorithm in the animal reinforcement learning task. The other is the reward-prediction-error-driven policy gradient algorithm. We compared the simulation results of these two computational models with human reinforcement learning behaviors. The model fitting result supports that the policy gradient algorithm is preferable to the Bayesian algorithm. This suggests that the human brain employs the reward prediction error to select an appropriate internal model in the reinforcement learning task.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002581",
    "keywords": [
      "Artificial intelligence",
      "Bayesian inference",
      "Bayesian probability",
      "Computer science",
      "Economics",
      "Machine learning",
      "Management",
      "Markov decision process",
      "Markov process",
      "Mathematics",
      "Mean squared prediction error",
      "Operating system",
      "Process (computing)",
      "Reinforcement learning",
      "Selection (genetic algorithm)",
      "Statistics",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Yihao"
      },
      {
        "surname": "Morita",
        "given_name": "Masahiko"
      },
      {
        "surname": "Izawa",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "AdjointBackMap: Reconstructing effective decision hypersurfaces from CNN layers using adjoint operators",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.037",
    "abstract": "There are several methods in the exploration of Convolutional Neural Networks’ (CNNs’) inner workings. However, in general, finding the inverse of the function performed by CNNs as a whole is an ill-posed problem. In this paper, we propose a method based on adjoint operators to reconstruct, given an arbitrary unit in the CNN (except for the first convolutional layer), its effective hypersurface in the input space. Since the reconstructed hyperplane (each point on the hypersurface) resides in the input space, we can easily visualize it. Our results show that the reconstructed hyperplane, when multiplied by the original input image, would give nearly the exact output value of that unit. We find that the CNN unit’s decision process is largely conditioned on the input, and the corresponding reconstructed hypersurfaces are highly sensitive to adversarial noise, thus providing insights on why CNNs are susceptible to adversarial attack.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002519",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Convolutional neural network",
      "Evolutionary biology",
      "Function (biology)",
      "Hyperplane",
      "Hypersurface",
      "Inverse problem",
      "Mathematical analysis",
      "Mathematics"
    ],
    "authors": [
      {
        "surname": "Wan",
        "given_name": "Qing"
      },
      {
        "surname": "Choe",
        "given_name": "Yoonsuck"
      }
    ]
  },
  {
    "title": "Subgraph-aware graph structure revision for spatial–temporal graph modeling",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.017",
    "abstract": "Spatial–temporal graph modeling has been widely studied in many fields, such as traffic forecasting and energy analysis, where data has time and space properties. Existing methods focus on capturing stable and dynamic spatial correlations by constructing physical and virtual graphs along with graph convolution and temporal modeling. However, existing methods tending to smooth node features may obscure the spatial–temporal patterns among nodes. Worse, the graph structure is not always available in some fields, while the manually constructed stable or dynamic graphs cannot necessarily reflect the true spatial correlations either. This paper proposes a Subgraph-Aware Graph Structure Revision network (SAGSR) to overcome these limitations. Architecturally, a subgraph-aware structure revision graph convolution module (SASR-GCM) is designed, which revises the learned stable graph to obtain a dynamic one to automatically infer the dynamics of spatial correlations. Each of these two graphs is separated into one homophilic subgraph and one heterophilic subgraph by a subgraph-aware graph convolution mechanism, which aggregates similar nodes in the homophilic subgraph with positive weights, while keeping nodes with dissimilar features in the heterophilic subgraph mutually away with negative aggregation weights to avoid pattern obfuscation. By combining a gated multi-scale temporal convolution module (GMS-TCM) for temporal modeling, SAGSR can efficiently capture the spatial–temporal correlations and extract complex spatial–temporal graph features. Extensive experiments, conducted on two specific tasks: traffic flow forecasting and energy consumption forecasting, indicate the effectiveness and superiority of our proposed approach over several competitive baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002738",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Data mining",
      "Graph",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yuhu"
      },
      {
        "surname": "Zhang",
        "given_name": "Chunxia"
      },
      {
        "surname": "Xiang",
        "given_name": "Shiming"
      },
      {
        "surname": "Pan",
        "given_name": "Chunhong"
      }
    ]
  },
  {
    "title": "Novel optimal trajectory tracking for nonlinear affine systems with an advanced critic learning structure",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.07.019",
    "abstract": "In this paper, a critic learning structure based on the novel utility function is developed to solve the optimal tracking control problem with the discount factor of affine nonlinear systems. The utility function is defined as the quadratic form of the error at the next moment, which can not only avoid solving the stable control input, but also effectively eliminate the tracking error. Next, the theoretical derivation of the method under value iteration is given in detail with convergence and stability analysis. Then, the dual heuristic dynamic programming (DHP) algorithm via a single neural network is introduced to reduce the amount of computation. The polynomial is used to approximate the costate function during the DHP implementation. The weighted residual method is used to update the weight matrix. During simulation, the convergence speed of the given strategy is compared with the heuristic dynamic programming (HDP) algorithm. The experiment results display that the convergence speed of the proposed method is faster than the HDP algorithm. Besides, the proposed method is compared with the traditional tracking control approach to verify its tracking performance. The experiment results show that the proposed method can avoid solving the stable control input, and the tracking error is closer to zero than the traditional strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002751",
    "keywords": [
      "Affine transformation",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computation",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Dynamic programming",
      "Economic growth",
      "Economics",
      "Heuristic",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Optimal control",
      "Physics",
      "Polynomial",
      "Pure mathematics",
      "Quantum mechanics",
      "Tracking error"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Ding"
      },
      {
        "surname": "Zhao",
        "given_name": "Huiling"
      },
      {
        "surname": "Zhao",
        "given_name": "Mingming"
      },
      {
        "surname": "Ren",
        "given_name": "Jin"
      }
    ]
  },
  {
    "title": "Graph regularized spatial–spectral subspace clustering for hyperspectral band selection",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.016",
    "abstract": "Hyperspectral band selection, which aims to select a small number of bands to reduce data redundancy and noisy bands, has attracted widespread attention in recent years. Many effective clustering-based band selection methods have been proposed to accomplish the band selection task and have achieved satisfying performance. However, most of the previous methods reshape the original hyperspectral images (HSIs) into a set of stretched band vectors, which ignore the spatial information of HSIs and the difference between diverse regions. To address these issues, a graph regularized spatial–spectral subspace clustering method for hyperspectral band selection is proposed in this paper, referred to as GRSC. Specifically, the proposed method adopts superpixel segmentation to preserve the spatial information of HSIs by segmenting their first principal component into diverse homogeneous regions. Then the discriminative latent features are generated from each segmented region to represent the whole band, which can mitigate the effect of noise on the band selection. Finally, a self-representation subspace clustering model and an l 2 , 1 -norm regularization are utilized to explore the spectral correlation among all bands. In addition, a similarity graph between region-aware latent features is adaptively learned to preserve the spatial structure of HSIs in the latent representation space. Extensive classification experimental results on three public datasets verify the effectiveness of GRSC over several state-of-the-art methods. The demo code of this work is publicly available at https://github.com/WangJun2023/GRSC.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002313",
    "keywords": [
      "Adjacency list",
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Discriminative model",
      "Graph",
      "Hyperspectral imaging",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Principal component analysis",
      "Spatial analysis",
      "Spectral clustering",
      "Statistics",
      "Subspace topology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Tang",
        "given_name": "Chang"
      },
      {
        "surname": "Zheng",
        "given_name": "Xiao"
      },
      {
        "surname": "Liu",
        "given_name": "Xinwang"
      },
      {
        "surname": "Zhang",
        "given_name": "Wei"
      },
      {
        "surname": "Zhu",
        "given_name": "En"
      }
    ]
  },
  {
    "title": "The minimum regret path problem on stochastic fuzzy time-varying networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.029",
    "abstract": "In this paper, we introduce a stochastic fuzzy time-varying minimum regret path problem (SFTMRP), which combines the characteristics of the min–max regret path and maximum probability path as a variant of the stochastic fuzzy time-varying shortest path problem, and its purpose is to find a path with the minimum regret degree in a given stochastic fuzzy time-varying network. To address this problem, we propose a random fuzzy delay neural network (RFDNN) based on novel random fuzzy delay neurons and without any training requirements. The random fuzzy delay neuron consists of six layers: an input layer, receiving layer, status layer, generation layer, sending layer, and output layer. Among them, the input and output layers are the ports of communication between neurons, and the receiving layer, status layer, generate layer, and sending layer are the information processing units of neurons. The information exchange between neurons is characterized by two kinds of signals: the shortest path signal and the maximum probability solution signal. The theoretical analysis of the proposed algorithm is carried out with respect to time-complexity and correctness. The numerical example and experimental results on 25 randomly generated stochastic fuzzy time-varying road networks with different numbers of 1000–5000 nodes show that the performance of the proposed algorithm is significantly better than that of existing algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002441",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Chemistry",
      "Computer science",
      "Correctness",
      "Fuzzy logic",
      "Graph",
      "Layer (electronics)",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Organic chemistry",
      "Path (computing)",
      "Programming language",
      "Regret",
      "Shortest path problem",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Wei"
      },
      {
        "surname": "Xu",
        "given_name": "Zhilei"
      },
      {
        "surname": "Zhu",
        "given_name": "Liehuang"
      }
    ]
  },
  {
    "title": "Boolean matrix factorization based on collaborative neurodynamic optimization with Boltzmann machines",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.006",
    "abstract": "This paper presents a collaborative neurodynamic approach to Boolean matrix factorization. Based on a binary optimization formulation to minimize the Hamming distance between a given data matrix and its low-rank reconstruction, the proposed approach employs a population of Boltzmann machines operating concurrently for scatter search of factorization solutions. In addition, a particle swarm optimization rule is used to re-initialize the neuronal states of Boltzmann machines upon their local convergence to escape from local minima toward global solutions. Experimental results demonstrate the superior convergence and performance of the proposed approach against six baseline methods on ten benchmark datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002118",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Boltzmann machine",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Convergence (economics)",
      "Demography",
      "Economic growth",
      "Economics",
      "Eigenvalues and eigenvectors",
      "Geodesy",
      "Geography",
      "Materials science",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Matrix decomposition",
      "Maxima and minima",
      "Particle swarm optimization",
      "Physics",
      "Population",
      "Quantum mechanics",
      "Rank (graph theory)",
      "Restricted Boltzmann machine",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xinqi"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Kwong",
        "given_name": "Sam"
      }
    ]
  },
  {
    "title": "Privacy preserving Generative Adversarial Networks to model Electronic Health Records",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.022",
    "abstract": "Hospitals and General Practitioner (GP) surgeries within National Health Services (NHS), collect patient information on a routine basis to create personal health records such as family medical history, chronic diseases, medications and dosing. The collected information could be used to build and model various machine learning algorithms, to simplify the task of those working within the NHS. However, such Electronic Health Records are not made publicly available due to privacy concerns. In our paper, we propose a privacy-preserving Generative Adversarial Network (pGAN), which can generate synthetic data of high quality, while preserving the privacy and statistical properties of the source data. pGAN is evaluated on two distinct datasets, one posing as a Classification task, and the other as a Regression task. Privacy score of generated data is calculated using the Nearest Neighbour Adversarial Accuracy. Cosine similarity scores of synthetic data from our proposed model indicate that the data generated is similar in nature, but not identical. Additionally, our proposed model was able to preserve privacy while maintaining high utility. Machine learning models trained on both synthetic data and original data have achieved accuracies of 74.3% and 74.5% respectively on the classification dataset; while they have attained an R2-Score of 0.84 and 0.85 on synthetic and original data of the regression task respectively. Our results, therefore, indicate that synthetic data from the proposed model could replace the use of original data for machine learning while preserving privacy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002374",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Computer security",
      "Cosine similarity",
      "Data mining",
      "Economics",
      "Image (mathematics)",
      "Information privacy",
      "Machine learning",
      "Management",
      "Similarity (geometry)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Venugopal",
        "given_name": "Rohit"
      },
      {
        "surname": "Shafqat",
        "given_name": "Noman"
      },
      {
        "surname": "Venugopal",
        "given_name": "Ishwar"
      },
      {
        "surname": "Tillbury",
        "given_name": "Benjamin Mark John"
      },
      {
        "surname": "Stafford",
        "given_name": "Harry Demetrios"
      },
      {
        "surname": "Bourazeri",
        "given_name": "Aikaterini"
      }
    ]
  },
  {
    "title": "MGLNN: Semi-supervised learning via Multiple Graph Cooperative Learning Neural Networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.024",
    "abstract": "In many machine learning applications, data are coming with multiple graphs, which is known as the multiple graph learning problem. The problem of multiple graph learning is to learn consistent representation by exploiting the complementary information of multiple graphs. Graph Learning Neural Networks (GLNNs) have been demonstrated powerfully for graph data representation and semi-supervised classification tasks. However, Existing GLNNs are mainly developed for single graph data which cannot be utilized for multiple graph data representation. In this paper, we propose a novel learning framework, called Multiple Graph Learning Neural Networks (MGLNN), for multiple graph learning and multi-view semi-supervised classification. The goal of MGLNN is to learn an optimal graph structure from multiple graph structures that best serves GNNs’ learning which integrates multiple graph learning and GNNs’ representation simultaneously. The proposed MGLNN is a general framework which can incorporate any specific GNN model to deal with multiple graphs. A general algorithm has also been developed to optimize/train the proposed MGLNN model. Experimental results on several datasets demonstrate that MGLNN outperforms some other related methods on semi-supervised classification tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001988",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "External Data Representation",
      "Feature learning",
      "Graph",
      "Machine learning",
      "Semi-supervised learning",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Bo"
      },
      {
        "surname": "Chen",
        "given_name": "Si"
      },
      {
        "surname": "Wang",
        "given_name": "Beibei"
      },
      {
        "surname": "Luo",
        "given_name": "Bin"
      }
    ]
  },
  {
    "title": "Adaptive 2-bits-triggered neural control for uncertain nonlinear multi-agent systems with full state constraints",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.019",
    "abstract": "This paper investigates an adaptive 2-bits-triggered neural control for a class of uncertain nonlinear multi-agent systems (MASs) with full state constraints. Considering the limitations of practical physical devices and operating conditions, MASs may suffer performance degradation or even crash while the system states are not restricted. With this in mind, combined with barrier Lyapunov function (BLF), an adaptive neural consensus control is developed to guarantee that the state constraints of all followers are not violated. Further, the conversion relationship between the state constraints of MASs and the synchronization error constraints is clarified more precisely, which could improve the synchronization performance of MASs. In addition, considering both trigger threshold setting and control signal transmission bits issues, a 2-bit trigger strategy is proposed to maximize the utilization of MASs bandwidth resources. Theoretical analysis shows that all signals are uniformly ultimately bounded. And the simulation results demonstrate its effectiveness.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001939",
    "keywords": [
      "Adaptive control",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "State (computer science)",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Zicong"
      },
      {
        "surname": "Wang",
        "given_name": "Jianhui"
      },
      {
        "surname": "Zou",
        "given_name": "Tao"
      },
      {
        "surname": "Ma",
        "given_name": "Kemao"
      },
      {
        "surname": "Wang",
        "given_name": "Qinruo"
      }
    ]
  },
  {
    "title": "Training much deeper spiking neural networks with a small number of time-steps",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.001",
    "abstract": "Spiking Neural Network (SNN) is a promising energy-efficient neural architecture when implemented on neuromorphic hardware. The Artificial Neural Network (ANN) to SNN conversion method, which is the most effective SNN training method, has successfully converted moderately deep ANNs to SNNs with satisfactory performance. However, this method requires a large number of time-steps, which hurts the energy efficiency of SNNs. How to effectively covert a very deep ANN (e.g., more than 100 layers) to an SNN with a small number of time-steps remains a difficult task. To tackle this challenge, this paper makes the first attempt to propose a novel error analysis framework that takes both the “quantization error” and the “deviation error” into account, which comes from the discretization of SNN dynamicsthe neuron’s coding scheme and the inconstant input currents at intermediate layers, respectively. Particularly, our theories reveal that the “deviation error” depends on both the spike threshold and the input variance. Based on our theoretical analysis, we further propose the Threshold Tuning and Residual Block Restructuring (TTRBR) method that can convert very deep ANNs (>100 layers) to SNNs with negligible accuracy degradation while requiring only a small number of time-steps. With very deep networks, our TTRBR method achieves state-of-the-art (SOTA) performance on the CIFAR-10, CIFAR-100, and ImageNet classification tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002064",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Block (permutation group theory)",
      "Computer science",
      "Deep neural networks",
      "Geometry",
      "Mathematics",
      "Neuromorphic engineering",
      "Pattern recognition (psychology)",
      "Skew",
      "Spiking neural network",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Meng",
        "given_name": "Qingyan"
      },
      {
        "surname": "Yan",
        "given_name": "Shen"
      },
      {
        "surname": "Xiao",
        "given_name": "Mingqing"
      },
      {
        "surname": "Wang",
        "given_name": "Yisen"
      },
      {
        "surname": "Lin",
        "given_name": "Zhouchen"
      },
      {
        "surname": "Luo",
        "given_name": "Zhi-Quan"
      }
    ]
  },
  {
    "title": "Oblique and rotation double random forest",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.012",
    "abstract": "Random Forest is an ensemble of decision trees based on the bagging and random subspace concepts. As suggested by Breiman, the strength of unstable learners and the diversity among them are the ensemble models’ core strength. In this paper, we propose two approaches known as oblique and rotation double random forests. In the first approach, we propose rotation based double random forest. In rotation based double random forests, transformation or rotation of the feature space is generated at each node. At each node different random feature subspace is chosen for evaluation, hence the transformation at each node is different. Different transformations result in better diversity among the base learners and hence, better generalization performance. With the double random forest as base learner, the data at each node is transformed via two different transformations namely, principal component analysis and linear discriminant analysis. In the second approach, we propose oblique double random forest. Decision trees in random forest and double random forest are univariate, and this results in the generation of axis parallel split which fails to capture the geometric structure of the data. Also, the standard random forest may not grow sufficiently large decision trees resulting in suboptimal performance. To capture the geometric properties and to grow the decision trees of sufficient depth, we propose oblique double random forest. The oblique double random forest models are multivariate decision trees. At each non-leaf node, multisurface proximal support vector machine generates the optimal plane for better generalization performance. Also, different regularization techniques (Tikhonov regularization, axis-parallel split regularization, Null space regularization) are employed for tackling the small sample size problems in the decision trees of oblique double random forest. The proposed ensembles of decision trees produce trees with bigger size compared to the standard ensembles of decision trees as bagging is used at each non-leaf node which results in improved performance. The evaluation of the baseline models and the proposed oblique and rotation double random forest models is performed on benchmark 121 UCI datasets and real-world fisheries datasets. Both statistical analysis and the experimental results demonstrate the efficacy of the proposed oblique and rotation double random forest models compared to the baseline models on the benchmark datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002258",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Decision tree",
      "Linguistics",
      "Mathematics",
      "Multivariate random variable",
      "Oblique case",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Random forest",
      "Random variable",
      "Rotation (mathematics)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Ganaie",
        "given_name": "M.A."
      },
      {
        "surname": "Tanveer",
        "given_name": "M."
      },
      {
        "surname": "Suganthan",
        "given_name": "P.N."
      },
      {
        "surname": "Snasel",
        "given_name": "V."
      }
    ]
  },
  {
    "title": "A new predefined-time stability theorem and its application in the synchronization of memristive complex-valued BAM neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.031",
    "abstract": "In this paper, two novel and general predefined-time stability lemmas are given and applied to the predefined-time synchronization problem of memristive complex-valued bidirectional associative memory neural networks (MCVBAMNNs). Firstly, different from the generally fixed-time stability lemma, the setting of an adjustable time parameter in the derived predefined-time stability lemma causes it to be more flexible and more general. Secondly, the model studied in the complex-valued BAM neural networks model, which is different from the previous discussion of the real part and imaginary part respectively. It is more practical to study the complex-valued nonseparation. Thirdly, two effective controllers are designed to realize the synchronization performance of BAM neural networks based on the predefined-time stability, and the analysis is given based on general predefined-time synchronization. Finally, the correctness of the theoretical derivation is verified by numerical simulation. A secure communication scheme based on predefined-time synchronization of MCVBAMNNs is proposed, and the effectiveness and superiority of the results are proved.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002052",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bidirectional associative memory",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Content-addressable memory",
      "Control (management)",
      "Control theory (sociology)",
      "Correctness",
      "Ecology",
      "Lemma (botany)",
      "Machine learning",
      "Poaceae",
      "Stability (learning theory)",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Aidi"
      },
      {
        "surname": "Zhao",
        "given_name": "Hui"
      },
      {
        "surname": "Wang",
        "given_name": "Qingjie"
      },
      {
        "surname": "Niu",
        "given_name": "Sijie"
      },
      {
        "surname": "Gao",
        "given_name": "Xizhan"
      },
      {
        "surname": "Chen",
        "given_name": "Chuan"
      },
      {
        "surname": "Li",
        "given_name": "Lixiang"
      }
    ]
  },
  {
    "title": "SepNet: A neural network for directionally correlated data",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.005",
    "abstract": "Multi-dimensional tensor data appear in diverse settings, including multichannel signals, spectrograms, and hyperspectral data from remote sensing. In many cases, these data are directionally correlated, i.e. the correlation between variables from different dimensions is significantly weaker than the correlation between variables from the same dimension. Convolutional neural networks are readily applicable to directionally correlated data but are often inefficient, as they impose many unnecessary connections between neurons. Here we propose a novel architecture, SepNet, specifically for directionally correlated datasets. SepNet uses directional operators to extract directional features from each dimension separately, followed by a linear operator along the depth to generate higher-level features from the directional features. Experiments on two representative directionally correlated datasets showed that SepNet improved network efficiency up to 100-fold while maintaining high accuracy comparable with state-of-the-art convolutional neural network models. Furthermore, SepNet can be flexibly constructed with minimal restriction on the output shape of each layer. These results reveal the potential of data-specific architecting of neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002106",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Convolutional neural network",
      "Correlation",
      "Dimension (graph theory)",
      "Gene",
      "Geometry",
      "Mathematics",
      "Operator (biology)",
      "Pattern recognition (psychology)",
      "Pure mathematics",
      "Repressor",
      "Tensor (intrinsic definition)",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Fuchang"
      },
      {
        "surname": "Ma",
        "given_name": "Yiqing"
      },
      {
        "surname": "Zhang",
        "given_name": "Boyu"
      },
      {
        "surname": "Xian",
        "given_name": "Min"
      }
    ]
  },
  {
    "title": "Graph Transformer Networks: Learning meta-path graphs to improve GNNs",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.026",
    "abstract": "Graph Neural Networks (GNNs) have been widely applied to various fields due to their powerful representations of graph-structured data. Despite the success of GNNs, most existing GNNs are designed to learn node representations on the fixed and homogeneous graphs. The limitations especially become problematic when learning representations on a misspecified graph or a heterogeneous graph that consists of various types of nodes and edges. To address these limitations, we propose Graph Transformer Networks (GTNs) that are capable of generating new graph structures, which preclude noisy connections and include useful connections (e.g., meta-paths) for tasks, while learning effective node representations on the new graphs in an end-to-end fashion. We further propose enhanced version of GTNs, Fast Graph Transformer Networks (FastGTNs), that improve scalability of graph transformations. Compared to GTNs, FastGTNs are up to 230 × and 150 × faster in inference and training, and use up to 100 × and 148 × less memory while allowing the identical graph transformations as GTNs. In addition, we extend graph transformations to the semantic proximity of nodes allowing non-local operations beyond meta-paths. Extensive experiments on both homogeneous graphs and heterogeneous graphs show that GTNs and FastGTNs with non-local operations achieve the state-of-the-art performance for node classification tasks. The code is available: https://github.com/seongjunyun/Graph_Transformer_Networks",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002003",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Database",
      "Graph",
      "Inference",
      "Line graph",
      "Scalability",
      "Theoretical computer science",
      "Topological graph theory",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Yun",
        "given_name": "Seongjun"
      },
      {
        "surname": "Jeong",
        "given_name": "Minbyul"
      },
      {
        "surname": "Yoo",
        "given_name": "Sungdong"
      },
      {
        "surname": "Lee",
        "given_name": "Seunghun"
      },
      {
        "surname": "Yi",
        "given_name": "Sean S."
      },
      {
        "surname": "Kim",
        "given_name": "Raehyun"
      },
      {
        "surname": "Kang",
        "given_name": "Jaewoo"
      },
      {
        "surname": "Kim",
        "given_name": "Hyunwoo J."
      }
    ]
  },
  {
    "title": "ME-PLAN: A deep prototypical learning with local attention network for dynamic micro-expression recognition",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.024",
    "abstract": "As one of the important psychological stress reactions, Micro-expressions (MEs) are spontaneous and subtle facial movements, which usually occur in a high-stake situation and can reveal genuine human feelings and cognition. ME, Recognition (MER) has essential applications in many fields such as lie detection, criminal investigation, and psychological healing. However, due to the challenges of learning discriminative ME features via fleeting facial subtle reactions as well as the shortage of available MEs data, this research topic is still far from well-studied. To this end, in this paper, we propose a deep prototypical learning framework, namely ME-PLAN, with a local attention mechanism for the MER problem. Specifically, ME-PLAN consists of two components, i.e., a 3D residual prototypical network and a local-wise attention module, where the former aims to learn the precise ME feature prototypes through expression-related knowledge transfer and episodic training, and the latter could facilitate the attention to the local facial movements. Furthermore, to alleviate the dilemma that most MER methods need to depend on manually annotated apex frames, we propose an apex frame spotting method with Unimodal Pattern Constrained (UPC) and further extract ME key-frames sequences based on the detected apex frames to train our proposed ME-PLAN in an end-to-end manner. Finally, through extensive experiments and interpretable analysis regarding the apex frame spotting and MER on composite-database, we demonstrate the superiority and effectiveness of the proposed methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002398",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Dilemma",
      "Discriminative model",
      "Epistemology",
      "Expression (computer science)",
      "Facial expression",
      "Feature (linguistics)",
      "Frame (networking)",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Sirui"
      },
      {
        "surname": "Tang",
        "given_name": "Huaying"
      },
      {
        "surname": "Liu",
        "given_name": "Shifeng"
      },
      {
        "surname": "Zhang",
        "given_name": "Yangsong"
      },
      {
        "surname": "Wang",
        "given_name": "Hao"
      },
      {
        "surname": "Xu",
        "given_name": "Tong"
      },
      {
        "surname": "Chen",
        "given_name": "Enhong"
      },
      {
        "surname": "Guan",
        "given_name": "Cuntai"
      }
    ]
  },
  {
    "title": "Approximation rates of DeepONets for learning operators arising from advection–diffusion equations",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.019",
    "abstract": "We present the analysis of approximation rates of operator learning in Chen and Chen (1995) and Lu et al. (2021), where continuous operators are approximated by a sum of products of branch and trunk networks. In this work, we consider the rates of learning solution operators from both linear and nonlinear advection–diffusion equations with or without reaction. We find that the approximation rates depend on the architecture of branch networks as well as the smoothness of inputs and outputs of solution operators.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002349",
    "keywords": [
      "Advection",
      "Applied mathematics",
      "Biochemistry",
      "Biology",
      "Bounded function",
      "Chemistry",
      "Chen",
      "Computer science",
      "Diffusion",
      "Gene",
      "Linear approximation",
      "Linear operators",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Operator (biology)",
      "Operator theory",
      "Paleontology",
      "Physics",
      "Quantum mechanics",
      "Repressor",
      "Smoothness",
      "Thermodynamics",
      "Transcription factor",
      "Work (physics)"
    ],
    "authors": [
      {
        "surname": "Deng",
        "given_name": "Beichuan"
      },
      {
        "surname": "Shin",
        "given_name": "Yeonjong"
      },
      {
        "surname": "Lu",
        "given_name": "Lu"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhongqiang"
      },
      {
        "surname": "Karniadakis",
        "given_name": "George Em"
      }
    ]
  },
  {
    "title": "Approximation in shift-invariant spaces with deep ReLU neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.013",
    "abstract": "We study the expressive power of deep ReLU neural networks for approximating functions in dilated shift-invariant spaces, which are widely used in signal processing, image processing, communications and so on. Approximation error bounds are estimated with respect to the width and depth of neural networks. The network construction is based on the bit extraction and data-fitting capacity of deep neural networks. As applications of our main results, the approximation rates of classical function spaces such as Sobolev spaces and Besov spaces are obtained. We also give lower bounds of the L p ( 1 ≤ p ≤ ∞ ) approximation error for Sobolev spaces, which show that our construction of neural network is asymptotically optimal up to a logarithmic factor.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200226X",
    "keywords": [
      "Algorithm",
      "Approximation error",
      "Approximation theory",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Deep learning",
      "Function approximation",
      "Invariant (physics)",
      "Logarithm",
      "Mathematical analysis",
      "Mathematical physics",
      "Mathematics",
      "Pure mathematics",
      "Sobolev space",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yunfei"
      },
      {
        "surname": "Li",
        "given_name": "Zhen"
      },
      {
        "surname": "Wang",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Modularity-aware graph autoencoders for joint community detection and link prediction",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.021",
    "abstract": "Graph autoencoders (GAE) and variational graph autoencoders (VGAE) emerged as powerful methods for link prediction. Their performances are less impressive on community detection problems where, according to recent and concurring experimental evaluations, they are often outperformed by simpler alternatives such as the Louvain method. It is currently still unclear to which extent one can improve community detection with GAE and VGAE, especially in the absence of node features. It is moreover uncertain whether one could do so while simultaneously preserving good performances on link prediction. In this paper, we show that jointly addressing these two tasks with high accuracy is possible. For this purpose, we introduce and theoretically study a community-preserving message passing scheme, doping our GAE and VGAE encoders by considering both the initial graph structure and modularity-based prior communities when computing embedding spaces. We also propose novel training and optimization strategies, including the introduction of a modularity-inspired regularizer complementing the existing reconstruction losses for joint link prediction and community detection. We demonstrate the empirical effectiveness of our approach, referred to as Modularity-Aware GAE and VGAE, through in-depth experimental validation on various real-world graphs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002362",
    "keywords": [
      "Architectural engineering",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Biology",
      "Computer network",
      "Computer science",
      "Data mining",
      "Embedding",
      "Engineering",
      "Genetics",
      "Graph",
      "Graph embedding",
      "Joint (building)",
      "Link (geometry)",
      "Machine learning",
      "Modularity (biology)",
      "Node (physics)",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Salha-Galvan",
        "given_name": "Guillaume"
      },
      {
        "surname": "Lutzeyer",
        "given_name": "Johannes F."
      },
      {
        "surname": "Dasoulas",
        "given_name": "George"
      },
      {
        "surname": "Hennequin",
        "given_name": "Romain"
      },
      {
        "surname": "Vazirgiannis",
        "given_name": "Michalis"
      }
    ]
  },
  {
    "title": "Fixed-time synchronization of discontinuous competitive neural networks with time-varying delays",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.002",
    "abstract": "In this article, the fixed-time (FXT) synchronization of discontinuous competitive neural networks (CNNs) involving time-varying delays is investigated. Firstly, two kinds of discontinuous FXT control schemes are proposed and two forms of Lyapunov function are constructed based on p -norm and 1-norm to discuss the FXT synchronization of CNNs. By means of nonsmooth analysis and some inequality techniques, some simple criteria are obtained to achieve FXT synchronization and the upper bound of the settling time with less conservativeness is provided. Furthermore, the effect of time scale on FXT synchronization of CNNs is considered. Lastly, some numerical results for an example are provided to demonstrate the derived theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002076",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Engineering",
      "Law",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Norm (philosophy)",
      "Physics",
      "Political science",
      "Quantum mechanics",
      "Settling time",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Zheng",
        "given_name": "Caicai"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Yu",
        "given_name": "Juan"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      }
    ]
  },
  {
    "title": "Reducing noisy annotations for depression estimation from facial images",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.025",
    "abstract": "Depression has been considered the most dominant mental disorder over the past few years. To help clinicians effectively and efficiently estimate the severity scale of depression, various automated systems based on deep learning have been proposed. To estimate the severity of depression, i.e., the depression severity score (Beck Depression Inventory-II), various deep architectures have been designed to perform regression using the Euclidean loss. However, they do not consider the label distribution, and they do not learn the relationships between the facial images and BDI-II scores, which can be resulting in the noisy labeling for automatic depression estimation (ADE). To mitigate this problem, we propose an automated deep architecture, namely the self-adaptation network (SAN), to improve this uncertain labeling for ADE. Specifically, the architecture consists of four modules: (1) ResNet-18 and ResNet-50 are adopted in the deep feature extraction module (DFEM) to extract informative deep features; (2) a self-attention module (SAM) is adopted to learn the weights from the mini-batch; (3) a square ranking regularization module (SRRM) to create high partitions and low partitions is proposed; and (4) a re-label module (RM) is used to re-label the uncertain annotations for ADE in the low partitions. We conduct extensive experiments on depression databases (i.e., AVEC2013 and AVEC2014) and obtain a performance comparable to the performances of other ADE methods in assessing the severity of depression. More importantly, the proposed method can learn valuable depression patterns from facial videos and obtain a performance comparable to the performances of other methods for depression recognition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200199X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Depression (economics)",
      "Economics",
      "Euclidean distance",
      "Feature engineering",
      "Machine learning",
      "Macroeconomics",
      "Pattern recognition (psychology)",
      "Ranking (information retrieval)",
      "Regularization (linguistics)",
      "Residual neural network"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Lang"
      },
      {
        "surname": "Tiwari",
        "given_name": "Prayag"
      },
      {
        "surname": "Lv",
        "given_name": "Chonghua"
      },
      {
        "surname": "Wu",
        "given_name": "WenShuai"
      },
      {
        "surname": "Guo",
        "given_name": "Liyong"
      }
    ]
  },
  {
    "title": "Dimensionality of the intermediate-level representation of shape and texture in monkey V4",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.027",
    "abstract": "The visual area V4 has been considered to play a crucial role in the intermediate representation of objects, where low-level image features are transformed into object-level representations. We estimated the intrinsic dimensionality in V4 for the representation of local patches generated from natural scenes. The dimensionality was approximately 40, which is approximately half of that reported in IT for the representation of whole natural objects. The analyses of the estimated dimensionality suggest both common and independent representations that code contour shapes and/or surfaces with textures, implying a relatively complex and mixed representation in the intermediate-level area.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002428",
    "keywords": [
      "Artificial intelligence",
      "Code (set theory)",
      "Computer science",
      "Computer vision",
      "Curse of dimensionality",
      "Image (mathematics)",
      "Law",
      "Mathematics",
      "Object (grammar)",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Programming language",
      "Representation (politics)",
      "Set (abstract data type)",
      "Texture (cosmology)"
    ],
    "authors": [
      {
        "surname": "Kodama",
        "given_name": "Atsushi"
      },
      {
        "surname": "Kimura",
        "given_name": "Kouji"
      },
      {
        "surname": "Sakai",
        "given_name": "Ko"
      }
    ]
  },
  {
    "title": "Approximation properties of Gaussian-binary restricted Boltzmann machines and Gaussian-binary deep belief networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.020",
    "abstract": "Despite the successful use of Gaussian-binary restricted Boltzmann machines (GB-RBMs) and Gaussian-binary deep belief networks (GB-DBNs), little is known about their theoretical approximation capabilities to represent distributions of continuous random variables. In this paper, we address the expressive properties of GB-RBMs and GB-DBNs, contributing theoretical insights to the optimal number of hidden variables. We first treat the GB-RBM’s unnormalized log-likelihood as a sum of a special two-layer feedforward neural network and a negative quadratic term. Then, a series of simulation results are established, which can be used to relate GB-RBMs to general two-layer feedforward neural networks whose expressive properties are much better understood. On this basis, we show that a two-layer ReLU network with all weights in the second layer being 1, along with a negative quadratic term, can approximate all continuous functions. In addition, we provide qualified lower bounds for the number of hidden variables of GB-RBMs required to approximate distributions whose log-likelihood are given by some classes of smooth functions. Moreover, we further study the universal approximation of GB-DBNs with two hidden layers by providing a sufficient number of hidden variables O ( ɛ − 2 ) that are guaranteed to approximate any given strictly positive continuous distribution within a given error ɛ . Finally, numerical experiments are carried out to verify some of the proposed theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001940",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Arithmetic",
      "Artificial intelligence",
      "Artificial neural network",
      "Binary number",
      "Boltzmann machine",
      "Computer science",
      "Deep belief network",
      "Gaussian",
      "Geometry",
      "Mathematics",
      "Physics",
      "Quadratic equation",
      "Quantum mechanics",
      "Restricted Boltzmann machine"
    ],
    "authors": [
      {
        "surname": "Gu",
        "given_name": "Linyan"
      },
      {
        "surname": "Yang",
        "given_name": "Lihua"
      },
      {
        "surname": "Zhou",
        "given_name": "Feng"
      }
    ]
  },
  {
    "title": "Convergence of deep convolutional neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.031",
    "abstract": "Convergence of deep neural networks as the depth of the networks tends to infinity is fundamental in building the mathematical foundation for deep learning. In a previous study, we investigated this question for deep networks with the Rectified Linear Unit (ReLU) activation function and with a fixed width. This does not cover the important convolutional neural networks where the widths are increased from layer to layer. For this reason, we first study convergence of general ReLU networks with increased widths and then apply the results obtained to deep convolutional neural networks. It turns out the convergence reduces to convergence of infinite products of matrices with increased sizes, which has not been considered in the literature. We establish sufficient conditions for convergence of such infinite products of matrices. Based on the conditions, we present sufficient conditions for pointwise convergence of general deep ReLU networks with increasing widths, and as well as pointwise convergence of deep ReLU convolutional neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002465",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Convergence (economics)",
      "Convolutional neural network",
      "Deep learning",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Mathematical analysis",
      "Mathematics",
      "Network topology",
      "Operating system",
      "Pointwise",
      "Pointwise convergence"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Yuesheng"
      },
      {
        "surname": "Zhang",
        "given_name": "Haizhang"
      }
    ]
  },
  {
    "title": "Toward reliable designs of data-driven reinforcement learning tracking control for Euler–Lagrange systems",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.017",
    "abstract": "This paper addresses reinforcement learning based, direct signal tracking control with an objective of developing mathematically suitable and practically useful design approaches. Specifically, we aim to provide reliable and easy to implement designs in order to reach reproducible neural network-based solutions. Our proposed new design takes advantage of two control design frameworks: a reinforcement learning based, data-driven approach to provide the needed adaptation and (sub)optimality, and a backstepping based approach to provide closed-loop system stability framework. We develop this work based on an established direct heuristic dynamic programming (dHDP) learning paradigm to perform online learning and adaptation and a backstepping design for a class of important nonlinear dynamics described as Euler–Lagrange systems. We provide a theoretical guarantee for the stability of the overall dynamic system, weight convergence of the approximating nonlinear neural networks, and the Bellman (sub)optimality of the resulted control policy. We use simulations to demonstrate significantly improved design performance of the proposed approach over the original dHDP.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001915",
    "keywords": [
      "Adaptive control",
      "Artificial intelligence",
      "Artificial neural network",
      "Backstepping",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Heuristic",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Yao",
        "given_name": "Zhikai"
      },
      {
        "surname": "Yao",
        "given_name": "Jianyong"
      }
    ]
  },
  {
    "title": "Computational role of exploration noise in error-based de novo motor learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.011",
    "abstract": "The redundancy inherent to the human body is a central problem that must be solved by the brain when acquiring new motor skills. The problem of redundancy becomes particularly critical when learning a new motor policy from scratch in a novel environment and task (i.e., de novo learning). It has been proposed that motor variability could be leveraged to explore and identify task-potent motor commands, and recent results indicated a possible role of motor exploration in error-based motor learning, including in de novo learning tasks. However, the precise computational mechanisms underlying this role remain poorly understood. A new controller in a de novo motor task can potentially be learned by first using motor exploration to learn a sensitivity derivative, which can transform observed task errors into motor corrections, enabling the error-based learning of the controller. Although this approach has been discussed, the computational properties of exploration and how this mechanism can explain recent reports of motor exploration in error-based de-novo learning have not been thoroughly examined. Here, we used this approach to simulate the tasks used in several recent studies of human motor learning tasks in which motor exploration was observed, and replicating their main results. Analyses of the proposed learning mechanism using equations and simulations suggested that exploring the entire motor command space leads to the training of an efficient sensitivity derivative, enabling rapid learning of the controller, in visuomotor adaptation and de novo tasks. The successful replication of previous experimental results elucidated the role of motor exploration in motor learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002246",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Engineering",
      "Machine learning",
      "Motor control",
      "Motor learning",
      "Motor skill",
      "Neuroscience",
      "Operating system",
      "Psychology",
      "Redundancy (engineering)",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Dal’Bello",
        "given_name": "Lucas Rebelo"
      },
      {
        "surname": "Izawa",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "SIRe-Networks: Convolutional neural networks architectural extension for information preservation via skip/residual connections and interlaced auto-encoders",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.030",
    "abstract": "Improving existing neural network architectures can involve several design choices such as manipulating the loss functions, employing a diverse learning strategy, exploiting gradient evolution at training time, optimizing the network hyper-parameters, or increasing the architecture depth. The latter approach is a straightforward solution, since it directly enhances the representation capabilities of a network; however, the increased depth generally incurs in the well-known vanishing gradient problem. In this paper, borrowing from different methods addressing this issue, we introduce an interlaced multi-task learning strategy, defined SIRe, to reduce the vanishing gradient in relation to the object classification task. The presented methodology directly improves a convolutional neural network (CNN) by preserving information from the input image through interlaced auto-encoders (AEs), and further refines the base network architecture by means of skip and residual connections. To validate the presented methodology, a simple CNN and various implementations of famous networks are extended via the SIRe strategy and extensively tested on five collections, i.e., MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100, and Caltech-256; where the SIRe-extended architectures achieve significantly increased performances across all models and datasets, thus confirming the presented approach effectiveness.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002453",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Deep learning",
      "Encoder",
      "Extension (predicate logic)",
      "MNIST database",
      "Machine learning",
      "Network architecture",
      "Operating system",
      "Pattern recognition (psychology)",
      "Programming language",
      "Residual",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Avola",
        "given_name": "Danilo"
      },
      {
        "surname": "Cinque",
        "given_name": "Luigi"
      },
      {
        "surname": "Fagioli",
        "given_name": "Alessio"
      },
      {
        "surname": "Foresti",
        "given_name": "Gian Luca"
      }
    ]
  },
  {
    "title": "Sparse signal reconstruction via recurrent neural networks with hyperbolic tangent function",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.022",
    "abstract": "In this paper, several recurrent neural networks (RNNs) for solving the L 1 -minimization problem are proposed. First, a one-layer RNN based on the hyperbolic tangent function and the projection matrix is designed. In addition, the stability and global convergence of the previously presented RNN are proved by the Lyapunov method. Then, the sliding mode control technique is introduced into the former RNN to design finite-time RNN (FTRNN). Under the condition that the projection matrix satisfies the Restricted Isometry Property (RIP), a suitable Lyapunov function is constructed to prove that the FTRNN is stable in the Lyapunov sense and has the finite-time convergence property. Finally, we make a comparison of the proposed RNN and FTRNN with the existing RNNs. To achieve this, we implement experiments for sparse signal reconstruction and image reconstruction. The results further demonstrate the effectiveness and superior performance of the proposed RNN and FTRNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001964",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Compressed sensing",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Geometry",
      "Lyapunov function",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Projection (relational algebra)",
      "Quantum mechanics",
      "Recurrent neural network",
      "Restricted isometry property",
      "Tangent"
    ],
    "authors": [
      {
        "surname": "Wen",
        "given_name": "Hongsong"
      },
      {
        "surname": "He",
        "given_name": "Xing"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Online subspace learning and imputation by Tensor-Ring decomposition",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.023",
    "abstract": "This paper considers the completion problem of a partially observed high-order streaming data, which is cast as an online low-rank tensor completion problem. Though the online low-rank tensor completion problem has drawn lots of attention in recent years, most of them are designed based on the traditional decomposition method, such as CP and Tucker. Inspired by the advantages of Tensor Ring decomposition over the traditional decompositions in expressing high-order data and its superiority in missing values estimation, this paper proposes two online subspace learning and imputation methods based on Tensor Ring decomposition. Specifically, we first propose an online Tensor Ring subspace learning and imputation model by formulating an exponentially weighted least squares with Frobenium norm regularization of TR-cores. Then, two commonly used optimization algorithms, i.e. alternating recursive least squares and stochastic-gradient algorithms, are developed to solve the proposed model. Numerical experiments show that the proposed methods are more effective to exploit the time-varying subspace in comparison with the conventional Tensor Ring completion methods. Besides, the proposed methods are demonstrated to be superior to obtain better results than state-of-the-art online methods in streaming data completion under varying missing ratios and noise.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001976",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Eigenvalues and eigenvectors",
      "Gaussian",
      "Imputation (statistics)",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Matrix completion",
      "Matrix decomposition",
      "Missing data",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Subspace topology",
      "Tensor (intrinsic definition)",
      "Tensor decomposition",
      "Tucker decomposition"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Jinshi"
      },
      {
        "surname": "Zou",
        "given_name": "Tao"
      },
      {
        "surname": "Zhou",
        "given_name": "Guoxu"
      }
    ]
  },
  {
    "title": "Single-layer vision transformers for more accurate early exits with less overhead",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.038",
    "abstract": "Deploying deep learning models in time-critical applications with limited computational resources, for instance in edge computing systems and IoT networks, is a challenging task that often relies on dynamic inference methods such as early exiting. In this paper, we introduce a novel architecture for early exiting based on the vision transformer architecture, as well as a fine-tuning strategy that significantly increase the accuracy of early exit branches compared to conventional approaches while introducing less overhead. Through extensive experiments on image and audio classification as well as audiovisual crowd counting, we show that our method works for both classification and regression problems, and in both single- and multi-modal settings. Additionally, we introduce a novel method for integrating audio and visual modalities within early exits in audiovisual data analysis, that can lead to a more fine-grained dynamic inference.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002532",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Cloud computing",
      "Computer engineering",
      "Computer science",
      "Deep learning",
      "Edge device",
      "Inference",
      "Machine learning",
      "Operating system",
      "Overhead (engineering)",
      "Physics",
      "Quantum mechanics",
      "Transformer",
      "Visual arts",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Bakhtiarnia",
        "given_name": "Arian"
      },
      {
        "surname": "Zhang",
        "given_name": "Qi"
      },
      {
        "surname": "Iosifidis",
        "given_name": "Alexandros"
      }
    ]
  },
  {
    "title": "Neural network interpolation operators optimized by Lagrange polynomial",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.007",
    "abstract": "In this paper, we introduce a new type of interpolation operators by using Lagrange polynomials of degree r , which can be regarded as feedforward neural networks with four layers. The approximation rate of the new operators can be estimated by the ( r + 1 ) -th modulus of smoothness of the objective functions. By adding some smooth assumptions on the activation function, we establish two important inequalities of the derivatives of the operators. With these two inequalities, by using the K -functional and Berens–Lorentz lemma in approximation theory, we establish the converse theorem of approximation. We also give the Voronovskaja-type asymptotic estimation of the operators for smooth functions. Furthermore, we extend our operators to the multivariate case, and investigate their approximation properties for multivariate functions. Finally, some numerical examples are given to demonstrate the validity of the theoretical results obtained and the superiority of the operators.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200212X",
    "keywords": [
      "Animation",
      "Applied mathematics",
      "Artificial neural network",
      "Biology",
      "Computer graphics (images)",
      "Computer science",
      "Converse",
      "Ecology",
      "Function approximation",
      "Geometry",
      "Interpolation (computer graphics)",
      "Lemma (botany)",
      "Machine learning",
      "Mathematics",
      "Modulus of continuity",
      "Poaceae",
      "Pure mathematics",
      "Type (biology)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Guoshun"
      },
      {
        "surname": "Yu",
        "given_name": "Dansheng"
      },
      {
        "surname": "Zhou",
        "given_name": "Ping"
      }
    ]
  },
  {
    "title": "Quantum Neural Networks and Topological Quantum Field Theories",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.028",
    "abstract": "Our work intends to show that: (1) Quantum Neural Networks (QNNs) can be mapped onto spin-networks, with the consequence that the level of analysis of their operation can be carried out on the side of Topological Quantum Field Theory (TQFT); (2) A number of Machine Learning (ML) key-concepts can be rephrased by using the terminology of TQFT. Our framework provides as well a working hypothesis for understanding the generalization behavior of DNNs, relating it to the topological features of the graph structures involved.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002027",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Field (mathematics)",
      "Generalization",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Philosophy",
      "Physics",
      "Pure mathematics",
      "Quantum",
      "Quantum field theory",
      "Quantum mechanics",
      "Terminology",
      "Topological quantum field theory",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Marcianò",
        "given_name": "Antonino"
      },
      {
        "surname": "Chen",
        "given_name": "Deen"
      },
      {
        "surname": "Fabrocini",
        "given_name": "Filippo"
      },
      {
        "surname": "Fields",
        "given_name": "Chris"
      },
      {
        "surname": "Greco",
        "given_name": "Enrico"
      },
      {
        "surname": "Gresnigt",
        "given_name": "Niels"
      },
      {
        "surname": "Jinklub",
        "given_name": "Krid"
      },
      {
        "surname": "Lulli",
        "given_name": "Matteo"
      },
      {
        "surname": "Terzidis",
        "given_name": "Kostas"
      },
      {
        "surname": "Zappala",
        "given_name": "Emanuele"
      }
    ]
  },
  {
    "title": "Recurrent neural networks as kinematics estimator and controller for redundant manipulators subject to physical constraints",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.021",
    "abstract": "Redundant manipulators could be efficient tools in industrial production as a result of their dexterity. However, existing kinematic control methods for redundant manipulators have two main disadvantages. On one hand, model uncertainties or unknown kinematic parameters may degrade the performance of existing model-based control methods subject to joint limits. On the other hand, existing model-free control methods ignore the existence of joint limits although they do not need to know kinematic models of redundant manipulators. In this paper, a quadratic programming (QP) scheme is elaborated to achieve the primary tracking control task of redundant manipulators as well as joint limits avoidance task. Besides, a gradient neurodynamics (GND) model is utilized to estimate the kinematics of redundant manipulators. Then, a primal dual neural network, which is employed to solve the QP problem, and the GND model are integrated towards developing a model-free control method constrained by joint angle and velocity limits for redundant manipulators. The visual sensory feedback is fed to the two neural networks. The efficacy of the proposed control method is demonstrated by extensive simulations and experiments, and the merits of the proposed method are also substantiated by comparisons.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001952",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Classical mechanics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Estimator",
      "Kinematics",
      "Mathematical optimization",
      "Mathematics",
      "Physics",
      "Quadratic programming",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Tan",
        "given_name": "Ning"
      },
      {
        "surname": "Yu",
        "given_name": "Peng"
      },
      {
        "surname": "Liao",
        "given_name": "Shen"
      },
      {
        "surname": "Sun",
        "given_name": "Zhenglong"
      }
    ]
  },
  {
    "title": "Exploring phase–amplitude coupling from primary motor cortex-basal ganglia–thalamus network model",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.027",
    "abstract": "The purpose of this study is to develop a primary motor cortex (M1)-basal ganglia–thalamus model capable of reproducing the physiological phenomenon of exaggerated phase–amplitude coupling (PAC) in Parkinson’s disease and exploring the potential sources of PAC anomalies in M1. The subthalamic nucleus (STN) phase-STN amplitude coupling, STN phase–M1 amplitude coupling, and M1 phase–M1 amplitude coupling are reproduced, where the phase frequencies are distributed in the beta band and the amplitude frequencies are distributed in the broad gamma band. We mainly study the impacts of thalamus → M1 connections and STN ↔ M1 bidirectional synaptic connections. Abnormal beta oscillations generated within the basal ganglia are found to be transmitted to M1 through the STN or thalamus and could be one of the potential sources of PAC-related beta oscillations in M1, thereby interfering with high-frequency signals in the motor cortex. Furthermore, the weakening of M1 → STN leads to a shift of the oscillations of the STN from the high beta band to the low beta band, which is more consistent with pathological experiments, thus supporting the experimental results that the hyper-direct path from M1 to STN drives the beta oscillations of STN. Finally, the suppression effect of STN deep brain stimulation on PAC is investigated. As the stimulation frequency increases, the PAC modulation index within different regions gradually decreases, in general agreement with the trend of synchronization level and beta oscillation energy, indirectly indicating that PAC can be used as a feedback indicator of parkinsonian state.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002015",
    "keywords": [
      "Amplitude",
      "BETA (programming language)",
      "Basal ganglia",
      "Beta Rhythm",
      "Central nervous system",
      "Computer science",
      "Cortex (anatomy)",
      "Coupling (piping)",
      "Deep brain stimulation",
      "Disease",
      "Electroencephalography",
      "Internal medicine",
      "Materials science",
      "Medicine",
      "Metallurgy",
      "Motor cortex",
      "Neuroscience",
      "Parkinson's disease",
      "Physics",
      "Primary motor cortex",
      "Programming language",
      "Psychology",
      "Quantum mechanics",
      "Stimulation",
      "Subthalamic nucleus",
      "Thalamus"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Ying"
      },
      {
        "surname": "Han",
        "given_name": "Fang"
      },
      {
        "surname": "Wang",
        "given_name": "Qingyun"
      }
    ]
  },
  {
    "title": "From YouTube to the brain: Transfer learning can improve brain-imaging predictions with deep learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.014",
    "abstract": "Deep learning has recently achieved best-in-class performance in several fields, including biomedical domains such as X-ray images. Yet, data scarcity poses a strict limit on training successful deep learning systems in many, if not most, biomedical applications, including those involving brain images. In this study, we translate state-of-the-art transfer learning techniques for single-subject prediction of simpler (sex and age) and more complex phenotypes (number of people in household, household income, fluid intelligence and smoking behavior). We fine-tuned 2D and 3D ResNet-18 convolutional neural networks for target phenotype predictions from brain images of ∼ 40,000 UK Biobank participants, after pretraining on YouTube videos from the Kinetics dataset and natural images from the ImageNet dataset. Transfer learning was effective on several phenotypes, especially sex and age classification. Additionally, transfer learning in particular outperformed deep learning models trained from scratch especially on smaller sample sizes. The out-of-sample performance using transfer learning from previously learned knowledge based on real-world images and videos could unlock the potential in many areas of imaging neuroscience where deep learning solutions are currently infeasible.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002295",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Inductive transfer",
      "Machine learning",
      "Mobile robot",
      "Neuroimaging",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Robot",
      "Robot learning",
      "Sample (material)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Malik",
        "given_name": "Nahiyan"
      },
      {
        "surname": "Bzdok",
        "given_name": "Danilo"
      }
    ]
  },
  {
    "title": "Image super-resolution with an enhanced group convolutional neural network",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.009",
    "abstract": "CNNs with strong learning abilities are widely chosen to resolve super-resolution problem. However, CNNs depend on deeper network architectures to improve performance of image super-resolution, which may increase computational cost in general. In this paper, we present an enhanced super-resolution group CNN (ESRGCNN) with a shallow architecture by fully fusing deep and wide channel features to extract more accurate low-frequency information in terms of correlations of different channels in single image super-resolution (SISR). Also, a signal enhancement operation in the ESRGCNN is useful to inherit more long-distance contextual information for resolving long-term dependency. An adaptive up-sampling operation is gathered into a CNN to obtain an image super-resolution model with low-resolution images of different sizes. Extensive experiments report that our ESRGCNN surpasses the state-of-the-arts in terms of SISR performance, complexity, execution speed, image quality evaluation and visual effect in SISR. Code is found at https://github.com/hellloxiaotian/ESRGCNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002143",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Code (set theory)",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Dependency (UML)",
      "Image (mathematics)",
      "Image resolution",
      "Pattern recognition (psychology)",
      "Programming language",
      "Resolution (logic)",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Chunwei"
      },
      {
        "surname": "Yuan",
        "given_name": "Yixuan"
      },
      {
        "surname": "Zhang",
        "given_name": "Shichao"
      },
      {
        "surname": "Lin",
        "given_name": "Chia-Wen"
      },
      {
        "surname": "Zuo",
        "given_name": "Wangmeng"
      },
      {
        "surname": "Zhang",
        "given_name": "David"
      }
    ]
  },
  {
    "title": "Exploring phase–amplitude coupling from primary motor cortex-basal ganglia–thalamus network model",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.027",
    "abstract": "The purpose of this study is to develop a primary motor cortex (M1)-basal ganglia–thalamus model capable of reproducing the physiological phenomenon of exaggerated phase–amplitude coupling (PAC) in Parkinson’s disease and exploring the potential sources of PAC anomalies in M1. The subthalamic nucleus (STN) phase-STN amplitude coupling, STN phase–M1 amplitude coupling, and M1 phase–M1 amplitude coupling are reproduced, where the phase frequencies are distributed in the beta band and the amplitude frequencies are distributed in the broad gamma band. We mainly study the impacts of thalamus → M1 connections and STN ↔ M1 bidirectional synaptic connections. Abnormal beta oscillations generated within the basal ganglia are found to be transmitted to M1 through the STN or thalamus and could be one of the potential sources of PAC-related beta oscillations in M1, thereby interfering with high-frequency signals in the motor cortex. Furthermore, the weakening of M1 → STN leads to a shift of the oscillations of the STN from the high beta band to the low beta band, which is more consistent with pathological experiments, thus supporting the experimental results that the hyper-direct path from M1 to STN drives the beta oscillations of STN. Finally, the suppression effect of STN deep brain stimulation on PAC is investigated. As the stimulation frequency increases, the PAC modulation index within different regions gradually decreases, in general agreement with the trend of synchronization level and beta oscillation energy, indirectly indicating that PAC can be used as a feedback indicator of parkinsonian state.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002015",
    "keywords": [
      "Amplitude",
      "BETA (programming language)",
      "Basal ganglia",
      "Beta Rhythm",
      "Central nervous system",
      "Computer science",
      "Cortex (anatomy)",
      "Coupling (piping)",
      "Deep brain stimulation",
      "Disease",
      "Electroencephalography",
      "Internal medicine",
      "Materials science",
      "Medicine",
      "Metallurgy",
      "Motor cortex",
      "Neuroscience",
      "Parkinson's disease",
      "Physics",
      "Primary motor cortex",
      "Programming language",
      "Psychology",
      "Quantum mechanics",
      "Stimulation",
      "Subthalamic nucleus",
      "Thalamus"
    ],
    "authors": [
      {
        "surname": "Yu",
        "given_name": "Ying"
      },
      {
        "surname": "Han",
        "given_name": "Fang"
      },
      {
        "surname": "Wang",
        "given_name": "Qingyun"
      }
    ]
  },
  {
    "title": "Online action proposal generation using spatio-temporal attention network",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.032",
    "abstract": "Temporal action proposal generation aims to generate temporal boundaries containing action instances. In real-time applications such as surveillance cameras, autonomous driving, and traffic monitoring, the online localization and recognition of human activities occurring in short temporal intervals are important areas of research. Existing approaches of temporal action proposal generation consider only the offline and frame-level feature aggregation along the temporal dimension. Those offline methods also generate many redundant irrelevant proposal regions in the frames as temporal boundaries. This leads to higher computational cost along with slow processing speed which is not suitable for online tasks. In this study, we propose a novel spatio-temporal attention network for online action proposal generation as opposed to existing offline proposal generation methods. Our novel proposed approach incorporates the inter-dependency between the spatial and temporal context information of each incoming video clip to generate more relevant online temporal action proposals. First, we propose a windowed spatial attention module to capture the inter-spatial relationship between the features of incoming frames. The windowed spatial network produces more robust clip-level feature representation and efficiently deals with noisy features such as occlusion or background scenes. Second, we introduce a temporal attention module to capture relevant temporal dynamic information mutually to the localized spatial information to model the long inter-frame temporal relationship since most online real life videos are untrimmed in nature. By applying these two attention modules sequentially, the novel proposed spatio-temporal network model is able to generate precise action boundaries at a particular instant of time. In addition, the model generates fewer discriminative temporal action proposals while maintaining a low computational cost and high processing speed suitable for online settings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002477",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Feature (linguistics)",
      "Frame (networking)",
      "Geology",
      "Law",
      "Linguistics",
      "Machine learning",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Political science",
      "Politics",
      "Quantum mechanics",
      "Remote sensing",
      "Representation (politics)",
      "Spatial analysis",
      "Spatial contextual awareness",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Keisham",
        "given_name": "Kanchan"
      },
      {
        "surname": "Jalali",
        "given_name": "Amin"
      },
      {
        "surname": "Lee",
        "given_name": "Minho"
      }
    ]
  },
  {
    "title": "Riemannian gradient methods for stochastic composition problems",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.004",
    "abstract": "In the paper, we study a class of novel stochastic composition optimization problems over Riemannian manifold, which have been raised by multiple emerging machine learning applications such as distributionally robust learning in Riemannian manifold setting. To solve these composition problems, we propose an effective Riemannian compositional gradient (RCG) algorithm, which has a sample complexity of O ( ϵ − 4 ) for finding an ϵ -stationary point. To further reduce sample complexity, we propose an accelerated momentum-based Riemannian compositional gradient (M-RCG) algorithm. Moreover, we prove that the M-RCG obtains a lower sample complexity of O ̃ ( ϵ − 3 ) without large batches, which achieves the best known sample complexity for its Euclidean counterparts. Extensive numerical experiments on training deep neural networks (DNNs) over Stiefel manifold and learning principal component analysis (PCA) over Grassmann manifold demonstrate effectiveness of our proposed algorithms. To the best of our knowledge, this is the first study of the composition optimization problems over Riemannian manifold.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200209X",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Composition (language)",
      "Computer science",
      "Engineering",
      "Euclidean geometry",
      "Geometry",
      "Linguistics",
      "Manifold (fluid mechanics)",
      "Mathematical optimization",
      "Mathematics",
      "Mechanical engineering",
      "Philosophy",
      "Physics",
      "Pure mathematics",
      "Riemannian manifold",
      "Sample (material)",
      "Stiefel manifold",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Feihu"
      },
      {
        "surname": "Gao",
        "given_name": "Shangqian"
      }
    ]
  },
  {
    "title": "Transfer learning for motor imagery based brain–computer interfaces: A tutorial",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.008",
    "abstract": "A brain–computer interface (BCI) enables a user to communicate directly with an external device, e.g., a computer, using brain signals. It can be used to research, map, assist, augment, or repair human cognitive or sensory–motor functions. A closed-loop BCI system performs signal acquisition, temporal filtering, spatial filtering, feature engineering and classification, before sending out the control signal to an external device. Transfer learning (TL) has been widely used in motor imagery (MI) based BCIs to reduce the calibration effort for a new subject, greatly increasing their utility. This tutorial describes how TL can be considered in as many components of a BCI system as possible, and introduces a complete TL pipeline for MI-based BCIs. Examples on two MI datasets demonstrated the advantages of considering TL in multiple components of MI-based BCIs. Especially, integrating data alignment and sophisticated TL approaches can significantly improve the classification performance, and hence greatly reduces the calibration effort.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002131",
    "keywords": [
      "Artificial intelligence",
      "Brain–computer interface",
      "Bubble",
      "Computer science",
      "Electroencephalography",
      "Human–computer interaction",
      "Interface (matter)",
      "Machine learning",
      "Maximum bubble pressure method",
      "Motor imagery",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Pipeline (software)",
      "Programming language",
      "Psychiatry",
      "Psychology",
      "SIGNAL (programming language)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Dongrui"
      },
      {
        "surname": "Jiang",
        "given_name": "Xue"
      },
      {
        "surname": "Peng",
        "given_name": "Ruimin"
      }
    ]
  },
  {
    "title": "A survey for deep reinforcement learning in markovian cyber–physical systems: Common problems and solutions",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.013",
    "abstract": "Deep Reinforcement Learning (DRL) is increasingly applied in cyber–physical systems for automation tasks. It is important to record the developing trends in DRL’s applications to help researchers overcome common problems using common solutions. This survey investigates trends seen within two applied settings: motor control tasks, and resource allocation tasks. The common problems include intractability of the action space, or state space, as well as hurdles associated with the prohibitive cost of training systems from scratch in the real-world. Real-world training data is sparse and difficult to derive and training in real-world can damage real-world learning systems. Researchers have provided a set of common as well as unique solutions. Tackling the problem of intractability, researchers have succeeded in guiding network training with handcrafted reward functions, auxiliary learning, and by simplifying the state or action spaces before performing transfer learning to more complex systems. Many state-of-the-art algorithms reformulate problems to use multi-agent or hierarchical learning to reduce the intractability of the state or action spaces for a single agent. Common solutions to the prohibitive cost of training include using benchmarks and simulations. This requires a shared feature space common to both simulation and the real world; without that you introduce what is known as the reality gap problem. This is the first survey, to our knowledge, that studies DRL as it is applied in the real world at this scope. It is our hope that the common solutions surveyed become common practice.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001873",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Cyber-physical system",
      "Machine learning",
      "Markov process",
      "Mathematics",
      "Operating system",
      "Psychology",
      "Reinforcement",
      "Reinforcement learning",
      "Social psychology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Rupprecht",
        "given_name": "Timothy"
      },
      {
        "surname": "Wang",
        "given_name": "Yanzhi"
      }
    ]
  },
  {
    "title": "A universal adversarial policy for text classifiers",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.018",
    "abstract": "Discovering the existence of universal adversarial perturbations had large theoretical and practical impacts on the field of adversarial learning. In the text domain, most universal studies focused on adversarial prefixes which are added to all texts. However, unlike the vision domain, adding the same perturbation to different inputs results in noticeably unnatural inputs. Therefore, we introduce a new universal adversarial setup – a universal adversarial policy, which has many advantages of other universal attacks but also results in valid texts – thus making it relevant in practice. We achieve this by learning a single search policy over a predefined set of semantics preserving text alterations, on many texts. This formulation is universal in that the policy is successful in finding adversarial examples on new texts efficiently. Our approach uses text perturbations which were extensively shown to produce natural attacks in the non-universal setup (specific synonym replacements). We suggest a strong baseline approach for this formulation which uses reinforcement learning. Its ability to generalise (from as few as 500 training texts) shows that universal adversarial patterns exist in the text domain as well.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002337",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Computer science",
      "Machine learning",
      "Programming language",
      "Set (abstract data type)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Maimon",
        "given_name": "Gallil"
      },
      {
        "surname": "Rokach",
        "given_name": "Lior"
      }
    ]
  },
  {
    "title": "Scalp EEG functional connection and brain network in infants with West syndrome",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.029",
    "abstract": "The common age-dependent West syndrome can be diagnosed accurately by electroencephalogram (EEG), but its pathogenesis and evolution remain unclear. Existing research mainly aims at the study of West seizure markers in time/frequency domain, while less literature uses a graph-theoretic approach to analyze changes among different brain regions. In this paper, the scalp EEG based functional connectivity (including Correlation, Coherence, Time Frequency Cross Mutual Information, Phase-Locking Value, Phase Lag Index, Weighted Phase Lag Index) and network topology parameters (including Clustering coefficient, Feature path length, Global efficiency, and Local efficiency) are comprehensively studied for the prognostic analysis of the West episode cycle. The scalp EEGs of 15 children with clinically diagnosed string spasticity seizures are used for prospective study, where the signal is divided into pre-seizure, seizure, and post-seizure states in 5 typical brain wave rhythm frequency bands ( δ (1–4 Hz), θ (4–8 Hz), α (8–13 Hz), β (13–30 Hz), and γ (30–80 Hz)) for functional connectivity analysis. The study shows that recurrent West seizures weaken connections between brain regions responsible for cognition and intelligence, while brain regions responsible for information synergy and visual reception have greater variability in connectivity during seizures. It is observed that the changes in β and γ frequency bands of the multiband brain network connectivity patterns calculated by Corr and WPLI can be preliminarily used as judgment of seizure cycle changes in West syndrome.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002039",
    "keywords": [
      "Anatomy",
      "Artificial intelligence",
      "Centrality",
      "Cluster analysis",
      "Clustering coefficient",
      "Coherence (philosophical gambling strategy)",
      "Combinatorics",
      "Complex network",
      "Computer science",
      "Electroencephalography",
      "Epilepsy",
      "Mathematics",
      "Medicine",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Scalp",
      "Small-world network",
      "West Syndrome",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Zheng",
        "given_name": "Runze"
      },
      {
        "surname": "Feng",
        "given_name": "Yuanmeng"
      },
      {
        "surname": "Wang",
        "given_name": "Tianlei"
      },
      {
        "surname": "Cao",
        "given_name": "Jiuwen"
      },
      {
        "surname": "Wu",
        "given_name": "Duanpo"
      },
      {
        "surname": "Jiang",
        "given_name": "Tiejia"
      },
      {
        "surname": "Gao",
        "given_name": "Feng"
      }
    ]
  },
  {
    "title": "Successfully and efficiently training deep multi-layer perceptrons with logistic activation function simply requires initializing the weights with an appropriate negative mean",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.030",
    "abstract": "The vanishing gradient problem (i.e., gradients prematurely becoming extremely small during training, thereby effectively preventing a network from learning) is a long-standing obstacle to the training of deep neural networks using sigmoid activation functions when using the standard back-propagation algorithm. In this paper, we found that an important contributor to the problem is weight initialization. We started by developing a simple theoretical model showing how the expected value of gradients is affected by the mean of the initial weights. We then developed a second theoretical model that allowed us to identify a sufficient condition for the vanishing gradient problem to occur. Using these theories we found that initial back-propagation gradients do not vanish if the mean of the initial weights is negative and inversely proportional to the number of neurons in a layer. Numerous experiments with networks with 10 and 15 hidden layers corroborated the theoretical predictions: If we initialized weights as indicated by the theory, the standard back-propagation algorithm was both highly successful and efficient at training deep neural networks using sigmoid activation functions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002040",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Biology",
      "Chemistry",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Gradient descent",
      "Initialization",
      "Law",
      "Layer (electronics)",
      "Logistic function",
      "Machine learning",
      "Mathematics",
      "Meteorology",
      "Multilayer perceptron",
      "Obstacle",
      "Organic chemistry",
      "Perceptron",
      "Physics",
      "Political science",
      "Programming language",
      "Sigmoid function",
      "Training (meteorology)"
    ],
    "authors": [
      {
        "surname": "Yilmaz",
        "given_name": "Ahmet"
      },
      {
        "surname": "Poli",
        "given_name": "Riccardo"
      }
    ]
  },
  {
    "title": "Cardinality-constrained portfolio selection via two-timescale duplex neurodynamic optimization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.023",
    "abstract": "This paper addresses portfolio selection based on neurodynamic optimization. The portfolio selection problem is formulated as a biconvex optimization problem with a variable weight in the Markowitz risk–return framework. In addition, the cardinality-constrained portfolio selection problem is formulated as a mixed-integer optimization problem and reformulated as a biconvex optimization problem. A two-timescale duplex neurodynamic approach is customized and applied for solving the reformulated portfolio optimization problem. In the two-timescale duplex neurodynamic approach, two recurrent neural networks operating at two timescales are employed for local searches, and their neuronal states are reinitialized upon local convergence using a particle swarm optimization rule to escape from local optima toward global ones. Experimental results on four datasets of world stock markets are elaborated to demonstrate the superior performance of the neurodynamic optimization approach to three baselines in terms of two major risk-adjusted performance criteria and portfolio returns.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002386",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Economics",
      "Financial economics",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Particle swarm optimization",
      "Portfolio",
      "Portfolio optimization",
      "Selection (genetic algorithm)"
    ],
    "authors": [
      {
        "surname": "Leung",
        "given_name": "Man-Fai"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Che",
        "given_name": "Hangjun"
      }
    ]
  },
  {
    "title": "A systematic exploration of reservoir computing for forecasting complex spatiotemporal dynamics",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.06.025",
    "abstract": "A reservoir computer (RC) is a type of recurrent neural network architecture with demonstrated success in the prediction of spatiotemporally chaotic dynamical systems. A further advantage of RC is that it reproduces intrinsic dynamical quantities essential for its incorporation into numerical forecasting routines such as the ensemble Kalman filter—used in numerical weather prediction to compensate for sparse and noisy data. We explore here the architecture and design choices for a “best in class” RC for a number of characteristic dynamical systems. Our analysis points to the importance of large scale parameter optimization. We also note in particular the importance of including input bias in the RC design, which has a significant impact on the forecast skill of the trained RC model. In our tests, the use of a nonlinear readout operator does not affect the forecast time or the stability of the forecast. The effects of the reservoir dimension, spinup time, amount of training data, normalization, noise, and the RC time step are also investigated. Finally, we detail how our investigation leads to optimal design choices for a parallel RC scheme applied to the 40 dimensional spatiotemporally chaotic Lorenz 1996 dynamics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022002404",
    "keywords": [
      "Anthropology",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chaotic",
      "Chemistry",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Dimension (graph theory)",
      "Dynamical systems theory",
      "Ensemble Kalman filter",
      "Extended Kalman filter",
      "Gene",
      "Image (mathematics)",
      "Kalman filter",
      "Lorenz system",
      "Machine learning",
      "Mathematics",
      "Noise (video)",
      "Nonlinear system",
      "Normalization (sociology)",
      "Operator (biology)",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics",
      "Recurrent neural network",
      "Repressor",
      "Reservoir computing",
      "Sociology",
      "Stability (learning theory)",
      "Transcription factor"
    ],
    "authors": [
      {
        "surname": "Platt",
        "given_name": "Jason A."
      },
      {
        "surname": "Penny",
        "given_name": "Stephen G."
      },
      {
        "surname": "Smith",
        "given_name": "Timothy A."
      },
      {
        "surname": "Chen",
        "given_name": "Tse-Chun"
      },
      {
        "surname": "Abarbanel",
        "given_name": "Henry D.I."
      }
    ]
  },
  {
    "title": "Multi-level landmark-guided deep network for face super-resolution",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.026",
    "abstract": "Recent years deep learning-based methods incorporating facial prior knowledge for face super-resolution (FSR) are advancing and have gained impressive performance. However, some important priors such as facial landmarks are not fully exploited in existing methods, leading to noticeable artifacts in the resultant SR face images especially under large magnification. In this paper, we propose a novel multi-level landmark-guided deep network (MLGDN) for FSR. More specifically, to fully exploit the dependencies between low and high resolution images and to reduce network parameters as well as capture more reliable feature representation, we introduce a recursive back-projection network with a particular feedback mechanism for coarse-to-fine FSR. Furthermore, we incorporate an attention fusion module in the front of backbone network to strengthen face components and a feature modulation module to refine features in the middle of backbone network. By this way, the facial landmarks extracted from face images can be fully shared by the modules in different levels, which benefit to produce more faithful facial details. Both quantitative and qualitative performance evaluations on two benchmark databases demonstrate that the proposed MLGDN can achieve more impressive SR results than other state-of-the-art competitors. Code will be available at https://github.com/zhuangcheng31/MLG_Face.git/",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001587",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Face (sociological concept)",
      "Face detection",
      "Face hallucination",
      "Facial recognition system",
      "Feature (linguistics)",
      "Geodesy",
      "Geography",
      "Landmark",
      "Linguistics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Projection (relational algebra)",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Zhuang",
        "given_name": "Cheng"
      },
      {
        "surname": "Li",
        "given_name": "Minqi"
      },
      {
        "surname": "Zhang",
        "given_name": "Kaibing"
      },
      {
        "surname": "Li",
        "given_name": "Zheng"
      },
      {
        "surname": "Lu",
        "given_name": "Jian"
      }
    ]
  },
  {
    "title": "Multistability analysis of delayed recurrent neural networks with a class of piecewise nonlinear activation functions",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.015",
    "abstract": "This paper studies the multistability of delayed recurrent neural networks (DRNNs) with a class of piecewise nonlinear activation functions. The coexistence as well as the stability of multiple equilibrium points (EPs) of DRNNs are proved. With the Brouwer’s fixed point theorem as well as the Lagrange mean value theorem, it is obtained that under some conditions, the n -neuron DRNNs with the proposed activation function can have at least 5 n EPs and 3 n of them are locally stable. Compared with the DRNNs with sigmoidal activation functions, DRNNs with this kind of activation function can have more total EPs and more locally stable EPs. It implies that when designing DRNNs with the proposed activation function to apply in associative memory, it can have an even larger storage capacity. Furthermore, it is obtained that there exists a relationship between the number of the total EPs/stable EPs and the frequency of the sinusoidal function in the proposed activation function. Last, the above obtained results are extended to a more general case. It is shown that, DRNNs with the extended activation function can have ( 2 k + 1 ) n EPs, ( k + 1 ) n of which are locally stable, therein k is closely related to the frequency of the sinusoidal function in the extended activation function. Two simulation examples are given to verify the correctness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001472",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Class (philosophy)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Correctness",
      "Evolutionary biology",
      "Function (biology)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Multistability",
      "Nonlinear system",
      "Physics",
      "Piecewise",
      "Quantum mechanics",
      "Sigmoid function"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Yang"
      },
      {
        "surname": "Wang",
        "given_name": "Zhen"
      },
      {
        "surname": "Ma",
        "given_name": "Qian"
      },
      {
        "surname": "Shen",
        "given_name": "Hao"
      }
    ]
  },
  {
    "title": "Tri-view two-photon microscopic image registration and deblurring with convolutional neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.011",
    "abstract": "Two-photon fluorescence microscopy has enabled the three-dimensional (3D) neural imaging of deep cortical regions. While it can capture the detailed neural structures in the x–y image space, the image quality along the depth direction is lower because of lens blur, which often makes it difficult to identify the neural connectivity. To address this problem, we propose a novel approach for restoring the isotropic image volume by estimating and fusing the intersection regions of the images captured from three orthogonal viewpoints using convolutional neural networks (CNNs). Because convolution on 3D images is computationally complex, the proposed method takes the form of cascaded CNN models consisting of rigid transformation, dense registration, and deblurring networks for more efficient processing. In addition, to enable self-supervised learning, we trained the CNN models with simulated synthetic images by considering the distortions of the microscopic imaging process. Through extensive experiments, the proposed method achieved substantial image quality improvements.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001411",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Deblurring",
      "Gene",
      "Image (mathematics)",
      "Image processing",
      "Image restoration",
      "Pattern recognition (psychology)",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Sehyung"
      },
      {
        "surname": "Kume",
        "given_name": "Hideaki"
      },
      {
        "surname": "Urakubo",
        "given_name": "Hidetoshi"
      },
      {
        "surname": "Kasai",
        "given_name": "Haruo"
      },
      {
        "surname": "Ishii",
        "given_name": "Shin"
      }
    ]
  },
  {
    "title": "Quantum pulse coupled neural network",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.007",
    "abstract": "Artificial neural network has been fully developed in recent years, but as the size of the network grows, the required computing power also grows rapidly. In order to take advantage of the parallel computing of quantum computing to solve the difficulties of large computation in neural network, quantum neural network was proposed. In this paper, based on the pulse coupled neural network (PCNN), quantum pulse coupled neural network (QPCNN) is proposed. In this model, the basic quantum logic gates are utilized to form quantum operation modules, such as quantum full adder, quantum multiplier, and quantum comparator. A quantum image convolution operation applicable to QPCNN is designed employing quantum full adders and neighborhood preparation module. And these modules are employed to complete the operations required for QPCNN. And based on QPCNN, an quantum image segmentation is designed. Meanwhile, the effectiveness of QPCNN is proved by simulation experiments, and the complexity analysis shows that QPCNN has exponential speedup compared with classical PCNN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200140X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Economics",
      "Macroeconomics",
      "Mathematics",
      "Multiplier (economics)",
      "Parallel computing",
      "Physics",
      "Quantum",
      "Quantum algorithm",
      "Quantum computer",
      "Quantum gate",
      "Quantum mechanics",
      "Quantum network",
      "Quantum phase estimation algorithm",
      "Speedup",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Zhaobin"
      },
      {
        "surname": "Xu",
        "given_name": "Minzhe"
      },
      {
        "surname": "Zhang",
        "given_name": "Yaonan"
      }
    ]
  },
  {
    "title": "LAP: Latency-aware automated pruning with dynamic-based filter selection",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.002",
    "abstract": "Model pruning is widely used to compress and accelerate convolutional neural networks (CNNs). Conventional pruning techniques only focus on how to remove more parameters while ensuring model accuracy. This work not only covers the optimization of model accuracy, but also optimizes the model latency during pruning. When there are multiple optimization objectives, the difficulty of algorithm design increases exponentially. So latency sensitivity is proposed to effectively guide the determination of layer sparsity in this paper. We present the latency-aware automated pruning (LAP) framework which leverages the reinforcement learning to automatically determine the layer sparsity. Latency sensitivity is used as a prior knowledge and involved into the exploration loop. Rather than relying on a single reward signal such as validation accuracy or floating-point operations (FLOPs), our agent receives the feedback on the accuracy error and latency sensitivity. We also provide a novel filter selection algorithm to accurately distinguish important filters within a layer based on their dynamic changes. Compared to the state-of-the-art compression policies, our framework demonstrated superior performances for VGGNet, ResNet, and MobileNet on CIFAR-10, ImageNet, and Food-101. Our LAP allowed the inference latency of MobileNet-V1 to achieve approximately 1.64 times speedup on the Titan RTX GPU, with no loss of ImageNet Top-1 accuracy. It significantly improved the pareto optimal curve on the accuracy and latency trade-off.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001745",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Convolutional neural network",
      "FLOPS",
      "Inference",
      "Latency (audio)",
      "Machine learning",
      "Parallel computing",
      "Pruning",
      "Reinforcement learning",
      "Speedup",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Zailong"
      },
      {
        "surname": "Liu",
        "given_name": "Chubo"
      },
      {
        "surname": "Yang",
        "given_name": "Wangdong"
      },
      {
        "surname": "Li",
        "given_name": "Kenli"
      },
      {
        "surname": "Li",
        "given_name": "Keqin"
      }
    ]
  },
  {
    "title": "Risk-based implementation of COLREGs for autonomous surface vehicles using deep reinforcement learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.008",
    "abstract": "Autonomous systems are becoming ubiquitous and gaining momentum within the marine sector. Since the electrification of transport is happening simultaneously, autonomous marine vessels can reduce environmental impact, lower costs, and increase efficiency. Although close monitoring is still required to ensure safety, the ultimate goal is full autonomy. One major milestone is to develop a control system that is versatile enough to handle any weather and encounter that is also robust and reliable. Additionally, the control system must adhere to the International Regulations for Preventing Collisions at Sea (COLREGs) for successful interaction with human sailors. Since the COLREGs were written for the human mind to interpret, they are written in ambiguous prose and therefore not machine-readable or verifiable. Due to these challenges and the wide variety of situations to be tackled, classical model-based approaches prove complicated to implement and computationally heavy. Within machine learning (ML), deep reinforcement learning (DRL) has shown great potential for a wide range of applications. The model-free and self-learning properties of DRL make it a promising candidate for autonomous vessels. In this work, a subset of the COLREGs is incorporated into a DRL-based path following and obstacle avoidance system using collision risk theory. The resulting autonomous agent dynamically interpolates between path following and COLREG-compliant collision avoidance in the training scenario, isolated encounter situations, and AIS-based simulations of real-world scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001435",
    "keywords": [
      "Archaeology",
      "Artificial intelligence",
      "Collision",
      "Collision avoidance",
      "Computer science",
      "Computer security",
      "Engineering",
      "History",
      "Milestone",
      "Operations research",
      "Reinforcement learning"
    ],
    "authors": [
      {
        "surname": "Heiberg",
        "given_name": "Amalie"
      },
      {
        "surname": "Larsen",
        "given_name": "Thomas Nakken"
      },
      {
        "surname": "Meyer",
        "given_name": "Eivind"
      },
      {
        "surname": "Rasheed",
        "given_name": "Adil"
      },
      {
        "surname": "San",
        "given_name": "Omer"
      },
      {
        "surname": "Varagnolo",
        "given_name": "Damiano"
      }
    ]
  },
  {
    "title": "GIU-GANs: Global Information Utilization for Generative Adversarial Networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.014",
    "abstract": "Recently, with the rapid development of artificial intelligence, image generation based on deep learning has advanced significantly. Image generation based on Generative Adversarial Networks (GANs) is a promising study. However, because convolutions are limited by spatial-agnostic and channel-specific, features extracted by conventional GANs based on convolution are constrained. Therefore, GANs cannot capture in-depth details per image. Moreover, straightforwardly stacking of convolutions causes too many parameters and layers in GANs, yielding a high overfitting risk. To overcome the abovementioned limitations, in this study, we propose a GANs called GIU-GANs (where Global Information Utilization: GIU). GIU-GANs leverages a new module called the GIU module, which integrates the squeeze-and-excitation module and involution to focus on global information via the channel attention mechanism, enhancing the generated image quality. Moreover, Batch Normalization (BN) inevitably ignores the representation differences among noise sampled by the generator and thus degrades the generated image quality. Thus, we introduce the representative BN to the GANs’ architecture. The CIFAR-10 and CelebA datasets are employed to demonstrate the effectiveness of the proposed model. Numerous experiments indicate that the proposed model achieves state-of-the-art performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001885",
    "keywords": [],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Yongqi"
      },
      {
        "surname": "Gong",
        "given_name": "Xueyuan"
      },
      {
        "surname": "Tang",
        "given_name": "Jialin"
      },
      {
        "surname": "Su",
        "given_name": "Binghua"
      },
      {
        "surname": "Liu",
        "given_name": "Xiaoxiang"
      },
      {
        "surname": "Zhang",
        "given_name": "Xinyuan"
      }
    ]
  },
  {
    "title": "Replacing pooling functions in Convolutional Neural Networks by linear combinations of increasing functions",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.028",
    "abstract": "Traditionally, Convolutional Neural Networks make use of the maximum or arithmetic mean in order to reduce the features extracted by convolutional layers in a downsampling process known as pooling. However, there is no strong argument to settle upon one of the two functions and, in practice, this selection turns to be problem dependent. Further, both of these options ignore possible dependencies among the data. We believe that a combination of both of these functions, as well as of additional ones which may retain different information, can benefit the feature extraction process. In this work, we replace traditional pooling by several alternative functions. In particular, we consider linear combinations of order statistics and generalizations of the Sugeno integral, extending the latter’s domain to the whole real line and setting the theoretical base for their application. We present an alternative pooling layer based on this strategy which we name “CombPool” layer. We replace the pooling layers of three different architectures of increasing complexity by CombPool layers, and empirically prove over multiple datasets that linear combinations outperform traditional pooling functions in most cases. Further, combinations with either the Sugeno integral or one of its generalizations usually yield the best results, proving a strong candidate to apply in most architectures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001605",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Image (mathematics)",
      "Machine learning",
      "Operating system",
      "Pooling",
      "Process (computing)",
      "Upsampling"
    ],
    "authors": [
      {
        "surname": "Rodriguez-Martinez",
        "given_name": "Iosu"
      },
      {
        "surname": "Lafuente",
        "given_name": "Julio"
      },
      {
        "surname": "Santiago",
        "given_name": "Regivan H.N."
      },
      {
        "surname": "Dimuro",
        "given_name": "Graçaliz Pereira"
      },
      {
        "surname": "Herrera",
        "given_name": "Francisco"
      },
      {
        "surname": "Bustince",
        "given_name": "Humberto"
      }
    ]
  },
  {
    "title": "A dynamical neural network approach for solving stochastic two-player zero-sum games",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.006",
    "abstract": "This paper aims at solving a stochastic two-player zero-sum Nash game problem studied in Singh and Lisser (2019). The main contribution of our paper is that we model this game problem as a dynamical neural network (DNN for short). In this paper, we show that the saddle point of this game problem is the equilibrium point of the DNN model, and we study the globally asymptotically stable of the DNN model. In our numerical experiments, we present the time-continuous feature of the DNN model and compare it with the state-of-the-art convex solvers, i.e., Splitting conic solver (SCS for short) and Cvxopt. Our numerical results show that our DNN method has two advantages in dealing with this game problem. Firstly, the DNN model can converge to a better optimal point. Secondly, the DNN method can solve all problems, even when the problem size is large.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001381",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Conic section",
      "Geometry",
      "Linguistics",
      "Mathematical optimization",
      "Mathematics",
      "Nash equilibrium",
      "Philosophy",
      "Recurrent neural network",
      "Saddle",
      "Saddle point",
      "Solver",
      "Stochastic neural network",
      "Zero (linguistics)",
      "Zero-sum game"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Dawen"
      },
      {
        "surname": "Lisser",
        "given_name": "Abdel"
      }
    ]
  },
  {
    "title": "Event-triggered integral reinforcement learning for nonzero-sum games with asymmetric input saturation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.013",
    "abstract": "In this paper, an event-triggered integral reinforcement learning (IRL) algorithm is developed for the nonzero-sum game problem with asymmetric input saturation. First, for each player, a novel non-quadratic value function with a discount factor is designed, and the coupled Hamilton–Jacobi equation that does not require a complete knowledge of the game is derived by using the idea of IRL. Second, the execution of each player is based on the event-triggered mechanism. In the implementation, an adaptive dynamic programming based learning scheme using a single critic neural network (NN) is developed. Experience replay technique is introduced into the classical gradient descent method to tune the weights of the critic NN. The stability of the system and the elimination of Zeno behavior are proved. Finally, simulation experiments verify the effectiveness of the event-triggered IRL algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001459",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bellman equation",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Dynamic programming",
      "Event (particle physics)",
      "Geometry",
      "Gradient descent",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Reinforcement learning",
      "Stability (learning theory)",
      "Zeno's paradoxes"
    ],
    "authors": [
      {
        "surname": "Xue",
        "given_name": "Shan"
      },
      {
        "surname": "Luo",
        "given_name": "Biao"
      },
      {
        "surname": "Liu",
        "given_name": "Derong"
      },
      {
        "surname": "Gao",
        "given_name": "Ying"
      }
    ]
  },
  {
    "title": "Non-linear perceptual multi-scale network for single image super-resolution",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.020",
    "abstract": "Recently, deep convolutional neural networks (CNNs) have been widely explored in single image super-resolution (SISR) and achieved remarkable progress. However, most of the existing CNN-based SISR networks with a single-stream structure fail to make full use of the multi-scale features of low-resolution (LR) image. While those multi-scale SR models often integrate the information with different receptive fields by means of linear fusion, which leads to the redundant feature extraction and hinders the reconstruction performance of the network. To address both issues, in this paper, we propose a non-linear perceptual multi-scale network (NLPMSNet) to fuse the multi-scale image information in a non-linear manner. Specifically, a novel non-linear perceptual multi-scale module (NLPMSM) is developed to learn more discriminative multi-scale feature correlation by using high-order channel attention mechanism, so as to adaptively extract image features at different scales. Besides, we present a multi-cascade residual nested group (MC-RNG) structure, which uses a global multi-cascade mechanism to organize multiple local residual nested groups (LRNG) to capture sufficient non-local hierarchical context information for reconstructing high-frequency details. LRNG uses a local residual nesting mechanism to stack NLPMSMs, which aims to form a more effective residual learning mechanism and obtain more representative local features. Experimental results show that, compared with the state-of-the-art SISR methods, the proposed NLPMSNet performs well in both quantitative metrics and visual quality with a small number of parameters.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001514",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Convolutional neural network",
      "Discriminative model",
      "Feature (linguistics)",
      "Feature extraction",
      "Linguistics",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Residual",
      "Scale (ratio)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Aiping"
      },
      {
        "surname": "Li",
        "given_name": "Leilei"
      },
      {
        "surname": "Wang",
        "given_name": "Jinbin"
      },
      {
        "surname": "Ji",
        "given_name": "Zhong"
      },
      {
        "surname": "Pang",
        "given_name": "Yanwei"
      },
      {
        "surname": "Cao",
        "given_name": "Jiale"
      },
      {
        "surname": "Wei",
        "given_name": "Zihao"
      }
    ]
  },
  {
    "title": "Attributed graph clustering with multi-task embedding learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.018",
    "abstract": "Attributed graph clustering is challenging as it needs to effectively combine both graph structure and node feature information to accomplish node clustering. Recent studies mostly adopt graph neural networks to learn node embeddings, then apply traditional clustering methods to obtain clusters. However, their node embeddings are not specifically designed for clustering. Moreover, most of their loss functions only rely on either structure or feature information, making both kinds of information not fully retained in node embeddings. In this paper, we propose a multi-task embedding learning method (MTEL) for attributed graph clustering, which constructs two prediction tasks in terms of structure and feature based adjacency matrices respectively. To make the node embeddings helpful for the downstream clustering, in each task, we predict the minimum hop number between each pair of nodes in the adjacency matrix, so that the correlation degrees among nodes can be encoded into node embeddings. To improve the performance of the prediction task, we regularize the model parameters in these two tasks via ℓ 2 , 1 norm, through which the model parameters can be jointly learned. Experiments on real attributed graphs show that MTEL is superior for attributed graph clustering over state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001502",
    "keywords": [
      "Adjacency list",
      "Adjacency matrix",
      "Algorithm",
      "Artificial intelligence",
      "Cluster analysis",
      "Clustering coefficient",
      "Computer science",
      "Correlation clustering",
      "Data mining",
      "Embedding",
      "Engineering",
      "Graph",
      "Graph embedding",
      "Node (physics)",
      "Pattern recognition (psychology)",
      "Structural engineering",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Xiaotong"
      },
      {
        "surname": "Liu",
        "given_name": "Han"
      },
      {
        "surname": "Zhang",
        "given_name": "Xianchao"
      },
      {
        "surname": "Liu",
        "given_name": "Xinyue"
      }
    ]
  },
  {
    "title": "Deep unsupervised feature selection by discarding nuisance and correlated features",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.002",
    "abstract": "Modern datasets often contain large subsets of correlated features and nuisance features, which are not or loosely related to the main underlying structures of the data. Nuisance features can be identified using the Laplacian score criterion, which evaluates the importance of a given feature via its consistency with the Graph Laplacians’ leading eigenvectors. We demonstrate that in the presence of large numbers of nuisance features, the Laplacian must be computed on the subset of selected features rather than on the complete feature set. To do this, we propose a fully differentiable approach for unsupervised feature selection, utilizing the Laplacian score criterion to avoid the selection of nuisance features. We employ an autoencoder architecture to cope with correlated features, trained to reconstruct the data from the subset of selected features. Building on the recently proposed concrete layer that allows controlling for the number of selected features via architectural design, simplifying the optimization process. Experimenting on several real-world datasets, we demonstrate that our proposed approach outperforms similar approaches designed to avoid only correlated or nuisance features, but not both. Several state-of-the-art clustering results are reported. Our code is publically available at https://github.com/jsvir/lscae.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001344",
    "keywords": [
      "Artificial intelligence",
      "Autoencoder",
      "Computer science",
      "Consistency (knowledge bases)",
      "Data mining",
      "Deep learning",
      "Feature (linguistics)",
      "Feature learning",
      "Feature selection",
      "Graph",
      "Laplacian matrix",
      "Law",
      "Linguistics",
      "Machine learning",
      "Nuisance",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Shaham",
        "given_name": "Uri"
      },
      {
        "surname": "Lindenbaum",
        "given_name": "Ofir"
      },
      {
        "surname": "Svirsky",
        "given_name": "Jonathan"
      },
      {
        "surname": "Kluger",
        "given_name": "Yuval"
      }
    ]
  },
  {
    "title": "A neuroscience-inspired spiking neural network for EEG-based auditory spatial attention detection",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.003",
    "abstract": "Recent studies have shown that alpha oscillations (8–13 Hz) enable the decoding of auditory spatial attention. Inspired by sparse coding in cortical neurons, we propose a spiking neural network model for auditory spatial attention detection. The proposed model can extract the patterns of recorded EEG of leftward and rightward attention, independently, and uses them to train the network to detect auditory spatial attention. Specifically, our model is composed of three layers, two of which are Integrate and Fire spiking neurons. We formulate a new learning rule that is based on the firing rate of pre- and post-synaptic neurons in the first and second layers of spiking neurons. The third layer has 10 spiking neurons and the pattern of their firing rate is used in the test phase to decode the auditory spatial attention of a given test sample. Moreover, the effects of using low connectivity rates of the layers and specific range of learning parameters of the learning rule are investigated. The proposed model achieves an average accuracy of 90% with only 10% of EEG signals as training data. This study also provides new insights into the role of sparse coding in both cortical networks subserving cognitive tasks and brain-inspired machine learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001757",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Coding (social sciences)",
      "Computer science",
      "Electroencephalography",
      "Mathematics",
      "Neural coding",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Spiking neural network",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Faghihi",
        "given_name": "Faramarz"
      },
      {
        "surname": "Cai",
        "given_name": "Siqi"
      },
      {
        "surname": "Moustafa",
        "given_name": "Ahmed A."
      }
    ]
  },
  {
    "title": "Sparse factorization of square matrices with application to neural attention modeling",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.014",
    "abstract": "Square matrices appear in many machine learning problems and models. Optimization over a large square matrix is expensive in memory and in time. Therefore an economic approximation is needed. Conventional approximation approaches factorize the square matrix into a number matrices of much lower ranks. However, the low-rank constraint is a performance bottleneck if the approximated matrix is intrinsically high-rank or close to full rank. In this paper, we propose to approximate a large square matrix with a product of sparse full-rank matrices. In the approximation, our method needs only N ( log N ) 2 non-zero numbers for an N × N full matrix. Our new method is especially useful for scalable neural attention modeling. Different from the conventional scaled dot-product attention methods, we train neural networks to map input data to the non-zero entries of the factorizing matrices. The sparse factorization method is tested for various square matrices, and the experimental results demonstrate that our method gives a better approximation when the approximated matrix is sparse and high-rank. As an attention module, our new method defeats Transformer and its several variants for long sequences in synthetic data sets and in the Long Range Arena benchmarks. Our code is publicly available 2 2 https://github.com/RuslanKhalitov/SparseFactorization. .",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001460",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bottleneck",
      "Combinatorics",
      "Composite material",
      "Computer science",
      "Eigenvalues and eigenvectors",
      "Embedded system",
      "Factorization",
      "Gaussian",
      "Geometry",
      "Low-rank approximation",
      "Materials science",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Matrix decomposition",
      "Matrix multiplication",
      "Physics",
      "Pure mathematics",
      "Quantum",
      "Quantum mechanics",
      "Rank (graph theory)",
      "Sparse matrix",
      "Square (algebra)",
      "Square matrix",
      "Symmetric matrix",
      "Tensor (intrinsic definition)"
    ],
    "authors": [
      {
        "surname": "Khalitov",
        "given_name": "Ruslan"
      },
      {
        "surname": "Yu",
        "given_name": "Tong"
      },
      {
        "surname": "Cheng",
        "given_name": "Lei"
      },
      {
        "surname": "Yang",
        "given_name": "Zhirong"
      }
    ]
  },
  {
    "title": "Discovering diverse solutions in deep reinforcement learning by maximizing state–action-based mutual information",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.009",
    "abstract": "Reinforcement learning algorithms are typically limited to learning a single solution for a specified task, even though diverse solutions often exist. Recent studies showed that learning a set of diverse solutions is beneficial because diversity enables robust few-shot adaptation. Although existing methods learn diverse solutions by using the mutual information as unsupervised rewards, such an approach often suffers from the bias of the gradient estimator induced by value function approximation. In this study, we propose a novel method that can learn diverse solutions without suffering the bias problem. In our method, a policy conditioned on a continuous or discrete latent variable is trained by directly maximizing the variational lower bound of the mutual information, instead of using the mutual information as unsupervised rewards as in previous studies. Through extensive experiments on robot locomotion tasks, we demonstrate that the proposed method successfully learns an infinite set of diverse solutions by learning continuous latent variables, which is more challenging than learning a finite number of solutions. Subsequently, we show that our method enables more effective few-shot adaptation compared with existing methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001393",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Estimator",
      "Evolutionary biology",
      "Function (biology)",
      "Latent variable",
      "Machine learning",
      "Mathematics",
      "Mutual information",
      "Optics",
      "Physics",
      "Programming language",
      "Reinforcement learning",
      "Set (abstract data type)",
      "Statistics",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Osa",
        "given_name": "Takayuki"
      },
      {
        "surname": "Tangkaratt",
        "given_name": "Voot"
      },
      {
        "surname": "Sugiyama",
        "given_name": "Masashi"
      }
    ]
  },
  {
    "title": "A new deep learning framework based on blood pressure range constraint for continuous cuffless BP estimation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.017",
    "abstract": "Blood pressure (BP) is known as an indicator of human health status, and regular measurement is helpful for early detection of cardiovascular diseases. Traditional techniques for measuring BP are either invasive or cuff-based and thus are not suitable for continuous measurement. Aiming at the deficiencies in existing studies, a novel cuffless BP estimation framework of Receptive Field Parallel Attention Shrinkage Network (RFPASN) and BP range constraint is proposed. Firstly, RFPASN uses the multi-scale large receptive field convolution module to capture the long-term dynamics in the photoplethysmography (PPG) signal without using long short-term memory (LSTM). On this basis, the features acquired by the parallel mixed domain attention module are used as thresholds, and the soft threshold function is used to screen the input features to enhance the discriminability and robustness of features, which can significantly improve the prediction accuracy of diastolic blood pressure (DBP) and systolic blood pressure (SBP). Finally, in order to prevent large fluctuations in the prediction results of RFPASN, RFPASN based on BP range constraint is proposed to make the prediction results of RFPASN more accurate and reasonable. The performance of the proposed method is demonstrated on a publically available MIMIC-II database. The database contains normal, hypertensive and hypotensive people. We have achieved MAE of 1.63/1.59 (DBP) and 2.26/2.15 (SBP) mmHg for BP on total population of 1562 subjects. A comparative study shows that the proposed algorithm is more promising than the state-of-the-art.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001496",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Blood pressure",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Constraint (computer-aided design)",
      "Convolution (computer science)",
      "Deep learning",
      "Environmental health",
      "Filter (signal processing)",
      "Gene",
      "Geometry",
      "Internal medicine",
      "Mathematics",
      "Medicine",
      "Pattern recognition (psychology)",
      "Photoplethysmogram",
      "Population",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Yongyi"
      },
      {
        "surname": "Zhang",
        "given_name": "Dan"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      },
      {
        "surname": "Deng",
        "given_name": "Chao"
      },
      {
        "surname": "Yin",
        "given_name": "Wutao"
      }
    ]
  },
  {
    "title": "Knowledge-guided multi-task attention network for survival risk prediction using multi-center computed tomography images",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.027",
    "abstract": "Accurate preoperative prediction of overall survival (OS) risk of human cancers based on CT images is greatly significant for personalized treatment. Deep learning methods have been widely explored to improve automated prediction of OS risk. However, the accuracy of OS risk prediction has been limited by prior existing methods. To facilitate capturing survival-related information, we proposed a novel knowledge-guided multi-task network with tailored attention modules for OS risk prediction and prediction of clinical stages simultaneously. The network exploits useful information contained in multiple learning tasks to improve prediction of OS risk. Three multi-center datasets, including two gastric cancer datasets with 459 patients, and a public American lung cancer dataset with 422 patients, are used to evaluate our proposed network. The results show that our proposed network can boost its performance by capturing and sharing information from other predictions of clinical stages. Our method outperforms the state-of-the-art methods with the highest geometrical metric. Furthermore, our method shows better prognostic value with the highest hazard ratio for stratifying patients into high- and low-risk groups. Therefore, our proposed method may be exploited as a potential tool for the improvement of personalized treatment.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001599",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Economics",
      "Image (mathematics)",
      "Machine learning",
      "Management",
      "Metric (unit)",
      "Operations management",
      "Similarity (geometry)",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Liwen"
      },
      {
        "surname": "Zhong",
        "given_name": "Lianzhen"
      },
      {
        "surname": "Li",
        "given_name": "Cong"
      },
      {
        "surname": "Zhang",
        "given_name": "Wenjuan"
      },
      {
        "surname": "Hu",
        "given_name": "Chaoen"
      },
      {
        "surname": "Dong",
        "given_name": "Di"
      },
      {
        "surname": "Liu",
        "given_name": "Zaiyi"
      },
      {
        "surname": "Zhou",
        "given_name": "Junlin"
      },
      {
        "surname": "Tian",
        "given_name": "Jie"
      }
    ]
  },
  {
    "title": "Dynamic image clustering from projected coordinates of deep similarity learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.030",
    "abstract": "Commonly used clustering algorithms typically require user parameters such as the number of clusters to be divided. Density-based algorithms do not have such requirements but are not suitable for high dimensional data. Recent studies have merged the cluster assignment task with deep similarity learning. In this paper, we propose a novel framework to perform dynamic image clustering without prior knowledge of the cluster count. A deep learning model first learns data similarity from scratch, followed by the use of a coordinate learning model to project high dimensional data onto a two-dimensional space. A new clustering algorithm, raster clustering, is proposed to evaluate and classify the projected data. This mechanism can be applied in high dimensional data clustering like image data, and it allows the prediction of unseen data in a consistent way without the need for consolidating with training data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001083",
    "keywords": [
      "Artificial intelligence",
      "CURE data clustering algorithm",
      "Cluster analysis",
      "Clustering high-dimensional data",
      "Computer science",
      "Correlation clustering",
      "Data mining",
      "Data stream clustering",
      "Deep learning",
      "Image (mathematics)",
      "Pattern recognition (psychology)",
      "Raster graphics",
      "Similarity (geometry)"
    ],
    "authors": [
      {
        "surname": "Chang",
        "given_name": "Jui-Hung"
      },
      {
        "surname": "Leung",
        "given_name": "Yin-Chung"
      }
    ]
  },
  {
    "title": "Social impact and governance of AI and neurotechnologies",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.012",
    "abstract": "Advances in artificial intelligence (AI) and brain science are going to have a huge impact on society. While technologies based on those advances can provide enormous social benefits, adoption of new technologies poses various risks. This article first reviews the co-evolution of AI and brain science and the benefits of brain-inspired AI in sustainability, healthcare, and scientific discoveries. We then consider possible risks from those technologies, including intentional abuse, autonomous weapons, cognitive enhancement by brain–computer interfaces, insidious effects of social media, inequity, and enfeeblement. We also discuss practical ways to bring ethical principles into practice. One proposal is to stop giving explicit goals to AI agents and to enable them to keep learning human preferences. Another is to learn from democratic mechanisms that evolved in human society to avoid over-consolidation of power. Finally, we emphasize the importance of open discussions not only by experts, but also including a diverse array of lay opinions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001861",
    "keywords": [
      "Business",
      "Cognitive science",
      "Computer science",
      "Corporate governance",
      "Data science",
      "Engineering",
      "Engineering ethics",
      "Finance",
      "Knowledge management",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Doya",
        "given_name": "Kenji"
      },
      {
        "surname": "Ema",
        "given_name": "Arisa"
      },
      {
        "surname": "Kitano",
        "given_name": "Hiroaki"
      },
      {
        "surname": "Sakagami",
        "given_name": "Masamichi"
      },
      {
        "surname": "Russell",
        "given_name": "Stuart"
      }
    ]
  },
  {
    "title": "Artificial neural networks with conformable transfer function for improving the performance in thermal and environmental processes",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.016",
    "abstract": "This research proposes a novel transfer function based on the hyperbolic tangent and the Khalil conformable exponential function. The non-integer order transfer function offers a suitable neural network configuration because of its ability to adapt. Consequently, this function was introduced into neural network models for three experimental cases: estimating the annular Nusselt number correlation to a helical double-pipe evaporator, the volumetric mass transfer coefficient in an electrochemical reaction, and the thermal efficiency of a solar parabolic trough collector. We found the new transfer function parameters during the training step of the neural networks. Therefore, weights and biases depend on them. We assessed the models applied to the three cases using the determination coefficient, adjusted determination coefficient, and the slope-intercept test. In addition, the MSE for the training set and the whole database were computed to show that there is no overfitting problem. The best-assessed models showed a relationship of 99%, 97%, and 95% with the experimental data for the first, second, and third cases. This novel proposal made reducing the number of neurons in the hidden layer feasible. Therefore, we show a neural network with a conformable transfer function (ANN-CTF) that learns well enough with less available information from the experimental database during its training.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001484",
    "keywords": [
      "Activation function",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Conformable matrix",
      "Electrical engineering",
      "Engineering",
      "Hyperbolic function",
      "Materials science",
      "Mathematical analysis",
      "Mathematics",
      "Overfitting",
      "Transfer function"
    ],
    "authors": [
      {
        "surname": "Solís-Pérez",
        "given_name": "J.E."
      },
      {
        "surname": "Hernández",
        "given_name": "J.A."
      },
      {
        "surname": "Parrales",
        "given_name": "A."
      },
      {
        "surname": "Gómez-Aguilar",
        "given_name": "J.F."
      },
      {
        "surname": "Huicochea",
        "given_name": "A."
      }
    ]
  },
  {
    "title": "Organization of a Latent Space structure in VAE/GAN trained by navigation data",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.012",
    "abstract": "We present a novel artificial cognitive mapping system using generative deep neural networks, called variational autoencoder/generative adversarial network (VAE/GAN), which can map input images to latent vectors and generate temporal sequences internally. The results show that the distance of the predicted image is reflected in the distance of the corresponding latent vector after training. This indicates that the latent space is self-organized to reflect the proximity structure of the dataset and may provide a mechanism through which many aspects of cognition are spatially represented. The present study allows the network to internally generate temporal sequences that are analogous to the hippocampal replay/pre-play ability, where VAE produces only near-accurate replays of past experiences, but by introducing GANs, the generated sequences are coupled with instability and novelty.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001447",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Biology",
      "Cognition",
      "Cognitive map",
      "Computer science",
      "Generative grammar",
      "Generative model",
      "Neuroscience",
      "Novelty",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Space (punctuation)",
      "Theology"
    ],
    "authors": [
      {
        "surname": "Kojima",
        "given_name": "Hiroki"
      },
      {
        "surname": "Ikegami",
        "given_name": "Takashi"
      }
    ]
  },
  {
    "title": "A multivariate adaptive gradient algorithm with reduced tuning efforts",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.016",
    "abstract": "Large neural networks usually perform well for executing machine learning tasks. However, models that achieve state-of-the-art performance involve arbitrarily large number of parameters and therefore their training is very expensive. It is thus desired to implement methods with small per-iteration costs, fast convergence rates, and reduced tuning. This paper proposes a multivariate adaptive gradient descent method that meets the above attributes. The proposed method updates every element of the model parameters separately in a computationally efficient manner using an adaptive vector-form learning rate, resulting in low per-iteration cost. The adaptive learning rate computes the absolute difference of current and previous model parameters over the difference in subgradients of current and previous state estimates. In the deterministic setting, we show that the cost function value converges at a linear rate for smooth and strongly convex cost functions. Whereas in both the deterministic and stochastic setting, we show that the gradient converges in expectation at the order of O ( 1 / k ) for a non-convex cost function with Lipschitz continuous gradient. In addition, we show that after T iterates, the cost function of the last iterate scales as O ( log ( T ) / T ) for non-smooth strongly convex cost functions. Effectiveness of the proposed method is validated on convex functions, smooth non-convex function, non-smooth convex function, and four image classification data sets, whilst showing that its execution requires hardly any tuning unlike existing popular optimizers that entail relatively large tuning efforts. Our empirical results show that our proposed algorithm provides the best overall performance when comparing it to tuned state-of-the-art optimizers.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001903",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer security",
      "Convergence (economics)",
      "Convex function",
      "Convex optimization",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Geometry",
      "Gradient descent",
      "Iterated function",
      "Key (lock)",
      "Lipschitz continuity",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Rate of convergence",
      "Regular polygon",
      "Stochastic gradient descent"
    ],
    "authors": [
      {
        "surname": "Saab",
        "given_name": "Samer"
      },
      {
        "surname": "Saab",
        "given_name": "Khaled"
      },
      {
        "surname": "Phoha",
        "given_name": "Shashi"
      },
      {
        "surname": "Zhu",
        "given_name": "Minghui"
      },
      {
        "surname": "Ray",
        "given_name": "Asok"
      }
    ]
  },
  {
    "title": "Multivariate time series forecasting method based on nonlinear spiking neural P systems and non-subsampled shearlet transform",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.030",
    "abstract": "Multivariate time series forecasting remains a challenging task because of its nonlinear, non-stationary, high-dimensional, and spatial–temporal characteristics, along with the dependence between variables. To address this limitation, we propose a novel method for multivariate time series forecasting based on nonlinear spiking neural P (NSNP) systems and non-subsampled shearlet transform (NSST). A multivariate time series is first converted into the NSST domain, and then NSNP systems are automatically constructed, trained, and predicted in the NSST domain. Because NSNP systems are used as nonlinear prediction models and work in the NSST domain, the proposed prediction method is essentially a multiscale transform (MST)–based prediction method. Therefore, the proposed prediction method can process nonlinear and non-stationary time series, and the dependence between variables can be characterized by the multiresolution features of the NSST transform. Five real-life multivariate time series were used to compare the proposed prediction method with five state-of-the-art and 28 baseline prediction methods. The comparison results demonstrate the effectiveness of the proposed method for multivariate time-series forecasting.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001708",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Computer vision",
      "Domain (mathematical analysis)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Multivariate statistics",
      "Nonlinear system",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Series (stratigraphy)",
      "Time domain",
      "Time series"
    ],
    "authors": [
      {
        "surname": "Long",
        "given_name": "Lifan"
      },
      {
        "surname": "Liu",
        "given_name": "Qian"
      },
      {
        "surname": "Peng",
        "given_name": "Hong"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Yang",
        "given_name": "Qian"
      }
    ]
  },
  {
    "title": "Robust kernel principal component analysis with optimal mean",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.005",
    "abstract": "The kernel principal component analysis (KPCA) serves as an efficient approach for dimensionality reduction. However, the KPCA method is sensitive to the outliers since the large square errors tend to dominate the loss of KPCA. To strengthen the robustness of KPCA method, we propose a novel robust kernel principal component analysis with optimal mean (RKPCA-OM) method. RKPCA-OM not only possesses stronger robustness for outliers than the conventional KPCA method, but also can eliminate the optimal mean automatically. What is more, the theoretical proof proves the convergence of the algorithm to guarantee that the optimal subspaces and means are obtained. Lastly, exhaustive experimental results verify the superiority of our method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001770",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Combinatorics",
      "Computer science",
      "Curse of dimensionality",
      "Dimensionality reduction",
      "Gene",
      "Kernel (algebra)",
      "Kernel method",
      "Kernel principal component analysis",
      "Mathematics",
      "Outlier",
      "Pattern recognition (psychology)",
      "Principal component analysis",
      "Robust principal component analysis",
      "Robustness (evolution)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Pei"
      },
      {
        "surname": "Zhang",
        "given_name": "Wenlin"
      },
      {
        "surname": "Lu",
        "given_name": "Chengjun"
      },
      {
        "surname": "Zhang",
        "given_name": "Rui"
      },
      {
        "surname": "Li",
        "given_name": "Xuelong"
      }
    ]
  },
  {
    "title": "Social impact and governance of AI and neurotechnologies",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.012",
    "abstract": "Advances in artificial intelligence (AI) and brain science are going to have a huge impact on society. While technologies based on those advances can provide enormous social benefits, adoption of new technologies poses various risks. This article first reviews the co-evolution of AI and brain science and the benefits of brain-inspired AI in sustainability, healthcare, and scientific discoveries. We then consider possible risks from those technologies, including intentional abuse, autonomous weapons, cognitive enhancement by brain–computer interfaces, insidious effects of social media, inequity, and enfeeblement. We also discuss practical ways to bring ethical principles into practice. One proposal is to stop giving explicit goals to AI agents and to enable them to keep learning human preferences. Another is to learn from democratic mechanisms that evolved in human society to avoid over-consolidation of power. Finally, we emphasize the importance of open discussions not only by experts, but also including a diverse array of lay opinions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001861",
    "keywords": [
      "Business",
      "Cognitive science",
      "Computer science",
      "Corporate governance",
      "Data science",
      "Engineering",
      "Engineering ethics",
      "Finance",
      "Knowledge management",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Doya",
        "given_name": "Kenji"
      },
      {
        "surname": "Ema",
        "given_name": "Arisa"
      },
      {
        "surname": "Kitano",
        "given_name": "Hiroaki"
      },
      {
        "surname": "Sakagami",
        "given_name": "Masamichi"
      },
      {
        "surname": "Russell",
        "given_name": "Stuart"
      }
    ]
  },
  {
    "title": "A manifold learning approach for gesture recognition from micro-Doppler radar measurements",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.024",
    "abstract": "A recent paper (Mhaskar (2020)) introduces a straightforward and simple kernel based approximation for manifold learning that does not require the knowledge of anything about the manifold, except for its dimension. In this paper, we examine how the pointwise error in approximation using least squares optimization based on similarly localized kernels depends upon the data characteristics and deteriorates as one goes away from the training data. The theory is presented with an abstract localized kernel, which can utilize any prior knowledge about the data being located on an unknown sub-manifold of a known manifold. We demonstrate the performance of our approach using a publicly available micro-Doppler data set, and investigate the use of different preprocessing measures, kernels, and manifold dimensions. Specifically, it is shown that the localized kernel introduced in the above mentioned paper when used with PCA components leads to a near-competitive performance to deep neural networks, and offers significant improvements in training speed and memory requirements. To demonstrate the fact that our methods are agnostic to the domain knowledge, we examine the classification problem in a simple video data set.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001563",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Dimension (graph theory)",
      "Dimensionality reduction",
      "Discrete mathematics",
      "Engineering",
      "Epistemology",
      "Kernel (algebra)",
      "Kernel method",
      "Machine learning",
      "Manifold (fluid mechanics)",
      "Manifold alignment",
      "Mathematical analysis",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Pointwise",
      "Preprocessor",
      "Pure mathematics",
      "Simple (philosophy)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Mason",
        "given_name": "E.S."
      },
      {
        "surname": "Mhaskar",
        "given_name": "H.N."
      },
      {
        "surname": "Guo",
        "given_name": "Adam"
      }
    ]
  },
  {
    "title": "Branching time active inference: Empirical study and complexity class analysis",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.010",
    "abstract": "Active inference is a state-of-the-art framework for modelling the brain that explains a wide range of mechanisms such as habit formation, dopaminergic discharge and curiosity. However, recent implementations suffer from an exponential (space and time) complexity class when computing the prior over all the possible policies up to the time horizon. Fountas et al. (2020) used Monte Carlo tree search to address this problem, leading to very good results in two different tasks. Additionally, Champion et al. (2021a) proposed a tree search approach based on (temporal) structure learning. This was enabled by the development of a variational message passing approach to active inference (Champion, Bowman, Grześ, 2021), which enables compositional construction of Bayesian networks for active inference. However, this message passing tree search approach, which we call branching-time active inference (BTAI), has never been tested empirically. In this paper, we present an experimental study of the approach (Champion, Grześ, Bowman, 2021) in the context of a maze solving agent. In this context, we show that both improved prior preferences and deeper search help mitigate the vulnerability to local minima. Then, we compare BTAI to standard active inference (AcI) on a graph navigation task. We show that for small graphs, both BTAI and AcI successfully solve the task. For larger graphs, AcI exhibits an exponential (space) complexity class, making the approach intractable. However, BTAI explores the space of policies more efficiently, successfully scaling to larger graphs. Then, BTAI was compared to the POMCP algorithm (Silver and Veness, 2010) on the frozen lake environment. The experiments suggest that BTAI and the POMCP algorithm accumulate a similar amount of reward. Also, we describe when BTAI receives more rewards than the POMCP agent, and when the opposite is true. Finally, we compared BTAI to the approach of Fountas et al. (2020) on the dSprites dataset, and we discussed the pros and cons of each approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001824",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Inference",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Theoretical computer science",
      "Tree (set theory)",
      "Tree traversal"
    ],
    "authors": [
      {
        "surname": "Champion",
        "given_name": "Théophile"
      },
      {
        "surname": "Bowman",
        "given_name": "Howard"
      },
      {
        "surname": "Grześ",
        "given_name": "Marek"
      }
    ]
  },
  {
    "title": "Visual context learning based on textual knowledge for image–text retrieval",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.008",
    "abstract": "Image–text bidirectional retrieval is a significant task within cross-modal learning field. The main issue lies on the jointly embedding learning and accurately measuring image–text matching score. Most prior works make use of either intra-modality methods performing within two separate modalities or inter-modality ones combining two modalities tightly. However, intra-modality methods remain ambiguous when learning visual context due to the existence of redundant messages. And inter-modality methods increase the complexity of retrieval because of unifying two modalities closely when learning modal features. In this research, we propose an eclectic Visual Context Learning based on Textual knowledge Network (VCLTN), which transfers textual knowledge to visual modality for context learning and decreases the discrepancy of information capacity between two modalities. Specifically, VCLTN merges label semantics into corresponding regional features and employs those labels as intermediaries between images and texts for better modal alignment. Contextual knowledge of those labels learned within textual modality is utilized to guide the visual context learning. Besides, considering the homogeneity within each modality, global features are merged into regional features for assisting in the context learning. In order to alleviate the imbalance of information capacity between images and texts, entities together with relations inside the given caption are extracted and an auxiliary caption is sampled for attaching supplementary messages to textual modality. Experiments performed on Flickr30K and MS-COCO reveal that our model VCLTN achieves best results compared with the state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001800",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Information retrieval",
      "Matching (statistics)",
      "Mathematics",
      "Modalities",
      "Modality (human–computer interaction)",
      "Natural language processing",
      "Paleontology",
      "Social science",
      "Sociology",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Qin",
        "given_name": "Yuzhuo"
      },
      {
        "surname": "Gu",
        "given_name": "Xiaodong"
      },
      {
        "surname": "Tan",
        "given_name": "Zhenshan"
      }
    ]
  },
  {
    "title": "Embedding graphs on Grassmann manifold",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.001",
    "abstract": "Learning efficient graph representation is the key to favorably addressing downstream tasks on graphs, such as node or graph property prediction. Given the non-Euclidean structural property of graphs, preserving the original graph data’s similarity relationship in the embedded space needs specific tools and a similarity metric. This paper develops a new graph representation learning scheme, namely Egg, which embeds approximated second-order graph characteristics into a Grassmann manifold. The proposed strategy leverages graph convolutions to learn hidden representations of the corresponding subspace of the graph, which is then mapped to a Grassmann point of a low dimensional manifold through truncated singular value decomposition (SVD). The established graph embedding approximates denoised correlationship of node attributes, as implemented in the form of a symmetric matrix space for Euclidean calculation. The effectiveness of Egg is demonstrated using both clustering and classification tasks at the node level and graph level. It outperforms baseline models on various benchmarks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001733",
    "keywords": [
      "Adjacency matrix",
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Embedding",
      "Euclidean space",
      "Graph",
      "Graph embedding",
      "Graph property",
      "Line graph",
      "Mathematics",
      "Theoretical computer science",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Bingxin"
      },
      {
        "surname": "Zheng",
        "given_name": "Xuebin"
      },
      {
        "surname": "Wang",
        "given_name": "Yu Guang"
      },
      {
        "surname": "Li",
        "given_name": "Ming"
      },
      {
        "surname": "Gao",
        "given_name": "Junbin"
      }
    ]
  },
  {
    "title": "Context-aware dynamic neural computational models for accurate Poly(A) signal prediction",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.025",
    "abstract": "Accurately predicting Polyadenylation (Poly(A)) signals isthe key to understand the mechanism of translation regulation and mRNA metabolism. However, existing computational algorithms fail to work well for predicting Poly(A) signals due to the vanishing gradient problem when simply increasing the number of layers. In this work, we devise a spatiotemporal context-aware neural model called ACNet for Poly(A) signal prediction based on co-occurrence embedding. Specifically, genomic sequences of Poly(A) signals are first split into k-mer sequences, and k-mer embeddings are pre-trained based on the co-occurrence matrix information; Then, gated residual networks are devised to fully extract spatial information, which has an excellent ability to control the information flow and ease the problem of vanishing gradients. The gated mechanism generates channel weights by a dilated convolution and aggregates local features by identity connections which are obtained by multi-scale dilated convolutions. Experimental results indicate that our ACNet model outperforms the state-of-the-art prediction methods on various Poly(A) signal data, and an ablation study shows the effectiveness of the design strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001575",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Context (archaeology)",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Embedding",
      "Gene",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Polyadenylation",
      "Programming language",
      "RNA",
      "SIGNAL (programming language)"
    ],
    "authors": [
      {
        "surname": "Guo",
        "given_name": "Yanbu"
      },
      {
        "surname": "Li",
        "given_name": "Chaoyang"
      },
      {
        "surname": "Zhou",
        "given_name": "Dongming"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      },
      {
        "surname": "Liang",
        "given_name": "Hui"
      }
    ]
  },
  {
    "title": "Sediment Prediction in the Great Barrier Reef using Vision Transformer with finite element analysis",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.022",
    "abstract": "Suspended sediment is a significant threat to the Great Barrier Reef (GBR) ecosystem. This catchment pollutant stems primarily from terrestrial soil erosion. Bulk masses of sediments have potential to propagate from river plumes into the mid-shelf and outer-shelf regions. Existing sediment forecasting methods suffer from the problem of low-resolution predictions, making them unsuitable for wide area coverage. In this paper, a novel sediment distribution prediction model is proposed to augment existing water quality management programs for the GBR. This model is based on the state-of-the-art Transformer network in conjunction with the well-known finite element analysis. For model training, the emerging physics-informed neural network is employed to incorporate both simulated and measured sediment data. Our proposed Finite Element Transformer (FE-Transformer) model offers accurate predictions of sediment across the entire GBR. It provides unblurred outputs, which cannot be achieved with previous next-frame prediction models. This paves a way for accurate forecasting of sediment, which in turn may lead to improved water quality management for the GBR.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200154X",
    "keywords": [
      "Biology",
      "Ecology",
      "Electrical engineering",
      "Engineering",
      "Environmental science",
      "Finite element method",
      "Geology",
      "Geomorphology",
      "Geotechnical engineering",
      "Hydrology (agriculture)",
      "Sediment",
      "Structural engineering",
      "Transformer",
      "Voltage",
      "Water quality"
    ],
    "authors": [
      {
        "surname": "Jahanbakht",
        "given_name": "Mohammad"
      },
      {
        "surname": "Xiang",
        "given_name": "Wei"
      },
      {
        "surname": "Azghadi",
        "given_name": "Mostafa Rahimi"
      }
    ]
  },
  {
    "title": "DynamicNet: A time-variant ODE network for multi-step wind speed prediction",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.004",
    "abstract": "Wind power is a new type of green energy. Though it is economical to access and gather such energy, effectively matching the energy with consumers’ demand is difficult, because of the fluctuate, intermittent and chaotic nature of wind speed. Hence, multi-step wind speed prediction becomes an important research topic. In this paper, we propose a novel deep learning method, DyanmicNet, for the problem. DynamicNet follows an encoder–decoder framework. To capture the fluctuate, intermittent and chaotic nature of wind speed, it leverages a time-variant structure to build the decoder, which is different from conventional encoder–decoder methods. In addition, a new neural block (ST-GRU-ODE) is developed, which can model the wind speed in a continuous manner by using the neural ordinary differential equation (ODE). To enhance the prediction performance, a multi-step training procedure is also put forward. Comprehensive experiments have been conducted on two real-world datasets, where wind speed is recorded in the form of two orthogonal components namely U-Wind and V-Wind. Each component can be illustrated as wind speed images. Experimental results demonstrate the effectiveness and superiority of the proposed method over state-of-the-art techniques.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001356",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Block (permutation group theory)",
      "Chaotic",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differential equation",
      "Electrical engineering",
      "Encoder",
      "Energy (signal processing)",
      "Engineering",
      "Geometry",
      "Matching (statistics)",
      "Mathematical analysis",
      "Mathematics",
      "Meteorology",
      "Ode",
      "Operating system",
      "Ordinary differential equation",
      "Physics",
      "Statistics",
      "Wind power",
      "Wind speed"
    ],
    "authors": [
      {
        "surname": "Ye",
        "given_name": "Rui"
      },
      {
        "surname": "Li",
        "given_name": "Xutao"
      },
      {
        "surname": "Ye",
        "given_name": "Yunming"
      },
      {
        "surname": "Zhang",
        "given_name": "Baoquan"
      }
    ]
  },
  {
    "title": "Semantic consistency learning on manifold for source data-free unsupervised domain adaptation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.015",
    "abstract": "Recently, source data-free unsupervised domain adaptation (SFUDA) attracts increasing attention. Current work shows that the geometry of the target data is helpful to solving this challenging problem. However, these methods define the geometric structures in Euclidean space. The geometry cannot completely draw the semantic relationship between the target data distributed on a manifold. This article proposed a new SFUDA method, semantic consistency learning on manifold (SCLM), to address this problem. Firstly, we generated pseudo-labels for the target data using a new clustering method, EntMomClustering, that enhanced k-means clustering by fusing the entropy momentum. Secondly, we constructed semantic neighbor topology (SNT) to capture complete geometric information on the manifold. Specifically, in SNT, the global neighbor was detected by a developed collaborative representation-based manifold projection, while the local neighbors were obtained by similarity comparison. Thirdly, we performed a semantic consistency learning on SNT to drive a new kind of deep clustering where SNT was taken as the basic clustering unit. To ensure SNT move as entirety, in the developed objective, the entropy regulator was constructed based on a semantic mixture fused on SNT, while the self-supervised regulator encouraged similar classification on SNT. Experiments on three benchmark datasets show that our method achieves state-of-the-art results. The code is available on https://github.com/tntek/SCLM.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001897",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Computer science",
      "Consistency (knowledge bases)",
      "Dimensionality reduction",
      "Engineering",
      "Entropy (arrow of time)",
      "Manifold (fluid mechanics)",
      "Manifold alignment",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Tang",
        "given_name": "Song"
      },
      {
        "surname": "Zou",
        "given_name": "Yan"
      },
      {
        "surname": "Song",
        "given_name": "Zihao"
      },
      {
        "surname": "Lyu",
        "given_name": "Jianzhi"
      },
      {
        "surname": "Chen",
        "given_name": "Lijuan"
      },
      {
        "surname": "Ye",
        "given_name": "Mao"
      },
      {
        "surname": "Zhong",
        "given_name": "Shouming"
      },
      {
        "surname": "Zhang",
        "given_name": "Jianwei"
      }
    ]
  },
  {
    "title": "Deep networks may capture biological behavior for shallow, but not deep, empirical characterizations",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.023",
    "abstract": "We assess whether deep convolutional networks (DCN) can account for a most fundamental property of human vision: detection/discrimination of elementary image elements (bars) at different contrast levels. The human visual process can be characterized to varying degrees of “depth,” ranging from percentage of correct detection to detailed tuning and operating characteristics of the underlying perceptual mechanism. We challenge deep networks with the same stimuli/tasks used with human observers and apply equivalent characterization of the stimulus–response coupling. In general, we find that popular DCN architectures do not account for signature properties of the human process. For shallow depth of characterization, some variants of network-architecture/training-protocol produce human-like trends; however, more articulate empirical descriptors expose glaring discrepancies. Networks can be coaxed into learning those richer descriptors by shadowing a human surrogate in the form of a tailored circuit perturbed by unstructured input, thus ruling out the possibility that human–model misalignment in standard protocols may be attributable to insufficient representational power. These results urge caution in assessing whether neural networks do or do not capture human behavior: ultimately, our ability to assess “success” in this area can only be as good as afforded by the depth of behavioral characterization against which the network is evaluated. We propose a novel set of metrics/protocols that impose stringent constraints on the evaluation of DCN behavior as an adequate approximation to biological processes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001551",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Machine learning"
    ],
    "authors": [
      {
        "surname": "Neri",
        "given_name": "Peter"
      }
    ]
  },
  {
    "title": "Set-membership filtering for complex networks with constraint communication channels",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.009",
    "abstract": "The set-membership filtering is studied for a class of multi-rate sampling complex networks with communication capacity constraint. For reducing communication load, the weighted try-once-discard scheduling protocol is utilized to transmit the most needed measurement. To improve the filtering performance, a novel mixed compensation method is proposed to obtain a compensatory measurement that is closer to the actual value. Accordingly, a mixed compensation dependent filter is designed, and a filtering error system is obtained. Sufficient conditions are established to ensure that the filtering error system satisfies P T k -dependent constraint. Then, a new algorithm is designed to obtain the optimized ellipsoid by minimizing the constraint matrix. Finally, an illustrative example is given to demonstrate the validity of the developed filter.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001812",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Astronomy",
      "Class (philosophy)",
      "Compensation (psychology)",
      "Computer science",
      "Computer vision",
      "Constraint (computer-aided design)",
      "Control (management)",
      "Control theory (sociology)",
      "Ellipsoid",
      "Filter (signal processing)",
      "Geometry",
      "Mathematical optimization",
      "Mathematics",
      "Physics",
      "Programming language",
      "Psychoanalysis",
      "Psychology",
      "Scheduling (production processes)",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Chang"
      },
      {
        "surname": "Yang",
        "given_name": "Lixin"
      },
      {
        "surname": "Tao",
        "given_name": "Jie"
      },
      {
        "surname": "Xu",
        "given_name": "Yong"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Corrigendum to “Event-centric Multi-modal Fusion Method for Dense Video Captioning” [Neural Networks 146 (2022) 120–129]",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.011",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200185X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Astrophysics",
      "Chemistry",
      "Closed captioning",
      "Computer science",
      "Deep neural networks",
      "Event (particle physics)",
      "Image (mathematics)",
      "Modal",
      "Physics",
      "Polymer chemistry"
    ],
    "authors": [
      {
        "surname": "Chang",
        "given_name": "Zhi"
      },
      {
        "surname": "Zhao",
        "given_name": "Dexin"
      },
      {
        "surname": "Chen",
        "given_name": "Huilin"
      },
      {
        "surname": "Li",
        "given_name": "Jingdan"
      },
      {
        "surname": "Liu",
        "given_name": "Pengfei"
      }
    ]
  },
  {
    "title": "Context meta-reinforcement learning via neuromodulation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.003",
    "abstract": "Meta-reinforcement learning (meta-RL) algorithms enable agents to adapt quickly to tasks from few samples in dynamic environments. Such a feat is achieved through dynamic representations in an agent’s policy network (obtained via reasoning about task context, model parameter updates, or both). However, obtaining rich dynamic representations for fast adaptation beyond simple benchmark problems is challenging due to the burden placed on the policy network to accommodate different policies. This paper addresses the challenge by introducing neuromodulation as a modular component to augment a standard policy network that regulates neuronal activities in order to produce efficient dynamic representations for task adaptation. The proposed extension to the policy network is evaluated across multiple discrete and continuous control environments of increasing complexity. To prove the generality and benefits of the extension in meta-RL, the neuromodulated network was applied to two state-of-the-art meta-RL algorithms (CAVIA and PEARL). The result demonstrates that meta-RL augmented with neuromodulation produces significantly better result and richer dynamic representations in comparison to the baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001368",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Computer science",
      "Construct (python library)",
      "Context (archaeology)",
      "Economics",
      "Generality",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Management",
      "Meta learning (computer science)",
      "Modular design",
      "Neuromodulation",
      "Neuroscience",
      "Operating system",
      "Optics",
      "Paleontology",
      "Physics",
      "Programming language",
      "Psychology",
      "Psychotherapist",
      "Reinforcement learning",
      "Stimulation",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Ben-Iwhiwhu",
        "given_name": "Eseoghene"
      },
      {
        "surname": "Dick",
        "given_name": "Jeffery"
      },
      {
        "surname": "Ketz",
        "given_name": "Nicholas A."
      },
      {
        "surname": "Pilly",
        "given_name": "Praveen K."
      },
      {
        "surname": "Soltoggio",
        "given_name": "Andrea"
      }
    ]
  },
  {
    "title": "Weighted Incremental–Decremental Support Vector Machines for concept drift with shifting window",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.018",
    "abstract": "We study the problem of learning the data samples’ distribution as it changes in time. This change, known as concept drift, complicates the task of training a model, as the predictions become less and less accurate. It is known that Support Vector Machines (SVMs) can learn weighted input instances and that they can also be trained online (incremental–decremental learning). Combining these two SVM properties, the open problem is to define an online SVM concept drift model with shifting weighted window. The classic SVM model should be retrained from scratch after each window shift. We introduce the Weighted Incremental–Decremental SVM (WIDSVM), a generalization of the incremental–decremental SVM for shifting windows. WIDSVM is capable of learning from data streams with concept drift, using the weighted shifting window technique. The soft margin constrained optimization problem imposed on the shifting window is reduced to an incremental–decremental SVM. At each window shift, we determine the exact conditions for vector migration during the incremental–decremental process. We perform experiments on artificial and real-world concept drift datasets; they show that the classification accuracy of WIDSVM significantly improves compared to a SVM with no shifting window. The WIDSVM training phase is fast, since it does not retrain from scratch after each window shift.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001927",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Concept drift",
      "Data stream mining",
      "Economics",
      "Generalization",
      "Incremental learning",
      "Machine learning",
      "Management",
      "Margin (machine learning)",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Scratch",
      "Support vector machine",
      "Task (project management)",
      "Window (computing)"
    ],
    "authors": [
      {
        "surname": "Gâlmeanu",
        "given_name": "Honorius"
      },
      {
        "surname": "Andonie",
        "given_name": "Răzvan"
      }
    ]
  },
  {
    "title": "Spatiotemporal CNN with Pyramid Bottleneck Blocks: Application to eye blinking detection",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.010",
    "abstract": "Eye blink detection is a challenging problem that many researchers are working on because it has the potential to solve many facial analysis tasks, such as face anti-spoofing, driver drowsiness detection, and some health disorders. There have been few attempts to detect blinking in the wild scenario, while most of the work has been done under controlled conditions. Moreover, current learning approaches are designed to process sequences that contain only a single blink ignoring the case of the presence of multiple eye blinks. In this work, we propose a fast framework for eye blink detection and eye blink verification that can effectively extract multiple blinks from image sequences considering several challenges such as lighting changes, variety of poses, and change in appearance. The proposed framework employs fast landmarks detector to extract multiple facial key points including the ones that identify the eye regions. Then, an SVD-based method is proposed to extract the potential eye blinks in a moving time window that is updated with new images every second. Finally, the detected blink candidates are verified using a 2D Pyramidal Bottleneck Block Network (PBBN). We also propose an alternative approach that uses a sequence of frames instead of an image as input and employs a continuous 3D PBBN that follows most of the state-of-the-art approaches schemes. Experimental results show the better performance of the proposed approach compared to the state-of-the-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001423",
    "keywords": [
      "Artificial intelligence",
      "Block (permutation group theory)",
      "Bottleneck",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Embedded system",
      "Face (sociological concept)",
      "Geometry",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Sliding window protocol",
      "Social science",
      "Sociology",
      "Spoofing attack",
      "Window (computing)"
    ],
    "authors": [
      {
        "surname": "Bekhouche",
        "given_name": "S.E."
      },
      {
        "surname": "Kajo",
        "given_name": "I."
      },
      {
        "surname": "Ruichek",
        "given_name": "Y."
      },
      {
        "surname": "Dornaika",
        "given_name": "F."
      }
    ]
  },
  {
    "title": "ExSpliNet: An interpretable and expressive spline-based neural network",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.029",
    "abstract": "In this paper we present ExSpliNet, an interpretable and expressive neural network model. The model combines ideas of Kolmogorov neural networks, ensembles of probabilistic trees, and multivariate B-spline representations. We give a probabilistic interpretation of the model and show its universal approximation properties. We also discuss how it can be efficiently encoded by exploiting B-spline properties. Finally, we test the effectiveness of the proposed model on synthetic approximation problems and classical machine learning benchmark datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001617",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Computer science",
      "Engineering",
      "Geodesy",
      "Geography",
      "Interpretation (philosophy)",
      "Machine learning",
      "Multivariate statistics",
      "Probabilistic logic",
      "Programming language",
      "Recurrent neural network",
      "Spline (mechanical)",
      "Structural engineering"
    ],
    "authors": [
      {
        "surname": "Fakhoury",
        "given_name": "Daniele"
      },
      {
        "surname": "Fakhoury",
        "given_name": "Emanuele"
      },
      {
        "surname": "Speleers",
        "given_name": "Hendrik"
      }
    ]
  },
  {
    "title": "Sampled-data synchronization of complex network based on periodic self-triggered intermittent control and its application to image encryption",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.004",
    "abstract": "The aim of this paper is to investigate exponential synchronization issue of time-varying multi-weights network with time delays (TMNTD) via periodic self-triggered intermittent sampled-data control. In particular, it is the first time to combine periodic self-triggered control and intermittent control with sampled-data, which has broader application prospects. Therein, self-triggered scheme is periodic judgment and aimed at intermittent control. And during control intervals in intermittent control, there is periodic sampled-data control. In addition, by applying tools of sampled-data control, intermittent control, event-driven control theory and stability analysis, some sufficient conditions are derived to guarantee exponential synchronization of TMNTD. After that, the theoretical results are utilized to research exponential synchronization issue of time-varying multi-weights Chua’s circuits with time delays. Meantime, numerical simulations are provided to demonstrate the validity of the theoretical results. Finally, an image encryption algorithm is designed as a practical application of the developed results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001769",
    "keywords": [
      "Artificial intelligence",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Encryption",
      "Engineering",
      "Exponential function",
      "Intermittent control",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Stability (learning theory)",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Hui"
      },
      {
        "surname": "Liu",
        "given_name": "Zijiang"
      },
      {
        "surname": "Chu",
        "given_name": "Dianhui"
      },
      {
        "surname": "Li",
        "given_name": "Wenxue"
      }
    ]
  },
  {
    "title": "Generative convolution layer for image generation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.05.006",
    "abstract": "This paper introduces a novel convolution method, called generative convolution (GConv), which is simple yet effective for improving the generative adversarial network (GAN) performance. Unlike the standard convolution, GConv first selects useful kernels compatible with the given latent vector, and then linearly combines the selected kernels to make latent-specific kernels. Using the latent-specific kernels, the proposed method produces the latent-specific features which encourage the generator to produce high-quality images. This approach is simple but surprisingly effective. First, the GAN performance is significantly improved with a little additional hardware cost. Second, GConv can be employed to the existing state-of-the-art generators without modifying the network architecture. To reveal the superiority of GConv, this paper provides extensive experiments using various standard datasets including CIFAR-10, CIFAR-100, LSUN-Church, CelebA, and tiny-ImageNet. Quantitative evaluations prove that GConv significantly boosts the performances of the unconditional and conditional GANs in terms of Frechet inception distance (FID) and Inception score (IS). For example, the proposed method improves both FID and IS scores on the tiny-ImageNet dataset from 35.13 to 29.76 and 20.23 to 22.64, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001782",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Convolution (computer science)",
      "Discrete mathematics",
      "Epistemology",
      "Generative grammar",
      "Generator (circuit theory)",
      "Image (mathematics)",
      "Kernel (algebra)",
      "Layer (electronics)",
      "Machine learning",
      "Mathematics",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Simple (philosophy)"
    ],
    "authors": [
      {
        "surname": "Park",
        "given_name": "Seung"
      },
      {
        "surname": "Shin",
        "given_name": "Yong-Goo"
      }
    ]
  },
  {
    "title": "Deep learning, reinforcement learning, and world models",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.037",
    "abstract": "Deep learning (DL) and reinforcement learning (RL) methods seem to be a part of indispensable factors to achieve human-level or super-human AI systems. On the other hand, both DL and RL have strong connections with our brain functions and with neuroscientific findings. In this review, we summarize talks and discussions in the “Deep Learning and Reinforcement Learning” session of the symposium, International Symposium on Artificial Intelligence and Brain Science. In this session, we discussed whether we can achieve comprehensive understanding of human intelligence based on the recent advances of deep learning and reinforcement learning algorithms. Speakers contributed to provide talks about their recent studies that can be key technologies to achieve human-level intelligence.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001150",
    "keywords": [
      "Artificial intelligence",
      "Cognitive science",
      "Computer science",
      "Deep learning",
      "Human intelligence",
      "Psychology",
      "Reinforcement",
      "Reinforcement learning",
      "Session (web analytics)",
      "Social psychology",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Matsuo",
        "given_name": "Yutaka"
      },
      {
        "surname": "LeCun",
        "given_name": "Yann"
      },
      {
        "surname": "Sahani",
        "given_name": "Maneesh"
      },
      {
        "surname": "Precup",
        "given_name": "Doina"
      },
      {
        "surname": "Silver",
        "given_name": "David"
      },
      {
        "surname": "Sugiyama",
        "given_name": "Masashi"
      },
      {
        "surname": "Uchibe",
        "given_name": "Eiji"
      },
      {
        "surname": "Morimoto",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Evaluation of text-to-gesture generation model using convolutional neural network",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.041",
    "abstract": "Conversational gestures have a crucial role in realizing natural interactions with virtual agents and robots. Data-driven approaches, such as deep learning and machine learning, are promising in constructing the gesture generation model, which automatically provides the gesture motion for speech or spoken texts. This study experimentally analyzes a deep learning-based gesture generation model from spoken text using a convolutional neural network. The proposed model takes a sequence of spoken words as the input and outputs a sequence of 2D joint coordinates representing the conversational gesture motion. We prepare a dataset consisting of gesture motions and spoken texts by adding text information to an existing dataset and train the models using specific speaker’s data. The quality of the generated gestures is compared with those from an existing speech-to-gesture generation model through a user perceptual study. The subjective evaluation shows that the model performance is comparable or superior to those by the existing speech-to-gesture generation model. In addition, we investigate the importance of data cleansing and loss function selection in the text-to-gesture generation model. We further examine the model transferability between speakers. The experimental results demonstrate successful model transferability of the proposed model. Finally, we show that the text-to-gesture generation model can produce good quality gestures even when using a transformer architecture.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001198",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Gesture",
      "Gesture recognition",
      "Natural language processing",
      "Speech recognition",
      "Spoken language"
    ],
    "authors": [
      {
        "surname": "Asakawa",
        "given_name": "Eiichi"
      },
      {
        "surname": "Kaneko",
        "given_name": "Naoshi"
      },
      {
        "surname": "Hasegawa",
        "given_name": "Dai"
      },
      {
        "surname": "Shirakawa",
        "given_name": "Shinichi"
      }
    ]
  },
  {
    "title": "Golden subject is everyone: A subject transfer neural network for motor imagery-based brain computer interfaces",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.025",
    "abstract": "Electroencephalographic measurement of cortical activity subserving motor behavior varies among different individuals, restricting the potential of brain computer interfaces (BCIs) based on motor imagery (MI). How to deal with this variability and thereby improve the accuracy of BCI classification remains a key issue. This paper proposes a deep learning-based approach to transfer the data distribution from BCI-friendly — “golden subjects” to the data from more typical BCI-illiterate users. In this work, we use the perceptual loss to align the dimensionality-reduced BCI-illiterate data with the data of golden subjects in low dimensions, by which a subject transfer neural network (STNN) is proposed. The network consists of two parts: 1) a generator, which generates the transferred BCI-illiterate features, and 2) a CNN classifier, which is used for the classification of the transferred features, thus outperforming traditional classification methods both in terms of accuracy and robustness. Electroencephalography (EEG) signals from 25 healthy subjects performing MI of the right hand and foot were classified with an average accuracy of 88 . 2 % ± 5 . 1 % . The proposed model was further validated on the BCI Competition IV dataset 2b, and was demonstrated to be robust to inter-subject variations. The advantages of STNN allow it to bridge the gap between the golden subjects and the BCI-illiterate ones, paving the way to real-time BCI applications.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001034",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Brain–computer interface",
      "Chemistry",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Electroencephalography",
      "Gene",
      "Machine learning",
      "Motor imagery",
      "Pattern recognition (psychology)",
      "Psychiatry",
      "Psychology",
      "Rendering (computer graphics)",
      "Robustness (evolution)",
      "Transfer of learning"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Biao"
      },
      {
        "surname": "Wu",
        "given_name": "Zexu"
      },
      {
        "surname": "Hu",
        "given_name": "Yong"
      },
      {
        "surname": "Li",
        "given_name": "Ting"
      }
    ]
  },
  {
    "title": "Dynamic Auxiliary Soft Labels for decoupled learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.027",
    "abstract": "The long-tailed distribution in the dataset is one of the major challenges of deep learning. Convolutional Neural Networks have poor performance in identifying classes with only a few samples. For this problem, it has been proved that separating the feature learning stage and the classifier learning stage improves the performance of models effectively, which is called decoupled learning. We use soft labels to improve the performance of the decoupled learning framework by proposing a Dynamic Auxiliary Soft Labels (DaSL) method. Specifically, we design a dedicated auxiliary network to generate auxiliary soft labels for the two different training stages. In the feature learning stage, it helps to learn features with smaller variance within the class, and in the classifier learning stage it helps to alleviate the overconfidence of the model prediction. We also introduce a feature-level distillation method for the feature learning, and improve the learning of general features through multi-scale feature fusion. We conduct extensive experiments on three long-tailed recognition benchmark datasets to demonstrate the effectiveness of our DaSL.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001058",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Classifier (UML)",
      "Computer science",
      "Convolutional neural network",
      "Feature (linguistics)",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yan"
      },
      {
        "surname": "Zhang",
        "given_name": "Yongshun"
      },
      {
        "surname": "Shen",
        "given_name": "Furao"
      },
      {
        "surname": "Zhao",
        "given_name": "Jian"
      }
    ]
  },
  {
    "title": "Improving generalization of deep neural networks by leveraging margin distribution",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.019",
    "abstract": "Recent research has used margin theory to analyze the generalization performance for deep neural networks (DNNs). The existed results are almost based on the spectrally-normalized minimum margin. However, optimizing the minimum margin ignores a mass of information about the entire margin distribution, which is crucial to generalization performance. In this paper, we prove a generalization upper bound dominated by the statistics of the entire margin distribution. Compared with the minimum margin bounds, our bound highlights an important measure for controlling the complexity, which is the ratio of the margin standard deviation to the expected margin. We utilize a convex margin distribution loss function on the deep neural networks to validate our theoretical results by optimizing the margin ratio. Experiments and visualizations confirm the effectiveness of our approach and the correlation between generalization gap and margin ratio.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000971",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Generalization",
      "Machine learning",
      "Margin (machine learning)",
      "Mathematical analysis",
      "Mathematics",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Lyu",
        "given_name": "Shen-Huan"
      },
      {
        "surname": "Wang",
        "given_name": "Lu"
      },
      {
        "surname": "Zhou",
        "given_name": "Zhi-Hua"
      }
    ]
  },
  {
    "title": "Think positive: An interpretable neural network for image recognition",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.034",
    "abstract": "The COVID-19 pandemic is an ongoing pandemic and is placing additional burden on healthcare systems around the world. Timely and effectively detecting the virus can help to reduce the spread of the disease. Although, RT-PCR is still a gold standard for COVID-19 testing, deep learning models to identify the virus from medical images can also be helpful in certain circumstances. In particular, in situations when patients undergo routine X -rays and/or CT-scans tests but within a few days of such tests they develop respiratory complications. Deep learning models can also be used for pre-screening prior to RT-PCR testing. However, the transparency/interpretability of the reasoning process of predictions made by such deep learning models is essential. In this paper, we propose an interpretable deep learning model that uses positive reasoning process to make predictions. We trained and tested our model over the dataset of chest CT-scan images of COVID-19 patients, normal people and pneumonia patients. Our model gives the accuracy, precision, recall and F-score equal to 99.48%, 0.99, 0.99 and 0.99, respectively.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001125",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Coronavirus disease 2019 (COVID-19)",
      "Deep learning",
      "Disease",
      "Gold standard (test)",
      "Infectious disease (medical specialty)",
      "Internal medicine",
      "Interpretability",
      "Machine learning",
      "Medicine",
      "Pathology",
      "Pneumonia",
      "Radiology",
      "Transparency (behavior)"
    ],
    "authors": [
      {
        "surname": "Singh",
        "given_name": "Gurmail"
      }
    ]
  },
  {
    "title": "Exploration in neo-Hebbian reinforcement learning: Computational approaches to the exploration–exploitation balance with bio-inspired neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.021",
    "abstract": "Recent theoretical and experimental works have connected Hebbian plasticity with the reinforcement learning (RL) paradigm, producing a class of trial-and-error learning in artificial neural networks known as neo-Hebbian plasticity. Inspired by the role of the neuromodulator dopamine in synaptic modification, neo-Hebbian RL methods extend unsupervised Hebbian learning rules with value-based modulation to selectively reinforce associations. This reinforcement allows for learning exploitative behaviors and produces RL models with strong biological plausibility. The review begins with coverage of fundamental concepts in rate- and spike-coded models. We introduce Hebbian correlation detection as a basis for modification of synaptic weighting and progress to neo-Hebbian RL models guided solely by extrinsic rewards. We then analyze state-of-the-art neo-Hebbian approaches to the exploration–exploitation balance under the RL paradigm, emphasizing works that employ additional mechanics to modulate that dynamic. Our review of neo-Hebbian RL methods in this context indicates substantial potential for novel improvements in exploratory learning, primarily through stronger incorporation of intrinsic motivators. We provide a number of research suggestions for this pursuit by drawing from modern theories and results in neuroscience and psychology. The exploration–exploitation balance is a central issue in RL research, and this review is the first to focus on it under the neo-Hebbian RL framework.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000995",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Generalization error",
      "Hebbian theory",
      "Leabra",
      "Machine learning",
      "Paleontology",
      "Reinforcement learning",
      "Unsupervised learning",
      "Wake-sleep algorithm"
    ],
    "authors": [
      {
        "surname": "Triche",
        "given_name": "Anthony"
      },
      {
        "surname": "Maida",
        "given_name": "Anthony S."
      },
      {
        "surname": "Kumar",
        "given_name": "Ashok"
      }
    ]
  },
  {
    "title": "MoËT: Mixture of Expert Trees and its application to verifiable reinforcement learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.022",
    "abstract": "Rapid advancements in deep learning have led to many recent breakthroughs. While deep learning models achieve superior performance, often statistically better than humans, their adoption into safety-critical settings, such as healthcare or self-driving cars is hindered by their inability to provide safety guarantees or to expose the inner workings of the model in a human understandable form. We present MoËT, a novel model based on Mixture of Experts, consisting of decision tree experts and a generalized linear model gating function. Thanks to such gating function the model is more expressive than the standard decision tree. To support non-differentiable decision trees as experts, we formulate a novel training procedure. In addition, we introduce a hard thresholding version, MoËT h, in which predictions are made solely by a single expert chosen via the gating function. Thanks to that property, MoËT h allows each prediction to be easily decomposed into a set of logical rules in a form which can be easily verified. While MoËT is a general use model, we illustrate its power in the reinforcement learning setting. By training MoËT models using an imitation learning procedure on deep RL agents we outperform the previous state-of-the-art technique based on decision trees while preserving the verifiability of the models. Moreover, we show that MoËT can also be used in real-world supervised problems on which it outperforms other verifiable machine learning models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001009",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Computer science",
      "Decision tree",
      "Evolutionary biology",
      "Function (biology)",
      "Geometry",
      "Hyperplane",
      "Image (mathematics)",
      "Machine learning",
      "Mathematics",
      "Programming language",
      "Reinforcement learning",
      "Set (abstract data type)",
      "Thresholding",
      "Verifiable secret sharing"
    ],
    "authors": [
      {
        "surname": "Vasić",
        "given_name": "Marko"
      },
      {
        "surname": "Petrović",
        "given_name": "Andrija"
      },
      {
        "surname": "Wang",
        "given_name": "Kaiyuan"
      },
      {
        "surname": "Nikolić",
        "given_name": "Mladen"
      },
      {
        "surname": "Singh",
        "given_name": "Rishabh"
      },
      {
        "surname": "Khurshid",
        "given_name": "Sarfraz"
      }
    ]
  },
  {
    "title": "Lag H ∞ synchronization of coupled neural networks with multiple state couplings and multiple delayed state couplings",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.032",
    "abstract": "This paper mainly focuses on the lag H ∞ synchronization problem of coupled neural networks with multiple state or delayed state couplings. On one hand, by exploiting state feedback controller and Lyapunov functional, a criterion of lag H ∞ synchronization for coupled neural networks with multiple state couplings (CNNMSCs) is insured, and lag H ∞ synchronization problem in CNNMSCs is also coped with based on the adaptive state feedback controller. On the other hand, we explore the lag H ∞ synchronization for coupled neural networks with multiple delayed state couplings (CNNMDSCs) by utilizing similar control strategies. At last, two numerical examples are presented to verify the effectiveness and correctness of lag H ∞ synchronization for CNNMSCs and CNNMDSCs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001101",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer science",
      "Controller (irrigation)",
      "Correctness",
      "Lag",
      "Operating system",
      "State (computer science)",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Cao",
        "given_name": "Yuting"
      },
      {
        "surname": "Zhao",
        "given_name": "Linhao"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "GHNN: Graph Harmonic Neural Networks for semi-supervised graph-level classification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.018",
    "abstract": "Graph classification aims to predict the property of the whole graph, which has attracted growing attention in the graph learning community. This problem has been extensively studied in the literature of both graph convolutional networks and graph kernels. Graph convolutional networks can learn effective node representations via message passing to mine graph topology in an implicit way, whereas graph kernels can explicitly utilize graph structural knowledge for classification. Due to the scarcity of labeled data in real-world applications, semi-supervised algorithms are anticipated for this problem. In this paper, we propose Graph Harmonic Neural Network (GHNN) which combines the advantages of both worlds to sufficiently leverage the unlabeled data, and thus overcomes label scarcity in semi-supervised scenarios. Specifically, our GHNN consists of a graph convolutional network (GCN) module and a graph kernel network (GKN) module that explore graph topology information from complementary perspectives. To fully leverage the unlabeled data, we develop a novel harmonic contrastive loss and a harmonic consistency loss to harmonize the training of two modules by giving priority to high-quality unlabeled data, thereby reconciling prediction consistency between both of them. In this manner, the two modules mutually enhance each other to sufficiently explore the graph topology of both labeled and unlabeled data. Extensive experiments on a variety of benchmarks demonstrate the effectiveness of our approach over competitive baselines.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200096X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Leverage (statistics)",
      "Line graph",
      "Machine learning",
      "Theoretical computer science",
      "Topological graph theory",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Ju",
        "given_name": "Wei"
      },
      {
        "surname": "Luo",
        "given_name": "Xiao"
      },
      {
        "surname": "Ma",
        "given_name": "Zeyu"
      },
      {
        "surname": "Yang",
        "given_name": "Junwei"
      },
      {
        "surname": "Deng",
        "given_name": "Minghua"
      },
      {
        "surname": "Zhang",
        "given_name": "Ming"
      }
    ]
  },
  {
    "title": "Branching Time Active Inference: The theory and its generality",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.036",
    "abstract": "Over the last 10 to 15 years, active inference has helped to explain various brain mechanisms from habit formation to dopaminergic discharge and even modelling curiosity. However, the current implementations suffer from an exponential (space and time) complexity class when computing the prior over all the possible policies up to the time-horizon. Fountas et al. (2020) used Monte Carlo tree search to address this problem, leading to impressive results in two different tasks. In this paper, we present an alternative framework that aims to unify tree search and active inference by casting planning as a structure learning problem. Two tree search algorithms are then presented. The first propagates the expected free energy forward in time (i.e., towards the leaves), while the second propagates it backward (i.e., towards the root). Then, we demonstrate that forward and backward propagations are related to active inference and sophisticated inference, respectively, thereby clarifying the differences between those two planning strategies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001149",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Generality",
      "Inference",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Psychology",
      "Psychotherapist",
      "Search algorithm",
      "Search tree",
      "Theoretical computer science",
      "Tree (set theory)"
    ],
    "authors": [
      {
        "surname": "Champion",
        "given_name": "Théophile"
      },
      {
        "surname": "Da Costa",
        "given_name": "Lancelot"
      },
      {
        "surname": "Bowman",
        "given_name": "Howard"
      },
      {
        "surname": "Grześ",
        "given_name": "Marek"
      }
    ]
  },
  {
    "title": "Towards understanding theoretical advantages of complex-reaction networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.024",
    "abstract": "Complex-valued neural networks have attracted increasing attention in recent years, while it remains open on the advantages of complex-valued neural networks in comparison with real-valued networks. This work takes one step on this direction by introducing the complex-reaction network with fully-connected feed-forward architecture. We prove the universal approximation property for complex-reaction networks, and show that a class of radial functions can be approximated by a complex-reaction network using the polynomial number of parameters, whereas real-valued networks need at least exponential parameters to reach the same approximation level. For empirical risk minimization, we study the landscape and convergence of complex gradient descents. Our theoretical result shows that the critical point set of complex-reaction networks is a proper subset of that of real-valued networks, which may show some insights on finding the optimal solutions more easily for complex-reaction networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001022",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Complex network",
      "Complex system",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Epistemology",
      "Exponential function",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Philosophy",
      "Polynomial",
      "Programming language",
      "Property (philosophy)",
      "Set (abstract data type)",
      "Theoretical computer science",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Shao-Qun"
      },
      {
        "surname": "Gao",
        "given_name": "Wei"
      },
      {
        "surname": "Zhou",
        "given_name": "Zhi-Hua"
      }
    ]
  },
  {
    "title": "Learning a discriminative SPD manifold neural network for image set classification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.012",
    "abstract": "Performing pattern analysis over the symmetric positive definite (SPD) manifold requires specific mathematical computations, characterizing the non-Euclidian property of the involved data points and learning tasks, such as the image set classification problem. Accompanied with the advanced neural networking techniques, several architectures for processing the SPD matrices have recently been studied to obtain fine-grained structured representations. However, existing approaches are challenged by the diversely changing appearance of the data points, begging the question of how to learn invariant representations for improved performance with supportive theories. Therefore, this paper designs two Riemannian operation modules for SPD manifold neural network. Specifically, a Riemannian batch regularization (RBR) layer is firstly proposed for the purpose of training a discriminative manifold-to-manifold transforming network with a novelly-designed metric learning regularization term. The second module realizes the Riemannian pooling operation with geometric computations on the Riemannian manifolds, notably the Riemannian barycenter, metric learning, and Riemannian optimization. Extensive experiments on five benchmarking datasets show the efficacy of the proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000909",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Discriminative model",
      "Engineering",
      "Manifold (fluid mechanics)",
      "Mathematics",
      "Mechanical engineering",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Pure mathematics",
      "Riemannian geometry",
      "Riemannian manifold"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Rui"
      },
      {
        "surname": "Wu",
        "given_name": "Xiao-Jun"
      },
      {
        "surname": "Chen",
        "given_name": "Ziheng"
      },
      {
        "surname": "Xu",
        "given_name": "Tianyang"
      },
      {
        "surname": "Kittler",
        "given_name": "Josef"
      }
    ]
  },
  {
    "title": "Hippocampal formation-inspired probabilistic generative model",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.001",
    "abstract": "In building artificial intelligence (AI) agents, referring to how brains function in real environments can accelerate development by reducing the design space. In this study, we propose a probabilistic generative model (PGM) for navigation in uncertain environments by integrating the neuroscientific knowledge of hippocampal formation (HF) and the engineering knowledge in robotics and AI, namely, simultaneous localization and mapping (SLAM). We follow the approach of brain reference architecture (BRA) (Yamakawa, 2021) to compose the PGM and outline how to verify the model. To this end, we survey and discuss the relationship between the HF findings and SLAM models. The proposed hippocampal formation-inspired probabilistic generative model (HF-PGM) is designed to be highly consistent with the anatomical structure and functions of the HF. By referencing the brain, we elaborate on the importance of integration of egocentric/allocentric information from the entorhinal cortex to the hippocampus and the use of discrete-event queues.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001332",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Entorhinal cortex",
      "Generative grammar",
      "Generative model",
      "Hippocampal formation",
      "Machine learning",
      "Neuroscience",
      "Probabilistic logic",
      "Psychology",
      "Robot",
      "Robotics"
    ],
    "authors": [
      {
        "surname": "Taniguchi",
        "given_name": "Akira"
      },
      {
        "surname": "Fukawa",
        "given_name": "Ayako"
      },
      {
        "surname": "Yamakawa",
        "given_name": "Hiroshi"
      }
    ]
  },
  {
    "title": "Neural network for a class of sparse optimization with L 0 -regularization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.033",
    "abstract": "Sparse optimization involving the L 0 -norm function as the regularization in objective function has a wide application in many fields. In this paper, we propose a projected neural network modeled by a differential equation to solve a class of these optimization problems, in which the objective function is the sum of a nonsmooth convex loss function and the regularization defined by the L 0 -norm function. This optimization problem is not only nonconvex, but also discontinuous. To simplify the structure of the proposed network and let it own better convergence properties, we use the smoothing method, where the new constructed smoothing function for the regularization term plays a key role. We prove that the solution to the proposed network is globally existent and unique, and any accumulation point of it is a critical point of the continuous relaxation model. Except for a special case, which can be easily justified, any critical point is a local minimizer of the considered sparse optimization problem. It is an interesting thing that all critical points own a promising lower bound property, which is satisfied by all global minimizers of the considered problem, but is not by all local minimizers. Finally, we use some numerical experiments to illustrate the efficiency and good performance of the proposed method for solving this class of sparse optimization problems, which include the most widely used models in feature selection of classification learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001113",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Computer vision",
      "Evolutionary biology",
      "Function (biology)",
      "Law",
      "Mathematical optimization",
      "Mathematics",
      "Norm (philosophy)",
      "Optimization problem",
      "Political science",
      "Regularization (linguistics)",
      "Smoothing"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Zhe"
      },
      {
        "surname": "Li",
        "given_name": "Qingfa"
      },
      {
        "surname": "Wei",
        "given_name": "Jiazhen"
      },
      {
        "surname": "Bian",
        "given_name": "Wei"
      }
    ]
  },
  {
    "title": "Guaranteed approximation error estimation of neural networks and model modification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.023",
    "abstract": "Approximation error is a key measure in the process of model validation and verification for neural networks. In this paper, the problems of guaranteed error estimation of neural networks and applications to assured system modeling and assured neural network compression are addressed. First, a concept called guaranteed error estimation of feedforward neural networks is proposed, which intends to provide the worst-case approximation error of a trained neural network with respect to a compact input set essentially containing an infinite number of values. Given different prior information about the original system, two approaches including Lipschitz constant analysis and set-valued reachability analysis methods are developed to efficiently compute upper-bounds of approximation errors. Based on the guaranteed approximation error estimation framework, an optimization for obtaining parameter values from data set is proposed. A robotic arm and neural network compression examples are presented to illustrate the effectiveness of our approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001010",
    "keywords": [
      "Algorithm",
      "Approximation error",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Feedforward neural network",
      "Key (lock)",
      "Lipschitz continuity",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Programming language",
      "Reachability",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yejiang"
      },
      {
        "surname": "Wang",
        "given_name": "Tao"
      },
      {
        "surname": "Woolard",
        "given_name": "Jefferson P."
      },
      {
        "surname": "Xiang",
        "given_name": "Weiming"
      }
    ]
  },
  {
    "title": "Provable training of a ReLU gate with an iterative non-gradient algorithm",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.040",
    "abstract": "In this work, we demonstrate provable guarantees on the training of a single ReLU gate in hitherto unexplored regimes. We give a simple iterative stochastic algorithm that can train a ReLU gate in the realizable setting in linear time while using significantly milder conditions on the data distribution than previous such results. Leveraging certain additional moment assumptions, we also show a first-of-its-kind approximate recovery of the true label generating parameters under an (online) data-poisoning attack on the true labels, while training a ReLU gate by the same algorithm. Our guarantee is shown to be nearly optimal in the worst case and its accuracy of recovering the true weight degrades gracefully with increasing probability of attack and its magnitude. For both the realizable and the non-realizable cases as outlined above, our analysis allows for mini-batching and computes how the convergence time scales with the mini-batch size. We corroborate our theorems with simulation results which also bring to light a striking similarity in trajectories between our algorithm and the popular S.G.D. algorithm — for which similar guarantees as here are still unknown.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001186",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Classical mechanics",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Epistemology",
      "Image (mathematics)",
      "Iterative method",
      "Moment (physics)",
      "Philosophy",
      "Physics",
      "Similarity (geometry)",
      "Simple (philosophy)"
    ],
    "authors": [
      {
        "surname": "Karmakar",
        "given_name": "Sayar"
      },
      {
        "surname": "Mukherjee",
        "given_name": "Anirbit"
      }
    ]
  },
  {
    "title": "DGInet: Dynamic graph and interaction-aware convolutional network for vehicle trajectory prediction",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.038",
    "abstract": "This paper investigates vehicle trajectory prediction problems in real traffic scenarios by fully harnessing the spatio-temporal dependencies between multiple vehicles. The existing GCN-based trajectory predictions are often considered in a single traffic scene without time attributes, complete interaction information, dynamic graph-based model, etc. Time and interaction aware models are more challenging than the existing ones. Despite very well does the graph-based model describe the relationship between driving vehicles, the critical problem in the traffic scene is how to deeply explore the spatio-temporal characteristics of dynamic graphs. Therefore, a novel dynamic graph and interaction-aware neural network model called as DGInet is proposed by combining a semi-global graph mechanism and an M-product based graph convolutional network, which are built into novel dual-network architecture in the entire model. The DGInet is built by exploiting the dynamic interaction in depth between driving vehicles in urban traffic scenarios, and then realized by utilizing semi-global graph convolution operations on the input data cell to capture the basic spatial interaction features of the driving scene. Meanwhile, the dynamic graph is further extracted by a novel M-product approach, in which the embedding of the model is then established along with the embedding of the semi-global network to perform the final embedding. Extensive experiments have been conducted on the two public datasets, named NGSIM and Apollo respectively, to show that our approach outperforms the existing ones with better performance and less computing time. Besides the real-world Shenzhen traffic dataset, China, is also developed to verify the effectiveness of our approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001162",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Data mining",
      "Embedding",
      "Graph",
      "Physics",
      "Theoretical computer science",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "An",
        "given_name": "Jiyao"
      },
      {
        "surname": "Liu",
        "given_name": "Wei"
      },
      {
        "surname": "Liu",
        "given_name": "Qingqin"
      },
      {
        "surname": "Guo",
        "given_name": "Liang"
      },
      {
        "surname": "Ren",
        "given_name": "Ping"
      },
      {
        "surname": "Li",
        "given_name": "Tao"
      }
    ]
  },
  {
    "title": "Decoding sensorimotor information from superior parietal lobule of macaque via Convolutional Neural Networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.044",
    "abstract": "Despite the well-recognized role of the posterior parietal cortex (PPC) in processing sensory information to guide action, the differential encoding properties of this dynamic processing, as operated by different PPC brain areas, are scarcely known. Within the monkey’s PPC, the superior parietal lobule hosts areas V6A, PEc, and PE included in the dorso-medial visual stream that is specialized in planning and guiding reaching movements. Here, a Convolutional Neural Network (CNN) approach is used to investigate how the information is processed in these areas. We trained two macaque monkeys to perform a delayed reaching task towards 9 positions (distributed on 3 different depth and direction levels) in the 3D peripersonal space. The activity of single cells was recorded from V6A, PEc, PE and fed to convolutional neural networks that were designed and trained to exploit the temporal structure of neuronal activation patterns, to decode the target positions reached by the monkey. Bayesian Optimization was used to define the main CNN hyper-parameters. In addition to discrete positions in space, we used the same network architecture to decode plausible reaching trajectories. We found that data from the most caudal V6A and PEc areas outperformed PE area in the spatial position decoding. In all areas, decoding accuracies started to increase at the time the target to reach was instructed to the monkey, and reached a plateau at movement onset. The results support a dynamic encoding of the different phases and properties of the reaching movement differentially distributed over a network of interconnected areas. This study highlights the usefulness of neurons’ firing rate decoding via CNNs to improve our understanding of how sensorimotor information is encoded in PPC to perform reaching movements. The obtained results may have implications in the perspective of novel neuroprosthetic devices based on the decoding of these rich signals for faithfully carrying out patient’s intentions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001228",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Cognition",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Decoding methods",
      "Encoding (memory)",
      "Inferior parietal lobule",
      "Macaque",
      "Neural decoding",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Posterior parietal cortex",
      "Psychology",
      "Sensory system",
      "Superior parietal lobule"
    ],
    "authors": [
      {
        "surname": "Filippini",
        "given_name": "Matteo"
      },
      {
        "surname": "Borra",
        "given_name": "Davide"
      },
      {
        "surname": "Ursino",
        "given_name": "Mauro"
      },
      {
        "surname": "Magosso",
        "given_name": "Elisa"
      },
      {
        "surname": "Fattori",
        "given_name": "Patrizia"
      }
    ]
  },
  {
    "title": "Multigraph classification using learnable integration network with application to gender fingerprinting",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.035",
    "abstract": "Multigraphs with heterogeneous views present one of the most challenging obstacles to classification tasks due to their complexity. Several works based on feature selection have been recently proposed to disentangle the problem of multigraph heterogeneity. However, such techniques have major drawbacks. First, the bulk of such works lies in the vectorization and the flattening operations, failing to preserve and exploit the rich topological properties of the multigraph. Second, they learn the classification process in a dichotomized manner where the cascaded learning steps are pieced in together independently. Hence, such architectures are inherently agnostic to the cumulative estimation error from step to step. To overcome these drawbacks, we introduce MICNet (multigraph integration and classifier network), the first end-to-end graph neural network based model for multigraph classification. First, we learn a single-view graph representation of a heterogeneous multigraph using a GNN based integration model. The integration process in our model helps tease apart the heterogeneity across the different views of the multigraph by generating a subject-specific graph template while preserving its geometrical and topological properties conserving the node-wise information while reducing the size of the graph (i.e., number of views). Second, we classify each integrated template using a geometric deep learning block which enables us to grasp the salient graph features. We train, in end-to-end fashion, these two blocks using a single objective function to optimize the classification performance. We evaluate our MICNet in gender classification using brain multigraphs derived from different cortical measures. We demonstrate that our MICNet significantly outperformed its variants thereby showing its great potential in multigraph classification.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001137",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Computer science",
      "Graph",
      "Machine learning",
      "Multigraph",
      "Pattern recognition (psychology)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Chaari",
        "given_name": "Nada"
      },
      {
        "surname": "Gharsallaoui",
        "given_name": "Mohammed Amine"
      },
      {
        "surname": "Akdağ",
        "given_name": "Hatice Camgöz"
      },
      {
        "surname": "Rekik",
        "given_name": "Islem"
      }
    ]
  },
  {
    "title": "DGInet: Dynamic graph and interaction-aware convolutional network for vehicle trajectory prediction",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.038",
    "abstract": "This paper investigates vehicle trajectory prediction problems in real traffic scenarios by fully harnessing the spatio-temporal dependencies between multiple vehicles. The existing GCN-based trajectory predictions are often considered in a single traffic scene without time attributes, complete interaction information, dynamic graph-based model, etc. Time and interaction aware models are more challenging than the existing ones. Despite very well does the graph-based model describe the relationship between driving vehicles, the critical problem in the traffic scene is how to deeply explore the spatio-temporal characteristics of dynamic graphs. Therefore, a novel dynamic graph and interaction-aware neural network model called as DGInet is proposed by combining a semi-global graph mechanism and an M-product based graph convolutional network, which are built into novel dual-network architecture in the entire model. The DGInet is built by exploiting the dynamic interaction in depth between driving vehicles in urban traffic scenarios, and then realized by utilizing semi-global graph convolution operations on the input data cell to capture the basic spatial interaction features of the driving scene. Meanwhile, the dynamic graph is further extracted by a novel M-product approach, in which the embedding of the model is then established along with the embedding of the semi-global network to perform the final embedding. Extensive experiments have been conducted on the two public datasets, named NGSIM and Apollo respectively, to show that our approach outperforms the existing ones with better performance and less computing time. Besides the real-world Shenzhen traffic dataset, China, is also developed to verify the effectiveness of our approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001162",
    "keywords": [
      "Artificial intelligence",
      "Astronomy",
      "Computer science",
      "Data mining",
      "Embedding",
      "Graph",
      "Physics",
      "Theoretical computer science",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "An",
        "given_name": "Jiyao"
      },
      {
        "surname": "Liu",
        "given_name": "Wei"
      },
      {
        "surname": "Liu",
        "given_name": "Qingqin"
      },
      {
        "surname": "Guo",
        "given_name": "Liang"
      },
      {
        "surname": "Ren",
        "given_name": "Ping"
      },
      {
        "surname": "Li",
        "given_name": "Tao"
      }
    ]
  },
  {
    "title": "Adaptive modeling of nonnegative environmental systems based on projectional Differential Neural Networks observer",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.028",
    "abstract": "A new design of a non-parametric adaptive approximate model based on Differential Neural Networks (DNNs) applied for a class of non-negative environmental systems with an uncertain mathematical model is the primary outcome of this study. The approximate model uses an extended state formulation that gathers the dynamics of the DNN and a state projector (pDNN). Implementing a non-differentiable projection operator ensures the positiveness of the identifier states. The extended form allows producing continuous dynamics for the projected model. The design of the learning laws for the weight adjustment of the continuous projected DNN considered the application of a controlled Lyapunov-like function. The stability analysis based on the proposed Lyapunov-like function leads to the characterization of the ultimate boundedness property for the identification error. Applying the Attractive Ellipsoid Method (AEM) yields to analyze the convergence quality of the designed approximate model. The solution to the specific optimization problem using the AEM with matrix inequalities constraints allows us to find the parameters of the considered DNN that minimizes the ultimate bound. The evaluation of two numerical examples confirmed the ability of the proposed pDNN to approximate the positive model in the presence of bounded noises and perturbations in the measured data. The first example corresponds to a catalytic ozonation system that can be used to decompose toxic and recalcitrant contaminants. The second one describes the bacteria growth in aerobic batch regime biodegrading simple organic matter mixture.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200106X",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Differentiable function",
      "Lyapunov function",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Chairez",
        "given_name": "Isaac"
      },
      {
        "surname": "Andrianova",
        "given_name": "Olga"
      },
      {
        "surname": "Poznyak",
        "given_name": "Tatyana"
      },
      {
        "surname": "Poznyak",
        "given_name": "Alexander"
      }
    ]
  },
  {
    "title": "Quantum support vector machine based on regularized Newton method",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.043",
    "abstract": "An elegant quantum version of least-square support vector machine, which is exponentially faster than the classical counterpart, was given by Rebentrost et al. using the matrix inversion algorithm (HHL). However, the application of the HHL algorithm is restricted when the structure of the input matrix is not well. The iteration algorithms such as the Newton method are widespread in training the classical support vector machine. This paper demonstrates a quantum support vector machine based on the regularized Newton method (RN-QSVM), which achieves an exponential speed-up over classical algorithm. At first, the regularized quantum Newton algorithm is proposed to get rid of the constraint of input matrix. Then we train the RN-QSVM by using the regularized quantum Newton algorithm and classify a query sample by constructing the quantum state. Experiments demonstrate that RN-QSVM respectively provides advantages in terms of accuracy, robustness, and complexity compared to QSLS-SVM, LS-QSVM, and the classical method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001216",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Composite material",
      "Computer science",
      "Gene",
      "Materials science",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Newton's method",
      "Nonlinear system",
      "Physics",
      "Quantum",
      "Quantum algorithm",
      "Quantum mechanics",
      "Quantum state",
      "Robustness (evolution)",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Rui"
      },
      {
        "surname": "Wang",
        "given_name": "Jian"
      },
      {
        "surname": "Jiang",
        "given_name": "Nan"
      },
      {
        "surname": "Li",
        "given_name": "Hong"
      },
      {
        "surname": "Wang",
        "given_name": "Zichen"
      }
    ]
  },
  {
    "title": "Informative pairs mining based adaptive metric learning for adversarial domain adaptation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.031",
    "abstract": "Adversarial domain adaptation has made remarkable in promoting feature transferability, while recent work reveals that there exists an unexpected degradation of feature discrimination during the procedure of learning transferable features. This paper proposes an informative pairs mining based adaptive metric learning (IPM-AML), where a novel two-triplet-sampling strategy is advanced to select informative positive pairs from the same classes and informative negative pairs from different classes, and a metric loss imposed with special weights is further utilized to adaptively pay more attention to those more informative pairs which can adaptively improve discrimination. Then, we incorporate IPM-AML into popular conditional domain adversarial network (CDAN) to learn feature representation that is transferable and discriminative desirably (IPM-AML-CDAN). To ensure the reliability of pseudo target labels in the whole training process, we select more confident target ones whose predicted scores are higher than a given threshold T , and also provide theoretical validation for this simple threshold strategy. Extensive experiment results on four cross-domain benchmarks validate that IPM-AML-CDAN can achieve competitive results compared with state-of-the-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001095",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Data mining",
      "Discriminative model",
      "Domain (mathematical analysis)",
      "Economics",
      "Feature (linguistics)",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Law",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Metric (unit)",
      "Operating system",
      "Operations management",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Political science",
      "Politics",
      "Power (physics)",
      "Process (computing)",
      "Quantum mechanics",
      "Reliability (semiconductor)",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Mengzhu"
      },
      {
        "surname": "Li",
        "given_name": "Paul"
      },
      {
        "surname": "Shen",
        "given_name": "Li"
      },
      {
        "surname": "Wang",
        "given_name": "Ye"
      },
      {
        "surname": "Wang",
        "given_name": "Shanshan"
      },
      {
        "surname": "Wang",
        "given_name": "Wei"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiang"
      },
      {
        "surname": "Chen",
        "given_name": "Junyang"
      },
      {
        "surname": "Luo",
        "given_name": "Zhigang"
      }
    ]
  },
  {
    "title": "Brain-inspired multiple-target tracking using Dynamic Neural Fields",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.026",
    "abstract": "Despite considerable progress in the field of automatic multi-target tracking, several problems such as data association remained challenging. On the other hand, cognitive studies have reported that humans can robustly track several objects simultaneously. Such circumstances happen regularly in daily life, and humans have evolved to handle the associated problems. Accordingly, using brain-inspired processing principles may contribute to significantly increase the performance of automatic systems able to follow the trajectories of multiple objects. In this paper, we propose a multiple-object tracking algorithm based on dynamic neural field theory which has been proven to provide neuro-plausible processing mechanisms for cognitive functions of the brain. We define several input neural fields responsible for representing previous location and orientation information as well as instantaneous linear and angular speed of the objects in successive video frames. Image processing techniques are applied to extract the critical object features including target location and orientation. Two prediction fields anticipate the objects’ locations and orientations in the upcoming frame after receiving excitatory and inhibitory inputs from the input fields in a feed-forward architecture. This information is used in the data association and labeling process. We tested the proposed algorithm on a zebrafish larvae segmentation and tracking dataset and an ant-tracking dataset containing non-rigid objects with spiky movements and frequently occurring occlusions. The results showed a significant improvement in tracking metrics compared to state-of-the-art algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001046",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Association (psychology)",
      "Computer science",
      "Computer vision",
      "Epistemology",
      "Field (mathematics)",
      "Geometry",
      "Mathematics",
      "Object (grammar)",
      "Orientation (vector space)",
      "Pattern recognition (psychology)",
      "Pedagogy",
      "Philosophy",
      "Psychology",
      "Pure mathematics",
      "Segmentation",
      "Tracking (education)",
      "Video tracking"
    ],
    "authors": [
      {
        "surname": "Kamkar",
        "given_name": "Shiva"
      },
      {
        "surname": "Abrishami Moghaddam",
        "given_name": "Hamid"
      },
      {
        "surname": "Lashgari",
        "given_name": "Reza"
      },
      {
        "surname": "Erlhagen",
        "given_name": "Wolfram"
      }
    ]
  },
  {
    "title": "Double structure scaled simplex representation for multi-view subspace clustering",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.039",
    "abstract": "In the era of big data, there are an increasing number of multisource information data, and multi-view clustering (MVC) algorithms have developed rapidly. However, the affinity matrix learned by most MVC methods is not clean and precise enough and cannot describe the latent structure of multi-view data accurately, which results in poor clustering performance. In this paper, we propose a novel Double Structure Scaled Simplex Representation (DSSSR) method for MVC. Initially, we concatenate the multi-view data into a joint representation. Then, we use the scaled simplex representation (SSR) method on the concatenated data to obtain the affinity matrix. However, the affinity matrix is not clean and precise. Therefore, we use the SSR method again on the obtained affinity matrix to obtain a more accurate and clean affinity matrix. Furthermore, the two-step SSR is integrated into a unified optimization framework, a clean and accurate affinity matrix can be obtained, and the sum of each column vector of the affinity matrix is constrained to be nonnegative and equal to s ( 0 < s < 1 ), which can be adjusted to obtain the best clustering performance. Finally, an efficient optimization algorithm based on the augmented Lagrangian method (ALM) for solving the objective function is also designed. The experimental results on some datasets show that this algorithm has better clustering performance than some state-of-the-art algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001174",
    "keywords": [
      "Affinity propagation",
      "Algorithm",
      "Artificial intelligence",
      "Augmented Lagrangian method",
      "Canopy clustering algorithm",
      "Cluster analysis",
      "Composite material",
      "Computer science",
      "Correlation clustering",
      "Geometry",
      "Law",
      "Linear programming",
      "Materials science",
      "Mathematical optimization",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Simplex",
      "Simplex algorithm"
    ],
    "authors": [
      {
        "surname": "Yao",
        "given_name": "Liang"
      },
      {
        "surname": "Lu",
        "given_name": "Gui-Fu"
      }
    ]
  },
  {
    "title": "TSFD-Net: Tissue specific feature distillation network for nuclei segmentation and classification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.020",
    "abstract": "Nuclei segmentation and classification of hematoxylin and eosin-stained histology images is a challenging task due to a variety of issues, such as color inconsistency that results from the non-uniform manual staining operations, clustering of nuclei, and blurry and overlapping nuclei boundaries. Existing approaches involve segmenting nuclei by drawing their polygon representations or by measuring the distances between nuclei centroids. In contrast, we leverage the fact that morphological features (appearance, shape, and texture) of nuclei in a tissue vary greatly depending upon the tissue type. We exploit this information by extracting tissue specific (TS) features from raw histopathology images using the proposed tissue specific feature distillation (TSFD) backbone. The bi-directional feature pyramid network (BiFPN) within TSFD-Net generates a robust hierarchical feature pyramid utilizing TS features where the interlinked decoders jointly optimize and fuse these features to generate final predictions. We also propose a novel combinational loss function for joint optimization and faster convergence of our proposed network. Extensive ablation studies are performed to validate the effectiveness of each component of TSFD-Net. The proposed network outperforms state-of-the-art networks such as StarDist, Micro-Net, Mask-RCNN, Hover-Net, and CPP-Net on the PanNuke dataset, which contains 19 different tissue types and 5 clinically important tumor classes, achieving 50.4% and 63.77% mean and binary panoptic quality, respectively. The code is available at: https://github.com/Mr-TalhaIlyas/TSFD.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000612",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Feature (linguistics)",
      "Linguistics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Ilyas",
        "given_name": "Talha"
      },
      {
        "surname": "Mannan",
        "given_name": "Zubaer Ibna"
      },
      {
        "surname": "Khan",
        "given_name": "Abbas"
      },
      {
        "surname": "Azam",
        "given_name": "Sami"
      },
      {
        "surname": "Kim",
        "given_name": "Hyongsuk"
      },
      {
        "surname": "De Boer",
        "given_name": "Friso"
      }
    ]
  },
  {
    "title": "Neural feedback facilitates rough-to-fine information retrieval",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.042",
    "abstract": "Categorical relationships between objects are encoded as overlapped neural representations in the brain, where the more similar the objects are, the larger the correlations between their evoked neuronal responses. These representation correlations, however, inevitably incur interference when memories are retrieved. Here, we propose that neural feedback, which is widely observed in the brain but whose function remains largely unknown, contributes to disentangle neural correlations to improve information retrieval. We study a hierarchical neural network storing the hierarchical categorical information of objects, and information retrieval goes from rough-to-fine, aided by the push–pull neural feedback. We elucidate that the push and the pull components of the feedback suppress the interferences due to the representation correlations between objects from different and the same categories, respectively. Our model reproduces the push–pull phenomenon observed in neural data and sheds light on our understanding of the role of feedback in neural information processing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022001204",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Categorical variable",
      "Computer science",
      "Evolutionary biology",
      "Function (biology)",
      "Law",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Xiao"
      },
      {
        "surname": "Zou",
        "given_name": "Xiaolong"
      },
      {
        "surname": "Ji",
        "given_name": "Zilong"
      },
      {
        "surname": "Tian",
        "given_name": "Gengshuo"
      },
      {
        "surname": "Mi",
        "given_name": "Yuanyuan"
      },
      {
        "surname": "Huang",
        "given_name": "Tiejun"
      },
      {
        "surname": "Wong",
        "given_name": "K.Y. Michael"
      },
      {
        "surname": "Wu",
        "given_name": "Si"
      }
    ]
  },
  {
    "title": "Distributed k -winners-take-all via multiple neural networks with inertia",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.04.005",
    "abstract": "This paper is dedicated to solving the k -winners-take-all problem with large-scale input signals in a distributed manner. According to the decomposition of global input signals, a novel dynamical system consisting of multiple coordinated neural networks is proposed for finding the k largest inputs. In the system, each neural network is designed to tackle its available partial inputs only for a local objective k i ( k i ≤ k ). Simultaneously, a consensus-based approach is adopted to coordinate multiple neural networks for achieving the global objective k . In addition, an inertial term is introduced in each neural network for regulating its transient behavior, which has the potential of accelerating the convergence. By developing a cocoercive operator, we theoretically prove that the multiple neural networks with inertial terms converge asymptotically/exponentially to the k -winners-take-all solution exactly from arbitrary initial states for whatever decomposition of inputs and objective. Furthermore, some extensions to distributed constrained k -winners-take-all are also investigated. Finally, simulation results are presented to substantiate the effectiveness of the proposed system as well as its superior performance over existing distributed networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200137X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Convergence (economics)",
      "Database",
      "Economic growth",
      "Economics",
      "Mathematics",
      "Scalability",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Xiaoxuan"
      },
      {
        "surname": "Yang",
        "given_name": "Shaofu"
      },
      {
        "surname": "Guo",
        "given_name": "Zhenyuan"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Knowledge-based tensor subspace analysis system for kinship verification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.020",
    "abstract": "Most existing automatic kinship verification methods focus on learning the optimal distance metrics between family members. However, learning facial features and kinship features simultaneously may cause the proposed models to be too weak. In this work, we explore the possibility of bridging this gap by developing knowledge-based tensor models based on pre-trained multi-view models. We propose an effective knowledge-based tensor similarity extraction framework for automatic facial kinship verification using four pre-trained networks (i.e., VGG-Face, VGG-F, VGG-M, and VGG-S). Therefore, knowledge-based deep face and general features (such as identity, age, gender, ethnicity, expression, lighting, pose, contour, edges, corners, shape, etc.) were successfully fused by our tensor design to understand the kinship cue. Multiple effective representations are learned for kinship verification statements (children and parents) using a margin maximization learning scheme based on Tensor Cross-view Quadratic Exponential Discriminant Analysis. Through the exponential learning process, the large gap between distributions of the same family can be reduced to the maximum, while the small gap between distributions of different families is simultaneously increased. The WCCN metric successfully reduces the intra-class variability problem caused by deep features. The explanation of black-box models and the problems of ubiquitous face recognition are considered in our system. The extensive experiments on four challenging datasets show that our system performs very well compared to state-of-the-art approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000983",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Facial recognition system",
      "Kinship",
      "Law",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Political science",
      "Pure mathematics",
      "Subspace topology",
      "Tensor (intrinsic definition)"
    ],
    "authors": [
      {
        "surname": "Serraoui",
        "given_name": "I."
      },
      {
        "surname": "Laiadi",
        "given_name": "O."
      },
      {
        "surname": "Ouamane",
        "given_name": "A."
      },
      {
        "surname": "Dornaika",
        "given_name": "F."
      },
      {
        "surname": "Taleb-Ahmed",
        "given_name": "A."
      }
    ]
  },
  {
    "title": "Two-stage streaming keyword detection and localization with multi-scale depthwise temporal convolution",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.003",
    "abstract": "A keyword spotting (KWS) system running on smart devices should accurately detect the appearances and predict the locations of predefined keywords from audio streams, with small footprint and high efficiency. To this end, this paper proposes a new two-stage KWS method which combines a novel multi-scale depthwise temporal convolution (MDTC) feature extractor and a two-stage keyword detection and localization module. The MDTC feature extractor learns multi-scale feature representation efficiently with dilated depthwise temporal convolution, modeling both the temporal context and the speech rate variation. We use a region proposal network (RPN) as the first-stage KWS. At each frame, we design multiple time regions, which all take the current frame as the end position but have different start positions. These time regions (or formally anchors) are used to indicate rough location candidates of keyword. With frame level features from the MDTC feature extractor as inputs, RPN learns to propose keyword region proposals based on the designed anchors. To alleviate the keyword/non-keyword class imbalance problem, we specifically introduce a hard example mining algorithm to select effective negative anchors in RPN training. The keyword region proposals from the first-stage RPN contain keyword location information which is subsequently used to explicitly extract keyword related sequential features to train the second-stage KWS. The second-stage system learns to classify and transform region proposal to keyword IDs and ground-truth keyword region respectively. Experiments on the Google Speech Command dataset show that the proposed MDTC feature extractor surpasses several competitive feature extractors with a new state-of-the-art command classification error rate of 1 . 74 % . With the MDTC feature extractor, we further conduct wake-up word (WuW) detection and localization experiments on a commercial WuW dataset. Compared to a strong baseline, our proposed two-stage method achieves relatively 27–32% better false rejection rate at one false alarm per hour, while for keyword localization, the two-stage approach achieves more than 0 . 95 mean intersection-over-union ratio, which is clearly better than the one-stage RPN method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000739",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Feature (linguistics)",
      "Frame (networking)",
      "Keyword spotting",
      "Linguistics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Hou",
        "given_name": "Jingyong"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      },
      {
        "surname": "Zhang",
        "given_name": "Shilei"
      }
    ]
  },
  {
    "title": "A novel ramp loss-based multi-task twin support vector machine with multi-parameter safe acceleration",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.006",
    "abstract": "Direct multi-task twin support vector machine (DMTSVM) is an effective algorithm to deal with multi-task classification problems. However, the generated hyperplane may shift to outliers since the hinge loss is used in DMTSVM. Therefore, we propose an improved multi-task model RaMTTSVM based on ramp loss to handle noisy points more effectively. It could limit the maximal loss value distinctly and put definite restrictions on the influences of noises. But RaMTTSVM is non-convex which should be solved by CCCP, then a series of approximate convex problems need to be solved. So, it may be time-consuming. Motivated by the sparse solution of our RaMTTSVM, we further propose a safe acceleration rule MSA to accelerate the solving speed. Based on optimality conditions and convex optimization theory, MSA could delete a lot of inactive samples corresponding to 0 elements in dual solutions before solving the model. Then the computation speed can be accelerated by just solving reduced problems. The rule contains three different parts that correspond to different parameters and different iteration phases of CCCP. It can be used not only for the first approximate convex problem of CCCP but also for the successive problems during the iteration process. More importantly, our MSA is safe in the sense that the reduced problem can derive an identical optimal solution as the original problem, so the prediction accuracy will not be disturbed. Experimental results on one artificial dataset, ten Benchmark datasets, ten Image datasets and one real wine dataset confirm the generalization and acceleration ability of our proposed algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000764",
    "keywords": [
      "Acceleration",
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Classical mechanics",
      "Computation",
      "Computer science",
      "Convex optimization",
      "Generalization",
      "Geodesy",
      "Geography",
      "Geometry",
      "Hinge loss",
      "Hyperplane",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Outlier",
      "Physics",
      "Regular polygon",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Pang",
        "given_name": "Xinying"
      },
      {
        "surname": "Zhao",
        "given_name": "Jiang"
      },
      {
        "surname": "Xu",
        "given_name": "Yitian"
      }
    ]
  },
  {
    "title": "Robust multi-view subspace clustering based on consensus representation and orthogonal diversity",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.009",
    "abstract": "The main purpose of multi-view subspace clustering is to reveal the intrinsic low-dimensional architecture of data points according to their multi-view characteristics. Exploring the potential relationship from views is one of the most essential research focuses of the multi-view task. To better utilize the complementary and consistency information from distinct views, we propose a novel robust subspace clustering approach based on consensus representation and orthogonal diversity (RMSCCO). A novel defined orthogonality term is adopted to improve the diversity and decrease the redundance of learning subspace representation. The consensus representation and subspace learning are integrated into one unified framework to characterize the consistency from views. The grouping-enhanced representation is utilized to maintain the local geometric architecture in the original data space. The ℓ 2 , 1 -norm regularizer constraint to the noise is applied to improve the robustness. Finally, an optimization algorithm is exploited to solve RMSCCO with the Alternating Direction Method of Multipliers (ADMM). Extensive experimental results on six challenging datasets demonstrate that our approach has accomplished highly qualified performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200079X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Cluster analysis",
      "Computer science",
      "Consistency (knowledge bases)",
      "Gene",
      "Geometry",
      "Law",
      "Linear subspace",
      "Machine learning",
      "Mathematics",
      "Orthogonality",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Robustness (evolution)",
      "Subspace topology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Nan"
      },
      {
        "surname": "Bu",
        "given_name": "Jie"
      }
    ]
  },
  {
    "title": "Universality of gradient descent neural network training",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.016",
    "abstract": "It has been observed that design choices of neural networks are often crucial for their successful optimization. In this article, we therefore discuss the question if it is always possible to redesign a neural network so that it trains well with gradient descent. This yields the following universality result: If, for a given network, there is any algorithm that can find good network weights for a classification task, then there exists an extension of this network that reproduces the same forward model by mere gradient descent training. The construction is not intended for practical computations, but it provides some orientation on the possibilities of pre-trained networks in meta-learning and related approaches.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000570",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computation",
      "Computer science",
      "Gradient descent",
      "Machine learning",
      "Physics",
      "Quantum mechanics",
      "Universality (dynamical systems)"
    ],
    "authors": [
      {
        "surname": "Welper",
        "given_name": "G."
      }
    ]
  },
  {
    "title": "Augmented Graph Neural Network with hierarchical global-based residual connections",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.008",
    "abstract": "Graph Neural Networks (GNNs) are powerful architectures for learning on graphs. They are efficient for predicting nodes, links and graphs properties. Standard GNN variants follow a message passing schema to update nodes representations using information from higher-order neighborhoods iteratively. Consequently, deeper GNNs make it possible to define high-level nodes representations generated based on local as well as distant neighborhoods. However, deeper networks are prone to suffer from over-smoothing. To build deeper GNN architectures and avoid losing the dependency between lower (the layers closer to the input) and higher (the layers closer to the output) layers, networks can integrate residual connections to connect intermediate layers. We propose the Augmented Graph Neural Network (AGNN) model with hierarchical global-based residual connections. Using the proposed residual connections, the model generates high-level nodes representations without the need for a deeper architecture. We disclose that the nodes representations generated through our proposed AGNN model are able to define an expressive all-encompassing representation of the entire graph. As such, the graph predictions generated through the AGNN model surpass considerably state-of-the-art results. Moreover, we carry out extensive experiments to identify the best global pooling strategy and attention weights to define the adequate hierarchical and global-based residual connections for different graph property prediction tasks. Furthermore, we propose a reversible variant of the AGNN model to address the extensive memory consumption problem that typically arises from training networks on large and dense graph datasets. The proposed Reversible Augmented Graph Neural Network (R-AGNN) only stores the nodes representations acquired from the output layer as opposed to saving all representations from intermediate layers as it is conventionally done when optimizing the parameters of other GNNs. We further refine the definition of the backpropagation algorithm to fit the R-AGNN model. We evaluate the proposed models AGNN and R-AGNN on benchmark Molecular, Bioinformatics and Social Networks datasets for graph classification and achieve state-of-the-art results. For instance the AGNN model realizes improvements of + 39 % on IMDB-MULTI reaching 91.7% accuracy and + 16 % on COLLAB reaching 96.8% accuracy compared to other GNN variants.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000788",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer vision",
      "Graph",
      "Graph property",
      "Line graph",
      "Pooling",
      "Residual",
      "Smoothing",
      "Theoretical computer science",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Rassil",
        "given_name": "Asmaa"
      },
      {
        "surname": "Chougrad",
        "given_name": "Hiba"
      },
      {
        "surname": "Zouaki",
        "given_name": "Hamid"
      }
    ]
  },
  {
    "title": "A self-learning cognitive architecture exploiting causality from rewards",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.029",
    "abstract": "Inspired by the human vision system and learning, we propose a novel cognitive architecture that understands the content of raw videos in terms of objects without using labels. The architecture achieves four objectives: (1) Decomposing raw frames in objects by exploiting foveal vision and memory. (2) Describing the world by projecting objects on an internal canvas. (3) Extracting relevant objects from the canvas by analyzing the causal relation between objects and rewards. (4) Exploiting the information of relevant objects to facilitate the reinforcement learning (RL) process. In order to speed up learning, and better identify objects that produce rewards, the architecture implements learning by causality from the perspective of Wiener and Granger using object trajectories stored in working memory and the time series of external rewards. A novel non-parametric estimator of directed information using Renyi’s entropy is designed and tested. Experiments on three environments show that our architecture extracts most of relevant objects. It can be thought of as ‘understanding’ the world in an object-oriented way. As a consequence, our architecture outperforms state-of-the-art deep reinforcement learning in terms of training speed and transfer learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000703",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Biology",
      "Cognition",
      "Cognitive architecture",
      "Computer science",
      "Learning object",
      "Machine learning",
      "Neuroscience",
      "Object (grammar)",
      "Reinforcement learning",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Hongming"
      },
      {
        "surname": "Dou",
        "given_name": "Ran"
      },
      {
        "surname": "Keil",
        "given_name": "Andreas"
      },
      {
        "surname": "Principe",
        "given_name": "Jose C."
      }
    ]
  },
  {
    "title": "The passive properties of dendrites modulate the propagation of slowly-varying firing rate in feedforward networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.001",
    "abstract": "The propagation of slowly-varying firing rates has been proved significant for the development of the central nervous system. Recent reports have shown that the membrane passive properties of dendrites play a key role in the computation of the single neuron, which is of great importance to the function of neural networks. However, it is still unclear how dendritic passive properties affect the ability of cortical networks to propagate slowly-varying spiking activity. Here, we use two-compartment biophysical models to construct multilayered feedforward neural networks (FFNs) to investigate how dendritic passive properties affect the propagation of the slow-varying inputs. In the two-compartment biophysical models, one compartment represents apical dendrites, and the other compartment describes the soma plus the axon initial segment. Area proportion occupied by somatic compartment and coupling conductance between dendritic and somatic compartments are abstracted to capture the dendritic passive properties. A time-varying signal is injected into the first layer of the FFNs and the fidelity of the signal during propagation is used to qualify the ability of the FFN to transmit wave-like signals. Numerical results reveal an optimal value of coupling conductance between dendritic and somatic compartments to maximize the fidelity of the initial spiking activity. An increase of the dendritic area enhances the initial firing rate of neurons in the first layer by increasing the response of neurons to slow-varying wave-like input, resulting in a delay of attenuation of the firing rate, thus promoting the transmission of signals in FFN. Using a mean-field approach, we examine that changes in area proportion occupied by somatic compartment and coupling conductance between dendritic and somatic compartment affect the signal propagation ability of the FFN by adjusting the input–output transform of a single neuron. With the participation of external noise, a wide range of initial firing rates maintains a unique representation during propagation, which ensures the reliable transmission of slow-varying signals in FFNs. These findings are helpful to understand how passive properties of dendrites participate in the propagation of slowly varying signals in the cerebellum.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000715",
    "keywords": [
      "Artificial intelligence",
      "Axon",
      "Biological neural network",
      "Biological system",
      "Biology",
      "Compartment (ship)",
      "Computer science",
      "Control engineering",
      "Coupling (piping)",
      "Dendrite (mathematics)",
      "Dendritic spike",
      "Engineering",
      "Excitatory postsynaptic potential",
      "Feed forward",
      "Geology",
      "Geometry",
      "Inhibitory postsynaptic potential",
      "Materials science",
      "Mathematics",
      "Metallurgy",
      "Network model",
      "Neuroscience",
      "Oceanography",
      "Physics",
      "Soma",
      "Synapse"
    ],
    "authors": [
      {
        "surname": "Gao",
        "given_name": "Tianshi"
      },
      {
        "surname": "Deng",
        "given_name": "Bin"
      },
      {
        "surname": "Wang",
        "given_name": "Jixuan"
      },
      {
        "surname": "Wang",
        "given_name": "Jiang"
      },
      {
        "surname": "Yi",
        "given_name": "Guosheng"
      }
    ]
  },
  {
    "title": "Novel projection neurodynamic approaches for constrained convex optimization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.011",
    "abstract": "Consider that the constrained convex optimization problems have emerged in a variety of scientific and engineering applications that often require efficient and fast solutions. Inspired by the Nesterov’s accelerated method for solving unconstrained convex and strongly convex optimization problems, in this paper we propose two novel accelerated projection neurodynamic approaches for constrained smooth convex and strongly convex optimization based on the variational approach. First, for smooth, and convex optimization problems, a non-autonomous accelerated projection neurodynamic approach (NAAPNA) is presented and the existence, uniqueness and feasibility of the solution to it are analyzed rigorously. We provide that the NAAPNA has a convergence rate which is inversely proportional to the square of the running time. In addition, we present a novel autonomous accelerated projection neurodynamic approach (AAPNA) for addressing the constrained, smooth, strongly convex optimization problems and prove the existence, uniqueness to the strong global solution of AAPNA based on the Cauchy–Lipschitz–Picard theorem. Furthermore, we also prove the global convergence of AAPNA with different exponential convergence rates for different parameters. Compared with existing projection neurodynamic approaches based on the Brouwer’s fixed point theorem, both NAAPNA and AAPNA use the projection operators of the auxiliary variable to map the primal variables to the constrained feasible region, thus our proposed neurodynamic approaches are easier to realize algorithm’s acceleration. Finally, the effectiveness of NAAPNA and AAPNA is illustrated with several numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000892",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Convergence (economics)",
      "Convex optimization",
      "Economic growth",
      "Economics",
      "Geometry",
      "Lipschitz continuity",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Projection (relational algebra)",
      "Regular polygon",
      "Uniqueness"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "You"
      },
      {
        "surname": "Liao",
        "given_name": "Xiaofeng"
      },
      {
        "surname": "He",
        "given_name": "Xing"
      }
    ]
  },
  {
    "title": "Quasi-synchronization of fractional-order multi-layer networks with mismatched parameters via delay-dependent impulsive feedback control",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.023",
    "abstract": "The paper is devoted to investigating the quasi-synchronization issue of fractional-order multi-layer networks with mismatched parameters under delay-dependent impulsive feedback control. It is worth highlighting that fractional-order multi-layer networks with mismatched parameters, as the extension model for single-layer or two-layer ones, are constructed in this paper. Simultaneously, the intra-layer and inter-layer couplings are taken into consideration, which is more general and rarely considered in discussions of network synchronization. An extended fractional differential inequality with impulsive effects is given to establish the grounded framework and theory on the quasi-synchronization problem under delay-dependent impulsive feedback control. Moreover, in the light of the Lyapunov method and graph theory, two criteria for achieving the quasi-synchronization of fractional-order multi-layer networks with mismatched parameters are derived. Furthermore, exponential convergence rates as well as the bounds of quasi-synchronization errors are successfully deduced. Ultimately, the theoretical results are applied in a practical power system, and some illustrative examples are proposed to show the effectiveness of theoretical analysis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000648",
    "keywords": [
      "Artificial intelligence",
      "Chemistry",
      "Combinatorics",
      "Complex network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Layer (electronics)",
      "Mathematics",
      "Organic chemistry",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Yao"
      },
      {
        "surname": "Liu",
        "given_name": "Jingjing"
      },
      {
        "surname": "Li",
        "given_name": "Wenxue"
      }
    ]
  },
  {
    "title": "Synchronization and state estimation for discrete-time coupled delayed complex-valued neural networks with random system parameters",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.028",
    "abstract": "In this paper, an array of discrete-time coupled complex-valued neural networks (CVNNs) with random system parameters and time-varying delays are introduced. The stochastic fluctuations of system parameters, which are characterized by a set of random variables, are considered in the individual CVNNs. Firstly, the synchronization issue is solved for the considered coupled CVNNs. By the use of the Lyapunov stability theory and the Kronecker product, a synchronization criterion is proposed to guarantee that the coupled CVNNs are asymptotically synchronized in the mean square. Subsequently, the state estimation issue is studied for the identical coupled CVNNs via available measurement output. By establishing a suitable Lyapunov functional, sufficient conditions are derived under which the mean square asymptotic stability of the estimation error system is ensured and the design scheme of desired state estimator is explicitly provided. Finally, two numerical simulation examples are shown for the purpose of illustrating the effectiveness of the proposed theory.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000697",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Estimator",
      "Exponential stability",
      "Kronecker delta",
      "Kronecker product",
      "Lyapunov function",
      "Lyapunov stability",
      "Machine learning",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)",
      "Stability theory",
      "State (computer science)",
      "Statistics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Yufei"
      },
      {
        "surname": "Shen",
        "given_name": "Bo"
      },
      {
        "surname": "Zhang",
        "given_name": "Ping"
      }
    ]
  },
  {
    "title": "Attributes learning network for generalized zero-shot learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.018",
    "abstract": "In the absence of unseen training data, zero-shot learning algorithms utilize the semantic knowledge shared by the seen and unseen classes to establish the connection between the visual space and the semantic space, so as to realize the recognition of the unseen classes. However, in real applications, the original semantic representation cannot well characterize both the class-specificity structure and discriminative information in dimension space, which leads to unseen classes being easily misclassified into seen classes. To tackle this problem, we propose a Salient Attributes Learning Network (SALN) to generate discriminative and expressive semantic representation under the supervision of the visual features. Meanwhile, ℓ 1 , 2 -norm constraint is employed to make the learned semantic representation well characterize the class-specificity structure and discriminative information in dimension space. Then feature alignment network projects the learned semantic representation into visual space and a relation network is adopted for classification. The performance of the proposed approach has made progress on the five benchmark datasets in generalized zero-shot learning task, and in-depth experiments indicate the effectiveness and excellence of our method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000594",
    "keywords": [
      "Artificial intelligence",
      "Class (philosophy)",
      "Computer science",
      "Discriminative model",
      "Feature (linguistics)",
      "Feature learning",
      "Feature vector",
      "Law",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Yun",
        "given_name": "Yu"
      },
      {
        "surname": "Wang",
        "given_name": "Sen"
      },
      {
        "surname": "Hou",
        "given_name": "Mingzhen"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      }
    ]
  },
  {
    "title": "All by Myself: Learning individualized competitive behavior with a contrastive reinforcement learning optimization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.013",
    "abstract": "In a competitive game scenario, a set of agents have to learn decisions that maximize their goals and minimize their adversaries’ goals at the same time. Besides dealing with the increased dynamics of the scenarios due to the opponents’ actions, they usually have to understand how to overcome the opponent’s strategies. Most of the common solutions, usually based on continual learning or centralized multi-agent experiences, however, do not allow the development of personalized strategies to face individual opponents. In this paper, we propose a novel model composed of three neural layers that learn a representation of a competitive game, learn how to map the strategy of specific opponents, and how to disrupt them. The entire model is trained online, using a composed loss based on a contrastive optimization, to learn competitive and multiplayer games. We evaluate our model on a pokemon duel scenario and the four-player competitive Chef’s Hat card game. Our experiments demonstrate that our model achieves better performance when playing against offline, online, and competitive-specific models, in particular when playing against the same opponent multiple times. We also present a discussion on the impact of our model, in particular on how well it deals with on specific strategy learning for each of the two scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000910",
    "keywords": [
      "Adversary",
      "Artificial intelligence",
      "Business",
      "Competitive advantage",
      "Computer science",
      "Computer security",
      "Face (sociological concept)",
      "Law",
      "Machine learning",
      "Marketing",
      "Political science",
      "Politics",
      "Programming language",
      "Reinforcement learning",
      "Representation (politics)",
      "Set (abstract data type)",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Barros",
        "given_name": "Pablo"
      },
      {
        "surname": "Sciutti",
        "given_name": "Alessandra"
      }
    ]
  },
  {
    "title": "A whole brain probabilistic generative model: Toward realizing cognitive architectures for developmental robots",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.026",
    "abstract": "Building a human-like integrative artificial cognitive system, that is, an artificial general intelligence (AGI), is the holy grail of the artificial intelligence (AI) field. Furthermore, a computational model that enables an artificial system to achieve cognitive development will be an excellent reference for brain and cognitive science. This paper describes an approach to develop a cognitive architecture by integrating elemental cognitive modules to enable the training of the modules as a whole. This approach is based on two ideas: (1) brain-inspired AI, learning human brain architecture to build human-level intelligence, and (2) a probabilistic generative model (PGM)-based cognitive architecture to develop a cognitive system for developmental robots by integrating PGMs. The proposed development framework is called a whole brain PGM (WB-PGM), which differs fundamentally from existing cognitive architectures in that it can learn continuously through a system based on sensory-motor information. In this paper, we describe the rationale for WB-PGM, the current status of PGM-based elemental cognitive modules, their relationship with the human brain, the approach to the integration of the cognitive modules, and future challenges. Our findings can serve as a reference for brain studies. As PGMs describe explicit informational relationships between variables, WB-PGM provides interpretable guidance from computational sciences to brain science. By providing such information, researchers in neuroscience can provide feedback to researchers in AI and robotics on what the current models lack with reference to the brain. Further, it can facilitate collaboration among researchers in neuro-cognitive sciences as well as AI and robotics.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000673",
    "keywords": [
      "Artificial intelligence",
      "Cognition",
      "Cognitive architecture",
      "Cognitive model",
      "Cognitive neuroscience",
      "Cognitive robotics",
      "Cognitive science",
      "Computer science",
      "Human–computer interaction",
      "Machine learning",
      "Neuroscience",
      "Probabilistic logic",
      "Psychology",
      "Robot",
      "Robotics"
    ],
    "authors": [
      {
        "surname": "Taniguchi",
        "given_name": "Tadahiro"
      },
      {
        "surname": "Yamakawa",
        "given_name": "Hiroshi"
      },
      {
        "surname": "Nagai",
        "given_name": "Takayuki"
      },
      {
        "surname": "Doya",
        "given_name": "Kenji"
      },
      {
        "surname": "Sakagami",
        "given_name": "Masamichi"
      },
      {
        "surname": "Suzuki",
        "given_name": "Masahiro"
      },
      {
        "surname": "Nakamura",
        "given_name": "Tomoaki"
      },
      {
        "surname": "Taniguchi",
        "given_name": "Akira"
      }
    ]
  },
  {
    "title": "A BERT based dual-channel explainable text emotion recognition system",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.017",
    "abstract": "In this paper, a novel dual-channel system for multi-class text emotion recognition has been proposed, and a novel technique to explain its training & predictions has been developed. The architecture of the proposed system contains the embedding module, dual-channel module, emotion classification module, and explainability module. The embedding module extracts the textual features from the input sentences in the form of embedding vectors using the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model. Then the embedding vectors are fed as the inputs to the dual-channel network containing two network channels made up of convolutional neural network (CNN) and bidirectional long short term memory (BiLSTM) network. The intuition behind using CNN and BiLSTM in both the channels was to harness the goodness of the convolutional layer for feature extraction and the BiLSTM layer to extract text’s order and sequence-related information. The outputs of both channels are in the form of embedding vectors which are concatenated and fed to the emotion classification module. The proposed system’s architecture has been determined by thorough ablation studies, and a framework has been developed to discuss its computational cost. The emotion classification module learns and projects the emotion embeddings on a hyperplane in the form of clusters. The proposed explainability technique explains the training and predictions of the proposed system by analyzing the inter & intra-cluster distances and the intersection of these clusters. The proposed approach’s consistent accuracy, precision, recall, and F1 score results for ISEAR, Aman, AffectiveText, and EmotionLines datasets, ensure its applicability to diverse texts.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000958",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Embedding",
      "Encoder",
      "Operating system",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Kumar",
        "given_name": "Puneet"
      },
      {
        "surname": "Raman",
        "given_name": "Balasubramanian"
      }
    ]
  },
  {
    "title": "Unsupervised feature selection via adaptive autoencoder with redundancy control",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.004",
    "abstract": "Unsupervised feature selection is one of the efficient approaches to reduce the dimension of unlabeled high-dimensional data. We present a novel adaptive autoencoder with redundancy control (AARC) as an unsupervised feature selector. By adding two Group Lasso penalties to the objective function, AARC integrates unsupervised feature selection and determination of a compact network structure into a single framework. Besides, a penalty based on a measure of dependency between features (such as Pearson correlation, mutual information) is added to the objective function for controlling the level of redundancy in the selected features. To realize the desired effects of different regularizers in different phases of the training, we introduce adaptive parameters which change with iterations. In addition, a smoothing function is utilized to approximate the three penalties since they are not differentiable at the origin. An ablation study is carried out to validate the capabilities of redundancy control and structure optimization of AARC. Subsequently, comparisons with nine state-of-the-art methods illustrate the efficiency of AARC for unsupervised feature selection.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000740",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Computer vision",
      "Data mining",
      "Dimensionality reduction",
      "Feature (linguistics)",
      "Feature selection",
      "Linguistics",
      "Machine learning",
      "Minimum redundancy feature selection",
      "Mutual information",
      "Operating system",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Redundancy (engineering)",
      "Smoothing",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Gong",
        "given_name": "Xiaoling"
      },
      {
        "surname": "Yu",
        "given_name": "Ling"
      },
      {
        "surname": "Wang",
        "given_name": "Jian"
      },
      {
        "surname": "Zhang",
        "given_name": "Kai"
      },
      {
        "surname": "Bai",
        "given_name": "Xiao"
      },
      {
        "surname": "Pal",
        "given_name": "Nikhil R."
      }
    ]
  },
  {
    "title": "Lifelong 3D object recognition and grasp synthesis using dual memory recurrent self-organization networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.027",
    "abstract": "Humans learn to recognize and manipulate new objects in lifelong settings without forgetting the previously gained knowledge under non-stationary and sequential conditions. In autonomous systems, the agents also need to mitigate similar behaviour to continually learn the new object categories and adapt to new environments. In most conventional deep neural networks, this is not possible due to the problem of catastrophic forgetting, where the newly gained knowledge overwrites existing representations. Furthermore, most state-of-the-art models excel either in recognizing the objects or in grasp prediction, while both tasks use visual input. The combined architecture to tackle both tasks is very limited. In this paper, we proposed a hybrid model architecture consists of a dynamically growing dual-memory recurrent neural network (GDM) and an autoencoder to tackle object recognition and grasping simultaneously. The autoencoder network is responsible to extract a compact representation for a given object, which serves as input for the GDM learning, and is responsible to predict pixel-wise antipodal grasp configurations. The GDM part is designed to recognize the object in both instances and categories levels. We address the problem of catastrophic forgetting using the intrinsic memory replay, where the episodic memory periodically replays the neural activation trajectories in the absence of external sensory information. To extensively evaluate the proposed model in a lifelong setting, we generate a synthetic dataset due to lack of sequential 3D objects dataset. Experiment results demonstrated that the proposed model can learn both object representation and grasping simultaneously in continual learning scenarios.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000685",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Forgetting",
      "GRASP",
      "Law",
      "Lifelong learning",
      "Linguistics",
      "Machine learning",
      "Object (grammar)",
      "Pedagogy",
      "Philosophy",
      "Political science",
      "Politics",
      "Programming language",
      "Psychology",
      "Recurrent neural network",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Santhakumar",
        "given_name": "Krishnakumar"
      },
      {
        "surname": "Kasaei",
        "given_name": "Hamidreza"
      }
    ]
  },
  {
    "title": "Efficient learning rate adaptation based on hierarchical optimization approach",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.014",
    "abstract": "This paper proposes a new hierarchical approach to learning rate adaptation in gradient methods, called learning rate optimization (LRO). LRO formulates the learning rate adaption problem as a hierarchical optimization problem that minimizes the loss function with respect to the learning rate for current model parameters and gradients. Then, LRO optimizes the learning rate based on the alternating direction method of multipliers (ADMM). In the process of this learning rate optimization, LRO does not require any second-order information and probabilistic model, so it is highly efficient. Furthermore, LRO does not require any additional hyperparameters when compared to the vanilla gradient method with the simple exponential learning rate decay. In the experiments, we integrated LRO with vanilla SGD and Adam. Then, we compared their optimization performance with the state-of-the-art learning rate adaptation methods and also the most commonly-used adaptive gradient methods. The SGD and Adam with LRO outperformed all the competitors on the benchmark datasets in image classification tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000478",
    "keywords": [
      "Adaptation (eye)",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Computer security",
      "Geodesy",
      "Geography",
      "Hyperparameter",
      "Key (lock)",
      "Machine learning",
      "Optics",
      "Physics",
      "Rate of convergence"
    ],
    "authors": [
      {
        "surname": "Na",
        "given_name": "Gyoung S."
      }
    ]
  },
  {
    "title": "Deep feature fusion based childhood epilepsy syndrome classification from electroencephalogram",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.014",
    "abstract": "Accurate classification of the children’s epilepsy syndrome is vital to the diagnosis and treatment of epilepsy. But existing literature mainly focuses on seizure detection and few attention has been paid to the children’s epilepsy syndrome classification. In this paper, we present a study on the classification of two most common epilepsy syndromes: the benign childhood epilepsy with centro-temporal spikes (BECT) and the infantile spasms (also known as the WEST syndrome), recorded from the Children’s Hospital, Zhejiang University School of Medicine (CHZU). A novel feature fusion model based on the deep transfer learning and the conventional time–frequency representation of the scalp electroencephalogram (EEG) is developed for the epilepsy syndrome characterization. A fully connected network is constructed for the feature learning and syndrome classification. Experiments on the CHZU database show that the proposed algorithm can offer an average of 92.35% classification accuracy on the BECT and WEST syndromes and their corresponding normal cases.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000922",
    "keywords": [
      "Anatomy",
      "Artificial intelligence",
      "Computer science",
      "Electroencephalography",
      "Epilepsy",
      "Epilepsy in children",
      "Epilepsy syndromes",
      "Feature (linguistics)",
      "Linguistics",
      "Medicine",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Psychology",
      "Scalp",
      "West Syndrome"
    ],
    "authors": [
      {
        "surname": "Cui",
        "given_name": "Xiaonan"
      },
      {
        "surname": "Hu",
        "given_name": "Dinghan"
      },
      {
        "surname": "Lin",
        "given_name": "Peng"
      },
      {
        "surname": "Cao",
        "given_name": "Jiuwen"
      },
      {
        "surname": "Lai",
        "given_name": "Xiaoping"
      },
      {
        "surname": "Wang",
        "given_name": "Tianlei"
      },
      {
        "surname": "Jiang",
        "given_name": "Tiejia"
      },
      {
        "surname": "Gao",
        "given_name": "Feng"
      }
    ]
  },
  {
    "title": "Learning online visual invariances for novel objects via supervised and self-supervised training",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.017",
    "abstract": "Humans can identify objects following various spatial transformations such as scale and viewpoint. This extends to novel objects, after a single presentation at a single pose, sometimes referred to as online invariance. CNNs have been proposed as a compelling model of human vision, but their ability to identify objects across transformations is typically tested on held-out samples of trained categories after extensive data augmentation. This paper assesses whether standard CNNs can support human-like online invariance by training models to recognize images of synthetic 3D objects that undergo several transformations: rotation, scaling, translation, brightness, contrast, and viewpoint. Through the analysis of models’ internal representations, we show that standard supervised CNNs trained on transformed objects can acquire strong invariances on novel classes even when trained with as few as 50 objects taken from 10 classes. This extended to a different dataset of photographs of real objects. We also show that these invariances can be acquired in a self-supervised way, through solving the same/different task. We suggest that this latter approach may be similar to how humans acquire invariances.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000582",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Contrast (vision)",
      "Law",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Biscione",
        "given_name": "Valerio"
      },
      {
        "surname": "Bowers",
        "given_name": "Jeffrey S."
      }
    ]
  },
  {
    "title": "A zeroing neural dynamics based acceleration optimization approach for optimizers in deep neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.010",
    "abstract": "The first-order optimizers in deep neural networks (DNN) are of pivotal essence for a concrete loss function to reach the local minimum or global one on the loss surface within convergence time. However, each optimizer possesses its own superiority and virtue when encountering a specific application scene and environment. In addition, the existing modified optimizers mostly emphasize a given optimizer without any transfer property. In this paper, a zeroing neural dynamics (ZND) based optimization approach for the first-order optimizers is proposed, which can assist ZND via the activation function to expedite the process of solving gradient information, with lower loss and higher accuracy. To the best of our knowledge, it is the first work to integrate the ZND in control domain with the first-order optimizers in DNN. This generic work is an optimization method for the most commonly-used first-order optimizers to handle different application scenes, rather than developing a brand-new algorithm besides the existing optimizers or their modifications. Furthermore, mathematic derivations concerning the gradient information transformation of the ZND are systematically provided. Finally, comparison experiments are implemented, which demonstrates the effectiveness of the proposed approach with different loss functions and network frameworks on the Reuters, CIFAR, and MNIST data sets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000806",
    "keywords": [
      "Acceleration",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Classical mechanics",
      "Computer science",
      "Convergence (economics)",
      "Domain (mathematical analysis)",
      "Economic growth",
      "Economics",
      "Epistemology",
      "Evolutionary biology",
      "Function (biology)",
      "Gene",
      "Global optimization",
      "MNIST database",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Philosophy",
      "Physics",
      "Process (computing)",
      "Property (philosophy)",
      "Transformation (genetics)"
    ],
    "authors": [
      {
        "surname": "Liao",
        "given_name": "Shan"
      },
      {
        "surname": "Li",
        "given_name": "Shubin"
      },
      {
        "surname": "Liu",
        "given_name": "Jiayong"
      },
      {
        "surname": "Huang",
        "given_name": "Haoen"
      },
      {
        "surname": "Xiao",
        "given_name": "Xiuchun"
      }
    ]
  },
  {
    "title": "Connectome of memristive nanowire networks through graph theory",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.022",
    "abstract": "Hardware implementation of neural networks represents a milestone for exploiting the advantages of neuromorphic-type data processing and for making use of the inherent parallelism associated with such structures. In this context, memristive devices with their analogue functionalities are called to be promising building blocks for the hardware realization of artificial neural networks. As an alternative to conventional crossbar architectures where memristive devices are organized with a top-down approach in a grid-like fashion, neuromorphic-type data processing and computing capabilities have been explored in networks realized according to the principle of self-organization similarity found in biological neural networks. Here, we explore structural and functional connectivity of self-organized memristive nanowire (NW) networks within the theoretical framework of graph theory. While graph metrics reveal the link of the graph theoretical approach with geometrical considerations, results show that the interplay between network structure and its capacity to transmit information is related to a phase transition process consistent with percolation theory. Also the concept of memristive distance is introduced to investigate activation patterns and the dynamic evolution of the information flow across the network represented as a memristive graph. In agreement with experimental results, the emergent short-term dynamics reveals the formation of self-selected pathways with enhanced transport characteristics connecting stimulated areas and regulating the trafficking of the information flow. The network capability to process spatio-temporal input signals can be exploited for the implementation of unconventional computing paradigms in memristive graphs that take into advantage the inherent relationship between structure and functionality as in biological systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000636",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Distributed computing",
      "Electronic engineering",
      "Engineering",
      "Graph",
      "Mathematics",
      "Memristor",
      "Neuromorphic engineering",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Milano",
        "given_name": "Gianluca"
      },
      {
        "surname": "Miranda",
        "given_name": "Enrique"
      },
      {
        "surname": "Ricciardi",
        "given_name": "Carlo"
      }
    ]
  },
  {
    "title": "Selective particle attention: Rapidly and flexibly selecting features for deep reinforcement learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.015",
    "abstract": "Deep Reinforcement Learning (RL) is often criticised for being data inefficient and inflexible to changes in task structure. Part of the reason for these issues is that Deep RL typically learns end-to-end using backpropagation, which results in task-specific representations. One approach for circumventing these problems is to apply Deep RL to existing representations that have been learned in a more task-agnostic fashion. However, this only partially solves the problem as the Deep RL algorithm learns a function of all pre-existing representations and is therefore still susceptible to data inefficiency and a lack of flexibility. Biological agents appear to solve this problem by forming internal representations over many tasks and only selecting a subset of these features for decision-making based on the task at hand; a process commonly referred to as selective attention. We take inspiration from selective attention in biological agents and propose a novel algorithm called Selective Particle Attention (SPA), which selects subsets of existing representations for Deep RL. Crucially, these subsets are not learned through backpropagation, which is slow and prone to overfitting, but instead via a particle filter that rapidly and flexibly identifies key subsets of features using only reward feedback. We evaluate SPA on two tasks that involve raw pixel input and dynamic changes to the task structure, and show that it greatly increases the efficiency and flexibility of downstream Deep RL algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000934",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Computer science",
      "Deep learning",
      "Economics",
      "Flexibility (engineering)",
      "Kalman filter",
      "Machine learning",
      "Management",
      "Mathematics",
      "Overfitting",
      "Particle filter",
      "Reinforcement learning",
      "Statistics",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Blakeman",
        "given_name": "Sam"
      },
      {
        "surname": "Mareschal",
        "given_name": "Denis"
      }
    ]
  },
  {
    "title": "Uncertainty-aware hierarchical segment-channel attention mechanism for reliable and interpretable multichannel signal classification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.019",
    "abstract": "Multichannel signal data analysis has been crucial in various industrial applications, such as human activity recognition, vehicle failure predictions, and manufacturing equipment monitoring. Recently, deep neural networks have come into use for multichannel signal data because of their ability to automatically extract useful features from complex multichannel signals. However, deep neural networks are black-box models whose internal working mechanisms cannot be put in a form readily understood by humans. To address this issue, we have proposed an uncertainty-aware hierarchical segment-channel attention model that consists of a time segment and channel level attentions. The hierarchical attention mechanism enables a neural network to identify important time segments and channels critical for prediction, making the model explainable. In addition, the model uses variational inferences to provide uncertainty information that yields a confidence interval that can be easily explained. We conducted experiments on simulated and real-world datasets to demonstrate the usefulness and applicability of our method. The results confirm that our method can attend to important time segments and sensors while achieving better classification performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000600",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Black box",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer science",
      "Data mining",
      "Deep neural networks",
      "Epistemology",
      "Interval (graph theory)",
      "Machine learning",
      "Mathematics",
      "Mechanism (biology)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "SIGNAL (programming language)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "Jiyoon"
      },
      {
        "surname": "Kim",
        "given_name": "Seoung Bum"
      }
    ]
  },
  {
    "title": "A differential Hebbian framework for biologically-plausible motor control",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.002",
    "abstract": "In this paper we explore a neural control architecture that is both biologically plausible, and capable of fully autonomous learning. It consists of feedback controllers that learn to achieve a desired state by selecting the errors that should drive them. This selection happens through a family of differential Hebbian learning rules that, through interaction with the environment, can learn to control systems where the error responds monotonically to the control signal. We next show that in a more general case, neural reinforcement learning can be coupled with a feedback controller to reduce errors that arise non-monotonically from the control signal. The use of feedback control can reduce the complexity of the reinforcement learning problem, because only a desired value must be learned, with the controller handling the details of how it is reached. This makes the function to be learned simpler, potentially allowing learning of more complex actions. We use simple examples to illustrate our approach, and discuss how it could be extended to hierarchical architectures.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000727",
    "keywords": [
      "Aerospace engineering",
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Differential (mechanical device)",
      "Engineering",
      "Evolutionary biology",
      "Function (biology)",
      "Hebbian theory",
      "Mathematical analysis",
      "Mathematics",
      "Monotonic function",
      "Programming language",
      "Reinforcement learning",
      "SIGNAL (programming language)",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Verduzco-Flores",
        "given_name": "Sergio"
      },
      {
        "surname": "Dorrell",
        "given_name": "William"
      },
      {
        "surname": "De Schutter",
        "given_name": "Erik"
      }
    ]
  },
  {
    "title": "SelfVIO: Self-supervised deep monocular Visual–Inertial Odometry and depth estimation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.005",
    "abstract": "In the last decade, numerous supervised deep learning approaches have been proposed for visual–inertial odometry (VIO) and depth map estimation, which require large amounts of labelled data. To overcome the data limitation, self-supervised learning has emerged as a promising alternative that exploits constraints such as geometric and photometric consistency in the scene. In this study, we present a novel self-supervised deep learning-based VIO and depth map recovery approach (SelfVIO) using adversarial training and self-adaptive visual–inertial sensor fusion. SelfVIO learns the joint estimation of 6 degrees-of-freedom (6-DoF) ego-motion and a depth map of the scene from unlabelled monocular RGB image sequences and inertial measurement unit (IMU) readings. The proposed approach is able to perform VIO without requiring IMU intrinsic parameters and/or extrinsic calibration between IMU and the camera. We provide comprehensive quantitative and qualitative evaluations of the proposed framework and compare its performance with state-of-the-art VIO, VO, and visual simultaneous localization and mapping (VSLAM) approaches on the KITTI, EuRoC and Cityscapes datasets. Detailed comparisons prove that SelfVIO outperforms state-of-the-art VIO approaches in terms of pose estimation and depth recovery, making it a promising approach among existing methods in the literature.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000752",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Inertial measurement unit",
      "Mobile robot",
      "Monocular",
      "Odometry",
      "Pose",
      "RGB color model",
      "Robot",
      "Simultaneous localization and mapping",
      "Visual odometry"
    ],
    "authors": [
      {
        "surname": "Almalioglu",
        "given_name": "Yasin"
      },
      {
        "surname": "Turan",
        "given_name": "Mehmet"
      },
      {
        "surname": "Saputra",
        "given_name": "Muhamad Risqi U."
      },
      {
        "surname": "de Gusmão",
        "given_name": "Pedro P.B."
      },
      {
        "surname": "Markham",
        "given_name": "Andrew"
      },
      {
        "surname": "Trigoni",
        "given_name": "Niki"
      }
    ]
  },
  {
    "title": "Towards improving fast adversarial training in multi-exit network",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.015",
    "abstract": "Adversarial examples are usually generated by adding adversarial perturbations on clean samples, designed to deceive the model to make wrong classifications. Adversarial robustness refers to the ability of a model to resist adversarial attacks. And currently, a mainstream method to enhance adversarial robustness is the Projected Gradient Descent (PGD). However, PGD is often criticized for being time-consuming during constructing adversarial examples. Fast adversarial training can improve the adversarial robustness in shorter time, but it only can train for a limited number of epochs, leading to sub-optimal performance. This paper demonstrates that the multi-exit network can reduce the impact of adversarial perturbations by outputting easily identified samples at early exits. Therefore, we can improve the adversarial robustness. Further, we find that the multi-exit network can prevent catastrophic overfitting existing in single-step adversarial training. Specifically, we find that, in the multi-exit network, (1) the norm of weights at a fully connected layer in a non-overfitted exit is much smaller than that in an overfitted exit; and (2) catastrophic overfitting occurs when the late exits have weight norms larger than the early exits. Based on these findings, we propose an approach to alleviating the catastrophic overfitting of the multi-exit network. Compared to PGD adversarial training, our approach can train a model with decreased time complexity and increased empirical robustness. Extensive experiments have been conducted to evaluate our approach against various adversarial attacks, and the experimental results demonstrate superior robustness accuracies on CIFAR-10, CIFAR-100 and SVHN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200048X",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Gene",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Overfitting",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Sihong"
      },
      {
        "surname": "Shen",
        "given_name": "Haojing"
      },
      {
        "surname": "Wang",
        "given_name": "Ran"
      },
      {
        "surname": "Wang",
        "given_name": "Xizhao"
      }
    ]
  },
  {
    "title": "Compression of Deep Neural Networks based on quantized tensor decomposition to implement on reconfigurable hardware platforms",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.024",
    "abstract": "Deep Neural Networks (DNNs) have been vastly and successfully employed in various artificial intelligence and machine learning applications (e.g., image processing and natural language processing). As DNNs become deeper and enclose more filters per layer, they incur high computational costs and large memory consumption to preserve their large number of parameters. Moreover, present processing platforms (e.g., CPU, GPU, and FPGA) have not enough internal memory, and hence external memory storage is needed. Hence deploying DNNs on mobile applications is difficult, considering the limited storage space, computation power, energy supply, and real-time processing requirements. In this work, using a method based on tensor decomposition, network parameters were compressed, thereby reducing access to external memory. This compression method decomposes the network layers’ weight tensor into a limited number of principal vectors such that (i) almost all the initial parameters can be retrieved, (ii) the network structure did not change, and (iii) the network quality after reproducing the parameters was almost similar to the original network in terms of detection accuracy. To optimize the realization of this method on FPGA, the tensor decomposition algorithm was modified while its convergence was not affected, and the reproduction of network parameters on FPGA was straightforward. The proposed algorithm reduced the parameters of ResNet50, VGG16, and VGG19 networks trained with Cifar10 and Cifar100 by almost 10 times.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200065X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computation",
      "Computer engineering",
      "Computer hardware",
      "Computer science",
      "Field-programmable gate array",
      "Mathematics",
      "Parallel computing",
      "Pure mathematics",
      "Tensor (intrinsic definition)"
    ],
    "authors": [
      {
        "surname": "Nekooei",
        "given_name": "Amirreza"
      },
      {
        "surname": "Safari",
        "given_name": "Saeed"
      }
    ]
  },
  {
    "title": "A class-specific mean vector-based weighted competitive and collaborative representation method for classification",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.021",
    "abstract": "Collaborative representation-based classification (CRC), as a typical kind of linear representation-based classification, has attracted more attention due to the effective and efficient pattern classification performance. However, the existing class-specific representations are not competitively learned from collaborative representation for achieving more informative pattern discrimination among all the classes. With the purpose of enhancing the power of competitive and discriminant representations among all the classes for favorable classification, we propose a novel CRC method called the class-specific mean vector-based weighted competitive and collaborative representation (CMWCCR). The CMWCCR mainly contains three discriminative constraints including the competitive, mean vector and weighted constraints that fully employ the discrimination information in different ways. In the competitive constraint, the representations from any one class and the other classes are adapted for learning competitive representations among all the classes. In the newly designed mean vector constraint, the mean vectors of all the class-specific training samples with the corresponding class-specific representations are taken into account to further enhance the competitive representations. In the devised weighted constraint, the class-specific weights are constrained on the representation coefficients to make the similar classes have more representation contributions to strengthening the discrimination among all the class-specific representations. Thus, these three constraints in the unified CMWCCR model can complement each other for competitively learning the discriminative class-specific representations. To verify the CMWCCR classification performance, the extensive experiments are conducted on twenty-eight data sets in comparisons with the state-of-the-art representation-based classification methods. The experimental results show that the proposed CMWCCR is an effective and robust CRC method with satisfactory performance.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000624",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Class (philosophy)",
      "Complement (music)",
      "Complementation",
      "Computer science",
      "Constraint (computer-aided design)",
      "Discriminative model",
      "Gene",
      "Geometry",
      "Law",
      "Linear discriminant analysis",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Phenotype",
      "Political science",
      "Politics",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Gou",
        "given_name": "Jianping"
      },
      {
        "surname": "He",
        "given_name": "Xin"
      },
      {
        "surname": "Lu",
        "given_name": "Junyu"
      },
      {
        "surname": "Ma",
        "given_name": "Hongxing"
      },
      {
        "surname": "Ou",
        "given_name": "Weihua"
      },
      {
        "surname": "Yuan",
        "given_name": "Yunhao"
      }
    ]
  },
  {
    "title": "Event-triggered delayed impulsive control for nonlinear systems with application to complex neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.007",
    "abstract": "This paper studies the Lyapunov stability of nonlinear systems and the synchronization of complex neural networks in the framework of event-triggered delayed impulsive control (ETDIC), where the effect of time delays in impulses is fully considered. Based on the Lyapunov-based event-triggered mechanism (ETM), some sufficient conditions are presented to avoid Zeno behavior and achieve globally asymptotical stability of the addressed system. In the framework of event-triggered impulse control (ETIC), control input is only generated at state-dependent triggered instants and there is no any control input during two consecutive triggered impulse instants, which can greatly reduce resource consumption and control waste. The contributions of this paper can be summarized as follows: Firstly, compared with the classical ETIC, our results not only provide the well-designed ETM to determine the impulse time sequence, but also fully extract the information of time delays in impulses and integrate it into the dynamic analysis of the system. Secondly, it is shown that the time delays in impulses in our results exhibit positive effects, that is, it may contribute to stabilizing a system and achieve better performance. Thirdly, as an application of ETDIC strategies, we apply the proposed theoretical results to synchronization problem of complex neural networks. Some sufficient conditions to ensure the synchronization of complex neural networks are presented, where the information of time delays in impulses is fully fetched in these conditions. Finally, two numerical examples are provided to show the effectiveness and validity of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000776",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Impulse (physics)",
      "Impulse control",
      "Lyapunov function",
      "Lyapunov stability",
      "Nonlinear system",
      "Physics",
      "Psychology",
      "Psychotherapist",
      "Quantum mechanics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Mingzhu"
      },
      {
        "surname": "Li",
        "given_name": "Xiaodi"
      },
      {
        "surname": "Duan",
        "given_name": "Peiyong"
      }
    ]
  },
  {
    "title": "Boosting the transferability of adversarial examples via stochastic serial attack",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.025",
    "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial examples, which are crafted by imposing mild perturbation on clean ones. An intriguing property of adversarial examples is that they are efficient among different DNNs. Thus transfer-based attacks against DNNs become an increasing concern. In this scenario, attackers devise adversarial instances based on the local model without feedback information from the target one. Unfortunately, most existing transfer-based attack methods only employ a single local model to generate adversarial examples. It results in poor transferability because of overfitting to the local model. Although several ensemble attacks have been proposed, the transferability of adversarial examples merely have a slight increase. Meanwhile, these methods need high memory cost during the training process. To this end, we propose a novel attack strategy called stochastic serial attack (SSA). It adopts a serial strategy to attack local models, which reduces memory consumption compared to parallel attacks. Moreover, since local models are stochastically selected from a large model set, SSA can ensure that the adversarial examples do not overfit specific weaknesses of local source models. Extensive experiments on the ImageNet dataset and NeurIPS 2017 adversarial competition dataset show the effectiveness of SSA in improving the transferability of adversarial examples and reducing the memory consumption of the training process.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000661",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Boosting (machine learning)",
      "Computer science",
      "Deep neural networks",
      "Logit",
      "Machine learning",
      "Operating system",
      "Overfitting",
      "Process (computing)",
      "Transferability"
    ],
    "authors": [
      {
        "surname": "Hao",
        "given_name": "Lingguang"
      },
      {
        "surname": "Hao",
        "given_name": "Kuangrong"
      },
      {
        "surname": "Wei",
        "given_name": "Bing"
      },
      {
        "surname": "Tang",
        "given_name": "Xue-song"
      }
    ]
  },
  {
    "title": "Predicting progression of Alzheimer’s disease using forward-to-backward bi-directional network with integrative imputation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.03.016",
    "abstract": "If left untreated, Alzheimer’s disease (AD) is a leading cause of slowly progressive dementia. Therefore, it is critical to detect AD to prevent its progression. In this study, we propose a bidirectional progressive recurrent network with imputation (BiPro) that uses longitudinal data, including patient demographics and biomarkers of magnetic resonance imaging (MRI), to forecast clinical diagnoses and phenotypic measurements at multiple timepoints. To compensate for missing observations in the longitudinal data, we use an imputation module to inspect both temporal and multivariate relations associated with the mean and forward relations inherent in the time series data. To encode the imputed information, we define a modification of the long short-term memory (LSTM) cell by using a progressive module to compute the progression score of each biomarker between the given timepoint and the baseline through a negative exponential function. These features are used for the prediction task. The proposed system is an end-to-end deep recurrent network that can accomplish multiple tasks at the same time, including (1) imputing missing values, (2) forecasting phenotypic measurements, and (3) predicting the clinical status of a patient based on longitudinal data. We experimented on 1,335 participants from The Alzheimer’s Disease Prediction of Longitudinal Evolution (TADPOLE) challenge cohort. The proposed method achieved a mean area under the receiver-operating characteristic curve (mAUC) of 78% for predicting the clinical status of patients, a mean absolute error (MAE) of 3 . 5 m l for forecasting MRI biomarkers, and an MAE of 6 . 9 m l for missing value imputation. The results confirm that our proposed model outperforms prevalent approaches, and can be used to minimize the progression of Alzheimer’s disease.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000946",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Imputation (statistics)",
      "Machine learning",
      "Missing data",
      "Multivariate statistics",
      "Receiver operating characteristic"
    ],
    "authors": [
      {
        "surname": "Ho",
        "given_name": "Ngoc-Huynh"
      },
      {
        "surname": "Yang",
        "given_name": "Hyung-Jeong"
      },
      {
        "surname": "Kim",
        "given_name": "Jahae"
      },
      {
        "surname": "Dao",
        "given_name": "Duy-Phuong"
      },
      {
        "surname": "Park",
        "given_name": "Hyuk-Ro"
      },
      {
        "surname": "Pant",
        "given_name": "Sudarshan"
      }
    ]
  },
  {
    "title": "Significance of event related causality (ERC) in eloquent neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.002",
    "abstract": "Neural activity emerges and propagates swiftly between brain areas. Investigation of these transient large-scale flows requires sophisticated statistical models. We present a method for assessing the statistical confidence of event-related neural propagation. Furthermore, we propose a criterion for statistical model selection, based on both goodness of fit and width of confidence intervals. We show that event-related causality (ERC) with two-dimensional (2D) moving average, is an efficient estimator of task-related neural propagation and that it can be used to determine how different cognitive task demands affect the strength and directionality of neural propagation across human cortical networks. Using electrodes surgically implanted on the surface of the brain for clinical testing prior to epilepsy surgery, we recorded electrocorticographic (ECoG) signals as subjects performed three naming tasks: naming of ambiguous and unambiguous visual objects, and as a contrast, naming to auditory description. ERC revealed robust and statistically significant patterns of high gamma activity propagation, consistent with models of visually and auditorily cued word production. Interestingly, ambiguous visual stimuli elicited more robust propagation from visual to auditory cortices relative to unambiguous stimuli, whereas naming to auditory description elicited propagation in the opposite direction, consistent with recruitment of modalities other than those of the stimulus during object recognition and naming. The new method introduced here is uniquely suitable to both research and clinical applications and can be used to estimate the statistical significance of neural propagation for both cognitive neuroscientific studies and functional brain mapping prior to resective surgery for epilepsy and brain tumors.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000351",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognition",
      "Computer science",
      "Neuroscience",
      "Psychology",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Korzeniewska",
        "given_name": "Anna"
      },
      {
        "surname": "Mitsuhashi",
        "given_name": "Takumi"
      },
      {
        "surname": "Wang",
        "given_name": "Yujing"
      },
      {
        "surname": "Asano",
        "given_name": "Eishi"
      },
      {
        "surname": "Franaszczuk",
        "given_name": "Piotr J."
      },
      {
        "surname": "Crone",
        "given_name": "Nathan E."
      }
    ]
  },
  {
    "title": "Synchronization issue of coupled neural networks based on flexible impulse control",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.020",
    "abstract": "The global exponential synchronization issue of coupled neural networks with time-delayed impulses is investigated in this paper. On the basis of the characteristics of coupled neural networks and theorems, we have built a novel coupled systems model. In order to fit the real situation, the impulses are flexible and it can beyond the impulsive interval under certain conditions in this paper. Therefore, our results are less restrictive and more practical compared to existing research. Besides, by using average impulsive delay (AID) and average impulsive interval (AII), we investigate two different effects of impulses on synchronization respectively and get a few adequate conditions for different types of synchronization. Finally, there are two examples of numerical simulations presented to illustrate the efficiency of the conclusions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000302",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Impulse (physics)",
      "Interval (graph theory)",
      "Mathematics",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Xiu",
        "given_name": "Ruihong"
      },
      {
        "surname": "Zhang",
        "given_name": "Wei"
      },
      {
        "surname": "Zhou",
        "given_name": "Zichuan"
      }
    ]
  },
  {
    "title": "Flexibly regularized mixture models and application to image segmentation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.010",
    "abstract": "Probabilistic finite mixture models are widely used for unsupervised clustering. These models can often be improved by adapting them to the topology of the data. For instance, in order to classify spatially adjacent data points similarly, it is common to introduce a Laplacian constraint on the posterior probability that each data point belongs to a class. Alternatively, the mixing probabilities can be treated as free parameters, while assuming Gauss–Markov or more complex priors to regularize those mixing probabilities. However, these approaches are constrained by the shape of the prior and often lead to complicated or intractable inference. Here, we propose a new parametrization of the Dirichlet distribution to flexibly regularize the mixing probabilities of over-parametrized mixture distributions. Using the Expectation–Maximization algorithm, we show that our approach allows us to define any linear update rule for the mixing probabilities, including spatial smoothing regularization as a special case. We then show that this flexible design can be extended to share class information between multiple mixture models. We apply our algorithm to artificial and natural image segmentation tasks, and we provide quantitative and qualitative comparison of the performance of Gaussian and Student-t mixtures on the Berkeley Segmentation Dataset. We also demonstrate how to propagate class information across the layers of deep convolutional neural networks in a probabilistically optimal way, suggesting a new interpretation for feedback signals in biological visual systems. Our flexible approach can be easily generalized to adapt probabilistic mixture models to arbitrary data topologies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000430",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Image (mathematics)",
      "Image segmentation",
      "Pattern recognition (psychology)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Vacher",
        "given_name": "Jonathan"
      },
      {
        "surname": "Launay",
        "given_name": "Claire"
      },
      {
        "surname": "Coen-Cagli",
        "given_name": "Ruben"
      }
    ]
  },
  {
    "title": "Detecting cell assemblies by NMF-based clustering from calcium imaging data",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.023",
    "abstract": "A large number of neurons form cell assemblies that process information in the brain. Recent developments in measurement technology, one of which is calcium imaging, have made it possible to study cell assemblies. In this study, we aim to extract cell assemblies from calcium imaging data. We propose a clustering approach based on non-negative matrix factorization (NMF). The proposed approach first obtains a similarity matrix between neurons by NMF and then performs spectral clustering on it. The application of NMF entails the problem of model selection. The number of bases in NMF affects the result considerably, and a suitable selection method is yet to be established. We attempt to resolve this problem by model averaging with a newly defined estimator based on NMF. Experiments on simulated data suggest that the proposed approach is superior to conventional correlation-based clustering methods over a wide range of sampling rates. We also analyzed calcium imaging data of sleeping/waking mice and the results suggest that the size of the cell assembly depends on the degree and spatial extent of slow wave generation in the cerebral cortex.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000338",
    "keywords": [
      "Artificial intelligence",
      "Calcium",
      "Calcium imaging",
      "Chemistry",
      "Cluster analysis",
      "Computer science",
      "Data mining",
      "Eigenvalues and eigenvectors",
      "Image (mathematics)",
      "Matrix decomposition",
      "Non-negative matrix factorization",
      "Organic chemistry",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Selection (genetic algorithm)",
      "Similarity (geometry)"
    ],
    "authors": [
      {
        "surname": "Nagayama",
        "given_name": "Mizuo"
      },
      {
        "surname": "Aritake",
        "given_name": "Toshimitsu"
      },
      {
        "surname": "Hino",
        "given_name": "Hideitsu"
      },
      {
        "surname": "Kanda",
        "given_name": "Takeshi"
      },
      {
        "surname": "Miyazaki",
        "given_name": "Takehiro"
      },
      {
        "surname": "Yanagisawa",
        "given_name": "Masashi"
      },
      {
        "surname": "Akaho",
        "given_name": "Shotaro"
      },
      {
        "surname": "Murata",
        "given_name": "Noboru"
      }
    ]
  },
  {
    "title": "Possibilistic classification by support vector networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.007",
    "abstract": "In many real-world classification problems, the available information is often uncertain. In order to effectively describe the inherent vagueness and improve the classification performance, this paper proposes a novel possibilistic classification algorithm using support vector machines (SVMs). Based on possibility theory, the proposed algorithm aims at finding a maximal-margin fuzzy hyperplane by solving a fuzzy mathematical optimization problem Moreover, the decision function of the proposed approach is generalized such that the values assigned to the data vectors fall within a specified range and indicate the membership grade of these data vectors in the positive class. The proposed algorithm retains the advantages of fuzzy set theory and SVM theory. The proposed approach is more robust for handling data corrupted by outliers. Moreover, the structural risk minimization principle of SVMs enables the proposed approach to effectively classify the unseen data. Furthermore, the proposed algorithm has additional advantage of using vagueness parameter v for controlling the bounds on fractions of support vectors and errors. The extensive experiments performed on benchmark datasets and real applications demonstrate that the proposed algorithm has satisfactory generalization accuracy and better describes the inherent vagueness in the given dataset.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000405",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Fuzzy logic",
      "Fuzzy set",
      "Generalization",
      "Geometry",
      "Hyperplane",
      "Machine learning",
      "Margin (machine learning)",
      "Mathematical analysis",
      "Mathematics",
      "Outlier",
      "Pattern recognition (psychology)",
      "Structural risk minimization",
      "Support vector machine",
      "Vagueness"
    ],
    "authors": [
      {
        "surname": "Hao",
        "given_name": "Pei-Yi"
      },
      {
        "surname": "Chiang",
        "given_name": "Jung-Hsien"
      },
      {
        "surname": "Chen",
        "given_name": "Yu-De"
      }
    ]
  },
  {
    "title": "Modeling learnable electrical synapse for high precision spatio-temporal recognition",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.006",
    "abstract": "Bio-inspired recipes are being introduced to artificial neural networks for the efficient processing of spatio-temporal tasks. Among them, Leaky Integrate and Fire (LIF) model is the most remarkable one thanks to its temporal processing capability, lightweight model structure, and well investigated direct training methods. However, most learnable LIF networks generally take neurons as independent individuals that communicate via chemical synapses, leaving electrical synapses all behind. On the contrary, it has been well investigated in biological neural networks that the inter-neuron electrical synapse takes a great effect on the coordination and synchronization of generating action potentials. In this work, we are engaged in modeling such electrical synapses in artificial LIF neurons, where membrane potentials propagate to neighbor neurons via convolution operations, and the refined neural model ECLIF is proposed. We then build deep networks using ECLIF and trained them using a back-propagation-through-time algorithm. We found that the proposed network has great accuracy improvement over traditional LIF on five datasets and achieves high accuracy on them. In conclusion, it reveals that the introduction of the electrical synapse is an important factor for achieving high accuracy on realistic spatio-temporal tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000399",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Channel (broadcasting)",
      "Chemistry",
      "Computer science",
      "Convolution (computer science)",
      "Deep learning",
      "Electrical Synapses",
      "Gap junction",
      "Intracellular",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Synapse",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Wu",
        "given_name": "Zhenzhi"
      },
      {
        "surname": "Zhang",
        "given_name": "Zhihong"
      },
      {
        "surname": "Gao",
        "given_name": "Huanhuan"
      },
      {
        "surname": "Qin",
        "given_name": "Jun"
      },
      {
        "surname": "Zhao",
        "given_name": "Rongzhen"
      },
      {
        "surname": "Zhao",
        "given_name": "Guangshe"
      },
      {
        "surname": "Li",
        "given_name": "Guoqi"
      }
    ]
  },
  {
    "title": "Finite-time and sampled-data synchronization of complex dynamical networks subject to average dwell-time switching signal",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.013",
    "abstract": "This study deals with the finite-time synchronization problem of a class of switched complex dynamical networks (CDNs) with distributed coupling delays via sampled-data control. First, the dynamical model is studied with coupling delays in more detail. The sampling system is then converted to a continuous time-delay system using an input delay technique. We obtain some unique and less conservative criteria on exponential stability using the Lyapunov–Krasovskii functional (LKF), which is generated with a Kronecker product, linear matrix inequalities (LMIs), and integral inequality. Furthermore, some sufficient criteria are derived by an average dwell-time method and determine the finite-time boundedness of CDNs with switching signal. The proposed sufficient conditions can be represented in the form of LMIs. Finally, numerical examples are given to show that the suggested strategy is feasible.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000466",
    "keywords": [
      "Artificial intelligence",
      "Clinical psychology",
      "Combinatorics",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Dwell time",
      "Exponential stability",
      "Filter (signal processing)",
      "Kronecker delta",
      "Kronecker product",
      "Machine learning",
      "Mathematics",
      "Medicine",
      "Nonlinear system",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "SIGNAL (programming language)",
      "Sampling (signal processing)",
      "Stability (learning theory)",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Gunasekaran",
        "given_name": "Nallappan"
      },
      {
        "surname": "Ali",
        "given_name": "M. Syed"
      },
      {
        "surname": "Arik",
        "given_name": "Sabri"
      },
      {
        "surname": "Ghaffar",
        "given_name": "H.I. Abdul"
      },
      {
        "surname": "Diab",
        "given_name": "Ahmed A. Zaki"
      }
    ]
  },
  {
    "title": "Deep Bayesian Unsupervised Lifelong Learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.001",
    "abstract": "Lifelong Learning (LL) refers to the ability to continually learn and solve new problems with incremental available information over time while retaining previous knowledge. Much attention has been given lately to Supervised Lifelong Learning (SLL) with a stream of labelled data. In contrast, we focus on resolving challenges in Unsupervised Lifelong Learning (ULL) with streaming unlabelled data when the data distribution and the unknown class labels evolve over time. Bayesian framework is natural to incorporate past knowledge and sequentially update the belief with new data. We develop a fully Bayesian inference framework for ULL with a novel end-to-end Deep Bayesian Unsupervised Lifelong Learning (DBULL) algorithm, which can progressively discover new clusters without forgetting the past with unlabelled data while learning latent representations. To efficiently maintain past knowledge, we develop a novel knowledge preservation mechanism via sufficient statistics of the latent representation for raw data. To detect the potential new clusters on the fly, we develop an automatic cluster discovery and redundancy removal strategy in our inference inspired by Nonparametric Bayesian statistics techniques. We demonstrate the effectiveness of our approach using image and text corpora benchmark datasets in both LL and batch settings.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200034X",
    "keywords": [
      "Artificial intelligence",
      "Bayesian inference",
      "Bayesian probability",
      "Benchmark (surveying)",
      "Computer science",
      "Forgetting",
      "Geodesy",
      "Geography",
      "Inference",
      "Lifelong learning",
      "Linguistics",
      "Machine learning",
      "Pedagogy",
      "Philosophy",
      "Psychology",
      "Unsupervised learning"
    ],
    "authors": [
      {
        "surname": "Zhao",
        "given_name": "Tingting"
      },
      {
        "surname": "Wang",
        "given_name": "Zifeng"
      },
      {
        "surname": "Masoomi",
        "given_name": "Aria"
      },
      {
        "surname": "Dy",
        "given_name": "Jennifer"
      }
    ]
  },
  {
    "title": "Joint learning of multiple Granger causal networks via non-convex regularizations: Inference of group-level brain connectivity",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.005",
    "abstract": "This paper considers joint learning of multiple sparse Granger graphical models to discover underlying common and differential Granger causality (GC) structures across multiple time series. This can be applied to drawing group-level brain connectivity inferences from a homogeneous group of subjects or discovering network differences among groups of signals collected under heterogeneous conditions. By recognizing that the GC of a single multivariate time series can be characterized by common zeros of vector autoregressive (VAR) lag coefficients, a group sparse prior is included in joint regularized least-squares estimations of multiple VAR models. Group-norm regularizations based on group- and fused-lasso penalties encourage a decomposition of multiple networks into a common GC structure, with other remaining parts defined in individual-specific networks. Prior information about sparseness and sparsity patterns of desired GC networks are incorporated as relative weights, while a non-convex group norm in the penalty is proposed to enhance the accuracy of network estimation in low-sample settings. Extensive numerical results on simulations illustrated our method’s improvements over existing sparse estimation approaches on GC network sparsity recovery. Our methods were also applied to available resting-state fMRI time series from the ADHD-200 data sets to learn the differences of causality mechanisms, called effective brain connectivity, between adolescents with ADHD and typically developing children. Our analysis revealed that parts of the causality differences between the two groups often resided in the orbitofrontal region and areas associated with the limbic system, which agreed with clinical findings and data-driven results in previous studies.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000387",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Autoregressive model",
      "Computer science",
      "Econometrics",
      "Granger causality",
      "Inference",
      "Machine learning",
      "Mathematics",
      "Multivariate statistics",
      "Pattern recognition (psychology)"
    ],
    "authors": [
      {
        "surname": "Manomaisaowapak",
        "given_name": "Parinthorn"
      },
      {
        "surname": "Songsiri",
        "given_name": "Jitkomut"
      }
    ]
  },
  {
    "title": "Zero-Hopf Bifurcation of a memristive synaptic Hopfield neural network with time delay",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.009",
    "abstract": "This paper proposes a novel memristive synaptic Hopfield neural network (MHNN) with time delay by using a memristor synapse to simulate the electromagnetic induced current caused by the membrane potential difference between two adjacent neurons. First, some sufficient conditions of zero bifurcation and zero-Hopf bifurcation are obtained by choosing time delay and coupling strength of memristor as bifurcation parameters. Then, the third-order normal form of zero-Hopf bifurcation is obtained. By analyzing the obtained normal form, six dynamic regions are found on the plane with coupling strength of memristor and time delay as abscissa and ordinate. There are some interesting dynamics in these areas, i.e., the coupling strength of memristor can affect the number and dynamics of system equilibrium, time delay can contribute to both trivial equilibrium and non-trivial equilibrium losing stability and generating periodic solutions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000429",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Bifurcation",
      "Biological applications of bifurcation theory",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Coupling (piping)",
      "Hopf bifurcation",
      "Hopfield network",
      "Machine learning",
      "Materials science",
      "Mathematics",
      "Memristor",
      "Metallurgy",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Saddle-node bifurcation",
      "Stability (learning theory)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Dong",
        "given_name": "Tao"
      },
      {
        "surname": "Gong",
        "given_name": "Xiaomei"
      },
      {
        "surname": "Huang",
        "given_name": "Tingwen"
      }
    ]
  },
  {
    "title": "Sign Stochastic Gradient Descents without bounded gradient assumption for the finite sum minimization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.012",
    "abstract": "Sign-based Stochastic Gradient Descents (Sign-based SGDs) use the signs of the stochastic gradients for communication costs reduction. Nevertheless, current convergence results of sign-based SGDs applied to the finite sum optimization are established on the bounded assumption of the gradient, which fails to hold in various cases. This paper presents a convergence framework about sign-based SGDs with the elimination of the bounded gradient assumption. The ergodic convergence rates are provided only with the smooth assumption of the objective functions. The Sign Stochastic Gradient Descent (signSGD) and its two variants, including majority vote and zeroth-order version, are developed for different application settings. Our framework also removes the bounded gradient assumption used in the previous analysis of these three algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000454",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Ergodic theory",
      "Gradient descent",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Minification",
      "Sign (mathematics)",
      "Stochastic gradient descent"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Tao"
      },
      {
        "surname": "Li",
        "given_name": "Dongsheng"
      }
    ]
  },
  {
    "title": "Transition dynamics and optogenetic controls of generalized periodic epileptiform discharges",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.022",
    "abstract": "This paper aims to analyze possible mechanisms underlying the generation of generalized periodic epileptiform discharges (GPEDs), especially to design targeted optogenetic regulation strategies. First and foremost, inspired by existing physiological experiments, we propose a new computational framework by introducing a second inhibitory neuronal population and related synaptic connections into the classic Liley mean field model. The improved model can simulate the basic normal and abnormal brain activities mentioned in previous studies, but much to our relief, it perfectly reproduces some types of GPEDs that match the clinical records. Specifically, results show that disinhibitory synaptic connections between inhibitory interneuronal populations are closely related to the occurrence, transition and termination of GPEDs, including delaying the occurrence of GPEDs caused by the excitatory AMPAergic autapses and regulating the transition process of GPEDs bidirectionally, which support the conjecture that selective changes of synaptic connections can trigger GPEDs. Additionally, we creatively offer six optogenetic strategies with dual targets. They can all control GPEDs well, just as experiments reveal that optogenetic stimulation of inhibitory interneurons can suppress abnormal activities in epilepsy or other brain diseases. More importantly, 1:1 coordinated reset stimulation with one period rest is concluded as the optimal strategy after taking into account the energy consumption and control effect. Hope these results provide feasible references for pathophysiological mechanisms of GPEDs.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000326",
    "keywords": [
      "Biology",
      "Computer science",
      "Environmental health",
      "Excitatory postsynaptic potential",
      "Inhibitory postsynaptic potential",
      "Local field potential",
      "Medicine",
      "Neuroscience",
      "Optogenetics",
      "Population"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Zhuan"
      },
      {
        "surname": "Zhang",
        "given_name": "Honghui"
      },
      {
        "surname": "Cao",
        "given_name": "Zilu"
      },
      {
        "surname": "Yan",
        "given_name": "Luyao"
      },
      {
        "surname": "Zhao",
        "given_name": "Yuzhi"
      },
      {
        "surname": "Du",
        "given_name": "Lin"
      },
      {
        "surname": "Deng",
        "given_name": "Zichen"
      }
    ]
  },
  {
    "title": "Deep adversarial transition learning using cross-grafted generative stacks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.011",
    "abstract": "As a common approach of deep domain adaptation in computer vision, current works have mainly focused on learning domain-invariant features from different domains, achieving limited success in transfer learning. In this paper, we present a novel “deep adversarial transition learning” (DATL) framework that bridges the domain gap by generating some intermediate, transitional spaces between the source and target domains through the employment of adjustable, cross-grafted generative network stacks and effective adversarial learning between transitions. Specifically, variational auto-encoders (VAEs) are constructed for the domains, and bidirectional transitions are formed by cross-grafting the VAEs’ decoder stacks. Generative adversarial networks are then employed to map the target domain data to the label space of the source domain, which is achieved by aligning the transitions initiated by different domains. This results in a new, effective learning paradigm, where training and testing are carried out in the associated transitional spaces instead of the original domains. Experimental results demonstrate that our method outperforms the state-of-the-art on a number of unsupervised domain adaptation benchmarks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000442",
    "keywords": [
      "Adversarial system",
      "Algorithm",
      "Artificial intelligence",
      "Autoencoder",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Deep learning",
      "Domain (mathematical analysis)",
      "Encoder",
      "Gene",
      "Generative grammar",
      "Invariant (physics)",
      "Machine learning",
      "Mathematical analysis",
      "Mathematical physics",
      "Mathematics",
      "Operating system",
      "Theoretical computer science",
      "Transition (genetics)"
    ],
    "authors": [
      {
        "surname": "Hou",
        "given_name": "Jinyong"
      },
      {
        "surname": "Ding",
        "given_name": "Xuejie"
      },
      {
        "surname": "Deng",
        "given_name": "Jeremiah D."
      },
      {
        "surname": "Cranefield",
        "given_name": "Stephen"
      }
    ]
  },
  {
    "title": "Cross-domain heterogeneous residual network for single image super-resolution",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.008",
    "abstract": "Single image super-resolution is an ill-posed problem, whose purpose is to acquire a high-resolution image from its degraded observation. Existing deep learning-based methods are compromised on their performance and speed due to the heavy design (i.e., huge model size) of networks. In this paper, we propose a novel high-performance cross-domain heterogeneous residual network for super-resolved image reconstruction. Our network models heterogeneous residuals between different feature layers by hierarchical residual learning. In outer residual learning, dual-domain enhancement modules extract the frequency-domain information to reinforce the space-domain features of network mapping. In middle residual learning, wide-activated residual-in-residual dense blocks are constructed by concatenating the outputs from previous blocks as the inputs into all subsequent blocks for better parameter efficacy. In inner residual learning, wide-activated residual attention blocks are introduced to capture direction- and location-aware feature maps. The proposed method was evaluated on four benchmark datasets, indicating that it can construct the high-quality super-resolved images and achieve the state-of-the-art performance. Code and pre-trained models are available at https://github.com/zhangyongqin/HRN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000417",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Code (set theory)",
      "Computer science",
      "Data mining",
      "Deep learning",
      "Domain (mathematical analysis)",
      "Feature (linguistics)",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Programming language",
      "Residual",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "Ji",
        "given_name": "Li"
      },
      {
        "surname": "Zhu",
        "given_name": "Qinghui"
      },
      {
        "surname": "Zhang",
        "given_name": "Yongqin"
      },
      {
        "surname": "Yin",
        "given_name": "Juanjuan"
      },
      {
        "surname": "Wei",
        "given_name": "Ruyi"
      },
      {
        "surname": "Xiao",
        "given_name": "Jinsheng"
      },
      {
        "surname": "Xiao",
        "given_name": "Deqiang"
      },
      {
        "surname": "Zhao",
        "given_name": "Guoying"
      }
    ]
  },
  {
    "title": "Backpropagation Neural Tree",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.003",
    "abstract": "We propose a novel algorithm called Backpropagation Neural Tree (BNeuralT), which is a stochastic computational dendritic tree. BNeuralT takes random repeated inputs through its leaves and imposes dendritic nonlinearities through its internal connections like a biological dendritic tree would do. Considering the dendritic-tree like plausible biological properties, BNeuralT is a single neuron neural tree model with its internal sub-trees resembling dendritic nonlinearities. BNeuralT algorithm produces an ad hoc neural tree which is trained using a stochastic gradient descent optimizer like gradient descent (GD), momentum GD, Nesterov accelerated GD, Adagrad, RMSprop, or Adam. BNeuralT training has two phases, each computed in a depth-first search manner: the forward pass computes neural tree’s output in a post-order traversal, while the error backpropagation during the backward pass is performed recursively in a pre-order traversal. A BNeuralT model can be considered a minimal subset of a neural network (NN), meaning it is a “thinned” NN whose complexity is lower than an ordinary NN. Our algorithm produces high-performing and parsimonious models balancing the complexity with descriptive ability on a wide variety of machine learning problems: classification, regression, and pattern recognition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000363",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backpropagation",
      "Computer science",
      "Gradient descent",
      "Mathematical analysis",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Stochastic gradient descent",
      "Tree (set theory)",
      "Tree traversal"
    ],
    "authors": [
      {
        "surname": "Ojha",
        "given_name": "Varun"
      },
      {
        "surname": "Nicosia",
        "given_name": "Giuseppe"
      }
    ]
  },
  {
    "title": "Incremental learning algorithm for large-scale semi-supervised ordinal regression",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.02.004",
    "abstract": "As a special case of multi-classification, ordinal regression (also known as ordinal classification) is a popular method to tackle the multi-class problems with samples marked by a set of ranks. Semi-supervised ordinal regression (SSOR) is especially important for data mining applications because semi-supervised learning can make use of the unlabeled samples to train a high-quality learning model. However, the training of large-scale SSOR is still an open question due to its complicated formulations and non-convexity to the best of our knowledge. To address this challenging problem, in this paper, we propose an incremental learning algorithm for SSOR (IL-SSOR), which can directly update the solution of SSOR based on the KKT conditions. More critically, we analyze the finite convergence of IL-SSOR which guarantees that SSOR can converge to a local minimum based on the framework of concave–convex procedure. To the best of our knowledge, the proposed new algorithm is the first efficient on-line learning algorithm for SSOR with local minimum convergence guarantee. The experimental results show, IL-SSOR can achieve better generalization than other semi-supervised multi-class algorithms. Compared with other semi-supervised ordinal regression algorithms, our experimental results show that IL-SSOR can achieve similar generalization with less running time.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000375",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Convergence (economics)",
      "Economic growth",
      "Economics",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Ordinal Scale",
      "Ordinal data",
      "Ordinal regression",
      "Physics",
      "Quantum mechanics",
      "Scale (ratio)",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Haiyan"
      },
      {
        "surname": "Jia",
        "given_name": "Yizhen"
      },
      {
        "surname": "Ge",
        "given_name": "Jiaming"
      },
      {
        "surname": "Gu",
        "given_name": "Bin"
      }
    ]
  },
  {
    "title": "Anomalous diffusion dynamics of learning in deep neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.019",
    "abstract": "Learning in deep neural networks (DNNs) is implemented through minimizing a highly non-convex loss function, typically by a stochastic gradient descent (SGD) method. This learning process can effectively find generalizable solutions at flat minima. In this study, we present a novel account of how such effective deep learning emerges through the interactions of the SGD and the geometrical structure of the loss landscape. We find that the SGD exhibits rich, complex dynamics when navigating through the loss landscape; initially, the SGD exhibits superdiffusion, which attenuates gradually and changes to subdiffusion at long times when approaching a solution. Such learning dynamics happen ubiquitously in different DNN types such as ResNet, VGG-like networks and Vision Transformers; similar results emerge for various batch size and learning rate settings. The superdiffusion process during the initial learning phase indicates that the motion of SGD along the loss landscape possesses intermittent, big jumps; this non-equilibrium property enables the SGD to effectively explore the loss landscape. By adapting methods developed for studying energy landscapes in complex physical systems, we find that such superdiffusive learning processes are due to the interactions of the SGD and the fractal-like regions of the loss landscape. We further develop a phenomenological model to demonstrate the mechanistic role of the fractal-like loss landscape in enabling the SGD to effectively find flat minima. Our results reveal the effectiveness of SGD in deep learning from a novel perspective and have implications for designing efficient deep neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000296",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Deep learning",
      "Energy landscape",
      "Fractal",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Maxima and minima",
      "Physics",
      "Statistical physics",
      "Stochastic gradient descent",
      "Thermodynamics"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Guozhang"
      },
      {
        "surname": "Qu",
        "given_name": "Cheng Kevin"
      },
      {
        "surname": "Gong",
        "given_name": "Pulin"
      }
    ]
  },
  {
    "title": "Improving data augmentation for low resource speech-to-text translation with diverse paraphrasing",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.016",
    "abstract": "High quality end-to-end speech translation model relies on a large scale of speech-to-text training data, which is usually scarce or even unavailable for some low-resource language pairs. To overcome this, we propose a target-side data augmentation method for low-resource language speech translation. In particular, we first generate large-scale target-side paraphrases based on a paraphrase generation model which incorporates several statistical machine translation (SMT) features and the commonly used recurrent neural network (RNN) feature. Then, a filtering model which consists of semantic similarity and speech–word pair co-occurrence was proposed to select the highest scoring source speech–target paraphrase pairs from candidates. Experimental results on English, Arabic, German, Latvian, Estonian, Slovenian and Swedish paraphrase generation show that the proposed method achieves significant and consistent improvements over several strong baseline models on PPDB datasets (http://paraphrase.org/). To introduce the results of paraphrase generation into the low-resource speech translation, we propose two strategies: audio–text pairs recombination and multiple references training. Experimental results show that the speech translation models trained on new audio–text datasets which combines the paraphrase generation results lead to substantial improvements over baselines, especially on low-resource languages.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000260",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Computer science",
      "Gene",
      "Machine translation",
      "Messenger RNA",
      "Natural language processing",
      "Paraphrase",
      "Speech recognition",
      "Translation (biology)"
    ],
    "authors": [
      {
        "surname": "Mi",
        "given_name": "Chenggang"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      },
      {
        "surname": "Zhang",
        "given_name": "Yanning"
      }
    ]
  },
  {
    "title": "Cross-modal distribution alignment embedding network for generalized zero-shot learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.007",
    "abstract": "Many approaches in generalized zero-shot learning (GZSL) rely on cross-modal mapping between the image feature space and the class embedding space, which achieves knowledge transfer from seen to unseen classes. However, these two spaces are completely different space and their manifolds are inconsistent, the existing methods suffer from highly overlapped semantic description of different classes, as in GZSL tasks unseen classes can be easily misclassified into seen classes. To handle these problems, we adopt a novel semantic embedding network which helps to encode more discriminative information from initial semantic attributes to semantic embeddings in visual space. Meanwhile, a distribution alignment constraint is adopted to help keep the distribution of the learned semantic embeddings consistent with the distribution of real image features. Moreover, an auxiliary classifier is adopted to strengthen the quality of the learned semantic embeddings. Finally, a relation network is used to classify the unseen images by computing the relation scores between the semantic embeddings and image features, which is much more flexible than the fixed distance metric functions. Experimental results demonstrate that our proposed method is superior to other state-of-the-arts.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000077",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Class (philosophy)",
      "Classifier (UML)",
      "Computer science",
      "Data mining",
      "Discrete mathematics",
      "Discriminative model",
      "ENCODE",
      "Embedding",
      "Feature vector",
      "Gene",
      "Mathematics",
      "Metric space",
      "Modal",
      "Pattern recognition (psychology)",
      "Polymer chemistry",
      "Relation (database)",
      "Semantic space"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Qin"
      },
      {
        "surname": "Hou",
        "given_name": "Mingzhen"
      },
      {
        "surname": "Lai",
        "given_name": "Hong"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      }
    ]
  },
  {
    "title": "Biological convolutions improve DNN robustness to noise and generalisation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.005",
    "abstract": "Deep Convolutional Neural Networks (DNNs) have achieved superhuman accuracy on standard image classification benchmarks. Their success has reignited significant interest in their use as models of the primate visual system, bolstered by claims of their architectural and representational similarities. However, closer scrutiny of these models suggests that they rely on various forms of shortcut learning to achieve their impressive performance, such as using texture rather than shape information. Such superficial solutions to image recognition have been shown to make DNNs brittle in the face of more challenging tests such as noise-perturbed or out-of-distribution images, casting doubt on their similarity to their biological counterparts. In the present work, we demonstrate that adding fixed biological filter banks, in particular banks of Gabor filters, helps to constrain the networks to avoid reliance on shortcuts, making them develop more structured internal representations and more tolerance to noise. Importantly, they also gained around 20–35% improved accuracy when generalising to our novel out-of-distribution test image sets over standard end-to-end trained architectures. We take these findings to suggest that these properties of the primate visual system should be incorporated into DNNs to make them more able to cope with real-world vision and better capture some of the more impressive aspects of human visual perception such as generalisation.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004780",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Biology",
      "Chemistry",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Deep neural networks",
      "Gene",
      "Image (mathematics)",
      "Machine learning",
      "Neuroscience",
      "Noise (video)",
      "Pattern recognition (psychology)",
      "Perception",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Evans",
        "given_name": "Benjamin D."
      },
      {
        "surname": "Malhotra",
        "given_name": "Gaurav"
      },
      {
        "surname": "Bowers",
        "given_name": "Jeffrey S."
      }
    ]
  },
  {
    "title": "Evolved explainable classifications for lymph node metastases",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.014",
    "abstract": "A novel evolutionary approach for Explainable Artificial Intelligence is presented: the “Evolved Explanations” model (EvEx). This methodology combines Local Interpretable Model Agnostic Explanations (LIME) with Multi-Objective Genetic Algorithms to allow for automated segmentation parameter tuning in image classification tasks. In this case, the dataset studied is Patch-Camelyon, comprised of patches from pathology whole slide images. A publicly available Convolutional Neural Network (CNN) was trained on this dataset to provide a binary classification for presence/absence of lymph node metastatic tissue. In turn, the classifications are explained by means of evolving segmentations, seeking to optimize three evaluation goals simultaneously. The final explanation is computed as the mean of all explanations generated by Pareto front individuals, evolved by the developed genetic algorithm. To enhance reproducibility and traceability of the explanations, each of them was generated from several different seeds, randomly chosen. The observed results show remarkable agreement between different seeds. Despite the stochastic nature of LIME explanations, regions of high explanation weights proved to have good agreement in the heat maps, as computed by pixel-wise relative standard deviations. The found heat maps coincide with expert medical segmentations, which demonstrates that this methodology can find high quality explanations (according to the evaluation metrics), with the novel advantage of automated parameter fine tuning. These results give additional insight into the inner workings of neural network black box decision making for medical data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004937",
    "keywords": [
      "Arithmetic",
      "Artificial intelligence",
      "Artificial neural network",
      "Binary number",
      "Black box",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Genetic programming",
      "Machine learning",
      "Mathematics",
      "Pattern recognition (psychology)",
      "Pixel",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Palatnik de Sousa",
        "given_name": "Iam"
      },
      {
        "surname": "Vellasco",
        "given_name": "Marley M.B.R."
      },
      {
        "surname": "Costa da Silva",
        "given_name": "Eduardo"
      }
    ]
  },
  {
    "title": "Discovering Parametric Activation Functions",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.001",
    "abstract": "Recent studies have shown that the choice of activation function can significantly affect the performance of deep learning networks. However, the benefits of novel activation functions have been inconsistent and task dependent, and therefore the rectified linear unit (ReLU) is still the most commonly used. This paper proposes a technique for customizing activation functions automatically, resulting in reliable improvements in performance. Evolutionary search is used to discover the general form of the function, and gradient descent to optimize its parameters for different parts of the network and over the learning process. Experiments with four different neural network architectures on the CIFAR-10 and CIFAR-100 image classification datasets show that this approach is effective. It discovers both general activation functions and specialized functions for different architectures, consistently improving accuracy over ReLU and other activation functions by significant margins. The approach can therefore be used as an automated optimization step in applying deep learning to new tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000016",
    "keywords": [],
    "authors": [
      {
        "surname": "Bingham",
        "given_name": "Garrett"
      },
      {
        "surname": "Miikkulainen",
        "given_name": "Risto"
      }
    ]
  },
  {
    "title": "Multi-dimensional conditional mutual information with application on the EEG signal analysis for spatial cognitive ability evaluation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.010",
    "abstract": "This study aims to explore an effective method to evaluate spatial cognitive ability, which can effectively extract and classify the feature of EEG signals collected from subjects participating in the virtual reality (VR) environment; and evaluate the training effect objectively and quantitatively to ensure the objectivity and accuracy of spatial cognition evaluation, according to the classification results. Therefore, a multi-dimensional conditional mutual information (MCMI) method is proposed, which could calculate the coupling strength of two channels considering the influence of other channels. The coupled characteristics of the multi-frequency combination were transformed into multi-spectral images, and the image data were classified employing the convolutional neural networks (CNN) model. The experimental results showed that the multi-spectral image transform features based on MCMI are better in classification than other methods, and among the classification results of six band combinations, the best classification accuracy of Beta1–Beta2–Gamma combination is 98.3%. The MCMI characteristics on the Beta1–Beta2–Gamma band combination can be a biological marker for the evaluation of spatial cognition. The proposed feature extraction method based on MCMI provides a new perspective for spatial cognitive ability assessment and analysis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004834",
    "keywords": [
      "Artificial intelligence",
      "Cognition",
      "Computer science",
      "Convolutional neural network",
      "Electroencephalography",
      "Feature extraction",
      "Mutual information",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychiatry",
      "Psychology"
    ],
    "authors": [
      {
        "surname": "Wen",
        "given_name": "Dong"
      },
      {
        "surname": "Li",
        "given_name": "Rou"
      },
      {
        "surname": "Jiang",
        "given_name": "Mengmeng"
      },
      {
        "surname": "Li",
        "given_name": "Jingjing"
      },
      {
        "surname": "Liu",
        "given_name": "Yijun"
      },
      {
        "surname": "Dong",
        "given_name": "Xianling"
      },
      {
        "surname": "Saripan",
        "given_name": "M. Iqbal"
      },
      {
        "surname": "Song",
        "given_name": "Haiqing"
      },
      {
        "surname": "Han",
        "given_name": "Wei"
      },
      {
        "surname": "Zhou",
        "given_name": "Yanhong"
      }
    ]
  },
  {
    "title": "Not every sample is efficient: Analogical generative adversarial network for unpaired image-to-image translation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.013",
    "abstract": "Image translation is to learn an effective mapping function that aims to convert an image from a source domain to another target domain. With the proposal and further developments of generative adversarial networks (GANs), the generative models have achieved great breakthroughs. The image-to-image (I2I) translation methods can mainly fall into two categories: Paired and Unpaired. The former paired methods usually require a large amount of input–output sample pairs to perform one-side image translation, which heavily limits its practicability. To address the lack of the paired samples, CycleGAN and its extensions utilize the cycle-consistency loss to provide an elegant and generic solution to perform the unpaired I2I translation between two domains based on unpaired data. This thread of dual learning-based methods usually adopts the random sampling strategy for optimizing and does not consider the content similarity between samples. However, not every sample is efficient and effective for the desired optimization and leads to optimal convergence. Inspired by analogical learning, which is to utilize the relationships and similarities between sample observations, we propose a novel generic metric-based sampling strategy to effectively select samples from different domains for training. Besides, we introduce a novel analogical adversarial loss to force the model to learn from the effective samples and alleviate the influence of the negative samples. Experimental results on various vision tasks have demonstrated the superior performance of the proposed method. The proposed method is also a generic framework that can be easily extended to other I2I translation methods and result in a performance gain.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000211",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Biochemistry",
      "Chemistry",
      "Chromatography",
      "Computer science",
      "Consistency (knowledge bases)",
      "Gene",
      "Generative grammar",
      "Image (mathematics)",
      "Image translation",
      "Machine learning",
      "Messenger RNA",
      "Pattern recognition (psychology)",
      "Sample (material)",
      "Similarity (geometry)",
      "Translation (biology)"
    ],
    "authors": [
      {
        "surname": "Zheng",
        "given_name": "Ziqiang"
      },
      {
        "surname": "Yang",
        "given_name": "Jie"
      },
      {
        "surname": "Yu",
        "given_name": "Zhibin"
      },
      {
        "surname": "Wang",
        "given_name": "Yubo"
      },
      {
        "surname": "Sun",
        "given_name": "Zhijian"
      },
      {
        "surname": "Zheng",
        "given_name": "Bing"
      }
    ]
  },
  {
    "title": "Noise-robust voice conversion with domain adversarial training",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.003",
    "abstract": "Voice conversion has made great progress in the past few years under the studio-quality test scenario in terms of speech quality and speaker similarity. However, in real applications, test speech from source speaker or target speaker can be corrupted by various environment noises, which seriously degrade the speech quality and speaker similarity. In this paper, we propose a novel encoder–decoder based noise-robust voice conversion framework, which consists of a speaker encoder, a content encoder, a decoder, and two domain adversarial neural networks. Specifically, we integrate disentangling speaker and content representation technique with domain adversarial training technique. Domain adversarial training makes speaker representations and content representations extracted by speaker encoder and content encoder from clean speech and noisy speech in the same space, respectively. In this way, the learned speaker and content representations are noise-invariant. Therefore, the two noise-invariant representations can be taken as input by the decoder to predict the clean converted spectrum. The experimental results demonstrate that our proposed method can synthesize clean converted speech under noisy test scenarios, where the source speech and target speech can be corrupted by seen or unseen noise types during the training process. Additionally, both speech quality and speaker similarity are improved.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802200003X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Encoder",
      "Image (mathematics)",
      "Noise (video)",
      "Operating system",
      "Speaker recognition",
      "Speech processing",
      "Speech recognition",
      "Voice activity detection"
    ],
    "authors": [
      {
        "surname": "Du",
        "given_name": "Hongqiang"
      },
      {
        "surname": "Xie",
        "given_name": "Lei"
      },
      {
        "surname": "Li",
        "given_name": "Haizhou"
      }
    ]
  },
  {
    "title": "Finite-time stabilization of complex-valued neural networks with proportional delays and inertial terms: A non-separation approach",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.005",
    "abstract": "This article mainly dedicates on the issue of finite-time stabilization of complex-valued neural networks with proportional delays and inertial terms via directly constructing Lyapunov functions without separating the original complex-valued neural networks into two real-valued subsystems equivalently. First of all, in order to facilitate the analysis of the second-order derivative caused by the inertial term, two intermediate variables are introduced to transfer complex-valued inertial neural networks (CVINNs) into the first-order differential equation form. Then, under the finite-time stability theory, some new criteria with less conservativeness are established to ensure the finite-time stabilizability of CVINNs by a newly designed complex-valued feedback controller. In addition, for reducing expenses of the control, an adaptive control strategy is also proposed to achieve the finite-time stabilization of CVINNs. At last, numerical examples are given to demonstrate the validity of the derived results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000053",
    "keywords": [
      "Agronomy",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Inertial frame of reference",
      "Lyapunov function",
      "Machine learning",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Stability (learning theory)"
    ],
    "authors": [
      {
        "surname": "Long",
        "given_name": "Changqing"
      },
      {
        "surname": "Zhang",
        "given_name": "Guodong"
      },
      {
        "surname": "Zeng",
        "given_name": "Zhigang"
      },
      {
        "surname": "Hu",
        "given_name": "Junhao"
      }
    ]
  },
  {
    "title": "The emergence of a concept in shallow neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.017",
    "abstract": "We consider restricted Boltzmann machine (RBMs) trained over an unstructured dataset made of blurred copies of definite but unavailable “archetypes” and we show that there exists a critical sample size beyond which the RBM can learn archetypes, namely the machine can successfully play as a generative model or as a classifier, according to the operational routine. In general, assessing a critical sample size (possibly in relation to the quality of the dataset) is still an open problem in machine learning. Here, restricting to the random theory, where shallow networks suffice and the “grandmother-cell” scenario is correct, we leverage the formal equivalence between RBMs and Hopfield networks, to obtain a phase diagram for both the neural architectures which highlights regions, in the space of the control parameters (i.e., number of archetypes, number of neurons, size and quality of the training set), where learning can be accomplished. Our investigations are led by analytical methods based on the statistical-mechanics of disordered systems and results are further corroborated by extensive Monte Carlo simulations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000272",
    "keywords": [],
    "authors": [
      {
        "surname": "Agliari",
        "given_name": "Elena"
      },
      {
        "surname": "Alemanno",
        "given_name": "Francesco"
      },
      {
        "surname": "Barra",
        "given_name": "Adriano"
      },
      {
        "surname": "De Marzo",
        "given_name": "Giordano"
      }
    ]
  },
  {
    "title": "Low-degree term first in ResNet, its variants and the whole neural network family",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.012",
    "abstract": "To explain the working mechanism of ResNet and its variants, this paper proposes a novel argument of shallow subnetwork first (SSF), essentially low-degree term first (LDTF), which also applies to the whole neural network family. A neural network with shortcut connections behaves as an ensemble of a number of subnetworks of differing depths. Among the subnetworks, the shallow subnetworks are trained firstly, having great effects on the performance of the neural network. The shallow subnetworks roughly correspond to low-degree polynomials, while the deep subnetworks are opposite. Based on Taylor expansion, SSF is consistent with LDTF. ResNet is in line with Taylor expansion: shallow subnetworks are trained firstly to keep low-degree terms, avoiding overfitting; deep subnetworks try to maintain high-degree terms, ensuring high description capacity. Experiments on ResNets and DenseNets show that shallow subnetworks are trained firstly and play important roles in the training of the networks. The experiments also reveal the reason why DenseNets outperform ResNets: The subnetworks playing vital roles in the training of the former are shallower than those in the training of the latter. Furthermore, LDTF can also be used to explain the working mechanism of other ResNet variants (SE-ResNets and SK-ResNets), and the common phenomena occurring in many neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000120",
    "keywords": [
      "Acoustics",
      "Argument (complex analysis)",
      "Artificial intelligence",
      "Artificial neural network",
      "Biochemistry",
      "Chemistry",
      "Computer network",
      "Computer science",
      "Degree (music)",
      "Overfitting",
      "Physics",
      "Quantum mechanics",
      "Residual neural network",
      "Subnetwork",
      "Term (time)"
    ],
    "authors": [
      {
        "surname": "Sun",
        "given_name": "Tongfeng"
      },
      {
        "surname": "Ding",
        "given_name": "Shifei"
      },
      {
        "surname": "Guo",
        "given_name": "Lili"
      }
    ]
  },
  {
    "title": "Region-aware network: Model human’s Top-Down visual perception mechanism for crowd counting",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.015",
    "abstract": "Background noise and scale variation are common problems that have been long recognized in crowd counting. Humans glance at a crowd image and instantly know the approximate number of human and where they are through attention the crowd regions and the congestion degree of crowd regions with a global receptive field. Hence, in this paper, we propose a novel feedback network with Region-Aware block called RANet by modeling human’s Top-Down visual perception mechanism. Firstly, we introduce a feedback architecture to generate priority maps that provide prior about candidate crowd regions in input images. The prior enables the RANet pay more attention to crowd regions. Then we design Region-Aware block that could adaptively encode the contextual information into input images through global receptive field. More specifically, we scan the whole input images and its priority maps in the form of column vector to obtain a relevance matrix estimating their similarity. The relevance matrix obtained would be utilized to build global relationships between pixels. Our method outperforms state-of-the-art crowd counting methods on several public datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000259",
    "keywords": [],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Yuehai"
      },
      {
        "surname": "Yang",
        "given_name": "Jing"
      },
      {
        "surname": "Zhang",
        "given_name": "Dong"
      },
      {
        "surname": "Zhang",
        "given_name": "Kun"
      },
      {
        "surname": "Chen",
        "given_name": "Badong"
      },
      {
        "surname": "Du",
        "given_name": "Shaoyi"
      }
    ]
  },
  {
    "title": "Finite-time synchronization of quaternion-valued neural networks with delays: A switching control method without decomposition",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.012",
    "abstract": "For a class of quaternion-valued neural networks (QVNNs) with discrete and distributed time delays, its finite-time synchronization (FTSYN) is addressed in this paper. Instead of decomposition, a direct analytical method named two-step analysis is proposed. That method can always be used to study FTSYN, under either 1-norm or 2-norm of quaternion. Compared with the decomposing method, the two-step method is also suitable for models that are not easily decomposed. Furthermore, a switching controller based on the two-step method is proposed. In addition, two criteria are given to realize the FTSYN of QVNNs. At last, three numerical examples illustrate the feasibility, effectiveness and practicability of our method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004858",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Decomposition",
      "Decomposition method (queueing theory)",
      "Discrete mathematics",
      "Discrete time and continuous time",
      "Ecology",
      "Geometry",
      "Law",
      "Mathematics",
      "Norm (philosophy)",
      "Political science",
      "Quaternion",
      "Statistics",
      "Synchronization (alternating current)"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Tao"
      },
      {
        "surname": "Zhong",
        "given_name": "Jie"
      },
      {
        "surname": "Tu",
        "given_name": "Zhengwen"
      },
      {
        "surname": "Lu",
        "given_name": "Jianquan"
      },
      {
        "surname": "Lou",
        "given_name": "Jungang"
      }
    ]
  },
  {
    "title": "Corrigendum to “Fractional-order discontinuous systems with indefinite LKFs: An application to fractional-order neural networks with time delays” [Neural Networks 145 (2022) 319–330]",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.008",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000089",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Economics",
      "Finance",
      "Fractional calculus",
      "Mathematics",
      "Order (exchange)"
    ],
    "authors": [
      {
        "surname": "Udhayakumar",
        "given_name": "K."
      },
      {
        "surname": "Rihan",
        "given_name": "Fathalla A."
      },
      {
        "surname": "Rakkiyappan",
        "given_name": "R."
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "On minimal representations of shallow ReLU networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.006",
    "abstract": "The realization function of a shallow ReLU network is a continuous and piecewise affine function f : R d → R , where the domain R d is partitioned by a set of n hyperplanes into cells on which f is affine. We show that the minimal representation for f uses either n , n + 1 or n + 2 neurons and we characterize each of the three cases. In the particular case, where the input layer is one-dimensional, minimal representations always use at most n + 1 neurons but in all higher dimensional settings there are functions for which n + 2 neurons are needed. Then we show that the set of minimal networks representing f forms a C ∞ -submanifold M and we derive the dimension and the number of connected components of M . Additionally, we give a criterion for the hyperplanes that guarantees that a continuous, piecewise affine function is the realization function of an appropriate shallow ReLU network.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000065",
    "keywords": [
      "Affine transformation",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Dimension (graph theory)",
      "Discrete mathematics",
      "Evolutionary biology",
      "Function (biology)",
      "Hyperplane",
      "Law",
      "Linear system",
      "Mathematical analysis",
      "Mathematics",
      "Minimal realization",
      "Piecewise",
      "Political science",
      "Politics",
      "Programming language",
      "Pure mathematics",
      "Realization (probability)",
      "Representation (politics)",
      "Set (abstract data type)",
      "Statistics",
      "Submanifold",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Dereich",
        "given_name": "Steffen"
      },
      {
        "surname": "Kassing",
        "given_name": "Sebastian"
      }
    ]
  },
  {
    "title": "Deep Rival Penalized Competitive Learning for low-resolution face recognition",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.009",
    "abstract": "Current face recognition tasks are usually carried out on high-quality face images, but in reality, most face images are captured under unconstrained or poor conditions, e.g., by video surveillance. Existing methods are featured by learning data uncertainty to avoid overfitting the noise, or by adding margins to the angle or cosine space of the normalized softmax loss to penalize the target logit, which enforces intra-class compactness and inter-class discrepancy. In this paper, we propose a deep Rival Penalized Competitive Learning (RPCL) for deep face recognition in low-resolution (LR) images. Inspired by the idea of the RPCL, our method further enforces regulation on the rival logit, which is defined as the largest non-target logit for an input image. Different from existing methods that only consider penalization on the target logit, our method not only strengthens the learning towards the target label, but also enforces a reverse direction, i.e., becoming de-learning, away from the rival label. Comprehensive experiments demonstrate that our method improves the existing state-of-the-art methods to be very robust for LR face recognition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000090",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Class (philosophy)",
      "Computer science",
      "Deep learning",
      "Face (sociological concept)",
      "Facial recognition system",
      "Logit",
      "Machine learning",
      "Overfitting",
      "Pattern recognition (psychology)",
      "Social science",
      "Sociology",
      "Softmax function"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Peiying"
      },
      {
        "surname": "Tu",
        "given_name": "Shikui"
      },
      {
        "surname": "Xu",
        "given_name": "Lei"
      }
    ]
  },
  {
    "title": "Joint learning adaptive metric and optimal classification hyperplane",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.002",
    "abstract": "Metric learning has attracted a lot of interest in classification tasks due to its efficient performance. Most traditional metric learning methods are based on k-nearest neighbors (kNN) classifiers to make decisions, while the choice k affects the generalization. In this work, we propose an end-to-end metric learning framework. Specifically, a new linear metric learning (LMML) is first proposed to jointly learn adaptive metrics and the optimal classification hyperplanes, where dissimilar samples are separated by maximizing classification margin. Then a nonlinear metric learning model (called RLMML) is developed based on a bound nonlinear kernel function to extend LMML. The non-convexity of the proposed models makes them difficult to optimize. The half-quadratic optimization algorithms are developed to solve iteratively the problems, by which the optimal classification hyperplane and adaptive metric are alternatively optimized. Moreover, the resulting algorithms are proved to be convergent theoretically. Numerical experiments on different types of data sets show the effectiveness of the proposed algorithms. Finally, the Wilcoxon test shows also the feasibility and effectiveness of the proposed models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000028",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convexity",
      "Economics",
      "Financial economics",
      "Generalization",
      "Geometry",
      "Hyperplane",
      "Large margin nearest neighbor",
      "Machine learning",
      "Margin (machine learning)",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Metric (unit)",
      "Operations management",
      "k-nearest neighbors algorithm"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yidan"
      },
      {
        "surname": "Yang",
        "given_name": "Liming"
      }
    ]
  },
  {
    "title": "GARAT: Generative Adversarial Learning for Robust and Accurate Tracking",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.010",
    "abstract": "Object tracking by the Siamese network has gained its popularity for its outstanding performance and considerable potential. However, most of the existing Siamese architectures are faced with great difficulties when it comes to the scenes where the target is going through dramatic shape or environmental changes. In this work, we proposed a novel and concise generative adversarial learning method to solve the problem especially when the target is going under drastic changes of appearance, illumination variations and background clutters. We consider the above situations as distractors for tracking and joint a distractor generator into the traditional Siamese network. The component can simulate these distractors, and more robust tracking performance is achieved by eliminating the distractors from the input instance search image. Besides, we use the generalized intersection over union ( GIoU ) as our training loss. GIoU is a more strict metric for the bounding box regression compared to the traditional IoU , which can be used as training loss for more accurate tracking results. Experiments on five challenging benchmarks have shown favorable and state-of-the-art results against other trackers in different aspects.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000107",
    "keywords": [
      "Active appearance model",
      "Aerospace engineering",
      "Artificial intelligence",
      "BitTorrent tracker",
      "Bounding overwatch",
      "Computer science",
      "Computer vision",
      "Engineering",
      "Eye tracking",
      "Generator (circuit theory)",
      "Image (mathematics)",
      "Intersection (aeronautics)",
      "Machine learning",
      "Margin (machine learning)",
      "Metric (unit)",
      "Minimum bounding box",
      "Object (grammar)",
      "Operations management",
      "Pedagogy",
      "Physics",
      "Power (physics)",
      "Psychology",
      "Quantum mechanics",
      "Tracking (education)",
      "Video tracking"
    ],
    "authors": [
      {
        "surname": "Yao",
        "given_name": "Bowen"
      },
      {
        "surname": "Li",
        "given_name": "Jing"
      },
      {
        "surname": "Xue",
        "given_name": "Shan"
      },
      {
        "surname": "Wu",
        "given_name": "Jia"
      },
      {
        "surname": "Guan",
        "given_name": "Huanmei"
      },
      {
        "surname": "Chang",
        "given_name": "Jun"
      },
      {
        "surname": "Ding",
        "given_name": "Zhiquan"
      }
    ]
  },
  {
    "title": "Feature-based intelligent models for optimisation of percussive drilling",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.021",
    "abstract": "As a rotary-percussion system, the vibro-impact drilling (VID) system utilises resonantly induced high frequency periodic impacts alongside existing drill-string rotation to cut through downhole rock layers. Due to the inhomogeneous nature of the rock layers, the system often experiences multi-stability which generates different categories of impact motions as drilling continues downhole. Some impact motions yield better drilling performance in terms of rate of penetration (ROP) and bit life-span when compared to others. As an optimisation strategy, the present study adopts feature-based classification algorithms including multi-layer perceptron, support vector machine and long short-term memory network as intelligent models for categorising impact motions from a one-degree-of-freedom impact oscillator representing the percussive bit-rock impacts of the VID system. This way, high-performance impacts can be easily detected and maintained while undesirable low-performance impacts are well avoided to increase ROP, improve bit life-span and save cost. In this study, scarce and limited classes of experimental impact data are merged with inexhaustibly simulated impact data to train different network models. By means of cross-validation, the trained networks were tested on separate sets of only-simulation and only-experimental data. Results show that extracting appropriate features from raw impact data is essential for optimising the performance of each network model. About 42% of the feature-based networks yield accuracies greater than 91% while about 67% yield accuracies greater than 77% on both simulation and experimental impact motion data.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000314",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data mining",
      "Drilling",
      "Engineering",
      "Feature (linguistics)",
      "Linguistics",
      "Mechanical engineering",
      "Perceptron",
      "Philosophy",
      "Simulation",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Afebu",
        "given_name": "Kenneth Omokhagbo"
      },
      {
        "surname": "Liu",
        "given_name": "Yang"
      },
      {
        "surname": "Papatheou",
        "given_name": "Evangelos"
      }
    ]
  },
  {
    "title": "Trade off analysis between fixed-time stabilization and energy consumption of nonlinear neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.004",
    "abstract": "This paper concentrates on trade off analysis between fixed-time stabilization and energy consumption for a type of nonlinear neural networks (NNs). By constructing a compound switching controller and utilizing inequality techniques, a sufficient condition is proposed to ensure the fixed-time stabilization. Then, an estimate of the upper bound of the energy consumed by the controller in the control process is given. Furthermore, the quantitative analysis of the trade-off between the control time and energy consumption is studied. This article reveals that appropriate control parameters can balance the above two indicators to achieve an optimal control state. Finally, the presented theoretical results are verified by two numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000041",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Consumption (sociology)",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Electrical engineering",
      "Energy (signal processing)",
      "Energy consumption",
      "Engineering",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Physics",
      "Process (computing)",
      "Quantum mechanics",
      "Social science",
      "Sociology",
      "Statistics",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Yuchun"
      },
      {
        "surname": "Zhu",
        "given_name": "Song"
      },
      {
        "surname": "Shao",
        "given_name": "Hu"
      },
      {
        "surname": "Wang",
        "given_name": "Li"
      },
      {
        "surname": "Wen",
        "given_name": "Shiping"
      }
    ]
  },
  {
    "title": "Quantifying the reproducibility of graph neural networks using multigraph data representation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.018",
    "abstract": "Graph neural networks (GNNs) have witnessed an unprecedented proliferation in tackling several problems in computer vision, computer-aided diagnosis and related fields. While prior studies have focused on boosting the model accuracy, quantifying the reproducibility of the most discriminative features identified by GNNs is still an intact problem that yields concerns about their reliability in clinical applications in particular. Specifically, the reproducibility of biological markers across clinical datasets and distribution shifts across classes (e.g., healthy and disordered brains) is of paramount importance in revealing the underpinning mechanisms of diseases as well as propelling the development of personalized treatment. Motivated by these issues, we propose, for the first time, reproducibility-based GNN selection (RG-Select), a framework for GNN reproducibility assessment via the quantification of the most discriminative features (i.e., biomarkers) shared between different models. To ascertain the soundness of our framework, the reproducibility assessment embraces variations of different factors such as training strategies and data perturbations. Despite these challenges, our framework successfully yielded replicable conclusions across different training strategies and various clinical datasets. Our findings could thus pave the way for the development of biomarker trustworthiness and reliability assessment methods for computer-aided diagnosis and prognosis tasks. RG-Select code is available on GitHub at https://github.com/basiralab/RG-Select.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000284",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Data science",
      "Discriminative model",
      "Graph",
      "Machine learning",
      "Mathematics",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Reliability (semiconductor)",
      "Reproducibility",
      "Statistics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Nebli",
        "given_name": "Ahmed"
      },
      {
        "surname": "Gharsallaoui",
        "given_name": "Mohammed Amine"
      },
      {
        "surname": "Gürler",
        "given_name": "Zeynep"
      },
      {
        "surname": "Rekik",
        "given_name": "Islem"
      }
    ]
  },
  {
    "title": "Signed network representation with novel node proximity evaluation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.014",
    "abstract": "Currently, signed network representation has been applied to many fields, e.g., recommendation platforms. A mainstream paradigm of network representation is to map nodes onto a low-dimensional space, such that the node proximity of interest can be preserved. Thus, a key aspect is the node proximity evaluation. Accordingly, three new node proximity metrics were proposed in this study, based on the rigorous theoretical investigation on a new distance metric - signed average first-passage time (SAFT). SAFT derives from a basic random-walk quantity for unsigned networks and can capture high-order network structure and edge signs. We conducted network representation using the proposed proximity metrics and empirically exhibited our advantage in solving two downstream tasks — sign prediction and link prediction. The code is publicly available.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000223",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Code (set theory)",
      "Combinatorics",
      "Computer science",
      "Computer security",
      "Data mining",
      "Economics",
      "Engineering",
      "Enhanced Data Rates for GSM Evolution",
      "Key (lock)",
      "Law",
      "Mathematical analysis",
      "Mathematics",
      "Metric (unit)",
      "Node (physics)",
      "Operations management",
      "Political science",
      "Politics",
      "Programming language",
      "Representation (politics)",
      "Set (abstract data type)",
      "Sign (mathematics)",
      "Structural engineering",
      "Theoretical computer science",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Pinghua"
      },
      {
        "surname": "Hu",
        "given_name": "Wenbin"
      },
      {
        "surname": "Wu",
        "given_name": "Jia"
      },
      {
        "surname": "Liu",
        "given_name": "Weiwei"
      }
    ]
  },
  {
    "title": "Exponential synchronization for variable-order fractional discontinuous complex dynamical networks with short memory via impulsive control",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.021",
    "abstract": "This paper considers the exponential synchronization issue for variable-order fractional complex dynamical networks (FCDNs) with short memory and derivative couplings via the impulsive control scheme, where dynamical nodes are modeled to be discontinuous. Firstly, the mathematics model with respect to variable-order fractional systems with short memory is established under the impulsive controller, in which the impulse strength is not only determined by the impulse control gain, but also the order of the control systems. Secondly, the exponential stability criterion for variable-order fractional systems with short memory is developed. Thirdly, the hybrid controller, which consists of the impulsive coupling controller and the discontinuous feedback controller, is designed to realize the synchronization objective. In addition, by constructing Lyapunov functional and applying inequality analysis techniques, the synchronization conditions are achieved in terms of linear matrix inequalities (LMIs). Finally, two simulation examples are performed to verify the effectiveness of the developed synchronization scheme and the theoretical outcomes.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021005037",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Exponential function",
      "Exponential stability",
      "Impulse (physics)",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Variable (mathematics)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Ruihong"
      },
      {
        "surname": "Wu",
        "given_name": "Huaiqin"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Dual Global Enhanced Transformer for image captioning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2022.01.011",
    "abstract": "Transformer-based architectures have shown great success in image captioning, where self-attention module can model source and target interaction (e.g., object-to-object, object-to-word, word-to-word). However, the global information is not explicitly considered in the attention weight calculation, which is essential to understand the scene content. In this paper, we propose Dual Global Enhanced Transformer (DGET) to incorporate global information in the encoding and decoding stages. Concretely, in DGET, we regard the grid feature as the visual global information and adaptively fuse it into region features in each layer by a novel Global Enhanced Encoder (GEE). During decoding, we proposed Global Enhanced Decoder (GED) to explicitly utilize the textual global information. First, we devise the context encoder to encode the existing caption generated by classic captioner as a context vector. Then, we use the context vector to guide the decoder to generate accurate words at each time step. To validate our model, we conduct extensive experiments on the MS COCO image captioning dataset and achieve superior performance over many state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608022000119",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Closed captioning",
      "Computer science",
      "Computer vision",
      "Decoding methods",
      "Encoder",
      "Encoding (memory)",
      "Image (mathematics)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Xian",
        "given_name": "Tiantao"
      },
      {
        "surname": "Li",
        "given_name": "Zhixin"
      },
      {
        "surname": "Zhang",
        "given_name": "Canlong"
      },
      {
        "surname": "Ma",
        "given_name": "Huifang"
      }
    ]
  },
  {
    "title": "A one-layer recurrent neural network for nonsmooth pseudoconvex optimization with quasiconvex inequality and affine equality constraints",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.001",
    "abstract": "As two important types of generalized convex functions, pseudoconvex and quasiconvex functions appear in many practical optimization problems. The lack of convexity poses some difficulties in solving pseudoconvex optimization with quasiconvex constraint functions. In this paper, we propose a one-layer recurrent neural network for solving such problems. We prove that the state of the proposed neural network is convergent from the feasible region to an optimal solution of the given optimization problem. We show that the proposed neural network has several advantages over the existing neural networks for pseudoconvex optimization. Specifically, the proposed neural network is applicable to optimization problems with quasiconvex inequality constraints as well as affine equality constraints. In addition, parameter matrix inversion is avoided and some assumptions on the objective function and inequality constraints in existing results are relaxed. We demonstrate the superior performance and characteristics of the proposed neural network with simulation results in three numerical examples.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004743",
    "keywords": [
      "Affine transformation",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Constrained optimization",
      "Constraint (computer-aided design)",
      "Convex function",
      "Convex optimization",
      "Convexity",
      "Economics",
      "Feasible region",
      "Financial economics",
      "Geometry",
      "Linear matrix inequality",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Pseudoconvex function",
      "Pure mathematics",
      "Quasiconvex function",
      "Regular polygon",
      "Subderivative"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Na"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      },
      {
        "surname": "Qin",
        "given_name": "Sitian"
      }
    ]
  },
  {
    "title": "Feature Correlation-Steered Capsule Network for object detection",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.003",
    "abstract": "Despite Convolutional Neural Networks (CNNs) based approaches have been successful in objects detection, they predominantly focus on positioning discriminative regions while overlooking the internal holistic part-whole associations within objects. This would ultimately lead to the neglect of feature relationships between object and its parts as well as among those parts, both of which are significantly helpful for detecting discriminative parts. In this paper, we propose to “look insider the objects” by digging into part-whole feature correlations and take the attempts to leverage those correlations endowed by the Capsule Network (CapsNet) for robust object detection. Actually, highly correlated capsules across adjacent layers share high familiarity, which will be more likely to be routed together. In light of this, we take such correlations between different capsules of the preceding training samples as an awareness to constrain the subsequent candidate voting scope during the routing procedure, and a Feature Correlation-Steered CapsNet (FCS-CapsNet) with Locally-Constrained Expectation-Maximum (EM) Routing Agreement (LCEMRA) is proposed. Different from conventional EM routing, LCEMRA stipulates that only those relevant low-level capsules (parts) meeting the requirement of quantified intra-object cohesiveness can be clustered to make up high-level capsules (objects). In doing so, part-object associations can be dug by transformation weighting matrixes between capsules layers during such “part backtracking” procedure. LCEMRA enables low-level capsules to selectively gather projections from a non-spatially-fixed set of high-level capsules. Experiments on VOC2007, VOC2012, HKU-IS, DUTS, and COCO show that FCS-CapsNet can achieve promising object detection effects across multiple evaluation metrics, which are on-par with state-of-the-arts.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004767",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "Discriminative model",
      "Feature (linguistics)",
      "Linguistics",
      "Medicine",
      "Object detection",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Radiology",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Lin",
        "given_name": "Zhongqi"
      },
      {
        "surname": "Jia",
        "given_name": "Jingdun"
      },
      {
        "surname": "Huang",
        "given_name": "Feng"
      },
      {
        "surname": "Gao",
        "given_name": "Wanlin"
      }
    ]
  },
  {
    "title": "Fully corrective gradient boosting with squared hinge: Fast learning rates and early stopping",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.016",
    "abstract": "In this paper, we propose an efficient boosting method with theoretical guarantees for binary classification. There are three key ingredients of the proposed boosting method: a fully corrective greedy (FCG) update, a differentiable squared hinge (also called truncated quadratic) loss function, and an efficient alternating direction method of multipliers (ADMM) solver. Compared with traditional boosting methods, on one hand, the FCG update accelerates the numerical convergence rate, and on the other hand, the squared hinge loss inherits the robustness of the hinge loss for classification and maintains the theoretical benefits of the square loss in regression. The ADMM solver with guaranteed fast convergence then provides an efficient implementation for the proposed boosting method. We conduct both theoretical analysis and numerical verification to show the outperformance of the proposed method. Theoretically, a fast learning rate of order O ( ( m / log m ) − 1 / 2 ) is proved under certain standard assumptions, where m is the size of sample set. Numerically, a series of toy simulations and real data experiments are carried out to verify the developed theory.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004950",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Biochemistry",
      "Boosting (machine learning)",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Gene",
      "Geometry",
      "Gradient boosting",
      "Hinge loss",
      "Key (lock)",
      "Mathematical optimization",
      "Mathematics",
      "Mean squared error",
      "Quadratic equation",
      "Random forest",
      "Rate of convergence",
      "Robustness (evolution)",
      "Solver",
      "Statistics",
      "Support vector machine"
    ],
    "authors": [
      {
        "surname": "Zeng",
        "given_name": "Jinshan"
      },
      {
        "surname": "Zhang",
        "given_name": "Min"
      },
      {
        "surname": "Lin",
        "given_name": "Shao-Bo"
      }
    ]
  },
  {
    "title": "NoAS-DS: Neural optimal architecture search for detection of diverse DNA signals",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.009",
    "abstract": "Neural network architectures are high-performing variable models that can solve many learning tasks. Designing architectures manually require substantial time and also prior knowledge and expertise to develop a high-accuracy model. Most of the architecture search methods are developed over the task of image classification resulting in the building of complex architectures intended for large data inputs such as images. Motivated by the applications of DNA computing in Neural Architecture Search (NAS), we propose NoAS-DS which is specifically built for the architecture search of sequence-based classification tasks. Furthermore, NoAS-DS is applied to the task of predicting binding sites. Unlike other methods that implement only Convolution layers, NoAS-DS, specifically combines Convolution and LSTM layers that helps in the process of automatic architecture building. This hybrid approach helped in achieving high accuracy results on TFBS and RBP datasets which outperformed other models in TF-DNA binding prediction tasks. The best architectures generated by the proposed model can be applied to other DNA datasets of similar nature using transfer learning technique that demonstrates its generalization capability. This greatly reduces the effort required to build new architectures for other prediction tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004822",
    "keywords": [
      "Architecture",
      "Art",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Data mining",
      "Deep learning",
      "Engineering",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Systems engineering",
      "Task (project management)",
      "Transfer of learning",
      "Visual arts"
    ],
    "authors": [
      {
        "surname": "Sivangi",
        "given_name": "Kaushik Bhargav"
      },
      {
        "surname": "Dasari",
        "given_name": "Chandra Mohan"
      },
      {
        "surname": "Amilpur",
        "given_name": "Santhosh"
      },
      {
        "surname": "Bhukya",
        "given_name": "Raju"
      }
    ]
  },
  {
    "title": "Associative anticipatory learning and control of the cerebellar cortex based on the spike-timing-dependent plasticity of the parallel fiber-Purkinje cell synapses",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.004",
    "abstract": "Time delays are inevitable in the neural processing of sensorimotor systems; small delays can cause severe damage to movement accuracy and stability. It is strongly suggested that the cerebellum compensates for delays in neural signal processing and performs predictive control. Neural computational theories have explored concepts of the internal models of control objects—believed to avoid delays by providing internal feedback information—although there has been no clear relevance to neural processing. The timing-dependent plasticity of parallel fiber-Purkinje cell synapses is well known. The long-term depression of the synapse is observed when parallel fiber activation precedes climbing fiber activation within − 50–300 ms, and is the greatest within 50–200 ms. This paper presents a theory that this temporal difference of 50–200 ms is the basis for an associative anticipation of as many milliseconds. Associative learning can theoretically connect an input signal to a desired signal; therefore, a 50–200 ms earlier input signal can be connected to a desired output signal through temporary asymmetric plasticity. After learning is completed, an input signal generates a desired output signal that appears 50–200 ms later. For the associative learning of temporally continuous signals, this study integrates the universal function approximation capability of the cerebellar cortex model and temporally asymmetric synaptic plasticity to create the theory of associative anticipatory learning of the cerebellum. The effective motor control of this learning is demonstrated by adaptively stabilizing an inverted pendulum with a delay similar to that done by humans.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004779",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Associative learning",
      "Biochemistry",
      "Biology",
      "Cerebellar cortex",
      "Cerebellum",
      "Climbing fiber",
      "Computer science",
      "Content-addressable memory",
      "Dentate gyrus",
      "Hippocampal formation",
      "Mossy fiber (hippocampus)",
      "Motor learning",
      "Neuroscience",
      "Parallel fiber",
      "Programming language",
      "Psychology",
      "Purkinje cell",
      "Receptor",
      "SIGNAL (programming language)",
      "Spike-timing-dependent plasticity",
      "Synaptic plasticity"
    ],
    "authors": [
      {
        "surname": "Fujita",
        "given_name": "Masahiko"
      }
    ]
  },
  {
    "title": "Towards efficient network compression via Few-Shot Slimming",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.011",
    "abstract": "While previous network compression methods achieve great success, most of them rely on the abundant training data which is, unfortunately, often unavailable in practice due to some reasons, e.g., privacy issues, storage constraints, and transmission limitations. A promising way to solve this problem is to perform compression with a few unlabeled data. Proceeding along this way, we propose a novel few-shot network compression framework named Few-Shot Slimming (FSS). FSS follows the student/teacher paradigm, and contains two steps: (1) construct the student by inheriting principal feature maps from the teacher; (2) refine the student feature representation by knowledge distillation with an enhanced mixing data augmentation method called GridMix. Specifically, in the first step, we employ normalized cross correlation to perform the principal feature analysis, and then theoretically construct a new indicator to select the most informative feature maps from the teacher for the student. The indicator is based on the variances of feature maps which can efficiently quantitate the information richness of the input feature maps in a feature-agnostic manner. In the second step, we perform the knowledge distillation for the initialized student in first step with a novel grid-based mixing data augmentation technique which greatly extends the limited sample dataset. In this way, the student is able to refine its feature representation and achieves a better result. Extensive experiments on multiple benchmarks demonstrate the state-of-the-art performance of FSS. For example, by using 0.2% label-free data of full training set, FSS yields a 60% FLOPs reduction for DenseNet-40 on CIFAR-10 with only a loss of 0.8% in top-1 accuracy, achieving a result on par with that obtained by the conventional full-data methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004846",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Construct (python library)",
      "Data mining",
      "Feature (linguistics)",
      "Feature learning",
      "Law",
      "Linguistics",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Political science",
      "Politics",
      "Programming language",
      "Representation (politics)",
      "Set (abstract data type)"
    ],
    "authors": [
      {
        "surname": "He",
        "given_name": "Junjie"
      },
      {
        "surname": "Ding",
        "given_name": "Yinzhang"
      },
      {
        "surname": "Zhang",
        "given_name": "Ming"
      },
      {
        "surname": "Li",
        "given_name": "Dongxiao"
      }
    ]
  },
  {
    "title": "SurvNAM: The machine learning survival model explanation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.015",
    "abstract": "An extension of the Neural Additive Model (NAM) called SurvNAM and its modifications are proposed to explain predictions of a black-box machine learning survival model. The method is based on applying the original NAM to solving the explanation problem in the framework of survival analysis. The basic idea behind SurvNAM is to train the network by means of a specific expected loss function which takes into account peculiarities of the survival model predictions. Moreover, the loss function approximates the black-box model by the extension of the Cox proportional hazards model, which uses the well-known Generalized Additive Model (GAM) in place of the simple linear relationship of covariates. The proposed method SurvNAM allows performing local and global explanations. The global explanation uses the whole training dataset. In contrast to the global explanation, a set of synthetic examples around the explained example are randomly generated for the local explanation. The proposed modifications of SurvNAM are based on using the Lasso-based regularization for functions from GAM and for a special representation of the GAM functions using their weighted linear and non-linear parts, which is implemented as a shortcut connection. Many numerical experiments illustrate efficiency of SurvNAM.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004949",
    "keywords": [
      "Additive model",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Black box",
      "Computer science",
      "Connection (principal bundle)",
      "Covariate",
      "Epistemology",
      "Evolutionary biology",
      "Function (biology)",
      "Generalized additive model",
      "Generalized linear model",
      "Geometry",
      "Lasso (programming language)",
      "Law",
      "Linear model",
      "Machine learning",
      "Mathematics",
      "Philosophy",
      "Political science",
      "Politics",
      "Regularization (linguistics)",
      "Representation (politics)",
      "Simple (philosophy)",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Utkin",
        "given_name": "Lev V."
      },
      {
        "surname": "Satyukov",
        "given_name": "Egor D."
      },
      {
        "surname": "Konstantinov",
        "given_name": "Andrei V."
      }
    ]
  },
  {
    "title": "UTRAD: Anomaly detection and localization with U-Transformer",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.008",
    "abstract": "Anomaly detection is an active research field in industrial defect detection and medical disease detection. However, previous anomaly detection works suffer from unstable training, or non-universal criteria of evaluating feature distribution. In this paper, we introduce UTRAD, a U-TRansformer based Anomaly Detection framework. Deep pre-trained features are regarded as dispersed word tokens, and represented with transformer-based autoencoders. With reconstruction on more informative feature distribution instead of raw images, we achieve a more stable training process and a more precise anomaly detection and localization result. In addition, our proposed UTRAD has a multi-scale pyramidal hierarchy with skip connections that help detect both multi-scale structural and non-structural anomalies. As attention layers are decomposed to multi-level patches, UTRAD significantly reduces the computational cost and memory usage compared with the vanilla transformer. Experiments on industrial dataset MVtec AD and medical datasets Retinal-OCT, Brain-MRI, Head-CT have been conducted. Our proposed UTRAD out-performs all other state-of-the-art methods in the above datasets. Code released at https://github.com/gordon-chenmo/UTRAD.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004810",
    "keywords": [
      "Anomaly detection",
      "Artificial intelligence",
      "Computer science",
      "Electrical engineering",
      "Engineering",
      "Feature (linguistics)",
      "Linguistics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Transformer",
      "Voltage"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Liyang"
      },
      {
        "surname": "You",
        "given_name": "Zhiyuan"
      },
      {
        "surname": "Zhang",
        "given_name": "Nian"
      },
      {
        "surname": "Xi",
        "given_name": "Juntong"
      },
      {
        "surname": "Le",
        "given_name": "Xinyi"
      }
    ]
  },
  {
    "title": "DMPP: Differentiable multi-pruner and predictor for neural network pruning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.020",
    "abstract": "Neural network pruning can trim the over-parameterized neural networks effectively by removing a number of network parameters. However, the traditional rule-based approaches always depend on manual experience. Existing heuristic search methods in discrete search spaces are usually time consuming and sub-optimal. In this paper, we develop a differentiable multi-pruner and predictor (DMPP) to prune neural networks automatically. The pruner composed of learnable parameters generates the pruning ratios of all convolutional layers as the continuous representation of the network. The neural network-based predictor is employed to predict the performance of different structures, which can accelerate the search process. Pruner and predictor enable us to directly employ gradient-based optimization to find a better structure. In addition, multi-pruner is presented to improve the efficiency of search, and knowledge distillation is leveraged to improve the performance of the pruned network. To evaluate the effectiveness of the proposed method, extensive experiments are performed on CIFAR-10, CIFAR-100, and ImageNet datasets with VGGNet and ResNet. Results show that the present DMPP can achieve a better performance than many previous state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004998",
    "keywords": [
      "Agronomy",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Convolutional neural network",
      "Differentiable function",
      "Heuristic",
      "Heuristics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Parameterized complexity",
      "Pattern recognition (psychology)",
      "Process (computing)",
      "Pruning"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Jiaxin"
      },
      {
        "surname": "Zhao",
        "given_name": "Bo"
      },
      {
        "surname": "Liu",
        "given_name": "Derong"
      }
    ]
  },
  {
    "title": "Fast writer adaptation with style extractor network for handwritten text recognition",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.002",
    "abstract": "Writing style is an abstract attribute in handwritten text. It plays an important role in recognition systems and is not easy to define explicitly. Considering the effect of writing style, a writer adaptation method is proposed to transform a writer-independent recognizer toward a particular writer. This transformation has the potential to significantly increase accuracy. In this paper, under the deep learning framework, we propose a general fast writer adaptation solution. Specifically, without depending on other complex skills, a well designed style extractor network (SEN) trained by identification loss (IDL) is introduced to explicitly extract personalized writer information. The architecture of SEN consists of a stack of convolutional layers followed by a recurrent neural network with gated recurrent units to remove semantic context and retain writer information. Then, the outputs of the GRU are further integrated into a one-dimensional vector that is adopted to represent writing style. Finally, the extracted style information is fed into the writer-independent recognizer to achieve adaptation. Validated on offline handwritten text recognition tasks, the proposed fast sentence-level adaptation achieves remarkable improvements in Chinese and English text recognition tasks. Specifically, in the HETR task, a multi-information fusion network that is equipped with a hybrid attention mechanism and that integrates visual features, context features and writing style is proposed. In addition, under the same condition (only one writer-specific text line used as adaptation data), the proposed solution, without consuming extra time, can significantly outperform the previous multiple-pass decoding method. The code is available at https://github.com/Wukong90/Handwritten-Text-Recognition.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004755",
    "keywords": [
      "Adaptation (eye)",
      "Archaeology",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Computer science",
      "Context (archaeology)",
      "Convolutional neural network",
      "Economics",
      "History",
      "Linguistics",
      "Management",
      "Natural language processing",
      "Optics",
      "Paleontology",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Sentence",
      "Speech recognition",
      "Style (visual arts)",
      "Task (project management)",
      "Writing style"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Zi-Rui"
      },
      {
        "surname": "Du",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Efficient joint model learning, segmentation and model updating for visual tracking",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.018",
    "abstract": "The Tracking-by-segmentation framework is widely used in visual tracking to handle severe appearance change such as deformation and occlusion. Tracking-by-segmentation methods first segment the target object from the background, then use the segmentation result to estimate the target state. In existing methods, target segmentation is formulated as a superpixel labeling problem constrained by a target likelihood constraint, a spatial smoothness constraint and a temporal consistency constraint. The target likelihood is calculated by a discriminative part model trained independently from the superpixel labeling framework and updated online using historical tracking results as pseudo-labels. Due to the lack of spatial and temporal constraints and inaccurate pseudo-labels, the discriminative model is unreliable and may lead to tracking failure. This paper addresses the aforementioned problems by integrating the objective function of model training into the target segmentation optimization framework. Thus, during the optimization process, the discriminative model can be constrained by spatial and temporal constraints and provides more accurate target likelihoods for part labeling, and the results produce more reliable pseudo-labels for model learning. Moreover, we also propose a supervision switch mechanism to detect erroneous pseudo-labels caused by a severe change in data distribution and switch the classifier to a semi-supervised setting in such a case. Evaluation results on OTB2013, OTB2015 and TC-128 benchmarks demonstrate the effectiveness of the proposed tracking algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004974",
    "keywords": [
      "Active appearance model",
      "Artificial intelligence",
      "Classifier (UML)",
      "Computer science",
      "Computer vision",
      "Discriminative model",
      "Eye tracking",
      "Image (mathematics)",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Segmentation"
    ],
    "authors": [
      {
        "surname": "Han",
        "given_name": "Wei"
      },
      {
        "surname": "Lekamalage",
        "given_name": "Chamara Kasun Liyanaarachchi"
      },
      {
        "surname": "Huang",
        "given_name": "Guang-Bin"
      }
    ]
  },
  {
    "title": "Observer-based adaptive neural tracking control for a class of nonlinear systems with prescribed performance and input dead-zone constraints",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.019",
    "abstract": "This paper investigates the problem of output feedback neural network (NN) learning tracking control for nonlinear strict feedback systems subject to prescribed performance and input dead-zone constraints. First, an NN is utilized to approximate the unknown nonlinear functions, then a state observer is developed to estimate the unmeasurable states. Second, based on the command filter method, an output feedback NN learning backstepping control algorithm is established. Third, a prescribed performance function is employed to ensure the transient performance of the closed-loop systems and forces the tracking error to fall within the prescribed performance boundary. It is rigorously proved mathematically that all the signals in the closed-loop systems are semi-globally uniformly ultimately bounded and the tracking error can converge to an arbitrarily small neighborhood of the origin. Finally, a numerical example and an application example of the electromechanical system are given to show effectiveness of the acquired control algorithm.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004986",
    "keywords": [
      "Adaptive control",
      "Artificial intelligence",
      "Artificial neural network",
      "Backstepping",
      "Boundary (topology)",
      "Bounded function",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Dead zone",
      "Filter (signal processing)",
      "Geology",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Observer (physics)",
      "Oceanography",
      "Pedagogy",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Tracking (education)",
      "Tracking error"
    ],
    "authors": [
      {
        "surname": "Zong",
        "given_name": "Guangdeng"
      },
      {
        "surname": "Wang",
        "given_name": "Yudi"
      },
      {
        "surname": "Karimi",
        "given_name": "Hamid Reza"
      },
      {
        "surname": "Shi",
        "given_name": "Kaibo"
      }
    ]
  },
  {
    "title": "Approximation capabilities of measure-preserving neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.007",
    "abstract": "Measure-preserving neural networks are well-developed invertible models, however, their approximation capabilities remain unexplored. This paper rigorously analyzes the approximation capabilities of existing measure-preserving neural networks including NICE and RevNets. It is shown that for compact U ⊂ R D with D ≥ 2 , the measure-preserving neural networks are able to approximate arbitrary measure-preserving map ψ : U → R D which is bounded and injective in the L p -norm. In particular, any continuously differentiable injective map with ± 1 determinant of Jacobian is measure-preserving, thus can be approximated.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004809",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Bounded function",
      "Computer science",
      "Data mining",
      "Differentiable function",
      "Discrete mathematics",
      "Injective function",
      "Invertible matrix",
      "Jacobian matrix and determinant",
      "Mathematical analysis",
      "Mathematics",
      "Measure (data warehouse)",
      "Pure mathematics",
      "Spurious relationship",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Zhu",
        "given_name": "Aiqing"
      },
      {
        "surname": "Jin",
        "given_name": "Pengzhan"
      },
      {
        "surname": "Tang",
        "given_name": "Yifa"
      }
    ]
  },
  {
    "title": "Corrigendum to “A model of operant learning based on chaotically varying synaptic strength” [Neural Netw. 108 (2018) 114–127]",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2019.02.003",
    "abstract": "",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608019300462",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Mathematics",
      "Neuroscience",
      "Operant conditioning",
      "Psychology",
      "Reinforcement",
      "Social psychology"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Tianqi"
      },
      {
        "surname": "Webb",
        "given_name": "Barbara"
      }
    ]
  },
  {
    "title": "HRel: Filter pruning based on High Relevance between activation maps and class labels",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.017",
    "abstract": "This paper proposes an Information Bottleneck theory based filter pruning method that uses a statistical measure called Mutual Information (MI). The MI between filters and class labels, also called Relevance, is computed using the filter’s activation maps and the annotations. The filters having High Relevance (HRel) are considered to be more important. Consequently, the least important filters, which have lower Mutual Information with the class labels, are pruned. Unlike the existing MI based pruning methods, the proposed method determines the significance of the filters purely based on their corresponding activation map’s relationship with the class labels. Architectures such as LeNet-5, VGG-16, ResNet-56, ResNet-110 and ResNet-50 are utilized to demonstrate the efficacy of the proposed pruning method over MNIST, CIFAR-10 and ImageNet datasets. The proposed method shows the state-of-the-art pruning results for LeNet-5, VGG-16, ResNet-56, ResNet-110 and ResNet-50 architectures. In the experiments, we prune 97.98%, 84.85%, 76.89%, 76.95%, and 63.99% of Floating Point Operation (FLOP)s from LeNet-5, VGG-16, ResNet-56, ResNet-110, and ResNet-50 respectively. The proposed HRel pruning method outperforms recent state-of-the-art filter pruning methods. Even after pruning the filters from convolutional layers of LeNet-5 drastically (i.e., from 20, 50 to 2, 3, respectively), only a small accuracy drop of 0.52% is observed. Notably, for VGG-16, 94.98% parameters are reduced, only with a drop of 0.36% in top-1 accuracy. ResNet-50 has shown a 1.17% drop in the top-5 accuracy after pruning 66.42% of the FLOPs. In addition to pruning, the Information Plane dynamics of Information Bottleneck theory is analyzed for various Convolutional Neural Network architectures with the effect of pruning. The code is available at https://github.com/sarvanichinthapalli/HRel.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004962",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Biology",
      "Class (philosophy)",
      "Computer science",
      "Computer vision",
      "Convolutional neural network",
      "FLOPS",
      "Filter (signal processing)",
      "Law",
      "Mathematics",
      "Parallel computing",
      "Pattern recognition (psychology)",
      "Political science",
      "Pruning",
      "Relevance (law)",
      "Residual neural network"
    ],
    "authors": [
      {
        "surname": "Sarvani",
        "given_name": "C.H."
      },
      {
        "surname": "Ghorai",
        "given_name": "Mrinmoy"
      },
      {
        "surname": "Dubey",
        "given_name": "Shiv Ram"
      },
      {
        "surname": "Basha",
        "given_name": "S.H. Shabbeer"
      }
    ]
  },
  {
    "title": "Command-filter-based adaptive neural tracking control for a class of nonlinear MIMO state-constrained systems with input delay and saturation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.006",
    "abstract": "This paper investigates the problem of adaptive tracking control for a class of nonlinear multi-input and multi-output (MIMO) state-constrained systems with input delay and saturation. During the process of the control scheme, neural network is employed to approximate the unknown nonlinear uncertainties and the appropriate barrier Lyapunov function is introduced to prevent violation of the constraint. In addition, for the issue of input saturation with time delay, a smooth non-affine approximate function and a novel auxiliary system are utilized, respectively. Moreover, adaptive neural tracking control is developed by combining the command filtering backstepping approach, which effectively avoids the explosion of differentiation and reduces the computation burden. The introduced filtering error compensating system brings a significant improvement for the system tracking performance. Finally, the simulation result is presented to verify the feasibility of the proposed strategy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004792",
    "keywords": [
      "Adaptive control",
      "Affine transformation",
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Backstepping",
      "Channel (broadcasting)",
      "Computation",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Control (management)",
      "Control theory (sociology)",
      "Filter (signal processing)",
      "Lyapunov function",
      "MIMO",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Pure mathematics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Zhou",
        "given_name": "Yuhao"
      },
      {
        "surname": "Wang",
        "given_name": "Xin"
      },
      {
        "surname": "Xu",
        "given_name": "Rui"
      }
    ]
  },
  {
    "title": "Symmetric positive definite manifold learning and its application in fault diagnosis",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.12.013",
    "abstract": "Locally linear embedding (LLE) is an effective tool to extract the significant features from a dataset. However, most of the relevant existing algorithms assume that the original dataset resides on a Euclidean space, unfortunately nearly all the original data space is non-Euclidean. In addition, the original LLE does not use the discriminant information of the dataset, which will degrade its performance in feature extraction. To address these problems raised in the conventional LLE, we first employ the original dataset to construct a symmetric positive definite manifold, and then estimate the tangent space of this manifold. Furthermore, the local and global discriminant information are integrated into the LLE, and the improved LLE is operated in the tangent space to extract the important features. We introduce Iris dataset to analyze the capability of the proposed method to extract features. Finally, several experiments are performed on five machinery datasets, and experimental results indicate that our proposed method can extract the excellent low-dimensional representations of the original dataset. Compared with the state-of-the-art methods, the proposed algorithm shows a strong capability for fault diagnosis.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100486X",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Dimensionality reduction",
      "Discriminant",
      "Embedding",
      "Engineering",
      "Euclidean distance",
      "Euclidean space",
      "Feature extraction",
      "Linear discriminant analysis",
      "Manifold (fluid mechanics)",
      "Mathematical analysis",
      "Mathematics",
      "Mechanical engineering",
      "Nonlinear dimensionality reduction",
      "Pattern recognition (psychology)",
      "Tangent space"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Yuanhong"
      },
      {
        "surname": "Hu",
        "given_name": "Zebiao"
      },
      {
        "surname": "Zhang",
        "given_name": "Yansheng"
      }
    ]
  },
  {
    "title": "Feedforward neural networks initialization based on discriminant learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.020",
    "abstract": "In this paper, a novel data-driven method for weight initialization of Multilayer Perceptrons and Convolutional Neural Networks based on discriminant learning is proposed. The approach relaxes some of the limitations of competing data-driven methods, including unimodality assumptions, limitations on the architectures related to limited maximal dimensionalities of the corresponding projection spaces, as well as limitations related to high computational requirements due to the need of eigendecomposition on high-dimensional data. We also consider assumptions of the method on the data and propose a way to account for them in a form of a new normalization layer. The experiments on three large-scale image datasets show improved accuracy of the trained models compared to competing random-based and data-driven weight initialization methods, as well as better convergence properties in certain cases.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004482",
    "keywords": [
      "Algorithm",
      "Anthropology",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Discriminant",
      "Initialization",
      "Machine learning",
      "Normalization (sociology)",
      "Pattern recognition (psychology)",
      "Perceptron",
      "Programming language",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Chumachenko",
        "given_name": "Kateryna"
      },
      {
        "surname": "Iosifidis",
        "given_name": "Alexandros"
      },
      {
        "surname": "Gabbouj",
        "given_name": "Moncef"
      }
    ]
  },
  {
    "title": "Fixed/Preassigned-time synchronization of quaternion-valued neural networks via pure power-law control",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.023",
    "abstract": "The fixed-time synchronization and preassigned-time synchronization of quaternion-valued neural networks are concerned in this article. By developing fixed-time stability and proposing a pure power-law control scheme, some simple conditions are obtained to realize fixed-time synchronization of quaternion-valued neural networks and the upper bound of the synchronized time is provided. Furthermore, the preassigned-time synchronization of quaternion-valued neural networks is investigated based on pure power-law control design, where the synchronization time is preassigned in advance and the control gains are finite. Note that the designed controllers in this paper are the pure power-law forms, which are simpler and more effective compared with the traditional design composed of the linear part and power-law part. Eventually, an example is given to illustrate the feasibility and validity of the results obtained.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004512",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Geometry",
      "Law",
      "Mathematics",
      "Physics",
      "Political science",
      "Power (physics)",
      "Quantum mechanics",
      "Quaternion",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Wei",
        "given_name": "Wanlu"
      },
      {
        "surname": "Yu",
        "given_name": "Juan"
      },
      {
        "surname": "Wang",
        "given_name": "Leimin"
      },
      {
        "surname": "Hu",
        "given_name": "Cheng"
      },
      {
        "surname": "Jiang",
        "given_name": "Haijun"
      }
    ]
  },
  {
    "title": "Imitation and mirror systems in robots through Deep Modality Blending Networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.004",
    "abstract": "Learning to interact with the environment not only empowers the agent with manipulation capability but also generates information to facilitate building of action understanding and imitation capabilities. This seems to be a strategy adopted by biological systems, in particular primates, as evidenced by the existence of mirror neurons that seem to be involved in multi-modal action understanding. How to benefit from the interaction experience of the robots to enable understanding actions and goals of other agents is still a challenging question. In this study, we propose a novel method, deep modality blending networks (DMBN), that creates a common latent space from multi-modal experience of a robot by blending multi-modal signals with a stochastic weighting mechanism. We show for the first time that deep learning, when combined with a novel modality blending scheme, can facilitate action recognition and produce structures to sustain anatomical and effect-based imitation capabilities. Our proposed system, which is based on conditional neural processes, can be conditioned on any desired sensory/motor value at any time step, and can generate a complete multi-modal trajectory consistent with the desired conditioning in one-shot by querying the network for all the sampled time points in parallel avoiding the accumulation of prediction errors. Based on simulation experiments with an arm-gripper robot and an RGB camera, we showed that DMBN could make accurate predictions about any missing modality (camera or joint angles) given the available ones outperforming recent multimodal variational autoencoder models in terms of long-horizon high-dimensional trajectory predictions. We further showed that given desired images from different perspectives, i.e. images generated by the observation of other robots placed on different sides of the table, our system could generate image and joint angle sequences that correspond to either anatomical or effect-based imitation behavior. To achieve this mirror-like behavior, our system does not perform a pixel-based template matching but rather benefits from and relies on the common latent space constructed by using both joint and image modalities, as shown by additional experiments. Moreover, we showed that mirror learning (in our system) does not only depend on visual experience and cannot be achieved without proprioceptive experience. Our experiments showed that out of ten training scenarios with different initial configurations, the proposed DMBN model could achieve mirror learning in all of the cases where the model that only uses visual information failed in half of them. Overall, the proposed DMBN architecture not only serves as a computational model for sustaining mirror neuron-like capabilities, but also stands as a powerful machine learning architecture for high-dimensional multi-modal temporal data with robust retrieval capabilities operating with partial information in one or multiple modalities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004329",
    "keywords": [
      "Action (physics)",
      "Artificial intelligence",
      "Artificial neural network",
      "Astronomy",
      "Autoencoder",
      "Computer science",
      "Computer vision",
      "Deep learning",
      "Dropout (neural networks)",
      "Imitation",
      "Machine learning",
      "Modality (human–computer interaction)",
      "Physics",
      "Psychology",
      "Quantum mechanics",
      "Robot",
      "Social psychology",
      "Trajectory"
    ],
    "authors": [
      {
        "surname": "Seker",
        "given_name": "M. Yunus"
      },
      {
        "surname": "Ahmetoglu",
        "given_name": "Alper"
      },
      {
        "surname": "Nagai",
        "given_name": "Yukie"
      },
      {
        "surname": "Asada",
        "given_name": "Minoru"
      },
      {
        "surname": "Oztop",
        "given_name": "Erhan"
      },
      {
        "surname": "Ugur",
        "given_name": "Emre"
      }
    ]
  },
  {
    "title": "A second-order accelerated neurodynamic approach for distributed convex optimization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.013",
    "abstract": "Based on the theories of inertial systems, a second-order accelerated neurodynamic approach is designed to solve a distributed convex optimization with inequality and set constraints. Most of the existing approaches for distributed convex optimization problems are usually first-order ones, and it is usually hard to analyze the convergence rate for the state solution of those first-order approaches. Due to the control design for the acceleration, the second-order neurodynamic approaches can often achieve faster convergence rate. Moreover, the existing second-order approaches are mostly designed to solve unconstrained distributed convex optimization problems, and are not suitable for solving constrained distributed convex optimization problems. It is acquired that the state solution of the designed neurodynamic approach in this paper converges to the optimal solution of the considered distributed convex optimization problem. An error function which demonstrates the performance of the designed neurodynamic approach, has a superquadratic convergence. Several numerical examples are provided to show the effectiveness of the presented second-order accelerated neurodynamic approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100441X",
    "keywords": [
      "Channel (broadcasting)",
      "Computer network",
      "Computer science",
      "Convergence (economics)",
      "Convex function",
      "Convex optimization",
      "Economic growth",
      "Economics",
      "Geometry",
      "Linear matrix inequality",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Rate of convergence",
      "Regular polygon"
    ],
    "authors": [
      {
        "surname": "Jiang",
        "given_name": "Xinrui"
      },
      {
        "surname": "Qin",
        "given_name": "Sitian"
      },
      {
        "surname": "Xue",
        "given_name": "Xiaoping"
      },
      {
        "surname": "Liu",
        "given_name": "Xinzhi"
      }
    ]
  },
  {
    "title": "CSITime: Privacy-preserving human activity recognition using WiFi channel state information",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.011",
    "abstract": "Human activity recognition (HAR) is an important task in many applications such as smart homes, sports analysis, healthcare services, etc. Popular modalities for human activity recognition involving computer vision and inertial sensors are in the literature for solving HAR, however, they face serious limitations with respect to different illumination, background, clutter, obtrusiveness, and other factors. In recent years, WiFi channel state information (CSI) based activity recognition is gaining momentum due to its many advantages including easy deployability, and cost-effectiveness. This work proposes CSITime, a modified InceptionTime network architecture, a generic architecture for CSI-based human activity recognition. We perceive CSI activity recognition as a multi-variate time series problem. The methodology of CSITime is threefold. First, we pre-process CSI signals followed by data augmentation using two label-mixing strategies — mixup and cutmix to enhance the neural network’s learning. Second, in the basic block of CSITime, features from multiple convolutional kernels are concatenated and passed through a self-attention layer followed by a fully connected layer with Mish activation. CSITime network consists of six such blocks followed by a global average pooling layer and a final fully connected layer for the final classification. Third, in the training of the neural network, instead of adopting general training procedures such as early stopping, we use one-cycle policy and cosine annealing to monitor the learning rate. The proposed model has been tested on publicly available benchmark datasets, i . e . , ARIL, StanWiFi, and SignFi datasets. The proposed CSITime has achieved accuracy of 98.20%, 98%, and 95.42% on ARIL, StanWiFi, and SignFi datasets, respectively, for WiFi-based activity recognition. This is an improvement on state-of-the-art accuracies by 3.3%, 0.67%, and 0.82% on ARIL, StanWiFi, and SignFi datasets, respectively. In lab-5 users’ scenario of the SignFi dataset, which has the training and testing data from different distributions, our model achieved accuracy was 2.17% higher than state-of-the-art, which shows the comparative robustness of our model.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004391",
    "keywords": [
      "Activity recognition",
      "Artificial intelligence",
      "Artificial neural network",
      "Benchmark (surveying)",
      "Channel state information",
      "Computer science",
      "Convolutional neural network",
      "Facial recognition system",
      "Geodesy",
      "Geography",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Telecommunications",
      "Wireless"
    ],
    "authors": [
      {
        "surname": "Yadav",
        "given_name": "Santosh Kumar"
      },
      {
        "surname": "Sai",
        "given_name": "Siva"
      },
      {
        "surname": "Gundewar",
        "given_name": "Akshay"
      },
      {
        "surname": "Rathore",
        "given_name": "Heena"
      },
      {
        "surname": "Tiwari",
        "given_name": "Kamlesh"
      },
      {
        "surname": "Pandey",
        "given_name": "Hari Mohan"
      },
      {
        "surname": "Mathur",
        "given_name": "Mohit"
      }
    ]
  },
  {
    "title": "Predictive accuracy of CNN for cortical oscillatory activity in an acute rat model of parkinsonism",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.025",
    "abstract": "In neurological and neuropsychiatric disorders neuronal oscillatory activity between basal ganglia and cortical circuits are altered, which may be useful as biomarker for adaptive deep brain stimulation. We investigated whether changes in the spectral power of oscillatory activity in the motor cortex (MCtx) and the sensorimotor cortex (SMCtx) of rats after injection of the dopamine (DA) receptor antagonist haloperidol (HALO) would be similar to those observed in Parkinson disease. Thereafter, we tested whether a convolutional neural network (CNN) model would identify brain signal alterations in this acute model of parkinsonism. A sixteen channel surface micro-electrocorticogram (ECoG) recording array was placed under the dura above the MCtx and SMCtx areas of one hemisphere under general anaesthesia in rats. Seven days after surgery, micro ECoG was recorded in individual free moving rats in three conditions: (1) basal activity, (2) after injection of HALO (0.5 mg/kg), and (3) with additional injection of apomorphine (APO) (1 mg/kg). Furthermore, a CNN-based classification consisting of 23,530 parameters was applied on the raw data. HALO injection decreased oscillatory theta band activity (4–8 Hz) and enhanced beta (12–30 Hz) and gamma (30–100 Hz) in MCtx and SMCtx, which was compensated after APO injection (P ¡ 0.001). Evaluation of classification performance of the CNN model provided accuracy of 92%, sensitivity of 90% and specificity of 93% on one-dimensional signals. The CNN proposed model requires a minimum of sensory hardware and may be integrated into future research on therapeutic devices for Parkinson disease, such as adaptive closed loop stimulation, thus contributing to more efficient way of treatment.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004664",
    "keywords": [
      "Basal ganglia",
      "Central nervous system",
      "Deep brain stimulation",
      "Disease",
      "Internal medicine",
      "Local field potential",
      "Medicine",
      "Neuroscience",
      "Parkinson's disease",
      "Parkinsonism",
      "Psychology",
      "Stimulation"
    ],
    "authors": [
      {
        "surname": "Abdul Nabi Ali",
        "given_name": "Ali"
      },
      {
        "surname": "Alam",
        "given_name": "Mesbah"
      },
      {
        "surname": "Klein",
        "given_name": "Simon C."
      },
      {
        "surname": "Behmann",
        "given_name": "Nicolai"
      },
      {
        "surname": "Krauss",
        "given_name": "Joachim K."
      },
      {
        "surname": "Doll",
        "given_name": "Theodor"
      },
      {
        "surname": "Blume",
        "given_name": "Holger"
      },
      {
        "surname": "Schwabe",
        "given_name": "Kerstin"
      }
    ]
  },
  {
    "title": "Multi-view Teacher–Student Network",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.002",
    "abstract": "Multi-view learning aims to fully exploit the view-consistency and view-discrepancy for performance improvement. Knowledge Distillation (KD), characterized by the so-called “Teacher–Student” (T-S) learning framework, can transfer information learned from one model to another. Inspired by knowledge distillation, we propose a Multi-view Teacher–Student Network (MTS-Net), which combines knowledge distillation and multi-view learning into a unified framework. We first redefine the teacher and student for the multi-view case. Then the MTS-Net is built by optimizing both the view classification loss and the knowledge distillation loss in an end-to-end training manner. We further extend MTS-Net to image recognition tasks and present a multi-view Teacher–Student framework with convolutional neural networks called MTSCNN. To the best of our knowledge, MTS-Net and MTSCNN bring a new insight to extend the Teacher–Student framework to tackle the multi-view learning problem. We theoretically verify the mechanism of MTS-Net and MTSCNN and comprehensive experiments demonstrate the effectiveness of the proposed methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004305",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Consistency (knowledge bases)",
      "Convolutional neural network",
      "Distillation",
      "Exploit",
      "Geometry",
      "Machine learning",
      "Mathematics",
      "Net (polyhedron)",
      "Organic chemistry"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Yingjie"
      },
      {
        "surname": "Sun",
        "given_name": "Shiding"
      },
      {
        "surname": "Tang",
        "given_name": "Jingjing"
      }
    ]
  },
  {
    "title": "Multi-layer information fusion based on graph convolutional network for knowledge-driven herb recommendation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.010",
    "abstract": "Prescription of Traditional Chinese Medicine (TCM) is a precious treasure accumulated in the long-term development of TCM. Artificial intelligence (AI) technology is used to build herb recommendation models to deeply understand regularities in prescriptions, which is of great significance to clinical application of TCM and discovery of new prescriptions. Most of herb recommendation models constructed in the past ignored the nature information of herbs, and most of them used statistical models based on bag-of-words for herb recommendation, which makes it difficult for the model to perceive the complex correlation between symptoms and herbs. In this paper, we introduce the properties of herbs as additional auxiliary information by constructing herb knowledge graph, and propose a graph convolution model with multi-layer information fusion to obtain symptom feature representations and herb feature representations with rich information and less noise. We apply the proposed model to the TCM prescription dataset, and the experiment results show that our model outperforms the baseline models in terms of Precision@5 by 6.2%, Recall@5 by 16.0% and F1-Score@5 by 12.0%.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100438X",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Herb",
      "Medical prescription",
      "Medicinal herbs",
      "Medicine",
      "Pharmacology",
      "Theoretical computer science",
      "Traditional medicine"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yun"
      },
      {
        "surname": "Rao",
        "given_name": "Yulong"
      },
      {
        "surname": "Yu",
        "given_name": "Minghao"
      },
      {
        "surname": "Kang",
        "given_name": "Yan"
      }
    ]
  },
  {
    "title": "ARCNN framework for multimodal infodemic detection",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.006",
    "abstract": "Fake news and misinformation have adopted various propagation media over time, nowadays spreading predominantly through online social networks. During the ongoing COVID-19 pandemic, false information is affecting human life in many spheres The world needs automated detection technology and efforts are being made to meet this requirement with the use of artificial intelligence. Neural network detection mechanisms are robust and durable and hence are used extensively in fake news detection. Deep learning algorithms demonstrate efficiency when they are provided with a large amount of training data. Given the scarcity of relevant fake news datasets, we built the Coronavirus Infodemic Dataset (CovID), which contains fake news posts and articles related to coronavirus. This paper presents a novel framework, the Allied Recurrent and Convolutional Neural Network (ARCNN), to detect fake news based on two different modalities: text and image. Our approach uses recurrent neural networks (RNNs) and convolutional neural networks (CNNs) and combines both streams to generate a final prediction. We present extensive research on various popular RNN and CNN models and their performance on six coronavirus-specific fake news datasets. To exhaustively analyze performance, we present experimentation performed and results obtained by combining both modalities using early fusion and four types of late fusion techniques. The proposed framework is validated by comparisons with state-of-the-art fake news detection mechanisms, and our models outperform each of them.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004342",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Deep learning",
      "Machine learning",
      "Misinformation",
      "Modalities",
      "Recurrent neural network",
      "Social media",
      "Social science",
      "Sociology",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Raj",
        "given_name": "Chahat"
      },
      {
        "surname": "Meel",
        "given_name": "Priyanka"
      }
    ]
  },
  {
    "title": "Dilated projection correction network based on autoencoder for hyperspectral image super-resolution",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.014",
    "abstract": "This paper focuses on improving the spatial resolution of the hyperspectral image (HSI) by taking the prior information into consideration. In recent years, single HSI super-resolution methods based on deep learning have achieved good performance. However, most of them only simply apply general image super-resolution deep networks to hyperspectral data, thus ignoring some specific characteristics of hyperspectral data itself. In order to make full use of spectral information of the HSI, we transform the HSI SR problem from the image domain into the abundance domain by the dilated projection correction network with an autoencoder, termed as aeDPCN. In particular, we first encode the low-resolution HSI to abundance representation and preserve the spectral information in the decoder network, which could largely reduce the computational complexity. Then, to enhance the spatial resolution of the abundance embedding, we super-resolve the embedding in a coarse-to-fine manner by the dilated projection correction network where the back-projection strategy is introduced to further eliminate spectral distortion. Finally, the predictive images are derived by the same decoder, which increases the stability of our method, even at a large upscaling factor. Extensive experiments on real hyperspectral image scenes demonstrate the superiority of our method over the state-of-the-art, in terms of accuracy and efficiency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004421",
    "keywords": [
      "Algorithm",
      "Amplifier",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Bandwidth (computing)",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Distortion (music)",
      "Embedding",
      "Hyperspectral imaging",
      "Image (mathematics)",
      "Image resolution",
      "Law",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Projection (relational algebra)",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Xinya"
      },
      {
        "surname": "Ma",
        "given_name": "Jiayi"
      },
      {
        "surname": "Jiang",
        "given_name": "Junjun"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiao-Ping"
      }
    ]
  },
  {
    "title": "NeuroLISP: High-level symbolic programming with attractor neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.009",
    "abstract": "Despite significant improvements in contemporary machine learning, symbolic methods currently outperform artificial neural networks on tasks that involve compositional reasoning, such as goal-directed planning and logical inference. This illustrates a computational explanatory gap between cognitive and neurocomputational algorithms that obscures the neurobiological mechanisms underlying cognition and impedes progress toward human-level artificial intelligence. Because of the strong relationship between cognition and working memory control, we suggest that the cognitive abilities of contemporary neural networks are limited by biologically-implausible working memory systems that rely on persistent activity maintenance and/or temporal nonlocality. Here we present NeuroLISP, an attractor neural network that can represent and execute programs written in the LISP programming language. Unlike previous approaches to high-level programming with neural networks, NeuroLISP features a temporally-local working memory based on itinerant attractor dynamics, top-down gating, and fast associative learning, and implements several high-level programming constructs such as compositional data structures, scoped variable binding, and the ability to manipulate and execute programmatic expressions in working memory (i.e., programs can be treated as data). Our computational experiments demonstrate the correctness of the NeuroLISP interpreter, and show that it can learn non-trivial programs that manipulate complex derived data structures (multiway trees), perform compositional string manipulation operations (PCFG SET task), and implement high-level symbolic AI algorithms (first-order unification). We conclude that NeuroLISP is an effective neurocognitive controller that can replace the symbolic components of hybrid models, and serves as a proof of concept for further development of high-level symbolic programming in neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004378",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Attractor",
      "Computer science",
      "Inductive programming",
      "Lisp",
      "Mathematical analysis",
      "Mathematics",
      "Programming language",
      "Programming paradigm",
      "Set (abstract data type)",
      "Symbolic programming",
      "Theoretical computer science",
      "Unification"
    ],
    "authors": [
      {
        "surname": "Davis",
        "given_name": "Gregory P."
      },
      {
        "surname": "Katz",
        "given_name": "Garrett E."
      },
      {
        "surname": "Gentili",
        "given_name": "Rodolphe J."
      },
      {
        "surname": "Reggia",
        "given_name": "James A."
      }
    ]
  },
  {
    "title": "Dilated projection correction network based on autoencoder for hyperspectral image super-resolution",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.014",
    "abstract": "This paper focuses on improving the spatial resolution of the hyperspectral image (HSI) by taking the prior information into consideration. In recent years, single HSI super-resolution methods based on deep learning have achieved good performance. However, most of them only simply apply general image super-resolution deep networks to hyperspectral data, thus ignoring some specific characteristics of hyperspectral data itself. In order to make full use of spectral information of the HSI, we transform the HSI SR problem from the image domain into the abundance domain by the dilated projection correction network with an autoencoder, termed as aeDPCN. In particular, we first encode the low-resolution HSI to abundance representation and preserve the spectral information in the decoder network, which could largely reduce the computational complexity. Then, to enhance the spatial resolution of the abundance embedding, we super-resolve the embedding in a coarse-to-fine manner by the dilated projection correction network where the back-projection strategy is introduced to further eliminate spectral distortion. Finally, the predictive images are derived by the same decoder, which increases the stability of our method, even at a large upscaling factor. Extensive experiments on real hyperspectral image scenes demonstrate the superiority of our method over the state-of-the-art, in terms of accuracy and efficiency.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004421",
    "keywords": [
      "Algorithm",
      "Amplifier",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Bandwidth (computing)",
      "Computer network",
      "Computer science",
      "Computer vision",
      "Distortion (music)",
      "Embedding",
      "Hyperspectral imaging",
      "Image (mathematics)",
      "Image resolution",
      "Law",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Projection (relational algebra)",
      "Representation (politics)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Xinya"
      },
      {
        "surname": "Ma",
        "given_name": "Jiayi"
      },
      {
        "surname": "Jiang",
        "given_name": "Junjun"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiao-Ping"
      }
    ]
  },
  {
    "title": "NeuroLISP: High-level symbolic programming with attractor neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.009",
    "abstract": "Despite significant improvements in contemporary machine learning, symbolic methods currently outperform artificial neural networks on tasks that involve compositional reasoning, such as goal-directed planning and logical inference. This illustrates a computational explanatory gap between cognitive and neurocomputational algorithms that obscures the neurobiological mechanisms underlying cognition and impedes progress toward human-level artificial intelligence. Because of the strong relationship between cognition and working memory control, we suggest that the cognitive abilities of contemporary neural networks are limited by biologically-implausible working memory systems that rely on persistent activity maintenance and/or temporal nonlocality. Here we present NeuroLISP, an attractor neural network that can represent and execute programs written in the LISP programming language. Unlike previous approaches to high-level programming with neural networks, NeuroLISP features a temporally-local working memory based on itinerant attractor dynamics, top-down gating, and fast associative learning, and implements several high-level programming constructs such as compositional data structures, scoped variable binding, and the ability to manipulate and execute programmatic expressions in working memory (i.e., programs can be treated as data). Our computational experiments demonstrate the correctness of the NeuroLISP interpreter, and show that it can learn non-trivial programs that manipulate complex derived data structures (multiway trees), perform compositional string manipulation operations (PCFG SET task), and implement high-level symbolic AI algorithms (first-order unification). We conclude that NeuroLISP is an effective neurocognitive controller that can replace the symbolic components of hybrid models, and serves as a proof of concept for further development of high-level symbolic programming in neural networks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004378",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Attractor",
      "Computer science",
      "Inductive programming",
      "Lisp",
      "Mathematical analysis",
      "Mathematics",
      "Programming language",
      "Programming paradigm",
      "Set (abstract data type)",
      "Symbolic programming",
      "Theoretical computer science",
      "Unification"
    ],
    "authors": [
      {
        "surname": "Davis",
        "given_name": "Gregory P."
      },
      {
        "surname": "Katz",
        "given_name": "Garrett E."
      },
      {
        "surname": "Gentili",
        "given_name": "Rodolphe J."
      },
      {
        "surname": "Reggia",
        "given_name": "James A."
      }
    ]
  },
  {
    "title": "LOss-Based SensiTivity rEgulaRization: Towards deep sparse neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.029",
    "abstract": "LOBSTER (LOss-Based SensiTivity rEgulaRization) is a method for training neural networks having a sparse topology. Let the sensitivity of a network parameter be the variation of the loss function with respect to the variation of the parameter. Parameters with low sensitivity, i.e. having little impact on the loss when perturbed, are shrunk and then pruned to sparsify the network. Our method allows to train a network from scratch, i.e. without preliminary learning or rewinding. Experiments on multiple architectures and datasets show competitive compression ratios with minimal computational overhead.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004706",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Astrophysics",
      "Computer science",
      "Electronic engineering",
      "Engineering",
      "Pattern recognition (psychology)",
      "Physics",
      "Regularization (linguistics)",
      "Sensitivity (control systems)",
      "Variation (astronomy)"
    ],
    "authors": [
      {
        "surname": "Tartaglione",
        "given_name": "Enzo"
      },
      {
        "surname": "Bragagnolo",
        "given_name": "Andrea"
      },
      {
        "surname": "Fiandrotti",
        "given_name": "Attilio"
      },
      {
        "surname": "Grangetto",
        "given_name": "Marco"
      }
    ]
  },
  {
    "title": "An inertial neural network approach for robust time-of-arrival localization considering clock asynchronization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.012",
    "abstract": "This paper presents an inertial neural network to solve the source localization optimization problem with l 1 -norm objective function based on the time of arrival (TOA) localization technique. The convergence and stability of the inertial neural network are analyzed by the Lyapunov function method. An inertial neural network iterative approach is further used to find a better solution among the solutions with different inertial parameters. Furthermore, the clock asynchronization is considered in the TOA l 1 -norm model for more general real applications, and the corresponding inertial neural network iterative approach is addressed. The numerical simulations and real data are both considered in the experiments. In the simulation experiments, the noise contains uncorrelated zero-mean Gaussian noise and uniform distributed outliers. In the real experiments, the data is obtained by using the ultra wide band (UWB) technology hardware modules. Whether or not there is clock asynchronization, the results show that the proposed approach always can find a more accurate source position compared with some of the existing algorithms, which implies that the proposed approach is more effective than the compared ones.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004408",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Gaussian",
      "Gaussian noise",
      "Inertial frame of reference",
      "Inertial navigation system",
      "Outlier",
      "Physics",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Xu",
        "given_name": "Chentao"
      },
      {
        "surname": "Liu",
        "given_name": "Qingshan"
      }
    ]
  },
  {
    "title": "Multi-view Teacher–Student Network",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.002",
    "abstract": "Multi-view learning aims to fully exploit the view-consistency and view-discrepancy for performance improvement. Knowledge Distillation (KD), characterized by the so-called “Teacher–Student” (T-S) learning framework, can transfer information learned from one model to another. Inspired by knowledge distillation, we propose a Multi-view Teacher–Student Network (MTS-Net), which combines knowledge distillation and multi-view learning into a unified framework. We first redefine the teacher and student for the multi-view case. Then the MTS-Net is built by optimizing both the view classification loss and the knowledge distillation loss in an end-to-end training manner. We further extend MTS-Net to image recognition tasks and present a multi-view Teacher–Student framework with convolutional neural networks called MTSCNN. To the best of our knowledge, MTS-Net and MTSCNN bring a new insight to extend the Teacher–Student framework to tackle the multi-view learning problem. We theoretically verify the mechanism of MTS-Net and MTSCNN and comprehensive experiments demonstrate the effectiveness of the proposed methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004305",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Computer science",
      "Computer security",
      "Consistency (knowledge bases)",
      "Convolutional neural network",
      "Distillation",
      "Exploit",
      "Geometry",
      "Machine learning",
      "Mathematics",
      "Net (polyhedron)",
      "Organic chemistry"
    ],
    "authors": [
      {
        "surname": "Tian",
        "given_name": "Yingjie"
      },
      {
        "surname": "Sun",
        "given_name": "Shiding"
      },
      {
        "surname": "Tang",
        "given_name": "Jingjing"
      }
    ]
  },
  {
    "title": "Understanding and mitigating noise in trained deep neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.008",
    "abstract": "Deep neural networks unlocked a vast range of new applications by solving tasks of which many were previously deemed as reserved to higher human intelligence. One of the developments enabling this success was a boost in computing power provided by special purpose hardware, such as graphic or tensor processing units. However, these do not leverage fundamental features of neural networks like parallelism and analog state variables. Instead, they emulate neural networks relying on binary computing, which results in unsustainable energy consumption and comparatively low speed. Fully parallel and analogue hardware promises to overcome these challenges, yet the impact of analogue neuron noise and its propagation, i.e. accumulation, threatens rendering such approaches inept. Here, we determine for the first time the propagation of noise in deep neural networks comprising noisy nonlinear neurons in trained fully connected layers. We study additive and multiplicative as well as correlated and uncorrelated noise, and develop analytical methods that predict the noise level in any layer of symmetric deep neural networks or deep neural networks trained with back propagation. We find that noise accumulation is generally bound, and adding additional network layers does not worsen the signal to noise ratio beyond a limit. Most importantly, noise accumulation can be suppressed entirely when neuron activation functions have a slope smaller than unity. We therefore developed the framework for noise in fully connected deep neural networks implemented in analog systems, and identify criteria allowing engineers to design noise-resilient novel neural network hardware.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004366",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Artificial noise",
      "Channel (broadcasting)",
      "Computer science",
      "Deep learning",
      "Deep neural networks",
      "Image (mathematics)",
      "Massively parallel",
      "Noise (video)",
      "Parallel computing",
      "Rendering (computer graphics)",
      "Telecommunications",
      "Transmitter"
    ],
    "authors": [
      {
        "surname": "Semenova",
        "given_name": "Nadezhda"
      },
      {
        "surname": "Larger",
        "given_name": "Laurent"
      },
      {
        "surname": "Brunner",
        "given_name": "Daniel"
      }
    ]
  },
  {
    "title": "Computational epidemiology study of homeostatic compensation during sensorimotor aging",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.024",
    "abstract": "The vestibulo-ocular reflex (VOR) stabilizes vision during head motion. Age-related changes of vestibular neuroanatomical properties predict a linear decay of VOR function. Nonetheless, human epidemiological data show a stable VOR function across the life span. In this study, we model cerebellum-dependent VOR adaptation to relate structural and functional changes throughout aging. We consider three neurosynaptic factors that may codetermine VOR adaptation during aging: the electrical coupling of inferior olive neurons, the long-term spike timing-dependent plasticity at parallel fiber – Purkinje cell synapses and mossy fiber – medial vestibular nuclei synapses, and the intrinsic plasticity of Purkinje cell synapses Our cross-sectional aging analyses suggest that long-term plasticity acts as a global homeostatic mechanism that underpins the stable temporal profile of VOR function. The results also suggest that the intrinsic plasticity of Purkinje cell synapses operates as a local homeostatic mechanism that further sustains the VOR at older ages. Importantly, the computational epidemiology approach presented in this study allows discrepancies among human cross-sectional studies to be understood in terms of interindividual variability in older individuals. Finally, our longitudinal aging simulations show that the amount of residual fibers coding for the peak and trough of the VOR cycle constitutes a predictive hallmark of VOR trajectories over a lifetime.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004652",
    "keywords": [
      "Biochemistry",
      "Biology",
      "Cerebellar cortex",
      "Cerebellum",
      "Homeostatic plasticity",
      "Metaplasticity",
      "Neuroscience",
      "Parallel fiber",
      "Psychology",
      "Purkinje cell",
      "Receptor",
      "Synaptic plasticity",
      "Vestibular system"
    ],
    "authors": [
      {
        "surname": "Luque",
        "given_name": "Niceto R."
      },
      {
        "surname": "Naveros",
        "given_name": "Francisco"
      },
      {
        "surname": "Sheynikhovich",
        "given_name": "Denis"
      },
      {
        "surname": "Ros",
        "given_name": "Eduardo"
      },
      {
        "surname": "Arleo",
        "given_name": "Angelo"
      }
    ]
  },
  {
    "title": "A hybridization of distributed policy and heuristic augmentation for improving federated learning approach",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.018",
    "abstract": "Modifying the existing models of classifiers’ operation is primarily aimed at increasing the effectiveness as well as minimizing the training time. An additional advantage is the ability to quickly implement a given solution to the real needs of the market. In this paper, we propose a method that can implement various classifiers using the federated learning concept and taking into account parallelism. Also, an important element is the analysis and selection of the best classifier depending on its reliability found for separated datasets extended by new, augmented samples. The proposed augmentation technique involves image processing techniques, neural architectures, and heuristic methods and improves the operation in federated learning by increasing the role of the server. The proposition has been presented and tested for the fruit image classification problem. The conducted experiments have shown that the described technique can be very useful as an implementation method even in the case of a small database. Obtained results are discussed concerning the advantages and disadvantages in the context of practical application like higher accuracy.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004469",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Computer science",
      "Data mining",
      "Heuristic",
      "Machine learning",
      "Physics",
      "Power (physics)",
      "Quantum mechanics",
      "Reliability (semiconductor)"
    ],
    "authors": [
      {
        "surname": "Połap",
        "given_name": "Dawid"
      },
      {
        "surname": "Woźniak",
        "given_name": "Marcin"
      }
    ]
  },
  {
    "title": "Stability and dissipativity criteria for neural networks with time-varying delays via an augmented zero equality approach",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.007",
    "abstract": "This work investigates the stability and dissipativity problems for neural networks with time-varying delay. By the construction of new augmented Lyapunov–Krasovskii functionals based on integral inequality and the use of zero equality approach, three improved results are proposed in the forms of linear matrix inequalities. And, based on the stability results, the dissipativity analysis for NNs with time-varying delays was investigated. Through some numerical examples, the superiority and effectiveness of the proposed results are shown by comparing the existing works.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004354",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Engineering",
      "Linear matrix inequality",
      "Linguistics",
      "Machine learning",
      "Materials science",
      "Mathematical optimization",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Mechanical engineering",
      "Philosophy",
      "Stability (learning theory)",
      "Work (physics)",
      "Zero (linguistics)"
    ],
    "authors": [
      {
        "surname": "Lee",
        "given_name": "S.H."
      },
      {
        "surname": "Park",
        "given_name": "M.J."
      },
      {
        "surname": "Ji",
        "given_name": "D.H."
      },
      {
        "surname": "Kwon",
        "given_name": "O.M."
      }
    ]
  },
  {
    "title": "Leveraging hierarchy in multimodal generative models for effective cross-modality inference",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.019",
    "abstract": "This work addresses the problem of cross-modality inference (CMI), i.e., inferring missing data of unavailable perceptual modalities (e.g., sound) using data from available perceptual modalities (e.g., image). We overview single-modality variational autoencoder methods and discuss three problems of computational cross-modality inference, arising from recent developments in multimodal generative models. Inspired by neural mechanisms of human recognition, we contribute the Nexus model, a novel hierarchical generative model that can learn a multimodal representation of an arbitrary number of modalities in an unsupervised way. By exploiting hierarchical representation levels, Nexus is able to generate high-quality, coherent data of missing modalities given any subset of available modalities. To evaluate CMI in a natural scenario with a high number of modalities, we contribute the “Multimodal Handwritten Digit” (MHD) dataset, a novel benchmark dataset that combines image, motion, sound and label information from digit handwriting. We access the key role of hierarchy in enabling high-quality samples during cross-modality inference and discuss how a novel training scheme enables Nexus to learn a multimodal representation robust to missing modalities at test time. Our results show that Nexus outperforms current state-of-the-art multimodal generative models in regards to their cross-modality inference capabilities.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004470",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Economics",
      "Generative grammar",
      "Generative model",
      "Geodesy",
      "Geography",
      "Hierarchy",
      "Inference",
      "Law",
      "Machine learning",
      "Market economy",
      "Modalities",
      "Modality (human–computer interaction)",
      "Multimodal learning",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Social science",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Vasco",
        "given_name": "Miguel"
      },
      {
        "surname": "Yin",
        "given_name": "Hang"
      },
      {
        "surname": "Melo",
        "given_name": "Francisco S."
      },
      {
        "surname": "Paiva",
        "given_name": "Ana"
      }
    ]
  },
  {
    "title": "Deep semi-supervised learning via dynamic anchor graph embedding in latent space",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.026",
    "abstract": "Recently, deep semi-supervised graph embedding learning has drawn much attention for its appealing performance on the data with a pre-specified graph structure, which could be predefined or empirically constructed based on given data samples. However, the pre-specified graphs often contain considerable noisy/inaccurate connections and have a huge size for large datasets. Most existing embedding algorithms just take the graph off the shelf during the whole training stage and thus are easy to be misled by the inaccurate graph edges, as well as may result in large model size. In this paper, we attempt to address these issues by proposing a novel deep semi-supervised algorithm for simultaneous graph embedding and node classification, utilizing dynamic graph learning in neural network hidden layer space. Particularly, we construct an anchor graph to summarize the whole dataset using the hidden layer features of a consistency-constrained network. The anchor graph is used for sampling node neighborhood context, which is then presented together with node labels as contextual information to train an embedding network. The outputs of the consistency network and the embedding networks are finally concatenated together to pass a softmax function to perform node classification. The two networks are optimized jointly using both labeled and unlabeled data to minimize a single semi-supervised objective function, including a cross-entropy loss, a consistency loss and an embedding loss. Extensive experimental results on popular image and text datasets have shown that the proposed method is able to improve the performance of existing graph embedding and node classification methods, and outperform many state-of-the-art approaches on both types of datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004676",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Embedding",
      "Graph",
      "Graph embedding",
      "Machine learning",
      "Pattern recognition (psychology)",
      "Semi-supervised learning",
      "Softmax function",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Tu",
        "given_name": "Enmei"
      },
      {
        "surname": "Wang",
        "given_name": "Zihao"
      },
      {
        "surname": "Yang",
        "given_name": "Jie"
      },
      {
        "surname": "Kasabov",
        "given_name": "Nikola"
      }
    ]
  },
  {
    "title": "Event-centric multi-modal fusion method for dense video captioning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.017",
    "abstract": "Dense video captioning aims to automatically describe several events that occur in a given video, which most state-of-the-art models accomplish by locating and describing multiple events in an untrimmed video. Despite much progress in this area, most current approaches only encode visual features in the event location phase and they neglect the relationships between events, which may degrade the consistency of the description in the identical video. Thus, in the present study, we attempted to exploit visual–audio cues to generate event proposals and enhance event-level representations by capturing their temporal and semantic relationships. Furthermore, to compensate for the major limitation of not fully utilizing multimodal information in the description process, we developed an attention-gating mechanism that dynamically fuses and regulates the multi-modal information. In summary, we propose an event-centric multi-modal fusion approach for dense video captioning (EMVC) to capture the relationships between events and effectively fuse multi-modal information. We conducted comprehensive experiments to evaluate the performance of EMVC based on the benchmark ActivityNet Caption and YouCook2 data sets. The experimental results showed that our model achieved impressive performance compared with state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004457",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biochemistry",
      "Chemistry",
      "Closed captioning",
      "Computer science",
      "Computer security",
      "ENCODE",
      "Electrical engineering",
      "Engineering",
      "Event (particle physics)",
      "Exploit",
      "Fuse (electrical)",
      "Gene",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Machine learning",
      "Modal",
      "Natural language processing",
      "Operating system",
      "Physics",
      "Polymer chemistry",
      "Process (computing)",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Chang",
        "given_name": "Zhi"
      },
      {
        "surname": "Zhao",
        "given_name": "Dexin"
      },
      {
        "surname": "Chen",
        "given_name": "Huilin"
      },
      {
        "surname": "Li",
        "given_name": "Jingdan"
      },
      {
        "surname": "Liu",
        "given_name": "Pengfei"
      }
    ]
  },
  {
    "title": "Multiple-view flexible semi-supervised classification through consistent graph construction and label propagation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.015",
    "abstract": "Graph construction plays an essential role in graph-based label propagation since graphs give some information on the structure of the data manifold. While most graph construction methods rely on predefined distance calculation, recent algorithms merge the task of label propagation and graph construction in a single process. Moreover, the use of several descriptors is proved to outperform a single descriptor in representing the relation between the nodes. In this article, we propose a Multiple-View Consistent Graph construction and Label propagation algorithm (MVCGL) that simultaneously constructs a consistent graph based on several descriptors and performs label propagation over unlabeled samples. Furthermore, it provides a mapping function from the feature space to the label space with which we estimate the label of unseen samples via a linear projection. The constructed graph does not rely on a predefined similarity function and exploits data and label smoothness. Experiments conducted on three face and one handwritten digit databases show that the proposed method can gain better performance compared to other graph construction and label propagation methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004433",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Graph",
      "Information retrieval",
      "Merge (version control)",
      "Pattern recognition (psychology)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Ziraki",
        "given_name": "Najmeh"
      },
      {
        "surname": "Dornaika",
        "given_name": "Fadi"
      },
      {
        "surname": "Bosaghzadeh",
        "given_name": "Alireza"
      }
    ]
  },
  {
    "title": "Efficient correntropy-based multi-view clustering with anchor graph embedding",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.027",
    "abstract": "Although multi-view clustering has received widespread attention due to its far superior performance to single-view clustering, it still faces the following issues: (1) high computational cost, considering the introduction of multi-view information, reduces the clustering efficiency greatly; (2) complex noises and outliers, existed in real-world data, pose a huge challenge to the robustness of clustering algorithms. Currently, how to increase the efficiency and robustness has become two important issues of multi-view clustering. To cope with the above issues, an efficient correntropy-based multi-view clustering algorithm (ECMC) is proposed in this paper, which can not only improve clustering efficiency by constructing embedded anchor graph and utilizing nonnegative matrix factorization (NMF), but also enhance the robustness by exploring correntropy to suppress various noises and outliers. To further improve clustering efficiency, one of the factors of NMF is constrained to be an indicator matrix instead of a traditional non-negative matrix, so that the categories of samples can be obtained directly without any extra operation. Subsequently, a novel half-quadratic-based strategy is proposed to optimize the non-convex objective function of ECMC. Finally, extensive experiments on eight real-world datasets and eighteen noisy datasets show that ECMC can guarantee faster speed and better robustness than other state-of-the-art multi-view clustering algorithms.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004688",
    "keywords": [
      "Artificial intelligence",
      "Biochemistry",
      "CURE data clustering algorithm",
      "Chemistry",
      "Cluster analysis",
      "Computer science",
      "Correlation clustering",
      "Data mining",
      "Eigenvalues and eigenvectors",
      "Embedding",
      "Gene",
      "Graph embedding",
      "Machine learning",
      "Matrix decomposition",
      "Non-negative matrix factorization",
      "Outlier",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Robustness (evolution)"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Ben"
      },
      {
        "surname": "Zhang",
        "given_name": "Xuetao"
      },
      {
        "surname": "Chen",
        "given_name": "Badong"
      },
      {
        "surname": "Nie",
        "given_name": "Feiping"
      },
      {
        "surname": "Lin",
        "given_name": "Zhiping"
      },
      {
        "surname": "Nan",
        "given_name": "Zhixiong"
      }
    ]
  },
  {
    "title": "Deep two-way matrix reordering for relational data analysis",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.028",
    "abstract": "Matrix reordering is a task to permute the rows and columns of a given observed matrix such that the resulting reordered matrix shows meaningful or interpretable structural patterns. Most existing matrix reordering techniques share the common processes of extracting some feature representations from an observed matrix in a predefined manner, and applying matrix reordering based on it. However, in some practical cases, we do not always have prior knowledge about the structural pattern of an observed matrix. To address this problem, we propose a new matrix reordering method, called deep two-way matrix reordering (DeepTMR), using a neural network model. The trained network can automatically extract nonlinear row/column features from an observed matrix, which can then be used for matrix reordering. Moreover, the proposed DeepTMR provides the denoised mean matrix of a given observed matrix as an output of the trained network. This denoised mean matrix can be used to visualize the global structure of the reordered observed matrix. We demonstrate the effectiveness of the proposed DeepTMR by applying it to both synthetic and practical datasets.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100469X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Column (typography)",
      "Composite material",
      "Computer science",
      "Database",
      "Frame (networking)",
      "Gaussian",
      "Materials science",
      "Matrix (chemical analysis)",
      "Matrix completion",
      "Pattern recognition (psychology)",
      "Physics",
      "Quantum mechanics",
      "Row",
      "Row and column spaces",
      "Sparse matrix",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Watanabe",
        "given_name": "Chihiro"
      },
      {
        "surname": "Suzuki",
        "given_name": "Taiji"
      }
    ]
  },
  {
    "title": "Using top-down modulation to optimally balance shared versus separated task representations",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.030",
    "abstract": "Human adaptive behavior requires continually learning and performing a wide variety of tasks, often with very little practice. To accomplish this, it is crucial to separate neural representations of different tasks in order to avoid interference. At the same time, sharing neural representations supports generalization and allows faster learning. Therefore, a crucial challenge is to find an optimal balance between shared versus separated representations. Typically, models of human cognition employ top-down modulatory signals to separate task representations, but there exist surprisingly little systematic computational investigations of how such modulation is best implemented. We identify and systematically evaluate two crucial features of modulatory signals. First, top-down input can be processed in an additive or multiplicative manner. Second, the modulatory signals can be adaptive (learned) or non-adaptive (random). We cross these two features, resulting in four modulation networks which are tested on a variety of input datasets and tasks with different degrees of stimulus-action mapping overlap. The multiplicative adaptive modulation network outperforms all other networks in terms of accuracy. Moreover, this network develops hidden units that optimally share representations between tasks. Specifically, different than the binary approach of currently popular latent state models, it exploits partial overlap between tasks.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004718",
    "keywords": [
      "Arithmetic",
      "Artificial intelligence",
      "Artificial neural network",
      "Binary number",
      "Computer science",
      "Economics",
      "Generalization",
      "Machine learning",
      "Management",
      "Mathematical analysis",
      "Mathematics",
      "Task (project management)",
      "Variety (cybernetics)"
    ],
    "authors": [
      {
        "surname": "Verbeke",
        "given_name": "Pieter"
      },
      {
        "surname": "Verguts",
        "given_name": "Tom"
      }
    ]
  },
  {
    "title": "Deep neural network enabled corrective source term approach to hybrid analysis and modeling",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.021",
    "abstract": "In this work, we introduce, justify and demonstrate the Corrective Source Term Approach (CoSTA)—a novel approach to Hybrid Analysis and Modeling (HAM). The objective of HAM is to combine physics-based modeling (PBM) and data-driven modeling (DDM) to create generalizable, trustworthy, accurate, computationally efficient and self-evolving models. CoSTA achieves this objective by augmenting the governing equation of a PBM model with a corrective source term generated using a deep neural network. In a series of numerical experiments on one-dimensional heat diffusion, CoSTA is found to outperform comparable DDM and PBM models in terms of accuracy – often reducing predictive errors by several orders of magnitude – while also generalizing better than pure DDM. Due to its flexible but solid theoretical foundation, CoSTA provides a modular framework for leveraging novel developments within both PBM and DDM. Its theoretical foundation also ensures that CoSTA can be used to model any system governed by (deterministic) partial differential equations. Moreover, CoSTA facilitates interpretation of the DNN-generated source term within the context of PBM, which results in improved explainability of the DNN. These factors make CoSTA a potential door-opener for data-driven techniques to enter high-stakes applications previously reserved for pure PBM.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004494",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Interpretability",
      "Machine learning",
      "Modular design",
      "Physics",
      "Programming language",
      "Quantum mechanics",
      "Term (time)",
      "Trustworthiness"
    ],
    "authors": [
      {
        "surname": "Blakseth",
        "given_name": "Sindre Stenen"
      },
      {
        "surname": "Rasheed",
        "given_name": "Adil"
      },
      {
        "surname": "Kvamsdal",
        "given_name": "Trond"
      },
      {
        "surname": "San",
        "given_name": "Omer"
      }
    ]
  },
  {
    "title": "Chapter three Applications of artificial neural networks in concentrating solar power systems",
    "journal": "Artificial Neural Networks for Renewable Energy Systems and Real-World Applications",
    "year": "2022",
    "doi": "10.1016/B978-0-12-820793-2.00008-2",
    "abstract": "Concentrating solar power (CSP) systems are one of the growing solutions to increased demands for renewable electricity generation. This growth implies the global capacity of these systems and, therefore, requires an increase in characterization tasks to ensure availability, design, and reliability. Accurate electric power forecasting contributes to guaranteeing safe dispatch and stable operation of a CSP system. As a great prediction tool, artificial neural network (ANN) methods recently have been used in CSP forecasting. In this chapter, applications of the ANN-based models to predict the key design criteria, and thermal and economical parameters that influence the performance of CSP systems are discussed. The results have shown different types of classical ANN models, in particular: Multilayered Perceptron ANN (MLP-ANN), forward feed ANN (FFANN), Data Handling Group Method (DHGM), and Adaptive Neuro-Fuzzy Inference System (ANFIS) models are used for performance prediction of CSP systems. The ANN-MLP model is the most widely and well-developed model for predicting the performance of CSP devices and offers a powerful tool for the simulation of such a CSP system. However, the prediction results of classical ANN methods are no longer accurate enough to predict in the smart grid. To improve the prediction accuracy, hybrid artificial intelligence models are needed to determine the optimal parameters of basic ANNs in order to maximize the performance prediction accuracy of different CSP systems to become more efficient and low computationally in the future.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128207932000082",
    "keywords": [
      "Adaptive neuro fuzzy inference system",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Computer security",
      "Control engineering",
      "Electric power system",
      "Engineering",
      "Fuzzy control system",
      "Fuzzy logic",
      "Key (lock)",
      "Machine learning",
      "Multilayer perceptron",
      "Neuro-fuzzy",
      "Physics",
      "Power (physics)",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Zayed",
        "given_name": "Mohamed E."
      },
      {
        "surname": "Zhao",
        "given_name": "Jun"
      },
      {
        "surname": "Li",
        "given_name": "Wenjia"
      },
      {
        "surname": "Sadek",
        "given_name": "S."
      },
      {
        "surname": "Elsheikh",
        "given_name": "Ammar H."
      }
    ]
  },
  {
    "title": "Detecting out-of-distribution samples via variational auto-encoder with reliable uncertainty estimation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.020",
    "abstract": "Variational autoencoders (VAEs) are influential generative models with rich representation capabilities from the deep neural network architecture and Bayesian method. However, VAE models have a weakness that assign a higher likelihood to out-of-distribution (OOD) inputs than in-distribution (ID) inputs. To address this problem, a reliable uncertainty estimation is considered to be critical for in-depth understanding of OOD inputs. In this study, we propose an improved noise contrastive prior (INCP) to be able to integrate into the encoder of VAEs, called INCPVAE. INCP is scalable, trainable and compatible with VAEs, and it also adopts the merits from the INCP for uncertainty estimation. Experiments on various datasets demonstrate that compared to the standard VAEs, our model is superior in uncertainty estimation for the OOD data and is robust in anomaly detection tasks. The INCPVAE model obtains reliable uncertainty estimation for OOD inputs and solves the OOD problem in VAE models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004111",
    "keywords": [
      "Anomaly detection",
      "Artificial intelligence",
      "Artificial neural network",
      "Autoencoder",
      "Computer science",
      "Database",
      "Encoder",
      "Image (mathematics)",
      "Law",
      "Machine learning",
      "Noise (video)",
      "Operating system",
      "Pattern recognition (psychology)",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Scalability"
    ],
    "authors": [
      {
        "surname": "Ran",
        "given_name": "Xuming"
      },
      {
        "surname": "Xu",
        "given_name": "Mingkun"
      },
      {
        "surname": "Mei",
        "given_name": "Lingrui"
      },
      {
        "surname": "Xu",
        "given_name": "Qi"
      },
      {
        "surname": "Liu",
        "given_name": "Quanying"
      }
    ]
  },
  {
    "title": "GuidedStyle: Attribute knowledge guided style manipulation for semantic face editing",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.017",
    "abstract": "Although significant progress has been made in synthesizing high-quality and visually realistic face images by unconditional Generative Adversarial Networks (GANs), there is still a lack of control over the generation process in order to achieve semantic face editing. In this paper, we propose a novel learning framework, called GuidedStyle, to achieve semantic face editing on pretrained StyleGAN by guiding the image generation process with a knowledge network. Furthermore, we allow an attention mechanism in StyleGAN generator to adaptively select a single layer for style manipulation. As a result, our method is able to perform disentangled and controllable edits along various attributes, including smiling, eyeglasses, gender, mustache, hair color and attractive. Both qualitative and quantitative results demonstrate the superiority of our method over other competing methods for semantic face editing. Moreover, we show that our model can be also applied to different types of real and artistic face editing, demonstrating strong generalization ability.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004081",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Face (sociological concept)",
      "Generalization",
      "Generative grammar",
      "Generator (circuit theory)",
      "Image (mathematics)",
      "Image editing",
      "Linguistics",
      "Mathematical analysis",
      "Mathematics",
      "Natural language processing",
      "Operating system",
      "Philosophy",
      "Physics",
      "Power (physics)",
      "Process (computing)",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Hou",
        "given_name": "Xianxu"
      },
      {
        "surname": "Zhang",
        "given_name": "Xiaokang"
      },
      {
        "surname": "Liang",
        "given_name": "Hanbang"
      },
      {
        "surname": "Shen",
        "given_name": "Linlin"
      },
      {
        "surname": "Lai",
        "given_name": "Zhihui"
      },
      {
        "surname": "Wan",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Chapter eight Artificial neural networks for engineering applications: a review",
    "journal": "Artificial Neural Networks for Renewable Energy Systems and Real-World Applications",
    "year": "2022",
    "doi": "10.1016/B978-0-12-820793-2.00003-3",
    "abstract": "The utilization of artificial neural networks (ANNs) has gained widespread popularity in various domains because it is based on the combination of intelligent control and the working principle of the neurons in a brain. Therefore it has achieved encouraging progress in the networks field, medical applications, image processing, and data science. In this chapter, the authors highlight the benefits of ANNs in engineering applications, such as chemical engineering, civil engineering, computer engineering, electrical engineering, construction engineering, mechanical engineering, and geotechnical engineering. Moreover, the chapter aims to guide researchers and students (especially engineers) interested in developing their skills using intelligent techniques.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128207932000033",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer network",
      "Computer science",
      "Engineering",
      "Engineering ethics",
      "Engineering management",
      "Field (mathematics)",
      "Informatics engineering",
      "Mathematics",
      "Mechatronics",
      "Network engineering",
      "Neural engineering",
      "Popularity",
      "Psychology",
      "Pure mathematics",
      "Science and engineering",
      "Social psychology",
      "Systems engineering"
    ],
    "authors": [
      {
        "surname": "Shehab",
        "given_name": "Mohammad"
      },
      {
        "surname": "Abualigah",
        "given_name": "Laith"
      },
      {
        "surname": "Omari",
        "given_name": "Mahmoud"
      },
      {
        "surname": "Shambour",
        "given_name": "Mohd Khaled Yousef"
      },
      {
        "surname": "Alshinwan",
        "given_name": "Mohammad"
      },
      {
        "surname": "Abuaddous",
        "given_name": "Hayfa Y."
      },
      {
        "surname": "Khasawneh",
        "given_name": "Ahmad M."
      }
    ]
  },
  {
    "title": "Reinforcement learning and its connections with neuroscience and psychology",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.003",
    "abstract": "Reinforcement learning methods have recently been very successful at performing complex sequential tasks like playing Atari games, Go and Poker. These algorithms have outperformed humans in several tasks by learning from scratch, using only scalar rewards obtained through interaction with their environment. While there certainly has been considerable independent innovation to produce such results, many core ideas in reinforcement learning are inspired by phenomena in animal learning, psychology and neuroscience. In this paper, we comprehensively review a large number of findings in both neuroscience and psychology that evidence reinforcement learning as a promising candidate for modeling learning and decision making in the brain. In doing so, we construct a mapping between various classes of modern RL algorithms and specific findings in both neurophysiological and behavioral literature. We then discuss the implications of this observed relationship between RL, neuroscience and psychology and its role in advancing research in both AI and brain science.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003944",
    "keywords": [
      "Animal learning",
      "Artificial intelligence",
      "Behavioral neuroscience",
      "Cognitive psychology",
      "Cognitive science",
      "Computer science",
      "Construct (python library)",
      "Neuroscience",
      "Programming language",
      "Psychology",
      "Reinforcement",
      "Reinforcement learning",
      "Social psychology"
    ],
    "authors": [
      {
        "surname": "Subramanian",
        "given_name": "Ajay"
      },
      {
        "surname": "Chitlangia",
        "given_name": "Sharad"
      },
      {
        "surname": "Baths",
        "given_name": "Veeky"
      }
    ]
  },
  {
    "title": "Exploiting dynamic spatio-temporal graph convolutional neural networks for citywide traffic flows prediction",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.021",
    "abstract": "The prediction of crowd flows is an important urban computing issue whose purpose is to predict the future number of incoming and outgoing people in regions. Measuring the complicated spatial–temporal dependencies with external factors, such as weather conditions and surrounding point-of-interest (POI) distribution is the most difficult aspect of predicting crowd flows movement. To overcome the above issue, this paper advises a unified dynamic deep spatio-temporal neural network model based on convolutional neural networks and long short-term memory, termed as (DHSTNet) to simultaneously predict crowd flows in every region of a city. The DHSTNet model is made up of four separate components: a recent, daily, weekly, and an external branch component. Our proposed approach simultaneously assigns various weights to different branches and integrates the four properties’ outputs to generate final predictions. Moreover, to verify the generalization and scalability of the proposed model, we apply a Graph Convolutional Network (GCN) based on Long Short Term Memory (LSTM) with the previously published model, termed as GCN-DHSTNet; to capture the spatial patterns and short-term temporal features; and to illustrate its exceptional accomplishment in predicting the traffic crowd flows. The GCN-DHSTNet model not only depicts the spatio-temporal dependencies but also reveals the influence of different time granularity, which are recent, daily, weekly periodicity and external properties, respectively. Finally, a fully connected neural network is utilized to fuse the spatio-temporal features and external properties together. Using two different real-world traffic datasets, our evaluation suggests that the proposed GCN-DHSTNet method is approximately 7.9%–27.2% and 11.2%–11.9% better than the AAtt-DHSTNet method in terms of RMSE and MAPE metrics, respectively. Furthermore, AAtt-DHSTNet outperforms other state-of-the-art methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004123",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convolutional neural network",
      "Data mining",
      "Database",
      "Electrical engineering",
      "Engineering",
      "Fuse (electrical)",
      "Generalization",
      "Granularity",
      "Graph",
      "Mathematical analysis",
      "Mathematics",
      "Operating system",
      "Scalability",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Ali",
        "given_name": "Ahmad"
      },
      {
        "surname": "Zhu",
        "given_name": "Yanmin"
      },
      {
        "surname": "Zakarya",
        "given_name": "Muhammad"
      }
    ]
  },
  {
    "title": "Chapter 9 Computational lung sound classification: a review",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00016-1",
    "abstract": "Computational lung sound classification (LSC) has attracted attention over many years. The number of studies on adventious lung sound detection as well as respiratory disease classification has increased dramatically. This chapter summarizes existing approaches of conventional machine learning and deep learning-based LSC systems. We provide a structural review of LSC systems including topics from data processing such as audio signal processing, feature extraction, and data augmentation to data modeling such as neural network architectures and learning paradigms. In addition, we shortly discuss current advances and open challenges for possible future developments toward the real-life application of LSC systems.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128198728000161",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer hardware",
      "Computer science",
      "Digital signal processing",
      "Feature (linguistics)",
      "Feature extraction",
      "Linguistics",
      "Machine learning",
      "Philosophy",
      "Signal processing",
      "Speech recognition"
    ],
    "authors": [
      {
        "surname": "Nguyen",
        "given_name": "Truc"
      },
      {
        "surname": "Pernkopf",
        "given_name": "Franz"
      }
    ]
  },
  {
    "title": "Chapter 1 Microscopy Cancer Cell Imaging in B-lineage Acute Lymphoblastic Leukemia",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00008-2",
    "abstract": "Acute lymphoblastic leukemia (ALL) is a type of white blood cancer, in which the B- and T- lymphocytes are affected. This cancer constitutes approximately 20% of the pediatric cancers. Morphologically, the normal progenitor cells and cancer blood cells when present at low numbers appear similar under the microscope to the naked eye, and the preliminary tests are based on the cancerous cell count. Moreover, the conventional tests are very expensive and are not available widely in pathology laboratories or hospitals, particularly in rural areas. Because microscopic examination is readily available and cost effective, conferring the ability of distinguishing cancer cells from normal cells to microscopic image processing evaluation will provide several benefits in terms of scaling and cost. The complete workflow of such a tool consists of the following steps: (1) capture of images and preparation of the dataset, (2) normalization of color stain to correct for abnormalities during the staining process, (3) segmentation of cells of interest, and (4) classification of cells as cancer cells or normal cells. In this chapter, all the four stages are discussed in detail.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128198728000082",
    "keywords": [
      "Biology",
      "Cancer",
      "Cancer cell",
      "Cancer research",
      "Immunology",
      "Internal medicine",
      "Leukemia",
      "Lymphoblastic Leukemia",
      "Medicine",
      "Pathology",
      "Stain",
      "Staining"
    ],
    "authors": [
      {
        "surname": "Gupta",
        "given_name": "Anubha"
      },
      {
        "surname": "Gehlot",
        "given_name": "Shiv"
      },
      {
        "surname": "Gupta",
        "given_name": "Ritu"
      }
    ]
  },
  {
    "title": "Minimum spanning tree based graph neural network for emotion classification using EEG",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.023",
    "abstract": "Emotion classification based on neurophysiology signals has been a challenging issue in the literature. Recent neuroscience findings suggest that brain network structure underlying the different emotions provides a window in understanding human affection. In this paper, we propose a novel method to capture the distinct minimum spanning tree (MST) topology underpinning the different emotions. Specifically, we propose a hierarchical aggregation-based graph neural network to investigate the MST structure in emotion recognition. Extensive experiments on the public available DEAP dataset demonstrate the superior performance of the model in emotion classification as compared to existing methods. In addition, the results show that the theta, lower beta and gamma frequency band network information are more sensitive to emotions, suggesting a multi-frequency interaction in emotion processing.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004226",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Electroencephalography",
      "Graph",
      "Machine learning",
      "Minimum spanning tree",
      "Neurophysiology",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Psychology",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Hanjie"
      },
      {
        "surname": "Zhang",
        "given_name": "Jinren"
      },
      {
        "surname": "Liu",
        "given_name": "Qingshan"
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Chapter one Basics of artificial neural networks",
    "journal": "Artificial Neural Networks for Renewable Energy Systems and Real-World Applications",
    "year": "2022",
    "doi": "10.1016/B978-0-12-820793-2.00002-1",
    "abstract": "Artificial neural networks (ANNs) have been reported as useful predictive tools to model complex engineering systems. ANNs mimic the natural behavior of the human brain in handling different problems instead of solving intricate mathematical models. They are used as a black-box with excellent capabilities to learn the nonlinear relation between the inputs and outputs of a certain system. They have also enhanced the generalization capability to handle unseen data after the learning process. In this chapter, a review of the basics of ANNs is presented. In general, ANNs have received increased attention in recent years since they have been applied to numerous real-world applications. They have many advantages, such as simplicity and efficiency. In this chapter, the authors introduce the basic mathematical concepts of the multilayer perceptron, the wavelet neural network, radial basis function, and the Elman neural network.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128207932000021",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Black box",
      "Computer science",
      "Data mining",
      "Generalization",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Nonlinear system",
      "Operating system",
      "Perceptron",
      "Physics",
      "Process (computing)",
      "Quantum mechanics",
      "Relation (database)"
    ],
    "authors": [
      {
        "surname": "Ibrahim",
        "given_name": "Rehab Ali"
      },
      {
        "surname": "Elsheikh",
        "given_name": "Ammar H."
      },
      {
        "surname": "Elasyed Abd Elaziz",
        "given_name": "Mohamed"
      },
      {
        "surname": "Al-qaness",
        "given_name": "Mohammed A.A."
      }
    ]
  },
  {
    "title": "Chapter 5 Adaptive graph convolutional neural network and its biomedical applications",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00012-4",
    "abstract": "Graph convolutional neural networks (GCN) are generalizations of classical CNNs to better work with graph-structured data that include biochemical molecular graph, 3D point cloud and social networks. Current convolutional kernels in GCNs were built upon fixed and shared graph structure. However, for most real-world data, graph structure varies in terms of both scale and topology. A generalizable convolutional operator on graph is supposed to be compatible with different graph topologies. In the article, authors introduced a generalized and flexible GCN framework along with a new spectral graph convolutional layer parameterizing distance metric and feature transform. Besides original graph structure, a residual graph is constructed and learned throughout training. Therefore, the introduced Adaptive graph convolutional network (AGCN) is adaptive to graphs of arbitrary topological structure and scale and is also adaptive to various learning tasks easily. With graph attention network, we enabled AGCN to learn graph representation from a bag of patches randomly sampled from large medical images such as Whole-slide-image for sophisticated understanding tasks, for example survival prediction. The DeepGraphSurv is an end-to-end framework that directly predict survival probability from patients’ WSI on tissues. Empowered by graph attention, an intuitive annotation of tumor cells is also learned and generated by the model. Extensive experiments of AGCN and state-of-the-arts on drug property benchmark datasets have demonstrated the superior performance improvement on both convergence speed and predictive accuracy for multi-tasks classification of graph (drug). We also executed survival time prediction experiment over 3 large WSI datasets of lung cancer patient, from which DeepGraphSurv indicated significant accuracy lift brought by graph representation learning over patches.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128198728000124",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Combinatorics",
      "Computer science",
      "Convolutional neural network",
      "Graph",
      "Line graph",
      "Mathematics",
      "Null model",
      "Theoretical computer science",
      "Topological graph theory",
      "Voltage graph"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Junzhou"
      },
      {
        "surname": "Li",
        "given_name": "Ruoyu"
      }
    ]
  },
  {
    "title": "Cardinality-constrained portfolio selection based on collaborative neurodynamic optimization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.007",
    "abstract": "Portfolio optimization is one of the most important investment strategies in financial markets. It is practically desirable for investors, especially high-frequency traders, to consider cardinality constraints in portfolio selection, to avoid odd lots and excessive costs such as transaction fees. In this paper, a collaborative neurodynamic optimization approach is presented for cardinality-constrained portfolio selection. The expected return and investment risk in the Markowitz framework are scalarized as a weighted Chebyshev function and the cardinality constraints are equivalently represented using introduced binary variables as an upper bound. Then cardinality-constrained portfolio selection is formulated as a mixed-integer optimization problem and solved by means of collaborative neurodynamic optimization with multiple recurrent neural networks repeatedly repositioned using a particle swarm optimization rule. The distribution of resulting Pareto-optimal solutions is also iteratively perfected by optimizing the weights in the scalarized objective functions based on particle swarm optimization. Experimental results with stock data from four major world markets are discussed to substantiate the superior performance of the collaborative neurodynamic approach to several exact and metaheuristic methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003981",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cardinality (data modeling)",
      "Computer science",
      "Data mining",
      "Economics",
      "Finance",
      "Mathematical optimization",
      "Mathematics",
      "Optimization problem",
      "Particle swarm optimization",
      "Portfolio",
      "Portfolio optimization",
      "Selection (genetic algorithm)"
    ],
    "authors": [
      {
        "surname": "Leung",
        "given_name": "Man-Fai"
      },
      {
        "surname": "Wang",
        "given_name": "Jun"
      }
    ]
  },
  {
    "title": "Chapter ten Incremental learning of convolutional neural networks in bioinformatics",
    "journal": "Artificial Neural Networks for Renewable Energy Systems and Real-World Applications",
    "year": "2022",
    "doi": "10.1016/B978-0-12-820793-2.00001-X",
    "abstract": "In recent years, convolutional neural networks (CNNs) have been widely used in various computer visual recognition tasks and then extensively applied for medical images, particularly for computer-aided diagnosis. Despite this success, CNNs suffer from a catastrophic forgetting issue, making it difficult for them to learn new tasks without being retrained from scratch. In this chapter the authors briefly introduce the concept of incremental learning for deep CNNs and highlight the catastrophic forgetting challenge by discussing methods from the literature that are used to mitigate it, particularly in the field of bioinformatics. To the best of the authors’ knowledge only two algorithms have been proposed for this purpose.",
    "link": "https://www.sciencedirect.com/science/article/pii/B978012820793200001X",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Cognitive psychology",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Field (mathematics)",
      "Forgetting",
      "Machine learning",
      "Mathematics",
      "Psychology",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Mousser",
        "given_name": "Wafa"
      },
      {
        "surname": "Ouadfel",
        "given_name": "Salima"
      },
      {
        "surname": "Taleb-Ahmed",
        "given_name": "Abdelmalik"
      }
    ]
  },
  {
    "title": "Fractional-order discontinuous systems with indefinite LKFs: An application to fractional-order neural networks with time delays",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.027",
    "abstract": "In this article, we discuss bipartite fixed-time synchronization for fractional-order signed neural networks with discontinuous activation patterns. The Filippov multi-map is used to convert the fixed-time stability of the fractional-order general solution into the zero solution of the fractional-order differential inclusions. On the Caputo fractional-order derivative, Lyapunov-Krasovskii functional is proved to possess the indefinite fractional derivatives for fixed-time stability of fragmentary discontinuous systems. Furthermore, the fixed-time stability of the fractional-order discontinuous system is achieved as well as an estimate of the new settling time.. The discontinuous controller is designed for the delayed fractional-order discontinuous signed neural networks with antagonistic interactions and new conditions for permanent fixed-time synchronization of these networks with antagonistic interactions are also provided, as well as the settling time for permanent fixed-time synchronization. Two numerical simulation results are presented to demonstrate the effectiveness of the main results",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004287",
    "keywords": [
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control engineering",
      "Control theory (sociology)",
      "Differential inclusion",
      "Economics",
      "Engineering",
      "Finance",
      "Fixed point",
      "Fractional calculus",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Order (exchange)",
      "Settling time",
      "Stability (learning theory)",
      "Step response",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)"
    ],
    "authors": [
      {
        "surname": "Udhayakumar",
        "given_name": "K."
      },
      {
        "surname": "Rihan",
        "given_name": "Fathalla A."
      },
      {
        "surname": "Rakkiyappan",
        "given_name": "R."
      },
      {
        "surname": "Cao",
        "given_name": "Jinde"
      }
    ]
  },
  {
    "title": "Chapter 6 Deep slice interpolation via marginal super-resolution, fusion, and refinement",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00013-6",
    "abstract": "We propose a marginal super-resolution (MSR) approach based on 2D convolutional neural networks (CNNs) for interpolating an anisotropic brain magnetic resonance scan along the highly under-sampled direction, which is assumed to axial without loss of generality. Previous methods for slice interpolation only considered data from pairs of adjacent 2D slices. The possibility of fusing information from the direction orthogonal to the 2D slices remains unexplored. Our approach performs MSR in both sagittal and coronal directions, which provides an initial estimate for slice interpolation. The interpolated slices are then fused and refined in the axial direction for improved consistency. As MSR consists of only 2D operations, it is more feasible in terms of GPU memory consumption and requires fewer training samples compared to 3D CNNs. Our experiments demonstrate that the proposed method outperforms traditional linear interpolation and baseline 2D/3D CNN-based approaches. We conclude by showcasing the method’s practical utility in estimating brain volumes from under-sampled brain MR scans through semantic segmentation.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128198728000136",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Artificial neural network",
      "Bilinear interpolation",
      "Computer science",
      "Computer vision",
      "Consistency (knowledge bases)",
      "Convolution (computer science)",
      "Convolutional neural network",
      "Image (mathematics)",
      "Interpolation (computer graphics)",
      "Linear interpolation",
      "Medicine",
      "Pattern recognition (psychology)",
      "Radiology",
      "Sagittal plane"
    ],
    "authors": [
      {
        "surname": "Peng",
        "given_name": "Cheng"
      },
      {
        "surname": "Lin",
        "given_name": "Wei-An"
      },
      {
        "surname": "Liao",
        "given_name": "Haofu"
      },
      {
        "surname": "Chellappa",
        "given_name": "Rama"
      },
      {
        "surname": "Zhou",
        "given_name": "Shaohua Kevin"
      }
    ]
  },
  {
    "title": "Chapter 11 Role of artificial intelligence and radiomics in diagnosing renal tumors: a survey",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00018-5",
    "abstract": "Several articles have discussed the growing role of artificial intelligence (AI), machine learning (ML), and radiomics in the evaluation and management of renal tumors; yet, no critical analysis has been made to date. This chapter reviews the recent diagnostic applications of AI and ML in renal tumor. AI is used for the differentiation of benign from malignant renal tumors, differentiation of renal cell carcinoma from angiomyolipoma, oncocytoma, and renal cyst. Several studies have discussed the role of AI in subtyping, grading, and staging of renal cell carcinoma as well as in the characterization of small renal mass. In addition, it is used for Fuhrman nuclear grade prediction and gene expression-based molecular signatures of renal cell carcinoma. The continuous incorporation of clinical data, further ML, texture analysis, and ML algorithm retraining, and generalizability of models will augment the prediction accuracy and enhance individualized medicine.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128198728000185",
    "keywords": [
      "Biology",
      "Developmental psychology",
      "Ecology",
      "Generalizability theory",
      "Grading (engineering)",
      "Internal medicine",
      "Kidney",
      "Medicine",
      "Nephrectomy",
      "Pathology",
      "Psychology",
      "Radiology",
      "Radiomics",
      "Renal cell carcinoma",
      "Renal tumor"
    ],
    "authors": [
      {
        "surname": "Shehata",
        "given_name": "Mohamed"
      },
      {
        "surname": "Elmahdy",
        "given_name": "Ahmed"
      },
      {
        "surname": "Alksas",
        "given_name": "Ahmed"
      },
      {
        "surname": "Abouelkheir",
        "given_name": "Rasha"
      },
      {
        "surname": "Mahmoud",
        "given_name": "Ali"
      },
      {
        "surname": "El-Ghar",
        "given_name": "Mohamed Abou"
      },
      {
        "surname": "Ghazal",
        "given_name": "Mohammed"
      },
      {
        "surname": "El-Baz",
        "given_name": "Ayman S."
      }
    ]
  },
  {
    "title": "Chapter 3 Deep neural networks and advanced computer vision algorithms in the early diagnosis of skin diseases",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00010-0",
    "abstract": "Malignant melanoma is one of the most deadly forms of skin cancer and the most advancing cancer among many white-skinned populations. Incidence and mortality rates caused by cutaneous melanoma, which is the most aggressive kind of skin cancer, have significantly increased during the past few decades. The main goals of modern dermatology are education, prevention, early diagnosis, and sophisticated treatment of the disease. There is a high demand to develop computer-aided diagnostic systems facilitating the early detection of melanoma, which would lower its misdiagnosis rate.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128198728000100",
    "keywords": [
      "Cancer",
      "Cancer research",
      "Dermatology",
      "Disease",
      "Incidence (geometry)",
      "Internal medicine",
      "Medicine",
      "Melanoma",
      "Optics",
      "Physics",
      "Skin cancer"
    ],
    "authors": [
      {
        "surname": "Jaworek-Korjakowska",
        "given_name": "Joanna"
      },
      {
        "surname": "Yap",
        "given_name": "Moi Hoon"
      },
      {
        "surname": "Bhattacharjee",
        "given_name": "Debotosh"
      },
      {
        "surname": "Kleczek",
        "given_name": "Pawel"
      },
      {
        "surname": "Brodzicki",
        "given_name": "Andrzej"
      },
      {
        "surname": "Gorgon",
        "given_name": "Marek"
      }
    ]
  },
  {
    "title": "On the capacity of deep generative networks for approximating distributions",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.012",
    "abstract": "We study the efficacy and efficiency of deep generative networks for approximating probability distributions. We prove that neural networks can transform a low-dimensional source distribution to a distribution that is arbitrarily close to a high-dimensional target distribution, when the closeness is measured by Wasserstein distances and maximum mean discrepancy. Upper bounds of the approximation error are obtained in terms of the width and depth of neural network. Furthermore, it is shown that the approximation error in Wasserstein distance grows at most linearly on the ambient dimension and that the approximation order only depends on the intrinsic dimension of the target distribution. On the contrary, when f -divergences are used as metrics of distributions, the approximation property is different. We show that in order to approximate the target distribution in f -divergences, the dimension of the source distribution cannot be smaller than the intrinsic dimension of the target distribution.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004032",
    "keywords": [
      "Applied mathematics",
      "Approximation error",
      "Artificial intelligence",
      "Artificial neural network",
      "Closeness",
      "Combinatorics",
      "Computer science",
      "Dimension (graph theory)",
      "Distribution (mathematics)",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Probability distribution",
      "Statistical physics",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yunfei"
      },
      {
        "surname": "Li",
        "given_name": "Zhen"
      },
      {
        "surname": "Wang",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Chapter seven Artificial neural network and desalination systems",
    "journal": "Artificial Neural Networks for Renewable Energy Systems and Real-World Applications",
    "year": "2022",
    "doi": "10.1016/B978-0-12-820793-2.00010-0",
    "abstract": "Industrial, medical, agricultural, and power systems are among the main enablers of human civilization and humanity. These systems need energy, as a key, to run. As is well known, the many disadvantages of the traditional forms of energy have led to making use of the available different types of renewable energy such as solar energy, wind energy, ocean energy, geothermal energy, biomass energy, and water energy. In addition, mathematical modeling-based investigations can be used to model the performance of a system without conducting costly and time-consuming experiments. Recently, the artificial neural network has been used as an effective way to predict, analyze, and optimize the behavior and performance of these systems, especially renewable energy-based systems. Several different models have been used to achieve that goal.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128207932000100",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Economics",
      "Electrical engineering",
      "Energy (signal processing)",
      "Engineering",
      "Environmental economics",
      "Mathematics",
      "Process engineering",
      "Renewable energy",
      "Statistics",
      "Wind power"
    ],
    "authors": [
      {
        "surname": "Essa",
        "given_name": "Fadl A."
      },
      {
        "surname": "Elasyed Abd Elaziz",
        "given_name": "Mohamed"
      },
      {
        "surname": "Shanmugan",
        "given_name": "S."
      },
      {
        "surname": "Elsheikh",
        "given_name": "Ammar H."
      }
    ]
  },
  {
    "title": "Chapter 8 Deep learning interpretability: measuring the relevance of clinical concepts in convolutional neural networks features",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00015-X",
    "abstract": "Deep learning models, with billions of parameters, have a great potential for improving our daily life activities, particularly in assisting the diagnosis of medical images. The detection of plus disease in retinopathy of prematurity is an example at the edge between two treatment strategies where a difficult decision in the diagnosis may make the difference between the risk of blindness and complete recovery. Explaining the complex decision-making of these models is crucial before their incorporation into the clinical workflows. This can guarantee that several aspects are respected, for example the absence of unwanted biases, model fairness, trustworthiness and, most importantly, to ensure that the model reflects the clinical expectations. This chapter begins by clarifying the confusion around the taxonomy related to interpretable AI, adding a rich literature review on explainability methods. To illustrate the use of our recently developed methods for explaining convolutional networks’ predictions, we have applied concept attribution to Retinopathy of prematurity. In collaboration with experts in ophthalmology, we define concepts that (1) are relevant to them for the diagnosis of plus disease and (2) can be extracted automatically from the images as visual features. We then evaluate how the Convolutional Neural Networks (CNN) predictions are influenced by these concepts. The results suggest that the decision-making process of the CNN aligns with that of the ophthalmologists.",
    "link": "https://www.sciencedirect.com/science/article/pii/B978012819872800015X",
    "keywords": [
      "Artificial intelligence",
      "Biology",
      "Childhood blindness",
      "Computer science",
      "Convolutional neural network",
      "Data science",
      "Database",
      "Deep learning",
      "Genetics",
      "Gestational age",
      "Interpretability",
      "Law",
      "Machine learning",
      "Political science",
      "Pregnancy",
      "Relevance (law)",
      "Retinopathy of prematurity",
      "Workflow"
    ],
    "authors": [
      {
        "surname": "Graziani",
        "given_name": "Mara"
      },
      {
        "surname": "Andrearczyk",
        "given_name": "Vincent"
      },
      {
        "surname": "Müller",
        "given_name": "Henning"
      }
    ]
  },
  {
    "title": "Zenithal isotropic object counting by localization using adversarial training",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.010",
    "abstract": "Counting objects in images is a very time-consuming task for humans that yields to errors caused by repetitiveness and boredom. In this paper, we present a novel object counting method that, unlike most of the recent works that focus on the regression of a density map, performs the counting procedure by localizing each single object. This key difference allows us to provide not only an accurate count but the position of every counted object, information that can be critical in some areas such as precision agriculture. The method is designed in two steps: first, a CNN is in charge of mapping arbitrary objects to blob-like structures. Then, using a Laplacian of Gaussian (LoG) filter, we are able to gather the position of all detected objects. We also propose a semi-adversarial training procedure that, combined with the former design, improves the result by a large margin. After evaluating the method on two public benchmarks of isometric objects, we stay on par with the state of the art while being able to provide extra position information.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004019",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Blob detection",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Economics",
      "Edge detection",
      "Finance",
      "Focus (optics)",
      "Generator (circuit theory)",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Image processing",
      "Key (lock)",
      "Machine learning",
      "Margin (machine learning)",
      "Object (grammar)",
      "Object detection",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Position (finance)",
      "Power (physics)",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Rodriguez-Vazquez",
        "given_name": "Javier"
      },
      {
        "surname": "Alvarez-Fernandez",
        "given_name": "Adrian"
      },
      {
        "surname": "Molina",
        "given_name": "Martin"
      },
      {
        "surname": "Campoy",
        "given_name": "Pascual"
      }
    ]
  },
  {
    "title": "Chapter eleven Hybrid Arabic classification techniques based on naïve Bayes algorithm for multidisciplinary applications",
    "journal": "Artificial Neural Networks for Renewable Energy Systems and Real-World Applications",
    "year": "2022",
    "doi": "10.1016/B978-0-12-820793-2.00004-5",
    "abstract": "Text classification is a major data-mining application that holds a high weight in the modern digitized world; it assists many areas such as renewable energy systems, manufacturing applications, email filtering, digital libraries, and security threats, among many other areas. In Arabic text classification area, the current works remain limited, which creates a huge possibility for new work. The Arabic language is one of the top five most spoken languages in the world, therefore, the availability of Arabic text is far from limited. In this chapter, three algorithms including support vector machine (SVM), artificial neural network (ANN), and J48, are combined with the naïve Bayes algorithm to create new hybrid algorithms, namely, Vote NBSVM, Vote NBANN, and Vote NBJ48. These algorithms are applied on three Arabic text datasets with a total of 32,262 documents, and their performance is measured and compared. The results showed that the voting NBSVM obtained better results than other algorithms. When combined with the naïve Bayes algorithm using the voting method, the accuracy levels dropped by 2.25% for the ANN algorithm, 6.62% for the SVM algorithm, and 2.52% for the J48 algorithm, where the new algorithm NBJ48 showed superior outstanding results that are highly competitive and increased the accuracy of the J48 by 5.72%. This is especially important taking into account that this algorithm has never been applied to Arabic text.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128207932000045",
    "keywords": [
      "Algorithm",
      "Arabic",
      "Artificial intelligence",
      "C4.5 algorithm",
      "Computer science",
      "Data mining",
      "Law",
      "Linguistics",
      "Machine learning",
      "Naive Bayes classifier",
      "Philosophy",
      "Political science",
      "Politics",
      "Statistical classification",
      "Support vector machine",
      "Voting"
    ],
    "authors": [
      {
        "surname": "Otair",
        "given_name": "Mohammed"
      },
      {
        "surname": "Zacout",
        "given_name": "Somaya"
      },
      {
        "surname": "Abualigah",
        "given_name": "Laith"
      },
      {
        "surname": "Omari",
        "given_name": "Mahmoud"
      }
    ]
  },
  {
    "title": "On the capacity of deep generative networks for approximating distributions",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.012",
    "abstract": "We study the efficacy and efficiency of deep generative networks for approximating probability distributions. We prove that neural networks can transform a low-dimensional source distribution to a distribution that is arbitrarily close to a high-dimensional target distribution, when the closeness is measured by Wasserstein distances and maximum mean discrepancy. Upper bounds of the approximation error are obtained in terms of the width and depth of neural network. Furthermore, it is shown that the approximation error in Wasserstein distance grows at most linearly on the ambient dimension and that the approximation order only depends on the intrinsic dimension of the target distribution. On the contrary, when f -divergences are used as metrics of distributions, the approximation property is different. We show that in order to approximate the target distribution in f -divergences, the dimension of the source distribution cannot be smaller than the intrinsic dimension of the target distribution.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004032",
    "keywords": [
      "Applied mathematics",
      "Approximation error",
      "Artificial intelligence",
      "Artificial neural network",
      "Closeness",
      "Combinatorics",
      "Computer science",
      "Dimension (graph theory)",
      "Distribution (mathematics)",
      "Mathematical analysis",
      "Mathematics",
      "Physics",
      "Probability distribution",
      "Statistical physics",
      "Statistics"
    ],
    "authors": [
      {
        "surname": "Yang",
        "given_name": "Yunfei"
      },
      {
        "surname": "Li",
        "given_name": "Zhen"
      },
      {
        "surname": "Wang",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Zenithal isotropic object counting by localization using adversarial training",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.010",
    "abstract": "Counting objects in images is a very time-consuming task for humans that yields to errors caused by repetitiveness and boredom. In this paper, we present a novel object counting method that, unlike most of the recent works that focus on the regression of a density map, performs the counting procedure by localizing each single object. This key difference allows us to provide not only an accurate count but the position of every counted object, information that can be critical in some areas such as precision agriculture. The method is designed in two steps: first, a CNN is in charge of mapping arbitrary objects to blob-like structures. Then, using a Laplacian of Gaussian (LoG) filter, we are able to gather the position of all detected objects. We also propose a semi-adversarial training procedure that, combined with the former design, improves the result by a large margin. After evaluating the method on two public benchmarks of isometric objects, we stay on par with the state of the art while being able to provide extra position information.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004019",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Blob detection",
      "Computer science",
      "Computer security",
      "Computer vision",
      "Economics",
      "Edge detection",
      "Finance",
      "Focus (optics)",
      "Generator (circuit theory)",
      "Geodesy",
      "Geography",
      "Image (mathematics)",
      "Image processing",
      "Key (lock)",
      "Machine learning",
      "Margin (machine learning)",
      "Object (grammar)",
      "Object detection",
      "Optics",
      "Pattern recognition (psychology)",
      "Physics",
      "Position (finance)",
      "Power (physics)",
      "Quantum mechanics"
    ],
    "authors": [
      {
        "surname": "Rodriguez-Vazquez",
        "given_name": "Javier"
      },
      {
        "surname": "Alvarez-Fernandez",
        "given_name": "Adrian"
      },
      {
        "surname": "Molina",
        "given_name": "Martin"
      },
      {
        "surname": "Campoy",
        "given_name": "Pascual"
      }
    ]
  },
  {
    "title": "Convergence analysis of AdaBound with relaxed bound functions for non-convex optimization",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.026",
    "abstract": "Clipping on learning rates in Adam leads to an effective stochastic algorithm—AdaBound. In spite of its effectiveness in practice, convergence analysis of AdaBound has not been fully explored, especially for non-convex optimization. To this end, we address the convergence of the last individual output of AdaBound for non-convex stochastic optimization problems, which is called individual convergence. We prove that, with the iteration of the AdaBound, the cost function converges to a finite value and the corresponding gradient converges to zero. The novelty of this proof is that the convergence conditions on the bound functions and momentum factors are much more relaxed than the existing results, especially when we remove the monotonicity and convergence of the bound functions, and only keep their boundedness. The momentum factors can be fixed to be constant, without the restriction of monotonically decreasing. This provides a new perspective on understanding the bound functions and momentum factors of AdaBound. At last, numerical experiments are provided to corroborate our theory and show that the convergence of AdaBound extends to more general bound functions.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004275",
    "keywords": [
      "Applied mathematics",
      "Biology",
      "Channel (broadcasting)",
      "Compact convergence",
      "Computer network",
      "Computer science",
      "Convergence (economics)",
      "Convergence tests",
      "Convex function",
      "Convex optimization",
      "Discrete mathematics",
      "Economic growth",
      "Economics",
      "Evolutionary biology",
      "Finance",
      "Function (biology)",
      "Geometry",
      "Isolated point",
      "Mathematical analysis",
      "Mathematical optimization",
      "Mathematics",
      "Modes of convergence (annotated index)",
      "Momentum (technical analysis)",
      "Monotonic function",
      "Normal convergence",
      "Rate of convergence",
      "Regular polygon",
      "Topological space",
      "Topological vector space",
      "Upper and lower bounds"
    ],
    "authors": [
      {
        "surname": "Liu",
        "given_name": "Jinlan"
      },
      {
        "surname": "Kong",
        "given_name": "Jun"
      },
      {
        "surname": "Xu",
        "given_name": "Dongpo"
      },
      {
        "surname": "Qi",
        "given_name": "Miao"
      },
      {
        "surname": "Lu",
        "given_name": "Yinghua"
      }
    ]
  },
  {
    "title": "Nostradamus: A novel event propagation prediction approach with spatio-temporal characteristics in non-Euclidean space",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.005",
    "abstract": "The prediction of event propagation has received extensive attention from the knowledge discovery community for applications such as virus spread analytics, social network analysis, earthquake location prediction, and typhoon tracking. The data describing these phenomena are multidimensional asynchronous event data that affect each other and show complex dynamic patterns in the continuous-time domain. Unlike the discrete characteristics formed by sampling at equal intervals of asynchronous time series, the timestamps of asynchronous events are in the continuous-time field. The study of these dynamic processes and the mining of their potential correlations provide a foundation for applying event propagation prediction, traceability, and causal inference at both the micro and macro levels. Most of the existing methods represent data as being embedded in the Euclidean space. However, when embedding a real-world graph with a tree-likeliness graph, Euclidean space cannot visually represent a graph. Inspired by the characteristics of hyperbolic space, we propose a model called Nostradamus to capture the propagation of the events of interest from historical events in a graph via the hyperbolic graph neural Hawkes process with Spatio-temporal characteristics. The Nostradamus’ core concept is to integrate the Hawkes process’s conditional intensity function with a hyperbolic graph convolutional recurrent neural network.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004330",
    "keywords": [
      "Artificial intelligence",
      "Asynchronous communication",
      "Computer network",
      "Computer science",
      "Data mining",
      "Event (particle physics)",
      "Graph",
      "Physics",
      "Quantum mechanics",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Du",
        "given_name": "Haizhou"
      },
      {
        "surname": "Zhou",
        "given_name": "Yan"
      }
    ]
  },
  {
    "title": "Chapter 2 Computational imaging applications in brain and breast cancer",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00009-4",
    "abstract": "The rapid development of advanced computational algorithms from the domain of machine learning has shown promise for application in the clinical environment to (1) assist clinicians with tedious daily tasks and allow them to focus more on complex or urgent patient management, (2) offer second reads or opinions on tasks that require specialized training, as well as (3) assist in the training and education of new clinical experts. This chapter offers an overview of the state-of-the-art deep learning applications in the field of brain and breast cancer, as well as challenges and potential methods to improve the reproducibility of deep learning algorithms in biomedical image analysis of brain and breast cancer patients. The included references should not be considered as an exhaustive literature review but as studies serving as examples for the points made in this chapter.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128198728000094",
    "keywords": [
      "Artificial intelligence",
      "Breast cancer",
      "Cancer",
      "Computer science",
      "Data science",
      "Deep learning",
      "Domain (mathematical analysis)",
      "Field (mathematics)",
      "Focus (optics)",
      "Internal medicine",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Medical physics",
      "Medicine",
      "Optics",
      "Physics",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Gastounioti",
        "given_name": "Aimilia"
      },
      {
        "surname": "Rathore",
        "given_name": "Saima"
      },
      {
        "surname": "Maghsoudi",
        "given_name": "Omid Haji"
      },
      {
        "surname": "Conant",
        "given_name": "Emily F."
      },
      {
        "surname": "Kontos",
        "given_name": "Despina"
      },
      {
        "surname": "Bakas",
        "given_name": "Spyridon"
      }
    ]
  },
  {
    "title": "Structure inference of networked system with the synergy of deep residual network and fully connected layer network",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.016",
    "abstract": "The networked systems are booming in multi-disciplines, including the industrial engineering system, the social system, and so on. The network structure is a prerequisite for the understanding and exploration of networked systems. However, the network structure is always unknown in practice, thus, it is significant yet challenging to investigate the inference of network structure. Although some model-based methods and data-driven methods, such as the phase-space based method and the compressive sensing based method, have investigated the structure inference tasks, they were time-consuming due to the greedy iterative optimization procedure, which makes them difficult to satisfy real-time structure inference requirements. Although the reconstruction time of L1 and other methods is short, the reconstruction accuracy is very low. Inspired by the powerful representation ability and time efficiency for the structure inference with the deep learning framework, a novel synergy method combines the deep residual network and fully connected layer network to solve the network structure inference task efficiently and accurately. This method perfectly solves the problems of long reconstruction time and low accuracy of traditional methods. Moreover, the proposed method can also fulfill the inference task of large scale complex network, which further indicates the scalability of the proposed method.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100407X",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Computer science",
      "Data mining",
      "Database",
      "Deep learning",
      "Engineering",
      "Inference",
      "Machine learning",
      "Residual",
      "Scalability",
      "Systems engineering",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Huang",
        "given_name": "Keke"
      },
      {
        "surname": "Li",
        "given_name": "Shuo"
      },
      {
        "surname": "Deng",
        "given_name": "Wenfeng"
      },
      {
        "surname": "Yu",
        "given_name": "Zhaofei"
      },
      {
        "surname": "Ma",
        "given_name": "Lei"
      }
    ]
  },
  {
    "title": "Chapter five Solar energy modelling and forecasting using artificial neural networks: a review, a case study, and applications",
    "journal": "Artificial Neural Networks for Renewable Energy Systems and Real-World Applications",
    "year": "2022",
    "doi": "10.1016/B978-0-12-820793-2.00009-4",
    "abstract": "In this chapter, for forecasting with high possible accuracy, solar radiation intensity, an approach for identifying the optimum set of input data from large sets of input parameters, is elaborated, assessed, and proposed. This approach is an input variable selection (IVS) technique and it is established using artificial neural networks (ANNs) as an effective means for approximating numerically the computed objective function. Based on the approach presented, we can determine the best combinations of inputs giving a great possible correlation and approximation with the considered output parameter. Recorded data from about 35 stations in different climatic zones were used for both training and testing purposes. Several new linear formulas between the global solar radiation and other climatological and meteorological parameters were developed and evaluated. Based on these relationships, we can forecast other climatological and meteorological parameters such as temperature, wind speed, and humidity. The statistical analysis was done, and the best performance of the proposed approach was checked and duly validated. Finally, a review of the most possible applications of solar energy for both human health and engineering is briefly summarized and presented.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128207932000094",
    "keywords": [
      "Artificial neural network",
      "Computer science",
      "Geography",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Meteorology",
      "Programming language",
      "Relative humidity",
      "Set (abstract data type)",
      "Sunshine duration",
      "Variable (mathematics)",
      "Wind speed"
    ],
    "authors": [
      {
        "surname": "El Mghouchi",
        "given_name": "Youness"
      }
    ]
  },
  {
    "title": "A complementary learning approach for expertise transference of human-optimized controllers",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.009",
    "abstract": "In this paper, a complementary learning scheme for experience transference of unknown continuous-time linear systems is proposed. The algorithm is inspired in the complementary learning properties that exhibit the hippocampus and neocortex learning systems via the striatum. The hippocampus is modelled as pattern-separated data of a human optimized controller. The neocortex is modelled as a Q-reinforcement learning algorithm which improves the hippocampus control policy. The complementary learning (striatum) is designed as an inverse reinforcement learning algorithm which relates the hippocampus and neocortex learning models to seek and transfer the weights of the hidden expert’s utility function. Convergence of the proposed approach is analysed using Lyapunov recursions. Simulations are given to verify the proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004007",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convergence (economics)",
      "Dopamine",
      "Economic growth",
      "Economics",
      "Hippocampus",
      "Neocortex",
      "Neuroscience",
      "Psychology",
      "Reinforcement learning",
      "Striatum"
    ],
    "authors": [
      {
        "surname": "Perrusquía",
        "given_name": "Adolfo"
      }
    ]
  },
  {
    "title": "Cycle-consistent Adversarial Adaptation Network and its application to machine fault diagnosis",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.003",
    "abstract": "Driven by industrial big data and intelligent manufacturing, deep learning approaches have flourished and yielded impressive achievements in the community of machine fault diagnosis. Nevertheless, current diagnosis models trained on a specific dataset seldom work well on other datasets due to the domain discrepancy. Recently, adversarial domain adaptation-based approaches have become an emerging and compelling tool to address this issue. Nonetheless, existing methods still have a shortcoming since they cannot guarantee sufficient feature similarity between the source domain and the target domain after adaptation, resulting in unguaranteed performance. To this end, a Cycle-consistent Adversarial Adaptation Network (CAAN) is advanced to realize more effective fault diagnosis of machinery. In CAAN, specifically, an adversarial game formed by the feature extractor and the domain discriminator is constructed to induce transferable feature learning. Meanwhile, the feature translators and discriminators between source and target domains are further designed to build a more comprehensive cycle-consistent generative adversarial constrain, which can more reliably ensure domain-invariant and class-separate characteristics of learned features. Extensive experiments constructed on three datasets from different mechanical systems demonstrate the effectiveness and superiority of CAAN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004317",
    "keywords": [
      "Adaptation (eye)",
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Computer science",
      "Deep learning",
      "Detector",
      "Discriminator",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Fault (geology)",
      "Feature (linguistics)",
      "Feature engineering",
      "Feature learning",
      "Geology",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Optics",
      "Philosophy",
      "Physics",
      "Seismology",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Jiao",
        "given_name": "Jinyang"
      },
      {
        "surname": "Lin",
        "given_name": "Jing"
      },
      {
        "surname": "Zhao",
        "given_name": "Ming"
      },
      {
        "surname": "Liang",
        "given_name": "Kaixuan"
      },
      {
        "surname": "Ding",
        "given_name": "Chuancang"
      }
    ]
  },
  {
    "title": "Multi-view graph embedding clustering network: Joint self-supervision and block diagonal representation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.006",
    "abstract": "Multi-view clustering has become an active topic in artificial intelligence. Yet, similar investigation for graph-structured data clustering has been absent so far. To fill this gap, we present a Multi-View Graph embedding Clustering network (MVGC). Specifically, unlike traditional multi-view construction methods, which are only suitable to describe Euclidean structure data, we leverage Euler transform to augment the node attribute, as a new view descriptor, for non-Euclidean structure data. Meanwhile, we impose block diagonal representation constraint, which is measured by the ℓ 1 , 2 -norm, on self-expression coefficient matrix to well explore the cluster structure. By doing so, the learned view-consensus coefficient matrix well encodes the discriminative information. Moreover, we make use of the learned clustering labels to guide the learnings of node representation and coefficient matrix, where the latter is used in turn to conduct the subsequent clustering. In this way, clustering and representation learning are seamlessly connected, with the aim to achieve better clustering performance. Extensive experimental results indicate that MVGC is superior to 11 state-of-the-art methods on four benchmark datasets. In particular, MVGC achieves an Accuracy of 96.17% (53.31%) on the ACM (IMDB) dataset, which is an up to 2.85% (1.97%) clustering performance improvement compared with the strongest baseline.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100397X",
    "keywords": [
      "Artificial intelligence",
      "Cluster analysis",
      "Clustering coefficient",
      "Computer science",
      "Correlation clustering",
      "Data mining",
      "Embedding",
      "Graph",
      "Pattern recognition (psychology)",
      "Theoretical computer science"
    ],
    "authors": [
      {
        "surname": "Xia",
        "given_name": "Wei"
      },
      {
        "surname": "Wang",
        "given_name": "Sen"
      },
      {
        "surname": "Yang",
        "given_name": "Ming"
      },
      {
        "surname": "Gao",
        "given_name": "Quanxue"
      },
      {
        "surname": "Han",
        "given_name": "Jungong"
      },
      {
        "surname": "Gao",
        "given_name": "Xinbo"
      }
    ]
  },
  {
    "title": "Chapter four Neural simulation of a solar thermal system in low temperature",
    "journal": "Artificial Neural Networks for Renewable Energy Systems and Real-World Applications",
    "year": "2022",
    "doi": "10.1016/B978-0-12-820793-2.00005-7",
    "abstract": "The operation of a low-temperature solar thermal system using artificial neural network (ANN) models of its components (flat-plate solar collector, internal heat exchanger, and stratified tank), and its workings with dynamic and static modes, has been simulated. The ANN models of these components, used as blocks, have been previously formulated using the experimental data of solar irradiance, ambient temperature, flow and temperature of the working fluid and water supplied to the tank, and stratification temperatures in eight levels of the tank, measured under the continental Mediterranean climate conditions of central Iberian Peninsula. The simulation, executed in intervals of 1 minute, was run on 2 days for each month of 1 year. The f-chart method was used to validate the neural simulation under the same conditions (without stratification) for 10 years, resulting in an average deviation of the performance of 1.85%. The results for 1 day at stratification temperatures show a root mean square error value of 0.77°C in dynamic operation mode and of 0.13°C in static operation mode.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128207932000057",
    "keywords": [
      "Artificial neural network",
      "Biology",
      "Botany",
      "Computer science",
      "Dormancy",
      "Electrical engineering",
      "Engineering",
      "Environmental science",
      "Geography",
      "Germination",
      "Heat exchanger",
      "Machine learning",
      "Mathematics",
      "Mean squared error",
      "Mechanical engineering",
      "Meteorology",
      "Mode (computer interface)",
      "Operating system",
      "Root mean square",
      "Seed dormancy",
      "Solar irradiance",
      "Statistics",
      "Stratification (seeds)",
      "Thermal",
      "Thermal stratification",
      "Turbulence",
      "Wind speed"
    ],
    "authors": [
      {
        "surname": "Diez",
        "given_name": "Francisco J."
      },
      {
        "surname": "Chico-Santamarta",
        "given_name": "Leticia"
      },
      {
        "surname": "Correa-Guimaraes",
        "given_name": "Adriana"
      },
      {
        "surname": "Martínez-Rodríguez",
        "given_name": "Andrés"
      },
      {
        "surname": "Navas-Gracia",
        "given_name": "Luis M."
      }
    ]
  },
  {
    "title": "Learning policy scheduling for text augmentation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.09.028",
    "abstract": "When training deep learning models, data augmentation is an important technique to improve the performance and alleviate overfitting. In natural language processing (NLP), existing augmentation methods often use fixed strategies. However, it might be preferred to use different augmentation policies in different stage of training, and different datasets may require different augmentation policies. In this paper, we take dynamic policy scheduling into consideration. We design a search space over augmentation policies by integrating several common augmentation operations. Then, we adopt a population based training method to search the best augmentation schedule. We conduct extensive experiments on five text classification and two machine translation tasks. The results show that the optimized dynamic augmentation schedules achieve significant improvements against previous methods.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003907",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Demography",
      "Early stopping",
      "Engineering",
      "Machine learning",
      "Natural language processing",
      "Operating system",
      "Operations management",
      "Overfitting",
      "Population",
      "Schedule",
      "Scheduling (production processes)",
      "Sociology"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Shuokai"
      },
      {
        "surname": "Ao",
        "given_name": "Xiang"
      },
      {
        "surname": "Pan",
        "given_name": "Feiyang"
      },
      {
        "surname": "He",
        "given_name": "Qing"
      }
    ]
  },
  {
    "title": "Cross-attention-map-based regularization for adversarial domain adaptation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.013",
    "abstract": "In unsupervised domain adaptation (UDA), many efforts are taken to pull the source domain and the target domain closer by adversarial training. Most methods focus on aligning distributions or features between the source domain and the target domain. However, little attention is paid to the interaction between finer-grained levels, such as classes or samples of the two domains. In contrast to UDA, another transfer learning task, i.e., few-shot learning (FSL), takes full advantage of the finer-grained-level alignment. Many FSL methods implement the interaction between samples of support sets and query sets, leading to significant improvements. We wonder whether we can get some inspiration from these methods and bring such ideas of FSL to UDA. To this end, we first take a closer look at the differences between FSL and UDA and bridge the gap between them by high-confidence sample selection (HCSS). Then we propose cross-attention map generation module (CAMGM) to interact samples selected by HCSS. Moreover, we propose a simple but efficient method called cross-attention-map-based regularization (CAMR) to regularize the feature maps generated by the feature extractor. Experiments on three challenging datasets demonstrate that CAMR can bring solid improvements when added to the original objective. More specifically, the proposed CAMR can outperform original methods by 1% to 2% in most tasks without bells and whistles.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004044",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Computer science",
      "Domain (mathematical analysis)",
      "Feature (linguistics)",
      "Focus (optics)",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Regularization (linguistics)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Jingwei"
      },
      {
        "surname": "Wang",
        "given_name": "Huanjie"
      },
      {
        "surname": "Wu",
        "given_name": "Ke"
      },
      {
        "surname": "Liu",
        "given_name": "Chengbao"
      },
      {
        "surname": "Tan",
        "given_name": "Jie"
      }
    ]
  },
  {
    "title": "Approximation capabilities of neural networks on unbounded domains",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.001",
    "abstract": "There is limited study in the literature on the representability of neural networks on unbounded domains. For some application areas, results in this direction provide additional value in the design of learning systems. Motivated by an old option pricing problem, we are led to the study of this subject. For networks with a single hidden layer, we show that under suitable conditions they are capable of universal approximation in L p ( R × [ 0 , 1 ] n ) but not in L p ( R 2 × [ 0 , 1 ] n ) . For deeper networks, we prove that the ReLU network with two hidden layers is a universal approximator in L p ( R n ) .",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003920",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Chemistry",
      "Combinatorics",
      "Computer science",
      "Deep neural networks",
      "Layer (electronics)",
      "Machine learning",
      "Mathematical optimization",
      "Mathematics",
      "Organic chemistry",
      "Topology (electrical circuits)",
      "Value (mathematics)"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Ming-Xi"
      },
      {
        "surname": "Qu",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Chapter 10 Clinical applications of machine learning in heart failure",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00017-3",
    "abstract": "Machine learning is increasingly applied to problems in clinical medicine. Heart failure (HF) is a heterogeneous clinical syndrome whereby reductions in cardiac output lead to inadequate blood supply to meet the needs of peripheral tissues. It is an important clinical condition, requiring detailed investigations to guide its diagnosis, phenotyping, prognosis, and clinical management. Machine learning, in particular neural network-based algorithms, can be efficiently and more accurately used for performing all of these tasks by learning from the data. This chapter reviews the latest evidence on the different machine learning methodologies for improving diagnostic accuracy and risk stratification in HF. Despite the advantages of neural network modeling, the disadvantages include difficulty in interpretation with potential limited clinical transferability and applicability. Researchers have addressed these areas of weakness through techniques such as attention-weighting and feature transformation to increase the interpretability of findings from the “black box.” In the future, studies w to improve the predictive performance for HF-related adverse events, such as hospital readmissions, are needed to evaluate better patients’ quality of life and the disease burden on the public health system.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128198728000173",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Heart failure",
      "Intensive care medicine",
      "Internal medicine",
      "Interpretability",
      "Machine learning",
      "Medicine",
      "Radiology",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Xinmu"
      },
      {
        "surname": "Lee",
        "given_name": "Sharen"
      },
      {
        "surname": "Bazoukis",
        "given_name": "George"
      },
      {
        "surname": "Tse",
        "given_name": "Gary"
      },
      {
        "surname": "Liu",
        "given_name": "Tong"
      }
    ]
  },
  {
    "title": "Chapter 2 Computational imaging applications in brain and breast cancer",
    "journal": "State of the Art in Neural Networks and Their Applications",
    "year": "2023",
    "doi": "10.1016/B978-0-12-819872-8.00009-4",
    "abstract": "The rapid development of advanced computational algorithms from the domain of machine learning has shown promise for application in the clinical environment to (1) assist clinicians with tedious daily tasks and allow them to focus more on complex or urgent patient management, (2) offer second reads or opinions on tasks that require specialized training, as well as (3) assist in the training and education of new clinical experts. This chapter offers an overview of the state-of-the-art deep learning applications in the field of brain and breast cancer, as well as challenges and potential methods to improve the reproducibility of deep learning algorithms in biomedical image analysis of brain and breast cancer patients. The included references should not be considered as an exhaustive literature review but as studies serving as examples for the points made in this chapter.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128198728000094",
    "keywords": [
      "Artificial intelligence",
      "Breast cancer",
      "Cancer",
      "Computer science",
      "Data science",
      "Deep learning",
      "Domain (mathematical analysis)",
      "Field (mathematics)",
      "Focus (optics)",
      "Internal medicine",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Medical physics",
      "Medicine",
      "Optics",
      "Physics",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Gastounioti",
        "given_name": "Aimilia"
      },
      {
        "surname": "Rathore",
        "given_name": "Saima"
      },
      {
        "surname": "Maghsoudi",
        "given_name": "Omid Haji"
      },
      {
        "surname": "Conant",
        "given_name": "Emily F."
      },
      {
        "surname": "Kontos",
        "given_name": "Despina"
      },
      {
        "surname": "Bakas",
        "given_name": "Spyridon"
      }
    ]
  },
  {
    "title": "Exponential synchronization of coupled neural networks under stochastic deception attacks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.015",
    "abstract": "In this paper, the issue of synchronization is investigated for coupled neural networks subject to stochastic deception attacks. Firstly, a general differential inequality with delayed impulses is given. Then, the established differential inequality is further extended to the case of delayed stochastic impulses, in which both the impulsive instants and impulsive intensity are stochastic. Secondly, by modeling the stochastic discrete-time deception attacks as stochastic impulses, synchronization criteria of the coupled neural networks under the corresponding attacks are given. Finally, two numerical examples are provided to demonstrate the correctness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004068",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Correctness",
      "Deception",
      "Law",
      "Mathematical optimization",
      "Mathematics",
      "Political science",
      "Recurrent neural network",
      "Statistics",
      "Stochastic differential equation",
      "Stochastic neural network",
      "Stochastic process",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Huihui"
      },
      {
        "surname": "Li",
        "given_name": "Lulu"
      },
      {
        "surname": "Li",
        "given_name": "Xiaodi"
      }
    ]
  },
  {
    "title": "Cross-attention-map-based regularization for adversarial domain adaptation",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.013",
    "abstract": "In unsupervised domain adaptation (UDA), many efforts are taken to pull the source domain and the target domain closer by adversarial training. Most methods focus on aligning distributions or features between the source domain and the target domain. However, little attention is paid to the interaction between finer-grained levels, such as classes or samples of the two domains. In contrast to UDA, another transfer learning task, i.e., few-shot learning (FSL), takes full advantage of the finer-grained-level alignment. Many FSL methods implement the interaction between samples of support sets and query sets, leading to significant improvements. We wonder whether we can get some inspiration from these methods and bring such ideas of FSL to UDA. To this end, we first take a closer look at the differences between FSL and UDA and bridge the gap between them by high-confidence sample selection (HCSS). Then we propose cross-attention map generation module (CAMGM) to interact samples selected by HCSS. Moreover, we propose a simple but efficient method called cross-attention-map-based regularization (CAMR) to regularize the feature maps generated by the feature extractor. Experiments on three challenging datasets demonstrate that CAMR can bring solid improvements when added to the original objective. More specifically, the proposed CAMR can outperform original methods by 1% to 2% in most tasks without bells and whistles.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004044",
    "keywords": [
      "Adversarial system",
      "Artificial intelligence",
      "Computer science",
      "Domain (mathematical analysis)",
      "Feature (linguistics)",
      "Focus (optics)",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Optics",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Regularization (linguistics)"
    ],
    "authors": [
      {
        "surname": "Li",
        "given_name": "Jingwei"
      },
      {
        "surname": "Wang",
        "given_name": "Huanjie"
      },
      {
        "surname": "Wu",
        "given_name": "Ke"
      },
      {
        "surname": "Liu",
        "given_name": "Chengbao"
      },
      {
        "surname": "Tan",
        "given_name": "Jie"
      }
    ]
  },
  {
    "title": "A complementary learning approach for expertise transference of human-optimized controllers",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.009",
    "abstract": "In this paper, a complementary learning scheme for experience transference of unknown continuous-time linear systems is proposed. The algorithm is inspired in the complementary learning properties that exhibit the hippocampus and neocortex learning systems via the striatum. The hippocampus is modelled as pattern-separated data of a human optimized controller. The neocortex is modelled as a Q-reinforcement learning algorithm which improves the hippocampus control policy. The complementary learning (striatum) is designed as an inverse reinforcement learning algorithm which relates the hippocampus and neocortex learning models to seek and transfer the weights of the hidden expert’s utility function. Convergence of the proposed approach is analysed using Lyapunov recursions. Simulations are given to verify the proposed approach.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004007",
    "keywords": [
      "Artificial intelligence",
      "Computer science",
      "Convergence (economics)",
      "Dopamine",
      "Economic growth",
      "Economics",
      "Hippocampus",
      "Neocortex",
      "Neuroscience",
      "Psychology",
      "Reinforcement learning",
      "Striatum"
    ],
    "authors": [
      {
        "surname": "Perrusquía",
        "given_name": "Adolfo"
      }
    ]
  },
  {
    "title": "Cycle-consistent Adversarial Adaptation Network and its application to machine fault diagnosis",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.003",
    "abstract": "Driven by industrial big data and intelligent manufacturing, deep learning approaches have flourished and yielded impressive achievements in the community of machine fault diagnosis. Nevertheless, current diagnosis models trained on a specific dataset seldom work well on other datasets due to the domain discrepancy. Recently, adversarial domain adaptation-based approaches have become an emerging and compelling tool to address this issue. Nonetheless, existing methods still have a shortcoming since they cannot guarantee sufficient feature similarity between the source domain and the target domain after adaptation, resulting in unguaranteed performance. To this end, a Cycle-consistent Adversarial Adaptation Network (CAAN) is advanced to realize more effective fault diagnosis of machinery. In CAAN, specifically, an adversarial game formed by the feature extractor and the domain discriminator is constructed to induce transferable feature learning. Meanwhile, the feature translators and discriminators between source and target domains are further designed to build a more comprehensive cycle-consistent generative adversarial constrain, which can more reliably ensure domain-invariant and class-separate characteristics of learned features. Extensive experiments constructed on three datasets from different mechanical systems demonstrate the effectiveness and superiority of CAAN.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004317",
    "keywords": [
      "Adaptation (eye)",
      "Adversarial system",
      "Artificial intelligence",
      "Artificial neural network",
      "Classifier (UML)",
      "Computer science",
      "Deep learning",
      "Detector",
      "Discriminator",
      "Domain (mathematical analysis)",
      "Domain adaptation",
      "Fault (geology)",
      "Feature (linguistics)",
      "Feature engineering",
      "Feature learning",
      "Geology",
      "Linguistics",
      "Machine learning",
      "Mathematical analysis",
      "Mathematics",
      "Optics",
      "Philosophy",
      "Physics",
      "Seismology",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Jiao",
        "given_name": "Jinyang"
      },
      {
        "surname": "Lin",
        "given_name": "Jing"
      },
      {
        "surname": "Zhao",
        "given_name": "Ming"
      },
      {
        "surname": "Liang",
        "given_name": "Kaixuan"
      },
      {
        "surname": "Ding",
        "given_name": "Chuancang"
      }
    ]
  },
  {
    "title": "Exponential synchronization of coupled neural networks under stochastic deception attacks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.015",
    "abstract": "In this paper, the issue of synchronization is investigated for coupled neural networks subject to stochastic deception attacks. Firstly, a general differential inequality with delayed impulses is given. Then, the established differential inequality is further extended to the case of delayed stochastic impulses, in which both the impulsive instants and impulsive intensity are stochastic. Secondly, by modeling the stochastic discrete-time deception attacks as stochastic impulses, synchronization criteria of the coupled neural networks under the corresponding attacks are given. Finally, two numerical examples are provided to demonstrate the correctness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004068",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Channel (broadcasting)",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Correctness",
      "Deception",
      "Law",
      "Mathematical optimization",
      "Mathematics",
      "Political science",
      "Recurrent neural network",
      "Statistics",
      "Stochastic differential equation",
      "Stochastic neural network",
      "Stochastic process",
      "Synchronization (alternating current)",
      "Telecommunications"
    ],
    "authors": [
      {
        "surname": "Zhang",
        "given_name": "Huihui"
      },
      {
        "surname": "Li",
        "given_name": "Lulu"
      },
      {
        "surname": "Li",
        "given_name": "Xiaodi"
      }
    ]
  },
  {
    "title": "Multi-level attention pooling for graph neural networks: Unifying graph representations with multiple localities",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.11.001",
    "abstract": "Graph neural networks (GNNs) have been widely used to learn vector representation of graph-structured data and achieved better task performance than conventional methods. The foundation of GNNs is the message passing procedure, which propagates the information in a node to its neighbors. Since this procedure proceeds one step per layer, the range of the information propagation among nodes is small in the lower layers, and it expands toward the higher layers. Therefore, a GNN model has to be deep enough to capture global structural information in a graph. On the other hand, it is known that deep GNN models suffer from performance degradation because they lose nodes’ local information, which would be essential for good model performance, through many message passing steps. In this study, we propose multi-level attention pooling (MLAP) for graph-level classification tasks, which can adapt to both local and global structural information in a graph. It has an attention pooling layer for each message passing step and computes the final graph representation by unifying the layer-wise graph representations. The MLAP architecture allows models to utilize the structural information of graphs with multiple levels of localities because it preserves layer-wise information before losing them due to oversmoothing. Results of our experiments show that the MLAP architecture improves the graph classification performance compared to the baseline architectures. In addition, analyses on the layer-wise graph representations suggest that aggregating information from multiple levels of localities indeed has the potential to improve the discriminability of learned graph representations.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004299",
    "keywords": [],
    "authors": [
      {
        "surname": "Itoh",
        "given_name": "Takeshi D."
      },
      {
        "surname": "Kubo",
        "given_name": "Takatomi"
      },
      {
        "surname": "Ikeda",
        "given_name": "Kazushi"
      }
    ]
  },
  {
    "title": "Event-based master–slave synchronization of complex-valued neural networks via pinning impulsive control",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.025",
    "abstract": "This paper investigates the synchronization problem of complex-valued neural networks via event-triggered pinning impulsive control (ETPIC). A time-delayed pinning impulsive controller is proposed based on three levels of event-triggered conditions. By employing the Lyapunov functional method and differential inequality technique, sufficient delay-dependent synchronization criteria are derived under the proposed ETPIC scheme. The obtained result shows that synchronization of master and slave complex-valued neural networks can be achieved even if the sizes of delays exceed the length of intervals between any two consecutive impulsive instants determined by Lyapunov-based event-triggered conditions in the proposed control strategy. Moreover, the linear matrix inequality approach is utilized to exclude Zeno behavior. Numerical examples are provided to illustrate the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004263",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Differential inclusion",
      "Event (particle physics)",
      "Geometry",
      "Linear matrix inequality",
      "Lyapunov function",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Zeno's paradoxes"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Yuan"
      },
      {
        "surname": "Liu",
        "given_name": "Xinzhi"
      }
    ]
  },
  {
    "title": "IC neuron: An efficient unit to construct neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.005",
    "abstract": "As a popular machine learning method, neural networks can be used to solve many complex tasks. Their strong generalization ability comes from the representation ability of the basic neuron models. The most popular neuron model is the McCulloch–Pitts (MP) neuron, which uses a simple transformation to process the input signal. A common trend is to use the MP neuron to design various neural networks. However, the optimization of the neuron structure is rarely considered. Inspired by the elastic collision model in physics, we propose a new neuron model that can represent more complex distributions. We term it the Inter-layer Collision (IC) neuron which divides the input space into multiple subspaces to represent different linear transformations. Through this operation, the IC neuron enhances the non-linear representation ability and emphasizes useful input features for a given task. We build the IC networks by integrating the IC neurons into the fully-connected, the convolutional, and the recurrent structures. The IC networks outperform the traditional neural networks in a wide range of tasks. Besides, we combine the IC neuron with deep learning models and show the superiority of the IC neuron. Our research proves that the IC neuron can be an effective basic unit to build network structures and make the network performance better.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003968",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Biological neuron model",
      "Biology",
      "Computer science",
      "Convolutional neural network",
      "Deep learning",
      "Law",
      "Neuron",
      "Neuroscience",
      "Political science",
      "Politics",
      "Representation (politics)",
      "Winner-take-all"
    ],
    "authors": [
      {
        "surname": "An",
        "given_name": "Junyi"
      },
      {
        "surname": "Liu",
        "given_name": "Fengshan"
      },
      {
        "surname": "Shen",
        "given_name": "Furao"
      },
      {
        "surname": "Zhao",
        "given_name": "Jian"
      },
      {
        "surname": "Li",
        "given_name": "Ruotong"
      },
      {
        "surname": "Gao",
        "given_name": "Kepan"
      }
    ]
  },
  {
    "title": "New effective approach to quasi synchronization of coupled heterogeneous complex networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.019",
    "abstract": "This short paper addresses quasi synchronization of linearly coupled heterogeneous systems. Similarity and difference between the complete synchronization of linearly coupled homogeneous systems and the quasi synchronization of linearly coupled heterogeneous systems will be revealed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100410X",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Complex network",
      "Complex system",
      "Computer science",
      "Heterogeneous network",
      "Homogeneous",
      "Image (mathematics)",
      "Mathematics",
      "Physics",
      "Similarity (geometry)",
      "Statistical physics",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Topology (electrical circuits)",
      "Wireless",
      "Wireless network",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Tianping"
      }
    ]
  },
  {
    "title": "Curriculum learning with Hindsight Experience Replay for sequential object manipulation tasks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.011",
    "abstract": "Learning complex tasks from scratch is challenging and often impossible for humans as well as for artificial agents. Instead, a curriculum can be used, which decomposes a complex task – the target task – into a sequence of source tasks. Each source task is a simplified version of the next source task with increasing complexity. Learning then occurs gradually by training on each source task while using knowledge from the curriculum’s prior source tasks. In this study, we present a new algorithm that combines curriculum learning with Hindsight Experience Replay (HER), to learn sequential object manipulation tasks for multiple goals and sparse feedback. The algorithm exploits the recurrent structure inherent in many object manipulation tasks and implements the entire learning process in the original simulation without adjusting it to each source task. We test our algorithm on three challenging throwing tasks in simulation and show significant improvements compared to vanilla-HER.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004020",
    "keywords": [],
    "authors": [
      {
        "surname": "Manela",
        "given_name": "B."
      },
      {
        "surname": "Biess",
        "given_name": "A."
      }
    ]
  },
  {
    "title": "Event-based master–slave synchronization of complex-valued neural networks via pinning impulsive control",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.025",
    "abstract": "This paper investigates the synchronization problem of complex-valued neural networks via event-triggered pinning impulsive control (ETPIC). A time-delayed pinning impulsive controller is proposed based on three levels of event-triggered conditions. By employing the Lyapunov functional method and differential inequality technique, sufficient delay-dependent synchronization criteria are derived under the proposed ETPIC scheme. The obtained result shows that synchronization of master and slave complex-valued neural networks can be achieved even if the sizes of delays exceed the length of intervals between any two consecutive impulsive instants determined by Lyapunov-based event-triggered conditions in the proposed control strategy. Moreover, the linear matrix inequality approach is utilized to exclude Zeno behavior. Numerical examples are provided to illustrate the effectiveness of the theoretical results.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004263",
    "keywords": [
      "Agronomy",
      "Artificial intelligence",
      "Artificial neural network",
      "Biology",
      "Combinatorics",
      "Computer science",
      "Control (management)",
      "Control theory (sociology)",
      "Controller (irrigation)",
      "Differential inclusion",
      "Event (particle physics)",
      "Geometry",
      "Linear matrix inequality",
      "Lyapunov function",
      "Mathematical optimization",
      "Mathematics",
      "Nonlinear system",
      "Physics",
      "Quantum mechanics",
      "Synchronization (alternating current)",
      "Topology (electrical circuits)",
      "Zeno's paradoxes"
    ],
    "authors": [
      {
        "surname": "Shen",
        "given_name": "Yuan"
      },
      {
        "surname": "Liu",
        "given_name": "Xinzhi"
      }
    ]
  },
  {
    "title": "Curriculum learning with Hindsight Experience Replay for sequential object manipulation tasks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.011",
    "abstract": "Learning complex tasks from scratch is challenging and often impossible for humans as well as for artificial agents. Instead, a curriculum can be used, which decomposes a complex task – the target task – into a sequence of source tasks. Each source task is a simplified version of the next source task with increasing complexity. Learning then occurs gradually by training on each source task while using knowledge from the curriculum’s prior source tasks. In this study, we present a new algorithm that combines curriculum learning with Hindsight Experience Replay (HER), to learn sequential object manipulation tasks for multiple goals and sparse feedback. The algorithm exploits the recurrent structure inherent in many object manipulation tasks and implements the entire learning process in the original simulation without adjusting it to each source task. We test our algorithm on three challenging throwing tasks in simulation and show significant improvements compared to vanilla-HER.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004020",
    "keywords": [],
    "authors": [
      {
        "surname": "Manela",
        "given_name": "B."
      },
      {
        "surname": "Biess",
        "given_name": "A."
      }
    ]
  },
  {
    "title": "New effective approach to quasi synchronization of coupled heterogeneous complex networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.019",
    "abstract": "This short paper addresses quasi synchronization of linearly coupled heterogeneous systems. Similarity and difference between the complete synchronization of linearly coupled homogeneous systems and the quasi synchronization of linearly coupled heterogeneous systems will be revealed.",
    "link": "https://www.sciencedirect.com/science/article/pii/S089360802100410X",
    "keywords": [
      "Artificial intelligence",
      "Combinatorics",
      "Complex network",
      "Complex system",
      "Computer science",
      "Heterogeneous network",
      "Homogeneous",
      "Image (mathematics)",
      "Mathematics",
      "Physics",
      "Similarity (geometry)",
      "Statistical physics",
      "Synchronization (alternating current)",
      "Telecommunications",
      "Topology (electrical circuits)",
      "Wireless",
      "Wireless network",
      "World Wide Web"
    ],
    "authors": [
      {
        "surname": "Chen",
        "given_name": "Tianping"
      }
    ]
  },
  {
    "title": "Chapter nine Incremental deep learning model for plant leaf diseases detection",
    "journal": "Artificial Neural Networks for Renewable Energy Systems and Real-World Applications",
    "year": "2022",
    "doi": "10.1016/B978-0-12-820793-2.00011-2",
    "abstract": "In recent years, deep learning has revolutionized machine learning and has been used with great success in various engineering fields, such as transportation, agriculture, finance, and marketing. The interest in deep learning for such applications is due to its ability to manage gigantic volumes of data and model complex interrelated systems in order to improve decision-making, reduce costs, and optimize resources. In the field of agriculture, plant diseases affect the growth of various species, hence there is a need to identify and treat them early. In this work, we propose an incremental learning method based on deep neural networks for the classification of plant diseases. The goal of incremental learning is to allow the learning model to adapt to the arrival of new data without forgetting its previously existing knowledge. Our method is based on preserving the diversity of old data, some of which will be used when training the network for new tasks. To test the effectiveness of the approach, we tested it on the PlantVillage Dataset. The experimental results have shown that this method is efficient and provides better results than the incremental model iCaRL.",
    "link": "https://www.sciencedirect.com/science/article/pii/B9780128207932000112",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Data science",
      "Deep learning",
      "Field (mathematics)",
      "Forgetting",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Philosophy",
      "Pure mathematics"
    ],
    "authors": [
      {
        "surname": "Ouadfel",
        "given_name": "Salima"
      },
      {
        "surname": "Mousser",
        "given_name": "Wafa"
      },
      {
        "surname": "Ghoul",
        "given_name": "Ismail"
      },
      {
        "surname": "Taleb-Ahmed",
        "given_name": "Abdelmalik"
      }
    ]
  },
  {
    "title": "FCL-Net: Towards accurate edge detection via Fine-scale Corrective Learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.022",
    "abstract": "Integrating multi-scale predictions has become a mainstream paradigm in edge detection. However, most existing methods mainly focus on effective feature extraction and multi-scale feature fusion while ignoring the low learning capacity in fine-level branches, limiting the overall fusion performance. In light of this, we propose a novel Fine-scale Corrective Learning Net (FCL-Net) that exploits semantic information from deep layers to facilitate fine-scale feature learning. FCL-Net mainly consists of a Top-down Attentional Guiding (TAG) and a Pixel-level Weighting (PW) module. TAG module adopts semantic attentional cues from coarse-scale prediction into guiding the fine-scale branches by learning a top-down LSTM. PW module treats the contribution of each spatial location independently and promote fine-level branches to detect detailed edges with high confidence. Experiments on three benchmark datasets, i.e., BSDS500, Multicue, and BIPED, show that our approach significantly outperforms the baseline and achieves a competitive ODS F-measure of 0.826 on the BSDS500 benchmark. The source code and models are publicly available at https://github.com/DREAMXFAR/FCL-Net.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004135",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Computer science",
      "Computer security",
      "Enhanced Data Rates for GSM Evolution",
      "Exploit",
      "Feature (linguistics)",
      "Feature extraction",
      "Feature learning",
      "Geodesy",
      "Geography",
      "Geometry",
      "Linguistics",
      "Machine learning",
      "Mathematics",
      "Medicine",
      "Net (polyhedron)",
      "Pattern recognition (psychology)",
      "Philosophy",
      "Physics",
      "Quantum mechanics",
      "Radiology",
      "Scale (ratio)",
      "Weighting"
    ],
    "authors": [
      {
        "surname": "Xuan",
        "given_name": "Wenjie"
      },
      {
        "surname": "Huang",
        "given_name": "Shaoli"
      },
      {
        "surname": "Liu",
        "given_name": "Juhua"
      },
      {
        "surname": "Du",
        "given_name": "Bo"
      }
    ]
  },
  {
    "title": "Generalized attention-weighted reinforcement learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.09.023",
    "abstract": "In neuroscience, attention has been shown to bidirectionally interact with reinforcement learning (RL) to reduce the dimensionality of task representations, restricting computations to relevant features. In machine learning, despite their popularity, attention mechanisms have seldom been administered to decision-making problems. Here, we leverage a theoretical model from computational neuroscience – the attention-weighted RL (AWRL), defining how humans identify task-relevant features (i.e., that allow value predictions) – to design an applied deep RL paradigm. We formally demonstrate that the conjunction of the self-attention mechanism, widely employed in machine learning, with value function approximation is a general formulation of the AWRL model. To evaluate our agent, we train it on three Atari tasks at different complexity levels, incorporating both task-relevant and irrelevant features. Because the model uses semantic observations, we can uncover not only which features the agent elects to base decisions on, but also how it chooses to compile more complex, relational features from simpler ones. We first show that performance depends in large part on the ability to compile new compound features, rather than mere focus on individual features. In line with neuroscience predictions, self-attention leads to high resiliency to noise (irrelevant features) compared to other benchmark models. Finally, we highlight the importance and separate contributions of both bottom-up and top-down attention in the learning process. Together, these results demonstrate the broader validity of the AWRL framework in complex task scenarios, and illustrate the benefits of a deeper integration between neuroscience-derived models and RL for decision making in machine learning.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003853",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Biology",
      "Computational model",
      "Computer science",
      "Curse of dimensionality",
      "Economics",
      "Evolutionary biology",
      "Function (biology)",
      "Geodesy",
      "Geography",
      "Leverage (statistics)",
      "Machine learning",
      "Management",
      "Reinforcement learning",
      "Task (project management)"
    ],
    "authors": [
      {
        "surname": "Bramlage",
        "given_name": "Lennart"
      },
      {
        "surname": "Cortese",
        "given_name": "Aurelio"
      }
    ]
  },
  {
    "title": "LGN-CNN: A biologically inspired CNN architecture",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.09.024",
    "abstract": "In this paper we introduce a biologically inspired Convolutional Neural Network (CNN) architecture called LGN-CNN that has a first convolutional layer composed of a single filter that mimics the role of the Lateral Geniculate Nucleus (LGN). The first layer of the neural network shows a rotational symmetric pattern justified by the structure of the net itself that turns up to be an approximation of a Laplacian of Gaussian (LoG). The latter function is in turn a good approximation of the receptive field profiles (RFPs) of the cells in the LGN. The analogy with the visual system is established, emerging directly from the architecture of the neural network. A proof of rotation invariance of the first layer is given on a fixed LGN-CNN architecture and the computational results are shown. Thus, contrast invariance capability of the LGN-CNN is investigated and a comparison between the Retinex effects of the first layer of LGN-CNN and the Retinex effects of a LoG is provided on different images. A statistical study is done on the filters of the second convolutional layer with respect to biological data. In conclusion, the model we have introduced approximates well the RFPs of both LGN and V1 attaining similar behavior as regards long range connections of LGN cells that show Retinex effects.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003865",
    "keywords": [
      "Algorithm",
      "Artificial intelligence",
      "Biology",
      "Blob detection",
      "Color constancy",
      "Computer science",
      "Computer security",
      "Convolutional neural network",
      "Edge detection",
      "Image (mathematics)",
      "Image processing",
      "Laplace operator",
      "Lateral geniculate nucleus",
      "Mathematical analysis",
      "Mathematics",
      "Network architecture",
      "Neuroscience",
      "Pattern recognition (psychology)",
      "Visual cortex"
    ],
    "authors": [
      {
        "surname": "Bertoni",
        "given_name": "Federico"
      },
      {
        "surname": "Citti",
        "given_name": "Giovanna"
      },
      {
        "surname": "Sarti",
        "given_name": "Alessandro"
      }
    ]
  },
  {
    "title": "Enriching query semantics for code search with reinforcement learning",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.09.025",
    "abstract": "Code search is a common practice for developers during software implementation. The challenges of accurate code search mainly lie in the knowledge gap between source code and natural language (i.e., queries). Due to the limited code-query pairs and large code-description pairs available, the prior studies based on deep learning techniques focus on learning the semantic matching relation between source code and corresponding description texts for the task, and hypothesize that the semantic gap between descriptions and user queries is marginal. In this work, we found that the code search models trained on code-description pairs may not perform well on user queries, which indicates the semantic distance between queries and code descriptions. To mitigate the semantic distance for more effective code search, we propose QueCos, a Query-enriched Code search model. QueCos learns to generate semantic enriched queries to capture the key semantics of given queries with reinforcement learning (RL). With RL, the code search performance is considered as a reward for producing accurate semantic enriched queries. The enriched queries are finally employed for code search. Experiments on the benchmark datasets show that QueCos can significantly outperform the state-of-the-art code search models.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021003877",
    "keywords": [
      "Artificial intelligence",
      "Benchmark (surveying)",
      "Code (set theory)",
      "Codebase",
      "Computer science",
      "Geodesy",
      "Geography",
      "Information retrieval",
      "Matching (statistics)",
      "Mathematics",
      "Natural language processing",
      "Programming language",
      "Reinforcement learning",
      "Search engine",
      "Semantic Web",
      "Semantic matching",
      "Semantic search",
      "Semantics (computer science)",
      "Set (abstract data type)",
      "Source code",
      "Statistics",
      "Web search query"
    ],
    "authors": [
      {
        "surname": "Wang",
        "given_name": "Chaozheng"
      },
      {
        "surname": "Nong",
        "given_name": "Zhenhao"
      },
      {
        "surname": "Gao",
        "given_name": "Cuiyun"
      },
      {
        "surname": "Li",
        "given_name": "Zongjie"
      },
      {
        "surname": "Zeng",
        "given_name": "Jichuan"
      },
      {
        "surname": "Xing",
        "given_name": "Zhenchang"
      },
      {
        "surname": "Liu",
        "given_name": "Yang"
      }
    ]
  },
  {
    "title": "Epistemic uncertainty quantification in deep learning classification by the Delta method",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.014",
    "abstract": "The Delta method is a classical procedure for quantifying epistemic uncertainty in statistical models, but its direct application to deep neural networks is prevented by the large number of parameters P . We propose a low cost approximation of the Delta method applicable to L 2 -regularized deep neural networks based on the top K eigenpairs of the Fisher information matrix. We address efficient computation of full-rank approximate eigendecompositions in terms of the exact inverse Hessian, the inverse outer-products of gradients approximation and the so-called Sandwich estimator. Moreover, we provide bounds on the approximation error for the uncertainty of the predictive class probabilities. We show that when the smallest computed eigenvalue of the Fisher information matrix is near the L 2 -regularization rate, the approximation error will be close to zero even when K ≪ P . A demonstration of the methodology is presented using a TensorFlow implementation, and we show that meaningful rankings of images based on predictive uncertainty can be obtained for two LeNet and ResNet-based neural networks using the MNIST and CIFAR-10 datasets. Further, we observe that false positives have on average a higher predictive epistemic uncertainty than true positives. This suggests that there is supplementing information in the uncertainty measure not captured by the classification alone.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004056",
    "keywords": [
      "Algorithm",
      "Applied mathematics",
      "Artificial intelligence",
      "Artificial neural network",
      "Composite material",
      "Computer science",
      "Estimator",
      "Fisher information",
      "Geometry",
      "Hessian matrix",
      "Inverse",
      "MNIST database",
      "Machine learning",
      "Materials science",
      "Mathematics",
      "Matrix (chemical analysis)",
      "Regularization (linguistics)",
      "Statistics",
      "Uncertainty quantification"
    ],
    "authors": [
      {
        "surname": "Nilsen",
        "given_name": "Geir K."
      },
      {
        "surname": "Munthe-Kaas",
        "given_name": "Antonella Z."
      },
      {
        "surname": "Skaug",
        "given_name": "Hans J."
      },
      {
        "surname": "Brun",
        "given_name": "Morten"
      }
    ]
  },
  {
    "title": "FOREX rate prediction improved by Elliott waves patterns based on neural networks",
    "journal": "Neural Networks",
    "year": "2022",
    "doi": "10.1016/j.neunet.2021.10.024",
    "abstract": "Financial market predictions represent a complex problem. Most prediction systems work with the term time window, which is represented by exchange rate values of a real financial commodity. Such values (time window) provide the base for prediction of future values. Real situations, however, prove that prediction of only a single time-series trend is insufficient. This article aims at suggesting a novelty and unconventional approach based on the use of several neural networks predicting probable courses of a future trend defined in a prediction time window. The basis of the proposed approach is a suitable representation of the training-set input data into the neural networks. It uses selected FFT coefficients as well as robust output indicators based on a histogram of the predicted course of the selected currency pair. At the same time, the given currency pair enters the prediction in a combination with another three mutually interconnected currency pairs. A significant output of the articles is, apart from the proposed methodology, confirmation that the Elliott wave theory is beneficial in the trading environment and provides a substantial profit compared with conventional prediction techniques. That was proved in the performed experimental study.",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608021004251",
    "keywords": [
      "Artificial intelligence",
      "Artificial neural network",
      "Computer science",
      "Currency",
      "Econometrics",
      "Economics",
      "Exchange rate",
      "Finance",
      "Foreign exchange market",
      "Machine learning",
      "Mathematics",
      "Monetary economics",
      "Novelty",
      "Philosophy",
      "Theology"
    ],
    "authors": [
      {
        "surname": "Jarusek",
        "given_name": "Robert"
      },
      {
        "surname": "Volna",
        "given_name": "Eva"
      },
      {
        "surname": "Kotyrba",
        "given_name": "Martin"
      }
    ]
  }
]